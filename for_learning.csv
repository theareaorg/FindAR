index,Title,Citation,DOI,Abstract,Classification_index_terms,Uncontrolled_terms,Controlled_terms,Year,Document_type,Journal_name,Authors,Authors_affiliation,PN,Relevant,LowLevel,LowLvlList,lowlvl,MidLevel,HighLevel,midlvl,highlvl,combinedTagsNew,ideaTags,ideaAbs,cleanAbstract,TagsPlusAbstract,IdeasTagsPlusAbstract
0,An Augmented Reality System with Advanced User Interfaces for Image-Guided Intervention Applications,"Bettati, P., & Fei, B. (2023). An advanced system with advanced user interfaces for image-guided intervention applications. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2653952
",10.1117/12.2653952,"Augmented Reality (AR) is becoming a more common addition to physicians' repertoire for aiding in resident training and patient interactions. However, the use of augmented reality in clinical settings is still beset with many complications, including the lack of physician control over the systems, set modes of interactions within the system, and physician's lack of familiarity with such AR systems. In this paper, we plan to expand on our previous prostate biopsy AR system by adding in improved user interface systems within the virtual world in order to allow the user to more accurately visualize only parts of the system which they consider to be useful at that time. To accomplish this, we have incorporated three-dimensional virtual sliders built from the ground up, using Unity to afford control over each model's RGB values, as well as their transparency. This means that the user would be able to fully edit the color, and transparency of each individual model in real time as they see fit quickly and easily while still being immersed in the augmented space. This would allow users to view internal holograms while not sacrificing the capability to view the external structure. Such leeway could be invaluable when visualizing a tumor within a prostate and would provide the physician with the capability to view as much or as little of the surrounded virtual models as desired, while providing the option to reinstate the surrounding models at will. The AR system can provide a new approach for potential uses in image-guided interventions including targeted biopsy of the prostate. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;746 Imaging Techniques",Advanced user interfaces;Augmented reality;Augmented reality systems;Clinical settings;Image-guided Intervention;Interface system;Patient interaction;Prostate biopsy;Virtual reality;Virtual worlds,Augmented reality;Biopsy;Transparency;Urology;User interfaces;Virtual reality,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Bettati, Patric; (1) Fei, Baowei; ","(1) Center for Imaging and Surgical Innovation, University of Texas at Dallas, Richardson; TX, United States; (2) Department of Bioengineering, University of Texas at Dallas, Richardson; TX, United States; (3) Department of Radiology, University of Texas Southwestern Medical Center, Dallas; TX, United States; ",SPIE,-1,"[""biopsy"", ""transparency"", ""urology"", ""user interfaces""]","[""biopsy"", ""transparency"", ""urology"", ""user interfaces""]",biopsy;transparency;urology;user interfaces,medical;graphics;human-computer interaction,technology;industries;end users and user experience,medical;graphics;human-computer interaction,technology;industries;end users and user experience,biopsy transparency urology user_interfaces advanced_user_interfaces augmented_reality augmented_reality_systems clinical_settings image guided_intervention interface_system patient_interaction prostate_biopsy virtual_reality virtual_worlds 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 746_imaging_techniques medical graphics human computer_interaction,biopsy transparency urology user_interfaces,advanced_user_interfaces augmented_reality augmented_reality_systems clinical_settings image guided_intervention interface_system patient_interaction prostate_biopsy virtual_reality virtual_worlds,augmented reality ar becoming common addition physician repertoire aiding resident training patient interaction however use augmented reality clinical setting still beset many complication including lack physician control system set mode interaction within system physician lack familiarity ar system paper plan expand previous prostate biopsy ar system adding improved user interface system within virtual world order allow user accurately visualize part system consider useful time accomplish incorporated three dimensional virtual slider built ground using unity afford control model rgb value well transparency mean user would able fully edit color transparency individual model real time see fit quickly easily still immersed augmented space would allow user view internal hologram sacrificing capability view external structure leeway could invaluable visualizing tumor within prostate would provide physician capability view much little surrounded virtual model desired providing option reinstate surrounding model ar system provide new approach potential us image guided intervention including targeted biopsy prostate copy 2023 spie,biopsy transparency urology user_interfaces advanced_user_interfaces augmented_reality augmented_reality_systems clinical_settings image guided_intervention interface_system patient_interaction prostate_biopsy virtual_reality virtual_worlds 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 746_imaging_techniques medical graphics human computer_interaction augmented reality ar becoming common addition physician repertoire aiding resident training patient interaction however use augmented reality clinical setting still beset many complication including lack physician control system set mode interaction within system physician lack familiarity ar system paper plan expand previous prostate biopsy ar system adding improved user interface system within virtual world order allow user accurately visualize part system consider useful time accomplish incorporated three dimensional virtual slider built ground using unity afford control model rgb value well transparency mean user would able fully edit color transparency individual model real time see fit quickly easily still immersed augmented space would allow user view internal hologram sacrificing capability view external structure leeway could invaluable visualizing tumor within prostate would provide physician capability view much little surrounded virtual model desired providing option reinstate surrounding model ar system provide new approach potential us image guided intervention including targeted biopsy prostate copy 2023 spie,augmented reality ar becoming common addition physician repertoire aiding resident training patient interaction however use augmented reality clinical setting still beset many complication including lack physician control system set mode interaction within system physician lack familiarity ar system paper plan expand previous prostate biopsy ar system adding improved user interface system within virtual world order allow user accurately visualize part system consider useful time accomplish incorporated three dimensional virtual slider built ground using unity afford control model rgb value well transparency mean user would able fully edit color transparency individual model real time see fit quickly easily still immersed augmented space would allow user view internal hologram sacrificing capability view external structure leeway could invaluable visualizing tumor within prostate would provide physician capability view much little surrounded virtual model desired providing option reinstate surrounding model ar system provide new approach potential us image guided intervention including targeted biopsy prostate copy 2023 spiebiopsy transparency urology user_interfacesadvanced_user_interfaces augmented_reality augmented_reality_systems clinical_settings image guided_intervention interface_system patient_interaction prostate_biopsy virtual_reality virtual_worlds
1,A New Trend in Car Personalization Based on Augmented Reality: A Study,"Husár, J., Hrehova, S., Knapčíková, L., & Trojanowska, J. (2023). A New Trend in Car Personalization Based on Augmented Reality: A Study. EAI/Springer Innovations in Communication and Computing, 165–178. https://doi.org/10.1007/978-3-031-28225-6_11
",10.1007/978-3-031-28225-6_11,"The article points to a new trend occurring in marketing. In the car industry, there is a lot of money and that is why car companies come to the market with new ideas. Augmented reality has become one of the tools to transfer the 3D dimension to the customer. Publicly available applications are being created that allow us to personalize car models according to our own requirements. The customer can choose the type, colour, design and equipment of the car. He can then project the configured car into space using a mobile phone. In the article, we want to present and compare three freely available augmented reality applications from three automotive companies. Each of the evaluated applications has its advantages and disadvantages, but this article points to selected parameters and options for working with the application for the best possible experience. In the end, individual applications of augmented reality are compared. In the article, we wanted to show that applications can be used in marketing to create the first contact with the client. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","662.1 Automobiles;723 Computer Software, Data Handling and Applications;911.4 Marketing",Augmented reality applications;Automotive companies;Car companies;Car industry;Car models;Color design;Personalizations,Augmented reality;Commerce;Marketing;Model automobiles,2023,Conference article (CA),EAI/Springer Inno. Comm. Comp.,"(1) Hus&aacute;r, Jozef; (1) Hrehova, Stella; (1) Knap&#269;&iacute;kov&aacute;, Lucia; (2) Trojanowska, Justyna; ","(1) Technical University of Ko&scaron;ice, Faculty of Manufacturing Technologies with a seat in Pre&scaron;ov, Department of Industrial Engineering and Informatics, Pre&scaron;ov, Slovakia; (2) Poznan University of Technology, Faculty of Mechanical Engineering, Department of Production Engineering, Poznan, Poland; ",Springer Science and Business Media Deutschland GmbH,-1,"[""commerce"", ""marketing"", ""model automobiles""]","[""commerce"", ""marketing"", ""model automobiles""]",commerce;marketing;model automobiles,sales and marketing;other;automotive,other;business;industries,sales and marketing;other;automotive,other;business;industries,commerce marketing model_automobiles augmented_reality_applications automotive_companies car_companies car_industry car_models color_design personalizations 662 1_automobiles 723_computer_software _data_handling_and_applications 911 4_marketing sales_and_marketing other automotive,commerce marketing model_automobiles,augmented_reality_applications automotive_companies car_companies car_industry car_models color_design personalizations,article point new trend occurring marketing car industry lot money car company come market new idea augmented reality become one tool transfer 3d dimension customer publicly available application created allow u personalize car model according requirement customer choose type colour design equipment car project configured car space using mobile phone article want present compare three freely available augmented reality application three automotive company evaluated application advantage disadvantage article point selected parameter option working application best possible experience end individual application augmented reality compared article wanted show application used marketing create first contact client copy 2023 author exclusive license springer nature switzerland ag,commerce marketing model_automobiles augmented_reality_applications automotive_companies car_companies car_industry car_models color_design personalizations 662 1_automobiles 723_computer_software _data_handling_and_applications 911 4_marketing sales_and_marketing other automotive article point new trend occurring marketing car industry lot money car company come market new idea augmented reality become one tool transfer 3d dimension customer publicly available application created allow u personalize car model according requirement customer choose type colour design equipment car project configured car space using mobile phone article want present compare three freely available augmented reality application three automotive company evaluated application advantage disadvantage article point selected parameter option working application best possible experience end individual application augmented reality compared article wanted show application used marketing create first contact client copy 2023 author exclusive license springer nature switzerland ag,article point new trend occurring marketing car industry lot money car company come market new idea augmented reality become one tool transfer 3d dimension customer publicly available application created allow u personalize car model according requirement customer choose type colour design equipment car project configured car space using mobile phone article want present compare three freely available augmented reality application three automotive company evaluated application advantage disadvantage article point selected parameter option working application best possible experience end individual application augmented reality compared article wanted show application used marketing create first contact client copy 2023 author exclusive license springer nature switzerland agcommerce marketing model_automobilesaugmented_reality_applications automotive_companies car_companies car_industry car_models color_design personalizations
2,Introduction to the application of Augmented Reality technology in the digital manufacturing process,"Zhao, Z., Jia, Z., & Li, Y. (2023). Introduction to the application of augmented reality technology in the digital manufacturing process. Ninth Symposium on Novel Photoelectronic Detection Technology and Applications. https://doi.org/10.1117/12.2664386
",10.1117/12.2664386,"Augmented Reality (AR) technology can skillfully blend virtual information with the real world, so it can greatly help the development of the manufacturing industry. The AR technology in this paper is mainly focused on 3D laser projection technology. This paper first describes the application background of AR technology. And then the basic principles of AR are analyzed and the key technologies such as virtual-real mapping and so on are systematically sorted out. On this basis, the basic composition of the AR system is described. And then, the application area is set out in the aviation manufacturing industry, aerospace manufacturing industry, shipbuilding, and so on. At last, we design an experiment to verify the laser spot error distribution of the calibration result point. &copy; 2023 SPIE.","405.3 Surveying;723 Computer Software, Data Handling and Applications",Augmented reality technology;Basic principles;Digital manufacturing;Laser projection;Manufacturing industries;Manufacturing process;Projection technology;Real-world;Virtual information;Virtual-real mapping,Augmented reality,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zhao, Ziyue; (1) Jia, Zhiting; (1) Li, Yan; ","(1) Changcheng Institute of Metrology and Measurement, Avic, Beijing, China; ",SPIE,-1,[],[],other,other,other,other,other,other augmented_reality_technology basic_principles digital_manufacturing laser_projection manufacturing_industries manufacturing_process projection_technology real world virtual_information virtual real_mapping 405 3_surveying 723_computer_software _data_handling_and_applications other,other,augmented_reality_technology basic_principles digital_manufacturing laser_projection manufacturing_industries manufacturing_process projection_technology real world virtual_information virtual real_mapping,augmented reality ar technology skillfully blend virtual information real world greatly help development manufacturing industry ar technology paper mainly focused 3d laser projection technology paper first describes application background ar technology basic principle ar analyzed key technology virtual real mapping systematically sorted basis basic composition ar system described application area set aviation manufacturing industry aerospace manufacturing industry shipbuilding last design experiment verify laser spot error distribution calibration result point copy 2023 spie,other augmented_reality_technology basic_principles digital_manufacturing laser_projection manufacturing_industries manufacturing_process projection_technology real world virtual_information virtual real_mapping 405 3_surveying 723_computer_software _data_handling_and_applications other augmented reality ar technology skillfully blend virtual information real world greatly help development manufacturing industry ar technology paper mainly focused 3d laser projection technology paper first describes application background ar technology basic principle ar analyzed key technology virtual real mapping systematically sorted basis basic composition ar system described application area set aviation manufacturing industry aerospace manufacturing industry shipbuilding last design experiment verify laser spot error distribution calibration result point copy 2023 spie,augmented reality ar technology skillfully blend virtual information real world greatly help development manufacturing industry ar technology paper mainly focused 3d laser projection technology paper first describes application background ar technology basic principle ar analyzed key technology virtual real mapping systematically sorted basis basic composition ar system described application area set aviation manufacturing industry aerospace manufacturing industry shipbuilding last design experiment verify laser spot error distribution calibration result point copy 2023 spieotheraugmented_reality_technology basic_principles digital_manufacturing laser_projection manufacturing_industries manufacturing_process projection_technology real world virtual_information virtual real_mapping
3,Impacts of augmented reality on foreign language teaching: a case study of Persian language,"Mozaffari, S., & Hamidi, H. R. (2022). Impacts of augmented reality on foreign language teaching: a case study of Persian language. Multimedia Tools and Applications, 82(3), 4735–4748. https://doi.org/10.1007/s11042-022-13370-5
",10.1007/s11042-022-13370-5,"The use of information technology in the field of foreign language teaching as an auxiliary tool is very important. In a foreign language classroom, place is just an abstract concept; where the language is separated from the community, culture and places in which it is used. Augmented reality is a technology in which virtual components are simultaneously combined with the real environment. Our aim in this study is to investigate the effects of location-based augmented reality in teaching Persian as a foreign language. In this study, after consulting with professors in the field of Persian language teaching and reviewing similar researches, we came to the conclusion that nothing has been done to teach Persian language using augmented reality. Therefore, a Persian game based on augmented reality was designed and implemented and then evaluated. For evaluation, two methods have been used; the user and the heuristic evaluation. Experts in the field of Persian language teaching, human-computer interaction and a number of language learners participated in the evaluation. Their feedback shows that the use of augmented reality increases satisfaction, enthusiasm and interaction with the environment and people, and also makes the process of learning and memorizing concepts more efficient.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction;C7820 Humanities computing",enthusiasm;foreign language classroom;foreign language teaching;language learners;location-based augmented reality;Persian game;Persian language teaching;reviewing similar researches;teaching Persian,augmented reality;computer aided instruction;teaching,2023,Journal article (JA),Multimed. Tools Appl. (Germany),"(1) Mozaffari, S.; (1) Hamidi, H.R.; ","(1) Imam Khomeini International University, Computer Engineering Department, Iran; ",Springer,-1,"[""computer aided instruction"", ""teaching""]","[""computer aided instruction"", ""teaching""]",computer aided instruction;teaching,education;training,use cases;industries,education;training,use cases;industries,computer_aided_instruction teaching enthusiasm foreign_language_classroom foreign_language_teaching language_learners location based_augmented_reality persian_game persian_language_teaching reviewing_similar_researches teaching_persian c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7820_humanities_computing education training,computer_aided_instruction teaching,enthusiasm foreign_language_classroom foreign_language_teaching language_learners location based_augmented_reality persian_game persian_language_teaching reviewing_similar_researches teaching_persian,use information technology field foreign language teaching auxiliary tool important foreign language classroom place abstract concept language separated community culture place used augmented reality technology virtual component simultaneously combined real environment aim study investigate effect location based augmented reality teaching persian foreign language study consulting professor field persian language teaching reviewing similar research came conclusion nothing done teach persian language using augmented reality therefore persian game based augmented reality designed implemented evaluated evaluation two method used user heuristic evaluation expert field persian language teaching human computer interaction number language learner participated evaluation feedback show use augmented reality increase satisfaction enthusiasm interaction environment people also make process learning memorizing concept efficient,computer_aided_instruction teaching enthusiasm foreign_language_classroom foreign_language_teaching language_learners location based_augmented_reality persian_game persian_language_teaching reviewing_similar_researches teaching_persian c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7820_humanities_computing education training use information technology field foreign language teaching auxiliary tool important foreign language classroom place abstract concept language separated community culture place used augmented reality technology virtual component simultaneously combined real environment aim study investigate effect location based augmented reality teaching persian foreign language study consulting professor field persian language teaching reviewing similar research came conclusion nothing done teach persian language using augmented reality therefore persian game based augmented reality designed implemented evaluated evaluation two method used user heuristic evaluation expert field persian language teaching human computer interaction number language learner participated evaluation feedback show use augmented reality increase satisfaction enthusiasm interaction environment people also make process learning memorizing concept efficient,use information technology field foreign language teaching auxiliary tool important foreign language classroom place abstract concept language separated community culture place used augmented reality technology virtual component simultaneously combined real environment aim study investigate effect location based augmented reality teaching persian foreign language study consulting professor field persian language teaching reviewing similar research came conclusion nothing done teach persian language using augmented reality therefore persian game based augmented reality designed implemented evaluated evaluation two method used user heuristic evaluation expert field persian language teaching human computer interaction number language learner participated evaluation feedback show use augmented reality increase satisfaction enthusiasm interaction environment people also make process learning memorizing concept efficientcomputer_aided_instruction teachingenthusiasm foreign_language_classroom foreign_language_teaching language_learners location based_augmented_reality persian_game persian_language_teaching reviewing_similar_researches teaching_persian
4,Improving Big Data Analytics With Interactive Augmented Reality,"Hirve, S. A., & Pradeep Reddy C. H. (2022). Improving Big Data Analytics With Interactive Augmented Reality. International Journal of Information System Modeling and Design, 13(7), 1–11. https://doi.org/10.4018/ijismd.315124
",10.4018/IJISMD.315124,"Since, data is generated every minute by everyone including consumers and/or business worldwide, there is an enormous worth for big data analytics. Big data analytics is a technique for extracting important information from large amounts of a data. Visualization is the best medium to analyze and share information. Visual images help to transmit bid data to the human brain within a few seconds. Visual interpretations help in visualizing data from different angles. Visualization helps to outline problems and understand current trends. Augmented reality enables the user to experience the real world, which is digitally augmented in a way. The main objective of this research work is to find the solution to visualize the analyzed data and show it to the users in a 3D view and to improve the angle of visualization with the help of augmented reality techniques.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130J Big Data,augmented reality techniques;bid data;improving big data analytics;interactive augmented reality;visual images help;visual interpretations help,augmented reality;Big Data;data analysis;data visualisation,2022,Journal article (JA),Int. J. Inf. Syst. Model. Des. (USA),"(1) Hirve, S.A.; ","(1) VIT-AP University, India; ",IGI Global,-1,"[""big data"", ""data analysis"", ""data visualization""]","[""big data"", ""data analysis"", ""data visualization""]",big data;data analysis;data visualization,data,technology,data,technology,big_data data_analysis data_visualization augmented_reality_techniques bid_data improving_big_data_analytics interactive_augmented_reality visual_images_help visual_interpretations_help c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130j_big_data data,big_data data_analysis data_visualization,augmented_reality_techniques bid_data improving_big_data_analytics interactive_augmented_reality visual_images_help visual_interpretations_help,since data generated every minute everyone including consumer business worldwide enormous worth big data analytics big data analytics technique extracting important information large amount data visualization best medium analyze share information visual image help transmit bid data human brain within second visual interpretation help visualizing data different angle visualization help outline problem understand current trend augmented reality enables user experience real world digitally augmented way main objective research work find solution visualize analyzed data show user 3d view improve angle visualization help augmented reality technique,big_data data_analysis data_visualization augmented_reality_techniques bid_data improving_big_data_analytics interactive_augmented_reality visual_images_help visual_interpretations_help c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130j_big_data data since data generated every minute everyone including consumer business worldwide enormous worth big data analytics big data analytics technique extracting important information large amount data visualization best medium analyze share information visual image help transmit bid data human brain within second visual interpretation help visualizing data different angle visualization help outline problem understand current trend augmented reality enables user experience real world digitally augmented way main objective research work find solution visualize analyzed data show user 3d view improve angle visualization help augmented reality technique,since data generated every minute everyone including consumer business worldwide enormous worth big data analytics big data analytics technique extracting important information large amount data visualization best medium analyze share information visual image help transmit bid data human brain within second visual interpretation help visualizing data different angle visualization help outline problem understand current trend augmented reality enables user experience real world digitally augmented way main objective research work find solution visualize analyzed data show user 3d view improve angle visualization help augmented reality techniquebig_data data_analysis data_visualizationaugmented_reality_techniques bid_data improving_big_data_analytics interactive_augmented_reality visual_images_help visual_interpretations_help
5,Augmented Reality Shopping System and Experience: Overview of the Literature,"Roche, C., & Hamam, A. (2023). Augmented Reality Shopping System and Experience: Overview of the Literature. SoutheastCon 2023. https://doi.org/10.1109/southeastcon51012.2023.10115104
",10.1109/SoutheastCon51012.2023.10115104,"This paper reviews literature related to the architecture for a proposed augmented reality shopping application under current development. The system consists of a progressive web app client that renders augmentations for the user and performs tracking, and a cloud server that performs object detection, localization, and product information retrieval and analysis. This review provides an overview of past cloud-based augmented reality applications and identifies design factors for the proposed system.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6190J Internet software;C7210N Information networks;C7250R Information retrieval techniques",augmented reality shopping system;cloud server;cloud-based augmented reality applications;object detection;product information retrieval;Web app client,augmented reality;cloud computing;information retrieval;mobile computing;object detection,2023,Conference article (CA),SoutheastCon 2023,"(1) Roche, C.; (1) Hamam, A.; ","(1) Florida Polytechnic University, Computer Science, United States; ",IEEE,-1,"[""cloud computing"", ""information retrieval"", ""mobile computing"", ""object detection""]","[""cloud computing"", ""information retrieval"", ""mobile computing"", ""object detection""]",cloud computing;information retrieval;mobile computing;object detection,computer vision;telecommunication;data;networks,technology;industries,computer vision;telecommunication;data;networks,technology;industries,cloud_computing information_retrieval mobile_computing object_detection augmented_reality_shopping_system cloud_server cloud based_augmented_reality_applications object_detection product_information_retrieval web_app_client b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190j_internet_software c7210n_information_networks c7250r_information_retrieval_techniques computer_vision telecommunication data networks,cloud_computing information_retrieval mobile_computing object_detection,augmented_reality_shopping_system cloud_server cloud based_augmented_reality_applications object_detection product_information_retrieval web_app_client,paper review literature related architecture proposed augmented reality shopping application current development system consists progressive web app client render augmentation user performs tracking cloud server performs object detection localization product information retrieval analysis review provides overview past cloud based augmented reality application identifies design factor proposed system,cloud_computing information_retrieval mobile_computing object_detection augmented_reality_shopping_system cloud_server cloud based_augmented_reality_applications object_detection product_information_retrieval web_app_client b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190j_internet_software c7210n_information_networks c7250r_information_retrieval_techniques computer_vision telecommunication data networks paper review literature related architecture proposed augmented reality shopping application current development system consists progressive web app client render augmentation user performs tracking cloud server performs object detection localization product information retrieval analysis review provides overview past cloud based augmented reality application identifies design factor proposed system,paper review literature related architecture proposed augmented reality shopping application current development system consists progressive web app client render augmentation user performs tracking cloud server performs object detection localization product information retrieval analysis review provides overview past cloud based augmented reality application identifies design factor proposed systemcloud_computing information_retrieval mobile_computing object_detectionaugmented_reality_shopping_system cloud_server cloud based_augmented_reality_applications object_detection product_information_retrieval web_app_client
6,"How Space is Told: Linking Trajectory, Narrative, and Intent in Augmented Reality Storytelling for Cultural Heritage Sites","Shin, J.-E., & Woo, W. (2023). How Space is Told. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581414
",10.1145/3544548.3581414,"We report on a qualitative study in which 22 participants created Augmented Reality (AR) stories for outdoor cultural heritage sites. As storytelling is a crucial strategy for AR content aimed at providing meaningful experiences, the emphasis has been on what storytelling does, rather than how it is done, the end user's needs prioritized over the author's. To address this imbalance, we identify how recurring patterns in the spatial trajectories and narrative compositions of AR stories for cultural heritage sites are linked to the author's intent and creative process: While authors tend to bind story arcs tightly to confined trajectories for narrative delivery, the need for spatial exploration results in thematic content mapped loosely onto encompassing trajectories. Based on our analysis, we present design recommendations for site-specific AR storytelling tools that can support authors in delivering their intent while leveraging the placeness of cultural heritage sites as a creative resource.",C7820 Humanities computing;C6130M Multimedia;C6130V Virtual reality,AR storytelling;augmented reality storytelling;cultural heritage sites;intent linking;narrative delivery;narrative linking;thematic content;trajectory linking,augmented reality;history;multimedia computing,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Shin, J.-E.; (2) Woo, W.; ","(1) Korea Advanced Institute of Science and Technology, Korea, Republic of; (2) Korea Advanced Institute of Science and Technology, Republic of and UVR Lab, Korea, Republic of; ",ACM,-1,"[""history"", ""multimedia computing""]","[""history"", ""multimedia computing""]",history;multimedia computing,education;liberal arts,industries,education;liberal arts,industries,history multimedia_computing ar_storytelling augmented_reality_storytelling cultural_heritage_sites intent_linking narrative_delivery narrative_linking thematic_content trajectory_linking c7820_humanities_computing c6130m_multimedia c6130v_virtual_reality education liberal_arts,history multimedia_computing,ar_storytelling augmented_reality_storytelling cultural_heritage_sites intent_linking narrative_delivery narrative_linking thematic_content trajectory_linking,report qualitative study 22 participant created augmented reality ar story outdoor cultural heritage site storytelling crucial strategy ar content aimed providing meaningful experience emphasis storytelling rather done end user need prioritized author address imbalance identify recurring pattern spatial trajectory narrative composition ar story cultural heritage site linked author intent creative process author tend bind story arc tightly confined trajectory narrative delivery need spatial exploration result thematic content mapped loosely onto encompassing trajectory based analysis present design recommendation site specific ar storytelling tool support author delivering intent leveraging placeness cultural heritage site creative resource,history multimedia_computing ar_storytelling augmented_reality_storytelling cultural_heritage_sites intent_linking narrative_delivery narrative_linking thematic_content trajectory_linking c7820_humanities_computing c6130m_multimedia c6130v_virtual_reality education liberal_arts report qualitative study 22 participant created augmented reality ar story outdoor cultural heritage site storytelling crucial strategy ar content aimed providing meaningful experience emphasis storytelling rather done end user need prioritized author address imbalance identify recurring pattern spatial trajectory narrative composition ar story cultural heritage site linked author intent creative process author tend bind story arc tightly confined trajectory narrative delivery need spatial exploration result thematic content mapped loosely onto encompassing trajectory based analysis present design recommendation site specific ar storytelling tool support author delivering intent leveraging placeness cultural heritage site creative resource,report qualitative study 22 participant created augmented reality ar story outdoor cultural heritage site storytelling crucial strategy ar content aimed providing meaningful experience emphasis storytelling rather done end user need prioritized author address imbalance identify recurring pattern spatial trajectory narrative composition ar story cultural heritage site linked author intent creative process author tend bind story arc tightly confined trajectory narrative delivery need spatial exploration result thematic content mapped loosely onto encompassing trajectory based analysis present design recommendation site specific ar storytelling tool support author delivering intent leveraging placeness cultural heritage site creative resourcehistory multimedia_computingar_storytelling augmented_reality_storytelling cultural_heritage_sites intent_linking narrative_delivery narrative_linking thematic_content trajectory_linking
7,Pearl: Physical Environment based Augmented Reality Lenses for In-Situ Human Movement Analysis,"Luo, W., Yu, Z., Rzayev, R., Satkowski, M., Gumhold, S., McGinity, M., & Dachselt, R. (2023). Pearl: Physical Environment based Augmented Reality Lenses for In-Situ Human Movement Analysis. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580715
",10.1145/3544548.3580715,"This paper presents Pearl, a mixed-reality approach for the analysis of human movement data in situ. As the physical environment shapes human motion and behavior, the analysis of such motion can benefit from the direct inclusion of the environment in the analytical process. We present methods for exploring movement data in relation to surrounding regions of interest, such as objects, furniture, and architectural elements. We introduce concepts for selecting and filtering data through direct interaction with the environment, and a suite of visualizations for revealing aggregated and emergent spatial and temporal relations. More sophisticated analysis is supported through complex queries comprising multiple regions of interest. To illustrate the potential of Pearl, we developed an Augmented Reality-based prototype and conducted expert review sessions and scenario walkthroughs in a simulated exhibition. Our contribution lays the foundation for leveraging the physical environment in the in-situ analysis of movement data.",C6130V Virtual reality;C6180 User interfaces,analytical process;architectural elements;augmented reality lenses;in-situ human movement analysis;mixed-reality approach;Pearl;physical environment;spatial relations;temporal relations,augmented reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Luo, W.; (2) Yu, Z.; (1) Rzayev, R.; (1) Satkowski, M.; (3) Gumhold, S.; (2) Mcginity, M.; (3) Dachselt, R.; ","(1) Interactive Media Lab Dresden, Germany; (2) Immersive Experience Lab, Germany; (3) Technische Universitat Dresden, Germany and Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany; ",ACM,-1,[],[],other,other,other,other,other,other analytical_process architectural_elements augmented_reality_lenses in situ_human_movement_analysis mixed reality_approach pearl physical_environment spatial_relations temporal_relations c6130v_virtual_reality c6180_user_interfaces other,other,analytical_process architectural_elements augmented_reality_lenses in situ_human_movement_analysis mixed reality_approach pearl physical_environment spatial_relations temporal_relations,paper present pearl mixed reality approach analysis human movement data situ physical environment shape human motion behavior analysis motion benefit direct inclusion environment analytical process present method exploring movement data relation surrounding region interest object furniture architectural element introduce concept selecting filtering data direct interaction environment suite visualization revealing aggregated emergent spatial temporal relation sophisticated analysis supported complex query comprising multiple region interest illustrate potential pearl developed augmented reality based prototype conducted expert review session scenario walkthroughs simulated exhibition contribution lay foundation leveraging physical environment situ analysis movement data,other analytical_process architectural_elements augmented_reality_lenses in situ_human_movement_analysis mixed reality_approach pearl physical_environment spatial_relations temporal_relations c6130v_virtual_reality c6180_user_interfaces other paper present pearl mixed reality approach analysis human movement data situ physical environment shape human motion behavior analysis motion benefit direct inclusion environment analytical process present method exploring movement data relation surrounding region interest object furniture architectural element introduce concept selecting filtering data direct interaction environment suite visualization revealing aggregated emergent spatial temporal relation sophisticated analysis supported complex query comprising multiple region interest illustrate potential pearl developed augmented reality based prototype conducted expert review session scenario walkthroughs simulated exhibition contribution lay foundation leveraging physical environment situ analysis movement data,paper present pearl mixed reality approach analysis human movement data situ physical environment shape human motion behavior analysis motion benefit direct inclusion environment analytical process present method exploring movement data relation surrounding region interest object furniture architectural element introduce concept selecting filtering data direct interaction environment suite visualization revealing aggregated emergent spatial temporal relation sophisticated analysis supported complex query comprising multiple region interest illustrate potential pearl developed augmented reality based prototype conducted expert review session scenario walkthroughs simulated exhibition contribution lay foundation leveraging physical environment situ analysis movement dataotheranalytical_process architectural_elements augmented_reality_lenses in situ_human_movement_analysis mixed reality_approach pearl physical_environment spatial_relations temporal_relations
8,Mobile Augmented Reality Shopping System,"Roche, C., & Hamam, A. (2023). Mobile Augmented Reality Shopping System. SoutheastCon 2023. https://doi.org/10.1109/southeastcon51012.2023.10115069
",10.1109/SoutheastCon51012.2023.10115069,"This document serves as an extended abstract to detail the architecture for an augmented reality shopping application under current development for a thesis. The system consists of a progressive web app client that presents the augmented view to the user and performs object tracking, and a cloud server that performs object detection, localization, and the necessary product information retrieval and analysis.","C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing;C7210N Information networks;C7250R Information retrieval techniques",augmented reality shopping application;augmented view;mobile augmented reality shopping system;progressive web app client,augmented reality;cloud computing;information retrieval;mobile computing;object detection;object tracking,2023,Conference article (CA),SoutheastCon 2023,"(1) Roche, C.; (1) Hamam, A.; ","(1) Florida Polytechnic University, Computer Science, United States; ",IEEE,-1,"[""cloud computing"", ""information retrieval"", ""mobile computing"", ""object detection"", ""object tracking""]","[""cloud computing"", ""information retrieval"", ""mobile computing"", ""object detection"", ""object tracking""]",cloud computing;information retrieval;mobile computing;object detection;object tracking,computer vision;telecommunication;data;networks,technology;industries,computer vision;telecommunication;data;networks,technology;industries,cloud_computing information_retrieval mobile_computing object_detection object_tracking augmented_reality_shopping_application augmented_view mobile_augmented_reality_shopping_system progressive_web_app_client c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks c7250r_information_retrieval_techniques computer_vision telecommunication data networks,cloud_computing information_retrieval mobile_computing object_detection object_tracking,augmented_reality_shopping_application augmented_view mobile_augmented_reality_shopping_system progressive_web_app_client,document serf extended abstract detail architecture augmented reality shopping application current development thesis system consists progressive web app client present augmented view user performs object tracking cloud server performs object detection localization necessary product information retrieval analysis,cloud_computing information_retrieval mobile_computing object_detection object_tracking augmented_reality_shopping_application augmented_view mobile_augmented_reality_shopping_system progressive_web_app_client c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks c7250r_information_retrieval_techniques computer_vision telecommunication data networks document serf extended abstract detail architecture augmented reality shopping application current development thesis system consists progressive web app client present augmented view user performs object tracking cloud server performs object detection localization necessary product information retrieval analysis,document serf extended abstract detail architecture augmented reality shopping application current development thesis system consists progressive web app client present augmented view user performs object tracking cloud server performs object detection localization necessary product information retrieval analysiscloud_computing information_retrieval mobile_computing object_detection object_trackingaugmented_reality_shopping_application augmented_view mobile_augmented_reality_shopping_system progressive_web_app_client
9,The validity of markerless augmented reality-based learning media on the concept of cell organelle,"Ihsan, M., Sa’adah, S., & Maspupah, M. (2023). The validity of markerless augmented reality-based learning media on the concept of cell organelle. THE 3RD INTERNATIONAL CONFERENCE ON SCIENCE, MATHEMATICS, ENVIRONMENT, AND EDUCATION: Flexibility in Research and Innovation on Science, Mathematics, Environment, and Education for Sustainable Development. https://doi.org/10.1063/5.0105748
",10.1063/5.0105748,"The use of technology today is an integral part of education, thus changing the way students learn. This study aims to analyze the feasibility of markerless augmented reality-based learning media on the concept of cell organelles based on media analysis. The validity of the learning media by material experts, media experts, biology teachers, and readability tests by students. The validation and readability tests aim to get input, recommendations for improvement, and an assessment of the developed media. The results showed that the validation test results of markerless augmented reality-based learning media on the concept of cell organelles had valid qualifications with an average of 0.89 in.the high category. The student's readability test showed that it was feasible, with a high interpretation of 88.19%. Based on this, the markerless augmented reality-based learning media on the concept of cell organelles is valid and feasible as a learning media. [The copyright for the referenced work is owned by Author(s). Copies of full-text articles should only be made or obtained from the publisher or authorized sources.]",C7810C Computer-aided instruction;C6130V Virtual reality;C7330 Biology and medical computing,cell organelle;markerless augmented reality-based learning media,augmented reality;biology computing;computer aided instruction,2023,Conference article (CA),AIP Conf. Proc. (USA),"(1) Ihsan, M.; (1) Sa'adah, S.; (1) Maspupah, M.; ","(1) Prodi Pendidikan Biologi UIN Sunan Gunung Djati Bandung, Indonesia; ",AIP Publishing,-1,"[""biology computing"", ""computer aided instruction""]","[""biology computing"", ""computer aided instruction""]",biology computing;computer aided instruction,medical;training,use cases;industries,medical;training,use cases;industries,biology_computing computer_aided_instruction cell_organelle markerless_augmented_reality based_learning_media c7810c_computer aided_instruction c6130v_virtual_reality c7330_biology_and_medical_computing medical training,biology_computing computer_aided_instruction,cell_organelle markerless_augmented_reality based_learning_media,use technology today integral part education thus changing way student learn study aim analyze feasibility markerless augmented reality based learning medium concept cell organelle based medium analysis validity learning medium material expert medium expert biology teacher readability test student validation readability test aim get input recommendation improvement assessment developed medium result showed validation test result markerless augmented reality based learning medium concept cell organelle valid qualification average 0 89 high category student readability test showed feasible high interpretation 88 19 based markerless augmented reality based learning medium concept cell organelle valid feasible learning medium copyright referenced work owned author copy full text article made obtained publisher authorized source,biology_computing computer_aided_instruction cell_organelle markerless_augmented_reality based_learning_media c7810c_computer aided_instruction c6130v_virtual_reality c7330_biology_and_medical_computing medical training use technology today integral part education thus changing way student learn study aim analyze feasibility markerless augmented reality based learning medium concept cell organelle based medium analysis validity learning medium material expert medium expert biology teacher readability test student validation readability test aim get input recommendation improvement assessment developed medium result showed validation test result markerless augmented reality based learning medium concept cell organelle valid qualification average 0 89 high category student readability test showed feasible high interpretation 88 19 based markerless augmented reality based learning medium concept cell organelle valid feasible learning medium copyright referenced work owned author copy full text article made obtained publisher authorized source,use technology today integral part education thus changing way student learn study aim analyze feasibility markerless augmented reality based learning medium concept cell organelle based medium analysis validity learning medium material expert medium expert biology teacher readability test student validation readability test aim get input recommendation improvement assessment developed medium result showed validation test result markerless augmented reality based learning medium concept cell organelle valid qualification average 0 89 high category student readability test showed feasible high interpretation 88 19 based markerless augmented reality based learning medium concept cell organelle valid feasible learning medium copyright referenced work owned author copy full text article made obtained publisher authorized sourcebiology_computing computer_aided_instructioncell_organelle markerless_augmented_reality based_learning_media
10,ARephotography: Revisiting Historical Photographs using Augmented Reality,"Hasselman, T., Lo, W. H., Langlotz, T., & Zollmann, S. (2023). ARephotography: Revisiting Historical Photographs using Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585646
",10.1145/3544549.3585646,"Augmented Reality (AR) opens up new possibilities for interactive experiences which can be used in a variety of circumstances. Rephotography is a photo technique commonly presented on dedicated internet pages that align a past view with a current photo, allowing you to have a comparative view of the past with the present. This project aims to combine these two concepts to create AR experiences where you can view buildings and street views from historical photography seamlessly embedded in the present environment. We report on our automated pipeline that can take a historical photograph of a building and produces a textured 3D model that can be placed in AR over the current view of the building using techniques from machine learning while also reporting on first feedback from a preliminary user study.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6130B Graphics techniques,align a past view;AR experiences;ARephotography;augmented Reality;Augmented Reality;buildings;comparative view;current photo;current view;dedicated internet pages;historical photograph;historical photography;interactive experiences;photo technique;rephotography;street views,augmented reality;history;image representation;Internet;photography;solid modelling,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Hasselman, T.; (2) Lo, W.H.; (1) Langlotz, T.; (3) Zollmann, S.; ","(1) University of Otago, New Zealand; (2) University of Otago, Department of Computer Science, New Zealand; (3) University of Otago, Computer Science, New Zealand; ",ACM,-1,"[""history"", ""image representation"", ""internet"", ""photography"", ""solid modelling""]","[""history"", ""image representation"", ""internet"", ""photography"", ""solid modelling""]",history;image representation;internet;photography;solid modelling,computer vision;manufacturing;liberal arts;networks,technology;industries,computer vision;manufacturing;liberal arts;networks,technology;industries,history image_representation internet photography solid_modelling align_a_past_view ar_experiences arephotography augmented_reality augmented_reality buildings comparative_view current_photo current_view dedicated_internet_pages historical_photograph historical_photography interactive_experiences photo_technique rephotography street_views c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques computer_vision manufacturing liberal_arts networks,history image_representation internet photography solid_modelling,align_a_past_view ar_experiences arephotography augmented_reality augmented_reality buildings comparative_view current_photo current_view dedicated_internet_pages historical_photograph historical_photography interactive_experiences photo_technique rephotography street_views,augmented reality ar open new possibility interactive experience used variety circumstance rephotography photo technique commonly presented dedicated internet page align past view current photo allowing comparative view past present project aim combine two concept create ar experience view building street view historical photography seamlessly embedded present environment report automated pipeline take historical photograph building produce textured 3d model placed ar current view building using technique machine learning also reporting first feedback preliminary user study,history image_representation internet photography solid_modelling align_a_past_view ar_experiences arephotography augmented_reality augmented_reality buildings comparative_view current_photo current_view dedicated_internet_pages historical_photograph historical_photography interactive_experiences photo_technique rephotography street_views c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques computer_vision manufacturing liberal_arts networks augmented reality ar open new possibility interactive experience used variety circumstance rephotography photo technique commonly presented dedicated internet page align past view current photo allowing comparative view past present project aim combine two concept create ar experience view building street view historical photography seamlessly embedded present environment report automated pipeline take historical photograph building produce textured 3d model placed ar current view building using technique machine learning also reporting first feedback preliminary user study,augmented reality ar open new possibility interactive experience used variety circumstance rephotography photo technique commonly presented dedicated internet page align past view current photo allowing comparative view past present project aim combine two concept create ar experience view building street view historical photography seamlessly embedded present environment report automated pipeline take historical photograph building produce textured 3d model placed ar current view building using technique machine learning also reporting first feedback preliminary user studyhistory image_representation internet photography solid_modellingalign_a_past_view ar_experiences arephotography augmented_reality augmented_reality buildings comparative_view current_photo current_view dedicated_internet_pages historical_photograph historical_photography interactive_experiences photo_technique rephotography street_views
11,Exploring Augmented Reality Waste Data Representations for Eco Feedback.,"Assor, A., Prouzeau, A., Dragicevic, P., & Hachet, M. (2023). Exploring Augmented Reality Waste Data Representations for Eco Feedback. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583905
",10.1145/3544549.3583905,"In this demo, we show how Augmented Reality can be used to visualize waste accumulation data in an engaging and visceral way. The negative impact humans have on the environment is partly caused by thoughtless consumption leading to unnecessary waste. A likely contributing factor is the relative invisibility of waste: waste produced by individuals is either out of their sight or quickly taken away. Nevertheless, waste disposal systems sometimes break down, creating natural information displays of waste production that can have educational value. We take inspiration from such natural displays and introduce a class of situated visualizations we call augmented-reality waste accumulation visualizations or ARwavs, which are literal representations of waste data embedded in users' familiar environment. We implemented examples of ARwavs and will present them at the venue.",A8675T Waste disposal (environmental science technology);C6130B Graphics techniques;C6130V Virtual reality;C7360 Environmental science computing,ARwavs;augmented reality waste data representation;augmented-reality waste accumulation visualizations;eco feedback;natural displays;natural information displays;situated visualizations;thoughtless consumption;waste accumulation data;waste disposal systems;waste production,augmented reality;data visualisation;environmental science computing;waste disposal,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Assor, A.; (1) Prouzeau, A.; (1) Dragicevic, P.; (1) Hachet, M.; ","(1) Inria, France; ",ACM,-1,"[""data visualization"", ""environmental science computing"", ""waste disposal""]","[""data visualization"", ""environmental science computing"", ""waste disposal""]",data visualization;environmental science computing;waste disposal,other;engineering;data,technology;other,other;engineering;data,technology;other,data_visualization environmental_science_computing waste_disposal arwavs augmented_reality_waste_data_representation augmented reality_waste_accumulation_visualizations eco_feedback natural_displays natural_information_displays situated_visualizations thoughtless_consumption waste_accumulation_data waste_disposal_systems waste_production a8675t_waste_disposal_ environmental_science_technology c6130b_graphics_techniques c6130v_virtual_reality c7360_environmental_science_computing other engineering data,data_visualization environmental_science_computing waste_disposal,arwavs augmented_reality_waste_data_representation augmented reality_waste_accumulation_visualizations eco_feedback natural_displays natural_information_displays situated_visualizations thoughtless_consumption waste_accumulation_data waste_disposal_systems waste_production,demo show augmented reality used visualize waste accumulation data engaging visceral way negative impact human environment partly caused thoughtless consumption leading unnecessary waste likely contributing factor relative invisibility waste waste produced individual either sight quickly taken away nevertheless waste disposal system sometimes break creating natural information display waste production educational value take inspiration natural display introduce class situated visualization call augmented reality waste accumulation visualization arwavs literal representation waste data embedded user familiar environment implemented example arwavs present venue,data_visualization environmental_science_computing waste_disposal arwavs augmented_reality_waste_data_representation augmented reality_waste_accumulation_visualizations eco_feedback natural_displays natural_information_displays situated_visualizations thoughtless_consumption waste_accumulation_data waste_disposal_systems waste_production a8675t_waste_disposal_ environmental_science_technology c6130b_graphics_techniques c6130v_virtual_reality c7360_environmental_science_computing other engineering data demo show augmented reality used visualize waste accumulation data engaging visceral way negative impact human environment partly caused thoughtless consumption leading unnecessary waste likely contributing factor relative invisibility waste waste produced individual either sight quickly taken away nevertheless waste disposal system sometimes break creating natural information display waste production educational value take inspiration natural display introduce class situated visualization call augmented reality waste accumulation visualization arwavs literal representation waste data embedded user familiar environment implemented example arwavs present venue,demo show augmented reality used visualize waste accumulation data engaging visceral way negative impact human environment partly caused thoughtless consumption leading unnecessary waste likely contributing factor relative invisibility waste waste produced individual either sight quickly taken away nevertheless waste disposal system sometimes break creating natural information display waste production educational value take inspiration natural display introduce class situated visualization call augmented reality waste accumulation visualization arwavs literal representation waste data embedded user familiar environment implemented example arwavs present venuedata_visualization environmental_science_computing waste_disposalarwavs augmented_reality_waste_data_representation augmented reality_waste_accumulation_visualizations eco_feedback natural_displays natural_information_displays situated_visualizations thoughtless_consumption waste_accumulation_data waste_disposal_systems waste_production
12,Lessons learned from human pose interaction in an industrial spatial augmented reality application,"Stübl, G., Heindl, C., Ebenhofer, G., Bauer, H., & Pichler, A. (2023). Lessons Learned from Human Pose Interaction in an Industrial Spatial Augmented Reality Application. Procedia Computer Science, 217, 912–917. https://doi.org/10.1016/j.procs.2022.12.288
",10.1016/j.procs.2022.12.288,"This paper is a technical description of a novel Augmented Reality application in the industrial domain of furniture production. In the presented case, workers suffered from high cognitive load in doing end-of-line quality inspection and individual handling of a high variety of products. The proposed solution consists of a Spatial Augmented Reality system, where a projector directly displays information on the product to assist the worker. At the same time results of an in-line quality inspections are shown which can be interactively modified through human gestures. The main contribution of this work is two-fold: (1) in contrast to other industrial augmented reality applications the described one technically builds upon a deep neural net based pose estimation. This allows a seamless interaction with the system and tracking of human actions rather than deriving them from the current state of the work piece, (2) the paper recapitulates experiences and results of the approach with a focus on lessons learned for using human pose estimation in smart production. All rights reserved Elsevier.",B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7480 Production engineering computing;E0410D Industrial applications of IT,end-of-line quality inspection;furniture production;high cognitive load;human actions;human gestures;human pose estimation;in-line quality inspections;individual handling;industrial augmented reality applications;industrial domain;industrial spatial augmented reality application;novel Augmented Reality application;presented case;seamless interaction;smart production;Spatial Augmented Reality system;technical description;time results,augmented reality;furniture;gesture recognition;pose estimation;production engineering computing,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Stu&#776;bl, G.; (1) Heindl, C.; (1) Ebenhofer, G.; (1) Bauer, H.; (1) Pichler, A.; ","(1) Profactor GmbH, Im Stadtgut D1, Austria; ",Elsevier B.V.,-1,"[""furniture"", ""gesture recognition"", ""pose estimation"", ""production engineering computing""]","[""furniture"", ""gesture recognition"", ""pose estimation"", ""production engineering computing""]",furniture;gesture recognition;pose estimation;production engineering computing,construction;graphics;input;human factors;engineering;manufacturing,technology;end users and user experience;industries,construction;graphics;input;human factors;engineering;manufacturing,technology;end users and user experience;industries,furniture gesture_recognition pose_estimation production_engineering_computing end of line_quality_inspection furniture_production high_cognitive_load human_actions human_gestures human_pose_estimation in line_quality_inspections individual_handling industrial_augmented_reality_applications industrial_domain industrial_spatial_augmented_reality_application novel_augmented_reality_application presented_case seamless_interaction smart_production spatial_augmented_reality_system technical_description time_results b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it construction graphics input human_factors engineering manufacturing,furniture gesture_recognition pose_estimation production_engineering_computing,end of line_quality_inspection furniture_production high_cognitive_load human_actions human_gestures human_pose_estimation in line_quality_inspections individual_handling industrial_augmented_reality_applications industrial_domain industrial_spatial_augmented_reality_application novel_augmented_reality_application presented_case seamless_interaction smart_production spatial_augmented_reality_system technical_description time_results,paper technical description novel augmented reality application industrial domain furniture production presented case worker suffered high cognitive load end line quality inspection individual handling high variety product proposed solution consists spatial augmented reality system projector directly display information product assist worker time result line quality inspection shown interactively modified human gesture main contribution work two fold 1 contrast industrial augmented reality application described one technically build upon deep neural net based pose estimation allows seamless interaction system tracking human action rather deriving current state work piece 2 paper recapitulates experience result approach focus lesson learned using human pose estimation smart production right reserved elsevier,furniture gesture_recognition pose_estimation production_engineering_computing end of line_quality_inspection furniture_production high_cognitive_load human_actions human_gestures human_pose_estimation in line_quality_inspections individual_handling industrial_augmented_reality_applications industrial_domain industrial_spatial_augmented_reality_application novel_augmented_reality_application presented_case seamless_interaction smart_production spatial_augmented_reality_system technical_description time_results b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it construction graphics input human_factors engineering manufacturing paper technical description novel augmented reality application industrial domain furniture production presented case worker suffered high cognitive load end line quality inspection individual handling high variety product proposed solution consists spatial augmented reality system projector directly display information product assist worker time result line quality inspection shown interactively modified human gesture main contribution work two fold 1 contrast industrial augmented reality application described one technically build upon deep neural net based pose estimation allows seamless interaction system tracking human action rather deriving current state work piece 2 paper recapitulates experience result approach focus lesson learned using human pose estimation smart production right reserved elsevier,paper technical description novel augmented reality application industrial domain furniture production presented case worker suffered high cognitive load end line quality inspection individual handling high variety product proposed solution consists spatial augmented reality system projector directly display information product assist worker time result line quality inspection shown interactively modified human gesture main contribution work two fold 1 contrast industrial augmented reality application described one technically build upon deep neural net based pose estimation allows seamless interaction system tracking human action rather deriving current state work piece 2 paper recapitulates experience result approach focus lesson learned using human pose estimation smart production right reserved elsevierfurniture gesture_recognition pose_estimation production_engineering_computingend of line_quality_inspection furniture_production high_cognitive_load human_actions human_gestures human_pose_estimation in line_quality_inspections individual_handling industrial_augmented_reality_applications industrial_domain industrial_spatial_augmented_reality_application novel_augmented_reality_application presented_case seamless_interaction smart_production spatial_augmented_reality_system technical_description time_results
13,How mobile augmented reality digitally transforms the retail sector: examining trust in augmented reality apps and online/offline store patronage intention,"Kang, J.-Y. M., Kim, J.-E., Lee, J. Y., & Lin, S. H. (2022). How mobile augmented reality digitally transforms the retail sector: examining trust in augmented reality apps and online/offline store patronage intention. Journal of Fashion Marketing and Management: An International Journal, 27(1), 161–181. https://doi.org/10.1108/jfmm-12-2020-0273
",10.1108/JFMM-12-2020-0273,"&lt;b&gt;Purpose &lt;/b&gt;The purpose of the study was to identify (1) whether aspects of expectancy-value judgments (EVJ) of uses and gratifications, such as novelty, fashion/status, sociability and relaxation, influenced trust in augmented reality (AR) apps; (2) whether trust in AR apps influenced usage intention toward AR apps and online/offline store patronage intention and (3) the moderating effect of consumer self-determination. &lt;b&gt;Design/methodology/approach &lt;/b&gt;Mobile users (&lt;i&gt;n&lt;/i&gt; = 630) were drawn from a USA market research company. The proposed model was tested by structural equation modeling with maximum likelihood estimation. &lt;b&gt;Findings &lt;/b&gt;The study found that trust in AR apps was a determinant of usage intention toward AR apps and online/offline store patronage intention. Novelty and fashion/status for EVJs of uses and gratifications affected trust in AR apps. Sociability for EVJs of uses and gratifications negatively affected trust in AR apps. Users' self-determination moderated the influence of users' trust in AR apps on usage intention toward AR apps and online/offline store patronage intention. &lt;b&gt;Originality/value &lt;/b&gt;First, the study elaborates on the impacts of the underlying aspects of an EVJ model of uses and gratifications regarding AR apps on trust in AR apps and EVJ model's influence on usage intention toward AR apps and online/offline store patronage intention. Second, the results of the study suggest useful strategies involved in the development of consumer-driven AR apps that satisfy users' needs and desires.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6190V Mobile, ubiquitous and pervasive computing;C7170 Marketing computing;C7210N Information networks",AR apps;augmented reality apps;gratifications affected trust;mobile augmented reality;usage intention,augmented reality;consumer behaviour;customer satisfaction;human factors;market research;maximum likelihood estimation;mobile computing;statistical analysis,2023,Journal article (JA),"J. Fash. Mark. Manag., Int. J. (UK)","(1) Kang, J.-Y.M.; (2) Kim, J.-E.; (3) Lee, J.Y.; (1) Lin, S.H.; ","(1) University of Hawai'i at Manoa, Department of Family and Consumer Sciences, Honolulu, HI, United States; (2) University of Auckland, Department of Marketing, New Zealand; (3) University at Buffalo, Department of Fashion and Textile Technology, Buffalo, NY, United States; ",Emerald,-1,"[""consumer behaviour"", ""customer satisfaction"", ""human factors"", ""market research"", ""maximum likelihood estimation"", ""mobile computing"", ""statistical analysis""]","[""consumer behaviour"", ""customer satisfaction"", ""human factors"", ""market research"", ""maximum likelihood estimation"", ""mobile computing"", ""statistical analysis""]",consumer behaviour;customer satisfaction;human factors;market research;maximum likelihood estimation;mobile computing;statistical analysis,education;other;medical;sales and marketing;human factors;telecommunication;data,other;business;end users and user experience;industries;technology,education;other;medical;sales and marketing;human factors;telecommunication;data,other;business;end users and user experience;industries;technology,consumer_behaviour customer_satisfaction human_factors market_research maximum_likelihood_estimation mobile_computing statistical_analysis ar_apps augmented_reality_apps gratifications_affected_trust mobile_augmented_reality usage_intention c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6190v_mobile _ubiquitous_and_pervasive_computing c7170_marketing_computing c7210n_information_networks education other medical sales_and_marketing human_factors telecommunication data,consumer_behaviour customer_satisfaction human_factors market_research maximum_likelihood_estimation mobile_computing statistical_analysis,ar_apps augmented_reality_apps gratifications_affected_trust mobile_augmented_reality usage_intention,lt b gt purpose lt b gt purpose study identify 1 whether aspect expectancy value judgment evj us gratification novelty fashion status sociability relaxation influenced trust augmented reality ar apps 2 whether trust ar apps influenced usage intention toward ar apps online offline store patronage intention 3 moderating effect consumer self determination lt b gt design methodology approach lt b gt mobile user lt gt n lt gt 630 drawn usa market research company proposed model tested structural equation modeling maximum likelihood estimation lt b gt finding lt b gt study found trust ar apps determinant usage intention toward ar apps online offline store patronage intention novelty fashion status evjs us gratification affected trust ar apps sociability evjs us gratification negatively affected trust ar apps user self determination moderated influence user trust ar apps usage intention toward ar apps online offline store patronage intention lt b gt originality value lt b gt first study elaborates impact underlying aspect evj model us gratification regarding ar apps trust ar apps evj model influence usage intention toward ar apps online offline store patronage intention second result study suggest useful strategy involved development consumer driven ar apps satisfy user need desire,consumer_behaviour customer_satisfaction human_factors market_research maximum_likelihood_estimation mobile_computing statistical_analysis ar_apps augmented_reality_apps gratifications_affected_trust mobile_augmented_reality usage_intention c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6190v_mobile _ubiquitous_and_pervasive_computing c7170_marketing_computing c7210n_information_networks education other medical sales_and_marketing human_factors telecommunication data lt b gt purpose lt b gt purpose study identify 1 whether aspect expectancy value judgment evj us gratification novelty fashion status sociability relaxation influenced trust augmented reality ar apps 2 whether trust ar apps influenced usage intention toward ar apps online offline store patronage intention 3 moderating effect consumer self determination lt b gt design methodology approach lt b gt mobile user lt gt n lt gt 630 drawn usa market research company proposed model tested structural equation modeling maximum likelihood estimation lt b gt finding lt b gt study found trust ar apps determinant usage intention toward ar apps online offline store patronage intention novelty fashion status evjs us gratification affected trust ar apps sociability evjs us gratification negatively affected trust ar apps user self determination moderated influence user trust ar apps usage intention toward ar apps online offline store patronage intention lt b gt originality value lt b gt first study elaborates impact underlying aspect evj model us gratification regarding ar apps trust ar apps evj model influence usage intention toward ar apps online offline store patronage intention second result study suggest useful strategy involved development consumer driven ar apps satisfy user need desire,lt b gt purpose lt b gt purpose study identify 1 whether aspect expectancy value judgment evj us gratification novelty fashion status sociability relaxation influenced trust augmented reality ar apps 2 whether trust ar apps influenced usage intention toward ar apps online offline store patronage intention 3 moderating effect consumer self determination lt b gt design methodology approach lt b gt mobile user lt gt n lt gt 630 drawn usa market research company proposed model tested structural equation modeling maximum likelihood estimation lt b gt finding lt b gt study found trust ar apps determinant usage intention toward ar apps online offline store patronage intention novelty fashion status evjs us gratification affected trust ar apps sociability evjs us gratification negatively affected trust ar apps user self determination moderated influence user trust ar apps usage intention toward ar apps online offline store patronage intention lt b gt originality value lt b gt first study elaborates impact underlying aspect evj model us gratification regarding ar apps trust ar apps evj model influence usage intention toward ar apps online offline store patronage intention second result study suggest useful strategy involved development consumer driven ar apps satisfy user need desireconsumer_behaviour customer_satisfaction human_factors market_research maximum_likelihood_estimation mobile_computing statistical_analysisar_apps augmented_reality_apps gratifications_affected_trust mobile_augmented_reality usage_intention
14,Location-Aware Adaptation of Augmented Reality Narratives,"Li, W., Li, C., Kim, M., Huang, H., & Yu, L.-F. (2023). Location-Aware Adaptation of Augmented Reality Narratives. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580978
",10.1145/3544548.3580978,"The recent popularity of augmented reality (AR) devices has enabled players to participate in interactive narratives through virtual events and characters populated in a real-world environment, where different actions may lead to different story branches. In this paper, we propose a novel approach to adapt narratives to real spaces for AR experiences. Our optimization-based approach automatically assigns contextually compatible locations to story events, synthesizing a navigation graph to guide players through different story branches while considering their walking experiences. We validated the effectiveness of our approach for adapting AR narratives to different scenes through experiments and user studies.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7830D Computer games",AR devices;AR experiences;augmented reality devices;augmented reality narratives;contextually compatible locations;interactive narratives;location-aware adaptation;optimization-based approach;story branches;story events;virtual events;walking experiences,augmented reality;computer games;location based services;virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Li, W.; (1) Li, C.; (1) Kim, M.; (2) Huang, H.; (3) Yu, L.-F.; ","(1) George Mason University, Fairfax, VA, United States; (2) George Mason University, Computer Science Department, Fairfax, VA, United States; (3) George Mason University, Computer Science, Fairfax, VA, United States; ",ACM,-1,"[""computer games"", ""location based services""]","[""computer games"", ""location based services""]",computer games;location based services,geospatial;liberal arts,technology;industries,geospatial;liberal arts,technology;industries,computer_games location_based_services ar_devices ar_experiences augmented_reality_devices augmented_reality_narratives contextually_compatible_locations interactive_narratives location aware_adaptation optimization based_approach story_branches story_events virtual_events walking_experiences c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games geospatial liberal_arts,computer_games location_based_services,ar_devices ar_experiences augmented_reality_devices augmented_reality_narratives contextually_compatible_locations interactive_narratives location aware_adaptation optimization based_approach story_branches story_events virtual_events walking_experiences,recent popularity augmented reality ar device enabled player participate interactive narrative virtual event character populated real world environment different action may lead different story branch paper propose novel approach adapt narrative real space ar experience optimization based approach automatically assigns contextually compatible location story event synthesizing navigation graph guide player different story branch considering walking experience validated effectiveness approach adapting ar narrative different scene experiment user study,computer_games location_based_services ar_devices ar_experiences augmented_reality_devices augmented_reality_narratives contextually_compatible_locations interactive_narratives location aware_adaptation optimization based_approach story_branches story_events virtual_events walking_experiences c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games geospatial liberal_arts recent popularity augmented reality ar device enabled player participate interactive narrative virtual event character populated real world environment different action may lead different story branch paper propose novel approach adapt narrative real space ar experience optimization based approach automatically assigns contextually compatible location story event synthesizing navigation graph guide player different story branch considering walking experience validated effectiveness approach adapting ar narrative different scene experiment user study,recent popularity augmented reality ar device enabled player participate interactive narrative virtual event character populated real world environment different action may lead different story branch paper propose novel approach adapt narrative real space ar experience optimization based approach automatically assigns contextually compatible location story event synthesizing navigation graph guide player different story branch considering walking experience validated effectiveness approach adapting ar narrative different scene experiment user studycomputer_games location_based_servicesar_devices ar_experiences augmented_reality_devices augmented_reality_narratives contextually_compatible_locations interactive_narratives location aware_adaptation optimization based_approach story_branches story_events virtual_events walking_experiences
15,User-Driven Constraints for Layout Optimisation in Augmented Reality,"Niyazov, A., Ens, B., Satriadi, K. A., Mellado, N., Barthe, L., Dwyer, T., & Serrano, M. (2023). User-Driven Constraints for Layout Optimisation in Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580873
",10.1145/3544548.3580873,"Automatic layout optimisation allows users to arrange augmented reality content in the real-world environment without the need for tedious manual interactions. This optimisation is often based on modelling the intended content placement as constraints, defined as cost functions. Then, applying a cost minimization algorithm leads to a desirable placement. However, such an approach is limited by the lack of user control over the optimisation results. In this paper we explore the concept of user-driven constraints for augmented reality layout optimisation. With our approach users can define and set up their own constraints directly within the real-world environment. We first present a design space composed of three dimensions: the constraints, the regions of interest and the constraint parameters. Then we explore which input gestures can be employed to define the user-driven constraints of our design space through a user elicitation study. Using the results of the study, we propose a holistic system design and implementation demonstrating our user-driven constraints, which we evaluate in a final user study where participants had to create several constraints at the same time to arrange a set of virtual contents.",C6130V Virtual reality;C1180 Optimisation techniques,augmented reality layout optimisation;constraint parameters;cost minimization algorithm;regions of interest;user control;user elicitation study;user-driven constraints;virtual contents,augmented reality;minimisation,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Niyazov, A.; (2) Ens, B.; (3) Satriadi, K.A.; (4) Mellado, N.; (1) Barthe, L.; (5) Dwyer, T.; (1) Serrano, M.; ","(1) University of Toulouse, IRIT, France; (2) Monash University, Faculty of Information Technology, Australia; (3) Monash University, Australia; (4) Centre National de la Recherche Scientifique, France; (5) Monash University, Data Visualisation and Immersive Analytics, Australia; ",ACM,-1,"[""minimisation""]","[""minimisation""]",minimisation,device energy management,displays,device energy management,displays,minimisation augmented_reality_layout_optimisation constraint_parameters cost_minimization_algorithm regions_of_interest user_control user_elicitation_study user driven_constraints virtual_contents c6130v_virtual_reality c1180_optimisation_techniques device_energy_management,minimisation,augmented_reality_layout_optimisation constraint_parameters cost_minimization_algorithm regions_of_interest user_control user_elicitation_study user driven_constraints virtual_contents,automatic layout optimisation allows user arrange augmented reality content real world environment without need tedious manual interaction optimisation often based modelling intended content placement constraint defined cost function applying cost minimization algorithm lead desirable placement however approach limited lack user control optimisation result paper explore concept user driven constraint augmented reality layout optimisation approach user define set constraint directly within real world environment first present design space composed three dimension constraint region interest constraint parameter explore input gesture employed define user driven constraint design space user elicitation study using result study propose holistic system design implementation demonstrating user driven constraint evaluate final user study participant create several constraint time arrange set virtual content,minimisation augmented_reality_layout_optimisation constraint_parameters cost_minimization_algorithm regions_of_interest user_control user_elicitation_study user driven_constraints virtual_contents c6130v_virtual_reality c1180_optimisation_techniques device_energy_management automatic layout optimisation allows user arrange augmented reality content real world environment without need tedious manual interaction optimisation often based modelling intended content placement constraint defined cost function applying cost minimization algorithm lead desirable placement however approach limited lack user control optimisation result paper explore concept user driven constraint augmented reality layout optimisation approach user define set constraint directly within real world environment first present design space composed three dimension constraint region interest constraint parameter explore input gesture employed define user driven constraint design space user elicitation study using result study propose holistic system design implementation demonstrating user driven constraint evaluate final user study participant create several constraint time arrange set virtual content,automatic layout optimisation allows user arrange augmented reality content real world environment without need tedious manual interaction optimisation often based modelling intended content placement constraint defined cost function applying cost minimization algorithm lead desirable placement however approach limited lack user control optimisation result paper explore concept user driven constraint augmented reality layout optimisation approach user define set constraint directly within real world environment first present design space composed three dimension constraint region interest constraint parameter explore input gesture employed define user driven constraint design space user elicitation study using result study propose holistic system design implementation demonstrating user driven constraint evaluate final user study participant create several constraint time arrange set virtual contentminimisationaugmented_reality_layout_optimisation constraint_parameters cost_minimization_algorithm regions_of_interest user_control user_elicitation_study user driven_constraints virtual_contents
16,Be our guest: intercultural heritage exchange through augmented reality (AR),"Sabie, D., Sheta, H., Ferdous, H. S., Kopalakrishnan, V., & Ahmed, S. I. (2023). Be Our Guest: Intercultural Heritage Exchange through Augmented Reality (AR). Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581005
",10.1145/3544548.3581005,"This paper explores how interactive applications can help mitigate the adversity of facing cultural differences between migrants and the host community, and between migrants of diverse backgrounds to foster intercultural exchange. Based on literature about situated cognition, immersive theater, and affordance, we designed and built Be Our Guest: an augmented reality application where a user is invited to the houses of people from different cultures and is asked to help with one of their cultural rituals around simple everyday objects. We detail the various phases we took to collect the cultural stories and construct the application. We then report the results of a user study with the developed application. Our findings show that participants were easily immersed in the augmented space due to the app's narrative, visuals, and interactive nature. Moreover, they enjoyed exploring cultural rituals, including their own, and felt more confident connecting with people from other cultures.",C7820 Humanities computing;C6130V Virtual reality,augmented reality application;Be Our Guest application;cultural differences;cultural rituals;cultural stories;immersive theater;intercultural exchange;intercultural heritage exchange;situated cognition,augmented reality;history,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Sabie, D.; (1) Sheta, H.; (2) Ferdous, H.S.; (1) Kopalakrishnan, V.; (1) Ahmed, S.I.; ","(1) University of Toronto, Computer Science, Toronto, ON, Canada; (2) University of Melbourne, Centre for Digital Transformation of Health, Melbourne, VIC, Australia; ",ACM,-1,"[""history""]","[""history""]",history,liberal arts,industries,liberal arts,industries,history augmented_reality_application be_our_guest_application cultural_differences cultural_rituals cultural_stories immersive_theater intercultural_exchange intercultural_heritage_exchange situated_cognition c7820_humanities_computing c6130v_virtual_reality liberal_arts,history,augmented_reality_application be_our_guest_application cultural_differences cultural_rituals cultural_stories immersive_theater intercultural_exchange intercultural_heritage_exchange situated_cognition,paper explores interactive application help mitigate adversity facing cultural difference migrant host community migrant diverse background foster intercultural exchange based literature situated cognition immersive theater affordance designed built guest augmented reality application user invited house people different culture asked help one cultural ritual around simple everyday object detail various phase took collect cultural story construct application report result user study developed application finding show participant easily immersed augmented space due app narrative visuals interactive nature moreover enjoyed exploring cultural ritual including felt confident connecting people culture,history augmented_reality_application be_our_guest_application cultural_differences cultural_rituals cultural_stories immersive_theater intercultural_exchange intercultural_heritage_exchange situated_cognition c7820_humanities_computing c6130v_virtual_reality liberal_arts paper explores interactive application help mitigate adversity facing cultural difference migrant host community migrant diverse background foster intercultural exchange based literature situated cognition immersive theater affordance designed built guest augmented reality application user invited house people different culture asked help one cultural ritual around simple everyday object detail various phase took collect cultural story construct application report result user study developed application finding show participant easily immersed augmented space due app narrative visuals interactive nature moreover enjoyed exploring cultural ritual including felt confident connecting people culture,paper explores interactive application help mitigate adversity facing cultural difference migrant host community migrant diverse background foster intercultural exchange based literature situated cognition immersive theater affordance designed built guest augmented reality application user invited house people different culture asked help one cultural ritual around simple everyday object detail various phase took collect cultural story construct application report result user study developed application finding show participant easily immersed augmented space due app narrative visuals interactive nature moreover enjoyed exploring cultural ritual including felt confident connecting people culturehistoryaugmented_reality_application be_our_guest_application cultural_differences cultural_rituals cultural_stories immersive_theater intercultural_exchange intercultural_heritage_exchange situated_cognition
17,An Efficient Class Room Teaching Learning Method Using Augmented Reality,"Valluru, D., Mustafa, M. A., Jasim, H. Y., Srikanth, K., RajaRao, M. V. L. N., & Sreedhar, P. S. S. (2023). An Efficient Class Room Teaching Learning Method Using Augmented Reality. 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS). https://doi.org/10.1109/icaccs57279.2023.10113096
",10.1109/ICACCS57279.2023.10113096,"Augmented Reality (AR), a unique method of integrating the virtual world into the real world, has the potential to increase academic attainment in the classroom. This research work focuses on developing and evaluating a strategy for enhancing student education with AR in the classroom. AR enables unique human-computer interactions in real time between the physical and digital worlds. The effectiveness of AR in the classroom will depend on its development, deployment, and integration into both standard and nontraditional teaching environments. Throughout the creation and implementation of an AR classroom, collaborative learning practices and other methodologies were taken into account. Collaboration occurs when two or more individuals work together, share information, and gain insights from one another. This research offers a succinct summary of the promise and challenges of adopting AR to transform the classroom.",C6130V Virtual reality;C6130G Groupware;C7810C Computer-aided instruction,academic attainment;AR classroom;Augmented Reality;augmented Reality;collaborative learning practices;developing evaluating;digital worlds;efficient class room teaching learning method;human-computer interactions;nontraditional teaching environments;physical worlds;standard teaching environments;student education;virtual world,augmented reality;computer aided instruction;groupware;teaching,2023,Conference article (CA),2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS),"(1) Valluru, D.; (2) Mustafa, M.A.; (3) Jasim, H.Y.; (4) Srikanth, K.; (4) Rajarao, M.V.L.N.; (4) Sreedhar, P.S.S.; ","(1) MLRITM Engineering College, Department of Computer Science and Engineering, India; (2) Imam Jaafar AL-Sadiq University, Department of Medical Laboratory Technology, Iraq; (3) Al-Farahidi University, Department of Law, Iraq; (4) Ministry of Electronics and Information Technology, Seshadri Rao Gudlavalleru Engineering College, India; ",IEEE,-1,"[""computer aided instruction"", ""groupware"", ""teaching""]","[""computer aided instruction"", ""groupware"", ""teaching""]",computer aided instruction;groupware;teaching,education;training;collaboration,use cases;industries,education;training;collaboration,use cases;industries,computer_aided_instruction groupware teaching academic_attainment ar_classroom augmented_reality augmented_reality collaborative_learning_practices developing_evaluating digital_worlds efficient_class_room_teaching_learning_method human computer_interactions nontraditional_teaching_environments physical_worlds standard_teaching_environments student_education virtual_world c6130v_virtual_reality c6130g_groupware c7810c_computer aided_instruction education training collaboration,computer_aided_instruction groupware teaching,academic_attainment ar_classroom augmented_reality augmented_reality collaborative_learning_practices developing_evaluating digital_worlds efficient_class_room_teaching_learning_method human computer_interactions nontraditional_teaching_environments physical_worlds standard_teaching_environments student_education virtual_world,augmented reality ar unique method integrating virtual world real world potential increase academic attainment classroom research work focus developing evaluating strategy enhancing student education ar classroom ar enables unique human computer interaction real time physical digital world effectiveness ar classroom depend development deployment integration standard nontraditional teaching environment throughout creation implementation ar classroom collaborative learning practice methodology taken account collaboration occurs two individual work together share information gain insight one another research offer succinct summary promise challenge adopting ar transform classroom,computer_aided_instruction groupware teaching academic_attainment ar_classroom augmented_reality augmented_reality collaborative_learning_practices developing_evaluating digital_worlds efficient_class_room_teaching_learning_method human computer_interactions nontraditional_teaching_environments physical_worlds standard_teaching_environments student_education virtual_world c6130v_virtual_reality c6130g_groupware c7810c_computer aided_instruction education training collaboration augmented reality ar unique method integrating virtual world real world potential increase academic attainment classroom research work focus developing evaluating strategy enhancing student education ar classroom ar enables unique human computer interaction real time physical digital world effectiveness ar classroom depend development deployment integration standard nontraditional teaching environment throughout creation implementation ar classroom collaborative learning practice methodology taken account collaboration occurs two individual work together share information gain insight one another research offer succinct summary promise challenge adopting ar transform classroom,augmented reality ar unique method integrating virtual world real world potential increase academic attainment classroom research work focus developing evaluating strategy enhancing student education ar classroom ar enables unique human computer interaction real time physical digital world effectiveness ar classroom depend development deployment integration standard nontraditional teaching environment throughout creation implementation ar classroom collaborative learning practice methodology taken account collaboration occurs two individual work together share information gain insight one another research offer succinct summary promise challenge adopting ar transform classroomcomputer_aided_instruction groupware teachingacademic_attainment ar_classroom augmented_reality augmented_reality collaborative_learning_practices developing_evaluating digital_worlds efficient_class_room_teaching_learning_method human computer_interactions nontraditional_teaching_environments physical_worlds standard_teaching_environments student_education virtual_world
18,An Augmented Reality based Intelligent Precision Agriculture using Cascade Advancement Technique,"Ulagammai, M., & Moorthy, R. N. (2023). An Augmented Reality based Intelligent Precision Agriculture using Cascade Advancement Technique. 2023 7th International Conference on Trends in Electronics and Informatics (ICOEI). https://doi.org/10.1109/icoei56765.2023.10125750
",10.1109/ICOEI56765.2023.10125750,"Agriculture is the backbone of developing countries and it is very important to the country's economy. Therefore, automation must be used in agriculture to solve the issues. The proposed system is based on augmented reality intelligent precision agriculture using the smart sensor. It consists of the hardware ESP32 microcontroller, DHT11 sensor, and Load, and the software unity hub in Augmented Reality technology and Blynk application is used. The proposed system uses a deep learning algorithm characterized by 4 process categories 1) sensor interface, 2) wireless transmission, 3) data processing and 4) data monitoring and controlling. Agriculture characteristics are mostly maintained in the IoT platform, and the AR controls the water outlet during irrigation. To improve system performance and reach maximum efficiency, it is helpful for farmers to maintain irrigation properly. This leads to alternatives that may be both effective and practical.","C7860 Agriculture, forestry and fisheries computing;C6130V Virtual reality;C6210 Knowledge based systems;C6264 Neural nets;E0410 Information technology applications;E3010 Agriculture",agriculture characteristics;augmented reality intelligent precision agriculture;augmented reality technology;cascade advancement technique;deep learning algorithm;DHT11 sensor;hardware ESP32 microcontroller;smart sensor;software unity hub;system performance,agriculture;augmented reality;deep learning (artificial intelligence);intelligent sensors;irrigation;microcontrollers,2023,Conference article (CA),2023 7th International Conference on Trends in Electronics and Informatics (ICOEI),"(1) Ulagammai, M.; (2) Moorthy, R.N.; ","(1) Saveetha Engineering College, Electrical and Electronics Engineering, India; (2) Embedded Systems Technologies, Saveetha Engineering College, India; ",IEEE,-1,"[""agriculture"", ""deep learning (artificial intelligence)"", ""intelligent sensors"", ""irrigation"", ""microcontrollers""]","[""agriculture"", ""deep learning (artificial intelligence)"", ""intelligent sensors"", ""irrigation"", ""microcontrollers""]",agriculture;deep learning (artificial intelligence);intelligent sensors;irrigation;microcontrollers,farming and natural science;other;input;liberal arts;medical;sensors;human-computer interaction;artificial intelligence,technology;other;end users and user experience;industries,farming and natural science;other;input;liberal arts;medical;sensors;human-computer interaction;artificial intelligence,technology;other;end users and user experience;industries,agriculture deep_learning_ artificial_intelligence intelligent_sensors irrigation microcontrollers agriculture_characteristics augmented_reality_intelligent_precision_agriculture augmented_reality_technology cascade_advancement_technique deep_learning_algorithm dht11_sensor hardware_esp32_microcontroller smart_sensor software_unity_hub system_performance c7860_agriculture _forestry_and_fisheries_computing c6130v_virtual_reality c6210_knowledge_based_systems c6264_neural_nets e0410_information_technology_applications e3010_agriculture farming_and_natural_science other input liberal_arts medical sensors human computer_interaction artificial_intelligence,agriculture deep_learning_ artificial_intelligence intelligent_sensors irrigation microcontrollers,agriculture_characteristics augmented_reality_intelligent_precision_agriculture augmented_reality_technology cascade_advancement_technique deep_learning_algorithm dht11_sensor hardware_esp32_microcontroller smart_sensor software_unity_hub system_performance,agriculture backbone developing country important country economy therefore automation must used agriculture solve issue proposed system based augmented reality intelligent precision agriculture using smart sensor consists hardware esp32 microcontroller dht11 sensor load software unity hub augmented reality technology blynk application used proposed system us deep learning algorithm characterized 4 process category 1 sensor interface 2 wireless transmission 3 data processing 4 data monitoring controlling agriculture characteristic mostly maintained iot platform ar control water outlet irrigation improve system performance reach maximum efficiency helpful farmer maintain irrigation properly lead alternative may effective practical,agriculture deep_learning_ artificial_intelligence intelligent_sensors irrigation microcontrollers agriculture_characteristics augmented_reality_intelligent_precision_agriculture augmented_reality_technology cascade_advancement_technique deep_learning_algorithm dht11_sensor hardware_esp32_microcontroller smart_sensor software_unity_hub system_performance c7860_agriculture _forestry_and_fisheries_computing c6130v_virtual_reality c6210_knowledge_based_systems c6264_neural_nets e0410_information_technology_applications e3010_agriculture farming_and_natural_science other input liberal_arts medical sensors human computer_interaction artificial_intelligence agriculture backbone developing country important country economy therefore automation must used agriculture solve issue proposed system based augmented reality intelligent precision agriculture using smart sensor consists hardware esp32 microcontroller dht11 sensor load software unity hub augmented reality technology blynk application used proposed system us deep learning algorithm characterized 4 process category 1 sensor interface 2 wireless transmission 3 data processing 4 data monitoring controlling agriculture characteristic mostly maintained iot platform ar control water outlet irrigation improve system performance reach maximum efficiency helpful farmer maintain irrigation properly lead alternative may effective practical,agriculture backbone developing country important country economy therefore automation must used agriculture solve issue proposed system based augmented reality intelligent precision agriculture using smart sensor consists hardware esp32 microcontroller dht11 sensor load software unity hub augmented reality technology blynk application used proposed system us deep learning algorithm characterized 4 process category 1 sensor interface 2 wireless transmission 3 data processing 4 data monitoring controlling agriculture characteristic mostly maintained iot platform ar control water outlet irrigation improve system performance reach maximum efficiency helpful farmer maintain irrigation properly lead alternative may effective practicalagriculture deep_learning_ artificial_intelligence intelligent_sensors irrigation microcontrollersagriculture_characteristics augmented_reality_intelligent_precision_agriculture augmented_reality_technology cascade_advancement_technique deep_learning_algorithm dht11_sensor hardware_esp32_microcontroller smart_sensor software_unity_hub system_performance
19,Explainable Human-Robot Training and Cooperation with Augmented Reality,"Wang, C., Belardinelli, A., Hasler, S., Stouraitis, T., Tanneberg, D., & Gienger, M. (2023). Explainable Human-Robot Training and Cooperation with Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583889
",10.1145/3544549.3583889,"The current spread of social and assistive robotics applications is increasingly highlighting the need for robots that can be easily taught and interacted with, even by users with no technical background. Still, it is often difficult to grasp what such robots know or to assess if a correct representation of the task is being formed. Augmented Reality (AR) has the potential to bridge this gap. We demonstrate three use cases where AR design elements enhance the explainability and efficiency of human-robot interaction: 1) a human teaching a robot some simple kitchen tasks by demonstration, 2) the robot showing its plan for solving novel tasks in AR to a human for validation, and 3) a robot communicating its intentions via AR while assisting people with limited mobility during daily activities.",C6180R Human-robot interaction;C3390 Robotics;C3390C Mobile robots;C6130V Virtual reality,assistive robotics applications;augmented Reality;Augmented Reality;correct representation;current spread;explainability;explainable human-robot training;human teaching;human-robot interaction;robots know;simple kitchen tasks;social robotics applications;technical background,augmented reality;human-robot interaction;mobile robots,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Wang, C.; (1) Belardinelli, A.; (1) Hasler, S.; (2) Stouraitis, T.; (2) Tanneberg, D.; (1) Gienger, M.; ","(1) Honda Research Institute Europe, Germany; (2) Honda Research Institute EU, Germany; ",ACM,-1,"[""human-robot interaction"", ""mobile robots""]","[""human-robot interaction"", ""mobile robots""]",human-robot interaction;mobile robots,robotics,technology,robotics,technology,human robot_interaction mobile_robots assistive_robotics_applications augmented_reality augmented_reality correct_representation current_spread explainability explainable_human robot_training human_teaching human robot_interaction robots_know simple_kitchen_tasks social_robotics_applications technical_background c6180r_human robot_interaction c3390_robotics c3390c_mobile_robots c6130v_virtual_reality robotics,human robot_interaction mobile_robots,assistive_robotics_applications augmented_reality augmented_reality correct_representation current_spread explainability explainable_human robot_training human_teaching human robot_interaction robots_know simple_kitchen_tasks social_robotics_applications technical_background,current spread social assistive robotics application increasingly highlighting need robot easily taught interacted even user technical background still often difficult grasp robot know ass correct representation task formed augmented reality ar potential bridge gap demonstrate three use case ar design element enhance explainability efficiency human robot interaction 1 human teaching robot simple kitchen task demonstration 2 robot showing plan solving novel task ar human validation 3 robot communicating intention via ar assisting people limited mobility daily activity,human robot_interaction mobile_robots assistive_robotics_applications augmented_reality augmented_reality correct_representation current_spread explainability explainable_human robot_training human_teaching human robot_interaction robots_know simple_kitchen_tasks social_robotics_applications technical_background c6180r_human robot_interaction c3390_robotics c3390c_mobile_robots c6130v_virtual_reality robotics current spread social assistive robotics application increasingly highlighting need robot easily taught interacted even user technical background still often difficult grasp robot know ass correct representation task formed augmented reality ar potential bridge gap demonstrate three use case ar design element enhance explainability efficiency human robot interaction 1 human teaching robot simple kitchen task demonstration 2 robot showing plan solving novel task ar human validation 3 robot communicating intention via ar assisting people limited mobility daily activity,current spread social assistive robotics application increasingly highlighting need robot easily taught interacted even user technical background still often difficult grasp robot know ass correct representation task formed augmented reality ar potential bridge gap demonstrate three use case ar design element enhance explainability efficiency human robot interaction 1 human teaching robot simple kitchen task demonstration 2 robot showing plan solving novel task ar human validation 3 robot communicating intention via ar assisting people limited mobility daily activityhuman robot_interaction mobile_robotsassistive_robotics_applications augmented_reality augmented_reality correct_representation current_spread explainability explainable_human robot_training human_teaching human robot_interaction robots_know simple_kitchen_tasks social_robotics_applications technical_background
20,Improvement and Application of Image Segmentation Algorithm for Outdoor Augmented Reality,"Liang, H., Wang, Z., & Li, Y. (2023). Improvement and Application of Image Segmentation Algorithm for Outdoor Augmented Reality. Proceedings of the International Conference on Internet of Things, Communication and Intelligent Technology, 366–376. https://doi.org/10.1007/978-981-99-0416-7_37
",10.1007/978-981-99-0416-7_37,"The traditional image recognition process mostly occurs in indoor scenes with relatively stable environment, and the current development of augmented reality tends to apply to outdoor scenes, such as the identification of buildings, statues and other objects in the tourism industry. Aimed to cope with the problem that the augmented reality effect of the ARToolKit system is difficult to be achieved in the outdoor natural scenes because of the wrong segmentation due to the influence of real-time changing illumination, occlusion and other factors, an improved GrabCut algorithm based on histogram equalization is proposed. Histogram equalization uses non-linear stretching of the image to improve image contrast. The boundary function of GrabCut algorithm is averaged to reduce the error segmentation of edge pixels, improve the edge integrity of the target image, and achieve accurate image segmentation. The experimental results show that the proposed method has high real-time performance and stability in complex real-world scenarios, and improves the processing performance of ARToolKit augmented reality system in outdoor scenes. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","713.5 Electronic Circuits Other Than Amplifiers, Oscillators, Modulators, Limiters, Discriminators or Mixers;723 Computer Software, Data Handling and Applications",'current;Artoolkit;Grabcut;Histogram equalizations;Image segmentation algorithm;Images segmentations;Outdoor augmented reality;Outdoor scenes;Recognition process;Tourism industry,Augmented reality;Equalizers;Graphic methods;Image enhancement;Image recognition,2023,Conference article (CA),Lect. Notes Electr. Eng.,"(1) Liang, Hua; (1) Wang, Ziyan; (1) Li, Yizheng; ","(1) Hunan International Economics University, Changsha; 410205, China; (2) University of Perpetual Help System DALTA Graduate School, Las Pi&ntilde;as City; 1740, Philippines; ",Springer Science and Business Media Deutschland GmbH,-1,"[""equalizers"", ""graphic methods"", ""image enhancement"", ""image recognition""]","[""equalizers"", ""graphic methods"", ""image enhancement"", ""image recognition""]",equalizers;graphic methods;image enhancement;image recognition,computer vision;human factors;graphics;other,technology;other;end users and user experience,computer vision;human factors;graphics;other,technology;other;end users and user experience,equalizers graphic_methods image_enhancement image_recognition current artoolkit grabcut histogram_equalizations image_segmentation_algorithm images_segmentations outdoor_augmented_reality outdoor_scenes recognition_process tourism_industry 713 5_electronic_circuits_other_than_amplifiers _oscillators _modulators _limiters _discriminators_or_mixers 723_computer_software _data_handling_and_applications computer_vision human_factors graphics other,equalizers graphic_methods image_enhancement image_recognition,current artoolkit grabcut histogram_equalizations image_segmentation_algorithm images_segmentations outdoor_augmented_reality outdoor_scenes recognition_process tourism_industry,traditional image recognition process mostly occurs indoor scene relatively stable environment current development augmented reality tends apply outdoor scene identification building statue object tourism industry aimed cope problem augmented reality effect artoolkit system difficult achieved outdoor natural scene wrong segmentation due influence real time changing illumination occlusion factor improved grabcut algorithm based histogram equalization proposed histogram equalization us non linear stretching image improve image contrast boundary function grabcut algorithm averaged reduce error segmentation edge pixel improve edge integrity target image achieve accurate image segmentation experimental result show proposed method high real time performance stability complex real world scenario improves processing performance artoolkit augmented reality system outdoor scene copy 2023 author exclusive license springer nature singapore pte ltd,equalizers graphic_methods image_enhancement image_recognition current artoolkit grabcut histogram_equalizations image_segmentation_algorithm images_segmentations outdoor_augmented_reality outdoor_scenes recognition_process tourism_industry 713 5_electronic_circuits_other_than_amplifiers _oscillators _modulators _limiters _discriminators_or_mixers 723_computer_software _data_handling_and_applications computer_vision human_factors graphics other traditional image recognition process mostly occurs indoor scene relatively stable environment current development augmented reality tends apply outdoor scene identification building statue object tourism industry aimed cope problem augmented reality effect artoolkit system difficult achieved outdoor natural scene wrong segmentation due influence real time changing illumination occlusion factor improved grabcut algorithm based histogram equalization proposed histogram equalization us non linear stretching image improve image contrast boundary function grabcut algorithm averaged reduce error segmentation edge pixel improve edge integrity target image achieve accurate image segmentation experimental result show proposed method high real time performance stability complex real world scenario improves processing performance artoolkit augmented reality system outdoor scene copy 2023 author exclusive license springer nature singapore pte ltd,traditional image recognition process mostly occurs indoor scene relatively stable environment current development augmented reality tends apply outdoor scene identification building statue object tourism industry aimed cope problem augmented reality effect artoolkit system difficult achieved outdoor natural scene wrong segmentation due influence real time changing illumination occlusion factor improved grabcut algorithm based histogram equalization proposed histogram equalization us non linear stretching image improve image contrast boundary function grabcut algorithm averaged reduce error segmentation edge pixel improve edge integrity target image achieve accurate image segmentation experimental result show proposed method high real time performance stability complex real world scenario improves processing performance artoolkit augmented reality system outdoor scene copy 2023 author exclusive license springer nature singapore pte ltdequalizers graphic_methods image_enhancement image_recognitioncurrent artoolkit grabcut histogram_equalizations image_segmentation_algorithm images_segmentations outdoor_augmented_reality outdoor_scenes recognition_process tourism_industry
21,May I Still Define Myself? Exploring How Dissonance in Displaying Personal Information Through Head-Mounted Augmented Reality Can Affect Personal Information Sovereignty,"Rixen, J. O., Funk, C., Rukzio, E., & Gugenheimer, J. (2023). May I Still Define Myself? Exploring How Dissonance in Displaying Personal Information Through Head-Mounted Augmented Reality Can Affect Personal Information Sovereignty. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585821
",10.1145/3544549.3585821,"Head-mounted Augmented Reality enables individuals to overlay digital information onto the physical world, consequently influencing how they assess and react to augmented social situations. While prior work has shown that augmenting social situations with faithful personal information can benefit a conversation, honest mistakes or an attempt to deceive might lead to a dissonance between augmentation and verbally disclosed information. In this work, we take the first steps towards understanding the happenings in case of information dissonance by conducting a preliminary within-subject online video study (N=30), investigating how it affects users, perception of the interlocutor, and if augmentation or interlocutor would act as the more trusted instance. We found that only 26.7% trusted the interlocutor's verbally uttered information, while a majority believed the AR device (46.7%) or were undecided (26.7%). We discuss this split in trust and argue for the importance of and factors for a follow-up study on this topic.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C5540D Computer displays,augmented social situations;head-mounted augmented reality;information dissonance;personal information displaying;personal information sovereignty,augmented reality;helmet mounted displays;human factors,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Rixen, J.O.; (1) Funk, C.; (2) Rukzio, E.; (3) Gugenheimer, J.; ","(1) Universitat Ulm, Institute of Media Informatics, Germany; (2) University of Ulm, Germany; (3) Technische Universitat Darmstadt, Germany; ",ACM,-1,"[""helmet mounted displays"", ""human factors""]","[""helmet mounted displays"", ""human factors""]",helmet mounted displays;human factors,display technology;human factors;wearables,displays;end users and user experience,display technology;human factors;wearables,displays;end users and user experience,helmet_mounted_displays human_factors augmented_social_situations head mounted_augmented_reality information_dissonance personal_information_displaying personal_information_sovereignty c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5540d_computer_displays display_technology human_factors wearables,helmet_mounted_displays human_factors,augmented_social_situations head mounted_augmented_reality information_dissonance personal_information_displaying personal_information_sovereignty,head mounted augmented reality enables individual overlay digital information onto physical world consequently influencing ass react augmented social situation prior work shown augmenting social situation faithful personal information benefit conversation honest mistake attempt deceive might lead dissonance augmentation verbally disclosed information work take first step towards understanding happening case information dissonance conducting preliminary within subject online video study n 30 investigating affect user perception interlocutor augmentation interlocutor would act trusted instance found 26 7 trusted interlocutor verbally uttered information majority believed ar device 46 7 undecided 26 7 discus split trust argue importance factor follow study topic,helmet_mounted_displays human_factors augmented_social_situations head mounted_augmented_reality information_dissonance personal_information_displaying personal_information_sovereignty c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5540d_computer_displays display_technology human_factors wearables head mounted augmented reality enables individual overlay digital information onto physical world consequently influencing ass react augmented social situation prior work shown augmenting social situation faithful personal information benefit conversation honest mistake attempt deceive might lead dissonance augmentation verbally disclosed information work take first step towards understanding happening case information dissonance conducting preliminary within subject online video study n 30 investigating affect user perception interlocutor augmentation interlocutor would act trusted instance found 26 7 trusted interlocutor verbally uttered information majority believed ar device 46 7 undecided 26 7 discus split trust argue importance factor follow study topic,head mounted augmented reality enables individual overlay digital information onto physical world consequently influencing ass react augmented social situation prior work shown augmenting social situation faithful personal information benefit conversation honest mistake attempt deceive might lead dissonance augmentation verbally disclosed information work take first step towards understanding happening case information dissonance conducting preliminary within subject online video study n 30 investigating affect user perception interlocutor augmentation interlocutor would act trusted instance found 26 7 trusted interlocutor verbally uttered information majority believed ar device 46 7 undecided 26 7 discus split trust argue importance factor follow study topichelmet_mounted_displays human_factorsaugmented_social_situations head mounted_augmented_reality information_dissonance personal_information_displaying personal_information_sovereignty
22,CO2LLAB: Creating an Eco-Conscious Community through Habit Tracking and Augmented Reality Visualisation,"Chun, H. Y. R., Gao, Y., Nursalamah, R. K., O Keeffe, C. M., & Shin, H. (2023). CO2LLAB: Creating an Eco-Conscious Community through Habit Tracking and Augmented Reality Visualisation. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583834
",10.1145/3544549.3583834,"CO2e emissions remain a substantial problem for the environment despite efforts from numerous initiatives over the years to curb their output. The role of younger generations is critical in this problem space. From user research, we found that young adults rarely volunteer but do engage frequently in individual actions geared towards the environment. They are also motivated when they see others' contributions. We decided to leverage this willingness for individual environmental actions and turn it into a collective effort by creating CO2LLAB, a platform that reimagines how young adults can reduce CO2e emissions with their community. It incorporates a habit-tracking app for eco-friendly actions and augmented reality technology to visualise their impact. Our prototype evaluation demonstrated that CO2LLAB not only educated them on the topic, but also motivated them to consider their impact on their community more.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6130B Graphics techniques;C6190V Mobile, ubiquitous and pervasive computing;E0230 Environmental issues",augmented reality technology;augmented reality visualisation;CO2LLAB;collective effort;eco-conscious community;eco-friendly actions;habit tracking;habit-tracking;individual actions;individual environmental actions;numerous initiatives;problem space;substantial problem;user research;young adults;younger generations,augmented reality;data visualisation;human factors;mobile computing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Chun, H.Y.R.; (1) Gao, Y.; (1) Nursalamah, R.K.; (1) O Keeffe, C.M.; (1) Shin, H.; ","(1) University College London, United Kingdom; ",ACM,-1,"[""data visualization"", ""human factors"", ""mobile computing""]","[""data visualization"", ""human factors"", ""mobile computing""]",data visualization;human factors;mobile computing,human factors;telecommunication;data,technology;industries;end users and user experience,human factors;telecommunication;data,technology;industries;end users and user experience,data_visualization human_factors mobile_computing augmented_reality_technology augmented_reality_visualisation co2llab collective_effort eco conscious_community eco friendly_actions habit_tracking habit tracking individual_actions individual_environmental_actions numerous_initiatives problem_space substantial_problem user_research young_adults younger_generations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing e0230_environmental_issues human_factors telecommunication data,data_visualization human_factors mobile_computing,augmented_reality_technology augmented_reality_visualisation co2llab collective_effort eco conscious_community eco friendly_actions habit_tracking habit tracking individual_actions individual_environmental_actions numerous_initiatives problem_space substantial_problem user_research young_adults younger_generations,co2e emission remain substantial problem environment despite effort numerous initiative year curb output role younger generation critical problem space user research found young adult rarely volunteer engage frequently individual action geared towards environment also motivated see others contribution decided leverage willingness individual environmental action turn collective effort creating co2llab platform reimagines young adult reduce co2e emission community incorporates habit tracking app eco friendly action augmented reality technology visualise impact prototype evaluation demonstrated co2llab educated topic also motivated consider impact community,data_visualization human_factors mobile_computing augmented_reality_technology augmented_reality_visualisation co2llab collective_effort eco conscious_community eco friendly_actions habit_tracking habit tracking individual_actions individual_environmental_actions numerous_initiatives problem_space substantial_problem user_research young_adults younger_generations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing e0230_environmental_issues human_factors telecommunication data co2e emission remain substantial problem environment despite effort numerous initiative year curb output role younger generation critical problem space user research found young adult rarely volunteer engage frequently individual action geared towards environment also motivated see others contribution decided leverage willingness individual environmental action turn collective effort creating co2llab platform reimagines young adult reduce co2e emission community incorporates habit tracking app eco friendly action augmented reality technology visualise impact prototype evaluation demonstrated co2llab educated topic also motivated consider impact community,co2e emission remain substantial problem environment despite effort numerous initiative year curb output role younger generation critical problem space user research found young adult rarely volunteer engage frequently individual action geared towards environment also motivated see others contribution decided leverage willingness individual environmental action turn collective effort creating co2llab platform reimagines young adult reduce co2e emission community incorporates habit tracking app eco friendly action augmented reality technology visualise impact prototype evaluation demonstrated co2llab educated topic also motivated consider impact communitydata_visualization human_factors mobile_computingaugmented_reality_technology augmented_reality_visualisation co2llab collective_effort eco conscious_community eco friendly_actions habit_tracking habit tracking individual_actions individual_environmental_actions numerous_initiatives problem_space substantial_problem user_research young_adults younger_generations
23,The Reflective Make-AR In-Action: Using Augmented Reality for Reflection-based Learning of Makerskills,"Turakhia, D. G., Jiang, P., & Mueller, S. (2023). The Reflective Make-AR In-Action: Using Augmented Reality for Reflection-based Learning of Makerskills. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585850
",10.1145/3544549.3585850,"Recent work on reflective learning supports self-paced learning of skills like breadboarding and using power tools in makerspaces through a reflection exercise toolkit. This toolkit monitors the learners' performances in real-time and prompts them to reflect both in-action and on-action i.e., during and after their maker activities. In this paper, we build on this prior work and use an augmented reality system to monitor, prompt, and record in-action reflections, i.e., while the maker activity is in progress. In particular, we propose a framework to design multi-modal reflective prompts for self-learning exercises using augmented reality with three specific goals - (1) adding real-world contextualization, (2) overlaying personalized multimodal contextual information for supporting in-action reflections, and (3) maintaining an immersive experience during the reflection exercises. We conclude with a discussion of three application case studies for reflective AR maker exercises.",C7810C Computer-aided instruction;C6130V Virtual reality;C7870 Sport,augmented reality system;makerskills;multimodal contextual information;reflection exercise toolkit;reflection-based learning;reflective AR maker exercises;reflective learning;reflective Make-AR In-Action;self-learning exercises,augmented reality;computer aided instruction;sport,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Turakhia, D.G.; (2) Jiang, P.; (3) Mueller, S.; ","(1) Massachusetts Institute of Technology, MIT CSAIL, Cambridge, MA, United States; (2) University of California, San Diego, Department of Cognitive Science and Design Lab, San Diego, CA, United States; (3) MIT CSAIL, Cambridge, MA, United States; ",ACM,-1,"[""computer aided instruction"", ""sports""]","[""computer aided instruction"", ""sports""]",computer aided instruction;sports,cultural heritage;training,use cases;industries,cultural heritage;training,use cases;industries,computer_aided_instruction sports augmented_reality_system makerskills multimodal_contextual_information reflection_exercise_toolkit reflection based_learning reflective_ar_maker_exercises reflective_learning reflective_make ar_in action self learning_exercises c7810c_computer aided_instruction c6130v_virtual_reality c7870_sport cultural_heritage training,computer_aided_instruction sports,augmented_reality_system makerskills multimodal_contextual_information reflection_exercise_toolkit reflection based_learning reflective_ar_maker_exercises reflective_learning reflective_make ar_in action self learning_exercises,recent work reflective learning support self paced learning skill like breadboarding using power tool makerspaces reflection exercise toolkit toolkit monitor learner performance real time prompt reflect action action e maker activity paper build prior work use augmented reality system monitor prompt record action reflection e maker activity progress particular propose framework design multi modal reflective prompt self learning exercise using augmented reality three specific goal 1 adding real world contextualization 2 overlaying personalized multimodal contextual information supporting action reflection 3 maintaining immersive experience reflection exercise conclude discussion three application case study reflective ar maker exercise,computer_aided_instruction sports augmented_reality_system makerskills multimodal_contextual_information reflection_exercise_toolkit reflection based_learning reflective_ar_maker_exercises reflective_learning reflective_make ar_in action self learning_exercises c7810c_computer aided_instruction c6130v_virtual_reality c7870_sport cultural_heritage training recent work reflective learning support self paced learning skill like breadboarding using power tool makerspaces reflection exercise toolkit toolkit monitor learner performance real time prompt reflect action action e maker activity paper build prior work use augmented reality system monitor prompt record action reflection e maker activity progress particular propose framework design multi modal reflective prompt self learning exercise using augmented reality three specific goal 1 adding real world contextualization 2 overlaying personalized multimodal contextual information supporting action reflection 3 maintaining immersive experience reflection exercise conclude discussion three application case study reflective ar maker exercise,recent work reflective learning support self paced learning skill like breadboarding using power tool makerspaces reflection exercise toolkit toolkit monitor learner performance real time prompt reflect action action e maker activity paper build prior work use augmented reality system monitor prompt record action reflection e maker activity progress particular propose framework design multi modal reflective prompt self learning exercise using augmented reality three specific goal 1 adding real world contextualization 2 overlaying personalized multimodal contextual information supporting action reflection 3 maintaining immersive experience reflection exercise conclude discussion three application case study reflective ar maker exercisecomputer_aided_instruction sportsaugmented_reality_system makerskills multimodal_contextual_information reflection_exercise_toolkit reflection based_learning reflective_ar_maker_exercises reflective_learning reflective_make ar_in action self learning_exercises
24,Spatial location-based outdoor mobile augmented reality 3D registration technology,"Zhou, Q., Wang, Q., Zhong, Q., & Han, M. (2023). Spatial location-based outdoor mobile augmented reality 3D registration technology. Fifth International Conference on Computer Information Science and Artificial Intelligence (CISAI 2022). https://doi.org/10.1117/12.2667317
",10.1117/12.2667317,"Human activities are closely related to geographic location. It is proposed to combine spatial location and mobile terminal pose sensor data with meeting the characteristics of real-time accuracy and flexibility in outdoor mobile augmented reality and to realize the virtual-real superposition through the transformation relationship between 3D model coordinate system, world coordinate system, camera coordinate system, image coordinate system, and pixel coordinate system. For the limitations of the vision-based registration method in outdoor scenes, this paper derives the transformation from spatial location data to screen coordinates in detail. It gives the solution and optimization of the transformation matrix and parameters. &copy; 2023 SPIE.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;921.3 Mathematical Transformations",3D registration;3D-registration;Co-ordinate system;Geographic location;Human activities;Location based;Mobile augmented reality;Outdoor scenes;Position and pose;Spatial location,3D modeling;Augmented reality;Linear transformations;Location,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zhou, Qian; (1) Wang, Qing; (1) Zhong, Qiang; (1) Han, Mao; ","(1) Department of Computer Science and Technology, China Agricultural University, Beijing; 100083, China; ",SPIE,-1,"[""3d modeling"", ""linear transformations"", ""location""]","[""3d modeling"", ""linear transformations"", ""location""]",3d modeling;linear transformations;location,geospatial;manufacturing;medical;data,technology;industries,geospatial;manufacturing;medical;data,technology;industries,3d_modeling linear_transformations location 3d_registration 3d registration co ordinate_system geographic_location human_activities location_based mobile_augmented_reality outdoor_scenes position_and_pose spatial_location 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 921 3_mathematical_transformations geospatial manufacturing medical data,3d_modeling linear_transformations location,3d_registration 3d registration co ordinate_system geographic_location human_activities location_based mobile_augmented_reality outdoor_scenes position_and_pose spatial_location,human activity closely related geographic location proposed combine spatial location mobile terminal pose sensor data meeting characteristic real time accuracy flexibility outdoor mobile augmented reality realize virtual real superposition transformation relationship 3d model coordinate system world coordinate system camera coordinate system image coordinate system pixel coordinate system limitation vision based registration method outdoor scene paper derives transformation spatial location data screen coordinate detail give solution optimization transformation matrix parameter copy 2023 spie,3d_modeling linear_transformations location 3d_registration 3d registration co ordinate_system geographic_location human_activities location_based mobile_augmented_reality outdoor_scenes position_and_pose spatial_location 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 921 3_mathematical_transformations geospatial manufacturing medical data human activity closely related geographic location proposed combine spatial location mobile terminal pose sensor data meeting characteristic real time accuracy flexibility outdoor mobile augmented reality realize virtual real superposition transformation relationship 3d model coordinate system world coordinate system camera coordinate system image coordinate system pixel coordinate system limitation vision based registration method outdoor scene paper derives transformation spatial location data screen coordinate detail give solution optimization transformation matrix parameter copy 2023 spie,human activity closely related geographic location proposed combine spatial location mobile terminal pose sensor data meeting characteristic real time accuracy flexibility outdoor mobile augmented reality realize virtual real superposition transformation relationship 3d model coordinate system world coordinate system camera coordinate system image coordinate system pixel coordinate system limitation vision based registration method outdoor scene paper derives transformation spatial location data screen coordinate detail give solution optimization transformation matrix parameter copy 2023 spie3d_modeling linear_transformations location3d_registration 3d registration co ordinate_system geographic_location human_activities location_based mobile_augmented_reality outdoor_scenes position_and_pose spatial_location
25,Augmented Reality System as a 5.0 Marketing Strategy in Restaurants: A Case Study in Ambato Ecuador,"Paredes, P.-R., & Ballesteros-Lopez, L.-G. (2023). Augmented Reality System as a 5.0 Marketing Strategy in Restaurants: A Case Study in Ambato Ecuador. Lecture Notes in Networks and Systems, 127–137. https://doi.org/10.1007/978-3-031-30592-4_10
",10.1007/978-3-031-30592-4_10,"The Covid-19 pandemic affected several productive sectors. However, the tourism sector was and continues to be one of the most damaged. Companies were forced to evolve technologically in order to cope with this condition. More than 90% of businesses lost their investment, as well as their human resources. After more than two and a half years after this crisis&rsquo;s beginning, establishments are still looking for a solution to their financial debacle. This article presents the development and implementation of an augmented reality system as a 5.0 marketing strategy focused on a restaurant in the city of Ambato, Ecuador. The results showed encouraging data. The evaluation of user experience through the System Usability Scale showed a value above 70. The comparison between before and after the implementation of this system showed a percentage increase in sales of 47.45%. Finally, the T-student test for independent samples was used to verify the existence of a statistically significant difference. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;911.4 Marketing;912.2 Management",Augmented reality systems;Case-studies;Condition;Covid-19;Ecuador;Evaluation of users;Food industries;Marketing 5.0;Marketing strategy;Tourism sectors,Augmented reality;Commerce;Strategic planning;Tourism,2023,Conference article (CA),Lect. Notes Networks Syst.,"(1) Paredes, Pablo-R.; (1) Ballesteros-Lopez, Leonardo-Gabriel; ","(1) Universidad Tecnica de Ambato, UTA, Ambato; 180103, Ecuador; ",Springer Science and Business Media Deutschland GmbH,-1,"[""commerce"", ""strategic planning"", ""tourism""]","[""commerce"", ""strategic planning"", ""tourism""]",commerce;strategic planning;tourism,sales and marketing;cultural heritage;business planning and management,business;industries,sales and marketing;cultural heritage;business planning and management,business;industries,commerce strategic_planning tourism augmented_reality_systems case studies condition covid 19 ecuador evaluation_of_users food_industries marketing_5 0 marketing_strategy tourism_sectors 723_computer_software _data_handling_and_applications 911 4_marketing 912 2_management sales_and_marketing cultural_heritage business_planning_and_management,commerce strategic_planning tourism,augmented_reality_systems case studies condition covid 19 ecuador evaluation_of_users food_industries marketing_5 0 marketing_strategy tourism_sectors,covid 19 pandemic affected several productive sector however tourism sector continues one damaged company forced evolve technologically order cope condition 90 business lost investment well human resource two half year crisis rsquo beginning establishment still looking solution financial debacle article present development implementation augmented reality system 5 0 marketing strategy focused restaurant city ambato ecuador result showed encouraging data evaluation user experience system usability scale showed value 70 comparison implementation system showed percentage increase sale 47 45 finally student test independent sample used verify existence statistically significant difference copy 2023 author exclusive license springer nature switzerland ag,commerce strategic_planning tourism augmented_reality_systems case studies condition covid 19 ecuador evaluation_of_users food_industries marketing_5 0 marketing_strategy tourism_sectors 723_computer_software _data_handling_and_applications 911 4_marketing 912 2_management sales_and_marketing cultural_heritage business_planning_and_management covid 19 pandemic affected several productive sector however tourism sector continues one damaged company forced evolve technologically order cope condition 90 business lost investment well human resource two half year crisis rsquo beginning establishment still looking solution financial debacle article present development implementation augmented reality system 5 0 marketing strategy focused restaurant city ambato ecuador result showed encouraging data evaluation user experience system usability scale showed value 70 comparison implementation system showed percentage increase sale 47 45 finally student test independent sample used verify existence statistically significant difference copy 2023 author exclusive license springer nature switzerland ag,covid 19 pandemic affected several productive sector however tourism sector continues one damaged company forced evolve technologically order cope condition 90 business lost investment well human resource two half year crisis rsquo beginning establishment still looking solution financial debacle article present development implementation augmented reality system 5 0 marketing strategy focused restaurant city ambato ecuador result showed encouraging data evaluation user experience system usability scale showed value 70 comparison implementation system showed percentage increase sale 47 45 finally student test independent sample used verify existence statistically significant difference copy 2023 author exclusive license springer nature switzerland agcommerce strategic_planning tourismaugmented_reality_systems case studies condition covid 19 ecuador evaluation_of_users food_industries marketing_5 0 marketing_strategy tourism_sectors
26,MOFA: Exploring Asymmetric Mixed Reality Design Strategy for Co-located Multiplayer Between Handheld and Head-mounted Augmented Reality,"Hu, B., Zhang, Y., Hao, S., & Tao, Y. (2023). MOFA: Exploring Asymmetric Mixed Reality Design Strategy for Co-located Multiplayer Between Handheld and Head-mounted Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583935
",10.1145/3544549.3583935,"For co-located multiplayer asymmetric Mixed Reality (MR) scenarios involving both Handheld Augmented Reality (HAR) and head-mounted Stereoscopic Augmented Reality (StAR) devices, we propose a design strategy to distinguish the roles of different players based on the affordances, limitations, and capabilities of these two kinds of AR devices. Specifically, the roles include: a HAR player as a third-person passive participant (termed spectator), a third-person active participant (termed puppeteer), a first-person participant, and a first-person partial-information participant; and a StAR player as a first-person participant and a first-person partial-information participant. In order to explore this concept, we designed four multiplayer MR game prototypes: The Duck, The Ghost, The Dragon, and The Duel to demonstrate strategies for creating interesting, engaging, and strategic cooperative experiences between players.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6180 User interfaces;C7830D Computer games,asymmetric Mixed Reality design strategy;co-located multiplayer asymmetric Mixed Reality scenarios;different players;first-person participant;Handheld Augmented Reality;HAR player;head-mounted Stereoscopic Augmented Reality devices;partial-information participant;roles include;StAR player;termed puppeteer;termed spectator;third-person active participant;third-person passive participant,augmented reality;computer games;human computer interaction;stereo image processing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Hu, B.; (1) Zhang, Y.; (1) Hao, S.; (1) Tao, Y.; ","(1) Holo Interactive, Washington, DC, United States; ",ACM,-1,"[""computer games"", ""human computer interaction"", ""stereo image processing""]","[""computer games"", ""human computer interaction"", ""stereo image processing""]",computer games;human computer interaction;stereo image processing,computer vision;liberal arts;data;human-computer interaction,technology;industries;end users and user experience,computer vision;liberal arts;data;human-computer interaction,technology;industries;end users and user experience,computer_games human_computer_interaction stereo_image_processing asymmetric_mixed_reality_design_strategy co located_multiplayer_asymmetric_mixed_reality_scenarios different_players first person_participant handheld_augmented_reality har_player head mounted_stereoscopic_augmented_reality_devices partial information_participant roles_include star_player termed_puppeteer termed_spectator third person_active_participant third person_passive_participant c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces c7830d_computer_games computer_vision liberal_arts data human computer_interaction,computer_games human_computer_interaction stereo_image_processing,asymmetric_mixed_reality_design_strategy co located_multiplayer_asymmetric_mixed_reality_scenarios different_players first person_participant handheld_augmented_reality har_player head mounted_stereoscopic_augmented_reality_devices partial information_participant roles_include star_player termed_puppeteer termed_spectator third person_active_participant third person_passive_participant,co located multiplayer asymmetric mixed reality mr scenario involving handheld augmented reality har head mounted stereoscopic augmented reality star device propose design strategy distinguish role different player based affordances limitation capability two kind ar device specifically role include har player third person passive participant termed spectator third person active participant termed puppeteer first person participant first person partial information participant star player first person participant first person partial information participant order explore concept designed four multiplayer mr game prototype duck ghost dragon duel demonstrate strategy creating interesting engaging strategic cooperative experience player,computer_games human_computer_interaction stereo_image_processing asymmetric_mixed_reality_design_strategy co located_multiplayer_asymmetric_mixed_reality_scenarios different_players first person_participant handheld_augmented_reality har_player head mounted_stereoscopic_augmented_reality_devices partial information_participant roles_include star_player termed_puppeteer termed_spectator third person_active_participant third person_passive_participant c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces c7830d_computer_games computer_vision liberal_arts data human computer_interaction co located multiplayer asymmetric mixed reality mr scenario involving handheld augmented reality har head mounted stereoscopic augmented reality star device propose design strategy distinguish role different player based affordances limitation capability two kind ar device specifically role include har player third person passive participant termed spectator third person active participant termed puppeteer first person participant first person partial information participant star player first person participant first person partial information participant order explore concept designed four multiplayer mr game prototype duck ghost dragon duel demonstrate strategy creating interesting engaging strategic cooperative experience player,co located multiplayer asymmetric mixed reality mr scenario involving handheld augmented reality har head mounted stereoscopic augmented reality star device propose design strategy distinguish role different player based affordances limitation capability two kind ar device specifically role include har player third person passive participant termed spectator third person active participant termed puppeteer first person participant first person partial information participant star player first person participant first person partial information participant order explore concept designed four multiplayer mr game prototype duck ghost dragon duel demonstrate strategy creating interesting engaging strategic cooperative experience playercomputer_games human_computer_interaction stereo_image_processingasymmetric_mixed_reality_design_strategy co located_multiplayer_asymmetric_mixed_reality_scenarios different_players first person_participant handheld_augmented_reality har_player head mounted_stereoscopic_augmented_reality_devices partial information_participant roles_include star_player termed_puppeteer termed_spectator third person_active_participant third person_passive_participant
27,Supporting Piggybacked Co-Located Leisure Activities via Augmented Reality,"Reig, S., Principe Cruz, E., Powers, M. M., He, J., Chong, T., Tham, Y. J., Kratz, S., Robinson, A., Smith, B. A., Vaish, R., & Monroy-Hernández, A. (2023). Supporting Piggybacked Co-Located Leisure Activities via Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580833
",10.1145/3544548.3580833,"Technology, especially the smartphone, is villainized for taking meaning and time away from in-person interactions and secluding people into ""digital bubbles"". We believe this is not an intrinsic property of digital gadgets, but evidence of a lack of imagination in technology design. Leveraging augmented reality (AR) toward this end allows us to create experiences for multiple people, their pets, and their environments. In this work, we explore the design of AR technology that ""piggybacks"" on everyday leisure to foster co-located interactions among close ties (with other people and pets). We designed, developed, and deployed three such AR applications, and evaluated them through a 41-participant and 19-pet user study. We gained key insights about the ability of AR to spur and enrich interaction in new channels, the importance of customization, and the challenges of designing for the physical aspects of AR devices (e.g., holding smartphones). These insights guide design implications for the novel research space of co-located AR.","C7820 Humanities computing;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",augmented reality;digital bubbles;digital gadgets;everyday leisure;in-person interactions;insights guide design implications;piggybacked co-located leisure activities;piggybacks;smartphones;technology design,augmented reality;humanities;smart phones,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Reig, S.; (1) Principe Cruz, E.; (2) Powers, M.M.; (3) He, J.; (4) Chong, T.; (5) Tham, Y.J.; (6) Kratz, S.; (5) Robinson, A.; (7) Smith, B.A.; (5) Vaish, R.; (8) Monroy-Herna&#769;ndez, A.; ","(1) Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; (2) New York University, New York, NY, United States; (3) Stanford University, Stanford, CA, United States; (4) University of Washington, Seattle, WA, United States; (5) Snap Inc, United States; (6) Independent, United States; (7) Columbia University, New York, NY, United States; (8) Princeton University, Computer Science, Princeton, NJ, United States; ",ACM,-1,"[""humanities"", ""smartphones""]","[""humanities"", ""smartphones""]",humanities;smartphones,telecommunication;liberal arts,industries,telecommunication;liberal arts,industries,humanities smartphones augmented_reality digital_bubbles digital_gadgets everyday_leisure in person_interactions insights_guide_design_implications piggybacked_co located_leisure_activities piggybacks smartphones technology_design c7820_humanities_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication liberal_arts,humanities smartphones,augmented_reality digital_bubbles digital_gadgets everyday_leisure in person_interactions insights_guide_design_implications piggybacked_co located_leisure_activities piggybacks smartphones technology_design,technology especially smartphone villainized taking meaning time away person interaction secluding people digital bubble believe intrinsic property digital gadget evidence lack imagination technology design leveraging augmented reality ar toward end allows u create experience multiple people pet environment work explore design ar technology piggyback everyday leisure foster co located interaction among close tie people pet designed developed deployed three ar application evaluated 41 participant 19 pet user study gained key insight ability ar spur enrich interaction new channel importance customization challenge designing physical aspect ar device e g holding smartphones insight guide design implication novel research space co located ar,humanities smartphones augmented_reality digital_bubbles digital_gadgets everyday_leisure in person_interactions insights_guide_design_implications piggybacked_co located_leisure_activities piggybacks smartphones technology_design c7820_humanities_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication liberal_arts technology especially smartphone villainized taking meaning time away person interaction secluding people digital bubble believe intrinsic property digital gadget evidence lack imagination technology design leveraging augmented reality ar toward end allows u create experience multiple people pet environment work explore design ar technology piggyback everyday leisure foster co located interaction among close tie people pet designed developed deployed three ar application evaluated 41 participant 19 pet user study gained key insight ability ar spur enrich interaction new channel importance customization challenge designing physical aspect ar device e g holding smartphones insight guide design implication novel research space co located ar,technology especially smartphone villainized taking meaning time away person interaction secluding people digital bubble believe intrinsic property digital gadget evidence lack imagination technology design leveraging augmented reality ar toward end allows u create experience multiple people pet environment work explore design ar technology piggyback everyday leisure foster co located interaction among close tie people pet designed developed deployed three ar application evaluated 41 participant 19 pet user study gained key insight ability ar spur enrich interaction new channel importance customization challenge designing physical aspect ar device e g holding smartphones insight guide design implication novel research space co located arhumanities smartphonesaugmented_reality digital_bubbles digital_gadgets everyday_leisure in person_interactions insights_guide_design_implications piggybacked_co located_leisure_activities piggybacks smartphones technology_design
28,An Optimal Visualization of Traffic System by using Augmented Reality and Virtual Reality,"Dang, R., Krishna, V., Sharma, R., & Kowsigan, M. (2023). An Optimal Visualization of Traffic System by using Augmented Reality and Virtual Reality. 2023 3rd International Conference on Smart Data Intelligence (ICSMDI). https://doi.org/10.1109/icsmdi57622.2023.00062
",10.1109/ICSMDI57622.2023.00062,"This study explains the concept of deadlock by focusing on prevention and avoidance with the help of one of the emerging technologies, Augmented Reality (AR). With the help of AR, people can easily understand this concept. This can be easily explained with the help of real time example of traffic system on the road. To solve this issue, this study has implemented the Bankers Algorithm, which is a Deadlock Prevention Algorithm. The Bankers Algorithm can use its calculation and prevent the occurrence of Deadlock or incase a deadlock is happening it can help to resolve it.",C6130V Virtual reality;C1160 Combinatorial mathematics;C1180 Optimisation techniques;E1510 Manufacturing systems,Augmented Reality;Bankers Algorithm;Deadlock Prevention Algorithm;optimal visualization;time example;traffic system;virtual Reality,augmented reality;concurrency control;flexible manufacturing systems;virtual reality,2023,Conference article (CA),2023 3rd International Conference on Smart Data Intelligence (ICSMDI),"(1) Dang, R.; (1) Krishna, V.; (1) Sharma, R.; (1) Kowsigan, M.; ","(1) SRM Institute of Science and Technology, Department of Computing Technologies, India; ",IEEE,-1,"[""concurrency control"", ""flexible manufacturing systems""]","[""concurrency control"", ""flexible manufacturing systems""]",concurrency control;flexible manufacturing systems,other;education;manufacturing,other;industries,other;education;manufacturing,other;industries,concurrency_control flexible_manufacturing_systems augmented_reality bankers_algorithm deadlock_prevention_algorithm optimal_visualization time_example traffic_system virtual_reality c6130v_virtual_reality c1160_combinatorial_mathematics c1180_optimisation_techniques e1510_manufacturing_systems other education manufacturing,concurrency_control flexible_manufacturing_systems,augmented_reality bankers_algorithm deadlock_prevention_algorithm optimal_visualization time_example traffic_system virtual_reality,study explains concept deadlock focusing prevention avoidance help one emerging technology augmented reality ar help ar people easily understand concept easily explained help real time example traffic system road solve issue study implemented banker algorithm deadlock prevention algorithm banker algorithm use calculation prevent occurrence deadlock incase deadlock happening help resolve,concurrency_control flexible_manufacturing_systems augmented_reality bankers_algorithm deadlock_prevention_algorithm optimal_visualization time_example traffic_system virtual_reality c6130v_virtual_reality c1160_combinatorial_mathematics c1180_optimisation_techniques e1510_manufacturing_systems other education manufacturing study explains concept deadlock focusing prevention avoidance help one emerging technology augmented reality ar help ar people easily understand concept easily explained help real time example traffic system road solve issue study implemented banker algorithm deadlock prevention algorithm banker algorithm use calculation prevent occurrence deadlock incase deadlock happening help resolve,study explains concept deadlock focusing prevention avoidance help one emerging technology augmented reality ar help ar people easily understand concept easily explained help real time example traffic system road solve issue study implemented banker algorithm deadlock prevention algorithm banker algorithm use calculation prevent occurrence deadlock incase deadlock happening help resolveconcurrency_control flexible_manufacturing_systemsaugmented_reality bankers_algorithm deadlock_prevention_algorithm optimal_visualization time_example traffic_system virtual_reality
29,"Dream Garden: Exploring Location-Based, Collaboratively-Created Augmented Reality Spaces","Petrov, E., & Monroy-Hernández, A. (2023). Dream Garden: Exploring Location-Based, Collaboratively-Created Augmented Reality Spaces. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585810
",10.1145/3544549.3585810,"We introduce Dream Garden, an augmented reality application (AR) that lets people place 3D flowers into the physical world to build a collaborative location-based garden. Despite the potential for connecting strangers in the digital realm, current research has not explored location-based augmented reality experiences that enable strangers to connect by building artifacts collaboratively. We explore this by creating an AR digital community garden deployed in a specific location. Anyone with the proper app can access and see the flowers previously planted by strangers, as well as plant their own flowers to grow the garden. We evaluated this app with 10 participants, with 5 visiting the digital garden more than once, to evaluate their sense of connection to the other participants as each participant added one digital flower to the garden. We found that participants were joyful about building a shared space, were excited about the dynamic nature of the garden, felt a connection to the physical location of the digital garden, and expressed a sense of belonging to a community of strangers but not necessarily an emotional connection.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6130G Groupware;C6190V Mobile, ubiquitous and pervasive computing",3D flowers;AR digital community garden;collaborative location-based garden;collaboratively-created augmented reality spaces;digital flower;digital realm;Dream Garden;emotional connection;location-based augmented reality experiences;physical location;physical world,augmented reality;groupware;human computer interaction;location based services;user experience,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Petrov, E.; (2) Monroy-Herna&#769;ndez, A.; ","(1) Princeton University, Princeton, NJ, United States; (2) Princeton University, Computer Science, Princeton, NJ, United States; ",ACM,-1,"[""groupware"", ""human computer interaction"", ""location based services"", ""user experience""]","[""groupware"", ""human computer interaction"", ""location based services"", ""user experience""]",groupware;human computer interaction;location based services;user experience,geospatial;human factors;human-computer interaction;collaboration,technology;use cases;end users and user experience,geospatial;human factors;human-computer interaction;collaboration,technology;use cases;end users and user experience,groupware human_computer_interaction location_based_services user_experience 3d_flowers ar_digital_community_garden collaborative_location based_garden collaboratively created_augmented_reality_spaces digital_flower digital_realm dream_garden emotional_connection location based_augmented_reality_experiences physical_location physical_world c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130g_groupware c6190v_mobile _ubiquitous_and_pervasive_computing geospatial human_factors human computer_interaction collaboration,groupware human_computer_interaction location_based_services user_experience,3d_flowers ar_digital_community_garden collaborative_location based_garden collaboratively created_augmented_reality_spaces digital_flower digital_realm dream_garden emotional_connection location based_augmented_reality_experiences physical_location physical_world,introduce dream garden augmented reality application ar let people place 3d flower physical world build collaborative location based garden despite potential connecting stranger digital realm current research explored location based augmented reality experience enable stranger connect building artifact collaboratively explore creating ar digital community garden deployed specific location anyone proper app access see flower previously planted stranger well plant flower grow garden evaluated app 10 participant 5 visiting digital garden evaluate sense connection participant participant added one digital flower garden found participant joyful building shared space excited dynamic nature garden felt connection physical location digital garden expressed sense belonging community stranger necessarily emotional connection,groupware human_computer_interaction location_based_services user_experience 3d_flowers ar_digital_community_garden collaborative_location based_garden collaboratively created_augmented_reality_spaces digital_flower digital_realm dream_garden emotional_connection location based_augmented_reality_experiences physical_location physical_world c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130g_groupware c6190v_mobile _ubiquitous_and_pervasive_computing geospatial human_factors human computer_interaction collaboration introduce dream garden augmented reality application ar let people place 3d flower physical world build collaborative location based garden despite potential connecting stranger digital realm current research explored location based augmented reality experience enable stranger connect building artifact collaboratively explore creating ar digital community garden deployed specific location anyone proper app access see flower previously planted stranger well plant flower grow garden evaluated app 10 participant 5 visiting digital garden evaluate sense connection participant participant added one digital flower garden found participant joyful building shared space excited dynamic nature garden felt connection physical location digital garden expressed sense belonging community stranger necessarily emotional connection,introduce dream garden augmented reality application ar let people place 3d flower physical world build collaborative location based garden despite potential connecting stranger digital realm current research explored location based augmented reality experience enable stranger connect building artifact collaboratively explore creating ar digital community garden deployed specific location anyone proper app access see flower previously planted stranger well plant flower grow garden evaluated app 10 participant 5 visiting digital garden evaluate sense connection participant participant added one digital flower garden found participant joyful building shared space excited dynamic nature garden felt connection physical location digital garden expressed sense belonging community stranger necessarily emotional connectiongroupware human_computer_interaction location_based_services user_experience3d_flowers ar_digital_community_garden collaborative_location based_garden collaboratively created_augmented_reality_spaces digital_flower digital_realm dream_garden emotional_connection location based_augmented_reality_experiences physical_location physical_world
30,Location-Based Augmented Reality for Cultural Heritage Communication and Education: The Doltso District Application,"Kleftodimos, A., Evagelou, A., Triantafyllidou, A., Grigoriou, M., & Lappas, G. (2023). Location-Based Augmented Reality for Cultural Heritage Communication and Education: The Doltso District Application. Sensors, 23(10), 4963. https://doi.org/10.3390/s23104963
",10.3390/s23104963,"Location-based Augmented Reality applications are increasingly used in many research and commercial fields. Some of the fields that these applications are used are recreational digital games, tourism, education, and marketing. This study aims to present a location-based augmented reality (AR) application for cultural heritage communication and education. The application was created to inform the public, especially K12 students, about a district of their city with cultural heritage value. Furthermore, Google Earth was utilized to create an interactive virtual tour for consolidating the knowledge acquired by the location-based AR application. A scheme for evaluating the AR application was also constructed using factors suitable for location-based applications: challenge, educational usefulness (knowledge), collaboration, and intention to reuse. A sample of 309 students evaluated the application. Descriptive statistical analysis showed that the application scored well in all factors, especially in challenge and knowledge (mean values 4.21 and 4.12). Furthermore, structural equation modeling (SEM) analysis led to a model construction that represents how the factors are causally related. Based on the findings, the perceived challenge significantly influenced the perceived educational usefulness (knowledge) (b = 0.459, sig = 0.000) and interaction levels (b = 0.645, sig = 0.000). Interaction amongst users also had a significant positive impact on users&rsquo; perceived educational usefulness (b = 0.374, sig = 0.000), which in turn influenced users&rsquo; intention to reuse the application (b = 0.624, sig = 0.000). &copy; 2023 by the authors.","723 Computer Software, Data Handling and Applications;922.2 Mathematical Statistics",Augmented reality applications;Cultural heritage communication;Cultural heritage Education;Cultural heritages;Digital games;Digital tourism;Game-based Learning;Location based;Location-based applications;Reuse,Augmented reality;Education computing;Factor analysis;Location,2023,Journal article (JA),Sensors,"(1) Kleftodimos, Alexandros; (2) Evagelou, Athanasios; (1) Triantafyllidou, Amalia; (2) Grigoriou, Magdalini; (1) Lappas, Georgios; ","(1) Department of Communication and Digital Media, University of Western Macedonia, Kastoria; 52100, Greece; (2) The Center for Education for the Environment and Sustainability of Kastoria, Kastoria; 52100, Greece; ",MDPI,-1,"[""education computing"", ""factor analysis"", ""location""]","[""education computing"", ""factor analysis"", ""location""]",education computing;factor analysis;location,geospatial;other;education,technology;other;industries,geospatial;other;education,technology;other;industries,education_computing factor_analysis location augmented_reality_applications cultural_heritage_communication cultural_heritage_education cultural_heritages digital_games digital_tourism game based_learning location_based location based_applications reuse 723_computer_software _data_handling_and_applications 922 2_mathematical_statistics geospatial other education,education_computing factor_analysis location,augmented_reality_applications cultural_heritage_communication cultural_heritage_education cultural_heritages digital_games digital_tourism game based_learning location_based location based_applications reuse,location based augmented reality application increasingly used many research commercial field field application used recreational digital game tourism education marketing study aim present location based augmented reality ar application cultural heritage communication education application created inform public especially k12 student district city cultural heritage value furthermore google earth utilized create interactive virtual tour consolidating knowledge acquired location based ar application scheme evaluating ar application also constructed using factor suitable location based application challenge educational usefulness knowledge collaboration intention reuse sample 309 student evaluated application descriptive statistical analysis showed application scored well factor especially challenge knowledge mean value 4 21 4 12 furthermore structural equation modeling sem analysis led model construction represents factor causally related based finding perceived challenge significantly influenced perceived educational usefulness knowledge b 0 459 sig 0 000 interaction level b 0 645 sig 0 000 interaction amongst user also significant positive impact user rsquo perceived educational usefulness b 0 374 sig 0 000 turn influenced user rsquo intention reuse application b 0 624 sig 0 000 copy 2023 author,education_computing factor_analysis location augmented_reality_applications cultural_heritage_communication cultural_heritage_education cultural_heritages digital_games digital_tourism game based_learning location_based location based_applications reuse 723_computer_software _data_handling_and_applications 922 2_mathematical_statistics geospatial other education location based augmented reality application increasingly used many research commercial field field application used recreational digital game tourism education marketing study aim present location based augmented reality ar application cultural heritage communication education application created inform public especially k12 student district city cultural heritage value furthermore google earth utilized create interactive virtual tour consolidating knowledge acquired location based ar application scheme evaluating ar application also constructed using factor suitable location based application challenge educational usefulness knowledge collaboration intention reuse sample 309 student evaluated application descriptive statistical analysis showed application scored well factor especially challenge knowledge mean value 4 21 4 12 furthermore structural equation modeling sem analysis led model construction represents factor causally related based finding perceived challenge significantly influenced perceived educational usefulness knowledge b 0 459 sig 0 000 interaction level b 0 645 sig 0 000 interaction amongst user also significant positive impact user rsquo perceived educational usefulness b 0 374 sig 0 000 turn influenced user rsquo intention reuse application b 0 624 sig 0 000 copy 2023 author,location based augmented reality application increasingly used many research commercial field field application used recreational digital game tourism education marketing study aim present location based augmented reality ar application cultural heritage communication education application created inform public especially k12 student district city cultural heritage value furthermore google earth utilized create interactive virtual tour consolidating knowledge acquired location based ar application scheme evaluating ar application also constructed using factor suitable location based application challenge educational usefulness knowledge collaboration intention reuse sample 309 student evaluated application descriptive statistical analysis showed application scored well factor especially challenge knowledge mean value 4 21 4 12 furthermore structural equation modeling sem analysis led model construction represents factor causally related based finding perceived challenge significantly influenced perceived educational usefulness knowledge b 0 459 sig 0 000 interaction level b 0 645 sig 0 000 interaction amongst user also significant positive impact user rsquo perceived educational usefulness b 0 374 sig 0 000 turn influenced user rsquo intention reuse application b 0 624 sig 0 000 copy 2023 authoreducation_computing factor_analysis locationaugmented_reality_applications cultural_heritage_communication cultural_heritage_education cultural_heritages digital_games digital_tourism game based_learning location_based location based_applications reuse
31,Are you talking to me? An Audio Augmented Reality conversational guide for cultural heritage,"Tsepapadakis, M., & Gavalas, D. (2023). Are you talking to me? An Audio Augmented Reality conversational guide for cultural heritage. Pervasive and Mobile Computing, 92, 101797. https://doi.org/10.1016/j.pmcj.2023.101797
",10.1016/j.pmcj.2023.101797,"Augmented Reality (AR) technologies are increasingly utilized as a means of stimulating immersive experiences to cultural site visitors, mainly through visual superimposition of interactive digital elements onto the physical world. Recent research has investigated the use of Audio AR (AAR) in heritage sites, wherein visitors listen to spatially registered sound which could be attributed to &lsquo;talking&rsquo; physical artefacts. A parallel trend in the audience engagement programs of cultural institutions involves the employment of AI chatbots which are engaged in dialogues with followers or visitors to provide meaningful responses to a number of user questions. Herein, we present Exhibot, an intelligent audio guide system aiming at enhancing the user experience of cultural site visitors. Exhibot involves the combination of AAR and chatbot technologies to enable natural visitor-exhibit interaction, while also leveraging IoT devices to contextualize the delivered information. The key contribution of the proposed system lies in the interplay of AAR, chatbot and IoT technologies to create immersive learning experiences in the context of an integrated cultural guide system. Exhibot has undergone field trials to validate its usability and utility in realistic operational conditions. As a case study, we have chosen the statue of a prominent politician situated at a central square in Heraklion, Greece. The evaluation results indicated a very positive attitude of users, which is attributed both to the sense of immersion evoked by the AAR-powered storytelling and the natural human-like conversation enabled by the chatbot. &copy; 2023 Elsevier B.V.","722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;751.1 Acoustic Waves",AI chatbot;Audio augmented reality;Chatbots;Context- awareness;Conversational audio guide;Cultural heritages;Cultural user experience;Exhibot;IBM watson;IoT;Spatial sound;User evaluations;Users' experiences,Augmented reality;Internet of things,2023,Journal article (JA),Pervasive Mob. Comput.,"(1) Tsepapadakis, Michalis; (2) Gavalas, Damianos; ","(1) School of Science and Technology, Hellenic Open University, Patras, Greece; (2) Department of Product and Systems Design Engineering, University of the Aegean, Syros, Greece; ",Elsevier B.V.,-1,"[""internet of things""]","[""internet of things""]",internet of things,internet of things;networks,technology,internet of things;networks,technology,internet_of_things ai_chatbot audio_augmented_reality chatbots context _awareness conversational_audio_guide cultural_heritages cultural_user_experience exhibot ibm_watson iot spatial_sound user_evaluations users _experiences 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 751 1_acoustic_waves internet_of_things networks,internet_of_things,ai_chatbot audio_augmented_reality chatbots context _awareness conversational_audio_guide cultural_heritages cultural_user_experience exhibot ibm_watson iot spatial_sound user_evaluations users _experiences,augmented reality ar technology increasingly utilized mean stimulating immersive experience cultural site visitor mainly visual superimposition interactive digital element onto physical world recent research investigated use audio ar aar heritage site wherein visitor listen spatially registered sound could attributed lsquo talking rsquo physical artefact parallel trend audience engagement program cultural institution involves employment ai chatbots engaged dialogue follower visitor provide meaningful response number user question herein present exhibot intelligent audio guide system aiming enhancing user experience cultural site visitor exhibot involves combination aar chatbot technology enable natural visitor exhibit interaction also leveraging iot device contextualize delivered information key contribution proposed system lie interplay aar chatbot iot technology create immersive learning experience context integrated cultural guide system exhibot undergone field trial validate usability utility realistic operational condition case study chosen statue prominent politician situated central square heraklion greece evaluation result indicated positive attitude user attributed sense immersion evoked aar powered storytelling natural human like conversation enabled chatbot copy 2023 elsevier b v,internet_of_things ai_chatbot audio_augmented_reality chatbots context _awareness conversational_audio_guide cultural_heritages cultural_user_experience exhibot ibm_watson iot spatial_sound user_evaluations users _experiences 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 751 1_acoustic_waves internet_of_things networks augmented reality ar technology increasingly utilized mean stimulating immersive experience cultural site visitor mainly visual superimposition interactive digital element onto physical world recent research investigated use audio ar aar heritage site wherein visitor listen spatially registered sound could attributed lsquo talking rsquo physical artefact parallel trend audience engagement program cultural institution involves employment ai chatbots engaged dialogue follower visitor provide meaningful response number user question herein present exhibot intelligent audio guide system aiming enhancing user experience cultural site visitor exhibot involves combination aar chatbot technology enable natural visitor exhibit interaction also leveraging iot device contextualize delivered information key contribution proposed system lie interplay aar chatbot iot technology create immersive learning experience context integrated cultural guide system exhibot undergone field trial validate usability utility realistic operational condition case study chosen statue prominent politician situated central square heraklion greece evaluation result indicated positive attitude user attributed sense immersion evoked aar powered storytelling natural human like conversation enabled chatbot copy 2023 elsevier b v,augmented reality ar technology increasingly utilized mean stimulating immersive experience cultural site visitor mainly visual superimposition interactive digital element onto physical world recent research investigated use audio ar aar heritage site wherein visitor listen spatially registered sound could attributed lsquo talking rsquo physical artefact parallel trend audience engagement program cultural institution involves employment ai chatbots engaged dialogue follower visitor provide meaningful response number user question herein present exhibot intelligent audio guide system aiming enhancing user experience cultural site visitor exhibot involves combination aar chatbot technology enable natural visitor exhibit interaction also leveraging iot device contextualize delivered information key contribution proposed system lie interplay aar chatbot iot technology create immersive learning experience context integrated cultural guide system exhibot undergone field trial validate usability utility realistic operational condition case study chosen statue prominent politician situated central square heraklion greece evaluation result indicated positive attitude user attributed sense immersion evoked aar powered storytelling natural human like conversation enabled chatbot copy 2023 elsevier b vinternet_of_thingsai_chatbot audio_augmented_reality chatbots context _awareness conversational_audio_guide cultural_heritages cultural_user_experience exhibot ibm_watson iot spatial_sound user_evaluations users _experiences
32,Predicting Gaze-based Target Selection in Augmented Reality Headsets based on Eye and Head Endpoint Distributions,"Wei, Y., Shi, R., Yu, D., Wang, Y., Li, Y., Yu, L., & Liang, H.-N. (2023). Predicting Gaze-based Target Selection in Augmented Reality Headsets based on Eye and Head Endpoint Distributions. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581042
",10.1145/3544548.3581042,"Target selection is a fundamental task in interactive Augmented Reality (AR) systems. Predicting the intended target of selection in such systems can provide users with a smooth, low-friction interaction experience. Our work aims to predict gaze-based target selection in AR headsets with eye and head endpoint distributions, which describe the probability distribution of eye and head 3D orientation when a user triggers a selection input. We first conducted a user study to collect users' eye and head behavior in a gaze-based pointing selection task with two confirmation mechanisms (air tap and blinking). Based on the study results, we then built two models: a unimodal model using only eye endpoints and a multimodal model using both eye and head endpoints. Results from a second user study showed that the pointing accuracy is improved by approximately 32% after integrating our models into gaze-based selection techniques.",C6130V Virtual reality;C5540B Interactive-input devices;C6180 User interfaces,Augmented Reality headsets;eye endpoints;gaze-based selection techniques;gaze-based target selection;head 3D orientation;head behavior;head endpoint distributions;head endpoints;interactive Augmented Reality systems;low-friction interaction experience;probability distribution;selection input;selection task;users,augmented reality;eye;gaze tracking;human computer interaction;probability,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Wei, Y.; (1) Shi, R.; (2) Yu, D.; (3) Wang, Y.; (1) Li, Y.; (1) Yu, L.; (1) Liang, H.-N.; ","(1) Xi'an Jiaotong-Liverpool University, Department of Computing, China; (2) University of Melbourne, School of Computing and Information Systems, Melbourne, VIC, Australia; (3) Xi'an Jiaotong-Liverpool University, Computer Science and Software Engineering, China; ",ACM,-1,"[""eye"", ""gaze tracking"", ""human computer interaction"", ""probability""]","[""eye"", ""gaze tracking"", ""human computer interaction"", ""probability""]",eye;gaze tracking;human computer interaction;probability,computer vision;input;video;human-computer interaction,technology;end users and user experience,computer vision;input;video;human-computer interaction,technology;end users and user experience,eye gaze_tracking human_computer_interaction probability augmented_reality_headsets eye_endpoints gaze based_selection_techniques gaze based_target_selection head_3d_orientation head_behavior head_endpoint_distributions head_endpoints interactive_augmented_reality_systems low friction_interaction_experience probability_distribution selection_input selection_task users c6130v_virtual_reality c5540b_interactive input_devices c6180_user_interfaces computer_vision input video human computer_interaction,eye gaze_tracking human_computer_interaction probability,augmented_reality_headsets eye_endpoints gaze based_selection_techniques gaze based_target_selection head_3d_orientation head_behavior head_endpoint_distributions head_endpoints interactive_augmented_reality_systems low friction_interaction_experience probability_distribution selection_input selection_task users,target selection fundamental task interactive augmented reality ar system predicting intended target selection system provide user smooth low friction interaction experience work aim predict gaze based target selection ar headset eye head endpoint distribution describe probability distribution eye head 3d orientation user trigger selection input first conducted user study collect user eye head behavior gaze based pointing selection task two confirmation mechanism air tap blinking based study result built two model unimodal model using eye endpoint multimodal model using eye head endpoint result second user study showed pointing accuracy improved approximately 32 integrating model gaze based selection technique,eye gaze_tracking human_computer_interaction probability augmented_reality_headsets eye_endpoints gaze based_selection_techniques gaze based_target_selection head_3d_orientation head_behavior head_endpoint_distributions head_endpoints interactive_augmented_reality_systems low friction_interaction_experience probability_distribution selection_input selection_task users c6130v_virtual_reality c5540b_interactive input_devices c6180_user_interfaces computer_vision input video human computer_interaction target selection fundamental task interactive augmented reality ar system predicting intended target selection system provide user smooth low friction interaction experience work aim predict gaze based target selection ar headset eye head endpoint distribution describe probability distribution eye head 3d orientation user trigger selection input first conducted user study collect user eye head behavior gaze based pointing selection task two confirmation mechanism air tap blinking based study result built two model unimodal model using eye endpoint multimodal model using eye head endpoint result second user study showed pointing accuracy improved approximately 32 integrating model gaze based selection technique,target selection fundamental task interactive augmented reality ar system predicting intended target selection system provide user smooth low friction interaction experience work aim predict gaze based target selection ar headset eye head endpoint distribution describe probability distribution eye head 3d orientation user trigger selection input first conducted user study collect user eye head behavior gaze based pointing selection task two confirmation mechanism air tap blinking based study result built two model unimodal model using eye endpoint multimodal model using eye head endpoint result second user study showed pointing accuracy improved approximately 32 integrating model gaze based selection techniqueeye gaze_tracking human_computer_interaction probabilityaugmented_reality_headsets eye_endpoints gaze based_selection_techniques gaze based_target_selection head_3d_orientation head_behavior head_endpoint_distributions head_endpoints interactive_augmented_reality_systems low friction_interaction_experience probability_distribution selection_input selection_task users
33,Media comparison studies dominate comparative research on augmented reality in education,"Buchner, J., & Kerres, M. (2023). Media comparison studies dominate comparative research on augmented reality in education. Computers &amp; Education, 195, 104711. https://doi.org/10.1016/j.compedu.2022.104711
",10.1016/j.compedu.2022.104711,"Research on the use of augmented reality (AR) in education has received a lot of attention in recent years. Based on many systematic reviews and meta-analyses, it has been concluded that AR is effective. Recently, however, researchers have criticized the fact that the empirical basis for this conclusion is based on results from methodologically problematic media comparison studies. However, an analysis of the literature and quantitative evidence for this claim are lacking. In this research project, this research gap was addressed using the Systematic Review method. A total of 92 primary studies from the top 12&lt;i&gt;Educational Technology&lt;/i&gt;journals were coded and analyzed. The results show that research on AR in education is based on media comparison studies: 80% of the studies compare AR to another medium or technology. Few studies examine how and when learning with AR is effective. In addition, results show that over the years, since 2009, more media comparison studies have been published than other research types. We summarize why media comparison studies are problematic and discuss directions for future research on AR in education. This research shifts from the question&lt;i&gt;if&lt;/i&gt;AR can be used in instruction to the more important questions of&lt;i&gt;how&lt;/i&gt;and&lt;i&gt;when&lt;/i&gt;learning and teaching with AR works. All rights reserved Elsevier.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality,92 primary studies;augmented reality;comparative research;methodologically problematic media comparison studies;research project;research types,augmented reality;computer aided instruction;educational technology;reviews;teaching,2023,Journal article (JA),Comput. Educ. (Netherlands),"(1) Buchner, J.; (2) Kerres, M.; ","(1) Padagogische Hochschule St Gallen, Mu&#776;ller-Friedbergstrasse 34, Switzerland; (2) University of Duisburg-Essen, Learning Lab, Universita&#776;tstra&#223;e 2, Germany; ",Elsevier B.V.,-1,"[""computer aided instruction"", ""educational technology"", ""reviews"", ""teaching""]","[""computer aided instruction"", ""educational technology"", ""reviews"", ""teaching""]",computer aided instruction;educational technology;reviews;teaching,education;training;human-computer interaction;standards,standards;end users and user experience;use cases;industries,education;training;human-computer interaction;standards,standards;end users and user experience;use cases;industries,computer_aided_instruction educational_technology reviews teaching 92_primary_studies augmented_reality comparative_research methodologically_problematic_media_comparison_studies research_project research_types c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality education training human computer_interaction standards,computer_aided_instruction educational_technology reviews teaching,92_primary_studies augmented_reality comparative_research methodologically_problematic_media_comparison_studies research_project research_types,research use augmented reality ar education received lot attention recent year based many systematic review meta analysis concluded ar effective recently however researcher criticized fact empirical basis conclusion based result methodologically problematic medium comparison study however analysis literature quantitative evidence claim lacking research project research gap addressed using systematic review method total 92 primary study top 12 lt gt educational technology lt gt journal coded analyzed result show research ar education based medium comparison study 80 study compare ar another medium technology study examine learning ar effective addition result show year since 2009 medium comparison study published research type summarize medium comparison study problematic discus direction future research ar education research shift question lt gt lt gt ar used instruction important question lt gt lt gt lt gt lt gt learning teaching ar work right reserved elsevier,computer_aided_instruction educational_technology reviews teaching 92_primary_studies augmented_reality comparative_research methodologically_problematic_media_comparison_studies research_project research_types c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality education training human computer_interaction standards research use augmented reality ar education received lot attention recent year based many systematic review meta analysis concluded ar effective recently however researcher criticized fact empirical basis conclusion based result methodologically problematic medium comparison study however analysis literature quantitative evidence claim lacking research project research gap addressed using systematic review method total 92 primary study top 12 lt gt educational technology lt gt journal coded analyzed result show research ar education based medium comparison study 80 study compare ar another medium technology study examine learning ar effective addition result show year since 2009 medium comparison study published research type summarize medium comparison study problematic discus direction future research ar education research shift question lt gt lt gt ar used instruction important question lt gt lt gt lt gt lt gt learning teaching ar work right reserved elsevier,research use augmented reality ar education received lot attention recent year based many systematic review meta analysis concluded ar effective recently however researcher criticized fact empirical basis conclusion based result methodologically problematic medium comparison study however analysis literature quantitative evidence claim lacking research project research gap addressed using systematic review method total 92 primary study top 12 lt gt educational technology lt gt journal coded analyzed result show research ar education based medium comparison study 80 study compare ar another medium technology study examine learning ar effective addition result show year since 2009 medium comparison study published research type summarize medium comparison study problematic discus direction future research ar education research shift question lt gt lt gt ar used instruction important question lt gt lt gt lt gt lt gt learning teaching ar work right reserved elseviercomputer_aided_instruction educational_technology reviews teaching92_primary_studies augmented_reality comparative_research methodologically_problematic_media_comparison_studies research_project research_types
34,Design and Prototype Development of Augmented Reality in Reading Learning for Autism,"Khoirunnisa, A. N., Munir, & Dewi, L. (2023). Design and Prototype Development of Augmented Reality in Reading Learning for Autism. Computers, 12(3), 55. https://doi.org/10.3390/computers12030055
",10.3390/computers12030055,"(1) Background: Augmented reality is no less popular than virtual reality. This technology has begun to be used in education fields, one of which is special education. Merging the real and virtual worlds is the advantage of augmented reality. However, it needs special attention in making software for children with special needs, such as children with autism. This paper presents an application prototype by paying attention to the characteristics of autistic individuals according to the Autism Guide, that has existed in previous studies. (2) Method: The method used in the development of this prototype is the Linear Sequential Model. Application development is made using Unity3D, Vuforia, and Adobe Illustrator by considering accessibility and other conveniences for developers. (3) Results: The prototype was developed with reference to the Autism Guide, then validated by media experts and autistic experts with the results of the assessment obtaining a score of 87.3/100 which is in the ""Very Good"" category and is suitable for use. (4) Conclusions: The development of a prototype that refers to the characteristics of children with autism needs to be considered so that what will be conveyed can be easily accepted.",C7810C Computer-aided instruction;C6130V Virtual reality,Adobe illustrator;application development;application prototype;augmented reality;Autism Guide;autism needs;children;education fields;linear sequential model;reading learning;real worlds;special education;Unity3D;virtual reality;virtual worlds;Vuforia,augmented reality;computer aided instruction;medical disorders,2023,Journal article (JA),Computers (Switzerland),"(1) Khoirunnisa, A.N.; (2) Munir; (1) Dewi, L.; ","(1) Indonesia University of Education, Curriculum Development Study Program, Indonesia; (2) Indonesia University of Education, Computer Science Education Study Program, Indonesia; ",MDPI,-1,"[""computer aided instruction"", ""medical disorders""]","[""computer aided instruction"", ""medical disorders""]",computer aided instruction;medical disorders,medical;training,use cases;industries,medical;training,use cases;industries,computer_aided_instruction medical_disorders adobe_illustrator application_development application_prototype augmented_reality autism_guide autism_needs children education_fields linear_sequential_model reading_learning real_worlds special_education unity3d virtual_reality virtual_worlds vuforia c7810c_computer aided_instruction c6130v_virtual_reality medical training,computer_aided_instruction medical_disorders,adobe_illustrator application_development application_prototype augmented_reality autism_guide autism_needs children education_fields linear_sequential_model reading_learning real_worlds special_education unity3d virtual_reality virtual_worlds vuforia,1 background augmented reality le popular virtual reality technology begun used education field one special education merging real virtual world advantage augmented reality however need special attention making software child special need child autism paper present application prototype paying attention characteristic autistic individual according autism guide existed previous study 2 method method used development prototype linear sequential model application development made using unity3d vuforia adobe illustrator considering accessibility convenience developer 3 result prototype developed reference autism guide validated medium expert autistic expert result assessment obtaining score 87 3 100 good category suitable use 4 conclusion development prototype refers characteristic child autism need considered conveyed easily accepted,computer_aided_instruction medical_disorders adobe_illustrator application_development application_prototype augmented_reality autism_guide autism_needs children education_fields linear_sequential_model reading_learning real_worlds special_education unity3d virtual_reality virtual_worlds vuforia c7810c_computer aided_instruction c6130v_virtual_reality medical training 1 background augmented reality le popular virtual reality technology begun used education field one special education merging real virtual world advantage augmented reality however need special attention making software child special need child autism paper present application prototype paying attention characteristic autistic individual according autism guide existed previous study 2 method method used development prototype linear sequential model application development made using unity3d vuforia adobe illustrator considering accessibility convenience developer 3 result prototype developed reference autism guide validated medium expert autistic expert result assessment obtaining score 87 3 100 good category suitable use 4 conclusion development prototype refers characteristic child autism need considered conveyed easily accepted,1 background augmented reality le popular virtual reality technology begun used education field one special education merging real virtual world advantage augmented reality however need special attention making software child special need child autism paper present application prototype paying attention characteristic autistic individual according autism guide existed previous study 2 method method used development prototype linear sequential model application development made using unity3d vuforia adobe illustrator considering accessibility convenience developer 3 result prototype developed reference autism guide validated medium expert autistic expert result assessment obtaining score 87 3 100 good category suitable use 4 conclusion development prototype refers characteristic child autism need considered conveyed easily acceptedcomputer_aided_instruction medical_disordersadobe_illustrator application_development application_prototype augmented_reality autism_guide autism_needs children education_fields linear_sequential_model reading_learning real_worlds special_education unity3d virtual_reality virtual_worlds vuforia
35,Augmented reality to support the maintenance of urban-line infrastructures: a case study,"Revolti, A., Dallasega, P., Schulze, F., & Walder, A. (2023). Augmented Reality to support the maintenance of urban-line infrastructures: A case study. Procedia Computer Science, 217, 746–755. https://doi.org/10.1016/j.procs.2022.12.271
",10.1016/j.procs.2022.12.271,"Urban-line infrastructure projects encounter the installation of new pipe networks for water, sewage, gas, heating and their resulting maintenance operations. Often such kind of projects are characterized by inaccurate information of the layed pipes in terms of their location, geometry and type. In the literature, only a few Augmented Reality practical applications in construction have been identified. This confirms the fact that guidelines, best cases and standardized implementation models are still missing for a successful roll-out of this technology in construction. In this article, we propose a feasibility study of Augmented Reality to support the maintenance of a heat-district installation project as case study. By using a S.W.O.T. analysis, the strengths and weaknesses as well as the opportunities and threats of Augmented Reality in these contexts were investigated. Future research activities will focus to support the creation of digital models as well as to have a bi-directional information flow between AR and real construction sites. All rights reserved Elsevier.",C6130V Virtual reality;C7440 Civil and mechanical engineering computing;E1020 Maintenance and reliability;E3030 Construction industry,Augmented Reality practical applications;best cases;geometry;heat-district installation project;heating;inaccurate information;layed pipes;pipe networks;resulting maintenance operations;standardized implementation models;urban-line infrastructure projects;urban-line infrastructures,augmented reality;construction industry;maintenance engineering;pipes,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Revolti, A.; (1) Dallasega, P.; (1) Schulze, F.; (2) Walder, A.; ","(1) Free University of Bozen-Bolzano, Faculty of Science and Technology, Piazza Universita, 1, Italy; (2) Photogram, Via Angelo Custode 4, Italy; ",Elsevier B.V.,-1,"[""construction industry"", ""maintenance engineering"", ""pipes""]","[""construction industry"", ""maintenance engineering"", ""pipes""]",construction industry;maintenance engineering;pipes,construction;manufacturing,industries,construction;manufacturing,industries,construction_industry maintenance_engineering pipes augmented_reality_practical_applications best_cases geometry heat district_installation_project heating inaccurate_information layed_pipes pipe_networks resulting_maintenance_operations standardized_implementation_models urban line_infrastructure_projects urban line_infrastructures c6130v_virtual_reality c7440_civil_and_mechanical_engineering_computing e1020_maintenance_and_reliability e3030_construction_industry construction manufacturing,construction_industry maintenance_engineering pipes,augmented_reality_practical_applications best_cases geometry heat district_installation_project heating inaccurate_information layed_pipes pipe_networks resulting_maintenance_operations standardized_implementation_models urban line_infrastructure_projects urban line_infrastructures,urban line infrastructure project encounter installation new pipe network water sewage gas heating resulting maintenance operation often kind project characterized inaccurate information layed pipe term location geometry type literature augmented reality practical application construction identified confirms fact guideline best case standardized implementation model still missing successful roll technology construction article propose feasibility study augmented reality support maintenance heat district installation project case study using w analysis strength weakness well opportunity threat augmented reality context investigated future research activity focus support creation digital model well bi directional information flow ar real construction site right reserved elsevier,construction_industry maintenance_engineering pipes augmented_reality_practical_applications best_cases geometry heat district_installation_project heating inaccurate_information layed_pipes pipe_networks resulting_maintenance_operations standardized_implementation_models urban line_infrastructure_projects urban line_infrastructures c6130v_virtual_reality c7440_civil_and_mechanical_engineering_computing e1020_maintenance_and_reliability e3030_construction_industry construction manufacturing urban line infrastructure project encounter installation new pipe network water sewage gas heating resulting maintenance operation often kind project characterized inaccurate information layed pipe term location geometry type literature augmented reality practical application construction identified confirms fact guideline best case standardized implementation model still missing successful roll technology construction article propose feasibility study augmented reality support maintenance heat district installation project case study using w analysis strength weakness well opportunity threat augmented reality context investigated future research activity focus support creation digital model well bi directional information flow ar real construction site right reserved elsevier,urban line infrastructure project encounter installation new pipe network water sewage gas heating resulting maintenance operation often kind project characterized inaccurate information layed pipe term location geometry type literature augmented reality practical application construction identified confirms fact guideline best case standardized implementation model still missing successful roll technology construction article propose feasibility study augmented reality support maintenance heat district installation project case study using w analysis strength weakness well opportunity threat augmented reality context investigated future research activity focus support creation digital model well bi directional information flow ar real construction site right reserved elsevierconstruction_industry maintenance_engineering pipesaugmented_reality_practical_applications best_cases geometry heat district_installation_project heating inaccurate_information layed_pipes pipe_networks resulting_maintenance_operations standardized_implementation_models urban line_infrastructure_projects urban line_infrastructures
36,"Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence","Cao, J., Lam, K.-Y., Lee, L.-H., Liu, X., Hui, P., & Su, X. (2023). Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence. ACM Computing Surveys, 55(9), 1–36. https://doi.org/10.1145/3557999
",10.1145/3557999,"Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and perform seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences using MAR devices to provide universal access to digital content. Over the past 20 years, several MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: (1) MAR applications; (2) MAR visualisation techniques adaptive to user mobility and contexts; (3) systematic evaluation of MAR frameworks, including supported platforms and corresponding features such as tracking, feature extraction, and sensing capabilities; (4) and underlying machine learning approaches supporting intelligent operations within MAR systems. Finally, we summarise the development of emerging research fields and the current state-of-the-art and discuss the important open challenges and possible theoretical and technical directions. This survey aims to benefit both researchers and MAR system developers alike.","C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",computer-generated virtual objects;MAR devices;MAR systems support user experiences;mobile Augmented Reality;Mobile Augmented Reality;mobile devices;physical world;surveying existing MAR frameworks;user interfaces;user mobility;user-centric design,augmented reality;feature extraction;learning (artificial intelligence);mobile computing;user interfaces,2023,Journal article (JA),ACM Comput. Surv. (USA),"(1) Cao, J.; (2) Lam, K.-Y.; (3) Lee, L.-H.; (4) Liu, X.; (5) Hui, P.; (6) Su, X.; ","(1) Norwegian University of Science and Technology, Norway; (2) Hong Kong University of Science and Technology, China; (3) Korea Advanced Institute of Science and Technology, Korea, Republic of; (4) University of Helsinki, Finland; (5) University of Helsinki, Hong Kong University of Science and Technology, Finland; (6) University of Oulu, Norwegian University of Science and Technology, Finland; ",ACM,-1,"[""feature extraction"", ""learning algorithms"", ""mobile computing"", ""user interfaces""]","[""feature extraction"", ""learning algorithms"", ""mobile computing"", ""user interfaces""]",feature extraction;learning algorithms;mobile computing;user interfaces,computer vision;medical;chemical;telecommunication;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,computer vision;medical;chemical;telecommunication;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,feature_extraction learning_algorithms mobile_computing user_interfaces computer generated_virtual_objects mar_devices mar_systems_support_user_experiences mobile_augmented_reality mobile_augmented_reality mobile_devices physical_world surveying_existing_mar_frameworks user_interfaces user_mobility user centric_design c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision medical chemical telecommunication human computer_interaction artificial_intelligence,feature_extraction learning_algorithms mobile_computing user_interfaces,computer generated_virtual_objects mar_devices mar_systems_support_user_experiences mobile_augmented_reality mobile_augmented_reality mobile_devices physical_world surveying_existing_mar_frameworks user_interfaces user_mobility user centric_design,mobile augmented reality mar integrates computer generated virtual object physical environment mobile device mar system enable user interact mar device smartphones head worn wearable perform seamless transition physical world mixed world digital entity mar system support user experience using mar device provide universal access digital content past 20 year several mar system developed however study design mar framework yet systematically reviewed perspective user centric design article present first effort surveying existing mar framework count 37 discus latest study mar top approach 1 mar application 2 mar visualisation technique adaptive user mobility context 3 systematic evaluation mar framework including supported platform corresponding feature tracking feature extraction sensing capability 4 underlying machine learning approach supporting intelligent operation within mar system finally summarise development emerging research field current state art discus important open challenge possible theoretical technical direction survey aim benefit researcher mar system developer alike,feature_extraction learning_algorithms mobile_computing user_interfaces computer generated_virtual_objects mar_devices mar_systems_support_user_experiences mobile_augmented_reality mobile_augmented_reality mobile_devices physical_world surveying_existing_mar_frameworks user_interfaces user_mobility user centric_design c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision medical chemical telecommunication human computer_interaction artificial_intelligence mobile augmented reality mar integrates computer generated virtual object physical environment mobile device mar system enable user interact mar device smartphones head worn wearable perform seamless transition physical world mixed world digital entity mar system support user experience using mar device provide universal access digital content past 20 year several mar system developed however study design mar framework yet systematically reviewed perspective user centric design article present first effort surveying existing mar framework count 37 discus latest study mar top approach 1 mar application 2 mar visualisation technique adaptive user mobility context 3 systematic evaluation mar framework including supported platform corresponding feature tracking feature extraction sensing capability 4 underlying machine learning approach supporting intelligent operation within mar system finally summarise development emerging research field current state art discus important open challenge possible theoretical technical direction survey aim benefit researcher mar system developer alike,mobile augmented reality mar integrates computer generated virtual object physical environment mobile device mar system enable user interact mar device smartphones head worn wearable perform seamless transition physical world mixed world digital entity mar system support user experience using mar device provide universal access digital content past 20 year several mar system developed however study design mar framework yet systematically reviewed perspective user centric design article present first effort surveying existing mar framework count 37 discus latest study mar top approach 1 mar application 2 mar visualisation technique adaptive user mobility context 3 systematic evaluation mar framework including supported platform corresponding feature tracking feature extraction sensing capability 4 underlying machine learning approach supporting intelligent operation within mar system finally summarise development emerging research field current state art discus important open challenge possible theoretical technical direction survey aim benefit researcher mar system developer alikefeature_extraction learning_algorithms mobile_computing user_interfacescomputer generated_virtual_objects mar_devices mar_systems_support_user_experiences mobile_augmented_reality mobile_augmented_reality mobile_devices physical_world surveying_existing_mar_frameworks user_interfaces user_mobility user centric_design
37,Movement Time for Pointing Tasks in Real and Augmented Reality Environments,"Zhao, C., Li, K. W., & Peng, L. (2023). Movement Time for Pointing Tasks in Real and Augmented Reality Environments. Applied Sciences, 13(2), 788. https://doi.org/10.3390/app13020788
",10.3390/app13020788,"Human-virtual target interactions are becoming more and more common due to the emergence and application of augmented reality (AR) devices. They are different from interacting with real objects. Quantification of movement time (MT) for human-virtual target interactions is essential for AR-based interface/environment design. This study aims to investigate the motion time when people interact with virtual targets and to compare the differences in motion time between real and AR environments. An experiment was conducted to measure the MT of pointing tasks on the basis of both a physical and a virtual calculator panel. A total of 30 healthy adults, 15 male and 15 female, joined. Each participant performed pointing tasks on both physical and virtual panels with an inclined angle of the panel, hand movement direction, target key, and handedness conditions. The participants wore an AR head piece (Microsoft Hololens 2) when they pointed on the virtual panel. When pointing on the physical panel, the participants pointed on a panel drawn on board. The results showed that the type of panel, inclined angle, gender, and handedness had significant (&lt;i&gt;p&lt;/i&gt;&lt; 0.0001) effects on the MT. A new finding of this study was that the MT of the pointing task on the virtual panel was significantly (&lt;i&gt;p&lt;/i&gt;&lt; 0.0001) higher than that of the physical one. Users using a Hololens 2 AR device had inferior performance in pointing tasks than on a physical panel. A revised Fitts's model was proposed to incorporate both the physical-virtual component and inclined angle of the panel in estimating the MT. This model is novel. The index of difficulty and throughput of the pointing tasks between using the physical and virtual panels were compared and discussed. The information in this paper is beneficial to AR designers in promoting the usability of their designs so as to improve the user experience of their products.",C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6180 User interfaces,AR devices;augmented reality devices;augmented reality environments;Hololens 2 AR device;human-virtual target interactions;inclined angle;motion time;movement time;MT;physical panel;physical panels;physical-virtual component;pointing task;virtual calculator panel;virtual panel;virtual panels;virtual targets,augmented reality;human computer interaction;user experience;user interfaces,2023,Journal article (JA),Appl. Sci. (Switzerland),"(1) Zhao, C.; (2) Li, K.W.; (3) Peng, L.; ","(1) Hunan Institute of Technology, School of Safety and Management Engineering, China; (2) Chung Hua University, Department of Industrial Management, Taiwan; (3) Nanjing Agricultural University, College of Information Management, China; ",MDPI,-1,"[""human computer interaction"", ""user experience"", ""user interfaces""]","[""human computer interaction"", ""user experience"", ""user interfaces""]",human computer interaction;user experience;user interfaces,human factors;human-computer interaction,end users and user experience,human factors;human-computer interaction,end users and user experience,human_computer_interaction user_experience user_interfaces ar_devices augmented_reality_devices augmented_reality_environments hololens_2_ar_device human virtual_target_interactions inclined_angle motion_time movement_time mt physical_panel physical_panels physical virtual_component pointing_task virtual_calculator_panel virtual_panel virtual_panels virtual_targets c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces human_factors human computer_interaction,human_computer_interaction user_experience user_interfaces,ar_devices augmented_reality_devices augmented_reality_environments hololens_2_ar_device human virtual_target_interactions inclined_angle motion_time movement_time mt physical_panel physical_panels physical virtual_component pointing_task virtual_calculator_panel virtual_panel virtual_panels virtual_targets,human virtual target interaction becoming common due emergence application augmented reality ar device different interacting real object quantification movement time mt human virtual target interaction essential ar based interface environment design study aim investigate motion time people interact virtual target compare difference motion time real ar environment experiment conducted measure mt pointing task basis physical virtual calculator panel total 30 healthy adult 15 male 15 female joined participant performed pointing task physical virtual panel inclined angle panel hand movement direction target key handedness condition participant wore ar head piece microsoft hololens 2 pointed virtual panel pointing physical panel participant pointed panel drawn board result showed type panel inclined angle gender handedness significant lt gt p lt gt lt 0 0001 effect mt new finding study mt pointing task virtual panel significantly lt gt p lt gt lt 0 0001 higher physical one user using hololens 2 ar device inferior performance pointing task physical panel revised fitts model proposed incorporate physical virtual component inclined angle panel estimating mt model novel index difficulty throughput pointing task using physical virtual panel compared discussed information paper beneficial ar designer promoting usability design improve user experience product,human_computer_interaction user_experience user_interfaces ar_devices augmented_reality_devices augmented_reality_environments hololens_2_ar_device human virtual_target_interactions inclined_angle motion_time movement_time mt physical_panel physical_panels physical virtual_component pointing_task virtual_calculator_panel virtual_panel virtual_panels virtual_targets c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces human_factors human computer_interaction human virtual target interaction becoming common due emergence application augmented reality ar device different interacting real object quantification movement time mt human virtual target interaction essential ar based interface environment design study aim investigate motion time people interact virtual target compare difference motion time real ar environment experiment conducted measure mt pointing task basis physical virtual calculator panel total 30 healthy adult 15 male 15 female joined participant performed pointing task physical virtual panel inclined angle panel hand movement direction target key handedness condition participant wore ar head piece microsoft hololens 2 pointed virtual panel pointing physical panel participant pointed panel drawn board result showed type panel inclined angle gender handedness significant lt gt p lt gt lt 0 0001 effect mt new finding study mt pointing task virtual panel significantly lt gt p lt gt lt 0 0001 higher physical one user using hololens 2 ar device inferior performance pointing task physical panel revised fitts model proposed incorporate physical virtual component inclined angle panel estimating mt model novel index difficulty throughput pointing task using physical virtual panel compared discussed information paper beneficial ar designer promoting usability design improve user experience product,human virtual target interaction becoming common due emergence application augmented reality ar device different interacting real object quantification movement time mt human virtual target interaction essential ar based interface environment design study aim investigate motion time people interact virtual target compare difference motion time real ar environment experiment conducted measure mt pointing task basis physical virtual calculator panel total 30 healthy adult 15 male 15 female joined participant performed pointing task physical virtual panel inclined angle panel hand movement direction target key handedness condition participant wore ar head piece microsoft hololens 2 pointed virtual panel pointing physical panel participant pointed panel drawn board result showed type panel inclined angle gender handedness significant lt gt p lt gt lt 0 0001 effect mt new finding study mt pointing task virtual panel significantly lt gt p lt gt lt 0 0001 higher physical one user using hololens 2 ar device inferior performance pointing task physical panel revised fitts model proposed incorporate physical virtual component inclined angle panel estimating mt model novel index difficulty throughput pointing task using physical virtual panel compared discussed information paper beneficial ar designer promoting usability design improve user experience producthuman_computer_interaction user_experience user_interfacesar_devices augmented_reality_devices augmented_reality_environments hololens_2_ar_device human virtual_target_interactions inclined_angle motion_time movement_time mt physical_panel physical_panels physical virtual_component pointing_task virtual_calculator_panel virtual_panel virtual_panels virtual_targets
38,Augmented Reality-based Indoor Positioning for Smart Home Automations,"Schenkluhn, M., Peukert, C., & Weinhardt, C. (2023). Augmented Reality-based Indoor Positioning for Smart Home Automations. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585745
",10.1145/3544549.3585745,"Ambient Assisted Living (AAL) has been discussed for some time; however, many systems are not considered as interoperable or user-friendly. This fact is an even more important issue as every interaction is more costly in terms of time and effort for people with disabilities or senior citizens. Therefore, this paper examines the potential of automations that can substitute typical daily interactions in AAL or Smart Home settings in general based on the users' location. Particularly, we suggest the novel approach of using the indoor positioning capabilities of Augmented Reality (AR) head-mounted displays (HMD) to detect, track, and identify residents for the purpose of automatically controlling various Internet of Things (IoT) devices in Smart Homes. An implementation of this feature on an off-the-shelf AR HMD without additional external trackers is demonstrated and the results of an initial feasibility study are presented.","C6130V Virtual reality;C5620D Internet of Things;C6190V Mobile, ubiquitous and pervasive computing",AAL;Ambient Assisted;Augmented Reality head-mounted displays;Augmented Reality-based indoor positioning;HMD;indoor positioning capabilities;interoperable user-friendly;senior citizens;Smart Home automations;Smart Home settings;Smart Homes;typical daily interactions;users,assisted living;augmented reality;helmet mounted displays;home automation;indoor navigation;Internet of Things,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schenkluhn, M.; (2) Peukert, C.; (2) Weinhardt, C.; ","(1) Germany and Robert Bosch GmbH, Karlsruhe Institute of Technology, Germany; (2) Karlsruhe Institute of Technology, Germany; ",ACM,-1,"[""assisted living"", ""helmet mounted displays"", ""home automation"", ""indoor navigation"", ""internet of things""]","[""assisted living"", ""helmet mounted displays"", ""home automation"", ""indoor navigation"", ""internet of things""]",assisted living;helmet mounted displays;home automation;indoor navigation;internet of things,medical;display technology;internet of things;smart cities;wearables;navigation;manufacturing;networks,technology;displays;use cases;industries,medical;display technology;internet of things;smart cities;wearables;navigation;manufacturing;networks,technology;displays;use cases;industries,assisted_living helmet_mounted_displays home_automation indoor_navigation internet_of_things aal ambient_assisted augmented_reality_head mounted_displays augmented_reality based_indoor_positioning hmd indoor_positioning_capabilities interoperable_user friendly senior_citizens smart_home_automations smart_home_settings smart_homes typical_daily_interactions users c6130v_virtual_reality c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing medical display_technology internet_of_things smart_cities wearables navigation manufacturing networks,assisted_living helmet_mounted_displays home_automation indoor_navigation internet_of_things,aal ambient_assisted augmented_reality_head mounted_displays augmented_reality based_indoor_positioning hmd indoor_positioning_capabilities interoperable_user friendly senior_citizens smart_home_automations smart_home_settings smart_homes typical_daily_interactions users,ambient assisted living aal discussed time however many system considered interoperable user friendly fact even important issue every interaction costly term time effort people disability senior citizen therefore paper examines potential automation substitute typical daily interaction aal smart home setting general based user location particularly suggest novel approach using indoor positioning capability augmented reality ar head mounted display hmd detect track identify resident purpose automatically controlling various internet thing iot device smart home implementation feature shelf ar hmd without additional external tracker demonstrated result initial feasibility study presented,assisted_living helmet_mounted_displays home_automation indoor_navigation internet_of_things aal ambient_assisted augmented_reality_head mounted_displays augmented_reality based_indoor_positioning hmd indoor_positioning_capabilities interoperable_user friendly senior_citizens smart_home_automations smart_home_settings smart_homes typical_daily_interactions users c6130v_virtual_reality c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing medical display_technology internet_of_things smart_cities wearables navigation manufacturing networks ambient assisted living aal discussed time however many system considered interoperable user friendly fact even important issue every interaction costly term time effort people disability senior citizen therefore paper examines potential automation substitute typical daily interaction aal smart home setting general based user location particularly suggest novel approach using indoor positioning capability augmented reality ar head mounted display hmd detect track identify resident purpose automatically controlling various internet thing iot device smart home implementation feature shelf ar hmd without additional external tracker demonstrated result initial feasibility study presented,ambient assisted living aal discussed time however many system considered interoperable user friendly fact even important issue every interaction costly term time effort people disability senior citizen therefore paper examines potential automation substitute typical daily interaction aal smart home setting general based user location particularly suggest novel approach using indoor positioning capability augmented reality ar head mounted display hmd detect track identify resident purpose automatically controlling various internet thing iot device smart home implementation feature shelf ar hmd without additional external tracker demonstrated result initial feasibility study presentedassisted_living helmet_mounted_displays home_automation indoor_navigation internet_of_thingsaal ambient_assisted augmented_reality_head mounted_displays augmented_reality based_indoor_positioning hmd indoor_positioning_capabilities interoperable_user friendly senior_citizens smart_home_automations smart_home_settings smart_homes typical_daily_interactions users
39,Ethnomatematics learning media based on augmented reality for learning geometry: A needs analysis,"Richardo, R., Abdullah, A. A., Rochmadi, T., Wijaya, A., & Nurkhamid. (2023). Ethnomatematics learning media based on augmented reality for learning geometry: A needs analysis. THE 3RD INTERNATIONAL CONFERENCE ON SCIENCE, MATHEMATICS, ENVIRONMENT, AND EDUCATION: Flexibility in Research and Innovation on Science, Mathematics, Environment, and Education for Sustainable Development. https://doi.org/10.1063/5.0105812
",10.1063/5.0105812,"Two-dimensional and three-dimensional geometric shapes are often mathematical objects that are difficult for elementary and junior high school students to understand. Using augmented reality technology to visualize it can make it easier for students to learn geometry material. The purpose of this study was to analyze the need for developing learning media based on ethnomathematics with augmented reality. This research is quantitative research. The research subjects were 40 mathematics teachers in Yogyakarta, Indonesia. Subject determination techniques using cluster random sampling in 5 districts in Yogyakarta Province. Research data were collected by giving questionnaires to respondents. The results of this study indicate (1) most of the teachers found that their students had difficulty in learning geometry material; (2) most mathematics teachers rarely use culture as a learning context; (3) all mathematics teachers have never used ethnomathematics-based Augmented reality-assisted learning media; (4) all mathematics teachers are in dire need of learning multimedia innovations to teach geometry material, such as augmented reality; and (5) the development of ethnomathematical AR multimedia based on geometry material can be a solution to create an innovation in mathematics learning that can facilitate students in learning, so as to improve mathematical abilities, make learning more meaningful, and can increase student self-regulated learning during the pandemic.",C7810C Computer-aided instruction;C6130B Graphics techniques;C6130M Multimedia;C6130V Virtual reality;C7310 Mathematics computing,augmented reality technology;determination techniques;elementary school students;ethnomathematical AR multimedia;ethnomathematics-based augmented reality-assisted learning media;junior high school students;learning geometry material;learning multimedia innovations;mathematical objects;mathematics learning;mathematics teachers;student self-regulated learning;three-dimensional geometric shapes;two-dimensional geometric shapes,augmented reality;computational geometry;computer aided instruction;educational institutions;mathematics computing;multimedia computing;teaching,2023,Conference article (CA),AIP Conf. Proc. (USA),"(1) Richardo, R.; (1) Abdullah, A.A.; (2) Rochmadi, T.; (3) Wijaya, A.; (4) Nurkhamid; ","(1) Universitas Alma Ata, Department of Mathematics Education, Indonesia; (2) Universitas Alma Ata, Department of Information System, Indonesia; (3) Universitas Negeri Yogyakarta, Department of Mathematics Education, Indonesia; (4) Universitas Negeri Yogyakarta, Department of Informatics Engineering Education, Indonesia; ",AIP Publishing,-1,"[""computational geometry"", ""computer aided instruction"", ""educational institutions"", ""mathematics computing"", ""multimedia computing"", ""teaching""]","[""computational geometry"", ""computer aided instruction"", ""educational institutions"", ""mathematics computing"", ""multimedia computing"", ""teaching""]",computational geometry;computer aided instruction;educational institutions;mathematics computing;multimedia computing;teaching,education;graphics;training;engineering;artificial intelligence,technology;use cases;industries,education;graphics;training;engineering;artificial intelligence,technology;use cases;industries,computational_geometry computer_aided_instruction educational_institutions mathematics_computing multimedia_computing teaching augmented_reality_technology determination_techniques elementary_school_students ethnomathematical_ar_multimedia ethnomathematics based_augmented_reality assisted_learning_media junior_high_school_students learning_geometry_material learning_multimedia_innovations mathematical_objects mathematics_learning mathematics_teachers student_self regulated_learning three dimensional_geometric_shapes two dimensional_geometric_shapes c7810c_computer aided_instruction c6130b_graphics_techniques c6130m_multimedia c6130v_virtual_reality c7310_mathematics_computing education graphics training engineering artificial_intelligence,computational_geometry computer_aided_instruction educational_institutions mathematics_computing multimedia_computing teaching,augmented_reality_technology determination_techniques elementary_school_students ethnomathematical_ar_multimedia ethnomathematics based_augmented_reality assisted_learning_media junior_high_school_students learning_geometry_material learning_multimedia_innovations mathematical_objects mathematics_learning mathematics_teachers student_self regulated_learning three dimensional_geometric_shapes two dimensional_geometric_shapes,two dimensional three dimensional geometric shape often mathematical object difficult elementary junior high school student understand using augmented reality technology visualize make easier student learn geometry material purpose study analyze need developing learning medium based ethnomathematics augmented reality research quantitative research research subject 40 mathematics teacher yogyakarta indonesia subject determination technique using cluster random sampling 5 district yogyakarta province research data collected giving questionnaire respondent result study indicate 1 teacher found student difficulty learning geometry material 2 mathematics teacher rarely use culture learning context 3 mathematics teacher never used ethnomathematics based augmented reality assisted learning medium 4 mathematics teacher dire need learning multimedia innovation teach geometry material augmented reality 5 development ethnomathematical ar multimedia based geometry material solution create innovation mathematics learning facilitate student learning improve mathematical ability make learning meaningful increase student self regulated learning pandemic,computational_geometry computer_aided_instruction educational_institutions mathematics_computing multimedia_computing teaching augmented_reality_technology determination_techniques elementary_school_students ethnomathematical_ar_multimedia ethnomathematics based_augmented_reality assisted_learning_media junior_high_school_students learning_geometry_material learning_multimedia_innovations mathematical_objects mathematics_learning mathematics_teachers student_self regulated_learning three dimensional_geometric_shapes two dimensional_geometric_shapes c7810c_computer aided_instruction c6130b_graphics_techniques c6130m_multimedia c6130v_virtual_reality c7310_mathematics_computing education graphics training engineering artificial_intelligence two dimensional three dimensional geometric shape often mathematical object difficult elementary junior high school student understand using augmented reality technology visualize make easier student learn geometry material purpose study analyze need developing learning medium based ethnomathematics augmented reality research quantitative research research subject 40 mathematics teacher yogyakarta indonesia subject determination technique using cluster random sampling 5 district yogyakarta province research data collected giving questionnaire respondent result study indicate 1 teacher found student difficulty learning geometry material 2 mathematics teacher rarely use culture learning context 3 mathematics teacher never used ethnomathematics based augmented reality assisted learning medium 4 mathematics teacher dire need learning multimedia innovation teach geometry material augmented reality 5 development ethnomathematical ar multimedia based geometry material solution create innovation mathematics learning facilitate student learning improve mathematical ability make learning meaningful increase student self regulated learning pandemic,two dimensional three dimensional geometric shape often mathematical object difficult elementary junior high school student understand using augmented reality technology visualize make easier student learn geometry material purpose study analyze need developing learning medium based ethnomathematics augmented reality research quantitative research research subject 40 mathematics teacher yogyakarta indonesia subject determination technique using cluster random sampling 5 district yogyakarta province research data collected giving questionnaire respondent result study indicate 1 teacher found student difficulty learning geometry material 2 mathematics teacher rarely use culture learning context 3 mathematics teacher never used ethnomathematics based augmented reality assisted learning medium 4 mathematics teacher dire need learning multimedia innovation teach geometry material augmented reality 5 development ethnomathematical ar multimedia based geometry material solution create innovation mathematics learning facilitate student learning improve mathematical ability make learning meaningful increase student self regulated learning pandemiccomputational_geometry computer_aided_instruction educational_institutions mathematics_computing multimedia_computing teachingaugmented_reality_technology determination_techniques elementary_school_students ethnomathematical_ar_multimedia ethnomathematics based_augmented_reality assisted_learning_media junior_high_school_students learning_geometry_material learning_multimedia_innovations mathematical_objects mathematics_learning mathematics_teachers student_self regulated_learning three dimensional_geometric_shapes two dimensional_geometric_shapes
40,Meta-analysis of augmented reality marketing,"Kumar, H., Gupta, P., & Chauhan, S. (2022). Meta-analysis of augmented reality marketing. Marketing Intelligence &amp; Planning, 41(1), 110–123. https://doi.org/10.1108/mip-06-2022-0221
",10.1108/MIP-06-2022-0221,"&lt;b&gt;Purpose &lt;/b&gt;Amidst the ambiguity about the impact of augmented reality (AR) attributes on hedonic or utilitarian values, the present study aims to understand what AR attributes create hedonic and utilitarian values and how their interaction determines consumers' behavioral intention. &lt;b&gt;Design/methodology/approach &lt;/b&gt;The study synthesizes the results of 19 quantitative studies on AR marketing by using the meta-analysis technique. &lt;b&gt;Findings &lt;/b&gt;The findings reveal that interactivity and augmentation are salient AR attributes that offer users both hedonic and utilitarian values. They are instrumental in fostering users' behavioral intention. However, interactivity does not have any direct influence on the behavioral intentions. &lt;b&gt;Originality/value &lt;/b&gt;Being one of the first meta-analyses on AR marketing; theoretically, it synthesizes the statistical data of the state of art literature on AR marketing. The results of the study would allow AR practitioners to decide on their AR marketing related activities in a better way.",C7170 Marketing computing;C6130V Virtual reality,AR marketing related activities;augmented reality marketing;behavioral intentions;consumers;hedonic values;meta-analyses;meta-analysis technique;quantitative studies;utilitarian values,augmented reality;consumer behaviour;organisational aspects;statistical analysis,2023,Journal article (JA),Mark. Intell. Plan. (UK),"(1) Kumar, H.; (2) Gupta, P.; (3) Chauhan, S.; ","(1) Management Development Institute Gurgaon, Department of Marketing, India; (2) Management Development Institute Gurgaon, India; (3) O.P. Jindal Global University, Jindal Global Business School, India; ",Emerald,-1,"[""consumer behaviour"", ""organisational aspects"", ""statistical analysis""]","[""consumer behaviour"", ""organisational aspects"", ""statistical analysis""]",consumer behaviour;organisational aspects;statistical analysis,sales and marketing;data;business planning and management,technology;business,sales and marketing;data;business planning and management,technology;business,consumer_behaviour organisational_aspects statistical_analysis ar_marketing_related_activities augmented_reality_marketing behavioral_intentions consumers hedonic_values meta analyses meta analysis_technique quantitative_studies utilitarian_values c7170_marketing_computing c6130v_virtual_reality sales_and_marketing data business_planning_and_management,consumer_behaviour organisational_aspects statistical_analysis,ar_marketing_related_activities augmented_reality_marketing behavioral_intentions consumers hedonic_values meta analyses meta analysis_technique quantitative_studies utilitarian_values,lt b gt purpose lt b gt amidst ambiguity impact augmented reality ar attribute hedonic utilitarian value present study aim understand ar attribute create hedonic utilitarian value interaction determines consumer behavioral intention lt b gt design methodology approach lt b gt study synthesizes result 19 quantitative study ar marketing using meta analysis technique lt b gt finding lt b gt finding reveal interactivity augmentation salient ar attribute offer user hedonic utilitarian value instrumental fostering user behavioral intention however interactivity direct influence behavioral intention lt b gt originality value lt b gt one first meta analysis ar marketing theoretically synthesizes statistical data state art literature ar marketing result study would allow ar practitioner decide ar marketing related activity better way,consumer_behaviour organisational_aspects statistical_analysis ar_marketing_related_activities augmented_reality_marketing behavioral_intentions consumers hedonic_values meta analyses meta analysis_technique quantitative_studies utilitarian_values c7170_marketing_computing c6130v_virtual_reality sales_and_marketing data business_planning_and_management lt b gt purpose lt b gt amidst ambiguity impact augmented reality ar attribute hedonic utilitarian value present study aim understand ar attribute create hedonic utilitarian value interaction determines consumer behavioral intention lt b gt design methodology approach lt b gt study synthesizes result 19 quantitative study ar marketing using meta analysis technique lt b gt finding lt b gt finding reveal interactivity augmentation salient ar attribute offer user hedonic utilitarian value instrumental fostering user behavioral intention however interactivity direct influence behavioral intention lt b gt originality value lt b gt one first meta analysis ar marketing theoretically synthesizes statistical data state art literature ar marketing result study would allow ar practitioner decide ar marketing related activity better way,lt b gt purpose lt b gt amidst ambiguity impact augmented reality ar attribute hedonic utilitarian value present study aim understand ar attribute create hedonic utilitarian value interaction determines consumer behavioral intention lt b gt design methodology approach lt b gt study synthesizes result 19 quantitative study ar marketing using meta analysis technique lt b gt finding lt b gt finding reveal interactivity augmentation salient ar attribute offer user hedonic utilitarian value instrumental fostering user behavioral intention however interactivity direct influence behavioral intention lt b gt originality value lt b gt one first meta analysis ar marketing theoretically synthesizes statistical data state art literature ar marketing result study would allow ar practitioner decide ar marketing related activity better wayconsumer_behaviour organisational_aspects statistical_analysisar_marketing_related_activities augmented_reality_marketing behavioral_intentions consumers hedonic_values meta analyses meta analysis_technique quantitative_studies utilitarian_values
41,A New Architecture of Augmented Reality Engine,"Xu, Z., Wu, S., & Zhang, L. (2023). A New Architecture of Augmented Reality Engine. 2023 2nd International Conference on Mechatronics and Electrical Engineering (MEEE). https://doi.org/10.1109/meee57080.2023.10127071
",10.1109/MEEE57080.2023.10127071,"Augmented reality (AR) technology has been a rapidly developing research hotspot in the past ten years. AR combines computer-generated virtual scenes with the real world to achieve sensory enhancements beyond reality. As the middleware between the operating system layer and the application layer, the AR engine is a platform-based underlying technology and the cornerstone of building an augmented reality ecosystem. In this paper, a new AR engine architecture is proposed, and the core modules such as architecture composition, data management, algorithm integration, and multi-platform support interfaces are described in detail. Also, Nanhu AR engine (NHAR) is developed based on the new architecture. And an application is developed using NHAR to test marker-based tracking and marker-less tracking function of the developed engine.",C6130V Virtual reality;C6150J Operating systems;C6190Z Other distributed systems software,application layer;AR engine architecture;architecture composition;augmented reality engine;computer-generated virtual scenes;marker-based tracking;marker-less tracking function;multiplatform support interfaces;Nanhu AR engine;operating system layer;platform-based underlying technology;sensory enhancements,augmented reality;middleware;operating systems (computers),2023,Conference article (CA),2023 2nd International Conference on Mechatronics and Electrical Engineering (MEEE),"(1) Xu, Z.; (1) Wu, S.; (1) Zhang, L.; ","(1) China Nanhu Academy of Electronics and Information Technology(CNAEIT), Augmented Reality Laboratory, China; ",IEEE,-1,"[""middleware"", ""operating systems""]","[""middleware"", ""operating systems""]",middleware;operating systems,education;developers,technology;industries,education;developers,technology;industries,middleware operating_systems application_layer ar_engine_architecture architecture_composition augmented_reality_engine computer generated_virtual_scenes marker based_tracking marker less_tracking_function multiplatform_support_interfaces nanhu_ar_engine operating_system_layer platform based_underlying_technology sensory_enhancements c6130v_virtual_reality c6150j_operating_systems c6190z_other_distributed_systems_software education developers,middleware operating_systems,application_layer ar_engine_architecture architecture_composition augmented_reality_engine computer generated_virtual_scenes marker based_tracking marker less_tracking_function multiplatform_support_interfaces nanhu_ar_engine operating_system_layer platform based_underlying_technology sensory_enhancements,augmented reality ar technology rapidly developing research hotspot past ten year ar combine computer generated virtual scene real world achieve sensory enhancement beyond reality middleware operating system layer application layer ar engine platform based underlying technology cornerstone building augmented reality ecosystem paper new ar engine architecture proposed core module architecture composition data management algorithm integration multi platform support interface described detail also nanhu ar engine nhar developed based new architecture application developed using nhar test marker based tracking marker le tracking function developed engine,middleware operating_systems application_layer ar_engine_architecture architecture_composition augmented_reality_engine computer generated_virtual_scenes marker based_tracking marker less_tracking_function multiplatform_support_interfaces nanhu_ar_engine operating_system_layer platform based_underlying_technology sensory_enhancements c6130v_virtual_reality c6150j_operating_systems c6190z_other_distributed_systems_software education developers augmented reality ar technology rapidly developing research hotspot past ten year ar combine computer generated virtual scene real world achieve sensory enhancement beyond reality middleware operating system layer application layer ar engine platform based underlying technology cornerstone building augmented reality ecosystem paper new ar engine architecture proposed core module architecture composition data management algorithm integration multi platform support interface described detail also nanhu ar engine nhar developed based new architecture application developed using nhar test marker based tracking marker le tracking function developed engine,augmented reality ar technology rapidly developing research hotspot past ten year ar combine computer generated virtual scene real world achieve sensory enhancement beyond reality middleware operating system layer application layer ar engine platform based underlying technology cornerstone building augmented reality ecosystem paper new ar engine architecture proposed core module architecture composition data management algorithm integration multi platform support interface described detail also nanhu ar engine nhar developed based new architecture application developed using nhar test marker based tracking marker le tracking function developed enginemiddleware operating_systemsapplication_layer ar_engine_architecture architecture_composition augmented_reality_engine computer generated_virtual_scenes marker based_tracking marker less_tracking_function multiplatform_support_interfaces nanhu_ar_engine operating_system_layer platform based_underlying_technology sensory_enhancements
42,"""In Your Face!"": Visualizing Fitness Tracker Data in Augmented Reality","Rigling, S., Yu, X., & Sedlmair, M. (2023). “In Your Face!”: Visualizing Fitness Tracker Data in Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585912
",10.1145/3544549.3585912,"The benefits of augmented reality (AR) have been demonstrated in both medicine and fitness, while its application in areas where these two fields overlap has been barely explored. We argue that AR opens up new opportunities to interact with, understand and share personal health data. To this end, we developed an app prototype that uses a Snapchat-like face filter to visualize personal health data from a fitness tracker in AR. We tested this prototype in two pilot studies and found that AR does have potential in this type of application. We suggest that AR cannot replace the current interfaces of smartwatches and mobile apps, but it can pick up where current technology falls short in creating intrinsic motivation and personal health awareness. We also provide ideas for future work in this direction.","C7330 Biology and medical computing;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",augmented reality;fitness tracker data;intrinsic motivation;mobile apps;personal health awareness;personal health data;Snapchat-like face filter,augmented reality;data visualisation;health care;medical computing;mobile computing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(None) Rigling, S.; (None) Yu, X.; (None) Sedlmair, M.; ",,ACM,-1,"[""data visualization"", ""health care"", ""medical computing"", ""mobile computing""]","[""data visualization"", ""health care"", ""medical computing"", ""mobile computing""]",data visualization;health care;medical computing;mobile computing,medical;telecommunication;data,technology;industries,medical;telecommunication;data,technology;industries,data_visualization health_care medical_computing mobile_computing augmented_reality fitness_tracker_data intrinsic_motivation mobile_apps personal_health_awareness personal_health_data snapchat like_face_filter c7330_biology_and_medical_computing c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing medical telecommunication data,data_visualization health_care medical_computing mobile_computing,augmented_reality fitness_tracker_data intrinsic_motivation mobile_apps personal_health_awareness personal_health_data snapchat like_face_filter,benefit augmented reality ar demonstrated medicine fitness application area two field overlap barely explored argue ar open new opportunity interact understand share personal health data end developed app prototype us snapchat like face filter visualize personal health data fitness tracker ar tested prototype two pilot study found ar potential type application suggest ar cannot replace current interface smartwatches mobile apps pick current technology fall short creating intrinsic motivation personal health awareness also provide idea future work direction,data_visualization health_care medical_computing mobile_computing augmented_reality fitness_tracker_data intrinsic_motivation mobile_apps personal_health_awareness personal_health_data snapchat like_face_filter c7330_biology_and_medical_computing c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing medical telecommunication data benefit augmented reality ar demonstrated medicine fitness application area two field overlap barely explored argue ar open new opportunity interact understand share personal health data end developed app prototype us snapchat like face filter visualize personal health data fitness tracker ar tested prototype two pilot study found ar potential type application suggest ar cannot replace current interface smartwatches mobile apps pick current technology fall short creating intrinsic motivation personal health awareness also provide idea future work direction,benefit augmented reality ar demonstrated medicine fitness application area two field overlap barely explored argue ar open new opportunity interact understand share personal health data end developed app prototype us snapchat like face filter visualize personal health data fitness tracker ar tested prototype two pilot study found ar potential type application suggest ar cannot replace current interface smartwatches mobile apps pick current technology fall short creating intrinsic motivation personal health awareness also provide idea future work directiondata_visualization health_care medical_computing mobile_computingaugmented_reality fitness_tracker_data intrinsic_motivation mobile_apps personal_health_awareness personal_health_data snapchat like_face_filter
43,HoloLens augmented reality system for transperineal free-hand prostate procedures,"Li, M., Mehralivand, S., Xu, S., Varble, N., Bakhutashvili, I., Gurram, S., Pinto, P. A., Choyke, P. L., Wood, B. J., & Turkbey, B. (2023). HoloLens augmented reality system for transperineal free-hand prostate procedures. Journal of Medical Imaging, 10(02). https://doi.org/10.1117/1.jmi.10.2.025001
",10.1117/1.JMI.10.2.025001,"Purpose: An augmented reality (AR) system was developed to facilitate free-hand real-time needle guidance for transperineal prostate (TP) procedures and to overcome the limitations of a traditional guidance grid. Approach: The HoloLens AR system enables the superimposition of annotated anatomy derived from preprocedural volumetric images onto a patient and addresses the most challenging part of free-hand TP procedures by providing real-time needle tip localization and needle depth visualization during insertion. The AR system accuracy, or the image overlay accuracy (n = 56), and needle targeting accuracy (n = 24) were evaluated within a 3D-printed phantom. Three operators each used a planned-path guidance method (n = 4) and free-hand guidance (n = 4) to guide needles into targets in a gel phantom. Placement error was recorded. The feasibility of the system was further evaluated by delivering soft tissue markers into tumors of an anthropomorphic pelvic phantom via the perineum. Results: The image overlay error was 1.29 &plusmn; 0.57 mm, and needle targeting error was 2.13 &plusmn; 0.52 mm. The planned-path guidance placements showed similar error compared to the free-hand guidance (4.14 &plusmn; 1.08 mm versus 4.20 &plusmn; 1.08 mm, p = 0.90). The markers were successfully implanted either into or in close proximity to the target lesion. Conclusions: The HoloLens AR system can provide accurate needle guidance for TP interventions. AR support for free-hand lesion targeting is feasible and may provide more flexibility than grid-based methods, due to the real-time 3D and immersive experience during free-hand TP procedures. &copy; 2023 Published by SPIE.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;723 Computer Software, Data Handling and Applications;746 Imaging Techniques",Augmented reality systems;Hololens guidancemedical imaging;Image overlay;Interventional radiology;Needle guidance;Path guidance;Percutaneous procedure;Planned paths;Real- time;Transperineal prostate procedure,Augmented reality;Errors;Medical imaging;Phantoms;Urology,2023,Journal article (JA),J. Med. Imaging,"(1) Li, Ming; (2) Mehralivand, Sherif; (1) Xu, Sheng; (1) Varble, Nicole; (1) Bakhutashvili, Ivane; (4) Gurram, Sandeep; (4) Pinto, Peter A.; (2) Choyke, Peter L.; (1) Wood, Bradford J.; (2) Turkbey, Baris; ","(1) National Institutes of Health, Center for Interventional Oncology, Radiology and Imaging Sciences, Clinical Center, Bethesda; MD, United States; (2) National Institutes of Health, Molecular Imaging Branch, National Cancer Institute, Bethesda; MD, United States; (3) Philips Research of North America, Cambridge; MA, United States; (4) National Institutes of Health, Urologic Oncology Branch, National Cancer Institute, Bethesda; MD, United States; ",SPIE,-1,"[""errors"", ""medical imaging"", ""phantoms"", ""urology""]","[""errors"", ""medical imaging"", ""phantoms"", ""urology""]",errors;medical imaging;phantoms;urology,medical;human factors,industries;end users and user experience,medical;human factors,industries;end users and user experience,errors medical_imaging phantoms urology augmented_reality_systems hololens_guidancemedical_imaging image_overlay interventional_radiology needle_guidance path_guidance percutaneous_procedure planned_paths real _time transperineal_prostate_procedure 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 746_imaging_techniques medical human_factors,errors medical_imaging phantoms urology,augmented_reality_systems hololens_guidancemedical_imaging image_overlay interventional_radiology needle_guidance path_guidance percutaneous_procedure planned_paths real _time transperineal_prostate_procedure,purpose augmented reality ar system developed facilitate free hand real time needle guidance transperineal prostate tp procedure overcome limitation traditional guidance grid approach hololens ar system enables superimposition annotated anatomy derived preprocedural volumetric image onto patient address challenging part free hand tp procedure providing real time needle tip localization needle depth visualization insertion ar system accuracy image overlay accuracy n 56 needle targeting accuracy n 24 evaluated within 3d printed phantom three operator used planned path guidance method n 4 free hand guidance n 4 guide needle target gel phantom placement error recorded feasibility system evaluated delivering soft tissue marker tumor anthropomorphic pelvic phantom via perineum result image overlay error 1 29 plusmn 0 57 mm needle targeting error 2 13 plusmn 0 52 mm planned path guidance placement showed similar error compared free hand guidance 4 14 plusmn 1 08 mm versus 4 20 plusmn 1 08 mm p 0 90 marker successfully implanted either close proximity target lesion conclusion hololens ar system provide accurate needle guidance tp intervention ar support free hand lesion targeting feasible may provide flexibility grid based method due real time 3d immersive experience free hand tp procedure copy 2023 published spie,errors medical_imaging phantoms urology augmented_reality_systems hololens_guidancemedical_imaging image_overlay interventional_radiology needle_guidance path_guidance percutaneous_procedure planned_paths real _time transperineal_prostate_procedure 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 746_imaging_techniques medical human_factors purpose augmented reality ar system developed facilitate free hand real time needle guidance transperineal prostate tp procedure overcome limitation traditional guidance grid approach hololens ar system enables superimposition annotated anatomy derived preprocedural volumetric image onto patient address challenging part free hand tp procedure providing real time needle tip localization needle depth visualization insertion ar system accuracy image overlay accuracy n 56 needle targeting accuracy n 24 evaluated within 3d printed phantom three operator used planned path guidance method n 4 free hand guidance n 4 guide needle target gel phantom placement error recorded feasibility system evaluated delivering soft tissue marker tumor anthropomorphic pelvic phantom via perineum result image overlay error 1 29 plusmn 0 57 mm needle targeting error 2 13 plusmn 0 52 mm planned path guidance placement showed similar error compared free hand guidance 4 14 plusmn 1 08 mm versus 4 20 plusmn 1 08 mm p 0 90 marker successfully implanted either close proximity target lesion conclusion hololens ar system provide accurate needle guidance tp intervention ar support free hand lesion targeting feasible may provide flexibility grid based method due real time 3d immersive experience free hand tp procedure copy 2023 published spie,purpose augmented reality ar system developed facilitate free hand real time needle guidance transperineal prostate tp procedure overcome limitation traditional guidance grid approach hololens ar system enables superimposition annotated anatomy derived preprocedural volumetric image onto patient address challenging part free hand tp procedure providing real time needle tip localization needle depth visualization insertion ar system accuracy image overlay accuracy n 56 needle targeting accuracy n 24 evaluated within 3d printed phantom three operator used planned path guidance method n 4 free hand guidance n 4 guide needle target gel phantom placement error recorded feasibility system evaluated delivering soft tissue marker tumor anthropomorphic pelvic phantom via perineum result image overlay error 1 29 plusmn 0 57 mm needle targeting error 2 13 plusmn 0 52 mm planned path guidance placement showed similar error compared free hand guidance 4 14 plusmn 1 08 mm versus 4 20 plusmn 1 08 mm p 0 90 marker successfully implanted either close proximity target lesion conclusion hololens ar system provide accurate needle guidance tp intervention ar support free hand lesion targeting feasible may provide flexibility grid based method due real time 3d immersive experience free hand tp procedure copy 2023 published spieerrors medical_imaging phantoms urologyaugmented_reality_systems hololens_guidancemedical_imaging image_overlay interventional_radiology needle_guidance path_guidance percutaneous_procedure planned_paths real _time transperineal_prostate_procedure
44,The Effect of Virtual Reality and Augmented Reality on Managing Projects,"Khatib, Dr. M. E., Al Falasi, F., Anani, H. A., & Shurrab, W. (2023). The Effect of Virtual Reality and Augmented Reality on Managing Projects. 2023 International Conference on Business Analytics for Technology and Security (ICBATS). https://doi.org/10.1109/icbats57792.2023.10111112
",10.1109/ICBATS57792.2023.10111112,"This report highlights how digital disruption and transformation have affected project management. Amazon was selected as the organization, and project management was chosen as the industry. Primary research-based open-end interviews with thirty project managers and secondary research based on a review of past literature were conducted to perform this study. It was found that digital disruption has occurred in the project management industry, which has modified the behaviors, needs, and expectations of people in society, the market, and the industry. It was found that virtual reality (VR) and augmented reality (AR) has disrupted the project management industry. The AR caused a shift in the consumer (sponsor/client) wants in the project management industry. Customer derives the demand want from. Therefore the businesses and their competitors' activities are modified to adapt the AR and VR-based technologies. AR and VR reduced the project managers' efforts, time, and resources. Moreover, the metaverse is another technology that will cause significant digital disruption and digital transformation in the project management industry.",C7100 Business and administrative computing;C6130V Virtual reality,Amazon;AR;augmented reality;business activities;competitor activities;consumer wants;digital disruption;digital transformation;metaverse;organization;project management industry;virtual reality;VR,augmented reality;business data processing;organisational aspects;project management,2023,Conference article (CA),2023 International Conference on Business Analytics for Technology and Security (ICBATS),"(1) Khatib, M.E.; (1) Al Falasi, F.; (1) Anani, H.A.; (1) Shurrab, W.; ","(1) Hamdan Bin Mohammed Smart University, School of Business & Quality Management, United Arab Emirates; ",IEEE,-1,"[""business data processing"", ""organisational aspects"", ""project management""]","[""business data processing"", ""organisational aspects"", ""project management""]",business data processing;organisational aspects;project management,data;business planning and management;business performance metrics,technology;business,data;business planning and management;business performance metrics,technology;business,business_data_processing organisational_aspects project_management amazon ar augmented_reality business_activities competitor_activities consumer_wants digital_disruption digital_transformation metaverse organization project_management_industry virtual_reality vr c7100_business_and_administrative_computing c6130v_virtual_reality data business_planning_and_management business_performance_metrics,business_data_processing organisational_aspects project_management,amazon ar augmented_reality business_activities competitor_activities consumer_wants digital_disruption digital_transformation metaverse organization project_management_industry virtual_reality vr,report highlight digital disruption transformation affected project management amazon selected organization project management chosen industry primary research based open end interview thirty project manager secondary research based review past literature conducted perform study found digital disruption occurred project management industry modified behavior need expectation people society market industry found virtual reality vr augmented reality ar disrupted project management industry ar caused shift consumer sponsor client want project management industry customer derives demand want therefore business competitor activity modified adapt ar vr based technology ar vr reduced project manager effort time resource moreover metaverse another technology cause significant digital disruption digital transformation project management industry,business_data_processing organisational_aspects project_management amazon ar augmented_reality business_activities competitor_activities consumer_wants digital_disruption digital_transformation metaverse organization project_management_industry virtual_reality vr c7100_business_and_administrative_computing c6130v_virtual_reality data business_planning_and_management business_performance_metrics report highlight digital disruption transformation affected project management amazon selected organization project management chosen industry primary research based open end interview thirty project manager secondary research based review past literature conducted perform study found digital disruption occurred project management industry modified behavior need expectation people society market industry found virtual reality vr augmented reality ar disrupted project management industry ar caused shift consumer sponsor client want project management industry customer derives demand want therefore business competitor activity modified adapt ar vr based technology ar vr reduced project manager effort time resource moreover metaverse another technology cause significant digital disruption digital transformation project management industry,report highlight digital disruption transformation affected project management amazon selected organization project management chosen industry primary research based open end interview thirty project manager secondary research based review past literature conducted perform study found digital disruption occurred project management industry modified behavior need expectation people society market industry found virtual reality vr augmented reality ar disrupted project management industry ar caused shift consumer sponsor client want project management industry customer derives demand want therefore business competitor activity modified adapt ar vr based technology ar vr reduced project manager effort time resource moreover metaverse another technology cause significant digital disruption digital transformation project management industrybusiness_data_processing organisational_aspects project_managementamazon ar augmented_reality business_activities competitor_activities consumer_wants digital_disruption digital_transformation metaverse organization project_management_industry virtual_reality vr
45,Representing Augmented Reality Applications in Systems Modeling Language,"Aoki, E., Tran, B., Tran, V., Soth, K., Thompson, C., Tripathy, S., Chandra, K., & Sastry, S. (2023). Representing Augmented Reality Applications in Systems Modeling Language. 2023 IEEE International Systems Conference (SysCon). https://doi.org/10.1109/syscon53073.2023.10131060
",10.1109/SysCon53073.2023.10131060,"Augmented Reality (AR) devices offer novel capabilities that can be exploited in AR systems to positively impact human-machine interactions in a variety of future-work and education contexts. This paper presents a systems model for a no-code AR systems framework that can be used to create AR applications that present just-in-time informatics to assist and guide users in the completion of complex task sequences while ensuring operator and environment safety. The salient structural and behavioral aspects of the system, and key use cases are modeled using the Systems Modeling Language (SysML). Representative examples of the model are presented using use case, block definition, internal block, activity, and state-machine diagrams. These models offer new insights into how AR capabilities can be integrated with a variety of engineered systems. In the future such SysML models can steer the design of new tools and an ontology to strengthen connections to domain knowledge.",C6130V Virtual reality;C6110F Formal methods;C6140D High level languages;C7480 Production engineering computing;E0410D Industrial applications of IT,Augmented Reality devices;behavioral aspects;education contexts;engineered systems;future-work;human-machine interactions;no-code AR systems framework;representing augmented Reality applications;salient structural aspects;systems model;Systems Modeling Language,augmented reality;human computer interaction;ontologies (artificial intelligence);production engineering computing;SysML;Unified Modeling Language,2023,Conference article (CA),2023 IEEE International Systems Conference (SysCon),"(1) Aoki, E.; (2) Tran, B.; (1) Tran, V.; (1) Soth, K.; (1) Thompson, C.; (3) Tripathy, S.; (1) Chandra, K.; (2) Sastry, S.; ","(1) University of Massachusetts Lowell, Department of Electrical & Computer Engineering, Lowell, MA 1854, United States; (2) University of Akron, Department of Electrical and Computer Engineering, Akron, OH 44325, United States; (3) University of Massachusetts Lowell, Department of Sociology, Lowell, MA 1854, United States; ",IEEE,-1,"[""human computer interaction"", ""ontology"", ""production engineering computing"", ""sysml"", ""unified modeling language""]","[""human computer interaction"", ""ontology"", ""production engineering computing"", ""sysml"", ""unified modeling language""]",human computer interaction;ontology;production engineering computing;sysml;unified modeling language,other;engineering;human-computer interaction;web services;manufacturing,technology;other;industries;end users and user experience,other;engineering;human-computer interaction;web services;manufacturing,technology;other;industries;end users and user experience,human_computer_interaction ontology production_engineering_computing sysml unified_modeling_language augmented_reality_devices behavioral_aspects education_contexts engineered_systems future work human machine_interactions no code_ar_systems_framework representing_augmented_reality_applications salient_structural_aspects systems_model systems_modeling_language c6130v_virtual_reality c6110f_formal_methods c6140d_high_level_languages c7480_production_engineering_computing e0410d_industrial_applications_of_it other engineering human computer_interaction web_services manufacturing,human_computer_interaction ontology production_engineering_computing sysml unified_modeling_language,augmented_reality_devices behavioral_aspects education_contexts engineered_systems future work human machine_interactions no code_ar_systems_framework representing_augmented_reality_applications salient_structural_aspects systems_model systems_modeling_language,augmented reality ar device offer novel capability exploited ar system positively impact human machine interaction variety future work education context paper present system model code ar system framework used create ar application present time informatics assist guide user completion complex task sequence ensuring operator environment safety salient structural behavioral aspect system key use case modeled using system modeling language sysml representative example model presented using use case block definition internal block activity state machine diagram model offer new insight ar capability integrated variety engineered system future sysml model steer design new tool ontology strengthen connection domain knowledge,human_computer_interaction ontology production_engineering_computing sysml unified_modeling_language augmented_reality_devices behavioral_aspects education_contexts engineered_systems future work human machine_interactions no code_ar_systems_framework representing_augmented_reality_applications salient_structural_aspects systems_model systems_modeling_language c6130v_virtual_reality c6110f_formal_methods c6140d_high_level_languages c7480_production_engineering_computing e0410d_industrial_applications_of_it other engineering human computer_interaction web_services manufacturing augmented reality ar device offer novel capability exploited ar system positively impact human machine interaction variety future work education context paper present system model code ar system framework used create ar application present time informatics assist guide user completion complex task sequence ensuring operator environment safety salient structural behavioral aspect system key use case modeled using system modeling language sysml representative example model presented using use case block definition internal block activity state machine diagram model offer new insight ar capability integrated variety engineered system future sysml model steer design new tool ontology strengthen connection domain knowledge,augmented reality ar device offer novel capability exploited ar system positively impact human machine interaction variety future work education context paper present system model code ar system framework used create ar application present time informatics assist guide user completion complex task sequence ensuring operator environment safety salient structural behavioral aspect system key use case modeled using system modeling language sysml representative example model presented using use case block definition internal block activity state machine diagram model offer new insight ar capability integrated variety engineered system future sysml model steer design new tool ontology strengthen connection domain knowledgehuman_computer_interaction ontology production_engineering_computing sysml unified_modeling_languageaugmented_reality_devices behavioral_aspects education_contexts engineered_systems future work human machine_interactions no code_ar_systems_framework representing_augmented_reality_applications salient_structural_aspects systems_model systems_modeling_language
46,Analyzing the impact and application of Augmented Reality in Education: The case of students with special educational needs,"Kapetanaki, A., Krouska, A., Troussas, C., & Sgouropoulou, C. (2022). Analyzing the impact and application of Augmented Reality in Education: The case of students with special educational needs. Proceedings of the 26th Pan-Hellenic Conference on Informatics. https://doi.org/10.1145/3575879.3575999
",10.1145/3575879.3575999,"This study presents a systematic review of the literature which analyzes the impact and application of Augmented Reality (AR) technology in the tutoring of students with special educational needs. In recent years, Information and Communication Technology (ICT) promotes learning in a pluralistic and multisensory environment that favors students with special educational needs. Augmented Reality is an emerging technology which has been widely used in the field of education, but only few studies are related to special education. This paper investigates the research in AR educational systems addressed to students with special educational needs. In total, 26 studies between 2014 and 2022 were selected and analyzed. Specifically, this systematic review examines the advantages and limitations of AR use in Special Education, the AR platforms and tools used in learning scenarios and the different types of students with special educational needs.",C7810C Computer-aided instruction;C6130V Virtual reality,AR educational systems;augmented reality technology;ICT;Information-and-Communication Technology;multisensory environment;pluralistic environment;special educational needs;systematic review,augmented reality;computer aided instruction,2022,Conference article (CA),PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics,"(1) Kapetanaki, A.; (1) Krouska, A.; (1) Troussas, C.; (1) Sgouropoulou, C.; ","(1) University of West Attica, Greece; ",ACM,-1,"[""computer aided instruction""]","[""computer aided instruction""]",computer aided instruction,training,use cases,training,use cases,computer_aided_instruction ar_educational_systems augmented_reality_technology ict information and communication_technology multisensory_environment pluralistic_environment special_educational_needs systematic_review c7810c_computer aided_instruction c6130v_virtual_reality training,computer_aided_instruction,ar_educational_systems augmented_reality_technology ict information and communication_technology multisensory_environment pluralistic_environment special_educational_needs systematic_review,study present systematic review literature analyzes impact application augmented reality ar technology tutoring student special educational need recent year information communication technology ict promotes learning pluralistic multisensory environment favor student special educational need augmented reality emerging technology widely used field education study related special education paper investigates research ar educational system addressed student special educational need total 26 study 2014 2022 selected analyzed specifically systematic review examines advantage limitation ar use special education ar platform tool used learning scenario different type student special educational need,computer_aided_instruction ar_educational_systems augmented_reality_technology ict information and communication_technology multisensory_environment pluralistic_environment special_educational_needs systematic_review c7810c_computer aided_instruction c6130v_virtual_reality training study present systematic review literature analyzes impact application augmented reality ar technology tutoring student special educational need recent year information communication technology ict promotes learning pluralistic multisensory environment favor student special educational need augmented reality emerging technology widely used field education study related special education paper investigates research ar educational system addressed student special educational need total 26 study 2014 2022 selected analyzed specifically systematic review examines advantage limitation ar use special education ar platform tool used learning scenario different type student special educational need,study present systematic review literature analyzes impact application augmented reality ar technology tutoring student special educational need recent year information communication technology ict promotes learning pluralistic multisensory environment favor student special educational need augmented reality emerging technology widely used field education study related special education paper investigates research ar educational system addressed student special educational need total 26 study 2014 2022 selected analyzed specifically systematic review examines advantage limitation ar use special education ar platform tool used learning scenario different type student special educational needcomputer_aided_instructionar_educational_systems augmented_reality_technology ict information and communication_technology multisensory_environment pluralistic_environment special_educational_needs systematic_review
47,"Virtual and Augmented Reality for Digital Medicine - Design and Implementation of a Hybrid, Interdisciplinary Course for Engineering and Medical Students","Eiler, T. J., Schmücker, V., Gießer, C., & Brück, R. (2023). Virtual and Augmented Reality for Digital Medicine - Design and Implementation of a Hybrid, Interdisciplinary Course for Engineering and Medical Students. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125163
",10.1109/EDUCON54358.2023.10125163,"In the winter semester 2021/22, the interdisciplinary course ""Virtual and Augmented Reality for Digital Medicine"" was offered. Here, students of medicine, medical technology, psychology as well as computer science were lectured together to merge the expertise from these fields and to promote mutual understanding. After a virtual theory phase, a practical phase took place on site. During the following hands-on phase, students collaborated in two different groups to develop an Augmented Reality (AR) and a Virtual Reality (VR) application with a medical context. After a presentation of the applications in front of an expert audience, the acquired knowledge was assessed by a written digital exam. The course was evaluated very positively by students from all fields and the good exam grades also indicate that the project was a success.",A0140 Education;A0150H Instructional computer use for education;C6130V Virtual reality;C7330 Biology and medical computing;C7810C Computer-aided instruction,augmented reality;digital medicine;hands-on phase;interdisciplinary course;medical context;medical technology;practical phase;virtual reality;virtual reality application;virtual theory phase;winter semester;written digital exam,augmented reality;biomedical education;computer aided instruction;educational courses;medical computing;psychology,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Eiler, T.J.; (1) Schmucker, V.; (1) Gieber, C.; (1) Bruck, R.; ","(1) University of Siegen, Medical Informatics and Microsystems Engineering, Germany; ",IEEE,-1,"[""biomedical education"", ""computer aided instruction"", ""educational courses"", ""medical computing"", ""psychology""]","[""biomedical education"", ""computer aided instruction"", ""educational courses"", ""medical computing"", ""psychology""]",biomedical education;computer aided instruction;educational courses;medical computing;psychology,medical;education;training,use cases;industries,medical;education;training,use cases;industries,biomedical_education computer_aided_instruction educational_courses medical_computing psychology augmented_reality digital_medicine hands on_phase interdisciplinary_course medical_context medical_technology practical_phase virtual_reality virtual_reality_application virtual_theory_phase winter_semester written_digital_exam a0140_education a0150h_instructional_computer_use_for_education c6130v_virtual_reality c7330_biology_and_medical_computing c7810c_computer aided_instruction medical education training,biomedical_education computer_aided_instruction educational_courses medical_computing psychology,augmented_reality digital_medicine hands on_phase interdisciplinary_course medical_context medical_technology practical_phase virtual_reality virtual_reality_application virtual_theory_phase winter_semester written_digital_exam,winter semester 2021 22 interdisciplinary course virtual augmented reality digital medicine offered student medicine medical technology psychology well computer science lectured together merge expertise field promote mutual understanding virtual theory phase practical phase took place site following hand phase student collaborated two different group develop augmented reality ar virtual reality vr application medical context presentation application front expert audience acquired knowledge assessed written digital exam course evaluated positively student field good exam grade also indicate project success,biomedical_education computer_aided_instruction educational_courses medical_computing psychology augmented_reality digital_medicine hands on_phase interdisciplinary_course medical_context medical_technology practical_phase virtual_reality virtual_reality_application virtual_theory_phase winter_semester written_digital_exam a0140_education a0150h_instructional_computer_use_for_education c6130v_virtual_reality c7330_biology_and_medical_computing c7810c_computer aided_instruction medical education training winter semester 2021 22 interdisciplinary course virtual augmented reality digital medicine offered student medicine medical technology psychology well computer science lectured together merge expertise field promote mutual understanding virtual theory phase practical phase took place site following hand phase student collaborated two different group develop augmented reality ar virtual reality vr application medical context presentation application front expert audience acquired knowledge assessed written digital exam course evaluated positively student field good exam grade also indicate project success,winter semester 2021 22 interdisciplinary course virtual augmented reality digital medicine offered student medicine medical technology psychology well computer science lectured together merge expertise field promote mutual understanding virtual theory phase practical phase took place site following hand phase student collaborated two different group develop augmented reality ar virtual reality vr application medical context presentation application front expert audience acquired knowledge assessed written digital exam course evaluated positively student field good exam grade also indicate project successbiomedical_education computer_aided_instruction educational_courses medical_computing psychologyaugmented_reality digital_medicine hands on_phase interdisciplinary_course medical_context medical_technology practical_phase virtual_reality virtual_reality_application virtual_theory_phase winter_semester written_digital_exam
48,Improving Learning-based Camera Pose Estimation for Image-based Augmented Reality Applications,"Cai, E., Rossi, R., & Xiao, C. (2023). Improving Learning-based Camera Pose Estimation for Image-based Augmented Reality Applications. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585756
",10.1145/3544549.3585756,"Camera tracking is essential for many augmented reality (AR) applications, such as rendering virtual content on top of a display. While marker-based camera tracking methods can accurately estimate the camera pose, they require pre-placed markers and occupy valuable screen space, potentially impacting the user experience. In contrast, markerless camera tracking methods do not have these limitations but tend to be less stable. In this work, we propose an improved approach for camera tracking that utilizes salient visual features commonly found on websites. We develop robust algorithms for detecting these features and design efficient methods for estimating the camera pose from them. Our approach outperforms state-of-the-art methods in terms of robustness, as demonstrated by our experiments. This work paves the way for a wide range of important AR applications, such as online shopping and interactive AR games.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality",design efficient methods;image-based augmented reality applications;important AR applications;improving learning-based camera pose estimation;marker-based camera tracking methods;markerless camera tracking methods;pre-placed markers;salient visual features;valuable screen space;virtual content,augmented reality;cameras;pose estimation,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Cai, E.; (2) Rossi, R.; (2) Xiao, C.; ","(1) Purdue University, West Lafayette, IN, United States; (2) Adobe Research, United States; ",ACM,-1,"[""cameras"", ""pose estimation""]","[""cameras"", ""pose estimation""]",cameras;pose estimation,graphics;input,technology,graphics;input,technology,cameras pose_estimation design_efficient_methods image based_augmented_reality_applications important_ar_applications improving_learning based_camera_pose_estimation marker based_camera_tracking_methods markerless_camera_tracking_methods pre placed_markers salient_visual_features valuable_screen_space virtual_content b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality graphics input,cameras pose_estimation,design_efficient_methods image based_augmented_reality_applications important_ar_applications improving_learning based_camera_pose_estimation marker based_camera_tracking_methods markerless_camera_tracking_methods pre placed_markers salient_visual_features valuable_screen_space virtual_content,camera tracking essential many augmented reality ar application rendering virtual content top display marker based camera tracking method accurately estimate camera pose require pre placed marker occupy valuable screen space potentially impacting user experience contrast markerless camera tracking method limitation tend le stable work propose improved approach camera tracking utilizes salient visual feature commonly found website develop robust algorithm detecting feature design efficient method estimating camera pose approach outperforms state art method term robustness demonstrated experiment work pave way wide range important ar application online shopping interactive ar game,cameras pose_estimation design_efficient_methods image based_augmented_reality_applications important_ar_applications improving_learning based_camera_pose_estimation marker based_camera_tracking_methods markerless_camera_tracking_methods pre placed_markers salient_visual_features valuable_screen_space virtual_content b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality graphics input camera tracking essential many augmented reality ar application rendering virtual content top display marker based camera tracking method accurately estimate camera pose require pre placed marker occupy valuable screen space potentially impacting user experience contrast markerless camera tracking method limitation tend le stable work propose improved approach camera tracking utilizes salient visual feature commonly found website develop robust algorithm detecting feature design efficient method estimating camera pose approach outperforms state art method term robustness demonstrated experiment work pave way wide range important ar application online shopping interactive ar game,camera tracking essential many augmented reality ar application rendering virtual content top display marker based camera tracking method accurately estimate camera pose require pre placed marker occupy valuable screen space potentially impacting user experience contrast markerless camera tracking method limitation tend le stable work propose improved approach camera tracking utilizes salient visual feature commonly found website develop robust algorithm detecting feature design efficient method estimating camera pose approach outperforms state art method term robustness demonstrated experiment work pave way wide range important ar application online shopping interactive ar gamecameras pose_estimationdesign_efficient_methods image based_augmented_reality_applications important_ar_applications improving_learning based_camera_pose_estimation marker based_camera_tracking_methods markerless_camera_tracking_methods pre placed_markers salient_visual_features valuable_screen_space virtual_content
49,The Recommendation Augmented Reality: For Maritime Navigation Applications in Indonesia,"Rezaldi, M. Y., Napitupulu, H., Husni, E., & Prakasa, E. (2022). The Recommendation Augmented Reality. Proceedings of the 2022 International Conference on Computer, Control, Informatics and Its Applications. https://doi.org/10.1145/3575882.3575930
",10.1145/3575882.3575930,"This paper discusses the understanding of augmented reality (AR), types of AR, its current AR use, and reviews the used AR specifically for ship safety navigation. The paper will make recommendations on what type of AR products are possible to develop. The AR can be used to support maritime navigation applications in Indonesia. The method used is primary literature review analysis through Systematic Literature Review (SLR) from thirty articles. Results of the literature review show that four types of AR based on the projection techniques. The types are a marker-based AR (image recognition), markerless AR, projection-based AR (hologram), and super impositing-based AR (object recognition). Currently, in various countries, AR products have begun to be developed for maritime navigation applications such as AR social to determine point of interest (POI), AR navigation, AR safety, and an immersive underwater world. From the literature review analysis results, this paper recommends that the right AR products based on the projection technique are markerless AR and projection-based AR types. However, in the future, it is necessary to make an in-depth study of the need for AR products for maritime navigation in Indonesia. The products include traditional navigation tools, navigational aid, and simulations for marine navigation training and then be implemented so that the AR products for maritime navigation that are produced are truly in accordance with the needs of ship crew and policymakers in Indonesia.",B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7445 Traffic engineering computing,hologram;image recognition;immersive underwater world;Indonesia;marine navigation training;maritime navigation;marker-based augmented reality;markerless augmented reality;navigation tools;navigational aid;object recognition;projection technique;projection-based augmented reality;recommendation augmented reality;ship crew;ship safety navigation;super impositing-based augmented reality;systematic literature review,augmented reality;holography;image recognition;marine navigation;marine safety;object recognition;reviews;ships;traffic engineering computing,2022,Conference article (CA),"IC3INA'22: Proceedings of the 2022 International Conference on Computer, Control, Informatics and Its Applications","(1) Rezaldi, M.Y.; (2) Napitupulu, H.; (3) Husni, E.; (1) Prakasa, E.; ","(1) National Research and Innovation Agency, Research Center for Data and Information, Indonesia; (2) Transportation Policy Agency, Ministry of Transportation Indonesia, Indonesia; (3) Institut Teknologi Bandung, School of Electrical Engineering & Informatics, Indonesia; ",ACM,-1,"[""holography"", ""image recognition"", ""marine navigation"", ""marine safety"", ""object recognition"", ""reviews"", ""ships"", ""traffic engineering computing""]","[""holography"", ""image recognition"", ""marine navigation"", ""marine safety"", ""object recognition"", ""reviews"", ""ships"", ""traffic engineering computing""]",holography;image recognition;marine navigation;marine safety;object recognition;reviews;ships;traffic engineering computing,"computer vision;other;transportation;government;inspection, safety and quality;human factors;display technology;engineering;standards;marine;navigation",other;displays;end users and user experience;industries;use cases;standards;technology,"computer vision;other;transportation;government;inspection, safety and quality;human factors;display technology;engineering;standards;marine;navigation",other;displays;end users and user experience;industries;use cases;standards;technology,holography image_recognition marine_navigation marine_safety object_recognition reviews ships traffic_engineering_computing hologram image_recognition immersive_underwater_world indonesia marine_navigation_training maritime_navigation marker based_augmented_reality markerless_augmented_reality navigation_tools navigational_aid object_recognition projection_technique projection based_augmented_reality recommendation_augmented_reality ship_crew ship_safety_navigation super_impositing based_augmented_reality systematic_literature_review b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7445_traffic_engineering_computing computer_vision other transportation government inspection _safety_and_quality human_factors display_technology engineering standards marine navigation,holography image_recognition marine_navigation marine_safety object_recognition reviews ships traffic_engineering_computing,hologram image_recognition immersive_underwater_world indonesia marine_navigation_training maritime_navigation marker based_augmented_reality markerless_augmented_reality navigation_tools navigational_aid object_recognition projection_technique projection based_augmented_reality recommendation_augmented_reality ship_crew ship_safety_navigation super_impositing based_augmented_reality systematic_literature_review,paper discus understanding augmented reality ar type ar current ar use review used ar specifically ship safety navigation paper make recommendation type ar product possible develop ar used support maritime navigation application indonesia method used primary literature review analysis systematic literature review slr thirty article result literature review show four type ar based projection technique type marker based ar image recognition markerless ar projection based ar hologram super impositing based ar object recognition currently various country ar product begun developed maritime navigation application ar social determine point interest poi ar navigation ar safety immersive underwater world literature review analysis result paper recommends right ar product based projection technique markerless ar projection based ar type however future necessary make depth study need ar product maritime navigation indonesia product include traditional navigation tool navigational aid simulation marine navigation training implemented ar product maritime navigation produced truly accordance need ship crew policymakers indonesia,holography image_recognition marine_navigation marine_safety object_recognition reviews ships traffic_engineering_computing hologram image_recognition immersive_underwater_world indonesia marine_navigation_training maritime_navigation marker based_augmented_reality markerless_augmented_reality navigation_tools navigational_aid object_recognition projection_technique projection based_augmented_reality recommendation_augmented_reality ship_crew ship_safety_navigation super_impositing based_augmented_reality systematic_literature_review b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7445_traffic_engineering_computing computer_vision other transportation government inspection _safety_and_quality human_factors display_technology engineering standards marine navigation paper discus understanding augmented reality ar type ar current ar use review used ar specifically ship safety navigation paper make recommendation type ar product possible develop ar used support maritime navigation application indonesia method used primary literature review analysis systematic literature review slr thirty article result literature review show four type ar based projection technique type marker based ar image recognition markerless ar projection based ar hologram super impositing based ar object recognition currently various country ar product begun developed maritime navigation application ar social determine point interest poi ar navigation ar safety immersive underwater world literature review analysis result paper recommends right ar product based projection technique markerless ar projection based ar type however future necessary make depth study need ar product maritime navigation indonesia product include traditional navigation tool navigational aid simulation marine navigation training implemented ar product maritime navigation produced truly accordance need ship crew policymakers indonesia,paper discus understanding augmented reality ar type ar current ar use review used ar specifically ship safety navigation paper make recommendation type ar product possible develop ar used support maritime navigation application indonesia method used primary literature review analysis systematic literature review slr thirty article result literature review show four type ar based projection technique type marker based ar image recognition markerless ar projection based ar hologram super impositing based ar object recognition currently various country ar product begun developed maritime navigation application ar social determine point interest poi ar navigation ar safety immersive underwater world literature review analysis result paper recommends right ar product based projection technique markerless ar projection based ar type however future necessary make depth study need ar product maritime navigation indonesia product include traditional navigation tool navigational aid simulation marine navigation training implemented ar product maritime navigation produced truly accordance need ship crew policymakers indonesiaholography image_recognition marine_navigation marine_safety object_recognition reviews ships traffic_engineering_computinghologram image_recognition immersive_underwater_world indonesia marine_navigation_training maritime_navigation marker based_augmented_reality markerless_augmented_reality navigation_tools navigational_aid object_recognition projection_technique projection based_augmented_reality recommendation_augmented_reality ship_crew ship_safety_navigation super_impositing based_augmented_reality systematic_literature_review
50,FlowAR: How Different Augmented Reality Visualizations of Online Fitness Videos Support Flow for At-Home Yoga Exercises,"Jo, H.-Y., Seidel, L., Pahud, M., Sinclair, M., & Bianchi, A. (2023). FlowAR: How Different Augmented Reality Visualizations of Online Fitness Videos Support Flow for At-Home Yoga Exercises. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580897
",10.1145/3544548.3580897,"Online fitness video tutorials are an increasingly popular way to stay fit at home without a personal trainer. However, to keep the screen playing the video in view, users typically disrupt their balance and break the motion flow - two main pillars for the correct execution of yoga poses. While past research partially addressed this problem, these approaches supported only a limited view of the instructor and simple movements. To enable the fluid execution of complex full-body yoga exercises, we propose FlowAR, an augmented reality system for home workouts that shows training video tutorials as always-present virtual static and dynamic overlays around the user. We tested different overlay layouts in a study with 16 participants, using motion capture equipment for baseline performance. Then, we iterated the prototype and tested it in a furnished lab simulating home settings with 12 users. Our results highlight the advantages of different visualizations and the system's general applicability.",B6135E Image recognition;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces,At-Home Yoga Exercises;augmented reality system;complex full-body yoga exercises;correct execution;different augmented reality visualizations;different visualizations;dynamic overlays;FlowAR;fluid execution;home settings;home workouts;main pillars;motion capture equipment;motion flow;online fitness video tutorials;online fitness videos support flow;personal trainer;simple movements;virtual static overlays;yoga poses,augmented reality;pose estimation;video signal processing;virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Jo, H.-Y.; (2) Seidel, L.; (3) Pahud, M.; (3) Sinclair, M.; (4) Bianchi, A.; ","(1) Korea Advanced Institute of Science and Technology, Korea, Republic of; (2) Hasso Plattner Institute, Germany; (3) Microsoft Research, Redmond, WA, United States; (4) Korea Advanced Institute of Science and Technology, Republic of and School of Computing, Korea, Republic of; ",ACM,-1,"[""pose estimation"", ""video signal processing""]","[""pose estimation"", ""video signal processing""]",pose estimation;video signal processing,semiconductors;graphics;data;sensors,technology,semiconductors;graphics;data;sensors,technology,pose_estimation video_signal_processing at home_yoga_exercises augmented_reality_system complex_full body_yoga_exercises correct_execution different_augmented_reality_visualizations different_visualizations dynamic_overlays flowar fluid_execution home_settings home_workouts main_pillars motion_capture_equipment motion_flow online_fitness_video_tutorials online_fitness_videos_support_flow personal_trainer simple_movements virtual_static_overlays yoga_poses b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces semiconductors graphics data sensors,pose_estimation video_signal_processing,at home_yoga_exercises augmented_reality_system complex_full body_yoga_exercises correct_execution different_augmented_reality_visualizations different_visualizations dynamic_overlays flowar fluid_execution home_settings home_workouts main_pillars motion_capture_equipment motion_flow online_fitness_video_tutorials online_fitness_videos_support_flow personal_trainer simple_movements virtual_static_overlays yoga_poses,online fitness video tutorial increasingly popular way stay fit home without personal trainer however keep screen playing video view user typically disrupt balance break motion flow two main pillar correct execution yoga pose past research partially addressed problem approach supported limited view instructor simple movement enable fluid execution complex full body yoga exercise propose flowar augmented reality system home workout show training video tutorial always present virtual static dynamic overlay around user tested different overlay layout study 16 participant using motion capture equipment baseline performance iterated prototype tested furnished lab simulating home setting 12 user result highlight advantage different visualization system general applicability,pose_estimation video_signal_processing at home_yoga_exercises augmented_reality_system complex_full body_yoga_exercises correct_execution different_augmented_reality_visualizations different_visualizations dynamic_overlays flowar fluid_execution home_settings home_workouts main_pillars motion_capture_equipment motion_flow online_fitness_video_tutorials online_fitness_videos_support_flow personal_trainer simple_movements virtual_static_overlays yoga_poses b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces semiconductors graphics data sensors online fitness video tutorial increasingly popular way stay fit home without personal trainer however keep screen playing video view user typically disrupt balance break motion flow two main pillar correct execution yoga pose past research partially addressed problem approach supported limited view instructor simple movement enable fluid execution complex full body yoga exercise propose flowar augmented reality system home workout show training video tutorial always present virtual static dynamic overlay around user tested different overlay layout study 16 participant using motion capture equipment baseline performance iterated prototype tested furnished lab simulating home setting 12 user result highlight advantage different visualization system general applicability,online fitness video tutorial increasingly popular way stay fit home without personal trainer however keep screen playing video view user typically disrupt balance break motion flow two main pillar correct execution yoga pose past research partially addressed problem approach supported limited view instructor simple movement enable fluid execution complex full body yoga exercise propose flowar augmented reality system home workout show training video tutorial always present virtual static dynamic overlay around user tested different overlay layout study 16 participant using motion capture equipment baseline performance iterated prototype tested furnished lab simulating home setting 12 user result highlight advantage different visualization system general applicabilitypose_estimation video_signal_processingat home_yoga_exercises augmented_reality_system complex_full body_yoga_exercises correct_execution different_augmented_reality_visualizations different_visualizations dynamic_overlays flowar fluid_execution home_settings home_workouts main_pillars motion_capture_equipment motion_flow online_fitness_video_tutorials online_fitness_videos_support_flow personal_trainer simple_movements virtual_static_overlays yoga_poses
51,Learning Chemistry with Interactive Simulations: Augmented Reality as Teaching Aid,"Benrahal, M., Bourhim, E. M., Dahane, A., Labti, O., & Akhiate, A. (2022). Learning Chemistry with Interactive Simulations: Augmented Reality as Teaching Aid. Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems, 526–535. https://doi.org/10.1007/978-3-031-20429-6_48
",10.1007/978-3-031-20429-6_48,"Augmented Reality (AR) has been identified by educational scientists as a technology with significant potential to improve emotional and cognitive learning outcomes. However, very few papers highlighted the technical process of creating AR applications reserved for education. The following paper proposes a method and framework for how to set up an AR application to teach primary school children the basic forms and shapes of atoms, molecules, and DNA. This framework uses the Unity 3D game engine (GE) with Vuforia SDK (Software Development Kit) packages combined with phone devices or tablets to create an interactive App for AR environments, to enhance the student's vision and understanding of basic chemistry models. We also point out some difficulties in practice. As for those difficulties mentioned, a series of solutions plus further development orientation are put forth.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7830D Computer games",AR application;augmented Reality;Augmented Reality;basic chemistry models;basic forms;cognitive learning outcomes;educational scientists;emotional learning outcomes;interactive App;interactive simulations;primary school children;Software Development Kit;teaching aid;technical process;Unity 3D game engine;Vuforia SDK packages,augmented reality;cognition;computer aided instruction;computer games;educational institutions;mobile computing;teaching,2023,Conference article (CA),Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems: ICETIS 2022. Lecture Notes in Networks and Systems (573),"(1) Benrahal, M.; (2) Bourhim, E.M.; (1) Dahane, A.; (3) Labti, O.; (1) Akhiate, A.; ","(1) Universite Hassan II de Casablanca, Artificial Intelligence and Complex Systems Engineering (AICSE), Morocco; (2) Mohammed V University, Industrial Engineering Department, Morocco; (3) Universite Hassan II de Casablanca, Laboratory of Research in Management, Morocco; (4) BP.154, Moroccan Association of Innovation and Scientific Research in Artificial Intelligence and Extended Reality, Morocco; ",Springer,-1,"[""cognition"", ""computer aided instruction"", ""computer games"", ""educational institutions"", ""mobile computing"", ""teaching""]","[""cognition"", ""computer aided instruction"", ""computer games"", ""educational institutions"", ""mobile computing"", ""teaching""]",cognition;computer aided instruction;computer games;educational institutions;mobile computing;teaching,education;liberal arts;training;human factors;telecommunication,end users and user experience;use cases;industries,education;liberal arts;training;human factors;telecommunication,end users and user experience;use cases;industries,cognition computer_aided_instruction computer_games educational_institutions mobile_computing teaching ar_application augmented_reality augmented_reality basic_chemistry_models basic_forms cognitive_learning_outcomes educational_scientists emotional_learning_outcomes interactive_app interactive_simulations primary_school_children software_development_kit teaching_aid technical_process unity_3d_game_engine vuforia_sdk_packages c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games education liberal_arts training human_factors telecommunication,cognition computer_aided_instruction computer_games educational_institutions mobile_computing teaching,ar_application augmented_reality augmented_reality basic_chemistry_models basic_forms cognitive_learning_outcomes educational_scientists emotional_learning_outcomes interactive_app interactive_simulations primary_school_children software_development_kit teaching_aid technical_process unity_3d_game_engine vuforia_sdk_packages,augmented reality ar identified educational scientist technology significant potential improve emotional cognitive learning outcome however paper highlighted technical process creating ar application reserved education following paper proposes method framework set ar application teach primary school child basic form shape atom molecule dna framework us unity 3d game engine ge vuforia sdk software development kit package combined phone device tablet create interactive app ar environment enhance student vision understanding basic chemistry model also point difficulty practice difficulty mentioned series solution plus development orientation put forth,cognition computer_aided_instruction computer_games educational_institutions mobile_computing teaching ar_application augmented_reality augmented_reality basic_chemistry_models basic_forms cognitive_learning_outcomes educational_scientists emotional_learning_outcomes interactive_app interactive_simulations primary_school_children software_development_kit teaching_aid technical_process unity_3d_game_engine vuforia_sdk_packages c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games education liberal_arts training human_factors telecommunication augmented reality ar identified educational scientist technology significant potential improve emotional cognitive learning outcome however paper highlighted technical process creating ar application reserved education following paper proposes method framework set ar application teach primary school child basic form shape atom molecule dna framework us unity 3d game engine ge vuforia sdk software development kit package combined phone device tablet create interactive app ar environment enhance student vision understanding basic chemistry model also point difficulty practice difficulty mentioned series solution plus development orientation put forth,augmented reality ar identified educational scientist technology significant potential improve emotional cognitive learning outcome however paper highlighted technical process creating ar application reserved education following paper proposes method framework set ar application teach primary school child basic form shape atom molecule dna framework us unity 3d game engine ge vuforia sdk software development kit package combined phone device tablet create interactive app ar environment enhance student vision understanding basic chemistry model also point difficulty practice difficulty mentioned series solution plus development orientation put forthcognition computer_aided_instruction computer_games educational_institutions mobile_computing teachingar_application augmented_reality augmented_reality basic_chemistry_models basic_forms cognitive_learning_outcomes educational_scientists emotional_learning_outcomes interactive_app interactive_simulations primary_school_children software_development_kit teaching_aid technical_process unity_3d_game_engine vuforia_sdk_packages
52,A Qualitative Approach to the Electromagnetic Induction Fostered by Augmented Reality,"Berger, R., & Lensing, P. (2023). A Qualitative Approach to the Electromagnetic Induction Fostered by Augmented Reality. The Physics Teacher, 61(1), 34–35. https://doi.org/10.1119/5.0062131
",10.1119/5.0062131,"In physics education, the topic of electromagnetic induction is an important but also challenging topic for many students. The early introduction of formulae, e.g., Faraday's law of induction, seems to hinder rather than to foster the understanding of the topic's underlying principles. In this paper, we present the basic idea for a teaching concept that can be helpful for a qualitative understanding of electromagnetic induction. To support this teaching concept further, we have developed an application for a tablet computer following the augmented reality approach. The tablet measures the magnetic field strength of a Helmholtz coil and superimposes the corresponding number of virtual field lines on the induction coil. [The copyright for the referenced work is owned by Author(s). Copies of full-text articles should only be made or obtained from the publisher or authorized sources.]",A0150 Educational aids;C6130V Virtual reality;C7810C Computer-aided instruction,augmented reality approach;early introduction;electromagnetic induction fostered;Faraday's law;important but also challenging topic;induction coil;physics education;qualitative approach;qualitative understanding;teaching concept,augmented reality;computer aided instruction;electromagnetic induction;physics education;teaching,2023,Journal article (JA),Phys. Teach. (USA),"(1) Berger, R.; (2) Lensing, P.; ","(1) Universitat Osnabruck, Physics Education Group, Germany; (2) Hochschule Osnabruck, Germany; ",AIP Publishing,-1,"[""computer aided instruction"", ""electromagnetic induction"", ""physics education"", ""teaching""]","[""computer aided instruction"", ""electromagnetic induction"", ""physics education"", ""teaching""]",computer aided instruction;electromagnetic induction;physics education;teaching,other;education;engineering;training,technology;other;use cases;industries,other;education;engineering;training,technology;other;use cases;industries,computer_aided_instruction electromagnetic_induction physics_education teaching augmented_reality_approach early_introduction electromagnetic_induction_fostered faraday s_law important_but_also_challenging_topic induction_coil physics_education qualitative_approach qualitative_understanding teaching_concept a0150_educational_aids c6130v_virtual_reality c7810c_computer aided_instruction other education engineering training,computer_aided_instruction electromagnetic_induction physics_education teaching,augmented_reality_approach early_introduction electromagnetic_induction_fostered faraday s_law important_but_also_challenging_topic induction_coil physics_education qualitative_approach qualitative_understanding teaching_concept,physic education topic electromagnetic induction important also challenging topic many student early introduction formula e g faraday law induction seems hinder rather foster understanding topic underlying principle paper present basic idea teaching concept helpful qualitative understanding electromagnetic induction support teaching concept developed application tablet computer following augmented reality approach tablet measure magnetic field strength helmholtz coil superimposes corresponding number virtual field line induction coil copyright referenced work owned author copy full text article made obtained publisher authorized source,computer_aided_instruction electromagnetic_induction physics_education teaching augmented_reality_approach early_introduction electromagnetic_induction_fostered faraday s_law important_but_also_challenging_topic induction_coil physics_education qualitative_approach qualitative_understanding teaching_concept a0150_educational_aids c6130v_virtual_reality c7810c_computer aided_instruction other education engineering training physic education topic electromagnetic induction important also challenging topic many student early introduction formula e g faraday law induction seems hinder rather foster understanding topic underlying principle paper present basic idea teaching concept helpful qualitative understanding electromagnetic induction support teaching concept developed application tablet computer following augmented reality approach tablet measure magnetic field strength helmholtz coil superimposes corresponding number virtual field line induction coil copyright referenced work owned author copy full text article made obtained publisher authorized source,physic education topic electromagnetic induction important also challenging topic many student early introduction formula e g faraday law induction seems hinder rather foster understanding topic underlying principle paper present basic idea teaching concept helpful qualitative understanding electromagnetic induction support teaching concept developed application tablet computer following augmented reality approach tablet measure magnetic field strength helmholtz coil superimposes corresponding number virtual field line induction coil copyright referenced work owned author copy full text article made obtained publisher authorized sourcecomputer_aided_instruction electromagnetic_induction physics_education teachingaugmented_reality_approach early_introduction electromagnetic_induction_fostered faraday s_law important_but_also_challenging_topic induction_coil physics_education qualitative_approach qualitative_understanding teaching_concept
53,Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,"Monteiro, K., Vatsal, R., Chulpongsatorn, N., Parnami, A., & Suzuki, R. (2023). Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581449
",10.1145/3544548.3581449,"This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6180 User interfaces,AR prototyping;arbitrary everyday objects;augmented reality prototyping tool;current marker-based approaches;deformable interfaces;functional AR prototypes;general-purpose prototyping experiences;interactive tangible AR applications;on-demand computer vision model;prototyping tangible augmented Reality;real-world interactions;tangible interfaces;Teachable Machine;Teachable Reality leverages vision-based interactive machine teaching;trigger-action authoring interface,augmented reality;computer vision;gesture recognition;human computer interaction;user interfaces,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Monteiro, K.; (1) Vatsal, R.; (2) Chulpongsatorn, N.; (3) Parnami, A.; (2) Suzuki, R.; ","(1) University of Calgary, Weave Lab, Calgary, AB, Canada; (2) University of Calgary, Calgary, AB, Canada; (3) IIIT-Delhi, Weave Lab, India; ",ACM,-1,"[""computer vision"", ""gesture recognition"", ""human computer interaction"", ""user interfaces""]","[""computer vision"", ""gesture recognition"", ""human computer interaction"", ""user interfaces""]",computer vision;gesture recognition;human computer interaction;user interfaces,input;computer vision;human factors;human-computer interaction,technology;end users and user experience,input;computer vision;human factors;human-computer interaction,technology;end users and user experience,computer_vision gesture_recognition human_computer_interaction user_interfaces ar_prototyping arbitrary_everyday_objects augmented_reality_prototyping_tool current_marker based_approaches deformable_interfaces functional_ar_prototypes general purpose_prototyping_experiences interactive_tangible_ar_applications on demand_computer_vision_model prototyping_tangible_augmented_reality real world_interactions tangible_interfaces teachable_machine teachable_reality_leverages_vision based_interactive_machine_teaching trigger action_authoring_interface c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces input computer_vision human_factors human computer_interaction,computer_vision gesture_recognition human_computer_interaction user_interfaces,ar_prototyping arbitrary_everyday_objects augmented_reality_prototyping_tool current_marker based_approaches deformable_interfaces functional_ar_prototypes general purpose_prototyping_experiences interactive_tangible_ar_applications on demand_computer_vision_model prototyping_tangible_augmented_reality real world_interactions tangible_interfaces teachable_machine teachable_reality_leverages_vision based_interactive_machine_teaching trigger action_authoring_interface,paper introduces teachable reality augmented reality ar prototyping tool creating interactive tangible ar application arbitrary everyday object teachable reality leverage vision based interactive machine teaching e g teachable machine capture real world interaction ar prototyping identifies user defined tangible gestural interaction using demand computer vision model based user easily create functional ar prototype without programming enabled trigger action authoring interface therefore approach allows flexibility customizability generalizability tangible ar application address limitation current marker based approach explore design space demonstrate various ar prototype include tangible deformable interface context aware assistant body driven ar application result user study expert interview confirm approach lower barrier creating functional ar prototype also allowing flexible general purpose prototyping experience,computer_vision gesture_recognition human_computer_interaction user_interfaces ar_prototyping arbitrary_everyday_objects augmented_reality_prototyping_tool current_marker based_approaches deformable_interfaces functional_ar_prototypes general purpose_prototyping_experiences interactive_tangible_ar_applications on demand_computer_vision_model prototyping_tangible_augmented_reality real world_interactions tangible_interfaces teachable_machine teachable_reality_leverages_vision based_interactive_machine_teaching trigger action_authoring_interface c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces input computer_vision human_factors human computer_interaction paper introduces teachable reality augmented reality ar prototyping tool creating interactive tangible ar application arbitrary everyday object teachable reality leverage vision based interactive machine teaching e g teachable machine capture real world interaction ar prototyping identifies user defined tangible gestural interaction using demand computer vision model based user easily create functional ar prototype without programming enabled trigger action authoring interface therefore approach allows flexibility customizability generalizability tangible ar application address limitation current marker based approach explore design space demonstrate various ar prototype include tangible deformable interface context aware assistant body driven ar application result user study expert interview confirm approach lower barrier creating functional ar prototype also allowing flexible general purpose prototyping experience,paper introduces teachable reality augmented reality ar prototyping tool creating interactive tangible ar application arbitrary everyday object teachable reality leverage vision based interactive machine teaching e g teachable machine capture real world interaction ar prototyping identifies user defined tangible gestural interaction using demand computer vision model based user easily create functional ar prototype without programming enabled trigger action authoring interface therefore approach allows flexibility customizability generalizability tangible ar application address limitation current marker based approach explore design space demonstrate various ar prototype include tangible deformable interface context aware assistant body driven ar application result user study expert interview confirm approach lower barrier creating functional ar prototype also allowing flexible general purpose prototyping experiencecomputer_vision gesture_recognition human_computer_interaction user_interfacesar_prototyping arbitrary_everyday_objects augmented_reality_prototyping_tool current_marker based_approaches deformable_interfaces functional_ar_prototypes general purpose_prototyping_experiences interactive_tangible_ar_applications on demand_computer_vision_model prototyping_tangible_augmented_reality real world_interactions tangible_interfaces teachable_machine teachable_reality_leverages_vision based_interactive_machine_teaching trigger action_authoring_interface
54,A human-centered conceptual model for integrating Augmented Reality and Dynamic Digital Models to reduce occupational risks in industrial contexts,"Gualtieri, L., Revolti, A., & Dallasega, P. (2023). A human-centered conceptual model for integrating Augmented Reality and Dynamic Digital Models to reduce occupational risks in industrial contexts. Procedia Computer Science, 217, 765–773. https://doi.org/10.1016/j.procs.2022.12.273
",10.1016/j.procs.2022.12.273,"The article proposes a human-centered conceptual model to integrate Augmented Reality (AR) and Dynamic Digital Models (DDM) to improve training and reduce occupational risks in industrial contexts. A general model integrating DDM and AR to support immersive training and customized and real-time risk management is missing in the literature. The proposed conceptual model was preliminarily validated with company experts in a laboratory environment. According to the expert's feedback, the system can improve the efficacy of training by means of an immersive environment where users can better perceive hazards and safety-critical situations. Considering the capability of the conceptual model to support real-time and customized risk management, the participating experts argue that the technology seems not to be ready yet, even if it is very interesting and it would be very useful in practice to mitigate occupational risks. Future research activities will consist of the development of a prototypical system based on the presented conceptual model by considering specific user requirements and experts' feedback. All rights reserved Elsevier.",C6130V Virtual reality;C7810C Computer-aided instruction;E0240H Health and safety aspects,Augmented Reality;DDM;Dynamic Digital Models;human-centered conceptual model;immersive training;industrial contexts;occupational risks;presented conceptual model;real-time risk management,augmented reality;computer based training;decision making;occupational safety;risk management,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Gualtieri, L.; (1) Revolti, A.; (1) Dallasega, P.; ","(1) Free University of Bozen-Bolzano, Faculty of Science and Technology, Piazza Universita&#768; 5, Italy; ",Elsevier B.V.,-1,"[""computer based training"", ""decision making"", ""occupational safety"", ""risk management""]","[""computer based training"", ""decision making"", ""occupational safety"", ""risk management""]",computer based training;decision making;occupational safety;risk management,"human factors;farming and natural science;training;inspection, safety and quality",end users and user experience;use cases;industries,"human factors;farming and natural science;training;inspection, safety and quality",end users and user experience;use cases;industries,computer_based_training decision_making occupational_safety risk_management augmented_reality ddm dynamic_digital_models human centered_conceptual_model immersive_training industrial_contexts occupational_risks presented_conceptual_model real time_risk_management c6130v_virtual_reality c7810c_computer aided_instruction e0240h_health_and_safety_aspects human_factors farming_and_natural_science training inspection _safety_and_quality,computer_based_training decision_making occupational_safety risk_management,augmented_reality ddm dynamic_digital_models human centered_conceptual_model immersive_training industrial_contexts occupational_risks presented_conceptual_model real time_risk_management,article proposes human centered conceptual model integrate augmented reality ar dynamic digital model ddm improve training reduce occupational risk industrial context general model integrating ddm ar support immersive training customized real time risk management missing literature proposed conceptual model preliminarily validated company expert laboratory environment according expert feedback system improve efficacy training mean immersive environment user better perceive hazard safety critical situation considering capability conceptual model support real time customized risk management participating expert argue technology seems ready yet even interesting would useful practice mitigate occupational risk future research activity consist development prototypical system based presented conceptual model considering specific user requirement expert feedback right reserved elsevier,computer_based_training decision_making occupational_safety risk_management augmented_reality ddm dynamic_digital_models human centered_conceptual_model immersive_training industrial_contexts occupational_risks presented_conceptual_model real time_risk_management c6130v_virtual_reality c7810c_computer aided_instruction e0240h_health_and_safety_aspects human_factors farming_and_natural_science training inspection _safety_and_quality article proposes human centered conceptual model integrate augmented reality ar dynamic digital model ddm improve training reduce occupational risk industrial context general model integrating ddm ar support immersive training customized real time risk management missing literature proposed conceptual model preliminarily validated company expert laboratory environment according expert feedback system improve efficacy training mean immersive environment user better perceive hazard safety critical situation considering capability conceptual model support real time customized risk management participating expert argue technology seems ready yet even interesting would useful practice mitigate occupational risk future research activity consist development prototypical system based presented conceptual model considering specific user requirement expert feedback right reserved elsevier,article proposes human centered conceptual model integrate augmented reality ar dynamic digital model ddm improve training reduce occupational risk industrial context general model integrating ddm ar support immersive training customized real time risk management missing literature proposed conceptual model preliminarily validated company expert laboratory environment according expert feedback system improve efficacy training mean immersive environment user better perceive hazard safety critical situation considering capability conceptual model support real time customized risk management participating expert argue technology seems ready yet even interesting would useful practice mitigate occupational risk future research activity consist development prototypical system based presented conceptual model considering specific user requirement expert feedback right reserved elseviercomputer_based_training decision_making occupational_safety risk_managementaugmented_reality ddm dynamic_digital_models human centered_conceptual_model immersive_training industrial_contexts occupational_risks presented_conceptual_model real time_risk_management
55,Wizard of Oz Prototyping for Interactive Spatial Augmented Reality in HCI Education: Experiences with Rapid Prototyping for Interactive Spatial Augmented Reality,"Mast, D., Roidl, A., & Jylha, A. (2023). Wizard of Oz Prototyping for Interactive Spatial Augmented Reality in HCI Education. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3573861
",10.1145/3544549.3573861,"In this paper we present our findings that emerged from Wizard of Oz (WOz) prototyping workshops of an undergrad course on UX design between 2017 - 2022. The purpose of these workshops is both to familiarize the students with WOz as a rapid low-complexity prototyping method and to facilitate them in designing for interactive systems beyond typical graphical user interfaces. In these workshops, students develop and test Wizard of Oz prototypes for interactive spatial augmented reality (SAR). Over the past six years, in total 93 prototypes have been created on the course. We analyzed the prototypes that emerged from the workshops based on input, purpose, play characteristics and projection surfaces. Based on the analysis and our experiences during the workshops, we conclude that the workshops stimulate creativity, enable students to rapidly create interactive SAR interfaces without being limited by their technical skills and time limitations and provide them with a tool that they apply beyond the scope of the prototyping course. We discuss advantages and limitations of the use of WOz prototyping for interactive Spatial Augmented Reality.",C0220 Computing education and training;C6130V Virtual reality;C6180G Graphical user interfaces,interactive SAR interfaces;interactive spatial augmented reality;low-complexity prototyping method;prototyping course;rapid prototyping;undergrad course;UX design;Wizard of Oz prototyping workshops;WOz,augmented reality;computer science education;graphical user interfaces;human computer interaction;interactive systems,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Mast, D.; (2) Roidl, A.; (3) Jylha, A.; ","(1) Hague University of Applied Sciences, Netherlands and Leiden Institute for Advanced Computer Science, Netherlands; (2) Hochschule Mainz, Germany; (3) Haaga-Helia University of Applied Sciences, Faculty of IT & Design, Finland; ",ACM,-1,"[""computer science education"", ""graphical user interfaces"", ""human computer interaction"", ""interactive systems""]","[""computer science education"", ""graphical user interfaces"", ""human computer interaction"", ""interactive systems""]",computer science education;graphical user interfaces;human computer interaction;interactive systems,education;graphics;input;developers;human-computer interaction,technology;end users and user experience;industries,education;graphics;input;developers;human-computer interaction,technology;end users and user experience;industries,computer_science_education graphical_user_interfaces human_computer_interaction interactive_systems interactive_sar_interfaces interactive_spatial_augmented_reality low complexity_prototyping_method prototyping_course rapid_prototyping undergrad_course ux_design wizard_of_oz_prototyping_workshops woz c0220_computing_education_and_training c6130v_virtual_reality c6180g_graphical_user_interfaces education graphics input developers human computer_interaction,computer_science_education graphical_user_interfaces human_computer_interaction interactive_systems,interactive_sar_interfaces interactive_spatial_augmented_reality low complexity_prototyping_method prototyping_course rapid_prototyping undergrad_course ux_design wizard_of_oz_prototyping_workshops woz,paper present finding emerged wizard oz woz prototyping workshop undergrad course ux design 2017 2022 purpose workshop familiarize student woz rapid low complexity prototyping method facilitate designing interactive system beyond typical graphical user interface workshop student develop test wizard oz prototype interactive spatial augmented reality sar past six year total 93 prototype created course analyzed prototype emerged workshop based input purpose play characteristic projection surface based analysis experience workshop conclude workshop stimulate creativity enable student rapidly create interactive sar interface without limited technical skill time limitation provide tool apply beyond scope prototyping course discus advantage limitation use woz prototyping interactive spatial augmented reality,computer_science_education graphical_user_interfaces human_computer_interaction interactive_systems interactive_sar_interfaces interactive_spatial_augmented_reality low complexity_prototyping_method prototyping_course rapid_prototyping undergrad_course ux_design wizard_of_oz_prototyping_workshops woz c0220_computing_education_and_training c6130v_virtual_reality c6180g_graphical_user_interfaces education graphics input developers human computer_interaction paper present finding emerged wizard oz woz prototyping workshop undergrad course ux design 2017 2022 purpose workshop familiarize student woz rapid low complexity prototyping method facilitate designing interactive system beyond typical graphical user interface workshop student develop test wizard oz prototype interactive spatial augmented reality sar past six year total 93 prototype created course analyzed prototype emerged workshop based input purpose play characteristic projection surface based analysis experience workshop conclude workshop stimulate creativity enable student rapidly create interactive sar interface without limited technical skill time limitation provide tool apply beyond scope prototyping course discus advantage limitation use woz prototyping interactive spatial augmented reality,paper present finding emerged wizard oz woz prototyping workshop undergrad course ux design 2017 2022 purpose workshop familiarize student woz rapid low complexity prototyping method facilitate designing interactive system beyond typical graphical user interface workshop student develop test wizard oz prototype interactive spatial augmented reality sar past six year total 93 prototype created course analyzed prototype emerged workshop based input purpose play characteristic projection surface based analysis experience workshop conclude workshop stimulate creativity enable student rapidly create interactive sar interface without limited technical skill time limitation provide tool apply beyond scope prototyping course discus advantage limitation use woz prototyping interactive spatial augmented realitycomputer_science_education graphical_user_interfaces human_computer_interaction interactive_systemsinteractive_sar_interfaces interactive_spatial_augmented_reality low complexity_prototyping_method prototyping_course rapid_prototyping undergrad_course ux_design wizard_of_oz_prototyping_workshops woz
56,Augmented Reality in Primary Education: Adopting the new normal in learning by easily using AR-based Android applications,"Roussos, G., Aliprantis, J., Alexandridis, G., & Caridakis, G. (2022). Augmented Reality in Primary Education: Adopting the new normal in learning by easily using AR-based Android applications. Proceedings of the 26th Pan-Hellenic Conference on Informatics. https://doi.org/10.1145/3575879.3576016
",10.1145/3575879.3576016,"Augmented Reality technologies can be considered to be a fascinating choice for educators seeking resources and methods to stimulate their students about the topic they teach. In recent years, the increasing number of relevant educational applications indicates that this new technology has the potential of becoming a leading educational method in schools and universities. The current work overviews the importance and impact of this technology in widening primary students' knowledge and how it can be used by teachers worldwide to motivate and broaden educational horizons. Furthermore, this work examines a wide number of augmented reality applications for the Android mobile operating system, available online for educational purposes and analyzes the ways in which they can be helpful for schoolteachers, lecturers, and parents.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",Android applications;Android mobile operating system;augmented reality applications;Augmented Reality technologies;educational horizons;educational purposes;fascinating choice;leading educational method;primary education;primary students;relevant educational applications;universities;wide number,Android (operating system);augmented reality;computer aided instruction;educational institutions;mobile computing;teaching,2022,Conference article (CA),PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics,"(1) Roussos, G.; (1) Aliprantis, J.; (1) Alexandridis, G.; (1) Caridakis, G.; ","(1) University of the Aegean, Greece; ",ACM,-1,"[""android"", ""computer aided instruction"", ""educational institutions"", ""mobile computing"", ""teaching""]","[""android"", ""computer aided instruction"", ""educational institutions"", ""mobile computing"", ""teaching""]",android;computer aided instruction;educational institutions;mobile computing;teaching,telecommunication;education;developers;training,technology;use cases;industries,telecommunication;education;developers;training,technology;use cases;industries,android computer_aided_instruction educational_institutions mobile_computing teaching android_applications android_mobile_operating_system augmented_reality_applications augmented_reality_technologies educational_horizons educational_purposes fascinating_choice leading_educational_method primary_education primary_students relevant_educational_applications universities wide_number c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication education developers training,android computer_aided_instruction educational_institutions mobile_computing teaching,android_applications android_mobile_operating_system augmented_reality_applications augmented_reality_technologies educational_horizons educational_purposes fascinating_choice leading_educational_method primary_education primary_students relevant_educational_applications universities wide_number,augmented reality technology considered fascinating choice educator seeking resource method stimulate student topic teach recent year increasing number relevant educational application indicates new technology potential becoming leading educational method school university current work overview importance impact technology widening primary student knowledge used teacher worldwide motivate broaden educational horizon furthermore work examines wide number augmented reality application android mobile operating system available online educational purpose analyzes way helpful schoolteacher lecturer parent,android computer_aided_instruction educational_institutions mobile_computing teaching android_applications android_mobile_operating_system augmented_reality_applications augmented_reality_technologies educational_horizons educational_purposes fascinating_choice leading_educational_method primary_education primary_students relevant_educational_applications universities wide_number c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication education developers training augmented reality technology considered fascinating choice educator seeking resource method stimulate student topic teach recent year increasing number relevant educational application indicates new technology potential becoming leading educational method school university current work overview importance impact technology widening primary student knowledge used teacher worldwide motivate broaden educational horizon furthermore work examines wide number augmented reality application android mobile operating system available online educational purpose analyzes way helpful schoolteacher lecturer parent,augmented reality technology considered fascinating choice educator seeking resource method stimulate student topic teach recent year increasing number relevant educational application indicates new technology potential becoming leading educational method school university current work overview importance impact technology widening primary student knowledge used teacher worldwide motivate broaden educational horizon furthermore work examines wide number augmented reality application android mobile operating system available online educational purpose analyzes way helpful schoolteacher lecturer parentandroid computer_aided_instruction educational_institutions mobile_computing teachingandroid_applications android_mobile_operating_system augmented_reality_applications augmented_reality_technologies educational_horizons educational_purposes fascinating_choice leading_educational_method primary_education primary_students relevant_educational_applications universities wide_number
57,UTAUT2 Model to Explain the Adoption of Augmented Reality Technology in Education: An Empirical Study in Morocco,"Benrahal, M., Bourhim, E. M., Dahane, A., Labti, O., & Akhiate, A. (2022). UTAUT2 Model to Explain the Adoption of Augmented Reality Technology in Education: An Empirical Study in Morocco. Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems, 491–500. https://doi.org/10.1007/978-3-031-20429-6_45
",10.1007/978-3-031-20429-6_45,"The use of Augmented Reality (AR) is recognized as the latest advances in technology that can serve as an educational device capable of improving learning outcomes. Previous research has found that learning through AR technology will help students understand knowledge more creatively and reach a high level of commitment to the learning system. In contrast, the acceptance behavior of AR in an educational setting has been examined by a limited amount of research. Therefore, it is necessary to understand the vitality of AR adoption to motivate learners to use this creative technology in education. In this regard, this study determined the factors of AR acceptance using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT 2). A total of 100 surveys were conducted. The results indicate that effort expectancy (EE), performance expectancy (PE), and social influence (SI) impact the behavioural intention (BI) to use AR-learning.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality,acceptance behavior;AR acceptance;AR adoption;AR technology;AR-learning;Augmented Reality Technology;creative technology;educational device;educational setting;learning outcomes;learning system;morocco;UTAUT 2;UTAUT2 model,augmented reality;computer aided instruction;human factors;technology acceptance model,2023,Conference article (CA),Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems: ICETIS 2022. Lecture Notes in Networks and Systems (573),"(1) Benrahal, M.; (2) Bourhim, E.M.; (1) Dahane, A.; (3) Labti, O.; (1) Akhiate, A.; ","(1) Universite Hassan II de Casablanca, Artificial Intelligence and Complex Systems Engineering (AICSE), Morocco; (2) Mohammed V University, Industrial Engineering Department, Morocco; (3) Universite Hassan II de Casablanca, Laboratory of Research in Management, Morocco; (4) Moroccan Association of Innovation and Scientific Research in Artificial Intelligence and Extended Reality, Morocco; ",Springer,-1,"[""computer aided instruction"", ""human factors"", ""technology acceptance model""]","[""computer aided instruction"", ""human factors"", ""technology acceptance model""]",computer aided instruction;human factors;technology acceptance model,human factors;training;human-computer interaction,use cases;end users and user experience,human factors;training;human-computer interaction,use cases;end users and user experience,computer_aided_instruction human_factors technology_acceptance_model acceptance_behavior ar_acceptance ar_adoption ar_technology ar learning augmented_reality_technology creative_technology educational_device educational_setting learning_outcomes learning_system morocco utaut_2 utaut2_model c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality human_factors training human computer_interaction,computer_aided_instruction human_factors technology_acceptance_model,acceptance_behavior ar_acceptance ar_adoption ar_technology ar learning augmented_reality_technology creative_technology educational_device educational_setting learning_outcomes learning_system morocco utaut_2 utaut2_model,use augmented reality ar recognized latest advance technology serve educational device capable improving learning outcome previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance using unified theory acceptance use technology 2 utaut 2 total 100 survey conducted result indicate effort expectancy ee performance expectancy pe social influence si impact behavioural intention bi use ar learning,computer_aided_instruction human_factors technology_acceptance_model acceptance_behavior ar_acceptance ar_adoption ar_technology ar learning augmented_reality_technology creative_technology educational_device educational_setting learning_outcomes learning_system morocco utaut_2 utaut2_model c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality human_factors training human computer_interaction use augmented reality ar recognized latest advance technology serve educational device capable improving learning outcome previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance using unified theory acceptance use technology 2 utaut 2 total 100 survey conducted result indicate effort expectancy ee performance expectancy pe social influence si impact behavioural intention bi use ar learning,use augmented reality ar recognized latest advance technology serve educational device capable improving learning outcome previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance using unified theory acceptance use technology 2 utaut 2 total 100 survey conducted result indicate effort expectancy ee performance expectancy pe social influence si impact behavioural intention bi use ar learningcomputer_aided_instruction human_factors technology_acceptance_modelacceptance_behavior ar_acceptance ar_adoption ar_technology ar learning augmented_reality_technology creative_technology educational_device educational_setting learning_outcomes learning_system morocco utaut_2 utaut2_model
58,XAIR: A Framework of Explainable AI in Augmented Reality,"Xu, X., Yu, A., Jonker, T. R., Todi, K., Lu, F., Qian, X., Evangelista Belo, J. M., Wang, T., Li, M., Mun, A., Wu, T.-Y., Shen, J., Zhang, T., Kokhlikyan, N., Wang, F., Sorenson, P., Kim, S., & Benko, H. (2023). XAIR: A Framework of Explainable AI in Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581500
",10.1145/3544548.3581500,"Explainable AI (XAI) has established itself as an important component of AI-driven interactive systems. With Augmented Reality (AR) becoming more integrated in daily lives, the role of XAI also becomes essential in AR because end-users will frequently interact with intelligent services. However, it is unclear how to design effective XAI experiences for AR. We propose XAIR, a design framework that addresses when, what, and how to provide explanations of AI output in AR. The framework was based on a multi-disciplinary literature review of XAI and HCI research, a large-scale survey probing 500+ end-users' preferences for AR-based explanations, and three workshops with 12 experts collecting their insights about XAI design in AR. XAIR's utility and effectiveness was verified via a study with 10 designers and another study with 12 end-users. XAIR can provide guidelines for designers, inspiring them to identify new design opportunities and achieve effective XAI designs in AR.",C6130V Virtual reality;C6180 User interfaces;C6210 Knowledge based systems,AI-driven interactive systems;AR-based explanations;Augmented Reality;design framework;design opportunities;effective XAI designs;effective XAI experiences;explainable AI;HCI research;intelligent services;multidisciplinary literature review;XAIR,artificial intelligence;augmented reality;human computer interaction;interactive systems,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Xu, X.; (2) Yu, A.; (3) Jonker, T.R.; (2) Todi, K.; (4) Lu, F.; (5) Qian, X.; (6) Evangelista Belo, J.M.; (2) Wang, T.; (2) Li, M.; (2) Mun, A.; (7) Wu, T.-Y.; (8) Shen, J.; (9) Zhang, T.; (10) Kokhlikyan, N.; (2) Wang, F.; (2) Sorenson, P.; (11) Kim, S.; (12) Benko, H.; ","(1) University of Washington, Reality Labs Research, Seattle, WA, United States; (2) Reality Labs Research, United States; (3) Facebook Reality Labs: Research, Menlo Park, CA, United States; (4) Computational Sciences (United States), Reality Labs Research, Madison, AL, United States; (5) Purdue University West Lafayette, Reality Labs Research, West Lafayette, IN, United States; (6) Aarhus University, Department of Computer Science, Denmark; (7) Dartmouth College, Reality Labs Research, United States; (8) University of Cambridge, United States and Department of Engineering, United Kingdom; (9) Chan Zuckerberg Initiative, Reality Labs Research, Palo Alto, CA, United States; (10) Facebook, Menlo Park, CA, United States; (11) Facebook Reality Labs, Menlo Park, CA, United States; (12) Meta Platforms Inc, Reality Labs Research, Seattle, WA, United States; ",ACM,-1,"[""artificial intelligence"", ""human computer interaction"", ""interactive systems""]","[""artificial intelligence"", ""human computer interaction"", ""interactive systems""]",artificial intelligence;human computer interaction;interactive systems,education;input;liberal arts;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,education;input;liberal arts;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,artificial_intelligence human_computer_interaction interactive_systems ai driven_interactive_systems ar based_explanations augmented_reality design_framework design_opportunities effective_xai_designs effective_xai_experiences explainable_ai hci_research intelligent_services multidisciplinary_literature_review xair c6130v_virtual_reality c6180_user_interfaces c6210_knowledge_based_systems education input liberal_arts human computer_interaction artificial_intelligence,artificial_intelligence human_computer_interaction interactive_systems,ai driven_interactive_systems ar based_explanations augmented_reality design_framework design_opportunities effective_xai_designs effective_xai_experiences explainable_ai hci_research intelligent_services multidisciplinary_literature_review xair,explainable ai xai established important component ai driven interactive system augmented reality ar becoming integrated daily life role xai also becomes essential ar end user frequently interact intelligent service however unclear design effective xai experience ar propose xair design framework address provide explanation ai output ar framework based multi disciplinary literature review xai hci research large scale survey probing 500 end user preference ar based explanation three workshop 12 expert collecting insight xai design ar xair utility effectiveness verified via study 10 designer another study 12 end user xair provide guideline designer inspiring identify new design opportunity achieve effective xai design ar,artificial_intelligence human_computer_interaction interactive_systems ai driven_interactive_systems ar based_explanations augmented_reality design_framework design_opportunities effective_xai_designs effective_xai_experiences explainable_ai hci_research intelligent_services multidisciplinary_literature_review xair c6130v_virtual_reality c6180_user_interfaces c6210_knowledge_based_systems education input liberal_arts human computer_interaction artificial_intelligence explainable ai xai established important component ai driven interactive system augmented reality ar becoming integrated daily life role xai also becomes essential ar end user frequently interact intelligent service however unclear design effective xai experience ar propose xair design framework address provide explanation ai output ar framework based multi disciplinary literature review xai hci research large scale survey probing 500 end user preference ar based explanation three workshop 12 expert collecting insight xai design ar xair utility effectiveness verified via study 10 designer another study 12 end user xair provide guideline designer inspiring identify new design opportunity achieve effective xai design ar,explainable ai xai established important component ai driven interactive system augmented reality ar becoming integrated daily life role xai also becomes essential ar end user frequently interact intelligent service however unclear design effective xai experience ar propose xair design framework address provide explanation ai output ar framework based multi disciplinary literature review xai hci research large scale survey probing 500 end user preference ar based explanation three workshop 12 expert collecting insight xai design ar xair utility effectiveness verified via study 10 designer another study 12 end user xair provide guideline designer inspiring identify new design opportunity achieve effective xai design arartificial_intelligence human_computer_interaction interactive_systemsai driven_interactive_systems ar based_explanations augmented_reality design_framework design_opportunities effective_xai_designs effective_xai_experiences explainable_ai hci_research intelligent_services multidisciplinary_literature_review xair
59,"ARctic Escape: Promoting Social Connection, Teamwork, and Collaboration Using a Co-Located Augmented Reality Escape Room","Knoll, T., Liaqat, A., & Monroy-Hernández, A. (2023). ARctic Escape: Promoting Social Connection, Teamwork, and Collaboration Using a Co-Located Augmented Reality Escape Room. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585841
",10.1145/3544549.3585841,"We present ARctic Escape, a co-located augmented reality (AR) escape room designed to promote collaboration between dyads through play. While physical escape rooms provide groups with fun, social experiences, they require a gameplay venue, props, and a game master, all of which detract from their ease of access. Existing AR escape rooms demonstrate that AR can make escape room experiences easier to access. Still, many AR escape rooms are single-player and therefore fail to maintain the social and collaborative elements of their physical counterparts. This paper presents ARctic Escape, a two-person AR escape room with clues emphasizing player interaction and teamwork. We evaluated ARctic Escape by conducting semi-structured interviews with four dyads to learn about participants' interpersonal dynamics and experiences during gameplay. We found that participants thought the experience was fun, collaborative, promoted discussion, and inspired new social dynamics, but sometimes the escape room's reliance on virtual content was disorienting.",C7830D Computer games;C0240 Ergonomic aspects of computing;C6130V Virtual reality,AR escape rooms;ARctic Escape;augmented reality escape room;collaborative elements;escape room experiences;physical escape rooms;promoted discussion;promoting social connection;social elements;two-person AR escape room,augmented reality;computer games;human computer interaction;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Knoll, T.; (1) Liaqat, A.; (2) Monroy-Herna&#769;ndez, A.; ","(1) Princeton University, Department of Computer Science, Princeton, NJ, United States; (2) Princeton University, Computer Science, Princeton, NJ, United States; ",ACM,-1,"[""computer games"", ""human computer interaction""]","[""computer games"", ""human computer interaction""]",computer games;human computer interaction,liberal arts;human-computer interaction,industries;end users and user experience,liberal arts;human-computer interaction,industries;end users and user experience,computer_games human_computer_interaction ar_escape_rooms arctic_escape augmented_reality_escape_room collaborative_elements escape_room_experiences physical_escape_rooms promoted_discussion promoting_social_connection social_elements two person_ar_escape_room c7830d_computer_games c0240_ergonomic_aspects_of_computing c6130v_virtual_reality liberal_arts human computer_interaction,computer_games human_computer_interaction,ar_escape_rooms arctic_escape augmented_reality_escape_room collaborative_elements escape_room_experiences physical_escape_rooms promoted_discussion promoting_social_connection social_elements two person_ar_escape_room,present arctic escape co located augmented reality ar escape room designed promote collaboration dyad play physical escape room provide group fun social experience require gameplay venue prop game master detract ease access existing ar escape room demonstrate ar make escape room experience easier access still many ar escape room single player therefore fail maintain social collaborative element physical counterpart paper present arctic escape two person ar escape room clue emphasizing player interaction teamwork evaluated arctic escape conducting semi structured interview four dyad learn participant interpersonal dynamic experience gameplay found participant thought experience fun collaborative promoted discussion inspired new social dynamic sometimes escape room reliance virtual content disorienting,computer_games human_computer_interaction ar_escape_rooms arctic_escape augmented_reality_escape_room collaborative_elements escape_room_experiences physical_escape_rooms promoted_discussion promoting_social_connection social_elements two person_ar_escape_room c7830d_computer_games c0240_ergonomic_aspects_of_computing c6130v_virtual_reality liberal_arts human computer_interaction present arctic escape co located augmented reality ar escape room designed promote collaboration dyad play physical escape room provide group fun social experience require gameplay venue prop game master detract ease access existing ar escape room demonstrate ar make escape room experience easier access still many ar escape room single player therefore fail maintain social collaborative element physical counterpart paper present arctic escape two person ar escape room clue emphasizing player interaction teamwork evaluated arctic escape conducting semi structured interview four dyad learn participant interpersonal dynamic experience gameplay found participant thought experience fun collaborative promoted discussion inspired new social dynamic sometimes escape room reliance virtual content disorienting,present arctic escape co located augmented reality ar escape room designed promote collaboration dyad play physical escape room provide group fun social experience require gameplay venue prop game master detract ease access existing ar escape room demonstrate ar make escape room experience easier access still many ar escape room single player therefore fail maintain social collaborative element physical counterpart paper present arctic escape two person ar escape room clue emphasizing player interaction teamwork evaluated arctic escape conducting semi structured interview four dyad learn participant interpersonal dynamic experience gameplay found participant thought experience fun collaborative promoted discussion inspired new social dynamic sometimes escape room reliance virtual content disorientingcomputer_games human_computer_interactionar_escape_rooms arctic_escape augmented_reality_escape_room collaborative_elements escape_room_experiences physical_escape_rooms promoted_discussion promoting_social_connection social_elements two person_ar_escape_room
60,Simulating Wearable Urban Augmented Reality Experiences in VR: Lessons Learnt from Designing Two Future Urban Interfaces,"Tran, T. T. M., Parker, C., Hoggenmüller, M., Hespanhol, L., & Tomitsch, M. (2023). Simulating Wearable Urban Augmented Reality Experiences in VR: Lessons Learnt from Designing Two Future Urban Interfaces. Multimodal Technologies and Interaction, 7(2), 21. https://doi.org/10.3390/mti7020021
",10.3390/mti7020021,"Augmented reality (AR) has the potential to fundamentally change how people engage with increasingly interactive urban environments. However, many challenges exist in designing and evaluating these new urban AR experiences, such as technical constraints and safety concerns associated with outdoor AR. We contribute to this domain by assessing the use of virtual reality (VR) for simulating wearable urban AR experiences, allowing participants to interact with future AR interfaces in a realistic, safe and controlled setting. This paper describes two wearable urban AR applications (pedestrian navigation and autonomous mobility) simulated in VR. Based on a thematic analysis of interview data collected across the two studies, we find that the VR simulation successfully elicited feedback on the functional benefits of AR concepts and the potential impact of urban contextual factors, such as safety concerns, attentional capacity, and social considerations. At the same time, we highlight the limitations of this approach in terms of assessing the AR interface's visual quality and providing exhaustive contextual information. The paper concludes with recommendations for simulating wearable urban AR experiences in VR.",C6130V Virtual reality;C3390C Mobile robots;C6180 User interfaces,controlled setting;designing two future urban interfaces;future AR interfaces;increasingly interactive urban environments;lessons learnt;realistic setting;safe setting;urban contextual factors;virtual reality;VR simulation;wearable urban AR applications;wearable urban AR experiences;wearable urban augmented reality experiences,augmented reality;mobile robots;virtual reality,2023,Journal article (JA),Multimodal Technol. Interact. (Switzerland),"(1) Tran, T.T.M.; (1) Parker, C.; (1) Hoggenmu&#776;ller, M.; (1) Hespanhol, L.; (1) Tomitsch, M.; ","(1) University of Sydney, Sydney School of Architecture, NSW 2006, Sydney, NSW NSW 2006, Australia; ",MDPI,-1,"[""mobile robots""]","[""mobile robots""]",mobile robots,robotics,technology,robotics,technology,mobile_robots controlled_setting designing_two_future_urban_interfaces future_ar_interfaces increasingly_interactive_urban_environments lessons_learnt realistic_setting safe_setting urban_contextual_factors virtual_reality vr_simulation wearable_urban_ar_applications wearable_urban_ar_experiences wearable_urban_augmented_reality_experiences c6130v_virtual_reality c3390c_mobile_robots c6180_user_interfaces robotics,mobile_robots,controlled_setting designing_two_future_urban_interfaces future_ar_interfaces increasingly_interactive_urban_environments lessons_learnt realistic_setting safe_setting urban_contextual_factors virtual_reality vr_simulation wearable_urban_ar_applications wearable_urban_ar_experiences wearable_urban_augmented_reality_experiences,augmented reality ar potential fundamentally change people engage increasingly interactive urban environment however many challenge exist designing evaluating new urban ar experience technical constraint safety concern associated outdoor ar contribute domain assessing use virtual reality vr simulating wearable urban ar experience allowing participant interact future ar interface realistic safe controlled setting paper describes two wearable urban ar application pedestrian navigation autonomous mobility simulated vr based thematic analysis interview data collected across two study find vr simulation successfully elicited feedback functional benefit ar concept potential impact urban contextual factor safety concern attentional capacity social consideration time highlight limitation approach term assessing ar interface visual quality providing exhaustive contextual information paper concludes recommendation simulating wearable urban ar experience vr,mobile_robots controlled_setting designing_two_future_urban_interfaces future_ar_interfaces increasingly_interactive_urban_environments lessons_learnt realistic_setting safe_setting urban_contextual_factors virtual_reality vr_simulation wearable_urban_ar_applications wearable_urban_ar_experiences wearable_urban_augmented_reality_experiences c6130v_virtual_reality c3390c_mobile_robots c6180_user_interfaces robotics augmented reality ar potential fundamentally change people engage increasingly interactive urban environment however many challenge exist designing evaluating new urban ar experience technical constraint safety concern associated outdoor ar contribute domain assessing use virtual reality vr simulating wearable urban ar experience allowing participant interact future ar interface realistic safe controlled setting paper describes two wearable urban ar application pedestrian navigation autonomous mobility simulated vr based thematic analysis interview data collected across two study find vr simulation successfully elicited feedback functional benefit ar concept potential impact urban contextual factor safety concern attentional capacity social consideration time highlight limitation approach term assessing ar interface visual quality providing exhaustive contextual information paper concludes recommendation simulating wearable urban ar experience vr,augmented reality ar potential fundamentally change people engage increasingly interactive urban environment however many challenge exist designing evaluating new urban ar experience technical constraint safety concern associated outdoor ar contribute domain assessing use virtual reality vr simulating wearable urban ar experience allowing participant interact future ar interface realistic safe controlled setting paper describes two wearable urban ar application pedestrian navigation autonomous mobility simulated vr based thematic analysis interview data collected across two study find vr simulation successfully elicited feedback functional benefit ar concept potential impact urban contextual factor safety concern attentional capacity social consideration time highlight limitation approach term assessing ar interface visual quality providing exhaustive contextual information paper concludes recommendation simulating wearable urban ar experience vrmobile_robotscontrolled_setting designing_two_future_urban_interfaces future_ar_interfaces increasingly_interactive_urban_environments lessons_learnt realistic_setting safe_setting urban_contextual_factors virtual_reality vr_simulation wearable_urban_ar_applications wearable_urban_ar_experiences wearable_urban_augmented_reality_experiences
61,A New Augmented Reality System for Calculating Social Distancing between Children at School,"Alshaweesh, O., Wedyan, M., Alazab, M., Abu-Salih, B., & Al-Jumaily, A. (2023). A New Augmented Reality System for Calculating Social Distancing between Children at School. Electronics, 12(2), 358. https://doi.org/10.3390/electronics12020358
",10.3390/electronics12020358,"Social distancing is one of the most important ways to prevent many diseases, especially the respiratory system, where the latest internationally spread is coronavirus disease, and it will not be the last. The spreading of this pandemic has become a major threat to human life, especially to the elderly and people suffering from chronic diseases. During the Corona pandemic, medical authorities were keen to control the spread through social distancing and monitoring it in markets, universities, and schools. This monitoring was mostly used to estimate the distance with the naked eye and interfere with estimating the distance on the observer only. In this study, a computer application was designed to monitor social distancing in closed areas, especially in schools and kindergartens, using a fast, effective and unobtrusive technique for children. In addition to this system, we use augmented reality to help to determine the location of violation of social distancing. This system was tested, and the results were accurate exceeding 98.5%.",C6130V Virtual reality;C7110 Educational administration;C7330 Biology and medical computing,Children;chronic diseases;closed areas;computer application;Corona pandemic;coronavirus disease;elderly;kindergartens;medical authorities;new augmented reality system;respiratory system;schools;social distancing;social distancing calculation;unobtrusive technique,augmented reality;diseases;educational institutions;epidemics;medical computing;paediatrics,2023,Journal article (JA),Electronics (Switzerland),"(1) Alshaweesh, O.; (2) Wedyan, M.; (2) Alazab, M.; (3) Abu-Salih, B.; (4) Al-Jumaily, A.; ","(1) Al-Hussein Bin Talal University, Department of Software Engineering, Jordan; (2) Al-Balqa` Applied University, Department of Autonomous Systems, Jordan; (3) University of Jordan, Computer Science Department, Jordan; (4) Universiti Teknologi, Faculty of Engineering, Brunei; (5) Ecole Nationale Superieure de Techniques Avancees Bretagne, France; (6) Charles Sturt University, School of Computing Mathematics and Engineering, Wagga Wagga, NSW 2678, Australia; (7) Edith Cowan University, School of Science, Joondalup, WA 6027, Australia; ",MDPI,-1,"[""diseases"", ""educational institutions"", ""epidemics"", ""medical computing"", ""paediatrics""]","[""diseases"", ""educational institutions"", ""epidemics"", ""medical computing"", ""paediatrics""]",diseases;educational institutions;epidemics;medical computing;paediatrics,medical;education,industries,medical;education,industries,diseases educational_institutions epidemics medical_computing paediatrics children chronic_diseases closed_areas computer_application corona_pandemic coronavirus_disease elderly kindergartens medical_authorities new_augmented_reality_system respiratory_system schools social_distancing social_distancing_calculation unobtrusive_technique c6130v_virtual_reality c7110_educational_administration c7330_biology_and_medical_computing medical education,diseases educational_institutions epidemics medical_computing paediatrics,children chronic_diseases closed_areas computer_application corona_pandemic coronavirus_disease elderly kindergartens medical_authorities new_augmented_reality_system respiratory_system schools social_distancing social_distancing_calculation unobtrusive_technique,social distancing one important way prevent many disease especially respiratory system latest internationally spread coronavirus disease last spreading pandemic become major threat human life especially elderly people suffering chronic disease corona pandemic medical authority keen control spread social distancing monitoring market university school monitoring mostly used estimate distance naked eye interfere estimating distance observer study computer application designed monitor social distancing closed area especially school kindergarten using fast effective unobtrusive technique child addition system use augmented reality help determine location violation social distancing system tested result accurate exceeding 98 5,diseases educational_institutions epidemics medical_computing paediatrics children chronic_diseases closed_areas computer_application corona_pandemic coronavirus_disease elderly kindergartens medical_authorities new_augmented_reality_system respiratory_system schools social_distancing social_distancing_calculation unobtrusive_technique c6130v_virtual_reality c7110_educational_administration c7330_biology_and_medical_computing medical education social distancing one important way prevent many disease especially respiratory system latest internationally spread coronavirus disease last spreading pandemic become major threat human life especially elderly people suffering chronic disease corona pandemic medical authority keen control spread social distancing monitoring market university school monitoring mostly used estimate distance naked eye interfere estimating distance observer study computer application designed monitor social distancing closed area especially school kindergarten using fast effective unobtrusive technique child addition system use augmented reality help determine location violation social distancing system tested result accurate exceeding 98 5,social distancing one important way prevent many disease especially respiratory system latest internationally spread coronavirus disease last spreading pandemic become major threat human life especially elderly people suffering chronic disease corona pandemic medical authority keen control spread social distancing monitoring market university school monitoring mostly used estimate distance naked eye interfere estimating distance observer study computer application designed monitor social distancing closed area especially school kindergarten using fast effective unobtrusive technique child addition system use augmented reality help determine location violation social distancing system tested result accurate exceeding 98 5diseases educational_institutions epidemics medical_computing paediatricschildren chronic_diseases closed_areas computer_application corona_pandemic coronavirus_disease elderly kindergartens medical_authorities new_augmented_reality_system respiratory_system schools social_distancing social_distancing_calculation unobtrusive_technique
62,User Acceptance of Augmented Reality in Education: An Analysis Based on the TAM Model,"Bourhim, E. M., & Labti, O. (2022). User Acceptance of Augmented Reality in Education: An Analysis Based on the TAM Model. Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems, 481–490. https://doi.org/10.1007/978-3-031-20429-6_44
",10.1007/978-3-031-20429-6_44,"Augmented reality (AR) is increasingly recognized in various fields, especially in educational processes. Previous research has found that learning through AR technology will help students understand knowledge more creatively and reach a high level of commitment to the learning system. In contrast, the acceptance behavior of AR in an educational setting has been examined by a limited amount of research. Therefore, it is necessary to understand the vitality of AR adoption to motivate learners to use this creative technology in education. In this regard, this study determined the factors of AR acceptance based on the technology acceptance model (TAM). A total of 91 surveys were conducted. The results reveal the positive impact of attitude and perceived usefulness (PU) on intentional behavior (BI) in the adoption of AR in education. The proposed model explains 72% of the variance in behavioral intention to use AR in learning.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality,acceptance behavior;AR acceptance;AR technology;augmented reality;behavioral intention;creative technology;educational processes;educational setting;intentional behavior;learning system;TAM model;technology acceptance model;user acceptance,augmented reality;computer aided instruction;human factors;technology acceptance model,2023,Conference article (CA),Proceedings of the 2nd International Conference on Emerging Technologies and Intelligent Systems: ICETIS 2022. Lecture Notes in Networks and Systems (573),"(1) Bourhim, E.M.; (2) Labti, O.; ","(1) Mohammed V University, Industrial Engineering Department, Morocco; (2) Universite Hassan II de Casablanca, Laboratory of Research in Management, Morocco; (3) BP.154, Moroccan Association of Innovation and Scientific Research in Artificial Intelligence and Extended Reality, Morocco; ",Springer,-1,"[""computer aided instruction"", ""human factors"", ""technology acceptance model""]","[""computer aided instruction"", ""human factors"", ""technology acceptance model""]",computer aided instruction;human factors;technology acceptance model,human factors;training;human-computer interaction,use cases;end users and user experience,human factors;training;human-computer interaction,use cases;end users and user experience,computer_aided_instruction human_factors technology_acceptance_model acceptance_behavior ar_acceptance ar_technology augmented_reality behavioral_intention creative_technology educational_processes educational_setting intentional_behavior learning_system tam_model technology_acceptance_model user_acceptance c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality human_factors training human computer_interaction,computer_aided_instruction human_factors technology_acceptance_model,acceptance_behavior ar_acceptance ar_technology augmented_reality behavioral_intention creative_technology educational_processes educational_setting intentional_behavior learning_system tam_model technology_acceptance_model user_acceptance,augmented reality ar increasingly recognized various field especially educational process previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance based technology acceptance model tam total 91 survey conducted result reveal positive impact attitude perceived usefulness pu intentional behavior bi adoption ar education proposed model explains 72 variance behavioral intention use ar learning,computer_aided_instruction human_factors technology_acceptance_model acceptance_behavior ar_acceptance ar_technology augmented_reality behavioral_intention creative_technology educational_processes educational_setting intentional_behavior learning_system tam_model technology_acceptance_model user_acceptance c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality human_factors training human computer_interaction augmented reality ar increasingly recognized various field especially educational process previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance based technology acceptance model tam total 91 survey conducted result reveal positive impact attitude perceived usefulness pu intentional behavior bi adoption ar education proposed model explains 72 variance behavioral intention use ar learning,augmented reality ar increasingly recognized various field especially educational process previous research found learning ar technology help student understand knowledge creatively reach high level commitment learning system contrast acceptance behavior ar educational setting examined limited amount research therefore necessary understand vitality ar adoption motivate learner use creative technology education regard study determined factor ar acceptance based technology acceptance model tam total 91 survey conducted result reveal positive impact attitude perceived usefulness pu intentional behavior bi adoption ar education proposed model explains 72 variance behavioral intention use ar learningcomputer_aided_instruction human_factors technology_acceptance_modelacceptance_behavior ar_acceptance ar_technology augmented_reality behavioral_intention creative_technology educational_processes educational_setting intentional_behavior learning_system tam_model technology_acceptance_model user_acceptance
63,HARIN: HoloLens Augmented Reality Indoor Navigation,"Lynam, H., Folmer, E., & Dascalu, S. (2022). HARIN: HoloLens Augmented Reality Indoor Navigation. Proceedings of the 9th International Conference on Applied Computing &amp; Information Technology. https://doi.org/10.1145/3543895.3543938
",10.1145/3543895.3543938,"This paper describes a proposed augmented reality software called HARIN for indoor navigation. Navigating buildings poses a significant problem to a variety of populations, including disabled individuals and maintenance workers. The general population also faces difficulties navigating larger, or unfamiliar, buildings; the potential benefits of a solution are significant in scope. Initial solution attempts have been produced successfully in other research, however there is much room for improvement, particularly in user interface design and localization accuracy. To pursue these improvements, this paper proposes an AR indoor navigation using the HoloLens as a platform for new types of navigation markers to improve user experiences and decrease location estimate error. A proof-of-concept software prototype for a part of the overall HARIN system is shown, and future work is discussed.",C6130V Virtual reality;C6180 User interfaces;C7850 Computer assistance for persons with handicaps,AR indoor navigation;augmented reality software;disabled individuals;HARIN system;HoloLens augmented reality indoor navigation;initial solution attempts;localization accuracy;maintenance workers;navigating buildings;navigation markers;proof-of-concept software prototype;user interface design,augmented reality;handicapped aids;indoor navigation;user experience;user interfaces,2022,Conference article (CA),ACIT '22: Proceedings of the 9th International Conference on Applied Computing &amp; Information Technology,"(1) Lynam, H.; (1) Folmer, E.; (1) Dascalu, S.; ","(1) University of Nevada Reno, Reno, NV, United States; ",ACM,-1,"[""handicapped aids"", ""indoor navigation"", ""user experience"", ""user interfaces""]","[""handicapped aids"", ""indoor navigation"", ""user experience"", ""user interfaces""]",handicapped aids;indoor navigation;user experience;user interfaces,medical;human factors;navigation;human-computer interaction,industries;use cases;end users and user experience,medical;human factors;navigation;human-computer interaction,industries;use cases;end users and user experience,handicapped_aids indoor_navigation user_experience user_interfaces ar_indoor_navigation augmented_reality_software disabled_individuals harin_system hololens_augmented_reality_indoor_navigation initial_solution_attempts localization_accuracy maintenance_workers navigating_buildings navigation_markers proof of concept_software_prototype user_interface_design c6130v_virtual_reality c6180_user_interfaces c7850_computer_assistance_for_persons_with_handicaps medical human_factors navigation human computer_interaction,handicapped_aids indoor_navigation user_experience user_interfaces,ar_indoor_navigation augmented_reality_software disabled_individuals harin_system hololens_augmented_reality_indoor_navigation initial_solution_attempts localization_accuracy maintenance_workers navigating_buildings navigation_markers proof of concept_software_prototype user_interface_design,paper describes proposed augmented reality software called harin indoor navigation navigating building pose significant problem variety population including disabled individual maintenance worker general population also face difficulty navigating larger unfamiliar building potential benefit solution significant scope initial solution attempt produced successfully research however much room improvement particularly user interface design localization accuracy pursue improvement paper proposes ar indoor navigation using hololens platform new type navigation marker improve user experience decrease location estimate error proof concept software prototype part overall harin system shown future work discussed,handicapped_aids indoor_navigation user_experience user_interfaces ar_indoor_navigation augmented_reality_software disabled_individuals harin_system hololens_augmented_reality_indoor_navigation initial_solution_attempts localization_accuracy maintenance_workers navigating_buildings navigation_markers proof of concept_software_prototype user_interface_design c6130v_virtual_reality c6180_user_interfaces c7850_computer_assistance_for_persons_with_handicaps medical human_factors navigation human computer_interaction paper describes proposed augmented reality software called harin indoor navigation navigating building pose significant problem variety population including disabled individual maintenance worker general population also face difficulty navigating larger unfamiliar building potential benefit solution significant scope initial solution attempt produced successfully research however much room improvement particularly user interface design localization accuracy pursue improvement paper proposes ar indoor navigation using hololens platform new type navigation marker improve user experience decrease location estimate error proof concept software prototype part overall harin system shown future work discussed,paper describes proposed augmented reality software called harin indoor navigation navigating building pose significant problem variety population including disabled individual maintenance worker general population also face difficulty navigating larger unfamiliar building potential benefit solution significant scope initial solution attempt produced successfully research however much room improvement particularly user interface design localization accuracy pursue improvement paper proposes ar indoor navigation using hololens platform new type navigation marker improve user experience decrease location estimate error proof concept software prototype part overall harin system shown future work discussedhandicapped_aids indoor_navigation user_experience user_interfacesar_indoor_navigation augmented_reality_software disabled_individuals harin_system hololens_augmented_reality_indoor_navigation initial_solution_attempts localization_accuracy maintenance_workers navigating_buildings navigation_markers proof of concept_software_prototype user_interface_design
64,"Virtual reality, augmented reality and mixed reality: For astronaut mental health; and space tourism, education and outreach","Holt, S. (2023). Virtual reality, augmented reality and mixed reality: For astronaut mental health; and space tourism, education and outreach. Acta Astronautica, 203, 436–446. https://doi.org/10.1016/j.actaastro.2022.12.016
",10.1016/j.actaastro.2022.12.016,"Virtual reality (VR), augmented reality (AR) and mixed reality (MR) can evoke a sense of presence, where a person can feel as though they are physically present in a virtual environment. The intention of this research is to understand whether VR/AR/MR can create human connection and experience through interactions with virtual environments to assist in the prevention and treatment of psychological impacts to astronaut health during long-term and long-distance space missions (experiencing Earth from space); and for space tourism, education and outreach purposes as a cost-effective way for people to experience space; to help people understand how important the space industry is to our lives; and to inspire future careers (experiencing space from Earth). Qualitative literature review was undertaken to understand current and potential future VR/AR/MR technologies and how they are being used in psychology; in space; for astronaut mental health in space; for two-way communication; for general tourism, education and outreach purposes; and for space tourism, space education and space outreach purposes. Recommendations are proposed for further study into VR/AR/MR as a tool for astronaut mental health and wellbeing; and for further development of VR/AR/MR experiences for space tourism, education and outreach purposes. All rights reserved Elsevier.",C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6180 User interfaces,AR;astronaut mental health;augmented reality;experiencing space;human connection;long-distance space missions;mixed reality;MR;outreach purposes;space education;space industry;space tourism;virtual environment;virtual reality;VR,augmented reality;psychology;space research;travel industry;virtual reality,2023,Journal article (JA),Acta Astronaut. (Netherlands),"(1) Holt, S.; ","(1) University of South Australia, Adelaide, SA 5095, Australia; ",Elsevier B.V.,-1,"[""psychology"", ""space research"", ""travel industry""]","[""psychology"", ""space research"", ""travel industry""]",psychology;space research;travel industry,medical;education;aviation and aerospace;transportation,industries,medical;education;aviation and aerospace;transportation,industries,psychology space_research travel_industry ar astronaut_mental_health augmented_reality experiencing_space human_connection long distance_space_missions mixed_reality mr outreach_purposes space_education space_industry space_tourism virtual_environment virtual_reality vr c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces medical education aviation_and_aerospace transportation,psychology space_research travel_industry,ar astronaut_mental_health augmented_reality experiencing_space human_connection long distance_space_missions mixed_reality mr outreach_purposes space_education space_industry space_tourism virtual_environment virtual_reality vr,virtual reality vr augmented reality ar mixed reality mr evoke sense presence person feel though physically present virtual environment intention research understand whether vr ar mr create human connection experience interaction virtual environment assist prevention treatment psychological impact astronaut health long term long distance space mission experiencing earth space space tourism education outreach purpose cost effective way people experience space help people understand important space industry life inspire future career experiencing space earth qualitative literature review undertaken understand current potential future vr ar mr technology used psychology space astronaut mental health space two way communication general tourism education outreach purpose space tourism space education space outreach purpose recommendation proposed study vr ar mr tool astronaut mental health wellbeing development vr ar mr experience space tourism education outreach purpose right reserved elsevier,psychology space_research travel_industry ar astronaut_mental_health augmented_reality experiencing_space human_connection long distance_space_missions mixed_reality mr outreach_purposes space_education space_industry space_tourism virtual_environment virtual_reality vr c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces medical education aviation_and_aerospace transportation virtual reality vr augmented reality ar mixed reality mr evoke sense presence person feel though physically present virtual environment intention research understand whether vr ar mr create human connection experience interaction virtual environment assist prevention treatment psychological impact astronaut health long term long distance space mission experiencing earth space space tourism education outreach purpose cost effective way people experience space help people understand important space industry life inspire future career experiencing space earth qualitative literature review undertaken understand current potential future vr ar mr technology used psychology space astronaut mental health space two way communication general tourism education outreach purpose space tourism space education space outreach purpose recommendation proposed study vr ar mr tool astronaut mental health wellbeing development vr ar mr experience space tourism education outreach purpose right reserved elsevier,virtual reality vr augmented reality ar mixed reality mr evoke sense presence person feel though physically present virtual environment intention research understand whether vr ar mr create human connection experience interaction virtual environment assist prevention treatment psychological impact astronaut health long term long distance space mission experiencing earth space space tourism education outreach purpose cost effective way people experience space help people understand important space industry life inspire future career experiencing space earth qualitative literature review undertaken understand current potential future vr ar mr technology used psychology space astronaut mental health space two way communication general tourism education outreach purpose space tourism space education space outreach purpose recommendation proposed study vr ar mr tool astronaut mental health wellbeing development vr ar mr experience space tourism education outreach purpose right reserved elsevierpsychology space_research travel_industryar astronaut_mental_health augmented_reality experiencing_space human_connection long distance_space_missions mixed_reality mr outreach_purposes space_education space_industry space_tourism virtual_environment virtual_reality vr
65,Augmented Reality in Service of Human Operations on the Moon: Insights from a Virtual Testbed,"Becker, L., Nilsson, T., Demedeiros, P., & Rometsch, F. (2023). Augmented Reality in Service of Human Operations on the Moon: Insights from a Virtual Testbed. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585860
",10.1145/3544549.3585860,"Future astronauts living and working on the Moon will face extreme environmental conditions impeding their operational safety and performance. While it has been suggested that Augmented Reality (AR) Head-Up Displays (HUDs) could potentially help mitigate some of these adversities, the applicability of AR in the unique lunar context remains underexplored. To address this limitation, we have produced an accurate representation of the lunar setting in virtual reality (VR) which then formed our testbed for the exploration of prospective operational scenarios with aerospace experts. Herein we present findings based on qualitative reflections made by the first 6 study participants. AR was found instrumental in several use cases, including the support of navigation and risk awareness. Major design challenges were likewise identified, including the importance of redundancy and contextual appropriateness. Drawing on these findings, we conclude by outlining directions for future research aimed at developing AR-based assistive solutions tailored to the lunar setting.",C7460 Aerospace engineering computing;C0240 Ergonomic aspects of computing;C6130V Virtual reality,adversities;aerospace experts;AR;augmented reality head-up displays;extreme environmental conditions;future astronauts;HUDs;human operations;lunar setting;Moon;operational safety;prospective operational scenarios;qualitative reflections;unique lunar context;virtual reality;virtual testbed,aerospace computing;augmented reality;head-up displays;space research,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Becker, L.; (2) Nilsson, T.; (2) Demedeiros, P.; (2) Rometsch, F.; ","(1) Deutsches Zentrum fur Luft- und Raumfahrt DLR Standort Augsburg, Institute for Software Technology - Software for Space Systems and Interactive Visualization, Germany; (2) European Astronaut Centre, Germany; ",ACM,-1,"[""aerospace computing"", ""head up displays"", ""space research""]","[""aerospace computing"", ""head up displays"", ""space research""]",aerospace computing;head up displays;space research,medical;display technology;education;aviation and aerospace,displays;industries,medical;display technology;education;aviation and aerospace,displays;industries,aerospace_computing head_up_displays space_research adversities aerospace_experts ar augmented_reality_head up_displays extreme_environmental_conditions future_astronauts huds human_operations lunar_setting moon operational_safety prospective_operational_scenarios qualitative_reflections unique_lunar_context virtual_reality virtual_testbed c7460_aerospace_engineering_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality medical display_technology education aviation_and_aerospace,aerospace_computing head_up_displays space_research,adversities aerospace_experts ar augmented_reality_head up_displays extreme_environmental_conditions future_astronauts huds human_operations lunar_setting moon operational_safety prospective_operational_scenarios qualitative_reflections unique_lunar_context virtual_reality virtual_testbed,future astronaut living working moon face extreme environmental condition impeding operational safety performance suggested augmented reality ar head display hud could potentially help mitigate adversity applicability ar unique lunar context remains underexplored address limitation produced accurate representation lunar setting virtual reality vr formed testbed exploration prospective operational scenario aerospace expert herein present finding based qualitative reflection made first 6 study participant ar found instrumental several use case including support navigation risk awareness major design challenge likewise identified including importance redundancy contextual appropriateness drawing finding conclude outlining direction future research aimed developing ar based assistive solution tailored lunar setting,aerospace_computing head_up_displays space_research adversities aerospace_experts ar augmented_reality_head up_displays extreme_environmental_conditions future_astronauts huds human_operations lunar_setting moon operational_safety prospective_operational_scenarios qualitative_reflections unique_lunar_context virtual_reality virtual_testbed c7460_aerospace_engineering_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality medical display_technology education aviation_and_aerospace future astronaut living working moon face extreme environmental condition impeding operational safety performance suggested augmented reality ar head display hud could potentially help mitigate adversity applicability ar unique lunar context remains underexplored address limitation produced accurate representation lunar setting virtual reality vr formed testbed exploration prospective operational scenario aerospace expert herein present finding based qualitative reflection made first 6 study participant ar found instrumental several use case including support navigation risk awareness major design challenge likewise identified including importance redundancy contextual appropriateness drawing finding conclude outlining direction future research aimed developing ar based assistive solution tailored lunar setting,future astronaut living working moon face extreme environmental condition impeding operational safety performance suggested augmented reality ar head display hud could potentially help mitigate adversity applicability ar unique lunar context remains underexplored address limitation produced accurate representation lunar setting virtual reality vr formed testbed exploration prospective operational scenario aerospace expert herein present finding based qualitative reflection made first 6 study participant ar found instrumental several use case including support navigation risk awareness major design challenge likewise identified including importance redundancy contextual appropriateness drawing finding conclude outlining direction future research aimed developing ar based assistive solution tailored lunar settingaerospace_computing head_up_displays space_researchadversities aerospace_experts ar augmented_reality_head up_displays extreme_environmental_conditions future_astronauts huds human_operations lunar_setting moon operational_safety prospective_operational_scenarios qualitative_reflections unique_lunar_context virtual_reality virtual_testbed
66,Tailor Twist: Assessing Rotational Mid-Air Interactions for Augmented Reality,"Schön, D., Kosch, T., Müller, F., Schmitz, M., Günther, S., Bommhardt, L., & Mühlhäuser, M. (2023). Tailor Twist: Assessing Rotational Mid-Air Interactions for Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581461
",10.1145/3544548.3581461,"Mid-air gestures, widely used in today's Augmented Reality (AR) applications, are prone to the ""gorilla arm"" effect, leading to discomfort with prolonged interactions. While prior work has proposed metrics to quantify this effect and means to improve comfort and ergonomics, these works usually only consider simplistic, one-dimensional AR interactions, like reaching for a point or pushing a button. However, interacting with AR environments also involves far more complex tasks, such as rotational knobs, potentially impacting ergonomics. This paper advances the understanding of the ergonomics of rotational mid-air interactions in AR. For this, we contribute the results of a controlled experiment exposing the participants to a rotational task in the interaction space defined by their arms' reach. Based on the results, we discuss how novel future mid-air gesture modalities benefit from our findings concerning ergonomic-aware rotational interaction.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces,assessing rotational mid-air interactions;augmented reality applications;ergonomic-aware rotational interaction;future mid-air gesture modalities;gorilla arm effect;interaction space;mid-air gestures;one-dimensional AR interactions;prolonged interactions;rotational knobs;rotational task;tailor twist,augmented reality;ergonomics;gesture recognition;human computer interaction,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Scho&#776;n, D.; (2) Kosch, T.; (3) Mu&#776;ller, F.; (4) Schmitz, M.; (1) Gu&#776;nther, S.; (1) Bommhardt, L.; (1) Mu&#776;hlha&#776;user, M.; ","(1) Technical University of Darmstadt, Telecooperation Lab, Germany; (2) Humboldt-Universitat zu Berlin, Germany; (3) Ludwig-Maximilians-Universita&#776;t Mu&#776;nchen, Germany; (4) Saarland University, Germany; ",ACM,-1,"[""ergonomics"", ""gesture recognition"", ""human computer interaction""]","[""ergonomics"", ""gesture recognition"", ""human computer interaction""]",ergonomics;gesture recognition;human computer interaction,human factors;input;human-computer interaction,technology;end users and user experience,human factors;input;human-computer interaction,technology;end users and user experience,ergonomics gesture_recognition human_computer_interaction assessing_rotational_mid air_interactions augmented_reality_applications ergonomic aware_rotational_interaction future_mid air_gesture_modalities gorilla_arm_effect interaction_space mid air_gestures one dimensional_ar_interactions prolonged_interactions rotational_knobs rotational_task tailor_twist c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces human_factors input human computer_interaction,ergonomics gesture_recognition human_computer_interaction,assessing_rotational_mid air_interactions augmented_reality_applications ergonomic aware_rotational_interaction future_mid air_gesture_modalities gorilla_arm_effect interaction_space mid air_gestures one dimensional_ar_interactions prolonged_interactions rotational_knobs rotational_task tailor_twist,mid air gesture widely used today augmented reality ar application prone gorilla arm effect leading discomfort prolonged interaction prior work proposed metric quantify effect mean improve comfort ergonomics work usually consider simplistic one dimensional ar interaction like reaching point pushing button however interacting ar environment also involves far complex task rotational knob potentially impacting ergonomics paper advance understanding ergonomics rotational mid air interaction ar contribute result controlled experiment exposing participant rotational task interaction space defined arm reach based result discus novel future mid air gesture modality benefit finding concerning ergonomic aware rotational interaction,ergonomics gesture_recognition human_computer_interaction assessing_rotational_mid air_interactions augmented_reality_applications ergonomic aware_rotational_interaction future_mid air_gesture_modalities gorilla_arm_effect interaction_space mid air_gestures one dimensional_ar_interactions prolonged_interactions rotational_knobs rotational_task tailor_twist c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces human_factors input human computer_interaction mid air gesture widely used today augmented reality ar application prone gorilla arm effect leading discomfort prolonged interaction prior work proposed metric quantify effect mean improve comfort ergonomics work usually consider simplistic one dimensional ar interaction like reaching point pushing button however interacting ar environment also involves far complex task rotational knob potentially impacting ergonomics paper advance understanding ergonomics rotational mid air interaction ar contribute result controlled experiment exposing participant rotational task interaction space defined arm reach based result discus novel future mid air gesture modality benefit finding concerning ergonomic aware rotational interaction,mid air gesture widely used today augmented reality ar application prone gorilla arm effect leading discomfort prolonged interaction prior work proposed metric quantify effect mean improve comfort ergonomics work usually consider simplistic one dimensional ar interaction like reaching point pushing button however interacting ar environment also involves far complex task rotational knob potentially impacting ergonomics paper advance understanding ergonomics rotational mid air interaction ar contribute result controlled experiment exposing participant rotational task interaction space defined arm reach based result discus novel future mid air gesture modality benefit finding concerning ergonomic aware rotational interactionergonomics gesture_recognition human_computer_interactionassessing_rotational_mid air_interactions augmented_reality_applications ergonomic aware_rotational_interaction future_mid air_gesture_modalities gorilla_arm_effect interaction_space mid air_gestures one dimensional_ar_interactions prolonged_interactions rotational_knobs rotational_task tailor_twist
67,Virtual and Augmented Reality for Environmental Sustainability: A Systematic Review,"Cosio, L. D., Buruk, O. “Oz,” Fernández Galeote, D., Bosman, I. D. V., & Hamari, J. (2023). Virtual and Augmented Reality for Environmental Sustainability: A Systematic Review. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581147
",10.1145/3544548.3581147,"In recent years, extended reality (XR) technology has seen a rise in use in environmental subjects, i.e., climate change or biodiversity loss, as a potential tool to inform and engage the public with current and future environmental issues. However, research on the potential of XR technology for environmental sustainability is still in the early stages, and there is no clear synthesis of the methods studied in this field. To provide a clearer view of existing approaches and research objectives, we systematically reviewed current literature dealing with XR use in environmental topics. Although the results indicate that the volume of literature exploring XR in environmental applications is increasing, empirical evidence of its impact is limited, hindering the possibility of presently drawing significant conclusions on its potential benefits. Based on our analyses, we identified thematic, theoretical, and methodological knowledge gaps and provide a guideline to aid future research in the field.",C7360 Environmental science computing;C6130V Virtual reality,augmented reality;climate change;environmental applications;environmental sustainability;extended reality;systematic review;virtual reality;XR technology,augmented reality;climate mitigation;environmental science computing;sustainable development,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Cosio, L.D.; (2) Buruk, O.'.; (3) Ferna&#769;ndez Galeote, D.; (4) Bosman, I.D.V.; (3) Hamari, J.; ","(1) Tampere University, Faculty of Information and communication sciences, Finland; (2) Tampere University, Faculty of Information Technology and Communications, Finland; (3) Tampere University, Faculty of Information Technology and Communication Sciences, Finland; (4) University of Pretoria, Department of Information Science, South Africa; ",ACM,-1,"[""climate mitigation"", ""environmental science computing"", ""sustainable development""]","[""climate mitigation"", ""environmental science computing"", ""sustainable development""]",climate mitigation;environmental science computing;sustainable development,policy;engineering,technology;business,policy;engineering,technology;business,climate_mitigation environmental_science_computing sustainable_development augmented_reality climate_change environmental_applications environmental_sustainability extended_reality systematic_review virtual_reality xr_technology c7360_environmental_science_computing c6130v_virtual_reality policy engineering,climate_mitigation environmental_science_computing sustainable_development,augmented_reality climate_change environmental_applications environmental_sustainability extended_reality systematic_review virtual_reality xr_technology,recent year extended reality xr technology seen rise use environmental subject e climate change biodiversity loss potential tool inform engage public current future environmental issue however research potential xr technology environmental sustainability still early stage clear synthesis method studied field provide clearer view existing approach research objective systematically reviewed current literature dealing xr use environmental topic although result indicate volume literature exploring xr environmental application increasing empirical evidence impact limited hindering possibility presently drawing significant conclusion potential benefit based analysis identified thematic theoretical methodological knowledge gap provide guideline aid future research field,climate_mitigation environmental_science_computing sustainable_development augmented_reality climate_change environmental_applications environmental_sustainability extended_reality systematic_review virtual_reality xr_technology c7360_environmental_science_computing c6130v_virtual_reality policy engineering recent year extended reality xr technology seen rise use environmental subject e climate change biodiversity loss potential tool inform engage public current future environmental issue however research potential xr technology environmental sustainability still early stage clear synthesis method studied field provide clearer view existing approach research objective systematically reviewed current literature dealing xr use environmental topic although result indicate volume literature exploring xr environmental application increasing empirical evidence impact limited hindering possibility presently drawing significant conclusion potential benefit based analysis identified thematic theoretical methodological knowledge gap provide guideline aid future research field,recent year extended reality xr technology seen rise use environmental subject e climate change biodiversity loss potential tool inform engage public current future environmental issue however research potential xr technology environmental sustainability still early stage clear synthesis method studied field provide clearer view existing approach research objective systematically reviewed current literature dealing xr use environmental topic although result indicate volume literature exploring xr environmental application increasing empirical evidence impact limited hindering possibility presently drawing significant conclusion potential benefit based analysis identified thematic theoretical methodological knowledge gap provide guideline aid future research fieldclimate_mitigation environmental_science_computing sustainable_developmentaugmented_reality climate_change environmental_applications environmental_sustainability extended_reality systematic_review virtual_reality xr_technology
68,An Augmented Reality Design Tool to Guide Furniture Arrangements at Home,"Qu, C., & Aflatoony, L. (2022). An Augmented Reality Design Tool to Guide Furniture Arrangements at Home. Proceedings of the 34th Australian Conference on Human-Computer Interaction. https://doi.org/10.1145/3572921.3576216
",10.1145/3572921.3576216,"Home is a place to live and an environment to support and enhance our psychological well-being. Factors such as furniture selection and arrangements can contribute to more harmonized and balanced home environments. Augmented reality (AR) tools have recently gained attention in home interior design due to their competencies and potential in improving and envisioning the experience of living at home. Following Feng Shui principles and iterative prototyping processes, we designed a high-fidelity AR prototype to guide users in making informed decisions about furniture arrangements at home. We then recruited nine participants to evaluate the tool's usability and usefulness. We discuss our preliminary findings on the benefit of the Feng Shui-supported AR design tool for users. We hope this research inspires future development of AR tools with embedded design recommendations for guiding users in advancing their home environments.",C6130V Virtual reality;C6110R Software performance evaluation;C6115 Programming support,AR tools;augmented reality design tool;augmented reality tools;balanced home environments;embedded design recommendations;Feng Shui principles;Feng Shui-supported AR design tool;furniture arrangement guide;harmonized home environments;high-fidelity AR prototype;home interior design;iterative prototyping processes,augmented reality;furniture;psychology;software performance evaluation;software tools,2022,Conference article (CA),OzCHI '22: Proceedings of the 34th Australian Conference on Human-Computer Interaction,"(1) Qu, C.; (1) Aflatoony, L.; ","(1) Georgia Institute of Technology, School of Industrial Design, Atlanta, GA, United States; ",ACM,-1,"[""furniture"", ""psychology"", ""software performance evaluation"", ""software tools""]","[""furniture"", ""psychology"", ""software performance evaluation"", ""software tools""]",furniture;psychology;software performance evaluation;software tools,"construction;medical;inspection, safety and quality;business performance metrics;developers;manufacturing",technology;business;use cases;industries,"construction;medical;inspection, safety and quality;business performance metrics;developers;manufacturing",technology;business;use cases;industries,furniture psychology software_performance_evaluation software_tools ar_tools augmented_reality_design_tool augmented_reality_tools balanced_home_environments embedded_design_recommendations feng_shui_principles feng_shui supported_ar_design_tool furniture_arrangement_guide harmonized_home_environments high fidelity_ar_prototype home_interior_design iterative_prototyping_processes c6130v_virtual_reality c6110r_software_performance_evaluation c6115_programming_support construction medical inspection _safety_and_quality business_performance_metrics developers manufacturing,furniture psychology software_performance_evaluation software_tools,ar_tools augmented_reality_design_tool augmented_reality_tools balanced_home_environments embedded_design_recommendations feng_shui_principles feng_shui supported_ar_design_tool furniture_arrangement_guide harmonized_home_environments high fidelity_ar_prototype home_interior_design iterative_prototyping_processes,home place live environment support enhance psychological well factor furniture selection arrangement contribute harmonized balanced home environment augmented reality ar tool recently gained attention home interior design due competency potential improving envisioning experience living home following feng shui principle iterative prototyping process designed high fidelity ar prototype guide user making informed decision furniture arrangement home recruited nine participant evaluate tool usability usefulness discus preliminary finding benefit feng shui supported ar design tool user hope research inspires future development ar tool embedded design recommendation guiding user advancing home environment,furniture psychology software_performance_evaluation software_tools ar_tools augmented_reality_design_tool augmented_reality_tools balanced_home_environments embedded_design_recommendations feng_shui_principles feng_shui supported_ar_design_tool furniture_arrangement_guide harmonized_home_environments high fidelity_ar_prototype home_interior_design iterative_prototyping_processes c6130v_virtual_reality c6110r_software_performance_evaluation c6115_programming_support construction medical inspection _safety_and_quality business_performance_metrics developers manufacturing home place live environment support enhance psychological well factor furniture selection arrangement contribute harmonized balanced home environment augmented reality ar tool recently gained attention home interior design due competency potential improving envisioning experience living home following feng shui principle iterative prototyping process designed high fidelity ar prototype guide user making informed decision furniture arrangement home recruited nine participant evaluate tool usability usefulness discus preliminary finding benefit feng shui supported ar design tool user hope research inspires future development ar tool embedded design recommendation guiding user advancing home environment,home place live environment support enhance psychological well factor furniture selection arrangement contribute harmonized balanced home environment augmented reality ar tool recently gained attention home interior design due competency potential improving envisioning experience living home following feng shui principle iterative prototyping process designed high fidelity ar prototype guide user making informed decision furniture arrangement home recruited nine participant evaluate tool usability usefulness discus preliminary finding benefit feng shui supported ar design tool user hope research inspires future development ar tool embedded design recommendation guiding user advancing home environmentfurniture psychology software_performance_evaluation software_toolsar_tools augmented_reality_design_tool augmented_reality_tools balanced_home_environments embedded_design_recommendations feng_shui_principles feng_shui supported_ar_design_tool furniture_arrangement_guide harmonized_home_environments high fidelity_ar_prototype home_interior_design iterative_prototyping_processes
69,Supporting collaborative discussions in surgical teleconsulting through augmented reality head mounted displays,"Maria, S., Mentis, H. M., Canlorbe, G., & Avellino, I. (2023). Supporting Collaborative Discussions In Surgical Teleconsulting Through Augmented Reality Head Mounted Displays. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580714
",10.1145/3544548.3580714,"Although Augmented Reality (AR) has been touted as the future of surgery, its contribution to distributed collaboration such as in surgical teleconsulting has not been articulated. We propose AR-Head Mounted Displays (AR-HMD) to tackle two previously-identified challenges: operating surgeons needing to view and interact with imaging systems that reside away from the operative field, and, their lack of gesturing tools to point and annotate on the shared images and physical environment. We report on a controlled lab experiment where 12 expert gynecology surgeons perform a tumor localisation task guided by a remote radiologist (confederate) via an AR-HMD. We find that bringing the shared images to the place of work reduces the need for clarifications and provides opportunistic access to information when required, and, that pointing and annotating provides opportunities to further support verbal instruction in deictic communication. Our results inform the design of intraoperative AR-HMD systems for surgical telecollaboration.","A8770E Patient diagnostic methods and instrumentation;B6135 Optical, image and video signal processing;B7260 Display technology;B7510 Biomedical measurement and imaging;C5260B Computer vision and image processing techniques;C5540D Computer displays;C6130G Groupware;C6130V Virtual reality;C7330 Biology and medical computing",AR-head mounted displays;augmented reality head;distributed collaboration;intraoperative AR-HMD systems;operating surgeons;physical environment;remote radiologist;share images;support verbal instruction;surgical telecollaboration;tumor localisation task,augmented reality;groupware;gynaecology;helmet mounted displays;medical image processing;surgery;tumours,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Maria, S.; (2) Mentis, H.M.; (1) Canlorbe, G.; (3) Avellino, I.; ","(1) Hopital Universitaire Pitie Salpetriere, France; (2) University of Maryland, Baltimore, Baltimore, MD, United States; (3) Sorbonne Universite&#769;, ISIR, France; ",ACM,-1,"[""groupware"", ""gynaecology"", ""helmet mounted displays"", ""medical image processing"", ""surgery"", ""tumors""]","[""groupware"", ""gynaecology"", ""helmet mounted displays"", ""medical image processing"", ""surgery"", ""tumors""]",groupware;gynaecology;helmet mounted displays;medical image processing;surgery;tumors,computer vision;farming and natural science;other;medical;collaboration;display technology;wearables;data,other;displays;industries;use cases;technology,computer vision;farming and natural science;other;medical;collaboration;display technology;wearables;data,other;displays;industries;use cases;technology,groupware gynaecology helmet_mounted_displays medical_image_processing surgery tumors ar head_mounted_displays augmented_reality_head distributed_collaboration intraoperative_ar hmd_systems operating_surgeons physical_environment remote_radiologist share_images support_verbal_instruction surgical_telecollaboration tumor_localisation_task a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b7260_display_technology b7510_biomedical_measurement_and_imaging c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130g_groupware c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision farming_and_natural_science other medical collaboration display_technology wearables data,groupware gynaecology helmet_mounted_displays medical_image_processing surgery tumors,ar head_mounted_displays augmented_reality_head distributed_collaboration intraoperative_ar hmd_systems operating_surgeons physical_environment remote_radiologist share_images support_verbal_instruction surgical_telecollaboration tumor_localisation_task,although augmented reality ar touted future surgery contribution distributed collaboration surgical teleconsulting articulated propose ar head mounted display ar hmd tackle two previously identified challenge operating surgeon needing view interact imaging system reside away operative field lack gesturing tool point annotate shared image physical environment report controlled lab experiment 12 expert gynecology surgeon perform tumor localisation task guided remote radiologist confederate via ar hmd find bringing shared image place work reduces need clarification provides opportunistic access information required pointing annotating provides opportunity support verbal instruction deictic communication result inform design intraoperative ar hmd system surgical telecollaboration,groupware gynaecology helmet_mounted_displays medical_image_processing surgery tumors ar head_mounted_displays augmented_reality_head distributed_collaboration intraoperative_ar hmd_systems operating_surgeons physical_environment remote_radiologist share_images support_verbal_instruction surgical_telecollaboration tumor_localisation_task a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b7260_display_technology b7510_biomedical_measurement_and_imaging c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130g_groupware c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision farming_and_natural_science other medical collaboration display_technology wearables data although augmented reality ar touted future surgery contribution distributed collaboration surgical teleconsulting articulated propose ar head mounted display ar hmd tackle two previously identified challenge operating surgeon needing view interact imaging system reside away operative field lack gesturing tool point annotate shared image physical environment report controlled lab experiment 12 expert gynecology surgeon perform tumor localisation task guided remote radiologist confederate via ar hmd find bringing shared image place work reduces need clarification provides opportunistic access information required pointing annotating provides opportunity support verbal instruction deictic communication result inform design intraoperative ar hmd system surgical telecollaboration,although augmented reality ar touted future surgery contribution distributed collaboration surgical teleconsulting articulated propose ar head mounted display ar hmd tackle two previously identified challenge operating surgeon needing view interact imaging system reside away operative field lack gesturing tool point annotate shared image physical environment report controlled lab experiment 12 expert gynecology surgeon perform tumor localisation task guided remote radiologist confederate via ar hmd find bringing shared image place work reduces need clarification provides opportunistic access information required pointing annotating provides opportunity support verbal instruction deictic communication result inform design intraoperative ar hmd system surgical telecollaborationgroupware gynaecology helmet_mounted_displays medical_image_processing surgery tumorsar head_mounted_displays augmented_reality_head distributed_collaboration intraoperative_ar hmd_systems operating_surgeons physical_environment remote_radiologist share_images support_verbal_instruction surgical_telecollaboration tumor_localisation_task
70,The Effects of Interaction Mode and Individual Differences on Usability and User Experience of Mobile Augmented Reality Navigation,"Hu, S., Rong, L., Han, J., Zhang, D., & Jiang, W. (2023). The Effects of Interaction Mode and Individual Differences on Usability and User Experience of Mobile Augmented Reality Navigation. IEEE Access, 11, 41783–41795. https://doi.org/10.1109/access.2023.3271522
",10.1109/ACCESS.2023.3271522,"In the context of the rapid development of navigation technology and the deepening of users' diversified needs, as an emerging public service, mobile AR (Augmented Reality) navigation is supposed to focus on human-computer interaction and user experience. To extract the influencing factors of efficient service of mobile AR navigation, we constructed an experimental method for the usability of mobile AR navigation and the users' emotional experience based on behavior-emotion analysis. In this study, the user types were divided according to the differences in Mental Cutting Ability and Gender. We explored the effects of Interaction Mode, Mental Cutting Ability, and Gender on the usability of mobile AR navigation and the users' PAD (Please-Arousal-Dominance) three-dimensional emotion through the objective performance and subjective scoring of users when completing AR navigation tasks. The results showed that the Interaction Mode and Mental Cutting Ability had significant effects on the usability of mobile AR navigation and the users' emotional experience; the Ease of Learning, Ease of Use in usability indicators, and the Arousal experience of three-dimensional emotion were significantly affected by Gender. Based on the experimental results, we excavated the mechanism of effects between various factors, extracted the behavioral and emotional trends of different types of users, broadened the research scope of mobile AR navigation-related fields, and finally summarized the design strategies from the perspective of human-robot-environment.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C6180R Human-robot interaction;C6190V Mobile, ubiquitous and pervasive computing",behavior-emotion analysis;completing AR navigation tasks;Gender;human-computer interaction;Interaction Mode;Mental Cutting Ability;mobile AR navigation;mobile Augmented Reality navigation;navigation technology;navigation-related fields;three-dimensional emotion;user experience;user types,augmented reality;emotion recognition;human-robot interaction;mobile computing,2023,Journal article (JA),IEEE Access (USA),"(1) Hu, S.; (1) Rong, L.; (1) Han, J.; (1) Zhang, D.; (1) Jiang, W.; ","(1) Hubei University of Technology, Department of Industrial Design, China; ",IEEE,-1,"[""emotion recognition"", ""human-robot interaction"", ""mobile computing""]","[""emotion recognition"", ""human-robot interaction"", ""mobile computing""]",emotion recognition;human-robot interaction;mobile computing,human factors;telecommunication;robotics;input,technology;industries;end users and user experience,human factors;telecommunication;robotics;input,technology;industries;end users and user experience,emotion_recognition human robot_interaction mobile_computing behavior emotion_analysis completing_ar_navigation_tasks gender human computer_interaction interaction_mode mental_cutting_ability mobile_ar_navigation mobile_augmented_reality_navigation navigation_technology navigation related_fields three dimensional_emotion user_experience user_types c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6180r_human robot_interaction c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication robotics input,emotion_recognition human robot_interaction mobile_computing,behavior emotion_analysis completing_ar_navigation_tasks gender human computer_interaction interaction_mode mental_cutting_ability mobile_ar_navigation mobile_augmented_reality_navigation navigation_technology navigation related_fields three dimensional_emotion user_experience user_types,context rapid development navigation technology deepening user diversified need emerging public service mobile ar augmented reality navigation supposed focus human computer interaction user experience extract influencing factor efficient service mobile ar navigation constructed experimental method usability mobile ar navigation user emotional experience based behavior emotion analysis study user type divided according difference mental cutting ability gender explored effect interaction mode mental cutting ability gender usability mobile ar navigation user pad please arousal dominance three dimensional emotion objective performance subjective scoring user completing ar navigation task result showed interaction mode mental cutting ability significant effect usability mobile ar navigation user emotional experience ease learning ease use usability indicator arousal experience three dimensional emotion significantly affected gender based experimental result excavated mechanism effect various factor extracted behavioral emotional trend different type user broadened research scope mobile ar navigation related field finally summarized design strategy perspective human robot environment,emotion_recognition human robot_interaction mobile_computing behavior emotion_analysis completing_ar_navigation_tasks gender human computer_interaction interaction_mode mental_cutting_ability mobile_ar_navigation mobile_augmented_reality_navigation navigation_technology navigation related_fields three dimensional_emotion user_experience user_types c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6180r_human robot_interaction c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication robotics input context rapid development navigation technology deepening user diversified need emerging public service mobile ar augmented reality navigation supposed focus human computer interaction user experience extract influencing factor efficient service mobile ar navigation constructed experimental method usability mobile ar navigation user emotional experience based behavior emotion analysis study user type divided according difference mental cutting ability gender explored effect interaction mode mental cutting ability gender usability mobile ar navigation user pad please arousal dominance three dimensional emotion objective performance subjective scoring user completing ar navigation task result showed interaction mode mental cutting ability significant effect usability mobile ar navigation user emotional experience ease learning ease use usability indicator arousal experience three dimensional emotion significantly affected gender based experimental result excavated mechanism effect various factor extracted behavioral emotional trend different type user broadened research scope mobile ar navigation related field finally summarized design strategy perspective human robot environment,context rapid development navigation technology deepening user diversified need emerging public service mobile ar augmented reality navigation supposed focus human computer interaction user experience extract influencing factor efficient service mobile ar navigation constructed experimental method usability mobile ar navigation user emotional experience based behavior emotion analysis study user type divided according difference mental cutting ability gender explored effect interaction mode mental cutting ability gender usability mobile ar navigation user pad please arousal dominance three dimensional emotion objective performance subjective scoring user completing ar navigation task result showed interaction mode mental cutting ability significant effect usability mobile ar navigation user emotional experience ease learning ease use usability indicator arousal experience three dimensional emotion significantly affected gender based experimental result excavated mechanism effect various factor extracted behavioral emotional trend different type user broadened research scope mobile ar navigation related field finally summarized design strategy perspective human robot environmentemotion_recognition human robot_interaction mobile_computingbehavior emotion_analysis completing_ar_navigation_tasks gender human computer_interaction interaction_mode mental_cutting_ability mobile_ar_navigation mobile_augmented_reality_navigation navigation_technology navigation related_fields three dimensional_emotion user_experience user_types
71,Demo Abstract: Edge-based Augmented Reality Guidance System for Retinal Laser Therapy via Feature Matching,"Eom, S., Janamsetty, R., Hadziahmetovic, M., Pajic, M., & Gorlatova, M. (2023). Demo Abstract: Edge-based Augmented Reality Guidance System for Retinal Laser Therapy via Feature Matching. The 22nd International Conference on Information Processing in Sensor Networks. https://doi.org/10.1145/3583120.3589814
",10.1145/3583120.3589814,"In ophthalmology, retinal laser therapy is a treatment for retinopathy that requires the use of magnifying lens to treat damaged regions of retinal landmarks, hence creating challenges of inverted magnified images and requiring prolonged training. Augmented Reality (AR) can benefit clinicians during retinal laser therapy by guiding them with retinal landmark holograms and contextual information. Though recent developments in AR magnification show that a direct overlay of the magnified scenes can be achieved, retinal laser therapy requires high precision and visual acuity while maintaining the visual perception of the rest of the environment. Therefore, we demonstrate an AR-based selective magnification system that provides contextual and visualization-based guidance to clinicians. An edge-computing architecture is developed for detecting and matching the feature points between the magnified image and color fundus image of the retina to identify the magnified region of retinal landmarks. We showcase how our AR guidance system can assist clinicians during retinal laser therapy.","A8770E Patient diagnostic methods and instrumentation;A8732 Physiological optics, vision;A8732C Anatomy and optics of the eye;A8760F Optical and laser radiation (medical uses);B4360H Biological and medical applications of lasers;B6135 Optical, image and video signal processing;B6135E Image recognition;B7510J Optical and laser radiation (biomedical imaging/measurement);C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7330 Biology and medical computing",edge-based augmented Reality guidance system;inverted magnified images;requiring prolonged training;retinal landmark holograms;retinal landmarks;retinal laser therapy,augmented reality;biomedical optical imaging;diseases;eye;feature extraction;laser applications in medicine;medical image processing;visual perception,2023,Conference article (CA),IPSN23: The 22nd International Conference on Information Processing in Sensor Networks,"(1) Eom, S.; (1) Janamsetty, R.; (2) Hadziahmetovic, M.; (1) Pajic, M.; (1) Gorlatova, M.; ","(1) Duke University, Department of Electrical and Computer Engineering, Durham, NC, United States; (2) Duke University, Department of Ophthalmology, Durham, NC, United States; ",ACM,-1,"[""biomedical optical imaging"", ""diseases"", ""eye"", ""feature extraction"", ""laser applications in medicine"", ""medical image processing"", ""visual perception""]","[""biomedical optical imaging"", ""diseases"", ""eye"", ""feature extraction"", ""laser applications in medicine"", ""medical image processing"", ""visual perception""]",biomedical optical imaging;diseases;eye;feature extraction;laser applications in medicine;medical image processing;visual perception,computer vision;other;input;medical;chemical;developers;data,technology;other;industries,computer vision;other;input;medical;chemical;developers;data,technology;other;industries,biomedical_optical_imaging diseases eye feature_extraction laser_applications_in_medicine medical_image_processing visual_perception edge based_augmented_reality_guidance_system inverted_magnified_images requiring_prolonged_training retinal_landmark_holograms retinal_landmarks retinal_laser_therapy a8770e_patient_diagnostic_methods_and_instrumentation a8732_physiological_optics _vision a8732c_anatomy_and_optics_of_the_eye a8760f_optical_and_laser_radiation_ medical_uses b4360h_biological_and_medical_applications_of_lasers b6135_optical _image_and_video_signal_processing b6135e_image_recognition b7510j_optical_and_laser_radiation_ biomedical_imaging measurement c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision other input medical chemical developers data,biomedical_optical_imaging diseases eye feature_extraction laser_applications_in_medicine medical_image_processing visual_perception,edge based_augmented_reality_guidance_system inverted_magnified_images requiring_prolonged_training retinal_landmark_holograms retinal_landmarks retinal_laser_therapy,ophthalmology retinal laser therapy treatment retinopathy requires use magnifying lens treat damaged region retinal landmark hence creating challenge inverted magnified image requiring prolonged training augmented reality ar benefit clinician retinal laser therapy guiding retinal landmark hologram contextual information though recent development ar magnification show direct overlay magnified scene achieved retinal laser therapy requires high precision visual acuity maintaining visual perception rest environment therefore demonstrate ar based selective magnification system provides contextual visualization based guidance clinician edge computing architecture developed detecting matching feature point magnified image color fundus image retina identify magnified region retinal landmark showcase ar guidance system assist clinician retinal laser therapy,biomedical_optical_imaging diseases eye feature_extraction laser_applications_in_medicine medical_image_processing visual_perception edge based_augmented_reality_guidance_system inverted_magnified_images requiring_prolonged_training retinal_landmark_holograms retinal_landmarks retinal_laser_therapy a8770e_patient_diagnostic_methods_and_instrumentation a8732_physiological_optics _vision a8732c_anatomy_and_optics_of_the_eye a8760f_optical_and_laser_radiation_ medical_uses b4360h_biological_and_medical_applications_of_lasers b6135_optical _image_and_video_signal_processing b6135e_image_recognition b7510j_optical_and_laser_radiation_ biomedical_imaging measurement c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision other input medical chemical developers data ophthalmology retinal laser therapy treatment retinopathy requires use magnifying lens treat damaged region retinal landmark hence creating challenge inverted magnified image requiring prolonged training augmented reality ar benefit clinician retinal laser therapy guiding retinal landmark hologram contextual information though recent development ar magnification show direct overlay magnified scene achieved retinal laser therapy requires high precision visual acuity maintaining visual perception rest environment therefore demonstrate ar based selective magnification system provides contextual visualization based guidance clinician edge computing architecture developed detecting matching feature point magnified image color fundus image retina identify magnified region retinal landmark showcase ar guidance system assist clinician retinal laser therapy,ophthalmology retinal laser therapy treatment retinopathy requires use magnifying lens treat damaged region retinal landmark hence creating challenge inverted magnified image requiring prolonged training augmented reality ar benefit clinician retinal laser therapy guiding retinal landmark hologram contextual information though recent development ar magnification show direct overlay magnified scene achieved retinal laser therapy requires high precision visual acuity maintaining visual perception rest environment therefore demonstrate ar based selective magnification system provides contextual visualization based guidance clinician edge computing architecture developed detecting matching feature point magnified image color fundus image retina identify magnified region retinal landmark showcase ar guidance system assist clinician retinal laser therapybiomedical_optical_imaging diseases eye feature_extraction laser_applications_in_medicine medical_image_processing visual_perceptionedge based_augmented_reality_guidance_system inverted_magnified_images requiring_prolonged_training retinal_landmark_holograms retinal_landmarks retinal_laser_therapy
72,Graphic Design and Evaluation of an Augmented Reality for Advergame,"Hu, B., Wang, W., Chan, K., Chen, Z., Tang, C., & Li, P. (2022). Graphic Design and Evaluation of an Augmented Reality for Advergame. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574462
",10.1145/3574131.3574462,"This letter attempts to introduce an Augmented Reality Advergame (ARA), which is designed to eliminate the pain-points present of current advergames. i.e., cumbersome interface design, excessive entertainment elements lead to user distraction, and low participation among middle-aged and elderly users. For this purpose, our ARA improves color scheme, optimizes graphic proportions, and reduces typographical complexity of interface design. Furthermore, we introduce an augmented reality way in interaction. Eye-tracking studies demonstrate that ARA is better at directing user attention to key information than the current advergames. Perceptive studies confirm that ARA user engagement is 25% higher than the control advergame.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7830D Computer games",ARA user engagement;augmented reality advergame;color scheme;cumbersome interface design;entertainment elements;eye-tracking studies;graphic design;graphic proportions;typographical complexity;user distraction,augmented reality;computer games;computer graphics;gaze tracking;user interfaces,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Hu, B.; (1) Wang, W.; (1) Chan, K.; (1) Chen, Z.; (2) Tang, C.; (3) Li, P.; ","(1) Macau University of Science and Technology, China; (2) Guangdong University of Technology, China; (3) Hong Kong Polytechnic University, China; ",ACM,-1,"[""computer games"", ""computer graphics"", ""gaze tracking"", ""user interfaces""]","[""computer games"", ""computer graphics"", ""gaze tracking"", ""user interfaces""]",computer games;computer graphics;gaze tracking;user interfaces,computer vision;graphics;input;liberal arts;human-computer interaction,technology;industries;end users and user experience,computer vision;graphics;input;liberal arts;human-computer interaction,technology;industries;end users and user experience,computer_games computer_graphics gaze_tracking user_interfaces ara_user_engagement augmented_reality_advergame color_scheme cumbersome_interface_design entertainment_elements eye tracking_studies graphic_design graphic_proportions typographical_complexity user_distraction b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7830d_computer_games computer_vision graphics input liberal_arts human computer_interaction,computer_games computer_graphics gaze_tracking user_interfaces,ara_user_engagement augmented_reality_advergame color_scheme cumbersome_interface_design entertainment_elements eye tracking_studies graphic_design graphic_proportions typographical_complexity user_distraction,letter attempt introduce augmented reality advergame ara designed eliminate pain point present current advergames e cumbersome interface design excessive entertainment element lead user distraction low participation among middle aged elderly user purpose ara improves color scheme optimizes graphic proportion reduces typographical complexity interface design furthermore introduce augmented reality way interaction eye tracking study demonstrate ara better directing user attention key information current advergames perceptive study confirm ara user engagement 25 higher control advergame,computer_games computer_graphics gaze_tracking user_interfaces ara_user_engagement augmented_reality_advergame color_scheme cumbersome_interface_design entertainment_elements eye tracking_studies graphic_design graphic_proportions typographical_complexity user_distraction b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7830d_computer_games computer_vision graphics input liberal_arts human computer_interaction letter attempt introduce augmented reality advergame ara designed eliminate pain point present current advergames e cumbersome interface design excessive entertainment element lead user distraction low participation among middle aged elderly user purpose ara improves color scheme optimizes graphic proportion reduces typographical complexity interface design furthermore introduce augmented reality way interaction eye tracking study demonstrate ara better directing user attention key information current advergames perceptive study confirm ara user engagement 25 higher control advergame,letter attempt introduce augmented reality advergame ara designed eliminate pain point present current advergames e cumbersome interface design excessive entertainment element lead user distraction low participation among middle aged elderly user purpose ara improves color scheme optimizes graphic proportion reduces typographical complexity interface design furthermore introduce augmented reality way interaction eye tracking study demonstrate ara better directing user attention key information current advergames perceptive study confirm ara user engagement 25 higher control advergamecomputer_games computer_graphics gaze_tracking user_interfacesara_user_engagement augmented_reality_advergame color_scheme cumbersome_interface_design entertainment_elements eye tracking_studies graphic_design graphic_proportions typographical_complexity user_distraction
73,Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality,"Zhao, Y., Fanello, S., & Guo, T. (2023). Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality. Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications. https://doi.org/10.1145/3572864.3580337
",10.1145/3572864.3580337,"Lighting understanding plays an important role in virtual object composition, including mobile augmented reality (AR) applications. Prior work often targets recovering lighting from the physical environment to support photorealistic AR rendering. Because the common workflow is to use a back-facing camera to capture the physical world for overlaying virtual objects, we refer to this usage pattern as back-facing AR. However, existing methods often fall short in supporting emerging front-facing mobile AR applications, e.g., virtual try-on where a user leverages a front-facing camera to explore the effect of various products (e.g., glasses or hats) of different styles. This lack of support can be attributed to the unique challenges of obtaining 360&#176; HDR environment maps, an ideal format of lighting representation, from the front-facing camera and existing techniques. In this paper, we propose to leverage dual-camera streaming to generate a high-quality environment map by combining multi-view lighting reconstruction and parametric directional lighting estimation. Our preliminary results show improved rendering quality using a dual-camera setup for front-facing AR compared to a commercial solution.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",360&#176; HDR environment maps;common workflow;dual-camera setup;high-quality environment map;leverage dual-camera streaming;lighting representation;lighting understanding;mobile augmented reality applications;multicamera lighting estimation;multiview lighting reconstruction;parametric directional lighting estimation;photorealistic AR rendering;photorealistic front-facing mobile augmented reality;physical environment;physical world;usage pattern;virtual object composition;virtual objects,augmented reality;cameras;image reconstruction;lighting;mobile computing;realistic images;rendering (computer graphics),2023,Conference article (CA),HotMobile '23: Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications,"(1) Zhao, Y.; (2) Fanello, S.; (1) Guo, T.; ","(1) Worcester Polytechnic Institute, Worcester, MA, United States; (2) Google, Mountain View, CA, United States; ",ACM,-1,"[""cameras"", ""image reconstruction"", ""lighting"", ""mobile computing"", ""realistic images"", ""rendering""]","[""cameras"", ""image reconstruction"", ""lighting"", ""mobile computing"", ""realistic images"", ""rendering""]",cameras;image reconstruction;lighting;mobile computing;realistic images;rendering,construction;computer vision;graphics;input;telecommunication,technology;industries,construction;computer vision;graphics;input;telecommunication,technology;industries,cameras image_reconstruction lighting mobile_computing realistic_images rendering 360 176 _hdr_environment_maps common_workflow dual camera_setup high quality_environment_map leverage_dual camera_streaming lighting_representation lighting_understanding mobile_augmented_reality_applications multicamera_lighting_estimation multiview_lighting_reconstruction parametric_directional_lighting_estimation photorealistic_ar_rendering photorealistic_front facing_mobile_augmented_reality physical_environment physical_world usage_pattern virtual_object_composition virtual_objects b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing construction computer_vision graphics input telecommunication,cameras image_reconstruction lighting mobile_computing realistic_images rendering,360 176 _hdr_environment_maps common_workflow dual camera_setup high quality_environment_map leverage_dual camera_streaming lighting_representation lighting_understanding mobile_augmented_reality_applications multicamera_lighting_estimation multiview_lighting_reconstruction parametric_directional_lighting_estimation photorealistic_ar_rendering photorealistic_front facing_mobile_augmented_reality physical_environment physical_world usage_pattern virtual_object_composition virtual_objects,lighting understanding play important role virtual object composition including mobile augmented reality ar application prior work often target recovering lighting physical environment support photorealistic ar rendering common workflow use back facing camera capture physical world overlaying virtual object refer usage pattern back facing ar however existing method often fall short supporting emerging front facing mobile ar application e g virtual try user leverage front facing camera explore effect various product e g glass hat different style lack support attributed unique challenge obtaining 360 176 hdr environment map ideal format lighting representation front facing camera existing technique paper propose leverage dual camera streaming generate high quality environment map combining multi view lighting reconstruction parametric directional lighting estimation preliminary result show improved rendering quality using dual camera setup front facing ar compared commercial solution,cameras image_reconstruction lighting mobile_computing realistic_images rendering 360 176 _hdr_environment_maps common_workflow dual camera_setup high quality_environment_map leverage_dual camera_streaming lighting_representation lighting_understanding mobile_augmented_reality_applications multicamera_lighting_estimation multiview_lighting_reconstruction parametric_directional_lighting_estimation photorealistic_ar_rendering photorealistic_front facing_mobile_augmented_reality physical_environment physical_world usage_pattern virtual_object_composition virtual_objects b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing construction computer_vision graphics input telecommunication lighting understanding play important role virtual object composition including mobile augmented reality ar application prior work often target recovering lighting physical environment support photorealistic ar rendering common workflow use back facing camera capture physical world overlaying virtual object refer usage pattern back facing ar however existing method often fall short supporting emerging front facing mobile ar application e g virtual try user leverage front facing camera explore effect various product e g glass hat different style lack support attributed unique challenge obtaining 360 176 hdr environment map ideal format lighting representation front facing camera existing technique paper propose leverage dual camera streaming generate high quality environment map combining multi view lighting reconstruction parametric directional lighting estimation preliminary result show improved rendering quality using dual camera setup front facing ar compared commercial solution,lighting understanding play important role virtual object composition including mobile augmented reality ar application prior work often target recovering lighting physical environment support photorealistic ar rendering common workflow use back facing camera capture physical world overlaying virtual object refer usage pattern back facing ar however existing method often fall short supporting emerging front facing mobile ar application e g virtual try user leverage front facing camera explore effect various product e g glass hat different style lack support attributed unique challenge obtaining 360 176 hdr environment map ideal format lighting representation front facing camera existing technique paper propose leverage dual camera streaming generate high quality environment map combining multi view lighting reconstruction parametric directional lighting estimation preliminary result show improved rendering quality using dual camera setup front facing ar compared commercial solutioncameras image_reconstruction lighting mobile_computing realistic_images rendering360 176 _hdr_environment_maps common_workflow dual camera_setup high quality_environment_map leverage_dual camera_streaming lighting_representation lighting_understanding mobile_augmented_reality_applications multicamera_lighting_estimation multiview_lighting_reconstruction parametric_directional_lighting_estimation photorealistic_ar_rendering photorealistic_front facing_mobile_augmented_reality physical_environment physical_world usage_pattern virtual_object_composition virtual_objects
74,Simulation of speckle in pixelated hologram image recovery: application for augmented-reality retinal projection device,"Rainouard, F., Colard, M., Haeberlé, O., & Martinez, C. (2023). Simulation of speckle in pixelated hologram image recovery: application for AR retinal projection device. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2649933
",10.1117/12.2649933,"Our team works on a disruptive concept of Near Eye Display for Augmented Reality (AR) applications. This device requires distributions of holographic elements described as Emissive Points Distributions (EPDs) to create a composite planar wavefront emitted towards the eye. The crystalline lens focuses this signal onto the retina in a mix of diffraction and refraction processes, to form the pixels of an image. We experimentally recorded an image of the letter ""R"" with pixelated holograms. At the reading of this image, we observe speckle that partially alters the image. Using image processing on the experimental results, we can suppress this speckle and recover the initial ""R"", which validates our concept. We develop a simulation tool based on Fourier optics to better understand the emergence of this speckle noise. With the knowledge of the recording process and the form of the hologram given by microscopy, we simulate the electric field En reflected by the different holographic elements from a unique collimated laser. Each field En encodes an angular pixel of the recorded image. The sum of these optical beams in field and/or in intensity allows us to analyze the role of the different optical elements in the generation of a speckle. In particular, the role of the cross interferences between different EPDs is questioned. The experimental analysis is brought for periodic EPDs but can be extended to the case of random EPDs. It gives some insights into some possible evolutions of our concept in terms of optical implementation. &copy; 2023 SPIE.","461.6 Medicine and Pharmacology;701.1 Electricity: Basic Concepts and Phenomena;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;741.1 Light/Optics;743 Holography",Augmented reality applications;Holographic elements;Holographic simulation;Image recovery;Planar wavefront;Projection devices;Retinal projection;Self-focusing effects;Team work;Waveguide design,Augmented reality;Electric fields;Holograms;Holographic displays;Integrated optics;Ophthalmology;Optical data processing;Pixels,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Rainouard, Fabian; (1) Colard, Matthias; (2) Haeberle, Olivier; (1) Martinez, Christophe; ","(1) Univ. Grenoble Alpes, CEA, LETI, Grenoble; F-38000, France; (2) Institut de Recherche en Informatique, Math&eacute;matiques, Automatique et Signal (IRIMAS UR UHA 7499), Universit&eacute; de Haute-Alsace, Mulhouse; Cedex 68093, France; (3) Laboratoire Jean Kuntzmann, Univ. Grenoble Alpes, France; ",SPIE,-1,"[""electric fields"", ""holograms"", ""holographic displays"", ""integrated optics"", ""ophthalmology"", ""optical data processing"", ""pixels""]","[""electric fields"", ""holograms"", ""holographic displays"", ""integrated optics"", ""ophthalmology"", ""optical data processing"", ""pixels""]",electric fields;holograms;holographic displays;integrated optics;ophthalmology;optical data processing;pixels,graphics;medical;optics;power and energy;display technology;data,technology;displays;industries,graphics;medical;optics;power and energy;display technology;data,technology;displays;industries,electric_fields holograms holographic_displays integrated_optics ophthalmology optical_data_processing pixels augmented_reality_applications holographic_elements holographic_simulation image_recovery planar_wavefront projection_devices retinal_projection self focusing_effects team_work waveguide_design 461 6_medicine_and_pharmacology 701 1_electricity _basic_concepts_and_phenomena 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 743_holography graphics medical optics power_and_energy display_technology data,electric_fields holograms holographic_displays integrated_optics ophthalmology optical_data_processing pixels,augmented_reality_applications holographic_elements holographic_simulation image_recovery planar_wavefront projection_devices retinal_projection self focusing_effects team_work waveguide_design,team work disruptive concept near eye display augmented reality ar application device requires distribution holographic element described emissive point distribution epds create composite planar wavefront emitted towards eye crystalline lens focus signal onto retina mix diffraction refraction process form pixel image experimentally recorded image letter r pixelated hologram reading image observe speckle partially alters image using image processing experimental result suppress speckle recover initial r validates concept develop simulation tool based fourier optic better understand emergence speckle noise knowledge recording process form hologram given microscopy simulate electric field en reflected different holographic element unique collimated laser field en encodes angular pixel recorded image sum optical beam field intensity allows u analyze role different optical element generation speckle particular role cross interference different epds questioned experimental analysis brought periodic epds extended case random epds give insight possible evolution concept term optical implementation copy 2023 spie,electric_fields holograms holographic_displays integrated_optics ophthalmology optical_data_processing pixels augmented_reality_applications holographic_elements holographic_simulation image_recovery planar_wavefront projection_devices retinal_projection self focusing_effects team_work waveguide_design 461 6_medicine_and_pharmacology 701 1_electricity _basic_concepts_and_phenomena 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 743_holography graphics medical optics power_and_energy display_technology data team work disruptive concept near eye display augmented reality ar application device requires distribution holographic element described emissive point distribution epds create composite planar wavefront emitted towards eye crystalline lens focus signal onto retina mix diffraction refraction process form pixel image experimentally recorded image letter r pixelated hologram reading image observe speckle partially alters image using image processing experimental result suppress speckle recover initial r validates concept develop simulation tool based fourier optic better understand emergence speckle noise knowledge recording process form hologram given microscopy simulate electric field en reflected different holographic element unique collimated laser field en encodes angular pixel recorded image sum optical beam field intensity allows u analyze role different optical element generation speckle particular role cross interference different epds questioned experimental analysis brought periodic epds extended case random epds give insight possible evolution concept term optical implementation copy 2023 spie,team work disruptive concept near eye display augmented reality ar application device requires distribution holographic element described emissive point distribution epds create composite planar wavefront emitted towards eye crystalline lens focus signal onto retina mix diffraction refraction process form pixel image experimentally recorded image letter r pixelated hologram reading image observe speckle partially alters image using image processing experimental result suppress speckle recover initial r validates concept develop simulation tool based fourier optic better understand emergence speckle noise knowledge recording process form hologram given microscopy simulate electric field en reflected different holographic element unique collimated laser field en encodes angular pixel recorded image sum optical beam field intensity allows u analyze role different optical element generation speckle particular role cross interference different epds questioned experimental analysis brought periodic epds extended case random epds give insight possible evolution concept term optical implementation copy 2023 spieelectric_fields holograms holographic_displays integrated_optics ophthalmology optical_data_processing pixelsaugmented_reality_applications holographic_elements holographic_simulation image_recovery planar_wavefront projection_devices retinal_projection self focusing_effects team_work waveguide_design
75,Exploring Text Selection in Augmented Reality Systems,"Liu, X., Meng, X., Spittle, B., Xu, W., Gao, B., & Liang, H.-N. (2022). Exploring Text Selection in Augmented Reality Systems. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574459
",10.1145/3574131.3574459,"Text selection is a common and essential activity during text interaction in all interactive systems. As Augmented Reality (AR) head-mounted displays (HMDs) become more widespread, they will need to provide effective interaction techniques for text selection that ensure users can complete a range of text manipulation tasks (e.g., to highlight, copy, and paste text, send instant messages, and browse the web). As a relatively new platform, text selection in AR is largely unexplored and the suitability of interaction techniques supported by current AR HMDs for text selection tasks is unclear. This research aims to fill this gap and reports on an experiment with 12 participants, which compares the performance and usability (user experience and workload) of four possible techniques (Hand+Pinch, Hand+Dwell, Head+Pinch, and Head+Dwell). Our results suggest that Head+Dwell should be the default selection technique, as it is relatively fast, has the lowest error rate and workload, and has the highest-rated user experience and social acceptance.",C6130V Virtual reality;C5540D Computer displays;C6130D Document processing and analysis techniques;C6180 User interfaces,AR HMD;augmented reality head-mounted displays;augmented reality systems;default selection technique;effective interaction techniques;Hand+Pinch;Head+Dwell;Head+Pinch;interactive systems;paste text;text interaction;text manipulation tasks;text selection tasks;user experience,augmented reality;helmet mounted displays;human computer interaction;interactive systems;text analysis,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Liu, X.; (1) Meng, X.; (2) Spittle, B.; (2) Xu, W.; (3) Gao, B.; (1) Liang, H.-N.; ","(1) Xi'an Jiaotong-Liverpool University, China; (2) Birmingham City University, United Kingdom; (3) Jinan University, China; ",ACM,-1,"[""helmet mounted displays"", ""human computer interaction"", ""interactive systems"", ""text analysis""]","[""helmet mounted displays"", ""human computer interaction"", ""interactive systems"", ""text analysis""]",helmet mounted displays;human computer interaction;interactive systems;text analysis,education;input;display technology;wearables;human-computer interaction,technology;end users and user experience;displays;industries,education;input;display technology;wearables;human-computer interaction,technology;end users and user experience;displays;industries,helmet_mounted_displays human_computer_interaction interactive_systems text_analysis ar_hmd augmented_reality_head mounted_displays augmented_reality_systems default_selection_technique effective_interaction_techniques hand pinch head dwell head pinch interactive_systems paste_text text_interaction text_manipulation_tasks text_selection_tasks user_experience c6130v_virtual_reality c5540d_computer_displays c6130d_document_processing_and_analysis_techniques c6180_user_interfaces education input display_technology wearables human computer_interaction,helmet_mounted_displays human_computer_interaction interactive_systems text_analysis,ar_hmd augmented_reality_head mounted_displays augmented_reality_systems default_selection_technique effective_interaction_techniques hand pinch head dwell head pinch interactive_systems paste_text text_interaction text_manipulation_tasks text_selection_tasks user_experience,text selection common essential activity text interaction interactive system augmented reality ar head mounted display hmds become widespread need provide effective interaction technique text selection ensure user complete range text manipulation task e g highlight copy paste text send instant message browse web relatively new platform text selection ar largely unexplored suitability interaction technique supported current ar hmds text selection task unclear research aim fill gap report experiment 12 participant compare performance usability user experience workload four possible technique hand pinch hand dwell head pinch head dwell result suggest head dwell default selection technique relatively fast lowest error rate workload highest rated user experience social acceptance,helmet_mounted_displays human_computer_interaction interactive_systems text_analysis ar_hmd augmented_reality_head mounted_displays augmented_reality_systems default_selection_technique effective_interaction_techniques hand pinch head dwell head pinch interactive_systems paste_text text_interaction text_manipulation_tasks text_selection_tasks user_experience c6130v_virtual_reality c5540d_computer_displays c6130d_document_processing_and_analysis_techniques c6180_user_interfaces education input display_technology wearables human computer_interaction text selection common essential activity text interaction interactive system augmented reality ar head mounted display hmds become widespread need provide effective interaction technique text selection ensure user complete range text manipulation task e g highlight copy paste text send instant message browse web relatively new platform text selection ar largely unexplored suitability interaction technique supported current ar hmds text selection task unclear research aim fill gap report experiment 12 participant compare performance usability user experience workload four possible technique hand pinch hand dwell head pinch head dwell result suggest head dwell default selection technique relatively fast lowest error rate workload highest rated user experience social acceptance,text selection common essential activity text interaction interactive system augmented reality ar head mounted display hmds become widespread need provide effective interaction technique text selection ensure user complete range text manipulation task e g highlight copy paste text send instant message browse web relatively new platform text selection ar largely unexplored suitability interaction technique supported current ar hmds text selection task unclear research aim fill gap report experiment 12 participant compare performance usability user experience workload four possible technique hand pinch hand dwell head pinch head dwell result suggest head dwell default selection technique relatively fast lowest error rate workload highest rated user experience social acceptancehelmet_mounted_displays human_computer_interaction interactive_systems text_analysisar_hmd augmented_reality_head mounted_displays augmented_reality_systems default_selection_technique effective_interaction_techniques hand pinch head dwell head pinch interactive_systems paste_text text_interaction text_manipulation_tasks text_selection_tasks user_experience
76,Remote sensing image processing technology based on mobile augmented reality technology in surveying and mapping engineering,"Lu, W., Zhao, L., & Xu, R. (2021). Remote sensing image processing technology based on mobile augmented reality technology in surveying and mapping engineering. Soft Computing, 27(1), 423–433. https://doi.org/10.1007/s00500-021-05650-3
",10.1007/s00500-021-05650-3,"With the continuous advancement of science and technology, the improvement of mobile terminal hardware performance and the large-scale popularization of smart phones have brought new experiences and methods to surveying and mapping work. This article mainly studies the application of remote sensing image processing technology based on mobile augmented reality technology in surveying and mapping engineering. First, perform grayscale processing on the image in the experiment, then remove the noise in the image and smooth the image through the median filter method and finally use the Canny operator to perform edge detection to obtain a binarized image containing only the target object, and this is done by image feature extraction. After using three-dimensional scanning modeling to extract the image feature points, the target manager is used for sample analysis. Obtain the projection matrix through the interface, and then perform coordinate conversion to complete the positioning of the target scene. In this paper, the BRISK feature point detection algorithm with fast speed and small calculation is used to detect the target, and SVM is used for remote sensing feature classification. Experimental data show that the recognition success rate of the algorithm is 84%. The results show that mobile augmented reality technology and remote sensing image processing technology can improve the efficiency and accuracy of surveying and mapping engineering, and have strong ease of use and stability.","B6135E Image recognition;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",binarized image;BRISK feature point detection algorithm;image feature extraction;image feature points;mapping engineering;mobile augmented reality technology;mobile terminal hardware performance;remote sensing feature classification;remote sensing image processing technology;surveying,augmented reality;edge detection;feature extraction;image processing;median filters;remote sensing;support vector machines,2023,Journal article (JA),Soft Comput. (Germany),"(1) Lu, W.; (2) Zhao, L.; (1) Xu, R.; ","(1) University of Army Engineering, Institute of Communication Engineering, China; (2) Unit 32142, China; ",Springer,-1,"[""edge detection"", ""feature extraction"", ""image processing"", ""median filters"", ""remote sensing"", ""support vector machines""]","[""edge detection"", ""feature extraction"", ""image processing"", ""median filters"", ""remote sensing"", ""support vector machines""]",edge detection;feature extraction;image processing;median filters;remote sensing;support vector machines,computer vision;chemical;sensors;data;artificial intelligence,technology;industries,computer vision;chemical;sensors;data;artificial intelligence,technology;industries,edge_detection feature_extraction image_processing median_filters remote_sensing support_vector_machines binarized_image brisk_feature_point_detection_algorithm image_feature_extraction image_feature_points mapping_engineering mobile_augmented_reality_technology mobile_terminal_hardware_performance remote_sensing_feature_classification remote_sensing_image_processing_technology surveying b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision chemical sensors data artificial_intelligence,edge_detection feature_extraction image_processing median_filters remote_sensing support_vector_machines,binarized_image brisk_feature_point_detection_algorithm image_feature_extraction image_feature_points mapping_engineering mobile_augmented_reality_technology mobile_terminal_hardware_performance remote_sensing_feature_classification remote_sensing_image_processing_technology surveying,continuous advancement science technology improvement mobile terminal hardware performance large scale popularization smart phone brought new experience method surveying mapping work article mainly study application remote sensing image processing technology based mobile augmented reality technology surveying mapping engineering first perform grayscale processing image experiment remove noise image smooth image median filter method finally use canny operator perform edge detection obtain binarized image containing target object done image feature extraction using three dimensional scanning modeling extract image feature point target manager used sample analysis obtain projection matrix interface perform coordinate conversion complete positioning target scene paper brisk feature point detection algorithm fast speed small calculation used detect target svm used remote sensing feature classification experimental data show recognition success rate algorithm 84 result show mobile augmented reality technology remote sensing image processing technology improve efficiency accuracy surveying mapping engineering strong ease use stability,edge_detection feature_extraction image_processing median_filters remote_sensing support_vector_machines binarized_image brisk_feature_point_detection_algorithm image_feature_extraction image_feature_points mapping_engineering mobile_augmented_reality_technology mobile_terminal_hardware_performance remote_sensing_feature_classification remote_sensing_image_processing_technology surveying b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision chemical sensors data artificial_intelligence continuous advancement science technology improvement mobile terminal hardware performance large scale popularization smart phone brought new experience method surveying mapping work article mainly study application remote sensing image processing technology based mobile augmented reality technology surveying mapping engineering first perform grayscale processing image experiment remove noise image smooth image median filter method finally use canny operator perform edge detection obtain binarized image containing target object done image feature extraction using three dimensional scanning modeling extract image feature point target manager used sample analysis obtain projection matrix interface perform coordinate conversion complete positioning target scene paper brisk feature point detection algorithm fast speed small calculation used detect target svm used remote sensing feature classification experimental data show recognition success rate algorithm 84 result show mobile augmented reality technology remote sensing image processing technology improve efficiency accuracy surveying mapping engineering strong ease use stability,continuous advancement science technology improvement mobile terminal hardware performance large scale popularization smart phone brought new experience method surveying mapping work article mainly study application remote sensing image processing technology based mobile augmented reality technology surveying mapping engineering first perform grayscale processing image experiment remove noise image smooth image median filter method finally use canny operator perform edge detection obtain binarized image containing target object done image feature extraction using three dimensional scanning modeling extract image feature point target manager used sample analysis obtain projection matrix interface perform coordinate conversion complete positioning target scene paper brisk feature point detection algorithm fast speed small calculation used detect target svm used remote sensing feature classification experimental data show recognition success rate algorithm 84 result show mobile augmented reality technology remote sensing image processing technology improve efficiency accuracy surveying mapping engineering strong ease use stabilityedge_detection feature_extraction image_processing median_filters remote_sensing support_vector_machinesbinarized_image brisk_feature_point_detection_algorithm image_feature_extraction image_feature_points mapping_engineering mobile_augmented_reality_technology mobile_terminal_hardware_performance remote_sensing_feature_classification remote_sensing_image_processing_technology surveying
77,Design android-based learning media using augmented reality technology to support ethnomathematics materials at junior high school,"Rochmadi, T., Richardo, R., Abdullah, A. A., Wijaya, A., & Nurkhamid. (2023). Design android-based learning media using augmented reality technology to support ethnomathematics materials at junior high school. THE 3RD INTERNATIONAL CONFERENCE ON SCIENCE, MATHEMATICS, ENVIRONMENT, AND EDUCATION: Flexibility in Research and Innovation on Science, Mathematics, Environment, and Education for Sustainable Development. https://doi.org/10.1063/5.0105904
",10.1063/5.0105904,"The era of the industrial revolution 4.0 has changed human life a lot because most of them use information and communication technology. However, from the many changes that occur, augmented reality technology becomes a solution and challenge to make interactive learning media, especially those that require visual media or require visiting places that are not accessible. Augmented reality is one of the technologies that is growing rapidly in the 4.0 era where the technology can present objects as if they are real in front of us using only Android. The use of android-based learning media using augmented reality technology in addition to helping in the interactive learning process is also a means of equal distribution of education in Indonesia where many schools are still lacking in terms of learning media infrastructure and the high cost of visiting museums. The method used in designing this media uses the ADDIE approach method, namely Analysis, Design, Develop, Implement and Evaluate with limitations without evaluation. The results of the research can produce android-based ethnomathematics learning media design. This means that this android-based learning media is affordable for all people because on average all junior high school students have an android smartphone. [The copyright for the referenced work is owned by Author(s). Copies of full-text articles should only be made or obtained from the publisher or authorized sources.]","C6190V Mobile, ubiquitous and pervasive computing;C6130V Virtual reality;C7480 Production engineering computing;C7810C Computer-aided instruction;C7820 Humanities computing;E0410D Industrial applications of IT",4.0 era;android-based ethnomathematics learning media;augmented reality technology;communication technology;Design android-based learning media;industrial revolution 4;interactive learning media;interactive learning process;junior high school;media infrastructure;visual media,Android (operating system);augmented reality;computer aided instruction;mobile computing;museums;production engineering computing;smart phones,2023,Conference article (CA),AIP Conf. Proc. (USA),"(1) Rochmadi, T.; (2) Richardo, R.; (2) Abdullah, A.A.; (3) Wijaya, A.; (4) Nurkhamid; ","(1) Alma Ata University, Department of Information Systems, Indonesia; (2) Alma Ata University, Faculty of Teaching and Education, Indonesia; (3) Yogyakarta State University, Department of Mathematics Education, Indonesia; (4) Yogyakarta State University, Department of Electronic Engineering Education, Indonesia; ",AIP Publishing,-1,"[""android"", ""computer aided instruction"", ""mobile computing"", ""museums"", ""production engineering computing"", ""smartphones""]","[""android"", ""computer aided instruction"", ""mobile computing"", ""museums"", ""production engineering computing"", ""smartphones""]",android;computer aided instruction;mobile computing;museums;production engineering computing;smartphones,liberal arts;cultural heritage;training;telecommunication;engineering;developers;manufacturing,technology;use cases;industries,liberal arts;cultural heritage;training;telecommunication;engineering;developers;manufacturing,technology;use cases;industries,android computer_aided_instruction mobile_computing museums production_engineering_computing smartphones 4 0_era android based_ethnomathematics_learning_media augmented_reality_technology communication_technology design_android based_learning_media industrial_revolution_4 interactive_learning_media interactive_learning_process junior_high_school media_infrastructure visual_media c6190v_mobile _ubiquitous_and_pervasive_computing c6130v_virtual_reality c7480_production_engineering_computing c7810c_computer aided_instruction c7820_humanities_computing e0410d_industrial_applications_of_it liberal_arts cultural_heritage training telecommunication engineering developers manufacturing,android computer_aided_instruction mobile_computing museums production_engineering_computing smartphones,4 0_era android based_ethnomathematics_learning_media augmented_reality_technology communication_technology design_android based_learning_media industrial_revolution_4 interactive_learning_media interactive_learning_process junior_high_school media_infrastructure visual_media,era industrial revolution 4 0 changed human life lot use information communication technology however many change occur augmented reality technology becomes solution challenge make interactive learning medium especially require visual medium require visiting place accessible augmented reality one technology growing rapidly 4 0 era technology present object real front u using android use android based learning medium using augmented reality technology addition helping interactive learning process also mean equal distribution education indonesia many school still lacking term learning medium infrastructure high cost visiting museum method used designing medium us addie approach method namely analysis design develop implement evaluate limitation without evaluation result research produce android based ethnomathematics learning medium design mean android based learning medium affordable people average junior high school student android smartphone copyright referenced work owned author copy full text article made obtained publisher authorized source,android computer_aided_instruction mobile_computing museums production_engineering_computing smartphones 4 0_era android based_ethnomathematics_learning_media augmented_reality_technology communication_technology design_android based_learning_media industrial_revolution_4 interactive_learning_media interactive_learning_process junior_high_school media_infrastructure visual_media c6190v_mobile _ubiquitous_and_pervasive_computing c6130v_virtual_reality c7480_production_engineering_computing c7810c_computer aided_instruction c7820_humanities_computing e0410d_industrial_applications_of_it liberal_arts cultural_heritage training telecommunication engineering developers manufacturing era industrial revolution 4 0 changed human life lot use information communication technology however many change occur augmented reality technology becomes solution challenge make interactive learning medium especially require visual medium require visiting place accessible augmented reality one technology growing rapidly 4 0 era technology present object real front u using android use android based learning medium using augmented reality technology addition helping interactive learning process also mean equal distribution education indonesia many school still lacking term learning medium infrastructure high cost visiting museum method used designing medium us addie approach method namely analysis design develop implement evaluate limitation without evaluation result research produce android based ethnomathematics learning medium design mean android based learning medium affordable people average junior high school student android smartphone copyright referenced work owned author copy full text article made obtained publisher authorized source,era industrial revolution 4 0 changed human life lot use information communication technology however many change occur augmented reality technology becomes solution challenge make interactive learning medium especially require visual medium require visiting place accessible augmented reality one technology growing rapidly 4 0 era technology present object real front u using android use android based learning medium using augmented reality technology addition helping interactive learning process also mean equal distribution education indonesia many school still lacking term learning medium infrastructure high cost visiting museum method used designing medium us addie approach method namely analysis design develop implement evaluate limitation without evaluation result research produce android based ethnomathematics learning medium design mean android based learning medium affordable people average junior high school student android smartphone copyright referenced work owned author copy full text article made obtained publisher authorized sourceandroid computer_aided_instruction mobile_computing museums production_engineering_computing smartphones4 0_era android based_ethnomathematics_learning_media augmented_reality_technology communication_technology design_android based_learning_media industrial_revolution_4 interactive_learning_media interactive_learning_process junior_high_school media_infrastructure visual_media
78,Ethical Design Approaches for Workplace Augmented Reality,"Greene, J. (2022). Ethical Design Approaches for Workplace Augmented Reality. Communication Design Quarterly, 10(4), 16–26. https://doi.org/10.1145/3531210.3531212
",10.1145/3531210.3531212,"Augmented reality (AR) technologies are increasingly being implemented in various workplace contexts; however, they pose a number of ethical design challenges. To discern the ethical implications of workplace AR, this article conducts an analysis of the promotional discourses surrounding a workplace AR system. This analysis demonstrates a tendency to frame AR technologies in terms of a transhumanist evolution in worker agency and organizational efficiency. Such discourses elide applications of workplace AR for purposes of worker surveillance and exploitation. The article concludes by outlining speculative ethical design guidelines that communication designers can take up in their work on workplace AR systems.","C6130V Virtual reality;C0230 Economic, social and political aspects of computing",communication designers;ethical design guidelines;ethical implications;organizational efficiency;promotional discourses;transhumanist evolution;worker agency;worker surveillance;workplace AR system;workplace augmented reality,augmented reality;ethical aspects;organisational aspects;personnel,2022,Journal article (JA),Commun. Des. Q. (USA),"(1) Greene, J.; ","(1) Arizona State University, Tempe, AZ, United States; ",ACM,-1,"[""ethical aspects"", ""organisational aspects"", ""personnel""]","[""ethical aspects"", ""organisational aspects"", ""personnel""]",ethical aspects;organisational aspects;personnel,policy;business planning and management;human resources,business,policy;business planning and management;human resources,business,ethical_aspects organisational_aspects personnel communication_designers ethical_design_guidelines ethical_implications organizational_efficiency promotional_discourses transhumanist_evolution worker_agency worker_surveillance workplace_ar_system workplace_augmented_reality c6130v_virtual_reality c0230_economic _social_and_political_aspects_of_computing policy business_planning_and_management human_resources,ethical_aspects organisational_aspects personnel,communication_designers ethical_design_guidelines ethical_implications organizational_efficiency promotional_discourses transhumanist_evolution worker_agency worker_surveillance workplace_ar_system workplace_augmented_reality,augmented reality ar technology increasingly implemented various workplace context however pose number ethical design challenge discern ethical implication workplace ar article conduct analysis promotional discourse surrounding workplace ar system analysis demonstrates tendency frame ar technology term transhumanist evolution worker agency organizational efficiency discourse elide application workplace ar purpose worker surveillance exploitation article concludes outlining speculative ethical design guideline communication designer take work workplace ar system,ethical_aspects organisational_aspects personnel communication_designers ethical_design_guidelines ethical_implications organizational_efficiency promotional_discourses transhumanist_evolution worker_agency worker_surveillance workplace_ar_system workplace_augmented_reality c6130v_virtual_reality c0230_economic _social_and_political_aspects_of_computing policy business_planning_and_management human_resources augmented reality ar technology increasingly implemented various workplace context however pose number ethical design challenge discern ethical implication workplace ar article conduct analysis promotional discourse surrounding workplace ar system analysis demonstrates tendency frame ar technology term transhumanist evolution worker agency organizational efficiency discourse elide application workplace ar purpose worker surveillance exploitation article concludes outlining speculative ethical design guideline communication designer take work workplace ar system,augmented reality ar technology increasingly implemented various workplace context however pose number ethical design challenge discern ethical implication workplace ar article conduct analysis promotional discourse surrounding workplace ar system analysis demonstrates tendency frame ar technology term transhumanist evolution worker agency organizational efficiency discourse elide application workplace ar purpose worker surveillance exploitation article concludes outlining speculative ethical design guideline communication designer take work workplace ar systemethical_aspects organisational_aspects personnelcommunication_designers ethical_design_guidelines ethical_implications organizational_efficiency promotional_discourses transhumanist_evolution worker_agency worker_surveillance workplace_ar_system workplace_augmented_reality
79,Bubbleu: Exploring Augmented Reality Game Design with Uncertain AI-based Interaction,"Kim, M., Lee, K., Balan, R., & Lee, Y. (2023). Bubbleu: Exploring Augmented Reality Game Design with Uncertain AI-based Interaction. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581270
",10.1145/3544548.3581270,"Object detection, while being an attractive interaction method for Augmented Reality (AR), is fundamentally error-prone due to the probabilistic nature of the underlying AI models, resulting in sub-optimal user experiences. In this paper, we explore the effect of three game design concepts, Ambiguity, Transparency, and Controllability, to provide better gameplay experiences in AR games that use error-prone object detection-based interaction modalities. First, we developed a base AR pet breeding game, called Bubbleu that uses object detection as a key interaction method. We then implemented three different variants, each according to the three concepts, to investigate the impact of each design concept on the overall user experience. Our user study results show that each design has its own strengths and can improve player experiences in different ways such as decreasing perceived errors (Ambiguity), explaining the system (Transparency), and enabling users to control the rate of uncertainties (Controllability).","B6135 Optical, image and video signal processing;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6210 Knowledge based systems;C7830D Computer games",AR pet breeding game;attractive interaction method;augmented reality game design;design concept;game design concepts;interaction method;suboptimal user experiences;uncertain AI-based interaction;underlying AI models;use error-prone object detection-based interaction modalities;user experience;user study results,artificial intelligence;augmented reality;computer games;object detection;user experience,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Kim, M.; (1) Lee, K.; (2) Balan, R.; (1) Lee, Y.; ","(1) Seoul National University, Computer Science and Engineering, Korea, Republic of; (2) Singapore Management University, School of Information Systems, Singapore; ",ACM,-1,"[""artificial intelligence"", ""computer games"", ""object detection"", ""user experience""]","[""artificial intelligence"", ""computer games"", ""object detection"", ""user experience""]",artificial intelligence;computer games;object detection;user experience,computer vision;human factors;artificial intelligence;liberal arts,technology;industries;end users and user experience,computer vision;human factors;artificial intelligence;liberal arts,technology;industries;end users and user experience,artificial_intelligence computer_games object_detection user_experience ar_pet_breeding_game attractive_interaction_method augmented_reality_game_design design_concept game_design_concepts interaction_method suboptimal_user_experiences uncertain_ai based_interaction underlying_ai_models use_error prone_object_detection based_interaction_modalities user_experience user_study_results b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6210_knowledge_based_systems c7830d_computer_games computer_vision human_factors artificial_intelligence liberal_arts,artificial_intelligence computer_games object_detection user_experience,ar_pet_breeding_game attractive_interaction_method augmented_reality_game_design design_concept game_design_concepts interaction_method suboptimal_user_experiences uncertain_ai based_interaction underlying_ai_models use_error prone_object_detection based_interaction_modalities user_experience user_study_results,object detection attractive interaction method augmented reality ar fundamentally error prone due probabilistic nature underlying ai model resulting sub optimal user experience paper explore effect three game design concept ambiguity transparency controllability provide better gameplay experience ar game use error prone object detection based interaction modality first developed base ar pet breeding game called bubbleu us object detection key interaction method implemented three different variant according three concept investigate impact design concept overall user experience user study result show design strength improve player experience different way decreasing perceived error ambiguity explaining system transparency enabling user control rate uncertainty controllability,artificial_intelligence computer_games object_detection user_experience ar_pet_breeding_game attractive_interaction_method augmented_reality_game_design design_concept game_design_concepts interaction_method suboptimal_user_experiences uncertain_ai based_interaction underlying_ai_models use_error prone_object_detection based_interaction_modalities user_experience user_study_results b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6210_knowledge_based_systems c7830d_computer_games computer_vision human_factors artificial_intelligence liberal_arts object detection attractive interaction method augmented reality ar fundamentally error prone due probabilistic nature underlying ai model resulting sub optimal user experience paper explore effect three game design concept ambiguity transparency controllability provide better gameplay experience ar game use error prone object detection based interaction modality first developed base ar pet breeding game called bubbleu us object detection key interaction method implemented three different variant according three concept investigate impact design concept overall user experience user study result show design strength improve player experience different way decreasing perceived error ambiguity explaining system transparency enabling user control rate uncertainty controllability,object detection attractive interaction method augmented reality ar fundamentally error prone due probabilistic nature underlying ai model resulting sub optimal user experience paper explore effect three game design concept ambiguity transparency controllability provide better gameplay experience ar game use error prone object detection based interaction modality first developed base ar pet breeding game called bubbleu us object detection key interaction method implemented three different variant according three concept investigate impact design concept overall user experience user study result show design strength improve player experience different way decreasing perceived error ambiguity explaining system transparency enabling user control rate uncertainty controllabilityartificial_intelligence computer_games object_detection user_experiencear_pet_breeding_game attractive_interaction_method augmented_reality_game_design design_concept game_design_concepts interaction_method suboptimal_user_experiences uncertain_ai based_interaction underlying_ai_models use_error prone_object_detection based_interaction_modalities user_experience user_study_results
80,Demonstrating CleAR Sight: Transparent Interaction Panels for Augmented Reality,"Büschel, W., Krug, K., Klamka, K., & Dachselt, R. (2023). Demonstrating CleAR Sight: Transparent Interaction Panels for Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583891
",10.1145/3544549.3583891,"In this work, we demonstrate our concepts for transparent interaction panels in augmented-reality environments. Mobile devices can support interaction with head-mounted displays by providing additional input channels, such as touch &amp; pen input and spatial device input, and also an additional, personal display. However, occlusion of the physical context, other people, or the virtual content can be problematic. To address this, we previously introduced CleAR Sight, a concept and research platform for transparent interaction panels to support interaction in HMD-based mixed reality. Here, we will demonstrate the different interaction and visualization techniques supported in CleAR Sight that facilitate basic manipulation, data exploration, and sketching &amp; annotation for various use cases such as 3D volume visualization, collaborative data analysis, and smart home control.",C6130V Virtual reality;C6130B Graphics techniques;C6180 User interfaces,3D volume visualization;annotation;augmented reality;CleAR Sight;collaborative data analysis;data exploration;head-mounted displays;HMD-based mixed reality;input channels;mobile devices;personal display;sketching;smart home control;spatial device input;touch &amp; pen input;transparent interaction panels,augmented reality;data visualisation;helmet mounted displays;human computer interaction,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Bu&#776;schel, W.; (1) Krug, K.; (1) Klamka, K.; (1) Dachselt, R.; ","(1) Interactive Media Lab Dresden, Germany; ",ACM,-1,"[""data visualization"", ""helmet mounted displays"", ""human computer interaction""]","[""data visualization"", ""helmet mounted displays"", ""human computer interaction""]",data visualization;helmet mounted displays;human computer interaction,display technology;wearables;data;human-computer interaction,technology;displays;end users and user experience,display technology;wearables;data;human-computer interaction,technology;displays;end users and user experience,data_visualization helmet_mounted_displays human_computer_interaction 3d_volume_visualization annotation augmented_reality clear_sight collaborative_data_analysis data_exploration head mounted_displays hmd based_mixed_reality input_channels mobile_devices personal_display sketching smart_home_control spatial_device_input touch_ amp _pen_input transparent_interaction_panels c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces display_technology wearables data human computer_interaction,data_visualization helmet_mounted_displays human_computer_interaction,3d_volume_visualization annotation augmented_reality clear_sight collaborative_data_analysis data_exploration head mounted_displays hmd based_mixed_reality input_channels mobile_devices personal_display sketching smart_home_control spatial_device_input touch_ amp _pen_input transparent_interaction_panels,work demonstrate concept transparent interaction panel augmented reality environment mobile device support interaction head mounted display providing additional input channel touch amp pen input spatial device input also additional personal display however occlusion physical context people virtual content problematic address previously introduced clear sight concept research platform transparent interaction panel support interaction hmd based mixed reality demonstrate different interaction visualization technique supported clear sight facilitate basic manipulation data exploration sketching amp annotation various use case 3d volume visualization collaborative data analysis smart home control,data_visualization helmet_mounted_displays human_computer_interaction 3d_volume_visualization annotation augmented_reality clear_sight collaborative_data_analysis data_exploration head mounted_displays hmd based_mixed_reality input_channels mobile_devices personal_display sketching smart_home_control spatial_device_input touch_ amp _pen_input transparent_interaction_panels c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces display_technology wearables data human computer_interaction work demonstrate concept transparent interaction panel augmented reality environment mobile device support interaction head mounted display providing additional input channel touch amp pen input spatial device input also additional personal display however occlusion physical context people virtual content problematic address previously introduced clear sight concept research platform transparent interaction panel support interaction hmd based mixed reality demonstrate different interaction visualization technique supported clear sight facilitate basic manipulation data exploration sketching amp annotation various use case 3d volume visualization collaborative data analysis smart home control,work demonstrate concept transparent interaction panel augmented reality environment mobile device support interaction head mounted display providing additional input channel touch amp pen input spatial device input also additional personal display however occlusion physical context people virtual content problematic address previously introduced clear sight concept research platform transparent interaction panel support interaction hmd based mixed reality demonstrate different interaction visualization technique supported clear sight facilitate basic manipulation data exploration sketching amp annotation various use case 3d volume visualization collaborative data analysis smart home controldata_visualization helmet_mounted_displays human_computer_interaction3d_volume_visualization annotation augmented_reality clear_sight collaborative_data_analysis data_exploration head mounted_displays hmd based_mixed_reality input_channels mobile_devices personal_display sketching smart_home_control spatial_device_input touch_ amp _pen_input transparent_interaction_panels
81,Integrated Registration and Occlusion Handling Based on Deep Learning for Augmented-Reality-Assisted Assembly Instruction,"Li, W., Wang, J., Liu, M., Zhao, S., & Ding, X. (2023). Integrated Registration and Occlusion Handling Based on Deep Learning for Augmented-Reality-Assisted Assembly Instruction. IEEE Transactions on Industrial Informatics, 19(5), 6825–6835. https://doi.org/10.1109/tii.2022.3189428
",10.1109/TII.2022.3189428,"Augmented reality (AR) can convert complex work instructions into virtual-reality fusion contents for assembly guidance. In the past, AR registration and occlusion were usually implemented separately, with low robustness and poor timeliness. This article proposes a novel deep learning scheme, named AR-CenterNet, to integrate AR registration and occlusion handling. The proposed method mainly includes two stages, i.e., the neural network prediction stage and the AR processing stage. In the first stage, AR-CenterNet is designed for keypoint detection and depth map prediction. In the second stage, the pose matrix of the physical camera is solved with the predicted keypoints and the depth map of the virtual scene is compared with the predicted depth map for occlusion handling. The experiments demonstrate that our method is robust against different conditions for assisted assembly. This article can provide a new solution method for AR virtual-reality fusion based on monocular images.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets",AR processing stage;AR registration;AR virtual-reality fusion;assembly guidance;augmented reality;augmented-reality-assisted assembly instruction;complex work instructions;deep learning scheme;integrated registration;low robustness;named AR-CenterNet;neural network prediction stage;occlusion handling;poor timeliness;predicted depth map;predicted keypoints;virtual scene;virtual-reality fusion contents,augmented reality;cameras;deep learning (artificial intelligence);feature extraction;image fusion;image registration;object detection;pose estimation;virtual reality,2023,Journal article (JA),IEEE Trans. Ind. Inform. (USA),"(1) Li, W.; (1) Wang, J.; (1) Liu, M.; (1) Zhao, S.; (1) Ding, X.; ","(1) Huazhong University of Science and Technology, School of Mechanical Science and Engineering, China; ",IEEE,-1,"[""cameras"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image fusion"", ""image registration"", ""object detection"", ""pose estimation""]","[""cameras"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image fusion"", ""image registration"", ""object detection"", ""pose estimation""]",cameras;deep learning (artificial intelligence);feature extraction;image fusion;image registration;object detection;pose estimation,computer vision;other;graphics;input;liberal arts;medical;chemical;artificial intelligence,technology;other;industries,computer vision;other;graphics;input;liberal arts;medical;chemical;artificial intelligence,technology;other;industries,cameras deep_learning_ artificial_intelligence feature_extraction image_fusion image_registration object_detection pose_estimation ar_processing_stage ar_registration ar_virtual reality_fusion assembly_guidance augmented_reality augmented reality assisted_assembly_instruction complex_work_instructions deep_learning_scheme integrated_registration low_robustness named_ar centernet neural_network_prediction_stage occlusion_handling poor_timeliness predicted_depth_map predicted_keypoints virtual_scene virtual reality_fusion_contents b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics input liberal_arts medical chemical artificial_intelligence,cameras deep_learning_ artificial_intelligence feature_extraction image_fusion image_registration object_detection pose_estimation,ar_processing_stage ar_registration ar_virtual reality_fusion assembly_guidance augmented_reality augmented reality assisted_assembly_instruction complex_work_instructions deep_learning_scheme integrated_registration low_robustness named_ar centernet neural_network_prediction_stage occlusion_handling poor_timeliness predicted_depth_map predicted_keypoints virtual_scene virtual reality_fusion_contents,augmented reality ar convert complex work instruction virtual reality fusion content assembly guidance past ar registration occlusion usually implemented separately low robustness poor timeliness article proposes novel deep learning scheme named ar centernet integrate ar registration occlusion handling proposed method mainly includes two stage e neural network prediction stage ar processing stage first stage ar centernet designed keypoint detection depth map prediction second stage pose matrix physical camera solved predicted keypoints depth map virtual scene compared predicted depth map occlusion handling experiment demonstrate method robust different condition assisted assembly article provide new solution method ar virtual reality fusion based monocular image,cameras deep_learning_ artificial_intelligence feature_extraction image_fusion image_registration object_detection pose_estimation ar_processing_stage ar_registration ar_virtual reality_fusion assembly_guidance augmented_reality augmented reality assisted_assembly_instruction complex_work_instructions deep_learning_scheme integrated_registration low_robustness named_ar centernet neural_network_prediction_stage occlusion_handling poor_timeliness predicted_depth_map predicted_keypoints virtual_scene virtual reality_fusion_contents b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics input liberal_arts medical chemical artificial_intelligence augmented reality ar convert complex work instruction virtual reality fusion content assembly guidance past ar registration occlusion usually implemented separately low robustness poor timeliness article proposes novel deep learning scheme named ar centernet integrate ar registration occlusion handling proposed method mainly includes two stage e neural network prediction stage ar processing stage first stage ar centernet designed keypoint detection depth map prediction second stage pose matrix physical camera solved predicted keypoints depth map virtual scene compared predicted depth map occlusion handling experiment demonstrate method robust different condition assisted assembly article provide new solution method ar virtual reality fusion based monocular image,augmented reality ar convert complex work instruction virtual reality fusion content assembly guidance past ar registration occlusion usually implemented separately low robustness poor timeliness article proposes novel deep learning scheme named ar centernet integrate ar registration occlusion handling proposed method mainly includes two stage e neural network prediction stage ar processing stage first stage ar centernet designed keypoint detection depth map prediction second stage pose matrix physical camera solved predicted keypoints depth map virtual scene compared predicted depth map occlusion handling experiment demonstrate method robust different condition assisted assembly article provide new solution method ar virtual reality fusion based monocular imagecameras deep_learning_ artificial_intelligence feature_extraction image_fusion image_registration object_detection pose_estimationar_processing_stage ar_registration ar_virtual reality_fusion assembly_guidance augmented_reality augmented reality assisted_assembly_instruction complex_work_instructions deep_learning_scheme integrated_registration low_robustness named_ar centernet neural_network_prediction_stage occlusion_handling poor_timeliness predicted_depth_map predicted_keypoints virtual_scene virtual reality_fusion_contents
82,Augmented Reality For Education Based On Markerless Dynamic Rendering,"Rakshit, S., Iyer, A., Raj.C, S. R., Elizabeth.D, S., & Vaidyanathan, A. (2023). Augmented Reality For Education Based On Markerless Dynamic Rendering. 2023 International Conference on Networking and Communications (ICNWC). https://doi.org/10.1109/icnwc57852.2023.10127337
",10.1109/ICNWC57852.2023.10127337,"Augmented Reality (AR) technology has the potential to revolutionize education by providing a new way for students to visualize and interact with complex concepts. In this project, a system is proposed to develop an AR smartphone application that allows students to visualize objects and scenarios that the teacher is teaching in real-time. The application will employ the smartphone's camera and sensors to materialize a user-friendly and easy-to-use dynamic AR experience, with the teacher allowing the students to simply access their smartphone to project 3D models of objects or scenarios onto a flat surface. Students will be able to view these models from any angle and interact with them in a variety of ways, such as by rotating them or zooming in on specific details. In addition to enhancing student's understanding of the material being taught, the AR application will also provide an engaging and immersive learning experience. The distinguishing factor is the storage of the 3D assets on the cloud that will equip the educator with the option of pre-planning and customizing their entire lesson as well as storing any number of models. This can help to increase student engagement and motivation, leading to better retention of the material being taught. Overall, the proposed AR smartphone application has the potential to significantly improve the way students learn and understand complex concepts, making education more effective and enjoyable for all.","C7810C Computer-aided instruction;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",AR application;AR smartphone application;Augmented Reality technology;complex concepts;easy-to-use dynamic AR experience;educator;engaging learning experience;flat surface;immersive learning experience;markerless dynamic rendering;project 3D;specific details;student engagement,augmented reality;computer aided instruction;mobile computing;smart phones;teaching,2023,Conference article (CA),2023 International Conference on Networking and Communications (ICNWC),"(1) Rakshit, S.; (1) Iyer, A.; (1) Sunil Retmin Raj, C.; (2) Elizabeth, D.S.; (1) Vaidyanathan, A.; ","(1) Anna University, Department of Information Technology, India; (2) Anna University, Department of Computer Science and Engineering, India; ",IEEE,-1,"[""computer aided instruction"", ""mobile computing"", ""smartphones"", ""teaching""]","[""computer aided instruction"", ""mobile computing"", ""smartphones"", ""teaching""]",computer aided instruction;mobile computing;smartphones;teaching,education;training;telecommunication;liberal arts,use cases;industries,education;training;telecommunication;liberal arts,use cases;industries,computer_aided_instruction mobile_computing smartphones teaching ar_application ar_smartphone_application augmented_reality_technology complex_concepts easy to use_dynamic_ar_experience educator engaging_learning_experience flat_surface immersive_learning_experience markerless_dynamic_rendering project_3d specific_details student_engagement c7810c_computer aided_instruction c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education training telecommunication liberal_arts,computer_aided_instruction mobile_computing smartphones teaching,ar_application ar_smartphone_application augmented_reality_technology complex_concepts easy to use_dynamic_ar_experience educator engaging_learning_experience flat_surface immersive_learning_experience markerless_dynamic_rendering project_3d specific_details student_engagement,augmented reality ar technology potential revolutionize education providing new way student visualize interact complex concept project system proposed develop ar smartphone application allows student visualize object scenario teacher teaching real time application employ smartphone camera sensor materialize user friendly easy use dynamic ar experience teacher allowing student simply access smartphone project 3d model object scenario onto flat surface student able view model angle interact variety way rotating zooming specific detail addition enhancing student understanding material taught ar application also provide engaging immersive learning experience distinguishing factor storage 3d asset cloud equip educator option pre planning customizing entire lesson well storing number model help increase student engagement motivation leading better retention material taught overall proposed ar smartphone application potential significantly improve way student learn understand complex concept making education effective enjoyable,computer_aided_instruction mobile_computing smartphones teaching ar_application ar_smartphone_application augmented_reality_technology complex_concepts easy to use_dynamic_ar_experience educator engaging_learning_experience flat_surface immersive_learning_experience markerless_dynamic_rendering project_3d specific_details student_engagement c7810c_computer aided_instruction c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education training telecommunication liberal_arts augmented reality ar technology potential revolutionize education providing new way student visualize interact complex concept project system proposed develop ar smartphone application allows student visualize object scenario teacher teaching real time application employ smartphone camera sensor materialize user friendly easy use dynamic ar experience teacher allowing student simply access smartphone project 3d model object scenario onto flat surface student able view model angle interact variety way rotating zooming specific detail addition enhancing student understanding material taught ar application also provide engaging immersive learning experience distinguishing factor storage 3d asset cloud equip educator option pre planning customizing entire lesson well storing number model help increase student engagement motivation leading better retention material taught overall proposed ar smartphone application potential significantly improve way student learn understand complex concept making education effective enjoyable,augmented reality ar technology potential revolutionize education providing new way student visualize interact complex concept project system proposed develop ar smartphone application allows student visualize object scenario teacher teaching real time application employ smartphone camera sensor materialize user friendly easy use dynamic ar experience teacher allowing student simply access smartphone project 3d model object scenario onto flat surface student able view model angle interact variety way rotating zooming specific detail addition enhancing student understanding material taught ar application also provide engaging immersive learning experience distinguishing factor storage 3d asset cloud equip educator option pre planning customizing entire lesson well storing number model help increase student engagement motivation leading better retention material taught overall proposed ar smartphone application potential significantly improve way student learn understand complex concept making education effective enjoyablecomputer_aided_instruction mobile_computing smartphones teachingar_application ar_smartphone_application augmented_reality_technology complex_concepts easy to use_dynamic_ar_experience educator engaging_learning_experience flat_surface immersive_learning_experience markerless_dynamic_rendering project_3d specific_details student_engagement
83,"""Periodic Fable Discovery"" Using Tangible Interactions and Augmented Reality to Promote STEM Subjects","Camara Olim, S. M., Nisi, V., & Rubegni, E. (2023). “Periodic Fable Discovery” Using Tangible Interactions and Augmented Reality to Promote STEM Subjects. Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction. https://doi.org/10.1145/3569009.3572804
",10.1145/3569009.3572804,"This pictorial presents Periodic Fable (PF), an educational game's design and graphic interface that promotes a constructivist approach to engage young children with Science, Technology, Engineering, and Math (STEM) subjects. The game presents children with scientific content supported with an exploratory activity using physical cubes manipulable through Tangible Interaction and Augmented Reality. The game's objective is to entertain children while engaging them with the basics of chemistry and the Periodic Table. We reflect upon the combination of these immersive technologies, game-play mechanics, and aesthetics geared towards conveying accurate scientific information through a ludic and entertaining approach. The quantitative and qualitative results of a study with 20 children, showed significant positive results in the participants' learning outcomes and engagement, thereby encouraging us to continue evaluating our design system as a tool that can promote STEM Education.",C7830D Computer games;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C7810C Computer-aided instruction,accurate scientific information;Augmented Reality;constructivist approach;design system;entertaining approach;exploratory activity;game-play mechanics;immersive technologies;ludic approach;Math subjects;Periodic Fable discovery;Periodic Table;physical cubes;pictorial;promote STEM subjects;promotes;quantitative results;scientific content;showed significant positive results;STEM Education;Tangible Interaction;Tangible interactions;young children,augmented reality;computer aided instruction;computer games;entertainment;STEM,2023,Conference article (CA),"TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction","(1) Camara Olim, S.M.; (2) Nisi, V.; (3) Rubegni, E.; ","(1) Universidade NOVA de Lisboa Faculdade de Ciencias e Tecnologia, Interactive Technologies Institute, Portugal; (2) University of Lisbon, Interactive Technology Institute, Portugal; (3) Lancaster University, School of Computing and Communications, United Kingdom; ",ACM,-1,"[""computer aided instruction"", ""computer games"", ""entertainment"", ""stem""]","[""computer aided instruction"", ""computer games"", ""entertainment"", ""stem""]",computer aided instruction;computer games;entertainment;stem,education;training;liberal arts,use cases;industries,education;training;liberal arts,use cases;industries,computer_aided_instruction computer_games entertainment stem accurate_scientific_information augmented_reality constructivist_approach design_system entertaining_approach exploratory_activity game play_mechanics immersive_technologies ludic_approach math_subjects periodic_fable_discovery periodic_table physical_cubes pictorial promote_stem_subjects promotes quantitative_results scientific_content showed_significant_positive_results stem_education tangible_interaction tangible_interactions young_children c7830d_computer_games c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction education training liberal_arts,computer_aided_instruction computer_games entertainment stem,accurate_scientific_information augmented_reality constructivist_approach design_system entertaining_approach exploratory_activity game play_mechanics immersive_technologies ludic_approach math_subjects periodic_fable_discovery periodic_table physical_cubes pictorial promote_stem_subjects promotes quantitative_results scientific_content showed_significant_positive_results stem_education tangible_interaction tangible_interactions young_children,pictorial present periodic fable pf educational game design graphic interface promotes constructivist approach engage young child science technology engineering math stem subject game present child scientific content supported exploratory activity using physical cube manipulable tangible interaction augmented reality game objective entertain child engaging basic chemistry periodic table reflect upon combination immersive technology game play mechanic aesthetic geared towards conveying accurate scientific information ludic entertaining approach quantitative qualitative result study 20 child showed significant positive result participant learning outcome engagement thereby encouraging u continue evaluating design system tool promote stem education,computer_aided_instruction computer_games entertainment stem accurate_scientific_information augmented_reality constructivist_approach design_system entertaining_approach exploratory_activity game play_mechanics immersive_technologies ludic_approach math_subjects periodic_fable_discovery periodic_table physical_cubes pictorial promote_stem_subjects promotes quantitative_results scientific_content showed_significant_positive_results stem_education tangible_interaction tangible_interactions young_children c7830d_computer_games c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction education training liberal_arts pictorial present periodic fable pf educational game design graphic interface promotes constructivist approach engage young child science technology engineering math stem subject game present child scientific content supported exploratory activity using physical cube manipulable tangible interaction augmented reality game objective entertain child engaging basic chemistry periodic table reflect upon combination immersive technology game play mechanic aesthetic geared towards conveying accurate scientific information ludic entertaining approach quantitative qualitative result study 20 child showed significant positive result participant learning outcome engagement thereby encouraging u continue evaluating design system tool promote stem education,pictorial present periodic fable pf educational game design graphic interface promotes constructivist approach engage young child science technology engineering math stem subject game present child scientific content supported exploratory activity using physical cube manipulable tangible interaction augmented reality game objective entertain child engaging basic chemistry periodic table reflect upon combination immersive technology game play mechanic aesthetic geared towards conveying accurate scientific information ludic entertaining approach quantitative qualitative result study 20 child showed significant positive result participant learning outcome engagement thereby encouraging u continue evaluating design system tool promote stem educationcomputer_aided_instruction computer_games entertainment stemaccurate_scientific_information augmented_reality constructivist_approach design_system entertaining_approach exploratory_activity game play_mechanics immersive_technologies ludic_approach math_subjects periodic_fable_discovery periodic_table physical_cubes pictorial promote_stem_subjects promotes quantitative_results scientific_content showed_significant_positive_results stem_education tangible_interaction tangible_interactions young_children
84,Advanced visualization of ergonomic assessment data through industrial Augmented Reality,"Evangelista, A., Manghisi, V. M., Romano, S., De Giglio, V., Cipriani, L., & Uva, A. E. (2023). Advanced visualization of ergonomic assessment data through industrial Augmented Reality. Procedia Computer Science, 217, 1470–1478. https://doi.org/10.1016/j.procs.2022.12.346
",10.1016/j.procs.2022.12.346,"The industrial transition to the 4.0 paradigm defines new scenarios in which the operator plays a central role within the industrial ecosystem. Thanks to the enabling technologies of Industry 4.0, it is possible to effectively improve operators' working conditions by applying the Human-Centered approach. Nowadays, one of the main challenges is to reduce work-related musculoskeletal disorders resulting from ergonomically incorrect working conditions in order to prevent the occurrence of occupational diseases. To this end, we developed a software tool that leverages a low-cost D-RGB camera (Kinect v2) to track the human body and an Augmented Reality (AR) visualization system based on Microsoft HoloLens 2. The tool assesses postural ergonomic risk in real-time according to the Rapid Upper Limb Assessment (RULA) metric. The proposed AR application allows a three-dimensional visualization of postures, which can be observed directly superimposed on the operator's body in the real scene. This approach aims to optimize the understanding of postures by creating a link between real information (operator's body) and virtual information (virtual skeleton, RULA score, and angles) by providing a simple and immediate user interface for ergonomists. All rights reserved Elsevier.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C7480 Production engineering computing;E0240H Health and safety aspects;E0410D Industrial applications of IT;E1410 Ergonomics,advanced visualization;Augmented Reality visualization system;D-RGB camera;ergonomic assessment data;ergonomically incorrect working conditions;human body;Human-Centered approach;industrial Augmented Reality;industrial ecosystem;industrial transition;Microsoft HoloLens 2;occupational diseases;operator;operators;Rapid Upper Limb Assessment metric;software tool;tool assesses postural ergonomic risk;work-related musculoskeletal disorders,augmented reality;cameras;diseases;employee welfare;ergonomics;occupational health;occupational safety;production engineering computing;software tools;user interfaces,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Evangelista, A.; (1) Manghisi, V.M.; (1) Romano, S.; (1) De Giglio, V.; (2) Cipriani, L.; (1) Uva, A.E.; ","(1) Politecnico di Bari, Department of Mechanics, via Orabona 4, Italy; (2) Inail Direzione regionale Puglia, Corso Trieste 29, Italy; ",Elsevier B.V.,-1,"[""cameras"", ""diseases"", ""employee welfare"", ""ergonomics"", ""occupational health"", ""occupational safety"", ""production engineering computing"", ""software tools"", ""user interfaces""]","[""cameras"", ""diseases"", ""employee welfare"", ""ergonomics"", ""occupational health"", ""occupational safety"", ""production engineering computing"", ""software tools"", ""user interfaces""]",cameras;diseases;employee welfare;ergonomics;occupational health;occupational safety;production engineering computing;software tools;user interfaces,"input;medical;inspection, safety and quality;human factors;engineering;developers;human-computer interaction;manufacturing;human resources",business;industries;end users and user experience;use cases;technology,"input;medical;inspection, safety and quality;human factors;engineering;developers;human-computer interaction;manufacturing;human resources",business;industries;end users and user experience;use cases;technology,cameras diseases employee_welfare ergonomics occupational_health occupational_safety production_engineering_computing software_tools user_interfaces advanced_visualization augmented_reality_visualization_system d rgb_camera ergonomic_assessment_data ergonomically_incorrect_working_conditions human_body human centered_approach industrial_augmented_reality industrial_ecosystem industrial_transition microsoft_hololens_2 occupational_diseases operator operators rapid_upper_limb_assessment_metric software_tool tool_assesses_postural_ergonomic_risk work related_musculoskeletal_disorders c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7480_production_engineering_computing e0240h_health_and_safety_aspects e0410d_industrial_applications_of_it e1410_ergonomics input medical inspection _safety_and_quality human_factors engineering developers human computer_interaction manufacturing human_resources,cameras diseases employee_welfare ergonomics occupational_health occupational_safety production_engineering_computing software_tools user_interfaces,advanced_visualization augmented_reality_visualization_system d rgb_camera ergonomic_assessment_data ergonomically_incorrect_working_conditions human_body human centered_approach industrial_augmented_reality industrial_ecosystem industrial_transition microsoft_hololens_2 occupational_diseases operator operators rapid_upper_limb_assessment_metric software_tool tool_assesses_postural_ergonomic_risk work related_musculoskeletal_disorders,industrial transition 4 0 paradigm defines new scenario operator play central role within industrial ecosystem thanks enabling technology industry 4 0 possible effectively improve operator working condition applying human centered approach nowadays one main challenge reduce work related musculoskeletal disorder resulting ergonomically incorrect working condition order prevent occurrence occupational disease end developed software tool leverage low cost rgb camera kinect v2 track human body augmented reality ar visualization system based microsoft hololens 2 tool ass postural ergonomic risk real time according rapid upper limb assessment rula metric proposed ar application allows three dimensional visualization posture observed directly superimposed operator body real scene approach aim optimize understanding posture creating link real information operator body virtual information virtual skeleton rula score angle providing simple immediate user interface ergonomists right reserved elsevier,cameras diseases employee_welfare ergonomics occupational_health occupational_safety production_engineering_computing software_tools user_interfaces advanced_visualization augmented_reality_visualization_system d rgb_camera ergonomic_assessment_data ergonomically_incorrect_working_conditions human_body human centered_approach industrial_augmented_reality industrial_ecosystem industrial_transition microsoft_hololens_2 occupational_diseases operator operators rapid_upper_limb_assessment_metric software_tool tool_assesses_postural_ergonomic_risk work related_musculoskeletal_disorders c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7480_production_engineering_computing e0240h_health_and_safety_aspects e0410d_industrial_applications_of_it e1410_ergonomics input medical inspection _safety_and_quality human_factors engineering developers human computer_interaction manufacturing human_resources industrial transition 4 0 paradigm defines new scenario operator play central role within industrial ecosystem thanks enabling technology industry 4 0 possible effectively improve operator working condition applying human centered approach nowadays one main challenge reduce work related musculoskeletal disorder resulting ergonomically incorrect working condition order prevent occurrence occupational disease end developed software tool leverage low cost rgb camera kinect v2 track human body augmented reality ar visualization system based microsoft hololens 2 tool ass postural ergonomic risk real time according rapid upper limb assessment rula metric proposed ar application allows three dimensional visualization posture observed directly superimposed operator body real scene approach aim optimize understanding posture creating link real information operator body virtual information virtual skeleton rula score angle providing simple immediate user interface ergonomists right reserved elsevier,industrial transition 4 0 paradigm defines new scenario operator play central role within industrial ecosystem thanks enabling technology industry 4 0 possible effectively improve operator working condition applying human centered approach nowadays one main challenge reduce work related musculoskeletal disorder resulting ergonomically incorrect working condition order prevent occurrence occupational disease end developed software tool leverage low cost rgb camera kinect v2 track human body augmented reality ar visualization system based microsoft hololens 2 tool ass postural ergonomic risk real time according rapid upper limb assessment rula metric proposed ar application allows three dimensional visualization posture observed directly superimposed operator body real scene approach aim optimize understanding posture creating link real information operator body virtual information virtual skeleton rula score angle providing simple immediate user interface ergonomists right reserved elseviercameras diseases employee_welfare ergonomics occupational_health occupational_safety production_engineering_computing software_tools user_interfacesadvanced_visualization augmented_reality_visualization_system d rgb_camera ergonomic_assessment_data ergonomically_incorrect_working_conditions human_body human centered_approach industrial_augmented_reality industrial_ecosystem industrial_transition microsoft_hololens_2 occupational_diseases operator operators rapid_upper_limb_assessment_metric software_tool tool_assesses_postural_ergonomic_risk work related_musculoskeletal_disorders
85,Augmented Reality and Waste Reduction: Enhancing the Recycling Process for Mobile E-Waste in Automotive Manufacturing,"Sureshkumar, S., Rani, P. K., C P, A., Kumar, B. A., & R, K. (2023). Augmented Reality and Waste Reduction: Enhancing the Recycling Process for Mobile E-Waste in Automotive Manufacturing. 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS). https://doi.org/10.1109/icaccs57279.2023.10112913
",10.1109/ICACCS57279.2023.10112913,"Electronic waste (e-waste) includes many items, such as waste from electronic devices, mobile parts, electronic appliances, and other household appliances that have reached the end of their life. India is the world's fifth-largest producer of e-waste, according to UN data. While many technologies and industries have been developed to recycle these enormous amounts of electronic waste, the challenge of separating various WEEE materials remains. To encourage the reuse of damaged or unused mobile phones or mobile parts, they can be utilized in automobile industries for applications such as cameras used in parking and GPS with voice assistance. Our proposed system utilizes augmented reality to gather information about unused parts that are suitable for desired applications in the automobile industry. By using augmented reality, our system can efficiently identify and categorize the parts needed for each application, reducing the time and cost of identifying and separating the parts manually. The aim of our proposed project is to reduce the production and recycling costs of mobile parts while also creating a hazard-free environment by reusing e-waste in the automobile industry.",C7360 Environmental science computing;C6130V Virtual reality;E0230 Environmental issues;E1840 Recycling;E3650A Automobile industry,augmented reality;automobile industry;automotive manufacturing;electronic devices;electronic waste;GPS;hazard-free environment;household appliances;India;mobile e-waste;mobile parts;mobile phones;recycling costs;recycling process;reusing e-waste;UN data;voice assistance;waste reduction;WEEE material,augmented reality;automobile industry;environmental science computing;recycling;waste recovery;waste reduction;WEEE Directive,2023,Conference article (CA),2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS),"(1) Sureshkumar, S.; (2) Rani, P.K.; (2) Agash, C.P.; (3) Kumar, B.A.; (4) Kaviyaraj, R.; ","(1) J.J College of Engineering and Technology, Centre for Science and Environment, India; (2) Sri Krishna College of Engineering and Technology, Centre for Science and Environment, India; (3) SRM Institute of Science and Technology, Centre for Science and Environment, India; (4) SRM Institute of Science and Technology, Department of Computational Intelligence, India; ",IEEE,-1,"[""automobile industry"", ""environmental science computing"", ""recycling"", ""waste recovery"", ""waste reduction"", ""weee directive""]","[""automobile industry"", ""environmental science computing"", ""recycling"", ""waste recovery"", ""waste reduction"", ""weee directive""]",automobile industry;environmental science computing;recycling;waste recovery;waste reduction;weee directive,other;industrial equipment;automotive;engineering;data,technology;other;industries,other;industrial equipment;automotive;engineering;data,technology;other;industries,automobile_industry environmental_science_computing recycling waste_recovery waste_reduction weee_directive augmented_reality automobile_industry automotive_manufacturing electronic_devices electronic_waste gps hazard free_environment household_appliances india mobile_e waste mobile_parts mobile_phones recycling_costs recycling_process reusing_e waste un_data voice_assistance waste_reduction weee_material c7360_environmental_science_computing c6130v_virtual_reality e0230_environmental_issues e1840_recycling e3650a_automobile_industry other industrial_equipment automotive engineering data,automobile_industry environmental_science_computing recycling waste_recovery waste_reduction weee_directive,augmented_reality automobile_industry automotive_manufacturing electronic_devices electronic_waste gps hazard free_environment household_appliances india mobile_e waste mobile_parts mobile_phones recycling_costs recycling_process reusing_e waste un_data voice_assistance waste_reduction weee_material,electronic waste e waste includes many item waste electronic device mobile part electronic appliance household appliance reached end life india world fifth largest producer e waste according un data many technology industry developed recycle enormous amount electronic waste challenge separating various weee material remains encourage reuse damaged unused mobile phone mobile part utilized automobile industry application camera used parking gps voice assistance proposed system utilizes augmented reality gather information unused part suitable desired application automobile industry using augmented reality system efficiently identify categorize part needed application reducing time cost identifying separating part manually aim proposed project reduce production recycling cost mobile part also creating hazard free environment reusing e waste automobile industry,automobile_industry environmental_science_computing recycling waste_recovery waste_reduction weee_directive augmented_reality automobile_industry automotive_manufacturing electronic_devices electronic_waste gps hazard free_environment household_appliances india mobile_e waste mobile_parts mobile_phones recycling_costs recycling_process reusing_e waste un_data voice_assistance waste_reduction weee_material c7360_environmental_science_computing c6130v_virtual_reality e0230_environmental_issues e1840_recycling e3650a_automobile_industry other industrial_equipment automotive engineering data electronic waste e waste includes many item waste electronic device mobile part electronic appliance household appliance reached end life india world fifth largest producer e waste according un data many technology industry developed recycle enormous amount electronic waste challenge separating various weee material remains encourage reuse damaged unused mobile phone mobile part utilized automobile industry application camera used parking gps voice assistance proposed system utilizes augmented reality gather information unused part suitable desired application automobile industry using augmented reality system efficiently identify categorize part needed application reducing time cost identifying separating part manually aim proposed project reduce production recycling cost mobile part also creating hazard free environment reusing e waste automobile industry,electronic waste e waste includes many item waste electronic device mobile part electronic appliance household appliance reached end life india world fifth largest producer e waste according un data many technology industry developed recycle enormous amount electronic waste challenge separating various weee material remains encourage reuse damaged unused mobile phone mobile part utilized automobile industry application camera used parking gps voice assistance proposed system utilizes augmented reality gather information unused part suitable desired application automobile industry using augmented reality system efficiently identify categorize part needed application reducing time cost identifying separating part manually aim proposed project reduce production recycling cost mobile part also creating hazard free environment reusing e waste automobile industryautomobile_industry environmental_science_computing recycling waste_recovery waste_reduction weee_directiveaugmented_reality automobile_industry automotive_manufacturing electronic_devices electronic_waste gps hazard free_environment household_appliances india mobile_e waste mobile_parts mobile_phones recycling_costs recycling_process reusing_e waste un_data voice_assistance waste_reduction weee_material
86,Low-cost mobile augmented reality service for building information modeling,"Um, J., Park, J. min, Park, S. yeon, & Yilmaz, G. (2023). Low-cost mobile augmented reality service for building information modeling. Automation in Construction, 146, 104662. https://doi.org/10.1016/j.autcon.2022.104662
",10.1016/j.autcon.2022.104662,"Informed decision-making is crucial for construction site operators. Cyber-physical systems, including various technologies such as augmented reality and building automation tools, are gathering popularity within the infrastructure management sector. However, they are expensive and inaccessible to adopt for most small organizations. This paper describes a prototype of low-cost mobile augmented reality service for BIM and demonstrated its usability for pipe maintenance by supporting inspection, workflow management, data reduction, and augmented reality. User views about the decision support, integration and ease of use of the prototype were also collected from the organisations in the UK and South Korea. The results showed that integrating the augmented reality service with the building automation tool connected to the BIM server enhances decision-making for on-site operations by generating a closed loop. This paper also highlights the need for developing low-cost digital solutions to foster the digitalization of construction organisations with limited budgets. All rights reserved Elsevier.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7440 Civil and mechanical engineering computing;E2110B Building structures;E3030 Construction industry",building automation tool;building automation tools;construction site operators;information modeling;informed decision-making;infrastructure management sector;low-cost digital solutions;low-cost mobile augmented reality service,augmented reality;building information modelling;building management systems;construction industry;cyber-physical systems;decision making;maintenance engineering;mobile computing;project management;structural engineering computing,2023,Journal article (JA),Autom. Constr. (Netherlands),"(1) Jumyung Um; (1) Joung Min Park; (1) Seo Yeon Park; (2) Yilmaz, G.; ","(1) Kyung Hee University, Korea, Republic of; (2) University of Cambridge, United Kingdom; ",Elsevier B.V.,-1,"[""building information modelling"", ""building management systems"", ""construction industry"", ""cyber-physical systems"", ""decision making"", ""maintenance engineering"", ""mobile computing"", ""project management"", ""structural engineering computing""]","[""building information modelling"", ""building management systems"", ""construction industry"", ""cyber-physical systems"", ""decision making"", ""maintenance engineering"", ""mobile computing"", ""project management"", ""structural engineering computing""]",building information modelling;building management systems;construction industry;cyber-physical systems;decision making;maintenance engineering;mobile computing;project management;structural engineering computing,construction;education;robotics;human factors;telecommunication;engineering;manufacturing;business planning and management,technology;end users and user experience;business;industries,construction;education;robotics;human factors;telecommunication;engineering;manufacturing;business planning and management,technology;end users and user experience;business;industries,building_information_modelling building_management_systems construction_industry cyber physical_systems decision_making maintenance_engineering mobile_computing project_management structural_engineering_computing building_automation_tool building_automation_tools construction_site_operators information_modeling informed_decision making infrastructure_management_sector low cost_digital_solutions low cost_mobile_augmented_reality_service c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7440_civil_and_mechanical_engineering_computing e2110b_building_structures e3030_construction_industry construction education robotics human_factors telecommunication engineering manufacturing business_planning_and_management,building_information_modelling building_management_systems construction_industry cyber physical_systems decision_making maintenance_engineering mobile_computing project_management structural_engineering_computing,building_automation_tool building_automation_tools construction_site_operators information_modeling informed_decision making infrastructure_management_sector low cost_digital_solutions low cost_mobile_augmented_reality_service,informed decision making crucial construction site operator cyber physical system including various technology augmented reality building automation tool gathering popularity within infrastructure management sector however expensive inaccessible adopt small organization paper describes prototype low cost mobile augmented reality service bim demonstrated usability pipe maintenance supporting inspection workflow management data reduction augmented reality user view decision support integration ease use prototype also collected organisation uk south korea result showed integrating augmented reality service building automation tool connected bim server enhances decision making site operation generating closed loop paper also highlight need developing low cost digital solution foster digitalization construction organisation limited budget right reserved elsevier,building_information_modelling building_management_systems construction_industry cyber physical_systems decision_making maintenance_engineering mobile_computing project_management structural_engineering_computing building_automation_tool building_automation_tools construction_site_operators information_modeling informed_decision making infrastructure_management_sector low cost_digital_solutions low cost_mobile_augmented_reality_service c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7440_civil_and_mechanical_engineering_computing e2110b_building_structures e3030_construction_industry construction education robotics human_factors telecommunication engineering manufacturing business_planning_and_management informed decision making crucial construction site operator cyber physical system including various technology augmented reality building automation tool gathering popularity within infrastructure management sector however expensive inaccessible adopt small organization paper describes prototype low cost mobile augmented reality service bim demonstrated usability pipe maintenance supporting inspection workflow management data reduction augmented reality user view decision support integration ease use prototype also collected organisation uk south korea result showed integrating augmented reality service building automation tool connected bim server enhances decision making site operation generating closed loop paper also highlight need developing low cost digital solution foster digitalization construction organisation limited budget right reserved elsevier,informed decision making crucial construction site operator cyber physical system including various technology augmented reality building automation tool gathering popularity within infrastructure management sector however expensive inaccessible adopt small organization paper describes prototype low cost mobile augmented reality service bim demonstrated usability pipe maintenance supporting inspection workflow management data reduction augmented reality user view decision support integration ease use prototype also collected organisation uk south korea result showed integrating augmented reality service building automation tool connected bim server enhances decision making site operation generating closed loop paper also highlight need developing low cost digital solution foster digitalization construction organisation limited budget right reserved elsevierbuilding_information_modelling building_management_systems construction_industry cyber physical_systems decision_making maintenance_engineering mobile_computing project_management structural_engineering_computingbuilding_automation_tool building_automation_tools construction_site_operators information_modeling informed_decision making infrastructure_management_sector low cost_digital_solutions low cost_mobile_augmented_reality_service
87,Analysis of emotions in the use of augmented reality technologies in education: A systematic review,"Gómez‐Rios, M. D., Paredes‐Velasco, M., Hernández‐Beleño, R. D., & Fuentes‐Pinargote, J. A. (2022). Analysis of emotions in the use of augmented reality technologies in education: A systematic review. Computer Applications in Engineering Education, 31(1), 216–234. Portico. https://doi.org/10.1002/cae.22593
",10.1002/cae.22593,"Currently, the availability and usefulness of computer applications developed supporting the teaching-learning process have increased and are progressively being used in different branches of education. Given the importance of emotions in learning, it is appropriate to review the influence of the use of technology in this field. Out of the many existing technologies, augmented reality (AR) has been of great interest to this study due to its great potential in learning. Therefore, the present study carries out a systematic mapping, whose objective is to review how AR technology influences the emotional state of the student in the learning process. The study indicates that the application of AR technology has both advantages and disadvantages. On the one hand, the use of AR on students produces enjoyment and interest due to visual feedback provided by AR, enthusiasm about the use of innovative technology tools, and curiosity when they view and interact with virtual objects in 3D. The attractive visualizations used and feedback generated by AR applications can reduce the cognitive load and increase student motivation in the learning process. On the other hand, AR may present some negative aspects, such as ergonomic problems, which produce that users prone to dizziness or nausea may reject the use of AR devices and a complex interaction when users must use multiple devices. Besides this, it should not be forgotten that their application may entail technological requirements and associated costs that may be difficult for some schools to afford. &#169; 2023 Wiley Periodicals LLC.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C7810C Computer-aided instruction,AR applications;AR technology;attractive visualizations;augmented reality technologies;computer applications;different branches;emotional state;enjoyment;innovative technology tools;student motivation;systematic mapping;systematic review;teaching-learning process;technological requirements;virtual objects;visual feedback,augmented reality;cognition;computer aided instruction;ergonomics;human factors;teaching;virtual reality,2023,Journal article (JA),Comput. Appl. Eng. Educ. (USA),"(1) Go&#769;mez-rios, M.D.; (2) Paredes-velasco, M.; (3) Herna&#769;ndez-belen&#771;o, R.D.; (1) Fuentes-pinargote, J.A.; ","(1) Politecnica Salesiana University, Department of Computer Science, Ecuador; (2) Universidad Rey Juan Carlos, Department of Computing and Statics, Spain; (3) Universidad Militar Nueva Granada, Department of Biomedical Engineering, Colombia; ",Wiley,-1,"[""cognition"", ""computer aided instruction"", ""ergonomics"", ""human factors"", ""teaching""]","[""cognition"", ""computer aided instruction"", ""ergonomics"", ""human factors"", ""teaching""]",cognition;computer aided instruction;ergonomics;human factors;teaching,human factors;education;training,end users and user experience;use cases;industries,human factors;education;training,end users and user experience;use cases;industries,cognition computer_aided_instruction ergonomics human_factors teaching ar_applications ar_technology attractive_visualizations augmented_reality_technologies computer_applications different_branches emotional_state enjoyment innovative_technology_tools student_motivation systematic_mapping systematic_review teaching learning_process technological_requirements virtual_objects visual_feedback c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education training,cognition computer_aided_instruction ergonomics human_factors teaching,ar_applications ar_technology attractive_visualizations augmented_reality_technologies computer_applications different_branches emotional_state enjoyment innovative_technology_tools student_motivation systematic_mapping systematic_review teaching learning_process technological_requirements virtual_objects visual_feedback,currently availability usefulness computer application developed supporting teaching learning process increased progressively used different branch education given importance emotion learning appropriate review influence use technology field many existing technology augmented reality ar great interest study due great potential learning therefore present study carry systematic mapping whose objective review ar technology influence emotional state student learning process study indicates application ar technology advantage disadvantage one hand use ar student produce enjoyment interest due visual feedback provided ar enthusiasm use innovative technology tool curiosity view interact virtual object 3d attractive visualization used feedback generated ar application reduce cognitive load increase student motivation learning process hand ar may present negative aspect ergonomic problem produce user prone dizziness nausea may reject use ar device complex interaction user must use multiple device besides forgotten application may entail technological requirement associated cost may difficult school afford 169 2023 wiley periodical llc,cognition computer_aided_instruction ergonomics human_factors teaching ar_applications ar_technology attractive_visualizations augmented_reality_technologies computer_applications different_branches emotional_state enjoyment innovative_technology_tools student_motivation systematic_mapping systematic_review teaching learning_process technological_requirements virtual_objects visual_feedback c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education training currently availability usefulness computer application developed supporting teaching learning process increased progressively used different branch education given importance emotion learning appropriate review influence use technology field many existing technology augmented reality ar great interest study due great potential learning therefore present study carry systematic mapping whose objective review ar technology influence emotional state student learning process study indicates application ar technology advantage disadvantage one hand use ar student produce enjoyment interest due visual feedback provided ar enthusiasm use innovative technology tool curiosity view interact virtual object 3d attractive visualization used feedback generated ar application reduce cognitive load increase student motivation learning process hand ar may present negative aspect ergonomic problem produce user prone dizziness nausea may reject use ar device complex interaction user must use multiple device besides forgotten application may entail technological requirement associated cost may difficult school afford 169 2023 wiley periodical llc,currently availability usefulness computer application developed supporting teaching learning process increased progressively used different branch education given importance emotion learning appropriate review influence use technology field many existing technology augmented reality ar great interest study due great potential learning therefore present study carry systematic mapping whose objective review ar technology influence emotional state student learning process study indicates application ar technology advantage disadvantage one hand use ar student produce enjoyment interest due visual feedback provided ar enthusiasm use innovative technology tool curiosity view interact virtual object 3d attractive visualization used feedback generated ar application reduce cognitive load increase student motivation learning process hand ar may present negative aspect ergonomic problem produce user prone dizziness nausea may reject use ar device complex interaction user must use multiple device besides forgotten application may entail technological requirement associated cost may difficult school afford 169 2023 wiley periodical llccognition computer_aided_instruction ergonomics human_factors teachingar_applications ar_technology attractive_visualizations augmented_reality_technologies computer_applications different_branches emotional_state enjoyment innovative_technology_tools student_motivation systematic_mapping systematic_review teaching learning_process technological_requirements virtual_objects visual_feedback
88,Augmented Reality for Programming Teaching: An Exploratory Study,"Branco, J., & Pombo, N. (2023). Augmented Reality for Programming Teaching: An Exploratory Study. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125256
",10.1109/EDUCON54358.2023.10125256,"The growing adoption of instructional technology in education has been driven by its contribution to society's development. Our study aimed to examine the use of Augmented Reality (AR) in teaching Python programming principles. The study consisted of three phases: a systematic review of AR using the PRISMA statement, the development of a mobile AR application called ""EDUpy,"" and the evaluation of EDUpy through two experiences with undergraduate students enrolled in different course units. The study found 30 studies in literature focused on the introduction of AR in educational contexts, ranging from kindergarten to higher education. Additionally, 57 students were enrolled in the experiences and the results showed that EDUpy was suitable in terms of user experience and effective in achieving students' learning goals. Further research is necessary to determine the impact of the application on students' soft skills, such as creativity, engagement, motivation, teamwork, and self-learning.",C7810C Computer-aided instruction;C0220 Computing education and training;C6130V Virtual reality,Augmented Reality;different course units;educational contexts;EDUpy;growing adoption;higher education;instructional technology;PRISMA statement;programming teaching;Python programming principles;society;systematic review;undergraduate students;user experience,augmented reality;computer aided instruction;computer science education;educational courses;further education;human factors;Python;teaching,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Branco, J.; (2) Pombo, N.; ","(1) Universidade da Beira Interior, Portugal; (2) Universidade da Beira Interior, Instituto de Telecomunicac&#807;o&#771;es, Portugal; ",IEEE,-1,"[""computer aided instruction"", ""computer science education"", ""educational courses"", ""further education"", ""human factors"", ""python"", ""teaching""]","[""computer aided instruction"", ""computer science education"", ""educational courses"", ""further education"", ""human factors"", ""python"", ""teaching""]",computer aided instruction;computer science education;educational courses;further education;human factors;python;teaching,education;other;training;human factors;developers,other;end users and user experience;industries;use cases;technology,education;other;training;human factors;developers,other;end users and user experience;industries;use cases;technology,computer_aided_instruction computer_science_education educational_courses further_education human_factors python teaching augmented_reality different_course_units educational_contexts edupy growing_adoption higher_education instructional_technology prisma_statement programming_teaching python_programming_principles society systematic_review undergraduate_students user_experience c7810c_computer aided_instruction c0220_computing_education_and_training c6130v_virtual_reality education other training human_factors developers,computer_aided_instruction computer_science_education educational_courses further_education human_factors python teaching,augmented_reality different_course_units educational_contexts edupy growing_adoption higher_education instructional_technology prisma_statement programming_teaching python_programming_principles society systematic_review undergraduate_students user_experience,growing adoption instructional technology education driven contribution society development study aimed examine use augmented reality ar teaching python programming principle study consisted three phase systematic review ar using prisma statement development mobile ar application called edupy evaluation edupy two experience undergraduate student enrolled different course unit study found 30 study literature focused introduction ar educational context ranging kindergarten higher education additionally 57 student enrolled experience result showed edupy suitable term user experience effective achieving student learning goal research necessary determine impact application student soft skill creativity engagement motivation teamwork self learning,computer_aided_instruction computer_science_education educational_courses further_education human_factors python teaching augmented_reality different_course_units educational_contexts edupy growing_adoption higher_education instructional_technology prisma_statement programming_teaching python_programming_principles society systematic_review undergraduate_students user_experience c7810c_computer aided_instruction c0220_computing_education_and_training c6130v_virtual_reality education other training human_factors developers growing adoption instructional technology education driven contribution society development study aimed examine use augmented reality ar teaching python programming principle study consisted three phase systematic review ar using prisma statement development mobile ar application called edupy evaluation edupy two experience undergraduate student enrolled different course unit study found 30 study literature focused introduction ar educational context ranging kindergarten higher education additionally 57 student enrolled experience result showed edupy suitable term user experience effective achieving student learning goal research necessary determine impact application student soft skill creativity engagement motivation teamwork self learning,growing adoption instructional technology education driven contribution society development study aimed examine use augmented reality ar teaching python programming principle study consisted three phase systematic review ar using prisma statement development mobile ar application called edupy evaluation edupy two experience undergraduate student enrolled different course unit study found 30 study literature focused introduction ar educational context ranging kindergarten higher education additionally 57 student enrolled experience result showed edupy suitable term user experience effective achieving student learning goal research necessary determine impact application student soft skill creativity engagement motivation teamwork self learningcomputer_aided_instruction computer_science_education educational_courses further_education human_factors python teachingaugmented_reality different_course_units educational_contexts edupy growing_adoption higher_education instructional_technology prisma_statement programming_teaching python_programming_principles society systematic_review undergraduate_students user_experience
89,Smart Teaching Materials with Real-Time Augmented Reality Support for Introductory Physics Education,"Javaheri, H., Lauer, F., Lauer, L., Altmeyer, K., Brünken, R., Peschel, M., Wehn, N., & Lukowicz, P. (2022). Smart Teaching Materials with Real-Time Augmented Reality Support for Introductory Physics Education. Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3560322
",10.1145/3544793.3560322,"In this demonstration, we present a system design that helps to reduce the split attention effect in multimedia learning by providing an interactive environment with augmented reality support for elementary physics education. The system consists of three main components: smart boxes, smart cables, and visualization app. Each smart box contains an input to plug different electrical components (bulb, battery, and switches) and two sockets to interconnect the boxes with each other using smart cables. These boxes are equipped with various sensor modalities that provide information related to connected cable identifications and the physical status of the boxes. This information is shared through a Bluetooth Low Energy interface with the connected visualization device. Visualization devices range between handheld tablets with augmented reality capabilities and headwear smart glasses. These devices are used to run the supportive app. The app is responsible to track the smart boxes using markers and provide a 3D augmented visualization of information coming from them. This system targets introductory physics education, in addition holds the potential to provide assistance for more advanced electrical circuits in secondary or higher physics education.","C6130V Virtual reality;C6130B Graphics techniques;C6130M Multimedia;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction",3D augmented visualization;augmented reality capabilities;augmented reality support;connected cable identifications;connected visualization device;different electrical components;elementary physics education;headwear smart glasses;higher physics education;introductory physics education;physical status;secondary physics education;smart box;smart cables;smart teaching materials;split attention effect;supportive app;system design;visualization app;visualization devices,augmented reality;Bluetooth;computer aided instruction;mobile computing;physics education;teaching,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) Javaheri, H.; (2) Lauer, F.; (3) Lauer, L.; (3) Altmeyer, K.; (3) Bru&#776;nken, R.; (3) Peschel, M.; (2) Wehn, N.; (1) Lukowicz, P.; ","(1) Deutsches Forschungszentrum fur Kunstliche Intelligenz GmbH, Germany; (2) Technische Universitat Kaiserslautern, Department of Electrical and Computer Engineering, Germany; (3) Saarland University, Germany; ",ACM,-1,"[""bluetooth"", ""computer aided instruction"", ""mobile computing"", ""physics education"", ""teaching""]","[""bluetooth"", ""computer aided instruction"", ""mobile computing"", ""physics education"", ""teaching""]",bluetooth;computer aided instruction;mobile computing;physics education;teaching,education;training;telecommunication;engineering;networks,technology;use cases;industries,education;training;telecommunication;engineering;networks,technology;use cases;industries,bluetooth computer_aided_instruction mobile_computing physics_education teaching 3d_augmented_visualization augmented_reality_capabilities augmented_reality_support connected_cable_identifications connected_visualization_device different_electrical_components elementary_physics_education headwear_smart_glasses higher_physics_education introductory_physics_education physical_status secondary_physics_education smart_box smart_cables smart_teaching_materials split_attention_effect supportive_app system_design visualization_app visualization_devices c6130v_virtual_reality c6130b_graphics_techniques c6130m_multimedia c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction education training telecommunication engineering networks,bluetooth computer_aided_instruction mobile_computing physics_education teaching,3d_augmented_visualization augmented_reality_capabilities augmented_reality_support connected_cable_identifications connected_visualization_device different_electrical_components elementary_physics_education headwear_smart_glasses higher_physics_education introductory_physics_education physical_status secondary_physics_education smart_box smart_cables smart_teaching_materials split_attention_effect supportive_app system_design visualization_app visualization_devices,demonstration present system design help reduce split attention effect multimedia learning providing interactive environment augmented reality support elementary physic education system consists three main component smart box smart cable visualization app smart box contains input plug different electrical component bulb battery switch two socket interconnect box using smart cable box equipped various sensor modality provide information related connected cable identification physical status box information shared bluetooth low energy interface connected visualization device visualization device range handheld tablet augmented reality capability headwear smart glass device used run supportive app app responsible track smart box using marker provide 3d augmented visualization information coming system target introductory physic education addition hold potential provide assistance advanced electrical circuit secondary higher physic education,bluetooth computer_aided_instruction mobile_computing physics_education teaching 3d_augmented_visualization augmented_reality_capabilities augmented_reality_support connected_cable_identifications connected_visualization_device different_electrical_components elementary_physics_education headwear_smart_glasses higher_physics_education introductory_physics_education physical_status secondary_physics_education smart_box smart_cables smart_teaching_materials split_attention_effect supportive_app system_design visualization_app visualization_devices c6130v_virtual_reality c6130b_graphics_techniques c6130m_multimedia c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction education training telecommunication engineering networks demonstration present system design help reduce split attention effect multimedia learning providing interactive environment augmented reality support elementary physic education system consists three main component smart box smart cable visualization app smart box contains input plug different electrical component bulb battery switch two socket interconnect box using smart cable box equipped various sensor modality provide information related connected cable identification physical status box information shared bluetooth low energy interface connected visualization device visualization device range handheld tablet augmented reality capability headwear smart glass device used run supportive app app responsible track smart box using marker provide 3d augmented visualization information coming system target introductory physic education addition hold potential provide assistance advanced electrical circuit secondary higher physic education,demonstration present system design help reduce split attention effect multimedia learning providing interactive environment augmented reality support elementary physic education system consists three main component smart box smart cable visualization app smart box contains input plug different electrical component bulb battery switch two socket interconnect box using smart cable box equipped various sensor modality provide information related connected cable identification physical status box information shared bluetooth low energy interface connected visualization device visualization device range handheld tablet augmented reality capability headwear smart glass device used run supportive app app responsible track smart box using marker provide 3d augmented visualization information coming system target introductory physic education addition hold potential provide assistance advanced electrical circuit secondary higher physic educationbluetooth computer_aided_instruction mobile_computing physics_education teaching3d_augmented_visualization augmented_reality_capabilities augmented_reality_support connected_cable_identifications connected_visualization_device different_electrical_components elementary_physics_education headwear_smart_glasses higher_physics_education introductory_physics_education physical_status secondary_physics_education smart_box smart_cables smart_teaching_materials split_attention_effect supportive_app system_design visualization_app visualization_devices
90,"Augmented reality navigation application to promote tourism to local state attraction ""Lawang Sewu""","Pranoto, H., Saputra, P. P., Sadekh, M., Darmadi, H., & Yanfi, Y. (2023). Augmented reality navigation application to promote tourism to local state attraction “Lawang Sewu.” Procedia Computer Science, 216, 757–764. https://doi.org/10.1016/j.procs.2022.12.193
",10.1016/j.procs.2022.12.193,"The writing of this paper and the creation of this application is a means to improve and add on facilities on the local state-run attraction. This subject matter was picked in conjunction with the decline of tourism in the said historical site due to a pandemic that rankles Indonesia's tourism industry and drives it to the ground. Augmented Reality as a method of deliverance was picked due to its popularity and freshness in the tourism market. The research method was conducted starting with analysis, development, implementation, then evaluation. Analysis was done using sourcing available to the public and a questioner. Implementation was done using Unity, Vuforia, and Maya. And with the positive responses of 66.6 percent of the sample market finding enjoyment in the use of this application in their exploration during User Acceptance testing with the existing prototype. This shows that the resulting use of this application improves user enjoyment in experiencing the state attraction. All rights reserved Elsevier.",C6130V Virtual reality;C7185 Administration of other service industries;E2110B Building structures,augmented reality navigation application;efficiency 66.6 percent;freshness;historical site;Lawang Sewu;local state attraction;local state-run attraction;rankles Indonesia's tourism industry;sample market;tourism market,augmented reality;building management systems;buildings (structures);energy conservation;space cooling;temperature measurement;thermal comfort;travel industry,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Pranoto, H.; (1) Saputra, P.P.; (1) Sadekh, M.; (1) Darmadi, H.; (1) Yanfi, Y.; ","(1) Bina Nusantara University, School of Computer Science, Indonesia; ",Elsevier B.V.,-1,"[""building management systems"", ""buildings"", ""energy conservation"", ""space cooling"", ""temperature measurement"", ""thermal comfort"", ""travel industry""]","[""building management systems"", ""buildings"", ""energy conservation"", ""space cooling"", ""temperature measurement"", ""thermal comfort"", ""travel industry""]",building management systems;buildings;energy conservation;space cooling;temperature measurement;thermal comfort;travel industry,"construction;education;farming and natural science;other;transportation;sensors;inspection, safety and quality;power and energy;human factors",other;end users and user experience;industries;use cases;technology,"construction;education;farming and natural science;other;transportation;sensors;inspection, safety and quality;power and energy;human factors",other;end users and user experience;industries;use cases;technology,building_management_systems buildings energy_conservation space_cooling temperature_measurement thermal_comfort travel_industry augmented_reality_navigation_application efficiency_66 6_percent freshness historical_site lawang_sewu local_state_attraction local_state run_attraction rankles_indonesia s_tourism_industry sample_market tourism_market c6130v_virtual_reality c7185_administration_of_other_service_industries e2110b_building_structures construction education farming_and_natural_science other transportation sensors inspection _safety_and_quality power_and_energy human_factors,building_management_systems buildings energy_conservation space_cooling temperature_measurement thermal_comfort travel_industry,augmented_reality_navigation_application efficiency_66 6_percent freshness historical_site lawang_sewu local_state_attraction local_state run_attraction rankles_indonesia s_tourism_industry sample_market tourism_market,writing paper creation application mean improve add facility local state run attraction subject matter picked conjunction decline tourism said historical site due pandemic rankles indonesia tourism industry drive ground augmented reality method deliverance picked due popularity freshness tourism market research method conducted starting analysis development implementation evaluation analysis done using sourcing available public questioner implementation done using unity vuforia maya positive response 66 6 percent sample market finding enjoyment use application exploration user acceptance testing existing prototype show resulting use application improves user enjoyment experiencing state attraction right reserved elsevier,building_management_systems buildings energy_conservation space_cooling temperature_measurement thermal_comfort travel_industry augmented_reality_navigation_application efficiency_66 6_percent freshness historical_site lawang_sewu local_state_attraction local_state run_attraction rankles_indonesia s_tourism_industry sample_market tourism_market c6130v_virtual_reality c7185_administration_of_other_service_industries e2110b_building_structures construction education farming_and_natural_science other transportation sensors inspection _safety_and_quality power_and_energy human_factors writing paper creation application mean improve add facility local state run attraction subject matter picked conjunction decline tourism said historical site due pandemic rankles indonesia tourism industry drive ground augmented reality method deliverance picked due popularity freshness tourism market research method conducted starting analysis development implementation evaluation analysis done using sourcing available public questioner implementation done using unity vuforia maya positive response 66 6 percent sample market finding enjoyment use application exploration user acceptance testing existing prototype show resulting use application improves user enjoyment experiencing state attraction right reserved elsevier,writing paper creation application mean improve add facility local state run attraction subject matter picked conjunction decline tourism said historical site due pandemic rankles indonesia tourism industry drive ground augmented reality method deliverance picked due popularity freshness tourism market research method conducted starting analysis development implementation evaluation analysis done using sourcing available public questioner implementation done using unity vuforia maya positive response 66 6 percent sample market finding enjoyment use application exploration user acceptance testing existing prototype show resulting use application improves user enjoyment experiencing state attraction right reserved elsevierbuilding_management_systems buildings energy_conservation space_cooling temperature_measurement thermal_comfort travel_industryaugmented_reality_navigation_application efficiency_66 6_percent freshness historical_site lawang_sewu local_state_attraction local_state run_attraction rankles_indonesia s_tourism_industry sample_market tourism_market
91,Comparison of Physical Activity Training Using Augmented Reality and Conventional Therapy on Physical Performance following a Total Knee Replacement: A Randomized Controlled Trial,"Yu, J.-H., Nekar, D. M., Kang, H.-Y., Lee, J.-W., & Oh, S.-Y. (2023). Comparison of Physical Activity Training Using Augmented Reality and Conventional Therapy on Physical Performance following a Total Knee Replacement: A Randomized Controlled Trial. Applied Sciences, 13(2), 894. https://doi.org/10.3390/app13020894
",10.3390/app13020894,"There is growing interest in using augmented reality (AR)-based training for rehabilitation programs, while it remains unclear whether physical exercises using AR can be more effective than conventional therapy for patients with total knee replacement (TKR). This study, therefore, aimed to compare the effects of AR-based training to conventional therapist-based training on the physical performance of early-stage rehabilitation in patients after a TKR. It was a double-blind randomized controlled trial with repeated measures (pre-surgery, post-surgery, and post-intervention). Twenty-four participants with TKR were allocated to either AR-based training or therapist-based training. Both groups received a training program for 30 min per session, three sessions per week, for four weeks. The outcome measures included the range of motion (ROM), muscle strength, balance, and perceived pain. The results showed significant improvements in all measured outcomes in both groups (&lt;i&gt;p&lt;/i&gt;&lt; 0.05). However, despite our hypothesis that ART would be more effective than the TKR, no significant differences in all the outcomes were found between the two groups. While there was some evidence showing that performing physical exercises using AR could improve physical performance in patients with TKR after surgery, a comparison with conventional therapy did not show superior effectiveness. However, AR could be used to provide real-time feedback and motivation appropriate for home-training programs.",A8770G Patient care and treatment;A8745D Physics of body movements;A8770J Prosthetics and other practical applications;B7520 Patient care and treatment;B7520E Prosthetics and orthotics;C3385 Biological and medical control systems;C6130V Virtual reality;C7330 Biology and medical computing,AR-based training;augmented reality-based training;balance;double-blind randomized controlled trial;early-stage rehabilitation;home-training programs;motion range;muscle strength;perceived pain;physical activity training;physical exercises;rehabilitation programs;therapist-based training;time 30.0 min;TKR;total knee replacement,augmented reality;biomechanics;medical computing;muscle;patient rehabilitation;prosthetics;surgery,2023,Journal article (JA),Appl. Sci. (Switzerland),"(1) Yu, J.-H.; (1) Nekar, D.M.; (1) Kang, H.-Y.; (1) Lee, J.-W.; (1) Oh, S.-Y.; ","(1) SunMoon University, Department of Physical Therapy, Korea, Republic of; ",MDPI,-1,"[""biomechanics"", ""medical computing"", ""muscle"", ""patient rehabilitation"", ""prosthetics"", ""surgery""]","[""biomechanics"", ""medical computing"", ""muscle"", ""patient rehabilitation"", ""prosthetics"", ""surgery""]",biomechanics;medical computing;muscle;patient rehabilitation;prosthetics;surgery,medical,industries,medical,industries,biomechanics medical_computing muscle patient_rehabilitation prosthetics surgery ar based_training augmented_reality based_training balance double blind_randomized_controlled_trial early stage_rehabilitation home training_programs motion_range muscle_strength perceived_pain physical_activity_training physical_exercises rehabilitation_programs therapist based_training time_30 0_min tkr total_knee_replacement a8770g_patient_care_and_treatment a8745d_physics_of_body_movements a8770j_prosthetics_and_other_practical_applications b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c6130v_virtual_reality c7330_biology_and_medical_computing medical,biomechanics medical_computing muscle patient_rehabilitation prosthetics surgery,ar based_training augmented_reality based_training balance double blind_randomized_controlled_trial early stage_rehabilitation home training_programs motion_range muscle_strength perceived_pain physical_activity_training physical_exercises rehabilitation_programs therapist based_training time_30 0_min tkr total_knee_replacement,growing interest using augmented reality ar based training rehabilitation program remains unclear whether physical exercise using ar effective conventional therapy patient total knee replacement tkr study therefore aimed compare effect ar based training conventional therapist based training physical performance early stage rehabilitation patient tkr double blind randomized controlled trial repeated measure pre surgery post surgery post intervention twenty four participant tkr allocated either ar based training therapist based training group received training program 30 min per session three session per week four week outcome measure included range motion rom muscle strength balance perceived pain result showed significant improvement measured outcome group lt gt p lt gt lt 0 05 however despite hypothesis art would effective tkr significant difference outcome found two group evidence showing performing physical exercise using ar could improve physical performance patient tkr surgery comparison conventional therapy show superior effectiveness however ar could used provide real time feedback motivation appropriate home training program,biomechanics medical_computing muscle patient_rehabilitation prosthetics surgery ar based_training augmented_reality based_training balance double blind_randomized_controlled_trial early stage_rehabilitation home training_programs motion_range muscle_strength perceived_pain physical_activity_training physical_exercises rehabilitation_programs therapist based_training time_30 0_min tkr total_knee_replacement a8770g_patient_care_and_treatment a8745d_physics_of_body_movements a8770j_prosthetics_and_other_practical_applications b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c6130v_virtual_reality c7330_biology_and_medical_computing medical growing interest using augmented reality ar based training rehabilitation program remains unclear whether physical exercise using ar effective conventional therapy patient total knee replacement tkr study therefore aimed compare effect ar based training conventional therapist based training physical performance early stage rehabilitation patient tkr double blind randomized controlled trial repeated measure pre surgery post surgery post intervention twenty four participant tkr allocated either ar based training therapist based training group received training program 30 min per session three session per week four week outcome measure included range motion rom muscle strength balance perceived pain result showed significant improvement measured outcome group lt gt p lt gt lt 0 05 however despite hypothesis art would effective tkr significant difference outcome found two group evidence showing performing physical exercise using ar could improve physical performance patient tkr surgery comparison conventional therapy show superior effectiveness however ar could used provide real time feedback motivation appropriate home training program,growing interest using augmented reality ar based training rehabilitation program remains unclear whether physical exercise using ar effective conventional therapy patient total knee replacement tkr study therefore aimed compare effect ar based training conventional therapist based training physical performance early stage rehabilitation patient tkr double blind randomized controlled trial repeated measure pre surgery post surgery post intervention twenty four participant tkr allocated either ar based training therapist based training group received training program 30 min per session three session per week four week outcome measure included range motion rom muscle strength balance perceived pain result showed significant improvement measured outcome group lt gt p lt gt lt 0 05 however despite hypothesis art would effective tkr significant difference outcome found two group evidence showing performing physical exercise using ar could improve physical performance patient tkr surgery comparison conventional therapy show superior effectiveness however ar could used provide real time feedback motivation appropriate home training programbiomechanics medical_computing muscle patient_rehabilitation prosthetics surgeryar based_training augmented_reality based_training balance double blind_randomized_controlled_trial early stage_rehabilitation home training_programs motion_range muscle_strength perceived_pain physical_activity_training physical_exercises rehabilitation_programs therapist based_training time_30 0_min tkr total_knee_replacement
92,PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality,"Wang, Z., Nguyen, C., Asente, P., & Dorsey, J. (2023). PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580776
",10.1145/3544548.3580776,"We present PointShopAR, a novel tablet-based system for AR environmental design using point clouds as the underlying representation. It integrates point cloud capture and editing in a single AR workflow to help users quickly prototype design ideas in their spatial context. We hypothesize that point clouds are well suited for prototyping, as they can be captured more rapidly than textured meshes and then edited immediately in situ on the capturing device. We based the design of PointShopAR on the practical needs of six architects in a formative study. Our system supports a variety of point cloud editing operations in AR, including selection, transformation, hole filling, drawing, morphing, and animation. We evaluate PointShopAR through a remote study on usability and an in-person study on environmental design support. Participants were able to iterate design rapidly, showing the merits of an integrated capture and editing workflow with point clouds in AR environmental design.",C6130V Virtual reality;C6130B Graphics techniques,animation;AR environmental design;augmented reality environmental design;drawing;environmental design prototyping;environmental design support;hole filling;morphing;point cloud capture;PointShopAR;selection;tablet-based system;transformation;workflow editing,augmented reality;computational geometry;computer animation;notebook computers,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Wang, Z.; (2) Nguyen, C.; (2) Asente, P.; (3) Dorsey, J.; ","(1) Hong Kong University of Science and Technology, Computational Media and Arts, China; (2) Adobe Research, United States; (3) Yale University, Department of Computer Science, New Haven, CT, United States; ",ACM,-1,"[""computational geometry"", ""computer animation"", ""notebook computers""]","[""computational geometry"", ""computer animation"", ""notebook computers""]",computational geometry;computer animation;notebook computers,artificial intelligence;developers;input;graphics,technology,artificial intelligence;developers;input;graphics,technology,computational_geometry computer_animation notebook_computers animation ar_environmental_design augmented_reality_environmental_design drawing environmental_design_prototyping environmental_design_support hole_filling morphing point_cloud_capture pointshopar selection tablet based_system transformation workflow_editing c6130v_virtual_reality c6130b_graphics_techniques artificial_intelligence developers input graphics,computational_geometry computer_animation notebook_computers,animation ar_environmental_design augmented_reality_environmental_design drawing environmental_design_prototyping environmental_design_support hole_filling morphing point_cloud_capture pointshopar selection tablet based_system transformation workflow_editing,present pointshopar novel tablet based system ar environmental design using point cloud underlying representation integrates point cloud capture editing single ar workflow help user quickly prototype design idea spatial context hypothesize point cloud well suited prototyping captured rapidly textured mesh edited immediately situ capturing device based design pointshopar practical need six architect formative study system support variety point cloud editing operation ar including selection transformation hole filling drawing morphing animation evaluate pointshopar remote study usability person study environmental design support participant able iterate design rapidly showing merit integrated capture editing workflow point cloud ar environmental design,computational_geometry computer_animation notebook_computers animation ar_environmental_design augmented_reality_environmental_design drawing environmental_design_prototyping environmental_design_support hole_filling morphing point_cloud_capture pointshopar selection tablet based_system transformation workflow_editing c6130v_virtual_reality c6130b_graphics_techniques artificial_intelligence developers input graphics present pointshopar novel tablet based system ar environmental design using point cloud underlying representation integrates point cloud capture editing single ar workflow help user quickly prototype design idea spatial context hypothesize point cloud well suited prototyping captured rapidly textured mesh edited immediately situ capturing device based design pointshopar practical need six architect formative study system support variety point cloud editing operation ar including selection transformation hole filling drawing morphing animation evaluate pointshopar remote study usability person study environmental design support participant able iterate design rapidly showing merit integrated capture editing workflow point cloud ar environmental design,present pointshopar novel tablet based system ar environmental design using point cloud underlying representation integrates point cloud capture editing single ar workflow help user quickly prototype design idea spatial context hypothesize point cloud well suited prototyping captured rapidly textured mesh edited immediately situ capturing device based design pointshopar practical need six architect formative study system support variety point cloud editing operation ar including selection transformation hole filling drawing morphing animation evaluate pointshopar remote study usability person study environmental design support participant able iterate design rapidly showing merit integrated capture editing workflow point cloud ar environmental designcomputational_geometry computer_animation notebook_computersanimation ar_environmental_design augmented_reality_environmental_design drawing environmental_design_prototyping environmental_design_support hole_filling morphing point_cloud_capture pointshopar selection tablet based_system transformation workflow_editing
93,Augmented Reality as an Educational Tool and Assistive Technology for People with Intellectual Disabilities: Scoping Review,"Zhu, Y., Roomkham, S., & Sitbon, L. (2022). Augmented Reality as an Educational Tool and Assistive Technology for People with Intellectual Disabilities: Scoping Review. Proceedings of the 34th Australian Conference on Human-Computer Interaction. https://doi.org/10.1145/3572921.3576218
",10.1145/3572921.3576218,"Many people with intellectual disability seek opportunities to develop their self-determination, personal development, interpersonal relationships, and well-being. Emerging technologies, such as augmented reality (AR), present an opportunity for new approaches to supporting inclusion and personal development. AR interactively integrates digital information and the real world, and has been increasingly used as a tool for intervention, education, or as an assistive technology. However, there has been little attention to how AR applications can engage and support people with intellectual disability. This paper presents a scoping review of seventeen studies in the past decade and discusses the benefits highlighted by the authors. Most studies conducted with people with intellectual disability have shown that AR performs a positive and effective role as an instructional or assistive tool in the areas of education, daily living, or health. AR provides an opportunity to help people acquire new knowledge (e.g., foreign language and numeracy), form new habits (e.g., teeth brushing technique), and experience environments inclusively (e.g., arrive to the classroom with the support of an AR navigation app on the smartphone). Hence, this paper provides a comprehensive overview of known useful aspects of AR technology in the support and inclusion of people with intellectual disabilities.","C6190V Mobile, ubiquitous and pervasive computing;C6130V Virtual reality;C7810C Computer-aided instruction;C7850 Computer assistance for persons with handicaps",assistive technology;assistive tool;augmented reality;educational tool;instructional tool;intellectual disability;personal development;scoping review;support people,augmented reality;computer aided instruction;handicapped aids;mobile computing;smart phones,2022,Conference article (CA),OzCHI '22: Proceedings of the 34th Australian Conference on Human-Computer Interaction,"(1) Zhu, Y.; (1) Roomkham, S.; (1) Sitbon, L.; ","(1) Queensland University of Technology, School of Computer Science, Brisbane, QLD, Australia; ",ACM,-1,"[""computer aided instruction"", ""handicapped aids"", ""mobile computing"", ""smartphones""]","[""computer aided instruction"", ""handicapped aids"", ""mobile computing"", ""smartphones""]",computer aided instruction;handicapped aids;mobile computing;smartphones,medical;telecommunication;training;liberal arts,use cases;industries,medical;telecommunication;training;liberal arts,use cases;industries,computer_aided_instruction handicapped_aids mobile_computing smartphones assistive_technology assistive_tool augmented_reality educational_tool instructional_tool intellectual_disability personal_development scoping_review support_people c6190v_mobile _ubiquitous_and_pervasive_computing c6130v_virtual_reality c7810c_computer aided_instruction c7850_computer_assistance_for_persons_with_handicaps medical telecommunication training liberal_arts,computer_aided_instruction handicapped_aids mobile_computing smartphones,assistive_technology assistive_tool augmented_reality educational_tool instructional_tool intellectual_disability personal_development scoping_review support_people,many people intellectual disability seek opportunity develop self determination personal development interpersonal relationship well emerging technology augmented reality ar present opportunity new approach supporting inclusion personal development ar interactively integrates digital information real world increasingly used tool intervention education assistive technology however little attention ar application engage support people intellectual disability paper present scoping review seventeen study past decade discus benefit highlighted author study conducted people intellectual disability shown ar performs positive effective role instructional assistive tool area education daily living health ar provides opportunity help people acquire new knowledge e g foreign language numeracy form new habit e g teeth brushing technique experience environment inclusively e g arrive classroom support ar navigation app smartphone hence paper provides comprehensive overview known useful aspect ar technology support inclusion people intellectual disability,computer_aided_instruction handicapped_aids mobile_computing smartphones assistive_technology assistive_tool augmented_reality educational_tool instructional_tool intellectual_disability personal_development scoping_review support_people c6190v_mobile _ubiquitous_and_pervasive_computing c6130v_virtual_reality c7810c_computer aided_instruction c7850_computer_assistance_for_persons_with_handicaps medical telecommunication training liberal_arts many people intellectual disability seek opportunity develop self determination personal development interpersonal relationship well emerging technology augmented reality ar present opportunity new approach supporting inclusion personal development ar interactively integrates digital information real world increasingly used tool intervention education assistive technology however little attention ar application engage support people intellectual disability paper present scoping review seventeen study past decade discus benefit highlighted author study conducted people intellectual disability shown ar performs positive effective role instructional assistive tool area education daily living health ar provides opportunity help people acquire new knowledge e g foreign language numeracy form new habit e g teeth brushing technique experience environment inclusively e g arrive classroom support ar navigation app smartphone hence paper provides comprehensive overview known useful aspect ar technology support inclusion people intellectual disability,many people intellectual disability seek opportunity develop self determination personal development interpersonal relationship well emerging technology augmented reality ar present opportunity new approach supporting inclusion personal development ar interactively integrates digital information real world increasingly used tool intervention education assistive technology however little attention ar application engage support people intellectual disability paper present scoping review seventeen study past decade discus benefit highlighted author study conducted people intellectual disability shown ar performs positive effective role instructional assistive tool area education daily living health ar provides opportunity help people acquire new knowledge e g foreign language numeracy form new habit e g teeth brushing technique experience environment inclusively e g arrive classroom support ar navigation app smartphone hence paper provides comprehensive overview known useful aspect ar technology support inclusion people intellectual disabilitycomputer_aided_instruction handicapped_aids mobile_computing smartphonesassistive_technology assistive_tool augmented_reality educational_tool instructional_tool intellectual_disability personal_development scoping_review support_people
94,Evaluating Working Postures with the Use of Augmented Reality and NIOSH Mobile Application,"Gonzalez-Mendivil, J. A., Rodriguez-Paz, M. X., & Zamora-Hernandez, I. (2022). Evaluating Working Postures with the Use of Augmented Reality and NIOSH Mobile Application. Proceedings of the 14th International Conference on Education Technology and Computers. https://doi.org/10.1145/3572549.3572644
",10.1145/3572549.3572644,"The evaluation of the maximum weight that a person can support during the performance of an activity related to the production or provision of services is a task of vital importance to ensure that our workers are not at risk of injuries or illnesses that impede them from doing their day-to-day job in the medium and long termSeveral studies affirm that about 20% of all injuries produced in the workplace are back injuries, and that about 30% are due to overexertion. These data provide an idea of the importance of a correct evaluation of the tasks that involve lifting loads and the adequate preparation of the positions involved. There are many measurements that we can carry out thanks to the use of methodologies such as RULAS, OWAS or the calculation of the NIOSH equation, this last topic will be addressed in this paper and how the use of NIOSH mobile applications and augmented reality achieve that the evaluation of an operator's task is carried out more efficiently.Early results have proven that there is a gain in the time that it takes to perform the activity without sacrificing the accuracy of the analysis.",C6130V Virtual reality;E0120M Human resource management;E0240H Health and safety aspects;E1410 Ergonomics,adequate preparation;augmented reality;correct evaluation;day-to-day job;injuries;long termSeveral studies affirm;maximum weight;NIOSH equation;NIOSH mobile application;working postures,augmented reality;ergonomics;injuries;lifting;occupational health;occupational safety;personnel,2022,Conference article (CA),ICETC '22: Proceedings of the 14th International Conference on Education Technology and Computers,"(1) Gonzalez-Mendivil, J.A.; (1) Rodriguez-Paz, M.X.; (1) Zamora-Hernandez, I.; ","(1) Tecnolo&#769;gico de Monterrey, Mexico; ",ACM,-1,"[""ergonomics"", ""injuries"", ""lifting"", ""occupational health"", ""occupational safety"", ""personnel""]","[""ergonomics"", ""injuries"", ""lifting"", ""occupational health"", ""occupational safety"", ""personnel""]",ergonomics;injuries;lifting;occupational health;occupational safety;personnel,"other;medical;inspection, safety and quality;human factors;human resources",other;business;industries;end users and user experience;use cases,"other;medical;inspection, safety and quality;human factors;human resources",other;business;industries;end users and user experience;use cases,ergonomics injuries lifting occupational_health occupational_safety personnel adequate_preparation augmented_reality correct_evaluation day to day_job injuries long_termseveral_studies_affirm maximum_weight niosh_equation niosh_mobile_application working_postures c6130v_virtual_reality e0120m_human_resource_management e0240h_health_and_safety_aspects e1410_ergonomics other medical inspection _safety_and_quality human_factors human_resources,ergonomics injuries lifting occupational_health occupational_safety personnel,adequate_preparation augmented_reality correct_evaluation day to day_job injuries long_termseveral_studies_affirm maximum_weight niosh_equation niosh_mobile_application working_postures,evaluation maximum weight person support performance activity related production provision service task vital importance ensure worker risk injury illness impede day day job medium long termseveral study affirm 20 injury produced workplace back injury 30 due overexertion data provide idea importance correct evaluation task involve lifting load adequate preparation position involved many measurement carry thanks use methodology rulas owas calculation niosh equation last topic addressed paper use niosh mobile application augmented reality achieve evaluation operator task carried efficiently early result proven gain time take perform activity without sacrificing accuracy analysis,ergonomics injuries lifting occupational_health occupational_safety personnel adequate_preparation augmented_reality correct_evaluation day to day_job injuries long_termseveral_studies_affirm maximum_weight niosh_equation niosh_mobile_application working_postures c6130v_virtual_reality e0120m_human_resource_management e0240h_health_and_safety_aspects e1410_ergonomics other medical inspection _safety_and_quality human_factors human_resources evaluation maximum weight person support performance activity related production provision service task vital importance ensure worker risk injury illness impede day day job medium long termseveral study affirm 20 injury produced workplace back injury 30 due overexertion data provide idea importance correct evaluation task involve lifting load adequate preparation position involved many measurement carry thanks use methodology rulas owas calculation niosh equation last topic addressed paper use niosh mobile application augmented reality achieve evaluation operator task carried efficiently early result proven gain time take perform activity without sacrificing accuracy analysis,evaluation maximum weight person support performance activity related production provision service task vital importance ensure worker risk injury illness impede day day job medium long termseveral study affirm 20 injury produced workplace back injury 30 due overexertion data provide idea importance correct evaluation task involve lifting load adequate preparation position involved many measurement carry thanks use methodology rulas owas calculation niosh equation last topic addressed paper use niosh mobile application augmented reality achieve evaluation operator task carried efficiently early result proven gain time take perform activity without sacrificing accuracy analysisergonomics injuries lifting occupational_health occupational_safety personneladequate_preparation augmented_reality correct_evaluation day to day_job injuries long_termseveral_studies_affirm maximum_weight niosh_equation niosh_mobile_application working_postures
95,CC-Glasses: Color Communication Support for People with Color Vision Deficiency Using Augmented Reality and Deep Learning,"Zhu, Z., Li, J., Tang, Y., Go, K., Toyoura, M., Kashiwagi, K., Fujishiro, I., & Mao, X. (2023). CC-Glasses: Color Communication Support for People with Color Vision Deficiency Using Augmented Reality and Deep Learning. Augmented Humans Conference. https://doi.org/10.1145/3582700.3582707
",10.1145/3582700.3582707,"People who suffer from color vision deficiency (CVD) can face difficulties when communicating with others by failing to identify target objects referred by their color names. While most existing studies on CVD compensation have focused on the issue of color contrast loss. Although there are approaches can provide clues of color name to users, these techniques either require training, or cannot protect users' privacy, i.e., the fact of having CVD. In this paper, based on augmented reality (AR) and deep learning technologies, we propose a novel system to provide supporting information to users affected by CVD for color communication assistance. The state-of-the-art deep neural network (DNN) model for referring segmentation (RS) is adopted to generate supporting information, and AR glasses are utilized for information presentation. To improve the performance of the proposed system further, a new dataset is constructed based on a novel concept called Color-Object Noun Pair. The results of evaluation experiments show that the new dataset can enhance the performance of the adopted DNN model, and the proposed system can help users affected by CVD successfully identify target objects by their color names.",C6264 Neural nets;C5260B Computer vision and image processing techniques;C6130V Virtual reality,augmented reality;color communication assistance;Color communication support;color contrast loss;color name;color vision deficiency;Color-Object Noun Pair;CVD compensation;deep learning;state-of-the-art deep neural network model;supporting information;target objects;users,augmented reality;colour vision;deep learning (artificial intelligence);image colour analysis;image segmentation,2023,Conference article (CA),AHs23: Proceedings of the Augmented Humans Conference 2023,"(1) Zhu, Z.; (1) Li, J.; (1) Tang, Y.; (1) Go, K.; (1) Toyoura, M.; (2) Kashiwagi, K.; (3) Fujishiro, I.; (1) Mao, X.; ","(1) University of Yamanashi, Department of Computer Science and Engineering, Japan; (2) University of Yamanashi, Department of Ophthalmology, Japan; (3) Keio University, Department of Information and Computer Science, Japan; ",ACM,-1,"[""color vision"", ""deep learning (artificial intelligence)"", ""image colour analysis"", ""image segmentation""]","[""color vision"", ""deep learning (artificial intelligence)"", ""image colour analysis"", ""image segmentation""]",color vision;deep learning (artificial intelligence);image colour analysis;image segmentation,computer vision;other;graphics;input;liberal arts;medical;artificial intelligence,technology;other;industries,computer vision;other;graphics;input;liberal arts;medical;artificial intelligence,technology;other;industries,color_vision deep_learning_ artificial_intelligence image_colour_analysis image_segmentation augmented_reality color_communication_assistance color_communication_support color_contrast_loss color_name color_vision_deficiency color object_noun_pair cvd_compensation deep_learning state of the art_deep_neural_network_model supporting_information target_objects users c6264_neural_nets c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision other graphics input liberal_arts medical artificial_intelligence,color_vision deep_learning_ artificial_intelligence image_colour_analysis image_segmentation,augmented_reality color_communication_assistance color_communication_support color_contrast_loss color_name color_vision_deficiency color object_noun_pair cvd_compensation deep_learning state of the art_deep_neural_network_model supporting_information target_objects users,people suffer color vision deficiency cvd face difficulty communicating others failing identify target object referred color name existing study cvd compensation focused issue color contrast loss although approach provide clue color name user technique either require training cannot protect user privacy e fact cvd paper based augmented reality ar deep learning technology propose novel system provide supporting information user affected cvd color communication assistance state art deep neural network dnn model referring segmentation r adopted generate supporting information ar glass utilized information presentation improve performance proposed system new dataset constructed based novel concept called color object noun pair result evaluation experiment show new dataset enhance performance adopted dnn model proposed system help user affected cvd successfully identify target object color name,color_vision deep_learning_ artificial_intelligence image_colour_analysis image_segmentation augmented_reality color_communication_assistance color_communication_support color_contrast_loss color_name color_vision_deficiency color object_noun_pair cvd_compensation deep_learning state of the art_deep_neural_network_model supporting_information target_objects users c6264_neural_nets c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision other graphics input liberal_arts medical artificial_intelligence people suffer color vision deficiency cvd face difficulty communicating others failing identify target object referred color name existing study cvd compensation focused issue color contrast loss although approach provide clue color name user technique either require training cannot protect user privacy e fact cvd paper based augmented reality ar deep learning technology propose novel system provide supporting information user affected cvd color communication assistance state art deep neural network dnn model referring segmentation r adopted generate supporting information ar glass utilized information presentation improve performance proposed system new dataset constructed based novel concept called color object noun pair result evaluation experiment show new dataset enhance performance adopted dnn model proposed system help user affected cvd successfully identify target object color name,people suffer color vision deficiency cvd face difficulty communicating others failing identify target object referred color name existing study cvd compensation focused issue color contrast loss although approach provide clue color name user technique either require training cannot protect user privacy e fact cvd paper based augmented reality ar deep learning technology propose novel system provide supporting information user affected cvd color communication assistance state art deep neural network dnn model referring segmentation r adopted generate supporting information ar glass utilized information presentation improve performance proposed system new dataset constructed based novel concept called color object noun pair result evaluation experiment show new dataset enhance performance adopted dnn model proposed system help user affected cvd successfully identify target object color namecolor_vision deep_learning_ artificial_intelligence image_colour_analysis image_segmentationaugmented_reality color_communication_assistance color_communication_support color_contrast_loss color_name color_vision_deficiency color object_noun_pair cvd_compensation deep_learning state of the art_deep_neural_network_model supporting_information target_objects users
96,Solving Tourism Management Challenges by Means of Mobile Augmented Reality Applications,"Ghandour, A., Kintonova, A., Demidchik, N., & Sverdlikova, E. (2021). Solving Tourism Management Challenges by Means of Mobile Augmented Reality Applications. International Journal of Web-Based Learning and Teaching Technologies, 16(6), 1–16. https://doi.org/10.4018/ijwltt.293280
",10.4018/IJWLTT.293280,"The purpose of the present article was to examine the use of mobile augmented reality technologies in the process of planning and organizing tourist activities. The analysis of the attitude of TUI Showroom's clients and managers of Russian travel agencies to the application of immersive technologies in travel consulting unveiled several possibilities for the practical use of mobile augmented reality applications in the travel business. The study concludes with the opinion that stimulation of the client's interest in the historical and cultural context of the tour by providing additional argumentation and high-quality information on the marketing proposal in a new, unusual manner forms the cultural, epistemic, and educational values of augmented reality, necessary in sales, personnel training, and interaction with business partners.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7185 Administration of other service industries",immersive technologies;mobile augmented reality applications;mobile augmented reality technologies;Russian travel agencies;tourism management challenges;travel business;travel consulting;TUI Showroom's clients,augmented reality;mobile computing;travel industry,2021,Journal article (JA),Int. J. Web-Based Learn. Teach. Technol. (USA),"(1) Ghandour, A.; (2) Kintonova, A.; (2) Demidchik, N.; (3) Sverdlikova, E.; ","(1) Al Ain University, United Arab Emirates; (2) L.N. Gumilyov Eurasian National University, Kazakhstan; (3) Lomonosov Moscow State University, Russia; ",IGI Global,-1,"[""mobile computing"", ""travel industry""]","[""mobile computing"", ""travel industry""]",mobile computing;travel industry,telecommunication;transportation,industries,telecommunication;transportation,industries,mobile_computing travel_industry immersive_technologies mobile_augmented_reality_applications mobile_augmented_reality_technologies russian_travel_agencies tourism_management_challenges travel_business travel_consulting tui_showroom s_clients c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7185_administration_of_other_service_industries telecommunication transportation,mobile_computing travel_industry,immersive_technologies mobile_augmented_reality_applications mobile_augmented_reality_technologies russian_travel_agencies tourism_management_challenges travel_business travel_consulting tui_showroom s_clients,purpose present article examine use mobile augmented reality technology process planning organizing tourist activity analysis attitude tui showroom client manager russian travel agency application immersive technology travel consulting unveiled several possibility practical use mobile augmented reality application travel business study concludes opinion stimulation client interest historical cultural context tour providing additional argumentation high quality information marketing proposal new unusual manner form cultural epistemic educational value augmented reality necessary sale personnel training interaction business partner,mobile_computing travel_industry immersive_technologies mobile_augmented_reality_applications mobile_augmented_reality_technologies russian_travel_agencies tourism_management_challenges travel_business travel_consulting tui_showroom s_clients c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7185_administration_of_other_service_industries telecommunication transportation purpose present article examine use mobile augmented reality technology process planning organizing tourist activity analysis attitude tui showroom client manager russian travel agency application immersive technology travel consulting unveiled several possibility practical use mobile augmented reality application travel business study concludes opinion stimulation client interest historical cultural context tour providing additional argumentation high quality information marketing proposal new unusual manner form cultural epistemic educational value augmented reality necessary sale personnel training interaction business partner,purpose present article examine use mobile augmented reality technology process planning organizing tourist activity analysis attitude tui showroom client manager russian travel agency application immersive technology travel consulting unveiled several possibility practical use mobile augmented reality application travel business study concludes opinion stimulation client interest historical cultural context tour providing additional argumentation high quality information marketing proposal new unusual manner form cultural epistemic educational value augmented reality necessary sale personnel training interaction business partnermobile_computing travel_industryimmersive_technologies mobile_augmented_reality_applications mobile_augmented_reality_technologies russian_travel_agencies tourism_management_challenges travel_business travel_consulting tui_showroom s_clients
97,A Comparative Study of Two Marker-Based Mobile Augmented Reality Applications for Solving 3D Anamorphic Illusion Puzzles,"Buhion, D. R., Dizon, M. N., Go, T. E., Oafallas, K. N., Joya, P. J., Mangune, A. C., Nerie, S. P., & Del Gallego, N. P. (2022). A Comparative Study of Two Marker-Based Mobile Augmented Reality Applications for Solving 3D Anamorphic Illusion Puzzles. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574443
",10.1145/3574131.3574443,"Anamorphic illusions are a class of optical illusions wherein objects are perspectively distorted in some way so that the object becomes recognizable when viewing them from a certain point of view or direction. We develop two marker-based mobile augmented reality applications to demonstrate 3D anamorphic illusions. We frame this as a puzzle-solving mechanic where users must align the anamorphic pieces through the movement of the device camera to form a distinguishable virtual model. The first AR proposed utilizes 2D printable markers (2D marker-based AR). In contrast, the second AR uses tabletop items as markers, such as cereal boxes, tin cans, action figures, and the like (3D marker-based AR). The AR applications differ regarding scene setup, user interactions, and examples of anamorphic illusions. We sliced public 3D models, and the corresponding slices were randomly distributed in a given virtual space, using a camera viewpoint where the model would become recognizable. Our proposed framework ensures that each playthrough provides a new anamorphic illusion. Early user testing results show that our 2D-marker-based AR application is more effective in showcasing anamorphic illusions.","C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6190V Mobile, ubiquitous and pervasive computing;C7830D Computer games",2D marker-based AR;2D-marker-based AR application;3D marker-based AR;anamorphic illusion;marker-based mobile augmented reality applications;optical illusions;utilizes 2D printable markers,augmented reality;cameras;cans;computer games;mobile computing,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Buhion, D.R.; (1) Dizon, M.N.; (1) Go, T.E.; (1) Oafallas, K.N.; (1) Joya, P.J.; (1) Mangune, A.C.; (1) Nerie, S.P.; (2) Del Gallego, N.P.; ","(1) De La Salle University, Philippines; (2) De La Salle University, Entertainment (GAME) Lab, Philippines; ",ACM,-1,"[""cameras"", ""cans"", ""computer games"", ""mobile computing""]","[""cameras"", ""cans"", ""computer games"", ""mobile computing""]",cameras;cans;computer games;mobile computing,other;telecommunication;liberal arts;input,technology;other;industries,other;telecommunication;liberal arts;input,technology;other;industries,cameras cans computer_games mobile_computing 2d_marker based_ar 2d marker based_ar_application 3d_marker based_ar anamorphic_illusion marker based_mobile_augmented_reality_applications optical_illusions utilizes_2d_printable_markers c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games other telecommunication liberal_arts input,cameras cans computer_games mobile_computing,2d_marker based_ar 2d marker based_ar_application 3d_marker based_ar anamorphic_illusion marker based_mobile_augmented_reality_applications optical_illusions utilizes_2d_printable_markers,anamorphic illusion class optical illusion wherein object perspectively distorted way object becomes recognizable viewing certain point view direction develop two marker based mobile augmented reality application demonstrate 3d anamorphic illusion frame puzzle solving mechanic user must align anamorphic piece movement device camera form distinguishable virtual model first ar proposed utilizes 2d printable marker 2d marker based ar contrast second ar us tabletop item marker cereal box tin can action figure like 3d marker based ar ar application differ regarding scene setup user interaction example anamorphic illusion sliced public 3d model corresponding slice randomly distributed given virtual space using camera viewpoint model would become recognizable proposed framework ensures playthrough provides new anamorphic illusion early user testing result show 2d marker based ar application effective showcasing anamorphic illusion,cameras cans computer_games mobile_computing 2d_marker based_ar 2d marker based_ar_application 3d_marker based_ar anamorphic_illusion marker based_mobile_augmented_reality_applications optical_illusions utilizes_2d_printable_markers c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games other telecommunication liberal_arts input anamorphic illusion class optical illusion wherein object perspectively distorted way object becomes recognizable viewing certain point view direction develop two marker based mobile augmented reality application demonstrate 3d anamorphic illusion frame puzzle solving mechanic user must align anamorphic piece movement device camera form distinguishable virtual model first ar proposed utilizes 2d printable marker 2d marker based ar contrast second ar us tabletop item marker cereal box tin can action figure like 3d marker based ar ar application differ regarding scene setup user interaction example anamorphic illusion sliced public 3d model corresponding slice randomly distributed given virtual space using camera viewpoint model would become recognizable proposed framework ensures playthrough provides new anamorphic illusion early user testing result show 2d marker based ar application effective showcasing anamorphic illusion,anamorphic illusion class optical illusion wherein object perspectively distorted way object becomes recognizable viewing certain point view direction develop two marker based mobile augmented reality application demonstrate 3d anamorphic illusion frame puzzle solving mechanic user must align anamorphic piece movement device camera form distinguishable virtual model first ar proposed utilizes 2d printable marker 2d marker based ar contrast second ar us tabletop item marker cereal box tin can action figure like 3d marker based ar ar application differ regarding scene setup user interaction example anamorphic illusion sliced public 3d model corresponding slice randomly distributed given virtual space using camera viewpoint model would become recognizable proposed framework ensures playthrough provides new anamorphic illusion early user testing result show 2d marker based ar application effective showcasing anamorphic illusioncameras cans computer_games mobile_computing2d_marker based_ar 2d marker based_ar_application 3d_marker based_ar anamorphic_illusion marker based_mobile_augmented_reality_applications optical_illusions utilizes_2d_printable_markers
98,A 3D Scene Information Enhancement Method Applied in Augmented Reality,"Li, B., Wang, X., Gao, Q., Song, Z., Zou, C., & Liu, S. (2022). A 3D Scene Information Enhancement Method Applied in Augmented Reality. Electronics, 11(24), 4123. https://doi.org/10.3390/electronics11244123
",10.3390/electronics11244123,"Aiming at the problem that the detection of small planes with unobvious texture is easy to be missed in augmented reality scene, a 3D scene information enhancement method to grab the planes for augmented reality scene is proposed based on a series of images of a real scene taken by a monocular camera. Firstly, we extract the feature points from the images. Secondly, we match the feature points from different images, and build the three-dimensional sparse point cloud data of the scene based on the feature points and the camera internal parameters. Thirdly, we estimate the position and size of the planes based on the sparse point cloud. The planes can be used to provide extra structural information for augmented reality. In this paper, an optimized feature points extraction and matching algorithm based on Scale Invariant Feature Transform (SIFT) is proposed, and a fast spatial planes recognition method based on a RANdom SAmple Consensus (RANSAC) is established. Experiments show that the method can achieve higher accuracy compared to the Oriented Fast and Rotated Brief (ORB), Binary Robust Invariant Scalable Keypoints (BRISK) and Super Point. The proposed method can effectively solve the problem of missing detection of faces in ARCore, and improve the integration effect between virtual objects and real scenes.","B6135E Image recognition;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",augmented reality scene;camera internal parameters;extra structural information;fast spatial planes recognition method;optimized feature points;Scale Invariant Feature Transform;Super Point;three-dimensional sparse point cloud data,augmented reality;cameras;feature extraction;image matching;image texture;object detection;transforms,2022,Journal article (JA),Electronics (Switzerland),"(1) Li, B.; (1) Wang, X.; (1) Gao, Q.; (2) Song, Z.; (1) Zou, C.; (1) Liu, S.; ","(1) Shenyang Institute of Engineering, China; (2) Shenyang Institute of Automation, China; ",MDPI,-1,"[""cameras"", ""feature extraction"", ""image matching"", ""image texture"", ""object detection"", ""transforms""]","[""cameras"", ""feature extraction"", ""image matching"", ""image texture"", ""object detection"", ""transforms""]",cameras;feature extraction;image matching;image texture;object detection;transforms,computer vision;chemical;graphics;input,technology;industries,computer vision;chemical;graphics;input,technology;industries,cameras feature_extraction image_matching image_texture object_detection transforms augmented_reality_scene camera_internal_parameters extra_structural_information fast_spatial_planes_recognition_method optimized_feature_points scale_invariant_feature_transform super_point three dimensional_sparse_point_cloud_data b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision chemical graphics input,cameras feature_extraction image_matching image_texture object_detection transforms,augmented_reality_scene camera_internal_parameters extra_structural_information fast_spatial_planes_recognition_method optimized_feature_points scale_invariant_feature_transform super_point three dimensional_sparse_point_cloud_data,aiming problem detection small plane unobvious texture easy missed augmented reality scene 3d scene information enhancement method grab plane augmented reality scene proposed based series image real scene taken monocular camera firstly extract feature point image secondly match feature point different image build three dimensional sparse point cloud data scene based feature point camera internal parameter thirdly estimate position size plane based sparse point cloud plane used provide extra structural information augmented reality paper optimized feature point extraction matching algorithm based scale invariant feature transform sift proposed fast spatial plane recognition method based random sample consensus ransac established experiment show method achieve higher accuracy compared oriented fast rotated brief orb binary robust invariant scalable keypoints brisk super point proposed method effectively solve problem missing detection face arcore improve integration effect virtual object real scene,cameras feature_extraction image_matching image_texture object_detection transforms augmented_reality_scene camera_internal_parameters extra_structural_information fast_spatial_planes_recognition_method optimized_feature_points scale_invariant_feature_transform super_point three dimensional_sparse_point_cloud_data b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision chemical graphics input aiming problem detection small plane unobvious texture easy missed augmented reality scene 3d scene information enhancement method grab plane augmented reality scene proposed based series image real scene taken monocular camera firstly extract feature point image secondly match feature point different image build three dimensional sparse point cloud data scene based feature point camera internal parameter thirdly estimate position size plane based sparse point cloud plane used provide extra structural information augmented reality paper optimized feature point extraction matching algorithm based scale invariant feature transform sift proposed fast spatial plane recognition method based random sample consensus ransac established experiment show method achieve higher accuracy compared oriented fast rotated brief orb binary robust invariant scalable keypoints brisk super point proposed method effectively solve problem missing detection face arcore improve integration effect virtual object real scene,aiming problem detection small plane unobvious texture easy missed augmented reality scene 3d scene information enhancement method grab plane augmented reality scene proposed based series image real scene taken monocular camera firstly extract feature point image secondly match feature point different image build three dimensional sparse point cloud data scene based feature point camera internal parameter thirdly estimate position size plane based sparse point cloud plane used provide extra structural information augmented reality paper optimized feature point extraction matching algorithm based scale invariant feature transform sift proposed fast spatial plane recognition method based random sample consensus ransac established experiment show method achieve higher accuracy compared oriented fast rotated brief orb binary robust invariant scalable keypoints brisk super point proposed method effectively solve problem missing detection face arcore improve integration effect virtual object real scenecameras feature_extraction image_matching image_texture object_detection transformsaugmented_reality_scene camera_internal_parameters extra_structural_information fast_spatial_planes_recognition_method optimized_feature_points scale_invariant_feature_transform super_point three dimensional_sparse_point_cloud_data
99,Color Offset Compensation Method of Art Image Based on Augmented Reality Technology,"Zhang, Y. (2022). Color Offset Compensation Method of Art Image Based on Augmented Reality Technology. 2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT). https://doi.org/10.1109/acait56212.2022.10137889
",10.1109/ACAIT56212.2022.10137889,"In the production of multi-scale block-fused art images, the image quality is poor due to the sudden change and occlusion of color shift. This paper puts forward a compensation method for color shift of multi-scale block-fused art images based on augmented reality technology. Based on the attenuation of optical parameters and the control of color balance, a multi-dimensional color fusion model of background light correlation of multi-scale block fused art images is established, and the augmented reality model of multi-scale block fused art images is constructed by combining the analysis method of surface features and illumination features distribution model of art images. Through the parameter analysis of each level feature map model of the similarity degree of the previous frame under color deviation, The gray texture and color texture features of multi-scale block-fused art images with complementary advantages and disadvantages are extracted, and augmented reality technology is adopted to realize gray scale enhancement and color enhancement in the process of color compensation of art images. Combined parameter identification method is adopted to realize color adjustment and feedback compensation control of output stability of art images. According to the characteristics of high-order moment output stability of color features, color offset compensation and optimal imaging processing of multi-scale block-fused art images are realized by calculating and counting boundary corner information and texture parameter analysis. The test shows that this method performs the color offset processing of multi-scale block fusion art image sensor, improves the color offset compensation ability of art images and the true color imaging quality of images, and increases the peak signal-to-noise ratio of output images.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",augmented reality technology;multiscale block fused art images;multiscale block fusion art image sensor;multiscale block-fused art images,augmented reality;compensation;feature extraction;feedback;image colour analysis;image fusion;image processing;image texture;parameter estimation,2022,Conference article (CA),2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT),"(1) Zhang, Y.; ","(1) Xianyang Normal University, Academy of Fine Arts, China; ",IEEE,-1,"[""compensation"", ""feature extraction"", ""feedback"", ""image colour analysis"", ""image fusion"", ""image processing"", ""image texture"", ""parameter estimation""]","[""compensation"", ""feature extraction"", ""feedback"", ""image colour analysis"", ""image fusion"", ""image processing"", ""image texture"", ""parameter estimation""]",compensation;feature extraction;feedback;image colour analysis;image fusion;image processing;image texture;parameter estimation,computer vision;other;graphics;chemical;data;human-computer interaction;video,technology;other;end users and user experience;industries,computer vision;other;graphics;chemical;data;human-computer interaction;video,technology;other;end users and user experience;industries,compensation feature_extraction feedback image_colour_analysis image_fusion image_processing image_texture parameter_estimation augmented_reality_technology multiscale_block_fused_art_images multiscale_block_fusion_art_image_sensor multiscale_block fused_art_images b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision other graphics chemical data human computer_interaction video,compensation feature_extraction feedback image_colour_analysis image_fusion image_processing image_texture parameter_estimation,augmented_reality_technology multiscale_block_fused_art_images multiscale_block_fusion_art_image_sensor multiscale_block fused_art_images,production multi scale block fused art image image quality poor due sudden change occlusion color shift paper put forward compensation method color shift multi scale block fused art image based augmented reality technology based attenuation optical parameter control color balance multi dimensional color fusion model background light correlation multi scale block fused art image established augmented reality model multi scale block fused art image constructed combining analysis method surface feature illumination feature distribution model art image parameter analysis level feature map model similarity degree previous frame color deviation gray texture color texture feature multi scale block fused art image complementary advantage disadvantage extracted augmented reality technology adopted realize gray scale enhancement color enhancement process color compensation art image combined parameter identification method adopted realize color adjustment feedback compensation control output stability art image according characteristic high order moment output stability color feature color offset compensation optimal imaging processing multi scale block fused art image realized calculating counting boundary corner information texture parameter analysis test show method performs color offset processing multi scale block fusion art image sensor improves color offset compensation ability art image true color imaging quality image increase peak signal noise ratio output image,compensation feature_extraction feedback image_colour_analysis image_fusion image_processing image_texture parameter_estimation augmented_reality_technology multiscale_block_fused_art_images multiscale_block_fusion_art_image_sensor multiscale_block fused_art_images b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision other graphics chemical data human computer_interaction video production multi scale block fused art image image quality poor due sudden change occlusion color shift paper put forward compensation method color shift multi scale block fused art image based augmented reality technology based attenuation optical parameter control color balance multi dimensional color fusion model background light correlation multi scale block fused art image established augmented reality model multi scale block fused art image constructed combining analysis method surface feature illumination feature distribution model art image parameter analysis level feature map model similarity degree previous frame color deviation gray texture color texture feature multi scale block fused art image complementary advantage disadvantage extracted augmented reality technology adopted realize gray scale enhancement color enhancement process color compensation art image combined parameter identification method adopted realize color adjustment feedback compensation control output stability art image according characteristic high order moment output stability color feature color offset compensation optimal imaging processing multi scale block fused art image realized calculating counting boundary corner information texture parameter analysis test show method performs color offset processing multi scale block fusion art image sensor improves color offset compensation ability art image true color imaging quality image increase peak signal noise ratio output image,production multi scale block fused art image image quality poor due sudden change occlusion color shift paper put forward compensation method color shift multi scale block fused art image based augmented reality technology based attenuation optical parameter control color balance multi dimensional color fusion model background light correlation multi scale block fused art image established augmented reality model multi scale block fused art image constructed combining analysis method surface feature illumination feature distribution model art image parameter analysis level feature map model similarity degree previous frame color deviation gray texture color texture feature multi scale block fused art image complementary advantage disadvantage extracted augmented reality technology adopted realize gray scale enhancement color enhancement process color compensation art image combined parameter identification method adopted realize color adjustment feedback compensation control output stability art image according characteristic high order moment output stability color feature color offset compensation optimal imaging processing multi scale block fused art image realized calculating counting boundary corner information texture parameter analysis test show method performs color offset processing multi scale block fusion art image sensor improves color offset compensation ability art image true color imaging quality image increase peak signal noise ratio output imagecompensation feature_extraction feedback image_colour_analysis image_fusion image_processing image_texture parameter_estimationaugmented_reality_technology multiscale_block_fused_art_images multiscale_block_fusion_art_image_sensor multiscale_block fused_art_images
100,Privacy-Enhancing Technology and Everyday Augmented Reality: Understanding Bystanders' Varying Needs for Awareness and Consent,"O’Hagan, J., Saeghe, P., Gugenheimer, J., Medeiros, D., Marky, K., Khamis, M., & McGill, M. (2022). Privacy-Enhancing Technology and Everyday Augmented Reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 6(4), 1–35. https://doi.org/10.1145/3569501
",10.1145/3569501,"Fundamental to Augmented Reality (AR) headsets is their capacity to visually and aurally sense the world around them, necessary to drive the positional tracking that makes rendering 3D spatial content possible. This requisite sensing also opens the door for more advanced AR-driven activities, such as augmented perception, volumetric capture and biometric identification - activities with the potential to expose bystanders to significant privacy risks. Existing Privacy-Enhancing Technologies (PETs) often safeguard against these risks at a low level e.g., instituting camera access controls. However, we argue that such PETs are incompatible with the need for always-on sensing given AR headsets' intended everyday use. Through an online survey (N=102), we examine bystanders' awareness of, and concerns regarding, potentially privacy infringing AR activities; the extent to which bystanders' consent should be sought; and the level of granularity of information necessary to provide awareness of AR activities to bystanders. Our findings suggest that PETs should take into account the AR activity type, and relationship to bystanders, selectively facilitating awareness and consent. In this way, we can ensure bystanders feel their privacy is respected by everyday AR headsets, and avoid unnecessary rejection of these powerful devices by society.","C6130S Data security;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",AR activities;AR activity type;AR-driven activities;augmented perception;Augmented Reality headsets;biometric identification - activities;bystanders;camera access controls;everyday AR headsets;everyday Augmented Reality;Existing Privacy-Enhancing Technologies;low level e.g;PETs;positional tracking;potentially privacy infringing;Privacy-Enhancing technology;rendering 3D spatial content possible;requisite sensing;sensing given AR headsets;significant privacy risks;volumetric capture,augmented reality;biometrics (access control);data privacy;rendering (computer graphics),2022,Journal article (JA),Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. (USA),"(1) O'hagan, J.; (1) Saeghe, P.; (2) Gugenheimer, J.; (1) Medeiros, D.; (3) Marky, K.; (1) Khamis, M.; (1) Mcgill, M.; ","(1) University of Glasgow, School of Computing Science, United Kingdom; (2) Technische Universitat Darmstadt, Germany; (3) Leibniz University Hannover, Germany; ",ACM,-1,"[""biometrics"", ""data privacy"", ""rendering""]","[""biometrics"", ""data privacy"", ""rendering""]",biometrics;data privacy;rendering,policy;graphics;human-computer interaction,technology;business;end users and user experience,policy;graphics;human-computer interaction,technology;business;end users and user experience,biometrics data_privacy rendering ar_activities ar_activity_type ar driven_activities augmented_perception augmented_reality_headsets biometric_identification_ _activities bystanders camera_access_controls everyday_ar_headsets everyday_augmented_reality existing_privacy enhancing_technologies low_level_e g pets positional_tracking potentially_privacy_infringing privacy enhancing_technology rendering_3d_spatial_content_possible requisite_sensing sensing_given_ar_headsets significant_privacy_risks volumetric_capture c6130s_data_security c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing policy graphics human computer_interaction,biometrics data_privacy rendering,ar_activities ar_activity_type ar driven_activities augmented_perception augmented_reality_headsets biometric_identification_ _activities bystanders camera_access_controls everyday_ar_headsets everyday_augmented_reality existing_privacy enhancing_technologies low_level_e g pets positional_tracking potentially_privacy_infringing privacy enhancing_technology rendering_3d_spatial_content_possible requisite_sensing sensing_given_ar_headsets significant_privacy_risks volumetric_capture,fundamental augmented reality ar headset capacity visually aurally sense world around necessary drive positional tracking make rendering 3d spatial content possible requisite sensing also open door advanced ar driven activity augmented perception volumetric capture biometric identification activity potential expose bystander significant privacy risk existing privacy enhancing technology pet often safeguard risk low level e g instituting camera access control however argue pet incompatible need always sensing given ar headset intended everyday use online survey n 102 examine bystander awareness concern regarding potentially privacy infringing ar activity extent bystander consent sought level granularity information necessary provide awareness ar activity bystander finding suggest pet take account ar activity type relationship bystander selectively facilitating awareness consent way ensure bystander feel privacy respected everyday ar headset avoid unnecessary rejection powerful device society,biometrics data_privacy rendering ar_activities ar_activity_type ar driven_activities augmented_perception augmented_reality_headsets biometric_identification_ _activities bystanders camera_access_controls everyday_ar_headsets everyday_augmented_reality existing_privacy enhancing_technologies low_level_e g pets positional_tracking potentially_privacy_infringing privacy enhancing_technology rendering_3d_spatial_content_possible requisite_sensing sensing_given_ar_headsets significant_privacy_risks volumetric_capture c6130s_data_security c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing policy graphics human computer_interaction fundamental augmented reality ar headset capacity visually aurally sense world around necessary drive positional tracking make rendering 3d spatial content possible requisite sensing also open door advanced ar driven activity augmented perception volumetric capture biometric identification activity potential expose bystander significant privacy risk existing privacy enhancing technology pet often safeguard risk low level e g instituting camera access control however argue pet incompatible need always sensing given ar headset intended everyday use online survey n 102 examine bystander awareness concern regarding potentially privacy infringing ar activity extent bystander consent sought level granularity information necessary provide awareness ar activity bystander finding suggest pet take account ar activity type relationship bystander selectively facilitating awareness consent way ensure bystander feel privacy respected everyday ar headset avoid unnecessary rejection powerful device society,fundamental augmented reality ar headset capacity visually aurally sense world around necessary drive positional tracking make rendering 3d spatial content possible requisite sensing also open door advanced ar driven activity augmented perception volumetric capture biometric identification activity potential expose bystander significant privacy risk existing privacy enhancing technology pet often safeguard risk low level e g instituting camera access control however argue pet incompatible need always sensing given ar headset intended everyday use online survey n 102 examine bystander awareness concern regarding potentially privacy infringing ar activity extent bystander consent sought level granularity information necessary provide awareness ar activity bystander finding suggest pet take account ar activity type relationship bystander selectively facilitating awareness consent way ensure bystander feel privacy respected everyday ar headset avoid unnecessary rejection powerful device societybiometrics data_privacy renderingar_activities ar_activity_type ar driven_activities augmented_perception augmented_reality_headsets biometric_identification_ _activities bystanders camera_access_controls everyday_ar_headsets everyday_augmented_reality existing_privacy enhancing_technologies low_level_e g pets positional_tracking potentially_privacy_infringing privacy enhancing_technology rendering_3d_spatial_content_possible requisite_sensing sensing_given_ar_headsets significant_privacy_risks volumetric_capture
101,Developing an Augmented Reality Lunar Surface Navigation System,"Ahner-McHaffie, K. T., Yang, S., Tan, Y., & Zhou, B. (2023). Developing an Augmented Reality Lunar Surface Navigation System. 2023 IEEE Aerospace Conference. https://doi.org/10.1109/aero55745.2023.10115923
",10.1109/AERO55745.2023.10115923,"For astronauts, lunar Extravehicular Activity (EVA) operations are extraordinarily challenging to perform. Physically, they must perform demanding tasks while clothed in exhaustingly heavy space suits. Mentally, they must perform complicated tasks without error while exploring unfamiliar and uncharted locations. With the high value of each moment spent on the moon, immense time pressure also increases the mental load placed on these astronauts. The Rhode Island School of Design (RISD) team participated in the 2022 NASA Spacesuit User Interface Technologies for Students (SUITS) Challenge and developed an augmented reality lunar surface navigation system, aiming at reducing the cognitive load for astronauts during their EVA operations. The overall design approach is to unify interfaces, separate planes for interactions, and maximize automation. The navigation system features an intuitive navigational aid, a three-dimensional path guide which is overlaid on the landscape, and a minimized user interface. Hardware components such as a tab-traversal style control are also incorporated to increase usability.","A9620D Lunar interior, surface, and atmosphere;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces",2022 NASA Spacesuit User Interface Technologies;astronauts;augmented reality lunar surface navigation system;EVA operations;exhaustingly heavy space suits;intuitive navigational aid;lunar Extravehicular Activity operations;mental load;Students Challenge;uncharted locations;unfamiliar locations,aerospace safety;augmented reality;cognition;data visualisation;lunar surface;space research;space vehicles;user interfaces;virtual reality,2023,Conference article (CA),2023 IEEE Aerospace Conference,"(1) Ahner-Mchaffie, K.T.; (2) Yang, S.; (3) Tan, Y.; (2) Zhou, B.; ","(1) Case Western Reserve University, Department of Computer Science, Cleveland, OH 44106, United States; (2) Rhode Island School of Design, Department of Industrial Design, Providence, RI RI 0290, United States; (3) Rhode Island School of Design, Department of Architecture, Providence, RI RI 0290, United States; ",IEEE,-1,"[""aerospace safety"", ""cognition"", ""data visualization"", ""lunar surface"", ""space research"", ""space vehicles"", ""user interfaces""]","[""aerospace safety"", ""cognition"", ""data visualization"", ""lunar surface"", ""space research"", ""space vehicles"", ""user interfaces""]",aerospace safety;cognition;data visualization;lunar surface;space research;space vehicles;user interfaces,"education;other;aviation and aerospace;medical;automotive;inspection, safety and quality;human factors;data;human-computer interaction",other;end users and user experience;industries;use cases;technology,"education;other;aviation and aerospace;medical;automotive;inspection, safety and quality;human factors;data;human-computer interaction",other;end users and user experience;industries;use cases;technology,aerospace_safety cognition data_visualization lunar_surface space_research space_vehicles user_interfaces 2022_nasa_spacesuit_user_interface_technologies astronauts augmented_reality_lunar_surface_navigation_system eva_operations exhaustingly_heavy_space_suits intuitive_navigational_aid lunar_extravehicular_activity_operations mental_load students_challenge uncharted_locations unfamiliar_locations a9620d_lunar_interior _surface _and_atmosphere c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces education other aviation_and_aerospace medical automotive inspection _safety_and_quality human_factors data human computer_interaction,aerospace_safety cognition data_visualization lunar_surface space_research space_vehicles user_interfaces,2022_nasa_spacesuit_user_interface_technologies astronauts augmented_reality_lunar_surface_navigation_system eva_operations exhaustingly_heavy_space_suits intuitive_navigational_aid lunar_extravehicular_activity_operations mental_load students_challenge uncharted_locations unfamiliar_locations,astronaut lunar extravehicular activity eva operation extraordinarily challenging perform physically must perform demanding task clothed exhaustingly heavy space suit mentally must perform complicated task without error exploring unfamiliar uncharted location high value moment spent moon immense time pressure also increase mental load placed astronaut rhode island school design risd team participated 2022 nasa spacesuit user interface technology student suit challenge developed augmented reality lunar surface navigation system aiming reducing cognitive load astronaut eva operation overall design approach unify interface separate plane interaction maximize automation navigation system feature intuitive navigational aid three dimensional path guide overlaid landscape minimized user interface hardware component tab traversal style control also incorporated increase usability,aerospace_safety cognition data_visualization lunar_surface space_research space_vehicles user_interfaces 2022_nasa_spacesuit_user_interface_technologies astronauts augmented_reality_lunar_surface_navigation_system eva_operations exhaustingly_heavy_space_suits intuitive_navigational_aid lunar_extravehicular_activity_operations mental_load students_challenge uncharted_locations unfamiliar_locations a9620d_lunar_interior _surface _and_atmosphere c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces education other aviation_and_aerospace medical automotive inspection _safety_and_quality human_factors data human computer_interaction astronaut lunar extravehicular activity eva operation extraordinarily challenging perform physically must perform demanding task clothed exhaustingly heavy space suit mentally must perform complicated task without error exploring unfamiliar uncharted location high value moment spent moon immense time pressure also increase mental load placed astronaut rhode island school design risd team participated 2022 nasa spacesuit user interface technology student suit challenge developed augmented reality lunar surface navigation system aiming reducing cognitive load astronaut eva operation overall design approach unify interface separate plane interaction maximize automation navigation system feature intuitive navigational aid three dimensional path guide overlaid landscape minimized user interface hardware component tab traversal style control also incorporated increase usability,astronaut lunar extravehicular activity eva operation extraordinarily challenging perform physically must perform demanding task clothed exhaustingly heavy space suit mentally must perform complicated task without error exploring unfamiliar uncharted location high value moment spent moon immense time pressure also increase mental load placed astronaut rhode island school design risd team participated 2022 nasa spacesuit user interface technology student suit challenge developed augmented reality lunar surface navigation system aiming reducing cognitive load astronaut eva operation overall design approach unify interface separate plane interaction maximize automation navigation system feature intuitive navigational aid three dimensional path guide overlaid landscape minimized user interface hardware component tab traversal style control also incorporated increase usabilityaerospace_safety cognition data_visualization lunar_surface space_research space_vehicles user_interfaces2022_nasa_spacesuit_user_interface_technologies astronauts augmented_reality_lunar_surface_navigation_system eva_operations exhaustingly_heavy_space_suits intuitive_navigational_aid lunar_extravehicular_activity_operations mental_load students_challenge uncharted_locations unfamiliar_locations
102,The Impact of the Use of Augmented Reality on Online Purchasing Behavior Sustainability: The Saudi Consumer as a Model,"AL Hilal, N. S. H. (2023). The Impact of the Use of Augmented Reality on Online Purchasing Behavior Sustainability: The Saudi Consumer as a Model. Sustainability, 15(6), 5448. https://doi.org/10.3390/su15065448
",10.3390/su15065448,"This study aimed to examine the impact of augmented reality (AR) on the purchasing behavior of Saudi customers using analytic-descriptive methods and data from a snowball sample of 812 online buyers. Positive correlations were found between AR factors (hermeneutic, embodiment, and background) and dimensions (quality, fun, and creativity) and the purchase experience. Young women aged 17-26 mainly use AR for buying clothes and accessories, and the majority of the sample shops are available locally through mobile apps. The findings indicate that AR has a significant influence on buying decisions and suggest its potential use in marketing communications. The results also reveal that gender, social status, education level, and monthly income have an impact on participants' responses to AR, with women and those who are married having more favorable views. Clothing and accessories were found to be the most frequently purchased products through AR. There were no significant differences based on age or the number of family members. Participants reported positively about their AR experience, and their concerns and anxiety did not affect their purchasing experience. Based on the main study's results, a number of recommendations can be made: Saudi businesses need to use AR in their marketing communication strategies to meet consumer needs and trends. To maximize the benefits of brand awareness, they should use AR techniques and adopt this technology for products that depend on design in their production. When using AR in general and in light of the theories that have been studied, it is important to think about the cultural traits and dimensions of Saudi consumers and conduct further exploratory research before implementation.","C7180 Retailing and distribution computing;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7170 Marketing computing;C7210N Information networks",812 online buyers;accessories;analytic-descriptive methods;AR experience;augmented reality;buying decisions;clothes;consumer needs;education level;favorable views;frequently purchased products;main study;marketing communication strategies;marketing communications;mobile apps;monthly income;online purchasing;participants;positive correlations;purchase experience;purchasing behavior;purchasing experience;sample shops;Saudi businesses;Saudi consumer;Saudi customers;snowball sample;social status;sustainability;young women,augmented reality;consumer behaviour;electronic commerce;mobile computing;purchasing,2023,Journal article (JA),Sustainability (Switzerland),"(1) Al Hilal, N.S.H.; ","(1) Imam Mohammad Ibn Saud Islamic University (IMSIU), College of Media & Communication, Saudi Arabia; ",MDPI,-1,"[""consumer behaviour"", ""electronic commerce"", ""mobile computing"", ""purchasing""]","[""consumer behaviour"", ""electronic commerce"", ""mobile computing"", ""purchasing""]",consumer behaviour;electronic commerce;mobile computing;purchasing,sales and marketing;logistics;telecommunication,business;industries,sales and marketing;logistics;telecommunication,business;industries,consumer_behaviour electronic_commerce mobile_computing purchasing 812_online_buyers accessories analytic descriptive_methods ar_experience augmented_reality buying_decisions clothes consumer_needs education_level favorable_views frequently_purchased_products main_study marketing_communication_strategies marketing_communications mobile_apps monthly_income online_purchasing participants positive_correlations purchase_experience purchasing_behavior purchasing_experience sample_shops saudi_businesses saudi_consumer saudi_customers snowball_sample social_status sustainability young_women c7180_retailing_and_distribution_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7170_marketing_computing c7210n_information_networks sales_and_marketing logistics telecommunication,consumer_behaviour electronic_commerce mobile_computing purchasing,812_online_buyers accessories analytic descriptive_methods ar_experience augmented_reality buying_decisions clothes consumer_needs education_level favorable_views frequently_purchased_products main_study marketing_communication_strategies marketing_communications mobile_apps monthly_income online_purchasing participants positive_correlations purchase_experience purchasing_behavior purchasing_experience sample_shops saudi_businesses saudi_consumer saudi_customers snowball_sample social_status sustainability young_women,study aimed examine impact augmented reality ar purchasing behavior saudi customer using analytic descriptive method data snowball sample 812 online buyer positive correlation found ar factor hermeneutic embodiment background dimension quality fun creativity purchase experience young woman aged 17 26 mainly use ar buying clothes accessory majority sample shop available locally mobile apps finding indicate ar significant influence buying decision suggest potential use marketing communication result also reveal gender social status education level monthly income impact participant response ar woman married favorable view clothing accessory found frequently purchased product ar significant difference based age number family member participant reported positively ar experience concern anxiety affect purchasing experience based main study result number recommendation made saudi business need use ar marketing communication strategy meet consumer need trend maximize benefit brand awareness use ar technique adopt technology product depend design production using ar general light theory studied important think cultural trait dimension saudi consumer conduct exploratory research implementation,consumer_behaviour electronic_commerce mobile_computing purchasing 812_online_buyers accessories analytic descriptive_methods ar_experience augmented_reality buying_decisions clothes consumer_needs education_level favorable_views frequently_purchased_products main_study marketing_communication_strategies marketing_communications mobile_apps monthly_income online_purchasing participants positive_correlations purchase_experience purchasing_behavior purchasing_experience sample_shops saudi_businesses saudi_consumer saudi_customers snowball_sample social_status sustainability young_women c7180_retailing_and_distribution_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7170_marketing_computing c7210n_information_networks sales_and_marketing logistics telecommunication study aimed examine impact augmented reality ar purchasing behavior saudi customer using analytic descriptive method data snowball sample 812 online buyer positive correlation found ar factor hermeneutic embodiment background dimension quality fun creativity purchase experience young woman aged 17 26 mainly use ar buying clothes accessory majority sample shop available locally mobile apps finding indicate ar significant influence buying decision suggest potential use marketing communication result also reveal gender social status education level monthly income impact participant response ar woman married favorable view clothing accessory found frequently purchased product ar significant difference based age number family member participant reported positively ar experience concern anxiety affect purchasing experience based main study result number recommendation made saudi business need use ar marketing communication strategy meet consumer need trend maximize benefit brand awareness use ar technique adopt technology product depend design production using ar general light theory studied important think cultural trait dimension saudi consumer conduct exploratory research implementation,study aimed examine impact augmented reality ar purchasing behavior saudi customer using analytic descriptive method data snowball sample 812 online buyer positive correlation found ar factor hermeneutic embodiment background dimension quality fun creativity purchase experience young woman aged 17 26 mainly use ar buying clothes accessory majority sample shop available locally mobile apps finding indicate ar significant influence buying decision suggest potential use marketing communication result also reveal gender social status education level monthly income impact participant response ar woman married favorable view clothing accessory found frequently purchased product ar significant difference based age number family member participant reported positively ar experience concern anxiety affect purchasing experience based main study result number recommendation made saudi business need use ar marketing communication strategy meet consumer need trend maximize benefit brand awareness use ar technique adopt technology product depend design production using ar general light theory studied important think cultural trait dimension saudi consumer conduct exploratory research implementationconsumer_behaviour electronic_commerce mobile_computing purchasing812_online_buyers accessories analytic descriptive_methods ar_experience augmented_reality buying_decisions clothes consumer_needs education_level favorable_views frequently_purchased_products main_study marketing_communication_strategies marketing_communications mobile_apps monthly_income online_purchasing participants positive_correlations purchase_experience purchasing_behavior purchasing_experience sample_shops saudi_businesses saudi_consumer saudi_customers snowball_sample social_status sustainability young_women
103,Utilizing Augmented Reality to Enhance Twenty-First Century Skills in Chemistry Education,"Abualrob, M., Ewais, A., Dalipi, F., & Awaad, T. (2023). Utilizing Augmented Reality to Enhance Twenty-First Century Skills in Chemistry Education. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125271
",10.1109/EDUCON54358.2023.10125271,"Numerous studies have shown that mobile devices like smartphones play a significant role in education these days, and it's clear that the influence and benefits of these devices regarding the potential for pedagogical perspectives are obvious. Mobile learning allows for flexibility by eliminating the need for learning to happen at a particular time and place. Moreover, mobile devices that can support Augmented Reality (AR) are becoming more powerful, less expensive and quite useful in the education process. In this paper, we conduct a study where mobile AR application alongside project-based learning is utilized in a classroom setting, where interviews are administered to understand the K-12 students' attitude towards the educational model based on mobile AR for enhancing the twenty-first century skills in chemistry education. The interviews are conducted with thirty students and their teacher who teaches them chemistry course. Four skills are investigated and discussed, i.e., innovation and creativity, critical skills and problem solving, communication and collaboration, and information culture. Based on the research findings, some recommendations are provided. Furthermore, in the scope of Agenda 2030 for Palestine, we believe these findings could serve as a basis for developing practical policy interventions attributed to enhancing the educational system with emerging technologies.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",Augmented Reality;chemistry course;chemistry education;critical skills;education process;education these days;educational model;educational system;K-12 students;mobile AR application;mobile devices;mobile learning;pedagogical perspectives;project-based learning;thirty students;twenty-first century skills,augmented reality;computer aided instruction;educational courses;mobile computing;mobile learning;smart phones;teaching,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Abualrob, M.; (1) Ewais, A.; (2) Dalipi, F.; (1) Awaad, T.; ","(1) Arab American University of Palestine, Palestinian Territory; (2) Linnaeus University, Sweden; ",IEEE,-1,"[""computer aided instruction"", ""educational courses"", ""mobile computing"", ""mobile learning"", ""smartphones"", ""teaching""]","[""computer aided instruction"", ""educational courses"", ""mobile computing"", ""mobile learning"", ""smartphones"", ""teaching""]",computer aided instruction;educational courses;mobile computing;mobile learning;smartphones;teaching,education;liberal arts;medical;training;telecommunication,use cases;industries,education;liberal arts;medical;training;telecommunication,use cases;industries,computer_aided_instruction educational_courses mobile_computing mobile_learning smartphones teaching augmented_reality chemistry_course chemistry_education critical_skills education_process education_these_days educational_model educational_system k 12_students mobile_ar_application mobile_devices mobile_learning pedagogical_perspectives project based_learning thirty_students twenty first_century_skills c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education liberal_arts medical training telecommunication,computer_aided_instruction educational_courses mobile_computing mobile_learning smartphones teaching,augmented_reality chemistry_course chemistry_education critical_skills education_process education_these_days educational_model educational_system k 12_students mobile_ar_application mobile_devices mobile_learning pedagogical_perspectives project based_learning thirty_students twenty first_century_skills,numerous study shown mobile device like smartphones play significant role education day clear influence benefit device regarding potential pedagogical perspective obvious mobile learning allows flexibility eliminating need learning happen particular time place moreover mobile device support augmented reality ar becoming powerful le expensive quite useful education process paper conduct study mobile ar application alongside project based learning utilized classroom setting interview administered understand k 12 student attitude towards educational model based mobile ar enhancing twenty first century skill chemistry education interview conducted thirty student teacher teach chemistry course four skill investigated discussed e innovation creativity critical skill problem solving communication collaboration information culture based research finding recommendation provided furthermore scope agenda 2030 palestine believe finding could serve basis developing practical policy intervention attributed enhancing educational system emerging technology,computer_aided_instruction educational_courses mobile_computing mobile_learning smartphones teaching augmented_reality chemistry_course chemistry_education critical_skills education_process education_these_days educational_model educational_system k 12_students mobile_ar_application mobile_devices mobile_learning pedagogical_perspectives project based_learning thirty_students twenty first_century_skills c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education liberal_arts medical training telecommunication numerous study shown mobile device like smartphones play significant role education day clear influence benefit device regarding potential pedagogical perspective obvious mobile learning allows flexibility eliminating need learning happen particular time place moreover mobile device support augmented reality ar becoming powerful le expensive quite useful education process paper conduct study mobile ar application alongside project based learning utilized classroom setting interview administered understand k 12 student attitude towards educational model based mobile ar enhancing twenty first century skill chemistry education interview conducted thirty student teacher teach chemistry course four skill investigated discussed e innovation creativity critical skill problem solving communication collaboration information culture based research finding recommendation provided furthermore scope agenda 2030 palestine believe finding could serve basis developing practical policy intervention attributed enhancing educational system emerging technology,numerous study shown mobile device like smartphones play significant role education day clear influence benefit device regarding potential pedagogical perspective obvious mobile learning allows flexibility eliminating need learning happen particular time place moreover mobile device support augmented reality ar becoming powerful le expensive quite useful education process paper conduct study mobile ar application alongside project based learning utilized classroom setting interview administered understand k 12 student attitude towards educational model based mobile ar enhancing twenty first century skill chemistry education interview conducted thirty student teacher teach chemistry course four skill investigated discussed e innovation creativity critical skill problem solving communication collaboration information culture based research finding recommendation provided furthermore scope agenda 2030 palestine believe finding could serve basis developing practical policy intervention attributed enhancing educational system emerging technologycomputer_aided_instruction educational_courses mobile_computing mobile_learning smartphones teachingaugmented_reality chemistry_course chemistry_education critical_skills education_process education_these_days educational_model educational_system k 12_students mobile_ar_application mobile_devices mobile_learning pedagogical_perspectives project based_learning thirty_students twenty first_century_skills
104,Eliciting Security &amp; Privacy-Informed Sharing Techniques for Multi-User Augmented Reality,"Rajaram, S., Chen, C., Roesner, F., & Nebeling, M. (2023). Eliciting Security &amp; Privacy-Informed Sharing Techniques for Multi-User Augmented Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581089
",10.1145/3544548.3581089,"The HCI community has explored new interaction designs for collaborative AR interfaces in terms of usability and feasibility; however, security &amp; privacy (S&amp;P) are often not considered in the design process and left to S&amp;P professionals. To produce interaction proposals with S&amp;P in mind, we extend the user-driven elicitation method with a scenario-based approach that incorporates a threat model involving access control in multi-user AR. We conducted an elicitation study in two conditions, pairing AR/AR experts in one condition and AR/S&amp;P experts in the other, to investigate the impact of each pairing. We contribute a set of expert-elicited interactions for sharing AR content enhanced with access control provisions, analyze the benefits and tradeoffs of pairing AR and S&amp;P experts, and present recommendations for designing future multi-user AR interactions that better balance competing design goals of usability, feasibility, and S&amp;P in collaborative AR.",C6130S Data security;C6130G Groupware;C6130V Virtual reality;C6180 User interfaces,access control provisions;collaborative AR interfaces;elicitation study;expert-elicited interactions;HCI community;interaction designs;interaction proposals;multiuser augmented reality;S&amp;P experts;scenario-based approach;security &amp; privacy-informed sharing techniques;user-driven elicitation method,augmented reality;authorisation;data privacy;groupware;human computer interaction,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Rajaram, S.; (1) Chen, C.; (2) Roesner, F.; (1) Nebeling, M.; ","(1) University of Michigan, School of Information, Ann Arbor, MI, United States; (2) University of Washington, Paul G. Allen School of Computer Science & Engineering, Seattle, WA, United States; ",ACM,-1,"[""authorisation"", ""data privacy"", ""groupware"", ""human computer interaction""]","[""authorisation"", ""data privacy"", ""groupware"", ""human computer interaction""]",authorisation;data privacy;groupware;human computer interaction,policy;security;human-computer interaction;collaboration,business;technology;use cases;end users and user experience,policy;security;human-computer interaction;collaboration,business;technology;use cases;end users and user experience,authorisation data_privacy groupware human_computer_interaction access_control_provisions collaborative_ar_interfaces elicitation_study expert elicited_interactions hci_community interaction_designs interaction_proposals multiuser_augmented_reality s amp p_experts scenario based_approach security_ amp _privacy informed_sharing_techniques user driven_elicitation_method c6130s_data_security c6130g_groupware c6130v_virtual_reality c6180_user_interfaces policy security human computer_interaction collaboration,authorisation data_privacy groupware human_computer_interaction,access_control_provisions collaborative_ar_interfaces elicitation_study expert elicited_interactions hci_community interaction_designs interaction_proposals multiuser_augmented_reality s amp p_experts scenario based_approach security_ amp _privacy informed_sharing_techniques user driven_elicitation_method,hci community explored new interaction design collaborative ar interface term usability feasibility however security amp privacy amp p often considered design process left amp p professional produce interaction proposal amp p mind extend user driven elicitation method scenario based approach incorporates threat model involving access control multi user ar conducted elicitation study two condition pairing ar ar expert one condition ar amp p expert investigate impact pairing contribute set expert elicited interaction sharing ar content enhanced access control provision analyze benefit tradeoff pairing ar amp p expert present recommendation designing future multi user ar interaction better balance competing design goal usability feasibility amp p collaborative ar,authorisation data_privacy groupware human_computer_interaction access_control_provisions collaborative_ar_interfaces elicitation_study expert elicited_interactions hci_community interaction_designs interaction_proposals multiuser_augmented_reality s amp p_experts scenario based_approach security_ amp _privacy informed_sharing_techniques user driven_elicitation_method c6130s_data_security c6130g_groupware c6130v_virtual_reality c6180_user_interfaces policy security human computer_interaction collaboration hci community explored new interaction design collaborative ar interface term usability feasibility however security amp privacy amp p often considered design process left amp p professional produce interaction proposal amp p mind extend user driven elicitation method scenario based approach incorporates threat model involving access control multi user ar conducted elicitation study two condition pairing ar ar expert one condition ar amp p expert investigate impact pairing contribute set expert elicited interaction sharing ar content enhanced access control provision analyze benefit tradeoff pairing ar amp p expert present recommendation designing future multi user ar interaction better balance competing design goal usability feasibility amp p collaborative ar,hci community explored new interaction design collaborative ar interface term usability feasibility however security amp privacy amp p often considered design process left amp p professional produce interaction proposal amp p mind extend user driven elicitation method scenario based approach incorporates threat model involving access control multi user ar conducted elicitation study two condition pairing ar ar expert one condition ar amp p expert investigate impact pairing contribute set expert elicited interaction sharing ar content enhanced access control provision analyze benefit tradeoff pairing ar amp p expert present recommendation designing future multi user ar interaction better balance competing design goal usability feasibility amp p collaborative arauthorisation data_privacy groupware human_computer_interactionaccess_control_provisions collaborative_ar_interfaces elicitation_study expert elicited_interactions hci_community interaction_designs interaction_proposals multiuser_augmented_reality s amp p_experts scenario based_approach security_ amp _privacy informed_sharing_techniques user driven_elicitation_method
105,Learning Media Innovation about Keris Cultural Heritage through Augmented Reality,"Marcellino, L., Harischandra, I. B. R., Buana, I. M. K. W., Maulana, F. I., & Ramadhani, M. (2022). Learning Media Innovation about Keris Cultural Heritage through Augmented Reality. 7th International Conference on Sustainable Information Engineering and Technology 2022. https://doi.org/10.1145/3568231.3568275
",10.1145/3568231.3568275,"Keris is a special weapon that is a cultural heritage in Indonesia which is of high value. Until now, the introduction and learning of culture about keris are still limited to 2D from books, or in exhibitions or museums. Learning about keris culture certainly needs to be supported by technological developments. The process of delivering information is currently experiencing rapid development, the latest technology used in delivering information is Augmented Reality (AR) technology. Users can visualize historical objects or objects in three-dimensional (3D) form via Android smartphones. The method used in this research is the ADDIE model, starting from Analysis, Design, Development, Implementation, and Evaluation. The results reveal that distance, marker angle, and device specifications all have a sizeable impact on the camera's marker readout. The shortest distance between the marker and the camera where 3D objects can be displayed is 20 cm, while the farthest distance at which 3D items cannot be displayed is 100 cm. And the marker reading angle is only about 0&#176; until 45&#176;. The application of Augmented Reality technology is interactive and real-time, so Augmented Reality can be implemented in various fields and become a learning medium to introduce historical objects that are cultural heritage.","B6250F Mobile radio systems;B7230G Image sensors;C6130B Graphics techniques;C6130V Virtual reality;C6180G Graphical user interfaces;C6190V Mobile, ubiquitous and pervasive computing;C7820 Humanities computing",augmented reality technology;delivering information;exhibitions;historical objects;Indonesia;Keris cultural heritage;keris culture;learning medium;marker reading angle;marker readout;media innovation;museums;technological developments;three-dimensional form,augmented reality;cameras;data visualisation;graphical user interfaces;history;mobile computing;museums;smart phones,2022,Conference article (CA),SIET22: 7th International Conference on Sustainable Information Engineering and Technology 2022,"(1) Marcellino, L.; (1) Harischandra, I.B.R.; (1) Buana, I.M.K.W.; (1) Maulana, F.I.; (1) Ramadhani, M.; ","(1) BINUS University, Indonesia; ",ACM,-1,"[""cameras"", ""data visualization"", ""graphical user interfaces"", ""history"", ""mobile computing"", ""museums"", ""smartphones""]","[""cameras"", ""data visualization"", ""graphical user interfaces"", ""history"", ""mobile computing"", ""museums"", ""smartphones""]",cameras;data visualization;graphical user interfaces;history;mobile computing;museums;smartphones,graphics;input;liberal arts;cultural heritage;telecommunication;data;human-computer interaction,technology;end users and user experience;industries,graphics;input;liberal arts;cultural heritage;telecommunication;data;human-computer interaction,technology;end users and user experience;industries,cameras data_visualization graphical_user_interfaces history mobile_computing museums smartphones augmented_reality_technology delivering_information exhibitions historical_objects indonesia keris_cultural_heritage keris_culture learning_medium marker_reading_angle marker_readout media_innovation museums technological_developments three dimensional_form b6250f_mobile_radio_systems b7230g_image_sensors c6130b_graphics_techniques c6130v_virtual_reality c6180g_graphical_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing graphics input liberal_arts cultural_heritage telecommunication data human computer_interaction,cameras data_visualization graphical_user_interfaces history mobile_computing museums smartphones,augmented_reality_technology delivering_information exhibitions historical_objects indonesia keris_cultural_heritage keris_culture learning_medium marker_reading_angle marker_readout media_innovation museums technological_developments three dimensional_form,keris special weapon cultural heritage indonesia high value introduction learning culture keris still limited 2d book exhibition museum learning keris culture certainly need supported technological development process delivering information currently experiencing rapid development latest technology used delivering information augmented reality ar technology user visualize historical object object three dimensional 3d form via android smartphones method used research addie model starting analysis design development implementation evaluation result reveal distance marker angle device specification sizeable impact camera marker readout shortest distance marker camera 3d object displayed 20 cm farthest distance 3d item cannot displayed 100 cm marker reading angle 0 176 45 176 application augmented reality technology interactive real time augmented reality implemented various field become learning medium introduce historical object cultural heritage,cameras data_visualization graphical_user_interfaces history mobile_computing museums smartphones augmented_reality_technology delivering_information exhibitions historical_objects indonesia keris_cultural_heritage keris_culture learning_medium marker_reading_angle marker_readout media_innovation museums technological_developments three dimensional_form b6250f_mobile_radio_systems b7230g_image_sensors c6130b_graphics_techniques c6130v_virtual_reality c6180g_graphical_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing graphics input liberal_arts cultural_heritage telecommunication data human computer_interaction keris special weapon cultural heritage indonesia high value introduction learning culture keris still limited 2d book exhibition museum learning keris culture certainly need supported technological development process delivering information currently experiencing rapid development latest technology used delivering information augmented reality ar technology user visualize historical object object three dimensional 3d form via android smartphones method used research addie model starting analysis design development implementation evaluation result reveal distance marker angle device specification sizeable impact camera marker readout shortest distance marker camera 3d object displayed 20 cm farthest distance 3d item cannot displayed 100 cm marker reading angle 0 176 45 176 application augmented reality technology interactive real time augmented reality implemented various field become learning medium introduce historical object cultural heritage,keris special weapon cultural heritage indonesia high value introduction learning culture keris still limited 2d book exhibition museum learning keris culture certainly need supported technological development process delivering information currently experiencing rapid development latest technology used delivering information augmented reality ar technology user visualize historical object object three dimensional 3d form via android smartphones method used research addie model starting analysis design development implementation evaluation result reveal distance marker angle device specification sizeable impact camera marker readout shortest distance marker camera 3d object displayed 20 cm farthest distance 3d item cannot displayed 100 cm marker reading angle 0 176 45 176 application augmented reality technology interactive real time augmented reality implemented various field become learning medium introduce historical object cultural heritagecameras data_visualization graphical_user_interfaces history mobile_computing museums smartphonesaugmented_reality_technology delivering_information exhibitions historical_objects indonesia keris_cultural_heritage keris_culture learning_medium marker_reading_angle marker_readout media_innovation museums technological_developments three dimensional_form
106,Development and Evaluation of Augmented Reality Learning Content for Pneumatic Flow: Case Study on Brake Operating Unit of Railway Vehicle,"Kwon, H. J., Kim, K. S., & Kim, C. S. (2023). Development and Evaluation of Augmented Reality Learning Content for Pneumatic Flow: Case Study on Brake Operating Unit of Railway Vehicle. IEEE Access, 11, 46173–46184. https://doi.org/10.1109/access.2023.3273605
",10.1109/ACCESS.2023.3273605,"The Brake operating unit (BOU) of a railway vehicle is one of the important systems for controlling the braking of the train. Because this system uses compressed air, it is difficult to understand and train the system. The existing education method involves learning the pneumatic flow of various control air in a 2D pneumatic circuit diagram based on a maintenance manual. However, in the actual braking system, it was difficult to learn effectively because the air flows in 3D. In order to solve these problems, the improvement of the training technique using the new 3D augmented reality (AR) was performed. In this study, to increase the learning effect of air brake flow, a technique for simultaneously displaying the pneumatic flow in 2D circuit diagram and 3D model was proposed. First, the distance ratio for simultaneous display can be determined using the proposed streamline matching variable calculation algorithm (SLMVC) that uses position and animation duration as input variables. Second, to avoid the complexity of using the 24 variables of the Particle System module in Unity, an existing universal 3D platform, a continuously emission property correction algorithm (CEPC) that can output particle objects as a streamline using only 4 properties (e.g., start lifetime, start speed, emission rate over time, start delay). As a result, the following 6 different types of BOU air pressure could be simultaneously displayed in 2D and 3D (e.g., AC, BC, SR, SBR, AS1, AS2). Therefore, maintenance staff can effectively learn complex pneumatic flow. To verify the usability of the developed content, a survey using the NASA-TLX technique was conducted targeting 60 maintenance staff. As a result of the comparison between Group A using the existing maintenance manual and Group B using the developed AR content, the perceived workload decreased by 28%. In particular, the frustration part decreased by 64% and the performance part decreased by 62%, indicating that the usability of AR content was very good.",C6130V Virtual reality;C6130B Graphics techniques;C7460 Aerospace engineering computing;C7810C Computer-aided instruction,2D circuit diagram;2D pneumatic circuit diagram;3D augmented reality;60 maintenance staff;actual braking system;air brake flow;augmented reality learning content;BOU air pressure;Brake operating unit;complex pneumatic flow;continuously emission property correction algorithm;control air;developed AR content;developed content;existing education method;existing maintenance manual;existing universal 3D platform;important systems;learning effect;Particle System module;railway vehicle;simultaneous display;training technique;variable calculation algorithm,aerospace computing;augmented reality;brakes;compressed air systems;computer aided instruction;computer animation;maintenance engineering;pneumatic systems;railways,2023,Journal article (JA),IEEE Access (USA),"(1) Kwon, H.J.; (2) Kim, K.S.; (3) Kim, C.S.; ","(1) Korea National University of Transportation, Department of Railroad Convergence System Engineering, Korea, Republic of; (2) Korea National University of Transportation, Industry-Academic Cooperation Foundation, Korea, Republic of; (3) Korea National University of Transportation, School of Railroad Engineering, Korea, Republic of; ",IEEE,-1,"[""aerospace computing"", ""brakes"", ""compressed air systems"", ""computer aided instruction"", ""computer animation"", ""maintenance engineering"", ""pneumatic systems"", ""railways""]","[""aerospace computing"", ""brakes"", ""compressed air systems"", ""computer aided instruction"", ""computer animation"", ""maintenance engineering"", ""pneumatic systems"", ""railways""]",aerospace computing;brakes;compressed air systems;computer aided instruction;computer animation;maintenance engineering;pneumatic systems;railways,education;other;aviation and aerospace;graphics;training;manufacturing,technology;other;use cases;industries,education;other;aviation and aerospace;graphics;training;manufacturing,technology;other;use cases;industries,aerospace_computing brakes compressed_air_systems computer_aided_instruction computer_animation maintenance_engineering pneumatic_systems railways 2d_circuit_diagram 2d_pneumatic_circuit_diagram 3d_augmented_reality 60_maintenance_staff actual_braking_system air_brake_flow augmented_reality_learning_content bou_air_pressure brake_operating_unit complex_pneumatic_flow continuously_emission_property_correction_algorithm control_air developed_ar_content developed_content existing_education_method existing_maintenance_manual existing_universal_3d_platform important_systems learning_effect particle_system_module railway_vehicle simultaneous_display training_technique variable_calculation_algorithm c6130v_virtual_reality c6130b_graphics_techniques c7460_aerospace_engineering_computing c7810c_computer aided_instruction education other aviation_and_aerospace graphics training manufacturing,aerospace_computing brakes compressed_air_systems computer_aided_instruction computer_animation maintenance_engineering pneumatic_systems railways,2d_circuit_diagram 2d_pneumatic_circuit_diagram 3d_augmented_reality 60_maintenance_staff actual_braking_system air_brake_flow augmented_reality_learning_content bou_air_pressure brake_operating_unit complex_pneumatic_flow continuously_emission_property_correction_algorithm control_air developed_ar_content developed_content existing_education_method existing_maintenance_manual existing_universal_3d_platform important_systems learning_effect particle_system_module railway_vehicle simultaneous_display training_technique variable_calculation_algorithm,brake operating unit bou railway vehicle one important system controlling braking train system us compressed air difficult understand train system existing education method involves learning pneumatic flow various control air 2d pneumatic circuit diagram based maintenance manual however actual braking system difficult learn effectively air flow 3d order solve problem improvement training technique using new 3d augmented reality ar performed study increase learning effect air brake flow technique simultaneously displaying pneumatic flow 2d circuit diagram 3d model proposed first distance ratio simultaneous display determined using proposed streamline matching variable calculation algorithm slmvc us position animation duration input variable second avoid complexity using 24 variable particle system module unity existing universal 3d platform continuously emission property correction algorithm cepc output particle object streamline using 4 property e g start lifetime start speed emission rate time start delay result following 6 different type bou air pressure could simultaneously displayed 2d 3d e g ac bc sr sbr as1 as2 therefore maintenance staff effectively learn complex pneumatic flow verify usability developed content survey using nasa tlx technique conducted targeting 60 maintenance staff result comparison group using existing maintenance manual group b using developed ar content perceived workload decreased 28 particular frustration part decreased 64 performance part decreased 62 indicating usability ar content good,aerospace_computing brakes compressed_air_systems computer_aided_instruction computer_animation maintenance_engineering pneumatic_systems railways 2d_circuit_diagram 2d_pneumatic_circuit_diagram 3d_augmented_reality 60_maintenance_staff actual_braking_system air_brake_flow augmented_reality_learning_content bou_air_pressure brake_operating_unit complex_pneumatic_flow continuously_emission_property_correction_algorithm control_air developed_ar_content developed_content existing_education_method existing_maintenance_manual existing_universal_3d_platform important_systems learning_effect particle_system_module railway_vehicle simultaneous_display training_technique variable_calculation_algorithm c6130v_virtual_reality c6130b_graphics_techniques c7460_aerospace_engineering_computing c7810c_computer aided_instruction education other aviation_and_aerospace graphics training manufacturing brake operating unit bou railway vehicle one important system controlling braking train system us compressed air difficult understand train system existing education method involves learning pneumatic flow various control air 2d pneumatic circuit diagram based maintenance manual however actual braking system difficult learn effectively air flow 3d order solve problem improvement training technique using new 3d augmented reality ar performed study increase learning effect air brake flow technique simultaneously displaying pneumatic flow 2d circuit diagram 3d model proposed first distance ratio simultaneous display determined using proposed streamline matching variable calculation algorithm slmvc us position animation duration input variable second avoid complexity using 24 variable particle system module unity existing universal 3d platform continuously emission property correction algorithm cepc output particle object streamline using 4 property e g start lifetime start speed emission rate time start delay result following 6 different type bou air pressure could simultaneously displayed 2d 3d e g ac bc sr sbr as1 as2 therefore maintenance staff effectively learn complex pneumatic flow verify usability developed content survey using nasa tlx technique conducted targeting 60 maintenance staff result comparison group using existing maintenance manual group b using developed ar content perceived workload decreased 28 particular frustration part decreased 64 performance part decreased 62 indicating usability ar content good,brake operating unit bou railway vehicle one important system controlling braking train system us compressed air difficult understand train system existing education method involves learning pneumatic flow various control air 2d pneumatic circuit diagram based maintenance manual however actual braking system difficult learn effectively air flow 3d order solve problem improvement training technique using new 3d augmented reality ar performed study increase learning effect air brake flow technique simultaneously displaying pneumatic flow 2d circuit diagram 3d model proposed first distance ratio simultaneous display determined using proposed streamline matching variable calculation algorithm slmvc us position animation duration input variable second avoid complexity using 24 variable particle system module unity existing universal 3d platform continuously emission property correction algorithm cepc output particle object streamline using 4 property e g start lifetime start speed emission rate time start delay result following 6 different type bou air pressure could simultaneously displayed 2d 3d e g ac bc sr sbr as1 as2 therefore maintenance staff effectively learn complex pneumatic flow verify usability developed content survey using nasa tlx technique conducted targeting 60 maintenance staff result comparison group using existing maintenance manual group b using developed ar content perceived workload decreased 28 particular frustration part decreased 64 performance part decreased 62 indicating usability ar content goodaerospace_computing brakes compressed_air_systems computer_aided_instruction computer_animation maintenance_engineering pneumatic_systems railways2d_circuit_diagram 2d_pneumatic_circuit_diagram 3d_augmented_reality 60_maintenance_staff actual_braking_system air_brake_flow augmented_reality_learning_content bou_air_pressure brake_operating_unit complex_pneumatic_flow continuously_emission_property_correction_algorithm control_air developed_ar_content developed_content existing_education_method existing_maintenance_manual existing_universal_3d_platform important_systems learning_effect particle_system_module railway_vehicle simultaneous_display training_technique variable_calculation_algorithm
107,Through an AR Lens: Augmented Reality Magnification through Feature Detection and Matching,"Eom, S., Hadziahmetovic, M., Pajic, M., & Gorlatova, M. (2022). Through an AR Lens. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568067
",10.1145/3560905.3568067,"Sensing and Augmented Reality (AR) can benefit a wide range of applications that involve the use of magnifying lenses. Recent developments in AR magnification provide a direct overlay of the magnified scenes in AR. However, instrumentation tasks that require high precision and visual acuity need to selectively magnify a region of interest while maintaining the visual perception of the rest of the environment. In this demo, we presentAR-Magnifier, an AR magnification system through feature detection and matching. We propose a general framework based on an edge-computing architecture that can be applied to various types of instrumentation tasks. A pipeline is developed for detecting feature points and computing the homography matching to identify the magnified region of an object. We showcase how selective magnification in AR through sensing can assist the user in complex instrumentation tasks by providing visualization-based guidance.","A4280A Optical lenses and mirrors;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",AR lens;AR magnification system;AR-Magnifier;Augmented Reality magnification;complex instrumentation tasks;direct overlay;edge-computing architecture;feature detection;feature points;homography matching;magnified region;magnified scenes;magnifying lenses;selective magnification;visual acuity need;visual perception;visualization-based guidance,augmented reality;feature extraction;lenses;visual perception,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Eom, S.; (2) Hadziahmetovic, M.; (1) Pajic, M.; (1) Gorlatova, M.; ","(1) Duke University, Durham, NC, United States; (2) Infinity Vision Dallas, Dallas, TX, United States; ",ACM,-1,"[""feature extraction"", ""lenses"", ""visual perception""]","[""feature extraction"", ""lenses"", ""visual perception""]",feature extraction;lenses;visual perception,computer vision;input;chemical;display technology,technology;displays;industries,computer vision;input;chemical;display technology,technology;displays;industries,feature_extraction lenses visual_perception ar_lens ar_magnification_system ar magnifier augmented_reality_magnification complex_instrumentation_tasks direct_overlay edge computing_architecture feature_detection feature_points homography_matching magnified_region magnified_scenes magnifying_lenses selective_magnification visual_acuity_need visual_perception visualization based_guidance a4280a_optical_lenses_and_mirrors b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input chemical display_technology,feature_extraction lenses visual_perception,ar_lens ar_magnification_system ar magnifier augmented_reality_magnification complex_instrumentation_tasks direct_overlay edge computing_architecture feature_detection feature_points homography_matching magnified_region magnified_scenes magnifying_lenses selective_magnification visual_acuity_need visual_perception visualization based_guidance,sensing augmented reality ar benefit wide range application involve use magnifying lens recent development ar magnification provide direct overlay magnified scene ar however instrumentation task require high precision visual acuity need selectively magnify region interest maintaining visual perception rest environment demo presentar magnifier ar magnification system feature detection matching propose general framework based edge computing architecture applied various type instrumentation task pipeline developed detecting feature point computing homography matching identify magnified region object showcase selective magnification ar sensing assist user complex instrumentation task providing visualization based guidance,feature_extraction lenses visual_perception ar_lens ar_magnification_system ar magnifier augmented_reality_magnification complex_instrumentation_tasks direct_overlay edge computing_architecture feature_detection feature_points homography_matching magnified_region magnified_scenes magnifying_lenses selective_magnification visual_acuity_need visual_perception visualization based_guidance a4280a_optical_lenses_and_mirrors b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input chemical display_technology sensing augmented reality ar benefit wide range application involve use magnifying lens recent development ar magnification provide direct overlay magnified scene ar however instrumentation task require high precision visual acuity need selectively magnify region interest maintaining visual perception rest environment demo presentar magnifier ar magnification system feature detection matching propose general framework based edge computing architecture applied various type instrumentation task pipeline developed detecting feature point computing homography matching identify magnified region object showcase selective magnification ar sensing assist user complex instrumentation task providing visualization based guidance,sensing augmented reality ar benefit wide range application involve use magnifying lens recent development ar magnification provide direct overlay magnified scene ar however instrumentation task require high precision visual acuity need selectively magnify region interest maintaining visual perception rest environment demo presentar magnifier ar magnification system feature detection matching propose general framework based edge computing architecture applied various type instrumentation task pipeline developed detecting feature point computing homography matching identify magnified region object showcase selective magnification ar sensing assist user complex instrumentation task providing visualization based guidancefeature_extraction lenses visual_perceptionar_lens ar_magnification_system ar magnifier augmented_reality_magnification complex_instrumentation_tasks direct_overlay edge computing_architecture feature_detection feature_points homography_matching magnified_region magnified_scenes magnifying_lenses selective_magnification visual_acuity_need visual_perception visualization based_guidance
108,A Stand-Alone Augmented Reality Intervention for Chronic Pain Using Embodied Systolic Stimulation,"Kannape, O. A., Pierret, J., Leeb, R., Cardin, S., Bourban, F., Mensi, S., Lebrun, Y., Merlini, N., Dorier, A., Moriot, V., Touillet, A., & Serino, A. (2023). A Stand-Alone Augmented Reality Intervention for Chronic Pain Using Embodied Systolic Stimulation. 2023 11th International IEEE/EMBS Conference on Neural Engineering (NER). https://doi.org/10.1109/ner52421.2023.10123746
",10.1109/NER52421.2023.10123746,"Chronic pain presents a tremendous personal, societal, and financial burden. Treatment options are often limited to managing symptoms as opposed to treating the causes, and the consequences of pharmacological treatments can be immensely harmful as evidenced by the on-going opioid epidemic. Virtual Reality interventions and digital therapeutics provide a new tool for therapists but are currently limited to pain-distraction or digitizing traditional approaches that are similarly focused on pain management. However, recent research suggests that potentially neurorestorative, non-pharmacological treatments are conceivable using personalized, embodied, multimodal feedback. In particular, i) providing visual feedback of the affected body part, ii) increasing its embodiment using multisensory stimulation, and iii) timing stimulation to the systole of the ECG cycle have been linked with analgesic effects in induced acute and chronic pain. Based on these findings and methods, we here propose a stand-alone solution that aims to provide neurorestorative feedback for individuals suffering from chronic pain by visualizing interoceptive signals and mapping them onto the patients affected body part using Augmented Reality, tapping into the three aforementioned principles. Our initial findings indicate the feasibility, acceptance, and stimulus adherence of the device and intervention, whose efficacy will be evaluated in an upcoming randomized controlled clinical trial.",A8770G Patient care and treatment;A8770F Electrodiagnostics and other electrical measurement techniques;B7510D Bioelectric signals;B7520 Patient care and treatment;C5260 Digital signal processing;C6130V Virtual reality;C7330 Biology and medical computing,"Augmented Reality;chronic pain;embodied systolic stimulation;financial burden;nonpharmacological treatments;pain management;pain-distraction;pharmacological treatments;societal, burden;treatment options;tremendous personal burden;Virtual Reality interventions",augmented reality;bioelectric potentials;diseases;electrocardiography;epidemics;medical computing;medical disorders;medical signal processing;neurophysiology;patient monitoring;patient treatment;virtual reality,2023,Conference article (CA),2023 11th International IEEE/EMBS Conference on Neural Engineering (NER),"(1) Kannape, O.A.; (2) Pierret, J.; (3) Leeb, R.; (4) Cardin, S.; (3) Bourban, F.; (3) Mensi, S.; (3) Lebrun, Y.; (3) Merlini, N.; (3) Dorier, A.; (2) Moriot, V.; (2) Touillet, A.; (5) Serino, A.; ","(1) University Hospital Geneva, Virtual Medicine Center, Switzerland; (2) IRR Site de Nancy, UGECAM NE, France; (3) MindMaze SA, MindMaze Labs, Switzerland; (4) E&#769;cole Polytechnique de Lausanne, EM+, Switzerland; (5) University Hospital Lausanne, Dept. Clinical Neuroscience, Switzerland; ",IEEE,-1,"[""bioelectric potentials"", ""diseases"", ""electrocardiography"", ""epidemics"", ""medical computing"", ""medical disorders"", ""medical signal processing"", ""neurophysiology"", ""patient monitoring"", ""patient treatment""]","[""bioelectric potentials"", ""diseases"", ""electrocardiography"", ""epidemics"", ""medical computing"", ""medical disorders"", ""medical signal processing"", ""neurophysiology"", ""patient monitoring"", ""patient treatment""]",bioelectric potentials;diseases;electrocardiography;epidemics;medical computing;medical disorders;medical signal processing;neurophysiology;patient monitoring;patient treatment,"medical;sensors;data;inspection, safety and quality",technology;use cases;industries,"medical;sensors;data;inspection, safety and quality",technology;use cases;industries,bioelectric_potentials diseases electrocardiography epidemics medical_computing medical_disorders medical_signal_processing neurophysiology patient_monitoring patient_treatment augmented_reality chronic_pain embodied_systolic_stimulation financial_burden nonpharmacological_treatments pain_management pain distraction pharmacological_treatments societal _burden treatment_options tremendous_personal_burden virtual_reality_interventions a8770g_patient_care_and_treatment a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b7510d_bioelectric_signals b7520_patient_care_and_treatment c5260_digital_signal_processing c6130v_virtual_reality c7330_biology_and_medical_computing medical sensors data inspection _safety_and_quality,bioelectric_potentials diseases electrocardiography epidemics medical_computing medical_disorders medical_signal_processing neurophysiology patient_monitoring patient_treatment,augmented_reality chronic_pain embodied_systolic_stimulation financial_burden nonpharmacological_treatments pain_management pain distraction pharmacological_treatments societal _burden treatment_options tremendous_personal_burden virtual_reality_interventions,chronic pain present tremendous personal societal financial burden treatment option often limited managing symptom opposed treating cause consequence pharmacological treatment immensely harmful evidenced going opioid epidemic virtual reality intervention digital therapeutic provide new tool therapist currently limited pain distraction digitizing traditional approach similarly focused pain management however recent research suggests potentially neurorestorative non pharmacological treatment conceivable using personalized embodied multimodal feedback particular providing visual feedback affected body part ii increasing embodiment using multisensory stimulation iii timing stimulation systole ecg cycle linked analgesic effect induced acute chronic pain based finding method propose stand alone solution aim provide neurorestorative feedback individual suffering chronic pain visualizing interoceptive signal mapping onto patient affected body part using augmented reality tapping three aforementioned principle initial finding indicate feasibility acceptance stimulus adherence device intervention whose efficacy evaluated upcoming randomized controlled clinical trial,bioelectric_potentials diseases electrocardiography epidemics medical_computing medical_disorders medical_signal_processing neurophysiology patient_monitoring patient_treatment augmented_reality chronic_pain embodied_systolic_stimulation financial_burden nonpharmacological_treatments pain_management pain distraction pharmacological_treatments societal _burden treatment_options tremendous_personal_burden virtual_reality_interventions a8770g_patient_care_and_treatment a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b7510d_bioelectric_signals b7520_patient_care_and_treatment c5260_digital_signal_processing c6130v_virtual_reality c7330_biology_and_medical_computing medical sensors data inspection _safety_and_quality chronic pain present tremendous personal societal financial burden treatment option often limited managing symptom opposed treating cause consequence pharmacological treatment immensely harmful evidenced going opioid epidemic virtual reality intervention digital therapeutic provide new tool therapist currently limited pain distraction digitizing traditional approach similarly focused pain management however recent research suggests potentially neurorestorative non pharmacological treatment conceivable using personalized embodied multimodal feedback particular providing visual feedback affected body part ii increasing embodiment using multisensory stimulation iii timing stimulation systole ecg cycle linked analgesic effect induced acute chronic pain based finding method propose stand alone solution aim provide neurorestorative feedback individual suffering chronic pain visualizing interoceptive signal mapping onto patient affected body part using augmented reality tapping three aforementioned principle initial finding indicate feasibility acceptance stimulus adherence device intervention whose efficacy evaluated upcoming randomized controlled clinical trial,chronic pain present tremendous personal societal financial burden treatment option often limited managing symptom opposed treating cause consequence pharmacological treatment immensely harmful evidenced going opioid epidemic virtual reality intervention digital therapeutic provide new tool therapist currently limited pain distraction digitizing traditional approach similarly focused pain management however recent research suggests potentially neurorestorative non pharmacological treatment conceivable using personalized embodied multimodal feedback particular providing visual feedback affected body part ii increasing embodiment using multisensory stimulation iii timing stimulation systole ecg cycle linked analgesic effect induced acute chronic pain based finding method propose stand alone solution aim provide neurorestorative feedback individual suffering chronic pain visualizing interoceptive signal mapping onto patient affected body part using augmented reality tapping three aforementioned principle initial finding indicate feasibility acceptance stimulus adherence device intervention whose efficacy evaluated upcoming randomized controlled clinical trialbioelectric_potentials diseases electrocardiography epidemics medical_computing medical_disorders medical_signal_processing neurophysiology patient_monitoring patient_treatmentaugmented_reality chronic_pain embodied_systolic_stimulation financial_burden nonpharmacological_treatments pain_management pain distraction pharmacological_treatments societal _burden treatment_options tremendous_personal_burden virtual_reality_interventions
109,"Innovative Cultural Experience (ICE), an Augmented Reality system for promoting cultural heritage","Kazanidis, I., Terzopoulos, G., Tsinakos, A., Georgiou, D., Karampatzakis, D., Georgiou, D., & Karampatzakis, D. (2022). Innovative Cultural Experience (ICE), an Augmented Reality system for promoting cultural heritage. Proceedings of the 26th Pan-Hellenic Conference on Informatics. https://doi.org/10.1145/3575879.3576001
",10.1145/3575879.3576001,"Innovative Cultural Experience (ICE) is an Augmented Reality (AR) system for promoting cultural heritage. ICE combines cutting-edge technologies such as an interactive transparent screen, AR, motion sensors and multimedia material in order to provide a unique personal or mass-touring experience, utilizing information based on material and intangible cultural heritage, through narrative scenarios. Part of the ICE system is an interactive transparent box in which an exhibit can be placed. When a user/visitor approaches the exhibit, multimedia information is displayed on the transparent screen of the box, creating an interactive AR experience for the user. Users can interact with the content which can be text, images, videos, 360 images, 360 videos, 3D models or even play games based on the exhibit that is in front of them. By combining the real exhibit with digital information displayed on top, an interactive AR experience is created. Additionally, users can provide feedback by recording and uploading text, images, and videos to the ICE system. ICE is cognitively neutral (domain independent) technology, which makes it useful for a variety of thematic items (from museum exhibits to folk customs, local recipes, etc.) and it can be used also in education, commercial and in the tourist sectors. This paper presents the architecture of the ICE system, and the technologies used for building it. Initial internal evaluation results show that the system is easy to use, and users tend to stay longer in front of the exhibit, interacting with it, thus collecting more information about it.",C7820 Humanities computing;C5260B Computer vision and image processing techniques;C6130M Multimedia;C6130V Virtual reality;C6180 User interfaces;C7185 Administration of other service industries;C7830D Computer games,Augmented Reality system;cutting-edge technologies;digital information;ICE system;innovative Cultural Experience;Innovative Cultural Experience;intangible cultural heritage;interactive AR experience;interactive transparent box;interactive transparent screen;mass-touring experience;motion sensors;multimedia information;multimedia material;museum exhibits;unique personal touring experience,augmented reality;history;museums;travel industry,2022,Conference article (CA),PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics,"(1) Kazanidis, I.; (1) Terzopoulos, G.; (1) Tsinakos, A.; (2) Georgiou, D.; (1) Karampatzakis, D.; (2) Georgiou, D.; (1) Karampatzakis, D.; ","(1) International Hellenic University, Computer Science Department, Greece; (2) International Hellenic University, Greece; ",ACM,-1,"[""history"", ""museums"", ""travel industry""]","[""history"", ""museums"", ""travel industry""]",history;museums;travel industry,cultural heritage;transportation;liberal arts,industries,cultural heritage;transportation;liberal arts,industries,history museums travel_industry augmented_reality_system cutting edge_technologies digital_information ice_system innovative_cultural_experience innovative_cultural_experience intangible_cultural_heritage interactive_ar_experience interactive_transparent_box interactive_transparent_screen mass touring_experience motion_sensors multimedia_information multimedia_material museum_exhibits unique_personal_touring_experience c7820_humanities_computing c5260b_computer_vision_and_image_processing_techniques c6130m_multimedia c6130v_virtual_reality c6180_user_interfaces c7185_administration_of_other_service_industries c7830d_computer_games cultural_heritage transportation liberal_arts,history museums travel_industry,augmented_reality_system cutting edge_technologies digital_information ice_system innovative_cultural_experience innovative_cultural_experience intangible_cultural_heritage interactive_ar_experience interactive_transparent_box interactive_transparent_screen mass touring_experience motion_sensors multimedia_information multimedia_material museum_exhibits unique_personal_touring_experience,innovative cultural experience ice augmented reality ar system promoting cultural heritage ice combine cutting edge technology interactive transparent screen ar motion sensor multimedia material order provide unique personal mass touring experience utilizing information based material intangible cultural heritage narrative scenario part ice system interactive transparent box exhibit placed user visitor approach exhibit multimedia information displayed transparent screen box creating interactive ar experience user user interact content text image video 360 image 360 video 3d model even play game based exhibit front combining real exhibit digital information displayed top interactive ar experience created additionally user provide feedback recording uploading text image video ice system ice cognitively neutral domain independent technology make useful variety thematic item museum exhibit folk custom local recipe etc used also education commercial tourist sector paper present architecture ice system technology used building initial internal evaluation result show system easy use user tend stay longer front exhibit interacting thus collecting information,history museums travel_industry augmented_reality_system cutting edge_technologies digital_information ice_system innovative_cultural_experience innovative_cultural_experience intangible_cultural_heritage interactive_ar_experience interactive_transparent_box interactive_transparent_screen mass touring_experience motion_sensors multimedia_information multimedia_material museum_exhibits unique_personal_touring_experience c7820_humanities_computing c5260b_computer_vision_and_image_processing_techniques c6130m_multimedia c6130v_virtual_reality c6180_user_interfaces c7185_administration_of_other_service_industries c7830d_computer_games cultural_heritage transportation liberal_arts innovative cultural experience ice augmented reality ar system promoting cultural heritage ice combine cutting edge technology interactive transparent screen ar motion sensor multimedia material order provide unique personal mass touring experience utilizing information based material intangible cultural heritage narrative scenario part ice system interactive transparent box exhibit placed user visitor approach exhibit multimedia information displayed transparent screen box creating interactive ar experience user user interact content text image video 360 image 360 video 3d model even play game based exhibit front combining real exhibit digital information displayed top interactive ar experience created additionally user provide feedback recording uploading text image video ice system ice cognitively neutral domain independent technology make useful variety thematic item museum exhibit folk custom local recipe etc used also education commercial tourist sector paper present architecture ice system technology used building initial internal evaluation result show system easy use user tend stay longer front exhibit interacting thus collecting information,innovative cultural experience ice augmented reality ar system promoting cultural heritage ice combine cutting edge technology interactive transparent screen ar motion sensor multimedia material order provide unique personal mass touring experience utilizing information based material intangible cultural heritage narrative scenario part ice system interactive transparent box exhibit placed user visitor approach exhibit multimedia information displayed transparent screen box creating interactive ar experience user user interact content text image video 360 image 360 video 3d model even play game based exhibit front combining real exhibit digital information displayed top interactive ar experience created additionally user provide feedback recording uploading text image video ice system ice cognitively neutral domain independent technology make useful variety thematic item museum exhibit folk custom local recipe etc used also education commercial tourist sector paper present architecture ice system technology used building initial internal evaluation result show system easy use user tend stay longer front exhibit interacting thus collecting informationhistory museums travel_industryaugmented_reality_system cutting edge_technologies digital_information ice_system innovative_cultural_experience innovative_cultural_experience intangible_cultural_heritage interactive_ar_experience interactive_transparent_box interactive_transparent_screen mass touring_experience motion_sensors multimedia_information multimedia_material museum_exhibits unique_personal_touring_experience
110,Perceptual Modifications in Augmented Reality: A Short Survey,"Nijholt, A. (2022). Perceptual Modifications in Augmented Reality: A Short Survey. Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3561318
",10.1145/3544793.3561318,"Views on Augmented Reality (AR) and its technology have changed. Rather than being a research area on its own, with a focus on computer vision and computer-generated imagery, we now have to deal with the integration of AR technology with ubiquitous computing where we have sensors, actuators, and processing capabilities beyond what is possible with a single AR device. The plethora of AR applications that follow from this point of view has not yet fully been investigated. In this paper, we review how in reported AR research this issue is dealt with. We survey the attempts from the AR community to integrate perception technology with AR. These attempts should be added to and integrated with augmented human and multisensorial research that nowadays is being done in the context of ubiquitous computing (Internet of Things, Ambient Intelligence, smart environments).","C6130V Virtual reality;C5260B Computer vision and image processing techniques;C5620D Internet of Things;C6190V Mobile, ubiquitous and pervasive computing",AR technology;augmented human research;Augmented Reality;computer vision;computer-generated imagery;multisensorial research;perception technology;perceptual modifications;reported AR research this issue;short survey;single AR device;ubiquitous computing,ambient intelligence;augmented reality;computer vision;Internet of Things;ubiquitous computing,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) Nijholt, A.; ","(1) University of Twente, Netherlands; ",ACM,-1,"[""ambient intelligence"", ""computer vision"", ""internet of things"", ""ubiquitous computing""]","[""ambient intelligence"", ""computer vision"", ""internet of things"", ""ubiquitous computing""]",ambient intelligence;computer vision;internet of things;ubiquitous computing,computer vision;internet of things;human-computer interaction;networks,technology;end users and user experience,computer vision;internet of things;human-computer interaction;networks,technology;end users and user experience,ambient_intelligence computer_vision internet_of_things ubiquitous_computing ar_technology augmented_human_research augmented_reality computer_vision computer generated_imagery multisensorial_research perception_technology perceptual_modifications reported_ar_research_this_issue short_survey single_ar_device ubiquitous_computing c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision internet_of_things human computer_interaction networks,ambient_intelligence computer_vision internet_of_things ubiquitous_computing,ar_technology augmented_human_research augmented_reality computer_vision computer generated_imagery multisensorial_research perception_technology perceptual_modifications reported_ar_research_this_issue short_survey single_ar_device ubiquitous_computing,view augmented reality ar technology changed rather research area focus computer vision computer generated imagery deal integration ar technology ubiquitous computing sensor actuator processing capability beyond possible single ar device plethora ar application follow point view yet fully investigated paper review reported ar research issue dealt survey attempt ar community integrate perception technology ar attempt added integrated augmented human multisensorial research nowadays done context ubiquitous computing internet thing ambient intelligence smart environment,ambient_intelligence computer_vision internet_of_things ubiquitous_computing ar_technology augmented_human_research augmented_reality computer_vision computer generated_imagery multisensorial_research perception_technology perceptual_modifications reported_ar_research_this_issue short_survey single_ar_device ubiquitous_computing c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision internet_of_things human computer_interaction networks view augmented reality ar technology changed rather research area focus computer vision computer generated imagery deal integration ar technology ubiquitous computing sensor actuator processing capability beyond possible single ar device plethora ar application follow point view yet fully investigated paper review reported ar research issue dealt survey attempt ar community integrate perception technology ar attempt added integrated augmented human multisensorial research nowadays done context ubiquitous computing internet thing ambient intelligence smart environment,view augmented reality ar technology changed rather research area focus computer vision computer generated imagery deal integration ar technology ubiquitous computing sensor actuator processing capability beyond possible single ar device plethora ar application follow point view yet fully investigated paper review reported ar research issue dealt survey attempt ar community integrate perception technology ar attempt added integrated augmented human multisensorial research nowadays done context ubiquitous computing internet thing ambient intelligence smart environmentambient_intelligence computer_vision internet_of_things ubiquitous_computingar_technology augmented_human_research augmented_reality computer_vision computer generated_imagery multisensorial_research perception_technology perceptual_modifications reported_ar_research_this_issue short_survey single_ar_device ubiquitous_computing
111,V-Light: Leveraging Edge Computing For The Design of Mobile Augmented Reality Games,"Hammad, N., Eiszler, T., Gazda, R., Cartmell, J., Harpstead, E., & Hammer, J. (2023). V-Light: Leveraging Edge Computing For The Design of Mobile Augmented Reality Games. Proceedings of the 18th International Conference on the Foundations of Digital Games. https://doi.org/10.1145/3582437.3582456
",10.1145/3582437.3582456,"We explore the future of synchronous, multiplayer mobile AR gaming through our game V-Light, which extends current mobile AR game capacities using edge computing. Mobile AR games are currently limited by on-board processing power, while offloading operations to the cloud introduces high latency costs. This is a critical issue for games needing real-time response to player input. V-Light demonstrates how mobile AR games can leverage the power of edge computing, bringing computational resources closer to the user, keeping latency low and bandwidth high. We share our development toolkit, analyze the design and development of V-Light through the lens of an existing model for shared-world mobile AR, and demonstrate that edge computing can provide a ""time machine"" that lets game designers prototype mobile AR games for devices that do not yet exist.","C6130V Virtual reality;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing;C7830D Computer games",computational resources;current mobile AR game capacities;edge computing;game designers prototype mobile;game V-Light;mobile augmented reality games;multiplayer mobile AR gaming;on-board processing power;shared-world mobile AR;synchronous AR gaming,augmented reality;cloud computing;computer games;edge computing;mobile computing,2023,Conference article (CA),FDG '23: Proceedings of the 18th International Conference on the Foundations of Digital Games,"(1) Hammad, N.; (2) Eiszler, T.; (3) Gazda, R.; (3) Cartmell, J.; (1) Harpstead, E.; (1) Hammer, J.; ","(1) Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; (2) Carnegie Mellon University, Computer Science Department, Pittsburgh, PA, United States; (3) Interdigital, United States; ",ACM,-1,"[""cloud computing"", ""computer games"", ""edge computing"", ""mobile computing""]","[""cloud computing"", ""computer games"", ""edge computing"", ""mobile computing""]",cloud computing;computer games;edge computing;mobile computing,telecommunication;liberal arts;networks,technology;industries,telecommunication;liberal arts;networks,technology;industries,cloud_computing computer_games edge_computing mobile_computing computational_resources current_mobile_ar_game_capacities edge_computing game_designers_prototype_mobile game_v light mobile_augmented_reality_games multiplayer_mobile_ar_gaming on board_processing_power shared world_mobile_ar synchronous_ar_gaming c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games telecommunication liberal_arts networks,cloud_computing computer_games edge_computing mobile_computing,computational_resources current_mobile_ar_game_capacities edge_computing game_designers_prototype_mobile game_v light mobile_augmented_reality_games multiplayer_mobile_ar_gaming on board_processing_power shared world_mobile_ar synchronous_ar_gaming,explore future synchronous multiplayer mobile ar gaming game v light extends current mobile ar game capacity using edge computing mobile ar game currently limited board processing power offloading operation cloud introduces high latency cost critical issue game needing real time response player input v light demonstrates mobile ar game leverage power edge computing bringing computational resource closer user keeping latency low bandwidth high share development toolkit analyze design development v light lens existing model shared world mobile ar demonstrate edge computing provide time machine let game designer prototype mobile ar game device yet exist,cloud_computing computer_games edge_computing mobile_computing computational_resources current_mobile_ar_game_capacities edge_computing game_designers_prototype_mobile game_v light mobile_augmented_reality_games multiplayer_mobile_ar_gaming on board_processing_power shared world_mobile_ar synchronous_ar_gaming c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7830d_computer_games telecommunication liberal_arts networks explore future synchronous multiplayer mobile ar gaming game v light extends current mobile ar game capacity using edge computing mobile ar game currently limited board processing power offloading operation cloud introduces high latency cost critical issue game needing real time response player input v light demonstrates mobile ar game leverage power edge computing bringing computational resource closer user keeping latency low bandwidth high share development toolkit analyze design development v light lens existing model shared world mobile ar demonstrate edge computing provide time machine let game designer prototype mobile ar game device yet exist,explore future synchronous multiplayer mobile ar gaming game v light extends current mobile ar game capacity using edge computing mobile ar game currently limited board processing power offloading operation cloud introduces high latency cost critical issue game needing real time response player input v light demonstrates mobile ar game leverage power edge computing bringing computational resource closer user keeping latency low bandwidth high share development toolkit analyze design development v light lens existing model shared world mobile ar demonstrate edge computing provide time machine let game designer prototype mobile ar game device yet existcloud_computing computer_games edge_computing mobile_computingcomputational_resources current_mobile_ar_game_capacities edge_computing game_designers_prototype_mobile game_v light mobile_augmented_reality_games multiplayer_mobile_ar_gaming on board_processing_power shared world_mobile_ar synchronous_ar_gaming
112,SkillsLab+ - Proof of Concept for Medical Augmented Reality Teaching Application with Haptic Feedback,"Gießer, C., Schmitt, J., Limbach, M., Otterbach, J., & Brück, R. (2023). SkillsLab+ - Proof of Concept for Medical Augmented Reality Teaching Application with Haptic Feedback. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125161
",10.1109/EDUCON54358.2023.10125161,"The classic SkillsLab is a training environment in which medical students can train procedures, examinations, hand movements, therapy, and treatment on anatomically correct models or simulated body parts. This training takes place in a stress-free environment, as there is no responsibility, risk, or time pressure. In addition, detailed explanations and instructions are provided by medical experts. SkillsLab+ is a digitalized version of the classic SkillsLab and currently implemented as proof of concept. The course concept is transferred into an augmented reality application, which currently includes nine stations of approaches to medical teaching. These include, among others, the injection into an arm and clinical abdominal exam. The purpose of this application is to allow medical students to work on the learning content independently at their own pace and even from home. Furthermore, the additional integration of haptic gloves allows students to feel and touch virtual objects. A distinction between different surface structures such as hard bones or soft skin can be made via vibrational and force feedback. The evaluation of a user questionnaire shows that a majority of the students felt supported in the preparation and follow-up of the medical content and can imagine using SkillsLab+ in distance learning and in medical teaching to deepen their knowledge in the medical application field.",A8770E Patient diagnostic methods and instrumentation;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing;C7810C Computer-aided instruction,additional integration;anatomically correct models;augmented reality application;classic SkillsLab;clinical abdominal exam;course concept;detailed explanations;digitalized version;hand movements;haptic feedback;haptic gloves;medical application field;medical augmented reality teaching application;medical content;medical experts;medical students;medical teaching;simulated body parts;stress-free environment;time pressure;training environment;vibrational force feedback,augmented reality;biomedical education;bone;computer aided instruction;computer based training;data gloves;distance learning;force feedback;haptic interfaces;medical computing;medical image processing;teaching;virtual reality,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Gieber, C.; (2) Schmitt, J.; (2) Limbach, M.; (2) Otterbach, J.; (1) Bruck, R.; ","(1) University of Siegen, Medical Informatics and Microsystems Engineering, Germany; (2) University of Siegen, Germany; ",IEEE,-1,"[""biomedical education"", ""bone"", ""computer aided instruction"", ""computer based training"", ""data gloves"", ""distance learning"", ""force feedback"", ""haptic interfaces"", ""medical computing"", ""medical image processing"", ""teaching""]","[""biomedical education"", ""bone"", ""computer aided instruction"", ""computer based training"", ""data gloves"", ""distance learning"", ""force feedback"", ""haptic interfaces"", ""medical computing"", ""medical image processing"", ""teaching""]",biomedical education;bone;computer aided instruction;computer based training;data gloves;distance learning;force feedback;haptic interfaces;medical computing;medical image processing;teaching,computer vision;education;farming and natural science;input;medical;training;data;human-computer interaction,technology;end users and user experience;use cases;industries,computer vision;education;farming and natural science;input;medical;training;data;human-computer interaction,technology;end users and user experience;use cases;industries,biomedical_education bone computer_aided_instruction computer_based_training data_gloves distance_learning force_feedback haptic_interfaces medical_computing medical_image_processing teaching additional_integration anatomically_correct_models augmented_reality_application classic_skillslab clinical_abdominal_exam course_concept detailed_explanations digitalized_version hand_movements haptic_feedback haptic_gloves medical_application_field medical_augmented_reality_teaching_application medical_content medical_experts medical_students medical_teaching simulated_body_parts stress free_environment time_pressure training_environment vibrational_force_feedback a8770e_patient_diagnostic_methods_and_instrumentation c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing c7810c_computer aided_instruction computer_vision education farming_and_natural_science input medical training data human computer_interaction,biomedical_education bone computer_aided_instruction computer_based_training data_gloves distance_learning force_feedback haptic_interfaces medical_computing medical_image_processing teaching,additional_integration anatomically_correct_models augmented_reality_application classic_skillslab clinical_abdominal_exam course_concept detailed_explanations digitalized_version hand_movements haptic_feedback haptic_gloves medical_application_field medical_augmented_reality_teaching_application medical_content medical_experts medical_students medical_teaching simulated_body_parts stress free_environment time_pressure training_environment vibrational_force_feedback,classic skillslab training environment medical student train procedure examination hand movement therapy treatment anatomically correct model simulated body part training take place stress free environment responsibility risk time pressure addition detailed explanation instruction provided medical expert skillslab digitalized version classic skillslab currently implemented proof concept course concept transferred augmented reality application currently includes nine station approach medical teaching include among others injection arm clinical abdominal exam purpose application allow medical student work learning content independently pace even home furthermore additional integration haptic glove allows student feel touch virtual object distinction different surface structure hard bone soft skin made via vibrational force feedback evaluation user questionnaire show majority student felt supported preparation follow medical content imagine using skillslab distance learning medical teaching deepen knowledge medical application field,biomedical_education bone computer_aided_instruction computer_based_training data_gloves distance_learning force_feedback haptic_interfaces medical_computing medical_image_processing teaching additional_integration anatomically_correct_models augmented_reality_application classic_skillslab clinical_abdominal_exam course_concept detailed_explanations digitalized_version hand_movements haptic_feedback haptic_gloves medical_application_field medical_augmented_reality_teaching_application medical_content medical_experts medical_students medical_teaching simulated_body_parts stress free_environment time_pressure training_environment vibrational_force_feedback a8770e_patient_diagnostic_methods_and_instrumentation c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing c7810c_computer aided_instruction computer_vision education farming_and_natural_science input medical training data human computer_interaction classic skillslab training environment medical student train procedure examination hand movement therapy treatment anatomically correct model simulated body part training take place stress free environment responsibility risk time pressure addition detailed explanation instruction provided medical expert skillslab digitalized version classic skillslab currently implemented proof concept course concept transferred augmented reality application currently includes nine station approach medical teaching include among others injection arm clinical abdominal exam purpose application allow medical student work learning content independently pace even home furthermore additional integration haptic glove allows student feel touch virtual object distinction different surface structure hard bone soft skin made via vibrational force feedback evaluation user questionnaire show majority student felt supported preparation follow medical content imagine using skillslab distance learning medical teaching deepen knowledge medical application field,classic skillslab training environment medical student train procedure examination hand movement therapy treatment anatomically correct model simulated body part training take place stress free environment responsibility risk time pressure addition detailed explanation instruction provided medical expert skillslab digitalized version classic skillslab currently implemented proof concept course concept transferred augmented reality application currently includes nine station approach medical teaching include among others injection arm clinical abdominal exam purpose application allow medical student work learning content independently pace even home furthermore additional integration haptic glove allows student feel touch virtual object distinction different surface structure hard bone soft skin made via vibrational force feedback evaluation user questionnaire show majority student felt supported preparation follow medical content imagine using skillslab distance learning medical teaching deepen knowledge medical application fieldbiomedical_education bone computer_aided_instruction computer_based_training data_gloves distance_learning force_feedback haptic_interfaces medical_computing medical_image_processing teachingadditional_integration anatomically_correct_models augmented_reality_application classic_skillslab clinical_abdominal_exam course_concept detailed_explanations digitalized_version hand_movements haptic_feedback haptic_gloves medical_application_field medical_augmented_reality_teaching_application medical_content medical_experts medical_students medical_teaching simulated_body_parts stress free_environment time_pressure training_environment vibrational_force_feedback
113,TitleIX: Step Up &amp; Step In! A Mobile Augmented Reality Game Featuring Interactive Embodied Conversational Agents for Sexual Assault Bystander Intervention Training on US College Campuses,"Schlesener, E. A., Lancaster, C. M., Barwulor, C., Murmu, C., & Schulenberg, K. (2023). TitleIX: Step Up &amp; Step In! A Mobile Augmented Reality Game Featuring Interactive Embodied Conversational Agents for Sexual Assault Bystander Intervention Training on US College Campuses. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583832
",10.1145/3544549.3583832,"Despite the efforts of existing Title IX training programs in the US, current intervention and prevention programs fail to address the problems caused by sexual violence on US college campuses. To address this issue, we designed a mobile augmented reality (AR) game - TitleIX: Step Up &amp; Step In! - that encourages students to become more active and supportive of bystanders through innovative game play, while aiming to improve current sexual assault bystander intervention training. Utilizing AR technology and embodied conversational agents (ECAs), this game provides highly immersive scenario based training for sexual assault bystander intervention while connecting the users to realistic campus experiences. This inventive game design leverages innovative technology to increase awareness of real-world problems; specifically, sexual harassment targeting women and LGBTQ+ students on college campuses. The design implemented in this paper can inform the future construction of AR serious games for social justice.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7820N Natural language processing;C7830D Computer games",AR serious games;immersive scenario based training;innovative game play;interactive embodied conversational agents;inventive game design;LGBTQ+ students;mobile augmented reality game;prevention programs;sexual assault bystander intervention training;sexual harassment;sexual violence;Title IX training programs;TitleIX: Step Up &amp; Step In!;US college campuses,augmented reality;chatbots;computer based training;educational institutions;gender issues;mobile learning;serious games (computing),2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schlesener, E.A.; (1) Lancaster, C.M.; (1) Barwulor, C.; (1) Murmu, C.; (1) Schulenberg, K.; ","(1) Clemson University, School of Computing, Clemson, SC, United States; ",ACM,-1,"[""chatbots"", ""computer based training"", ""educational institutions"", ""gender issues"", ""mobile learning"", ""serious games""]","[""chatbots"", ""computer based training"", ""educational institutions"", ""gender issues"", ""mobile learning"", ""serious games""]",chatbots;computer based training;educational institutions;gender issues;mobile learning;serious games,education;farming and natural science;other;simulation;medical;training,other;use cases;industries,education;farming and natural science;other;simulation;medical;training,other;use cases;industries,chatbots computer_based_training educational_institutions gender_issues mobile_learning serious_games ar_serious_games immersive_scenario_based_training innovative_game_play interactive_embodied_conversational_agents inventive_game_design lgbtq _students mobile_augmented_reality_game prevention_programs sexual_assault_bystander_intervention_training sexual_harassment sexual_violence title_ix_training_programs titleix _step_up_ amp _step_in us_college_campuses c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7820n_natural_language_processing c7830d_computer_games education farming_and_natural_science other simulation medical training,chatbots computer_based_training educational_institutions gender_issues mobile_learning serious_games,ar_serious_games immersive_scenario_based_training innovative_game_play interactive_embodied_conversational_agents inventive_game_design lgbtq _students mobile_augmented_reality_game prevention_programs sexual_assault_bystander_intervention_training sexual_harassment sexual_violence title_ix_training_programs titleix _step_up_ amp _step_in us_college_campuses,despite effort existing title ix training program u current intervention prevention program fail address problem caused sexual violence u college campus address issue designed mobile augmented reality ar game titleix step amp step encourages student become active supportive bystander innovative game play aiming improve current sexual assault bystander intervention training utilizing ar technology embodied conversational agent ecas game provides highly immersive scenario based training sexual assault bystander intervention connecting user realistic campus experience inventive game design leverage innovative technology increase awareness real world problem specifically sexual harassment targeting woman lgbtq student college campus design implemented paper inform future construction ar serious game social justice,chatbots computer_based_training educational_institutions gender_issues mobile_learning serious_games ar_serious_games immersive_scenario_based_training innovative_game_play interactive_embodied_conversational_agents inventive_game_design lgbtq _students mobile_augmented_reality_game prevention_programs sexual_assault_bystander_intervention_training sexual_harassment sexual_violence title_ix_training_programs titleix _step_up_ amp _step_in us_college_campuses c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7820n_natural_language_processing c7830d_computer_games education farming_and_natural_science other simulation medical training despite effort existing title ix training program u current intervention prevention program fail address problem caused sexual violence u college campus address issue designed mobile augmented reality ar game titleix step amp step encourages student become active supportive bystander innovative game play aiming improve current sexual assault bystander intervention training utilizing ar technology embodied conversational agent ecas game provides highly immersive scenario based training sexual assault bystander intervention connecting user realistic campus experience inventive game design leverage innovative technology increase awareness real world problem specifically sexual harassment targeting woman lgbtq student college campus design implemented paper inform future construction ar serious game social justice,despite effort existing title ix training program u current intervention prevention program fail address problem caused sexual violence u college campus address issue designed mobile augmented reality ar game titleix step amp step encourages student become active supportive bystander innovative game play aiming improve current sexual assault bystander intervention training utilizing ar technology embodied conversational agent ecas game provides highly immersive scenario based training sexual assault bystander intervention connecting user realistic campus experience inventive game design leverage innovative technology increase awareness real world problem specifically sexual harassment targeting woman lgbtq student college campus design implemented paper inform future construction ar serious game social justicechatbots computer_based_training educational_institutions gender_issues mobile_learning serious_gamesar_serious_games immersive_scenario_based_training innovative_game_play interactive_embodied_conversational_agents inventive_game_design lgbtq _students mobile_augmented_reality_game prevention_programs sexual_assault_bystander_intervention_training sexual_harassment sexual_violence title_ix_training_programs titleix _step_up_ amp _step_in us_college_campuses
114,Designing a new approach to augmented reality for early childhood self-learning capability at home.,"Riwu, M. C. H., Tolle, H., & Budi, A. S. (2022). Designing a new approach to augmented reality for early childhood self-learning capability at home. 7th International Conference on Sustainable Information Engineering and Technology 2022. https://doi.org/10.1145/3568231.3568269
",10.1145/3568231.3568269,"Augmented reality is a technology that can improve students' learning experience, motivation, and learning achievement. This technology can be used to teach concepts and materials that are abstract and difficult to understand in early childhood. In its application, a good learning process should be centered on the learner. But the challenge must be overcome to design AR media that can be used for independent learning. AR design and features must be easy to use and understand by all students with different technological knowledge backgrounds. In this study, AR learning media was successfully designed with a new, more humanist, and interactive approach to teaching symbols and concepts of numbers 1-20. Each stage of the media design process that has been carried out is described in a structured manner by combining the ADDIE (Analysis, Design, Development, Implementation, and Evaluation) and RAD (Rapid Application Development) methods. We have validated the design of media and materials with three experts each. The validation results obtained are 93.7% for the feasibility of media design and 92.1% for the feasibility of the material. These results prove that AR design by displaying avatar objects as 3D virtual friends can support early childhood to study independently at home with more fun, easy, and exciting learning atmosphere and experience.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C7810C Computer-aided instruction,ADDIE;analysis-design-development-implementation-and-evaluation;AR design;AR learning media;augmented reality;humanist approach;independent learning;interactive approach;knowledge backgrounds;learning achievement;media design process;motivation;RAD methods;rapid application development;self-learning capability;students learning experience;teaching symbols,augmented reality;computer aided instruction;human factors;teaching,2022,Conference article (CA),SIET22: 7th International Conference on Sustainable Information Engineering and Technology 2022,"(1) Riwu, M.C.H.; (1) Tolle, H.; (1) Budi, A.S.; ","(1) University of Brawijaya, Department of Informatics Engineering, Indonesia; ",ACM,-1,"[""computer aided instruction"", ""human factors"", ""teaching""]","[""computer aided instruction"", ""human factors"", ""teaching""]",computer aided instruction;human factors;teaching,human factors;education;training,end users and user experience;use cases;industries,human factors;education;training,end users and user experience;use cases;industries,computer_aided_instruction human_factors teaching addie analysis design development implementation and evaluation ar_design ar_learning_media augmented_reality humanist_approach independent_learning interactive_approach knowledge_backgrounds learning_achievement media_design_process motivation rad_methods rapid_application_development self learning_capability students_learning_experience teaching_symbols c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education training,computer_aided_instruction human_factors teaching,addie analysis design development implementation and evaluation ar_design ar_learning_media augmented_reality humanist_approach independent_learning interactive_approach knowledge_backgrounds learning_achievement media_design_process motivation rad_methods rapid_application_development self learning_capability students_learning_experience teaching_symbols,augmented reality technology improve student learning experience motivation learning achievement technology used teach concept material abstract difficult understand early childhood application good learning process centered learner challenge must overcome design ar medium used independent learning ar design feature must easy use understand student different technological knowledge background study ar learning medium successfully designed new humanist interactive approach teaching symbol concept number 1 20 stage medium design process carried described structured manner combining addie analysis design development implementation evaluation rad rapid application development method validated design medium material three expert validation result obtained 93 7 feasibility medium design 92 1 feasibility material result prove ar design displaying avatar object 3d virtual friend support early childhood study independently home fun easy exciting learning atmosphere experience,computer_aided_instruction human_factors teaching addie analysis design development implementation and evaluation ar_design ar_learning_media augmented_reality humanist_approach independent_learning interactive_approach knowledge_backgrounds learning_achievement media_design_process motivation rad_methods rapid_application_development self learning_capability students_learning_experience teaching_symbols c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education training augmented reality technology improve student learning experience motivation learning achievement technology used teach concept material abstract difficult understand early childhood application good learning process centered learner challenge must overcome design ar medium used independent learning ar design feature must easy use understand student different technological knowledge background study ar learning medium successfully designed new humanist interactive approach teaching symbol concept number 1 20 stage medium design process carried described structured manner combining addie analysis design development implementation evaluation rad rapid application development method validated design medium material three expert validation result obtained 93 7 feasibility medium design 92 1 feasibility material result prove ar design displaying avatar object 3d virtual friend support early childhood study independently home fun easy exciting learning atmosphere experience,augmented reality technology improve student learning experience motivation learning achievement technology used teach concept material abstract difficult understand early childhood application good learning process centered learner challenge must overcome design ar medium used independent learning ar design feature must easy use understand student different technological knowledge background study ar learning medium successfully designed new humanist interactive approach teaching symbol concept number 1 20 stage medium design process carried described structured manner combining addie analysis design development implementation evaluation rad rapid application development method validated design medium material three expert validation result obtained 93 7 feasibility medium design 92 1 feasibility material result prove ar design displaying avatar object 3d virtual friend support early childhood study independently home fun easy exciting learning atmosphere experiencecomputer_aided_instruction human_factors teachingaddie analysis design development implementation and evaluation ar_design ar_learning_media augmented_reality humanist_approach independent_learning interactive_approach knowledge_backgrounds learning_achievement media_design_process motivation rad_methods rapid_application_development self learning_capability students_learning_experience teaching_symbols
115,Towards Enhancing Children's Science Education using Augmented Reality and Computer Vision,"Joshi, S., Agbo, F. J., & Jormanainen, I. (2023). Towards Enhancing Children’s Science Education using Augmented Reality and Computer Vision. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125242
",10.1109/EDUCON54358.2023.10125242,"Today's technological advancements in mobile technologies and the growing number of mobile devices are extremely beneficial in the mobile learning process. This study is a work in progress that discusses the possibilities of integrating Augmented Reality (AR) and computer vision (CV) into science education which uses deep learning to detect animals in real-time and teach children to classify animals, and learn about their habitat, sound, and important facts. In this study, the Design Science Research (DSR) is used which is a pragmatic approach to creating substantial knowledge for problem-solving through the development of artifacts. The mobile application - AnimalCircle - was developed following the DSR method, and initial users' study was conducted to investigate the efficacy of the use of AR and CV in mobile learning on children's science education and if it can enhance children learning experience. Semi-structured interviews were conducted with children studying at primary level class in Kathmandu district of Nepal between the age groups of 6-12. The findings show that children are positive toward usage of AnimalCircle app in their learning process because they find it beneficial and effective in their learning. However, most children also found it difficult and complained of getting confused during their initial usage. Therefore, significant efforts are required to improve the usage of these technologies in the mobile app and to provide a child-friendly learning experience.","C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C6264 Neural nets",Augmented Reality;child-friendly learning experience;children learning;computer vision;deep learning;Design Science Research;DSR method;important facts;initial users;mobile app;mobile application - AnimalCircle;mobile devices;mobile learning process;mobile technologies;science education;technological advancements;towards enhancing children,augmented reality;computer aided instruction;computer vision;deep learning (artificial intelligence);mobile computing;mobile learning;teaching,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Joshi, S.; (1) Agbo, F.J.; (1) Jormanainen, I.; ","(1) University of Eastern Finland, School of Computing, Finland; (2) Willamette University, Computing and Data Science, Salem, OR, United States; ",IEEE,-1,"[""computer aided instruction"", ""computer vision"", ""deep learning (artificial intelligence)"", ""mobile computing"", ""mobile learning"", ""teaching""]","[""computer aided instruction"", ""computer vision"", ""deep learning (artificial intelligence)"", ""mobile computing"", ""mobile learning"", ""teaching""]",computer aided instruction;computer vision;deep learning (artificial intelligence);mobile computing;mobile learning;teaching,computer vision;education;other;liberal arts;medical;training;telecommunication;artificial intelligence,technology;other;use cases;industries,computer vision;education;other;liberal arts;medical;training;telecommunication;artificial intelligence,technology;other;use cases;industries,computer_aided_instruction computer_vision deep_learning_ artificial_intelligence mobile_computing mobile_learning teaching augmented_reality child friendly_learning_experience children_learning computer_vision deep_learning design_science_research dsr_method important_facts initial_users mobile_app mobile_application_ _animalcircle mobile_devices mobile_learning_process mobile_technologies science_education technological_advancements towards_enhancing_children c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision education other liberal_arts medical training telecommunication artificial_intelligence,computer_aided_instruction computer_vision deep_learning_ artificial_intelligence mobile_computing mobile_learning teaching,augmented_reality child friendly_learning_experience children_learning computer_vision deep_learning design_science_research dsr_method important_facts initial_users mobile_app mobile_application_ _animalcircle mobile_devices mobile_learning_process mobile_technologies science_education technological_advancements towards_enhancing_children,today technological advancement mobile technology growing number mobile device extremely beneficial mobile learning process study work progress discus possibility integrating augmented reality ar computer vision cv science education us deep learning detect animal real time teach child classify animal learn habitat sound important fact study design science research dsr used pragmatic approach creating substantial knowledge problem solving development artifact mobile application animalcircle developed following dsr method initial user study conducted investigate efficacy use ar cv mobile learning child science education enhance child learning experience semi structured interview conducted child studying primary level class kathmandu district nepal age group 6 12 finding show child positive toward usage animalcircle app learning process find beneficial effective learning however child also found difficult complained getting confused initial usage therefore significant effort required improve usage technology mobile app provide child friendly learning experience,computer_aided_instruction computer_vision deep_learning_ artificial_intelligence mobile_computing mobile_learning teaching augmented_reality child friendly_learning_experience children_learning computer_vision deep_learning design_science_research dsr_method important_facts initial_users mobile_app mobile_application_ _animalcircle mobile_devices mobile_learning_process mobile_technologies science_education technological_advancements towards_enhancing_children c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision education other liberal_arts medical training telecommunication artificial_intelligence today technological advancement mobile technology growing number mobile device extremely beneficial mobile learning process study work progress discus possibility integrating augmented reality ar computer vision cv science education us deep learning detect animal real time teach child classify animal learn habitat sound important fact study design science research dsr used pragmatic approach creating substantial knowledge problem solving development artifact mobile application animalcircle developed following dsr method initial user study conducted investigate efficacy use ar cv mobile learning child science education enhance child learning experience semi structured interview conducted child studying primary level class kathmandu district nepal age group 6 12 finding show child positive toward usage animalcircle app learning process find beneficial effective learning however child also found difficult complained getting confused initial usage therefore significant effort required improve usage technology mobile app provide child friendly learning experience,today technological advancement mobile technology growing number mobile device extremely beneficial mobile learning process study work progress discus possibility integrating augmented reality ar computer vision cv science education us deep learning detect animal real time teach child classify animal learn habitat sound important fact study design science research dsr used pragmatic approach creating substantial knowledge problem solving development artifact mobile application animalcircle developed following dsr method initial user study conducted investigate efficacy use ar cv mobile learning child science education enhance child learning experience semi structured interview conducted child studying primary level class kathmandu district nepal age group 6 12 finding show child positive toward usage animalcircle app learning process find beneficial effective learning however child also found difficult complained getting confused initial usage therefore significant effort required improve usage technology mobile app provide child friendly learning experiencecomputer_aided_instruction computer_vision deep_learning_ artificial_intelligence mobile_computing mobile_learning teachingaugmented_reality child friendly_learning_experience children_learning computer_vision deep_learning design_science_research dsr_method important_facts initial_users mobile_app mobile_application_ _animalcircle mobile_devices mobile_learning_process mobile_technologies science_education technological_advancements towards_enhancing_children
116,Augmented Reality and Machine Learning Incorporation Using YOLOv3 and ARKit,"Le, H., Nguyen, M., Yan, W. Q., & Nguyen, H. (2021). Augmented Reality and Machine Learning Incorporation Using YOLOv3 and ARKit. Applied Sciences, 11(13), 6006. https://doi.org/10.3390/app11136006
",10.3390/app11136006,"Augmented reality is one of the fastest growing fields, receiving increased funding for the last few years as people realise the potential benefits of rendering virtual information in the real world. Most of today's augmented reality marker-based applications use local feature detection and tracking techniques. The disadvantage of applying these techniques is that the markers must be modified to match the unique classified algorithms or they suffer from low detection accuracy. Machine learning is an ideal solution to overcome the current drawbacks of image processing in augmented reality applications. However, traditional data annotation requires extensive time and labour, as it is usually done manually. This study incorporates machine learning to detect and track augmented reality marker targets in an application using deep neural networks. We firstly implement the auto-generated dataset tool, which is used for the machine learning dataset preparation. The final iOS prototype application incorporates object detection, object tracking and augmented reality. The machine learning model is trained to recognise the differences between targets using one of YOLO's most well-known object detection methods. The final product makes use of a valuable toolkit for developing augmented reality applications called ARKit.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",augmented reality applications;augmented reality marker targets;augmented reality marker-based applications;fastest growing fields;final iOS prototype application;local feature detection;low detection accuracy;machine learning dataset preparation;machine learning incorporation;machine learning model;object detection methods;tracking techniques,augmented reality;feature extraction;learning (artificial intelligence);neural nets;object detection;object tracking,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Le, H.; (1) Nguyen, M.; (1) Yan, W.Q.; (1) Nguyen, H.; ","(1) Auckland University of Technology, School of Computer and Mathematical Sciences, New Zealand; ",MDPI,-1,"[""feature extraction"", ""learning algorithms"", ""neural networks"", ""object detection"", ""object tracking""]","[""feature extraction"", ""learning algorithms"", ""neural networks"", ""object detection"", ""object tracking""]",feature extraction;learning algorithms;neural networks;object detection;object tracking,medical;computer vision;artificial intelligence;chemical,technology;industries,medical;computer vision;artificial intelligence;chemical,technology;industries,feature_extraction learning_algorithms neural_networks object_detection object_tracking augmented_reality_applications augmented_reality_marker_targets augmented_reality_marker based_applications fastest_growing_fields final_ios_prototype_application local_feature_detection low_detection_accuracy machine_learning_dataset_preparation machine_learning_incorporation machine_learning_model object_detection_methods tracking_techniques b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality medical computer_vision artificial_intelligence chemical,feature_extraction learning_algorithms neural_networks object_detection object_tracking,augmented_reality_applications augmented_reality_marker_targets augmented_reality_marker based_applications fastest_growing_fields final_ios_prototype_application local_feature_detection low_detection_accuracy machine_learning_dataset_preparation machine_learning_incorporation machine_learning_model object_detection_methods tracking_techniques,augmented reality one fastest growing field receiving increased funding last year people realise potential benefit rendering virtual information real world today augmented reality marker based application use local feature detection tracking technique disadvantage applying technique marker must modified match unique classified algorithm suffer low detection accuracy machine learning ideal solution overcome current drawback image processing augmented reality application however traditional data annotation requires extensive time labour usually done manually study incorporates machine learning detect track augmented reality marker target application using deep neural network firstly implement auto generated dataset tool used machine learning dataset preparation final io prototype application incorporates object detection object tracking augmented reality machine learning model trained recognise difference target using one yolo well known object detection method final product make use valuable toolkit developing augmented reality application called arkit,feature_extraction learning_algorithms neural_networks object_detection object_tracking augmented_reality_applications augmented_reality_marker_targets augmented_reality_marker based_applications fastest_growing_fields final_ios_prototype_application local_feature_detection low_detection_accuracy machine_learning_dataset_preparation machine_learning_incorporation machine_learning_model object_detection_methods tracking_techniques b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality medical computer_vision artificial_intelligence chemical augmented reality one fastest growing field receiving increased funding last year people realise potential benefit rendering virtual information real world today augmented reality marker based application use local feature detection tracking technique disadvantage applying technique marker must modified match unique classified algorithm suffer low detection accuracy machine learning ideal solution overcome current drawback image processing augmented reality application however traditional data annotation requires extensive time labour usually done manually study incorporates machine learning detect track augmented reality marker target application using deep neural network firstly implement auto generated dataset tool used machine learning dataset preparation final io prototype application incorporates object detection object tracking augmented reality machine learning model trained recognise difference target using one yolo well known object detection method final product make use valuable toolkit developing augmented reality application called arkit,augmented reality one fastest growing field receiving increased funding last year people realise potential benefit rendering virtual information real world today augmented reality marker based application use local feature detection tracking technique disadvantage applying technique marker must modified match unique classified algorithm suffer low detection accuracy machine learning ideal solution overcome current drawback image processing augmented reality application however traditional data annotation requires extensive time labour usually done manually study incorporates machine learning detect track augmented reality marker target application using deep neural network firstly implement auto generated dataset tool used machine learning dataset preparation final io prototype application incorporates object detection object tracking augmented reality machine learning model trained recognise difference target using one yolo well known object detection method final product make use valuable toolkit developing augmented reality application called arkitfeature_extraction learning_algorithms neural_networks object_detection object_trackingaugmented_reality_applications augmented_reality_marker_targets augmented_reality_marker based_applications fastest_growing_fields final_ios_prototype_application local_feature_detection low_detection_accuracy machine_learning_dataset_preparation machine_learning_incorporation machine_learning_model object_detection_methods tracking_techniques
117,Dementia Eyes: Co-Design and Evaluation of a Dementia Education Augmented Reality Experience for Medical Workers,"Shen, X., Pai, Y. S., Kiuchi, D., Bao, K., Aoki, T., Meguro, H., Oishi, K., Wang, Z., Wakisaka, S., & Minamizawa, K. (2023). Dementia Eyes: Co-Design and Evaluation of a Dementia Education Augmented Reality Experience for Medical Workers. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581009
",10.1145/3544548.3581009,"Dementia describes a syndrome of cognitive degeneration, and Behavioural and Psychological Symptoms of Dementia (BPSD) is the non-cognitive symptom. BPSD can be improved by care services. To aid better care service, we explore the potential of using Augmented Reality (AR) to support dementia education for medical workers in three steps: (1) We explore medical workers' perspective on dementia care lived experience and XR, (2) we co-design an educational experience containing an AR-based application and a 5-min activity with medical workers, (3) we evaluate the effectiveness of the system through a mixed method study. Our result shows that the AR experience successfully touches participants, and motivates them to reflect on the provision of care service. On this basis, we discuss the elements and challenges of designing XR-enabled dementia education for users unfamiliar with novel technology, and the potential of using XR in clinical education.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C7330 Biology and medical computing;C7810 Social and behavioural sciences computing,AR experience;behavioural and psychological symptoms of dementia;BPSD;care service;clinical education;cognitive degeneration;dementia care;dementia education augmented reality experience;dementia eyes;educational experience;medical workers;mixed method study;noncognitive symptom;system effectiveness evaluation;XR-enabled dementia education,augmented reality;biomedical education;cognition;computer aided instruction;continuing professional development;health care;human factors;medical computing;medical disorders;personnel;psychology,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Shen, X.; (1) Pai, Y.S.; (2) Kiuchi, D.; (2) Bao, K.; (2) Aoki, T.; (2) Meguro, H.; (2) Oishi, K.; (1) Wang, Z.; (1) Wakisaka, S.; (1) Minamizawa, K.; ","(1) Keio Gijuku Daigaku Daigakuin Media Design Kenkyuka, Japan; (2) Kabushiki Kaisha Mediva, Japan; ",ACM,-1,"[""biomedical education"", ""cognition"", ""computer aided instruction"", ""continuing professional development"", ""health care"", ""human factors"", ""medical computing"", ""medical disorders"", ""personnel"", ""psychology""]","[""biomedical education"", ""cognition"", ""computer aided instruction"", ""continuing professional development"", ""health care"", ""human factors"", ""medical computing"", ""medical disorders"", ""personnel"", ""psychology""]",biomedical education;cognition;computer aided instruction;continuing professional development;health care;human factors;medical computing;medical disorders;personnel;psychology,education;medical;training;human factors;human resources,end users and user experience;business;use cases;industries,education;medical;training;human factors;human resources,end users and user experience;business;use cases;industries,biomedical_education cognition computer_aided_instruction continuing_professional_development health_care human_factors medical_computing medical_disorders personnel psychology ar_experience behavioural_and_psychological_symptoms_of_dementia bpsd care_service clinical_education cognitive_degeneration dementia_care dementia_education_augmented_reality_experience dementia_eyes educational_experience medical_workers mixed_method_study noncognitive_symptom system_effectiveness_evaluation xr enabled_dementia_education c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7330_biology_and_medical_computing c7810_social_and_behavioural_sciences_computing education medical training human_factors human_resources,biomedical_education cognition computer_aided_instruction continuing_professional_development health_care human_factors medical_computing medical_disorders personnel psychology,ar_experience behavioural_and_psychological_symptoms_of_dementia bpsd care_service clinical_education cognitive_degeneration dementia_care dementia_education_augmented_reality_experience dementia_eyes educational_experience medical_workers mixed_method_study noncognitive_symptom system_effectiveness_evaluation xr enabled_dementia_education,dementia describes syndrome cognitive degeneration behavioural psychological symptom dementia bpsd non cognitive symptom bpsd improved care service aid better care service explore potential using augmented reality ar support dementia education medical worker three step 1 explore medical worker perspective dementia care lived experience xr 2 co design educational experience containing ar based application 5 min activity medical worker 3 evaluate effectiveness system mixed method study result show ar experience successfully touch participant motivates reflect provision care service basis discus element challenge designing xr enabled dementia education user unfamiliar novel technology potential using xr clinical education,biomedical_education cognition computer_aided_instruction continuing_professional_development health_care human_factors medical_computing medical_disorders personnel psychology ar_experience behavioural_and_psychological_symptoms_of_dementia bpsd care_service clinical_education cognitive_degeneration dementia_care dementia_education_augmented_reality_experience dementia_eyes educational_experience medical_workers mixed_method_study noncognitive_symptom system_effectiveness_evaluation xr enabled_dementia_education c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7330_biology_and_medical_computing c7810_social_and_behavioural_sciences_computing education medical training human_factors human_resources dementia describes syndrome cognitive degeneration behavioural psychological symptom dementia bpsd non cognitive symptom bpsd improved care service aid better care service explore potential using augmented reality ar support dementia education medical worker three step 1 explore medical worker perspective dementia care lived experience xr 2 co design educational experience containing ar based application 5 min activity medical worker 3 evaluate effectiveness system mixed method study result show ar experience successfully touch participant motivates reflect provision care service basis discus element challenge designing xr enabled dementia education user unfamiliar novel technology potential using xr clinical education,dementia describes syndrome cognitive degeneration behavioural psychological symptom dementia bpsd non cognitive symptom bpsd improved care service aid better care service explore potential using augmented reality ar support dementia education medical worker three step 1 explore medical worker perspective dementia care lived experience xr 2 co design educational experience containing ar based application 5 min activity medical worker 3 evaluate effectiveness system mixed method study result show ar experience successfully touch participant motivates reflect provision care service basis discus element challenge designing xr enabled dementia education user unfamiliar novel technology potential using xr clinical educationbiomedical_education cognition computer_aided_instruction continuing_professional_development health_care human_factors medical_computing medical_disorders personnel psychologyar_experience behavioural_and_psychological_symptoms_of_dementia bpsd care_service clinical_education cognitive_degeneration dementia_care dementia_education_augmented_reality_experience dementia_eyes educational_experience medical_workers mixed_method_study noncognitive_symptom system_effectiveness_evaluation xr enabled_dementia_education
118,Usability Evaluation of an Augmented Reality Sensorimotor Assessment Tool for Astronauts,"Weiss, H., & Stirling, L. (2023). Usability Evaluation of an Augmented Reality Sensorimotor Assessment Tool for Astronauts. 2023 IEEE Aerospace Conference. https://doi.org/10.1109/aero55745.2023.10115780
",10.1109/AERO55745.2023.10115780,"As next-generation space exploration missions require increased autonomy from astronaut crews, real-time diagnostics of astronaut health and performance are essential for mission operations, especially for determining Extravehicular Activity (EVA) readiness. Due to the disruption of the sensorimotor and neurovestibular systems in microgravity, astronauts exhibit significant impairments in their functional abilities that require distinct adaptation timelines. Physiological decrements can significantly affect operations during and shortly after gravity transitions, when performance risks are greatest. An Augmented Reality (AR) system may be a viable solution to the resource, volumetric, and time constraints of space operations by allowing holographic visual cueing to replace physical objects used in traditional Earth-based assessments. This paper presents the development and preliminary usability testing of a non-intrusive system that employs Augmented Reality and inertial measurement units (IMU) to evaluate sensorimotor and neurovestibular performance throughout mission timelines. The Augmented Reality Operations Readiness Assessment (AURORA) includes distinct assessments for static, dynamic, and operational balance and hand-eye coordination. During the AR development process of AURORA, human-in-the-loop usability experiments were conducted with first-time users (n=15) to gather feedback regarding the user interactions within the application. Usability questions were modeled after established usability surveys (e.g., SUS, NASA TLX) to probe for perceived ease of use, system capabilities, user interface readability, comfort, future use intention, and overall reactions to the system affordances. Thirteen participants reported that the system effectively described assessment requirements via animations and task instructions so they could self-administer assessments. Twelve participants reported their overall experience using the system as positive and rated the process of learning the hand gestures and operating the application as moderately and extremely easy. Questionnaire results indicate that the system has very strong potential for supporting self-administered physiological assessments while maintaining relatively low levels of mental and physical effort. Throughout the study several usability issues were discovered. Four participants struggled to properly execute the trained hand gestures and had issues with depth perception thereby limiting their ability to effectively interact with the system. Explorations into AR design and button interactions will be considered to support users who struggled with system interactions. Further training and instructional protocols will also be implemented to support users. Findings from the usability testing support recommendations for future designers of AR systems and the creation of a full beta version to support validation testing of the derived performance metrics. The research also lays the foundation for countermeasures development and AR training to mitigate impairments to astronauts' functional abilities that may impact operations.",B6135E Image recognition;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7460 Aerospace engineering computing,AR development process;AR systems;assessment requirements;astronaut crews;astronaut health;astronauts;augmented reality operations readiness assessment;augmented reality sensorimotor assessment tool;AURORA;derived performance metrics;distinct adaptation timelines;distinct assessments;Earth-based assessments;extravehicular activity readiness;first-time users;functional abilities;hand-eye coordination;holographic visual cueing;human-in-the-loop usability experiments;inertial measurement units;mission operations;mission timelines;neurovestibular performance;next-generation space exploration missions;nonintrusive system;operational balance;performance risks;physiological assessments;physiological decrements;preliminary usability testing;real-time diagnostics;self-administer assessments;space operations;static balance;system affordances;system capabilities;system interactions;time constraints;trained hand gestures;usability evaluation;usability questions;usability surveys;user interactions;user interface readability,aerospace computing;augmented reality;data visualisation;gesture recognition;human computer interaction;human factors;neurophysiology;space research,2023,Conference article (CA),2023 IEEE Aerospace Conference,"(1) Weiss, H.; (1) Stirling, L.; ","(1) University of Michigan, Department of Industrial and Operations Engineering, Ann Arbor, MI 48109, United States; ",IEEE,-1,"[""aerospace computing"", ""data visualization"", ""gesture recognition"", ""human computer interaction"", ""human factors"", ""neurophysiology"", ""space research""]","[""aerospace computing"", ""data visualization"", ""gesture recognition"", ""human computer interaction"", ""human factors"", ""neurophysiology"", ""space research""]",aerospace computing;data visualization;gesture recognition;human computer interaction;human factors;neurophysiology;space research,education;aviation and aerospace;input;medical;human factors;data;human-computer interaction,technology;end users and user experience;industries,education;aviation and aerospace;input;medical;human factors;data;human-computer interaction,technology;end users and user experience;industries,aerospace_computing data_visualization gesture_recognition human_computer_interaction human_factors neurophysiology space_research ar_development_process ar_systems assessment_requirements astronaut_crews astronaut_health astronauts augmented_reality_operations_readiness_assessment augmented_reality_sensorimotor_assessment_tool aurora derived_performance_metrics distinct_adaptation_timelines distinct_assessments earth based_assessments extravehicular_activity_readiness first time_users functional_abilities hand eye_coordination holographic_visual_cueing human in the loop_usability_experiments inertial_measurement_units mission_operations mission_timelines neurovestibular_performance next generation_space_exploration_missions nonintrusive_system operational_balance performance_risks physiological_assessments physiological_decrements preliminary_usability_testing real time_diagnostics self administer_assessments space_operations static_balance system_affordances system_capabilities system_interactions time_constraints trained_hand_gestures usability_evaluation usability_questions usability_surveys user_interactions user_interface_readability b6135e_image_recognition c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7460_aerospace_engineering_computing education aviation_and_aerospace input medical human_factors data human computer_interaction,aerospace_computing data_visualization gesture_recognition human_computer_interaction human_factors neurophysiology space_research,ar_development_process ar_systems assessment_requirements astronaut_crews astronaut_health astronauts augmented_reality_operations_readiness_assessment augmented_reality_sensorimotor_assessment_tool aurora derived_performance_metrics distinct_adaptation_timelines distinct_assessments earth based_assessments extravehicular_activity_readiness first time_users functional_abilities hand eye_coordination holographic_visual_cueing human in the loop_usability_experiments inertial_measurement_units mission_operations mission_timelines neurovestibular_performance next generation_space_exploration_missions nonintrusive_system operational_balance performance_risks physiological_assessments physiological_decrements preliminary_usability_testing real time_diagnostics self administer_assessments space_operations static_balance system_affordances system_capabilities system_interactions time_constraints trained_hand_gestures usability_evaluation usability_questions usability_surveys user_interactions user_interface_readability,next generation space exploration mission require increased autonomy astronaut crew real time diagnostics astronaut health performance essential mission operation especially determining extravehicular activity eva readiness due disruption sensorimotor neurovestibular system microgravity astronaut exhibit significant impairment functional ability require distinct adaptation timeline physiological decrement significantly affect operation shortly gravity transition performance risk greatest augmented reality ar system may viable solution resource volumetric time constraint space operation allowing holographic visual cueing replace physical object used traditional earth based assessment paper present development preliminary usability testing non intrusive system employ augmented reality inertial measurement unit imu evaluate sensorimotor neurovestibular performance throughout mission timeline augmented reality operation readiness assessment aurora includes distinct assessment static dynamic operational balance hand eye coordination ar development process aurora human loop usability experiment conducted first time user n 15 gather feedback regarding user interaction within application usability question modeled established usability survey e g sus nasa tlx probe perceived ease use system capability user interface readability comfort future use intention overall reaction system affordances thirteen participant reported system effectively described assessment requirement via animation task instruction could self administer assessment twelve participant reported overall experience using system positive rated process learning hand gesture operating application moderately extremely easy questionnaire result indicate system strong potential supporting self administered physiological assessment maintaining relatively low level mental physical effort throughout study several usability issue discovered four participant struggled properly execute trained hand gesture issue depth perception thereby limiting ability effectively interact system exploration ar design button interaction considered support user struggled system interaction training instructional protocol also implemented support user finding usability testing support recommendation future designer ar system creation full beta version support validation testing derived performance metric research also lay foundation countermeasure development ar training mitigate impairment astronaut functional ability may impact operation,aerospace_computing data_visualization gesture_recognition human_computer_interaction human_factors neurophysiology space_research ar_development_process ar_systems assessment_requirements astronaut_crews astronaut_health astronauts augmented_reality_operations_readiness_assessment augmented_reality_sensorimotor_assessment_tool aurora derived_performance_metrics distinct_adaptation_timelines distinct_assessments earth based_assessments extravehicular_activity_readiness first time_users functional_abilities hand eye_coordination holographic_visual_cueing human in the loop_usability_experiments inertial_measurement_units mission_operations mission_timelines neurovestibular_performance next generation_space_exploration_missions nonintrusive_system operational_balance performance_risks physiological_assessments physiological_decrements preliminary_usability_testing real time_diagnostics self administer_assessments space_operations static_balance system_affordances system_capabilities system_interactions time_constraints trained_hand_gestures usability_evaluation usability_questions usability_surveys user_interactions user_interface_readability b6135e_image_recognition c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7460_aerospace_engineering_computing education aviation_and_aerospace input medical human_factors data human computer_interaction next generation space exploration mission require increased autonomy astronaut crew real time diagnostics astronaut health performance essential mission operation especially determining extravehicular activity eva readiness due disruption sensorimotor neurovestibular system microgravity astronaut exhibit significant impairment functional ability require distinct adaptation timeline physiological decrement significantly affect operation shortly gravity transition performance risk greatest augmented reality ar system may viable solution resource volumetric time constraint space operation allowing holographic visual cueing replace physical object used traditional earth based assessment paper present development preliminary usability testing non intrusive system employ augmented reality inertial measurement unit imu evaluate sensorimotor neurovestibular performance throughout mission timeline augmented reality operation readiness assessment aurora includes distinct assessment static dynamic operational balance hand eye coordination ar development process aurora human loop usability experiment conducted first time user n 15 gather feedback regarding user interaction within application usability question modeled established usability survey e g sus nasa tlx probe perceived ease use system capability user interface readability comfort future use intention overall reaction system affordances thirteen participant reported system effectively described assessment requirement via animation task instruction could self administer assessment twelve participant reported overall experience using system positive rated process learning hand gesture operating application moderately extremely easy questionnaire result indicate system strong potential supporting self administered physiological assessment maintaining relatively low level mental physical effort throughout study several usability issue discovered four participant struggled properly execute trained hand gesture issue depth perception thereby limiting ability effectively interact system exploration ar design button interaction considered support user struggled system interaction training instructional protocol also implemented support user finding usability testing support recommendation future designer ar system creation full beta version support validation testing derived performance metric research also lay foundation countermeasure development ar training mitigate impairment astronaut functional ability may impact operation,next generation space exploration mission require increased autonomy astronaut crew real time diagnostics astronaut health performance essential mission operation especially determining extravehicular activity eva readiness due disruption sensorimotor neurovestibular system microgravity astronaut exhibit significant impairment functional ability require distinct adaptation timeline physiological decrement significantly affect operation shortly gravity transition performance risk greatest augmented reality ar system may viable solution resource volumetric time constraint space operation allowing holographic visual cueing replace physical object used traditional earth based assessment paper present development preliminary usability testing non intrusive system employ augmented reality inertial measurement unit imu evaluate sensorimotor neurovestibular performance throughout mission timeline augmented reality operation readiness assessment aurora includes distinct assessment static dynamic operational balance hand eye coordination ar development process aurora human loop usability experiment conducted first time user n 15 gather feedback regarding user interaction within application usability question modeled established usability survey e g sus nasa tlx probe perceived ease use system capability user interface readability comfort future use intention overall reaction system affordances thirteen participant reported system effectively described assessment requirement via animation task instruction could self administer assessment twelve participant reported overall experience using system positive rated process learning hand gesture operating application moderately extremely easy questionnaire result indicate system strong potential supporting self administered physiological assessment maintaining relatively low level mental physical effort throughout study several usability issue discovered four participant struggled properly execute trained hand gesture issue depth perception thereby limiting ability effectively interact system exploration ar design button interaction considered support user struggled system interaction training instructional protocol also implemented support user finding usability testing support recommendation future designer ar system creation full beta version support validation testing derived performance metric research also lay foundation countermeasure development ar training mitigate impairment astronaut functional ability may impact operationaerospace_computing data_visualization gesture_recognition human_computer_interaction human_factors neurophysiology space_researchar_development_process ar_systems assessment_requirements astronaut_crews astronaut_health astronauts augmented_reality_operations_readiness_assessment augmented_reality_sensorimotor_assessment_tool aurora derived_performance_metrics distinct_adaptation_timelines distinct_assessments earth based_assessments extravehicular_activity_readiness first time_users functional_abilities hand eye_coordination holographic_visual_cueing human in the loop_usability_experiments inertial_measurement_units mission_operations mission_timelines neurovestibular_performance next generation_space_exploration_missions nonintrusive_system operational_balance performance_risks physiological_assessments physiological_decrements preliminary_usability_testing real time_diagnostics self administer_assessments space_operations static_balance system_affordances system_capabilities system_interactions time_constraints trained_hand_gestures usability_evaluation usability_questions usability_surveys user_interactions user_interface_readability
119,Augmented reality and image processing solutions for sport events and training : principles and practice,"Yosra, M., Lotfi, M., Najeh, L. M., Imed, J., & Tahar, B. (2022). Augmented reality and image processing solutions for sport events and training : principles and practice. 2022 IEEE Information Technologies &amp; Smart Industrial Systems (ITSIS). https://doi.org/10.1109/itsis56166.2022.10118428
",10.1109/ITSIS56166.2022.10118428,"Emergence of new information technologies (NTIC), cameras and video cameras have become ubiquitous. Image processing algorithms and applications are used in many fields, particularly in sports. This is the context of our article. In the first section, we will present the interest of using these applications for sports competitions. In the second section, the identification of players experienced in various applications using a tracking camera during sports competitions will be described. In the third section, a real-time distributed solution that we have proposed allowing to automatically building models of the actors followed thanks to its capacity to support the probabilistic fusion of various sources of information and to structure the incoming perceptions will be described. Finally, this article will end with the description of a system solution that we have proposed and which has been tested with real images.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",augmented reality;image processing algorithms;image processing solutions;NTIC;real-time distributed solution;sport events;sports competitions;system solution;tracking camera;video cameras,augmented reality;cameras;image processing;sport;video cameras,2022,Conference article (CA),2022 IEEE Information Technologies &amp; Smart Industrial Systems (ITSIS),"(1) Yosra, M.; (2) Lotfi, M.; (3) Najeh, L.M.; (2) Imed, J.; (2) Tahar, B.; ","(1) ESPRIT School of Business, Tunisia; (2) University of Tunis, National Superior School of Engineering, Tunisia; (3) University of Carthage, National Engineering School of Carthage, Tunisia; ",IEEE,-1,"[""cameras"", ""image processing"", ""sports"", ""video cameras""]","[""cameras"", ""image processing"", ""sports"", ""video cameras""]",cameras;image processing;sports;video cameras,computer vision;input;cultural heritage;data;video,technology;industries,computer vision;input;cultural heritage;data;video,technology;industries,cameras image_processing sports video_cameras augmented_reality image_processing_algorithms image_processing_solutions ntic real time_distributed_solution sport_events sports_competitions system_solution tracking_camera video_cameras b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input cultural_heritage data video,cameras image_processing sports video_cameras,augmented_reality image_processing_algorithms image_processing_solutions ntic real time_distributed_solution sport_events sports_competitions system_solution tracking_camera video_cameras,emergence new information technology ntic camera video camera become ubiquitous image processing algorithm application used many field particularly sport context article first section present interest using application sport competition second section identification player experienced various application using tracking camera sport competition described third section real time distributed solution proposed allowing automatically building model actor followed thanks capacity support probabilistic fusion various source information structure incoming perception described finally article end description system solution proposed tested real image,cameras image_processing sports video_cameras augmented_reality image_processing_algorithms image_processing_solutions ntic real time_distributed_solution sport_events sports_competitions system_solution tracking_camera video_cameras b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input cultural_heritage data video emergence new information technology ntic camera video camera become ubiquitous image processing algorithm application used many field particularly sport context article first section present interest using application sport competition second section identification player experienced various application using tracking camera sport competition described third section real time distributed solution proposed allowing automatically building model actor followed thanks capacity support probabilistic fusion various source information structure incoming perception described finally article end description system solution proposed tested real image,emergence new information technology ntic camera video camera become ubiquitous image processing algorithm application used many field particularly sport context article first section present interest using application sport competition second section identification player experienced various application using tracking camera sport competition described third section real time distributed solution proposed allowing automatically building model actor followed thanks capacity support probabilistic fusion various source information structure incoming perception described finally article end description system solution proposed tested real imagecameras image_processing sports video_camerasaugmented_reality image_processing_algorithms image_processing_solutions ntic real time_distributed_solution sport_events sports_competitions system_solution tracking_camera video_cameras
120,LiDAR-Based Augmented Reality for the Development of Test Scenarios on Safety for Autonomous Operation of a Shunting Locomotive,"Kohlisch, N., Koch, P., & May, S. (2023). LiDAR-Based Augmented Reality for the Development of Test Scenarios on Safety for Autonomous Operation of a Shunting Locomotive. 2023 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC). https://doi.org/10.1109/icarsc58346.2023.10129540
",10.1109/ICARSC58346.2023.10129540,"As public interest in autonomous driving systems grows, safety is becoming a critical issue. Extensive testing is therefore required before these systems can be deployed in real-world traffic. Simulation-based testing has proven to be a valuable tool for evaluating autonomous systems, but there remains a gap between simulation and real-world testing. A system may be well tested in simulation, but in real-world testing it may encounter sudden events that result in unpredictable behavior, and equipment may be damaged in the event of a malfunction. This paper describes a novel augmentation interface for Light Detection And Ranging (LiDAR) sensor data that aims to bridge this gap. The interface is designed to generate realistic test scenarios on live data streams, making it ideal for investigating special and borderline cases. The interface has been developed for the Robot Operating System (ROS) using the Point Cloud Library and is intended to be used for testing an autonomous shunting locomotive. With this interface, a data stream from a 3D LiDAR can be augmented with any given object represented by a point cloud, allowing for the use of data from both simulation and real-world environments.",B6320C Optical radar;C3390C Mobile robots;C6110 Systems analysis and programming;C6130V Virtual reality;C7420 Control engineering computing;C7445 Traffic engineering computing,3D LiDAR;autonomous driving systems;autonomous operation;autonomous shunting locomotive;autonomous systems;extensive testing;LiDAR-based augmented reality;live data streams;novel augmentation interface;public interest;Ranging sensor data;real-world environments;real-world testing;real-world traffic;realistic test scenarios;Robot Operating System;simulation-based testing;sudden events,augmented reality;mobile robots;optical radar;robot programming,2023,Conference article (CA),2023 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),"(1) Kohlisch, N.; (1) Koch, P.; (1) May, S.; ","(1) Nuremberg Institute of Technology Georg-Simon-Ohm, Faculty for Electrical Engineering, Germany; ",IEEE,-1,"[""mobile robots"", ""optical radar"", ""robot programming""]","[""mobile robots"", ""optical radar"", ""robot programming""]",mobile robots;optical radar;robot programming,geospatial;optics;developers;robotics,technology;displays,geospatial;optics;developers;robotics,technology;displays,mobile_robots optical_radar robot_programming 3d_lidar autonomous_driving_systems autonomous_operation autonomous_shunting_locomotive autonomous_systems extensive_testing lidar based_augmented_reality live_data_streams novel_augmentation_interface public_interest ranging_sensor_data real world_environments real world_testing real world_traffic realistic_test_scenarios robot_operating_system simulation based_testing sudden_events b6320c_optical_radar c3390c_mobile_robots c6110_systems_analysis_and_programming c6130v_virtual_reality c7420_control_engineering_computing c7445_traffic_engineering_computing geospatial optics developers robotics,mobile_robots optical_radar robot_programming,3d_lidar autonomous_driving_systems autonomous_operation autonomous_shunting_locomotive autonomous_systems extensive_testing lidar based_augmented_reality live_data_streams novel_augmentation_interface public_interest ranging_sensor_data real world_environments real world_testing real world_traffic realistic_test_scenarios robot_operating_system simulation based_testing sudden_events,public interest autonomous driving system grows safety becoming critical issue extensive testing therefore required system deployed real world traffic simulation based testing proven valuable tool evaluating autonomous system remains gap simulation real world testing system may well tested simulation real world testing may encounter sudden event result unpredictable behavior equipment may damaged event malfunction paper describes novel augmentation interface light detection ranging lidar sensor data aim bridge gap interface designed generate realistic test scenario live data stream making ideal investigating special borderline case interface developed robot operating system ro using point cloud library intended used testing autonomous shunting locomotive interface data stream 3d lidar augmented given object represented point cloud allowing use data simulation real world environment,mobile_robots optical_radar robot_programming 3d_lidar autonomous_driving_systems autonomous_operation autonomous_shunting_locomotive autonomous_systems extensive_testing lidar based_augmented_reality live_data_streams novel_augmentation_interface public_interest ranging_sensor_data real world_environments real world_testing real world_traffic realistic_test_scenarios robot_operating_system simulation based_testing sudden_events b6320c_optical_radar c3390c_mobile_robots c6110_systems_analysis_and_programming c6130v_virtual_reality c7420_control_engineering_computing c7445_traffic_engineering_computing geospatial optics developers robotics public interest autonomous driving system grows safety becoming critical issue extensive testing therefore required system deployed real world traffic simulation based testing proven valuable tool evaluating autonomous system remains gap simulation real world testing system may well tested simulation real world testing may encounter sudden event result unpredictable behavior equipment may damaged event malfunction paper describes novel augmentation interface light detection ranging lidar sensor data aim bridge gap interface designed generate realistic test scenario live data stream making ideal investigating special borderline case interface developed robot operating system ro using point cloud library intended used testing autonomous shunting locomotive interface data stream 3d lidar augmented given object represented point cloud allowing use data simulation real world environment,public interest autonomous driving system grows safety becoming critical issue extensive testing therefore required system deployed real world traffic simulation based testing proven valuable tool evaluating autonomous system remains gap simulation real world testing system may well tested simulation real world testing may encounter sudden event result unpredictable behavior equipment may damaged event malfunction paper describes novel augmentation interface light detection ranging lidar sensor data aim bridge gap interface designed generate realistic test scenario live data stream making ideal investigating special borderline case interface developed robot operating system ro using point cloud library intended used testing autonomous shunting locomotive interface data stream 3d lidar augmented given object represented point cloud allowing use data simulation real world environmentmobile_robots optical_radar robot_programming3d_lidar autonomous_driving_systems autonomous_operation autonomous_shunting_locomotive autonomous_systems extensive_testing lidar based_augmented_reality live_data_streams novel_augmentation_interface public_interest ranging_sensor_data real world_environments real world_testing real world_traffic realistic_test_scenarios robot_operating_system simulation based_testing sudden_events
121,SOCRAR: Semantic OCR through Augmented Reality,"Strecker, J., García, K., Bektaş, K., Mayer, S., & Ramanathan, G. (2022). SOCRAR: Semantic OCR through Augmented Reality. Proceedings of the 12th International Conference on the Internet of Things. https://doi.org/10.1145/3567445.3567453
",10.1145/3567445.3567453,"To enable people to interact more efficiently with virtual and physical services in their surroundings, it would be beneficial if information could more fluently be passed across digital and non-digital spaces. To this end, we propose to combine semantic technologies with Optical Character Recognition on an Augmented Reality (AR) interface to enable the semantic integration of (written) information located in our everyday environments with Internet of Things devices. We hence present SOCRAR, a system that is able to detect written information from a user's physical environment while contextualizing this data through a semantic backend. The SOCRAR system enables in-band semantic translation on an AR interface, permits semantic filtering and selection of appropriate device interfaces, and provides cognitive offloading by enabling users to store information for later use. We demonstrate the feasibility of SOCRAR through the implementation of three concrete scenarios.","B6135E Image recognition;C5260B Computer vision and image processing techniques;C5620D Internet of Things;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7210N Information networks",appropriate device interfaces;AR interface;Augmented Reality interface;everyday environments;in-band semantic translation;nondigital spaces;Optical Character Recognition;physical services;semantic backend;semantic filtering;semantic integration;semantic OCR;semantic technologies;SOCRAR system;user;virtual services;written information,augmented reality;cognition;data visualisation;Internet of Things;optical character recognition,2022,Conference article (CA),IoT 2022: Proceedings of the 12th International Conference on the Internet of Things,"(1) Strecker, J.; (1) Garci&#769;a, K.; (1) Bektas&#807;, K.; (1) Mayer, S.; (1) Ramanathan, G.; ","(1) University of St. Gallen, Switzerland; ",ACM,-1,"[""cognition"", ""data visualization"", ""internet of things"", ""optical character recognition""]","[""cognition"", ""data visualization"", ""internet of things"", ""optical character recognition""]",cognition;data visualization;internet of things;optical character recognition,input;human factors;internet of things;data;networks,technology;end users and user experience,input;human factors;internet of things;data;networks,technology;end users and user experience,cognition data_visualization internet_of_things optical_character_recognition appropriate_device_interfaces ar_interface augmented_reality_interface everyday_environments in band_semantic_translation nondigital_spaces optical_character_recognition physical_services semantic_backend semantic_filtering semantic_integration semantic_ocr semantic_technologies socrar_system user virtual_services written_information b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks input human_factors internet_of_things data networks,cognition data_visualization internet_of_things optical_character_recognition,appropriate_device_interfaces ar_interface augmented_reality_interface everyday_environments in band_semantic_translation nondigital_spaces optical_character_recognition physical_services semantic_backend semantic_filtering semantic_integration semantic_ocr semantic_technologies socrar_system user virtual_services written_information,enable people interact efficiently virtual physical service surroundings would beneficial information could fluently passed across digital non digital space end propose combine semantic technology optical character recognition augmented reality ar interface enable semantic integration written information located everyday environment internet thing device hence present socrar system able detect written information user physical environment contextualizing data semantic backend socrar system enables band semantic translation ar interface permit semantic filtering selection appropriate device interface provides cognitive offloading enabling user store information later use demonstrate feasibility socrar implementation three concrete scenario,cognition data_visualization internet_of_things optical_character_recognition appropriate_device_interfaces ar_interface augmented_reality_interface everyday_environments in band_semantic_translation nondigital_spaces optical_character_recognition physical_services semantic_backend semantic_filtering semantic_integration semantic_ocr semantic_technologies socrar_system user virtual_services written_information b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks input human_factors internet_of_things data networks enable people interact efficiently virtual physical service surroundings would beneficial information could fluently passed across digital non digital space end propose combine semantic technology optical character recognition augmented reality ar interface enable semantic integration written information located everyday environment internet thing device hence present socrar system able detect written information user physical environment contextualizing data semantic backend socrar system enables band semantic translation ar interface permit semantic filtering selection appropriate device interface provides cognitive offloading enabling user store information later use demonstrate feasibility socrar implementation three concrete scenario,enable people interact efficiently virtual physical service surroundings would beneficial information could fluently passed across digital non digital space end propose combine semantic technology optical character recognition augmented reality ar interface enable semantic integration written information located everyday environment internet thing device hence present socrar system able detect written information user physical environment contextualizing data semantic backend socrar system enables band semantic translation ar interface permit semantic filtering selection appropriate device interface provides cognitive offloading enabling user store information later use demonstrate feasibility socrar implementation three concrete scenariocognition data_visualization internet_of_things optical_character_recognitionappropriate_device_interfaces ar_interface augmented_reality_interface everyday_environments in band_semantic_translation nondigital_spaces optical_character_recognition physical_services semantic_backend semantic_filtering semantic_integration semantic_ocr semantic_technologies socrar_system user virtual_services written_information
122,A state-of-the-art survey on Augmented Reality-assisted Digital Twin for futuristic human-centric industry transformation,"Yin, Y., Zheng, P., Li, C., & Wang, L. (2023). A state-of-the-art survey on Augmented Reality-assisted Digital Twin for futuristic human-centric industry transformation. Robotics and Computer-Integrated Manufacturing, 81, 102515. https://doi.org/10.1016/j.rcim.2022.102515
",10.1016/j.rcim.2022.102515,"The combination of Augmented Reality (AR) and Digital Twin (DT) has begun to show its potential nowadays, leading to a growing research interest in both academia and industry. Especially under the current human-centric trend, AR embraces the potential to integrate operators into the new generation of Human Cyber-Physical System (HCPS), in which DT is a pillar component. Some review articles have focused on this topic and discussed the benefits of combining AR and DT, but all of them are limited to a specific domain. To fill the gap, this research conducts a state-of-the-art survey (till 17-July-2022) from the AR-assisted DT perspective across different sectors of the industrial field, covering a total of 118 selected publications. Firstly, application scenarios and functions of AR-assisted DT are summarized by following the engineering lifecycle, among which production process, service design, and Human-Machine Interaction (HMI) are hot topics. Then, improvements specifically brought by AR are analyzed according to three dimensions, namely virtual twin, hybrid twin, and cognitive twin, respectively. Finally, challenges and future perspectives of AR-assisted DT for futuristic human-centric industry transformation are proposed, including promoting product design, robotic-related works, cyber-physical interaction, and human ergonomics. All rights reserved Elsevier.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C7480 Production engineering computing;E0410D Industrial applications of IT,AR-assisted DT;Augmented Reality-assisted Digital Twin;cognitive twin;cyber-physical interaction;DT perspective;growing research interest;Human Cyber-Physical System;human ergonomics;human-centric industry transformation;human-centric trend;Human-Machine Interaction;hybrid twin;industrial field;state-of-the-art survey;virtual twin,augmented reality;cyber-physical systems;digital twins;ergonomics;human computer interaction;product design;production engineering computing;reviews,2023,Journal article (JA),Robot. Comput.-Integr. Manuf. (Netherlands),"(1) Yin, Y.; (1) Zheng, P.; (1) Li, C.; (3) Wang, L.; ","(1) Hong Kong Polytechnic University, Department of Industrial and Systems Engineering, China; (2) Laboratory for Artificial Intelligence in Design, Hong Kong Science Park, China; (3) Kungliga Tekniska Hogskolan, Department of Production Engineering, Sweden; ",Elsevier B.V.,-1,"[""cyber-physical systems"", ""digital twins"", ""ergonomics"", ""human computer interaction"", ""product design"", ""production engineering computing"", ""reviews""]","[""cyber-physical systems"", ""digital twins"", ""ergonomics"", ""human computer interaction"", ""product design"", ""production engineering computing"", ""reviews""]",cyber-physical systems;digital twins;ergonomics;human computer interaction;product design;production engineering computing;reviews,education;other;robotics;human factors;engineering;smart cities;human-computer interaction;standards;manufacturing,other;end users and user experience;industries;use cases;standards;technology,education;other;robotics;human factors;engineering;smart cities;human-computer interaction;standards;manufacturing,other;end users and user experience;industries;use cases;standards;technology,cyber physical_systems digital_twins ergonomics human_computer_interaction product_design production_engineering_computing reviews ar assisted_dt augmented_reality assisted_digital_twin cognitive_twin cyber physical_interaction dt_perspective growing_research_interest human_cyber physical_system human_ergonomics human centric_industry_transformation human centric_trend human machine_interaction hybrid_twin industrial_field state of the art_survey virtual_twin c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it education other robotics human_factors engineering smart_cities human computer_interaction standards manufacturing,cyber physical_systems digital_twins ergonomics human_computer_interaction product_design production_engineering_computing reviews,ar assisted_dt augmented_reality assisted_digital_twin cognitive_twin cyber physical_interaction dt_perspective growing_research_interest human_cyber physical_system human_ergonomics human centric_industry_transformation human centric_trend human machine_interaction hybrid_twin industrial_field state of the art_survey virtual_twin,combination augmented reality ar digital twin dt begun show potential nowadays leading growing research interest academia industry especially current human centric trend ar embrace potential integrate operator new generation human cyber physical system hcps dt pillar component review article focused topic discussed benefit combining ar dt limited specific domain fill gap research conduct state art survey till 17 july 2022 ar assisted dt perspective across different sector industrial field covering total 118 selected publication firstly application scenario function ar assisted dt summarized following engineering lifecycle among production process service design human machine interaction hmi hot topic improvement specifically brought ar analyzed according three dimension namely virtual twin hybrid twin cognitive twin respectively finally challenge future perspective ar assisted dt futuristic human centric industry transformation proposed including promoting product design robotic related work cyber physical interaction human ergonomics right reserved elsevier,cyber physical_systems digital_twins ergonomics human_computer_interaction product_design production_engineering_computing reviews ar assisted_dt augmented_reality assisted_digital_twin cognitive_twin cyber physical_interaction dt_perspective growing_research_interest human_cyber physical_system human_ergonomics human centric_industry_transformation human centric_trend human machine_interaction hybrid_twin industrial_field state of the art_survey virtual_twin c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it education other robotics human_factors engineering smart_cities human computer_interaction standards manufacturing combination augmented reality ar digital twin dt begun show potential nowadays leading growing research interest academia industry especially current human centric trend ar embrace potential integrate operator new generation human cyber physical system hcps dt pillar component review article focused topic discussed benefit combining ar dt limited specific domain fill gap research conduct state art survey till 17 july 2022 ar assisted dt perspective across different sector industrial field covering total 118 selected publication firstly application scenario function ar assisted dt summarized following engineering lifecycle among production process service design human machine interaction hmi hot topic improvement specifically brought ar analyzed according three dimension namely virtual twin hybrid twin cognitive twin respectively finally challenge future perspective ar assisted dt futuristic human centric industry transformation proposed including promoting product design robotic related work cyber physical interaction human ergonomics right reserved elsevier,combination augmented reality ar digital twin dt begun show potential nowadays leading growing research interest academia industry especially current human centric trend ar embrace potential integrate operator new generation human cyber physical system hcps dt pillar component review article focused topic discussed benefit combining ar dt limited specific domain fill gap research conduct state art survey till 17 july 2022 ar assisted dt perspective across different sector industrial field covering total 118 selected publication firstly application scenario function ar assisted dt summarized following engineering lifecycle among production process service design human machine interaction hmi hot topic improvement specifically brought ar analyzed according three dimension namely virtual twin hybrid twin cognitive twin respectively finally challenge future perspective ar assisted dt futuristic human centric industry transformation proposed including promoting product design robotic related work cyber physical interaction human ergonomics right reserved elseviercyber physical_systems digital_twins ergonomics human_computer_interaction product_design production_engineering_computing reviewsar assisted_dt augmented_reality assisted_digital_twin cognitive_twin cyber physical_interaction dt_perspective growing_research_interest human_cyber physical_system human_ergonomics human centric_industry_transformation human centric_trend human machine_interaction hybrid_twin industrial_field state of the art_survey virtual_twin
123,IoT-Enabled Environment Illuminance Optimization for Augmented Reality,"Scargill, T., Dabrowski, A., Xu, A., & Gorlatova, M. (2022). IoT-Enabled Environment Illuminance Optimization for Augmented Reality. Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3560357
",10.1145/3544793.3560357,"In order to provide high quality augmented reality (AR) experiences, environmental conditions such as light level must be conducive to a high level of virtual content stability, accurate eye tracking and good virtual content visibility. This is challenging due to the dynamic nature of environmental conditions and AR application requirements. In this poster we present the first automatic environment optimization system for AR which adapts to both environment lighting and texture. First we conduct experiments that demonstrate the effect of light level on virtual object stability and eye tracking. We then detail our edge computing system architecture which uses IoT devices to sense and adjust environment conditions, and lays the foundation for future environment-aware AR applications.","C6130V Virtual reality;C5620D Internet of Things;C6190V Mobile, ubiquitous and pervasive computing",accurate eye tracking;application requirements;automatic environment optimization system;environment conditions;environment lighting;environmental conditions;future environment-aware AR applications;good virtual content visibility;high quality augmented reality;IoT devices;IoT-enabled environment illuminance optimization;light level;system architecture;texture;virtual content stability;virtual object stability,augmented reality;edge computing;gaze tracking;Internet of Things,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) Scargill, T.; (1) Dabrowski, A.; (1) Xu, A.; (2) Gorlatova, M.; ","(1) Duke University, Durham, NC, United States; (2) Duke University, Electrical and Computer Engineering, Durham, NC, United States; ",ACM,-1,"[""edge computing"", ""gaze tracking"", ""internet of things""]","[""edge computing"", ""gaze tracking"", ""internet of things""]",edge computing;gaze tracking;internet of things,computer vision;internet of things;input;networks,technology,computer vision;internet of things;input;networks,technology,edge_computing gaze_tracking internet_of_things accurate_eye_tracking application_requirements automatic_environment_optimization_system environment_conditions environment_lighting environmental_conditions future_environment aware_ar_applications good_virtual_content_visibility high_quality_augmented_reality iot_devices iot enabled_environment_illuminance_optimization light_level system_architecture texture virtual_content_stability virtual_object_stability c6130v_virtual_reality c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision internet_of_things input networks,edge_computing gaze_tracking internet_of_things,accurate_eye_tracking application_requirements automatic_environment_optimization_system environment_conditions environment_lighting environmental_conditions future_environment aware_ar_applications good_virtual_content_visibility high_quality_augmented_reality iot_devices iot enabled_environment_illuminance_optimization light_level system_architecture texture virtual_content_stability virtual_object_stability,order provide high quality augmented reality ar experience environmental condition light level must conducive high level virtual content stability accurate eye tracking good virtual content visibility challenging due dynamic nature environmental condition ar application requirement poster present first automatic environment optimization system ar adapts environment lighting texture first conduct experiment demonstrate effect light level virtual object stability eye tracking detail edge computing system architecture us iot device sense adjust environment condition lay foundation future environment aware ar application,edge_computing gaze_tracking internet_of_things accurate_eye_tracking application_requirements automatic_environment_optimization_system environment_conditions environment_lighting environmental_conditions future_environment aware_ar_applications good_virtual_content_visibility high_quality_augmented_reality iot_devices iot enabled_environment_illuminance_optimization light_level system_architecture texture virtual_content_stability virtual_object_stability c6130v_virtual_reality c5620d_internet_of_things c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision internet_of_things input networks order provide high quality augmented reality ar experience environmental condition light level must conducive high level virtual content stability accurate eye tracking good virtual content visibility challenging due dynamic nature environmental condition ar application requirement poster present first automatic environment optimization system ar adapts environment lighting texture first conduct experiment demonstrate effect light level virtual object stability eye tracking detail edge computing system architecture us iot device sense adjust environment condition lay foundation future environment aware ar application,order provide high quality augmented reality ar experience environmental condition light level must conducive high level virtual content stability accurate eye tracking good virtual content visibility challenging due dynamic nature environmental condition ar application requirement poster present first automatic environment optimization system ar adapts environment lighting texture first conduct experiment demonstrate effect light level virtual object stability eye tracking detail edge computing system architecture us iot device sense adjust environment condition lay foundation future environment aware ar applicationedge_computing gaze_tracking internet_of_thingsaccurate_eye_tracking application_requirements automatic_environment_optimization_system environment_conditions environment_lighting environmental_conditions future_environment aware_ar_applications good_virtual_content_visibility high_quality_augmented_reality iot_devices iot enabled_environment_illuminance_optimization light_level system_architecture texture virtual_content_stability virtual_object_stability
124,Augmented Reality: An Emergent Technology for Students' Learning Motivation for Chemical Engineering Laboratories during the COVID-19 Pandemic,"Guaya, D., Meneses, M. Á., Jaramillo-Fierro, X., & Valarezo, E. (2023). Augmented Reality: An Emergent Technology for Students’ Learning Motivation for Chemical Engineering Laboratories during the COVID-19 Pandemic. Sustainability, 15(6), 5175. https://doi.org/10.3390/su15065175
",10.3390/su15065175,"In higher education, the learning of Unit Operations in Chemical Engineering and the development of practical activities became a real challenge. Therefore, the use of emerging technologies became necessary to develop practical laboratory activities of the Unit Operations due to the inaccessibility to the equipment infrastructure. In this study, Project-Based Learning methodology was assisted with the Augmented Reality (AR) technology for the development of subjects. The development of a real educational experiment for the application of a basic topic of the course as a project for each subject was proposed. The results were presented using the Zappar application, and a unique rubric was used for the evaluation of project. The evaluation of students' motivation for learning was measured using Keller's Attention, Relevance, Confidence and Satisfaction (ARCS) model of motivation by Instructional Materials Motivation Survey (IMMS). The attention, confidence and satisfaction demonstrate an acceptable reliability in comparison to relevance, which was considered as moderate reliability. Above 96% of students considered that the activities, materials, and organization of information used for the AR project caught their attention and encouraged their interest towards the fundamentals applied in the project. Around 80% of students expressed concern about the ease of AR technology use, and understood the learning aim of the project. Above 85% of students recognized the relevance of activities and their usefulness, and considered AR as a meaningful educational tool. 90% of students considered that AR technology helped them to develop the subject competencies. Cronbach's Alpha was used to indicate an acceptable reliability of IMMS instrument. Regarding IMMS, values were superior to 0.7, which could be considered acceptable. For the individual ARCS dimensions, values of Cronbach's alpha reached values of 0.94.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality,acceptable reliability;AR project;AR technology use;Augmented Reality technology;basic topic;Chemical Engineering laboratories;COVID-19 pandemic;educational experiment;emergent technology;equipment infrastructure;higher education;IMMS;Instructional Materials Motivation Survey;Keller's Attention;learning aim;meaningful educational tool;moderate reliability;practical activities;practical laboratory activities;Project-Based Learning methodology;students;subject competencies;unique rubric;Unit Operations;Zappar application,augmented reality;computer aided instruction;diseases;educational courses;epidemics;further education;human factors,2023,Journal article (JA),Sustainability (Switzerland),"(1) Guaya, D.; (1) Meneses, M.A.; (1) Jaramillo-Fierro, X.; (1) Valarezo, E.; ","(1) Universidad Te&#769;cnica Particular de Loja, Department of Chemistry, Ecuador; ",MDPI,-1,"[""computer aided instruction"", ""diseases"", ""educational courses"", ""epidemics"", ""further education"", ""human factors""]","[""computer aided instruction"", ""diseases"", ""educational courses"", ""epidemics"", ""further education"", ""human factors""]",computer aided instruction;diseases;educational courses;epidemics;further education;human factors,medical;human factors;education;training,end users and user experience;use cases;industries,medical;human factors;education;training,end users and user experience;use cases;industries,computer_aided_instruction diseases educational_courses epidemics further_education human_factors acceptable_reliability ar_project ar_technology_use augmented_reality_technology basic_topic chemical_engineering_laboratories covid 19_pandemic educational_experiment emergent_technology equipment_infrastructure higher_education imms instructional_materials_motivation_survey keller s_attention learning_aim meaningful_educational_tool moderate_reliability practical_activities practical_laboratory_activities project based_learning_methodology students subject_competencies unique_rubric unit_operations zappar_application c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality medical human_factors education training,computer_aided_instruction diseases educational_courses epidemics further_education human_factors,acceptable_reliability ar_project ar_technology_use augmented_reality_technology basic_topic chemical_engineering_laboratories covid 19_pandemic educational_experiment emergent_technology equipment_infrastructure higher_education imms instructional_materials_motivation_survey keller s_attention learning_aim meaningful_educational_tool moderate_reliability practical_activities practical_laboratory_activities project based_learning_methodology students subject_competencies unique_rubric unit_operations zappar_application,higher education learning unit operation chemical engineering development practical activity became real challenge therefore use emerging technology became necessary develop practical laboratory activity unit operation due inaccessibility equipment infrastructure study project based learning methodology assisted augmented reality ar technology development subject development real educational experiment application basic topic course project subject proposed result presented using zappar application unique rubric used evaluation project evaluation student motivation learning measured using keller attention relevance confidence satisfaction arc model motivation instructional material motivation survey imms attention confidence satisfaction demonstrate acceptable reliability comparison relevance considered moderate reliability 96 student considered activity material organization information used ar project caught attention encouraged interest towards fundamental applied project around 80 student expressed concern ease ar technology use understood learning aim project 85 student recognized relevance activity usefulness considered ar meaningful educational tool 90 student considered ar technology helped develop subject competency cronbach alpha used indicate acceptable reliability imms instrument regarding imms value superior 0 7 could considered acceptable individual arc dimension value cronbach alpha reached value 0 94,computer_aided_instruction diseases educational_courses epidemics further_education human_factors acceptable_reliability ar_project ar_technology_use augmented_reality_technology basic_topic chemical_engineering_laboratories covid 19_pandemic educational_experiment emergent_technology equipment_infrastructure higher_education imms instructional_materials_motivation_survey keller s_attention learning_aim meaningful_educational_tool moderate_reliability practical_activities practical_laboratory_activities project based_learning_methodology students subject_competencies unique_rubric unit_operations zappar_application c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality medical human_factors education training higher education learning unit operation chemical engineering development practical activity became real challenge therefore use emerging technology became necessary develop practical laboratory activity unit operation due inaccessibility equipment infrastructure study project based learning methodology assisted augmented reality ar technology development subject development real educational experiment application basic topic course project subject proposed result presented using zappar application unique rubric used evaluation project evaluation student motivation learning measured using keller attention relevance confidence satisfaction arc model motivation instructional material motivation survey imms attention confidence satisfaction demonstrate acceptable reliability comparison relevance considered moderate reliability 96 student considered activity material organization information used ar project caught attention encouraged interest towards fundamental applied project around 80 student expressed concern ease ar technology use understood learning aim project 85 student recognized relevance activity usefulness considered ar meaningful educational tool 90 student considered ar technology helped develop subject competency cronbach alpha used indicate acceptable reliability imms instrument regarding imms value superior 0 7 could considered acceptable individual arc dimension value cronbach alpha reached value 0 94,higher education learning unit operation chemical engineering development practical activity became real challenge therefore use emerging technology became necessary develop practical laboratory activity unit operation due inaccessibility equipment infrastructure study project based learning methodology assisted augmented reality ar technology development subject development real educational experiment application basic topic course project subject proposed result presented using zappar application unique rubric used evaluation project evaluation student motivation learning measured using keller attention relevance confidence satisfaction arc model motivation instructional material motivation survey imms attention confidence satisfaction demonstrate acceptable reliability comparison relevance considered moderate reliability 96 student considered activity material organization information used ar project caught attention encouraged interest towards fundamental applied project around 80 student expressed concern ease ar technology use understood learning aim project 85 student recognized relevance activity usefulness considered ar meaningful educational tool 90 student considered ar technology helped develop subject competency cronbach alpha used indicate acceptable reliability imms instrument regarding imms value superior 0 7 could considered acceptable individual arc dimension value cronbach alpha reached value 0 94computer_aided_instruction diseases educational_courses epidemics further_education human_factorsacceptable_reliability ar_project ar_technology_use augmented_reality_technology basic_topic chemical_engineering_laboratories covid 19_pandemic educational_experiment emergent_technology equipment_infrastructure higher_education imms instructional_materials_motivation_survey keller s_attention learning_aim meaningful_educational_tool moderate_reliability practical_activities practical_laboratory_activities project based_learning_methodology students subject_competencies unique_rubric unit_operations zappar_application
125,Using Augmented Reality to Explore Gender and Power Dynamics in STEM Higher Education,,10.1145/3572921.3576203,"We report on results from a pilot study that used Augmented Reality (AR) to explore gender and power dynamics in STEM Higher Education. The so called ""leaky pipeline"", affecting retention and recruitment of women in higher education fields of Science, Technology, Engineering and Mathematics (STEM) is a well-documented issue. We conducted a co-design workshop with six academics, asking to reflect on an AR storyboard prototype, discuss aspects of personal and professional identity, and imagine alternative endings for the storyboard. The storyboard depicted a hypothetical workplace conflict involving an episode of gender-based discrimination. Participants collaboratively imagined possible responses to the situation depicted using a combination of paper-prototyping and open discussions. The found themes were that 1) reflecting on personal identities can drive empathy and understanding for others; 2) co-creating the AR experiences was an engaging way of scaffolding these reflections, and 3) the co-created AR prototypes offered constructive and community-centred approaches to supporting diversity. We contribute a preliminary format for an identity-based AR co-creation workshop and opportunities for applying AR to support dialogue on gender and power dynamics.","C7810C Computer-aided instruction;C0230 Economic, social and political aspects of computing;C6130G Groupware;C6130V Virtual reality;C6180 User interfaces","AR storyboard prototype;augmented reality;called leaky pipeline;co-created AR prototypes;explore gender;gender-based discrimination;hypothetical workplace conflict;paper-prototyping;personal identities;personal identity;power dynamics;professional identity;science, technology, engineering and mathematics;STEM higher education",augmented reality;computer aided instruction;educational institutions;further education;gender issues;groupware;user interfaces,2022,Conference article (CA),OzCHI '22: Proceedings of the 34th Australian Conference on Human-Computer Interaction,"(1) Holopainen, N.; (1) Soro, A.; (1) Brereton, M.; ","(1) Queensland University of Technology, Faculty of Science, Brisbane, QLD, Australia; ",ACM,-1,"[""computer aided instruction"", ""educational institutions"", ""further education"", ""gender issues"", ""groupware"", ""user interfaces""]","[""computer aided instruction"", ""educational institutions"", ""further education"", ""gender issues"", ""groupware"", ""user interfaces""]",computer aided instruction;educational institutions;further education;gender issues;groupware;user interfaces,other;education;training;collaboration;human-computer interaction,other;end users and user experience;use cases;industries,other;education;training;collaboration;human-computer interaction,other;end users and user experience;use cases;industries,computer_aided_instruction educational_institutions further_education gender_issues groupware user_interfaces ar_storyboard_prototype augmented_reality called_leaky_pipeline co created_ar_prototypes explore_gender gender based_discrimination hypothetical_workplace_conflict paper prototyping personal_identities personal_identity power_dynamics professional_identity science _technology _engineering_and_mathematics stem_higher_education c7810c_computer aided_instruction c0230_economic _social_and_political_aspects_of_computing c6130g_groupware c6130v_virtual_reality c6180_user_interfaces other education training collaboration human computer_interaction,computer_aided_instruction educational_institutions further_education gender_issues groupware user_interfaces,ar_storyboard_prototype augmented_reality called_leaky_pipeline co created_ar_prototypes explore_gender gender based_discrimination hypothetical_workplace_conflict paper prototyping personal_identities personal_identity power_dynamics professional_identity science _technology _engineering_and_mathematics stem_higher_education,report result pilot study used augmented reality ar explore gender power dynamic stem higher education called leaky pipeline affecting retention recruitment woman higher education field science technology engineering mathematics stem well documented issue conducted co design workshop six academic asking reflect ar storyboard prototype discus aspect personal professional identity imagine alternative ending storyboard storyboard depicted hypothetical workplace conflict involving episode gender based discrimination participant collaboratively imagined possible response situation depicted using combination paper prototyping open discussion found theme 1 reflecting personal identity drive empathy understanding others 2 co creating ar experience engaging way scaffolding reflection 3 co created ar prototype offered constructive community centred approach supporting diversity contribute preliminary format identity based ar co creation workshop opportunity applying ar support dialogue gender power dynamic,computer_aided_instruction educational_institutions further_education gender_issues groupware user_interfaces ar_storyboard_prototype augmented_reality called_leaky_pipeline co created_ar_prototypes explore_gender gender based_discrimination hypothetical_workplace_conflict paper prototyping personal_identities personal_identity power_dynamics professional_identity science _technology _engineering_and_mathematics stem_higher_education c7810c_computer aided_instruction c0230_economic _social_and_political_aspects_of_computing c6130g_groupware c6130v_virtual_reality c6180_user_interfaces other education training collaboration human computer_interaction report result pilot study used augmented reality ar explore gender power dynamic stem higher education called leaky pipeline affecting retention recruitment woman higher education field science technology engineering mathematics stem well documented issue conducted co design workshop six academic asking reflect ar storyboard prototype discus aspect personal professional identity imagine alternative ending storyboard storyboard depicted hypothetical workplace conflict involving episode gender based discrimination participant collaboratively imagined possible response situation depicted using combination paper prototyping open discussion found theme 1 reflecting personal identity drive empathy understanding others 2 co creating ar experience engaging way scaffolding reflection 3 co created ar prototype offered constructive community centred approach supporting diversity contribute preliminary format identity based ar co creation workshop opportunity applying ar support dialogue gender power dynamic,report result pilot study used augmented reality ar explore gender power dynamic stem higher education called leaky pipeline affecting retention recruitment woman higher education field science technology engineering mathematics stem well documented issue conducted co design workshop six academic asking reflect ar storyboard prototype discus aspect personal professional identity imagine alternative ending storyboard storyboard depicted hypothetical workplace conflict involving episode gender based discrimination participant collaboratively imagined possible response situation depicted using combination paper prototyping open discussion found theme 1 reflecting personal identity drive empathy understanding others 2 co creating ar experience engaging way scaffolding reflection 3 co created ar prototype offered constructive community centred approach supporting diversity contribute preliminary format identity based ar co creation workshop opportunity applying ar support dialogue gender power dynamiccomputer_aided_instruction educational_institutions further_education gender_issues groupware user_interfacesar_storyboard_prototype augmented_reality called_leaky_pipeline co created_ar_prototypes explore_gender gender based_discrimination hypothetical_workplace_conflict paper prototyping personal_identities personal_identity power_dynamics professional_identity science _technology _engineering_and_mathematics stem_higher_education
126,Designing Interactive Shoes for Tactile Augmented Reality,"Wittchen, D., Martinez-Missir, V., Mavali, S., Sabnis, N., Reed, C. N., & Strohmeier, P. (2023). Designing Interactive Shoes for Tactile Augmented Reality. Augmented Humans Conference. https://doi.org/10.1145/3582700.3582728
",10.1145/3582700.3582728,"Augmented Footwear has become an increasingly common research area. However, as this is a comparatively new direction in HCI, researchers and designers are not able to build upon common platforms. We discuss the design space of shoes for augmented tactile reality, focussing on physiological and biomechanical factors as well as technical considerations. We present an open source example implementation from this space, intended as an experimental platform for vibrotactile rendering and tactile AR and provide details on experiences that could be evoked with such a system. Anecdotally, the new prototype provided experiences of material properties like compliance, as well as altered perception of their movements and agency. We intend our work to lower the barrier of entry for new researchers and to support the field of tactile rendering in footwear in general by making it easier to compare results between studies.",C6130V Virtual reality;C5540B Interactive-input devices;C6130B Graphics techniques;C6180 User interfaces,Augmented Footwear;augmented tactile reality;biomechanical factors;common platforms;comparatively new direction;design space;designing interactive shoes;HCI;increasingly common research area;open source example implementation;physiological factors;tactile augmented reality;tactile rendering;technical considerations;vibrotactile rendering,augmented reality;biomechanics;footwear;haptic interfaces;human computer interaction;rendering (computer graphics),2023,Conference article (CA),AHs23: Proceedings of the Augmented Humans Conference 2023,"(1) Wittchen, D.; (1) Martinez-Missir, V.; (1) Mavali, S.; (1) Sabnis, N.; (1) Reed, C.N.; (1) Strohmeier, P.; ","(1) Max Planck Institute for Informatics, Germany; ",ACM,-1,"[""biomechanics"", ""footwear"", ""haptic interfaces"", ""human computer interaction"", ""rendering""]","[""biomechanics"", ""footwear"", ""haptic interfaces"", ""human computer interaction"", ""rendering""]",biomechanics;footwear;haptic interfaces;human computer interaction;rendering,"other;graphics;input;medical;inspection, safety and quality;human-computer interaction",other;industries;end users and user experience;use cases;technology,"other;graphics;input;medical;inspection, safety and quality;human-computer interaction",other;industries;end users and user experience;use cases;technology,biomechanics footwear haptic_interfaces human_computer_interaction rendering augmented_footwear augmented_tactile_reality biomechanical_factors common_platforms comparatively_new_direction design_space designing_interactive_shoes hci increasingly_common_research_area open_source_example_implementation physiological_factors tactile_augmented_reality tactile_rendering technical_considerations vibrotactile_rendering c6130v_virtual_reality c5540b_interactive input_devices c6130b_graphics_techniques c6180_user_interfaces other graphics input medical inspection _safety_and_quality human computer_interaction,biomechanics footwear haptic_interfaces human_computer_interaction rendering,augmented_footwear augmented_tactile_reality biomechanical_factors common_platforms comparatively_new_direction design_space designing_interactive_shoes hci increasingly_common_research_area open_source_example_implementation physiological_factors tactile_augmented_reality tactile_rendering technical_considerations vibrotactile_rendering,augmented footwear become increasingly common research area however comparatively new direction hci researcher designer able build upon common platform discus design space shoe augmented tactile reality focussing physiological biomechanical factor well technical consideration present open source example implementation space intended experimental platform vibrotactile rendering tactile ar provide detail experience could evoked system anecdotally new prototype provided experience material property like compliance well altered perception movement agency intend work lower barrier entry new researcher support field tactile rendering footwear general making easier compare result study,biomechanics footwear haptic_interfaces human_computer_interaction rendering augmented_footwear augmented_tactile_reality biomechanical_factors common_platforms comparatively_new_direction design_space designing_interactive_shoes hci increasingly_common_research_area open_source_example_implementation physiological_factors tactile_augmented_reality tactile_rendering technical_considerations vibrotactile_rendering c6130v_virtual_reality c5540b_interactive input_devices c6130b_graphics_techniques c6180_user_interfaces other graphics input medical inspection _safety_and_quality human computer_interaction augmented footwear become increasingly common research area however comparatively new direction hci researcher designer able build upon common platform discus design space shoe augmented tactile reality focussing physiological biomechanical factor well technical consideration present open source example implementation space intended experimental platform vibrotactile rendering tactile ar provide detail experience could evoked system anecdotally new prototype provided experience material property like compliance well altered perception movement agency intend work lower barrier entry new researcher support field tactile rendering footwear general making easier compare result study,augmented footwear become increasingly common research area however comparatively new direction hci researcher designer able build upon common platform discus design space shoe augmented tactile reality focussing physiological biomechanical factor well technical consideration present open source example implementation space intended experimental platform vibrotactile rendering tactile ar provide detail experience could evoked system anecdotally new prototype provided experience material property like compliance well altered perception movement agency intend work lower barrier entry new researcher support field tactile rendering footwear general making easier compare result studybiomechanics footwear haptic_interfaces human_computer_interaction renderingaugmented_footwear augmented_tactile_reality biomechanical_factors common_platforms comparatively_new_direction design_space designing_interactive_shoes hci increasingly_common_research_area open_source_example_implementation physiological_factors tactile_augmented_reality tactile_rendering technical_considerations vibrotactile_rendering
127,Augmented reality android based: Education of modern and traditional instruments,"Alamsyah, D. P., Parulian, J. M., & Herliana, A. (2023). Augmented reality android based: Education of modern and traditional instruments. Procedia Computer Science, 216, 266–273. https://doi.org/10.1016/j.procs.2022.12.136
",10.1016/j.procs.2022.12.136,"Musical instruments in Indonesia are divided into two types, namely traditional musical instruments and modern musical instruments, which in this study will be discussed with more than ten musical instruments. Today, there are still many Indonesian people who do not know traditional musical instruments and modern musical instruments due to lack of knowledge and the lack of means to provide visual access to both traditional and modern musical instruments. The purpose of this research is to help people recognize traditional musical instruments and modern musical instruments digitally easily. The method used in this research is the Marker-Based AR method, because it takes a marker on each object to display a clear object in the Augmented Reality application to find information from an image directly. The results of this study are in the form of an Android-based Augmented Reality application with a page display feature, displaying information on 3D objects of traditional musical instruments and modern musical instruments with writing and sound, as well as showing how to use the application. All rights reserved Elsevier.","C6130V Virtual reality;C6130B Graphics techniques;C6190V Mobile, ubiquitous and pervasive computing;C7820 Humanities computing",modern instruments;modern musical instruments;traditional instruments;traditional musical instruments,augmented reality;music;musical instruments,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Alamsyah, D.P.; (2) Parulian, J.M.; (2) Herliana, A.; ","(1) Binus University, Entrepreneurship Department, Indonesia; (2) Universitas Adhirajasa Reswara Sanjaya, Indonesia; ",Elsevier B.V.,-1,"[""music"", ""musical instruments""]","[""music"", ""musical instruments""]",music;musical instruments,audio,technology,audio,technology,music musical_instruments modern_instruments modern_musical_instruments traditional_instruments traditional_musical_instruments c6130v_virtual_reality c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing audio,music musical_instruments,modern_instruments modern_musical_instruments traditional_instruments traditional_musical_instruments,musical instrument indonesia divided two type namely traditional musical instrument modern musical instrument study discussed ten musical instrument today still many indonesian people know traditional musical instrument modern musical instrument due lack knowledge lack mean provide visual access traditional modern musical instrument purpose research help people recognize traditional musical instrument modern musical instrument digitally easily method used research marker based ar method take marker object display clear object augmented reality application find information image directly result study form android based augmented reality application page display feature displaying information 3d object traditional musical instrument modern musical instrument writing sound well showing use application right reserved elsevier,music musical_instruments modern_instruments modern_musical_instruments traditional_instruments traditional_musical_instruments c6130v_virtual_reality c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing audio musical instrument indonesia divided two type namely traditional musical instrument modern musical instrument study discussed ten musical instrument today still many indonesian people know traditional musical instrument modern musical instrument due lack knowledge lack mean provide visual access traditional modern musical instrument purpose research help people recognize traditional musical instrument modern musical instrument digitally easily method used research marker based ar method take marker object display clear object augmented reality application find information image directly result study form android based augmented reality application page display feature displaying information 3d object traditional musical instrument modern musical instrument writing sound well showing use application right reserved elsevier,musical instrument indonesia divided two type namely traditional musical instrument modern musical instrument study discussed ten musical instrument today still many indonesian people know traditional musical instrument modern musical instrument due lack knowledge lack mean provide visual access traditional modern musical instrument purpose research help people recognize traditional musical instrument modern musical instrument digitally easily method used research marker based ar method take marker object display clear object augmented reality application find information image directly result study form android based augmented reality application page display feature displaying information 3d object traditional musical instrument modern musical instrument writing sound well showing use application right reserved elseviermusic musical_instrumentsmodern_instruments modern_musical_instruments traditional_instruments traditional_musical_instruments
128,"Effect of augmented reality-based virtual educational robotics on programming students' enjoyment of learning, computational thinking skills, and academic achievement","Ou Yang, F.-C., Lai, H.-M., & Wang, Y.-W. (2023). Effect of augmented reality-based virtual educational robotics on programming students’ enjoyment of learning, computational thinking skills, and academic achievement. Computers &amp; Education, 195, 104721. https://doi.org/10.1016/j.compedu.2022.104721
",10.1016/j.compedu.2022.104721,"The use of educational robotics for programming education has been shown to be effective in fostering students' computational thinking (CT) skills. However, physical educational robots are expensive, which may limit their wide use in the classroom. This study used augmented reality technology to develop a virtual educational robotic system (AR Bot for short), which offers 3D visual learning feedback to strengthen spatial ability, as well as delayed feedback and auto-scoring feedback to promote students' deeper CT processes. To examine the impact of AR Bot on programming learning, this study used a quasi-experimental design to compare an experimental group of 41 first-year university students who used AR Bot and a control group of 34 first-year university students who used Scratch. We assessed the impact of the two CT tools on students' internal learning processes (enjoyment of learning), CT skills (problem decomposition, algorithm design, and algorithm efficiency skills), and academic achievement. The results showed that students who used AR Bot had higher enjoyment of learning, algorithm design skills, and algorithm efficiency skills but not higher problem decomposition skills and academic achievement than students who used Scratch. Enjoyment of learning led to higher problem decomposition, algorithm design, and algorithm efficiency skills but not academic achievement. Problem decomposition and algorithm design skills, but not algorithm efficiency skills, led to academic achievement. The theoretical and practical implications of the proposed tool and other CT tools in programming education are discussed. All rights reserved Elsevier.",C6130V Virtual reality;C0220 Computing education and training;C7810C Computer-aided instruction,3D visual learning feedback;academic achievement;algorithm design skills;algorithm efficiency skills;AR Bot;augmented reality-based virtual educational robotics;auto-scoring feedback;computational thinking skills;CT skills;CT tools;delayed feedback;first-year university students;higher enjoyment;higher problem decomposition skills;physical educational robots;programming education;programming learning;programming students;quasiexperimental design;virtual educational robotic system,augmented reality;computer aided instruction;computer science education;educational institutions;educational robots;physics education;virtual reality,2023,Journal article (JA),Comput. Educ. (Netherlands),"(1) Ou Yang, F.-C.; (2) Lai, H.-M.; (3) Wang, Y.-W.; ","(1) National Taipei University of Business, Department of Digital Multimedia Design, 100, Taiwan; (2) National Taichung University of Science and Technology, Department of Business Administration, No. 129, Sec. 3, Sanmin Road, 404, Taiwan; (3) Chien Hsin University, Department of Industrial Management, Taiwan; ",Elsevier B.V.,-1,"[""computer aided instruction"", ""computer science education"", ""educational institutions"", ""educational robots"", ""physics education""]","[""computer aided instruction"", ""computer science education"", ""educational institutions"", ""educational robots"", ""physics education""]",computer aided instruction;computer science education;educational institutions;educational robots;physics education,education;robotics;training;engineering;developers,technology;use cases;industries,education;robotics;training;engineering;developers,technology;use cases;industries,computer_aided_instruction computer_science_education educational_institutions educational_robots physics_education 3d_visual_learning_feedback academic_achievement algorithm_design_skills algorithm_efficiency_skills ar_bot augmented_reality based_virtual_educational_robotics auto scoring_feedback computational_thinking_skills ct_skills ct_tools delayed_feedback first year_university_students higher_enjoyment higher_problem_decomposition_skills physical_educational_robots programming_education programming_learning programming_students quasiexperimental_design virtual_educational_robotic_system c6130v_virtual_reality c0220_computing_education_and_training c7810c_computer aided_instruction education robotics training engineering developers,computer_aided_instruction computer_science_education educational_institutions educational_robots physics_education,3d_visual_learning_feedback academic_achievement algorithm_design_skills algorithm_efficiency_skills ar_bot augmented_reality based_virtual_educational_robotics auto scoring_feedback computational_thinking_skills ct_skills ct_tools delayed_feedback first year_university_students higher_enjoyment higher_problem_decomposition_skills physical_educational_robots programming_education programming_learning programming_students quasiexperimental_design virtual_educational_robotic_system,use educational robotics programming education shown effective fostering student computational thinking ct skill however physical educational robot expensive may limit wide use classroom study used augmented reality technology develop virtual educational robotic system ar bot short offer 3d visual learning feedback strengthen spatial ability well delayed feedback auto scoring feedback promote student deeper ct process examine impact ar bot programming learning study used quasi experimental design compare experimental group 41 first year university student used ar bot control group 34 first year university student used scratch assessed impact two ct tool student internal learning process enjoyment learning ct skill problem decomposition algorithm design algorithm efficiency skill academic achievement result showed student used ar bot higher enjoyment learning algorithm design skill algorithm efficiency skill higher problem decomposition skill academic achievement student used scratch enjoyment learning led higher problem decomposition algorithm design algorithm efficiency skill academic achievement problem decomposition algorithm design skill algorithm efficiency skill led academic achievement theoretical practical implication proposed tool ct tool programming education discussed right reserved elsevier,computer_aided_instruction computer_science_education educational_institutions educational_robots physics_education 3d_visual_learning_feedback academic_achievement algorithm_design_skills algorithm_efficiency_skills ar_bot augmented_reality based_virtual_educational_robotics auto scoring_feedback computational_thinking_skills ct_skills ct_tools delayed_feedback first year_university_students higher_enjoyment higher_problem_decomposition_skills physical_educational_robots programming_education programming_learning programming_students quasiexperimental_design virtual_educational_robotic_system c6130v_virtual_reality c0220_computing_education_and_training c7810c_computer aided_instruction education robotics training engineering developers use educational robotics programming education shown effective fostering student computational thinking ct skill however physical educational robot expensive may limit wide use classroom study used augmented reality technology develop virtual educational robotic system ar bot short offer 3d visual learning feedback strengthen spatial ability well delayed feedback auto scoring feedback promote student deeper ct process examine impact ar bot programming learning study used quasi experimental design compare experimental group 41 first year university student used ar bot control group 34 first year university student used scratch assessed impact two ct tool student internal learning process enjoyment learning ct skill problem decomposition algorithm design algorithm efficiency skill academic achievement result showed student used ar bot higher enjoyment learning algorithm design skill algorithm efficiency skill higher problem decomposition skill academic achievement student used scratch enjoyment learning led higher problem decomposition algorithm design algorithm efficiency skill academic achievement problem decomposition algorithm design skill algorithm efficiency skill led academic achievement theoretical practical implication proposed tool ct tool programming education discussed right reserved elsevier,use educational robotics programming education shown effective fostering student computational thinking ct skill however physical educational robot expensive may limit wide use classroom study used augmented reality technology develop virtual educational robotic system ar bot short offer 3d visual learning feedback strengthen spatial ability well delayed feedback auto scoring feedback promote student deeper ct process examine impact ar bot programming learning study used quasi experimental design compare experimental group 41 first year university student used ar bot control group 34 first year university student used scratch assessed impact two ct tool student internal learning process enjoyment learning ct skill problem decomposition algorithm design algorithm efficiency skill academic achievement result showed student used ar bot higher enjoyment learning algorithm design skill algorithm efficiency skill higher problem decomposition skill academic achievement student used scratch enjoyment learning led higher problem decomposition algorithm design algorithm efficiency skill academic achievement problem decomposition algorithm design skill algorithm efficiency skill led academic achievement theoretical practical implication proposed tool ct tool programming education discussed right reserved elseviercomputer_aided_instruction computer_science_education educational_institutions educational_robots physics_education3d_visual_learning_feedback academic_achievement algorithm_design_skills algorithm_efficiency_skills ar_bot augmented_reality based_virtual_educational_robotics auto scoring_feedback computational_thinking_skills ct_skills ct_tools delayed_feedback first year_university_students higher_enjoyment higher_problem_decomposition_skills physical_educational_robots programming_education programming_learning programming_students quasiexperimental_design virtual_educational_robotic_system
129,SAR.IoT: secured augmented reality for iot devices management,"Fuentes, D., Correia, L., Costa, N., Reis, A., Barroso, J., & Pereira, A. (2021). SAR.IoT: Secured Augmented Reality for IoT Devices Management. Sensors, 21(18), 6001. https://doi.org/10.3390/s21186001
",10.3390/s21186001,"Currently, solutions based on the Internet of Things (IoT) concept are increasingly being adopted in several fields, namely, industry, agriculture, and home automation. The costs associated with this type of equipment is reasonably small, as IoT devices usually do not have output peripherals to display information about their status (e.g., a screen or a printer), although they may have informative LEDs, which is sometimes insufficient. For most IoT devices, the price of a minimalist display, to output and display the device's running status (i.e., what the device is doing), might cost much more than the actual IoT device. Occasionally, it might become necessary to visualize the IoT device output, making it necessary to find solutions to show the hardware output information in real time, without requiring extra equipment, only what the administrator usually has with them. In order to solve the above, a technological solution that allows for the visualization of IoT device information in actual time, using augmented reality and a simple smartphone, was developed and analyzed. In addition, the system created integrates a security layer, at the level of AR, to secure the shown data from unwanted eyes. The results of the tests carried out allowed us to validate the operation of the solution when accessing the information of the IoT devices, verify the operation of the security layer in AR, analyze the interaction between smartphones, the platform, and the devices, and check which AR markers are most optimized for this use case. This work results in a secure augmented reality solution, which can be used with a simple smartphone, to monitor/manage IoT devices in industrial, laboratory or research environments.","C6190V Mobile, ubiquitous and pervasive computing;C6130S Data security;C6130V Virtual reality",hardware output information;Internet of Things concept;iot devices management;SAR.IoT;secure augmented reality solution,augmented reality;Internet of Things;smart phones,2021,Journal article (JA),Sensors (Switzerland),"(1) Fuentes, D.; (1) Correia, L.; (1) Costa, N.; (2) Reis, A.; (2) Barroso, J.; (1) Pereira, A.; ","(1) Polytechnic Institute of Leiria, School of Technology and Management, Portugal; (2) University of Porto, INESC TEC, Portugal; (3) Institute of New Technologies, INOV INESC Inovac&#807;a&#771;o, Campus 2, Apartado 4163, Portugal; ",MDPI,-1,"[""internet of things"", ""smartphones""]","[""internet of things"", ""smartphones""]",internet of things;smartphones,internet of things;telecommunication;liberal arts;networks,technology;industries,internet of things;telecommunication;liberal arts;networks,technology;industries,internet_of_things smartphones hardware_output_information internet_of_things_concept iot_devices_management sar iot secure_augmented_reality_solution c6190v_mobile _ubiquitous_and_pervasive_computing c6130s_data_security c6130v_virtual_reality internet_of_things telecommunication liberal_arts networks,internet_of_things smartphones,hardware_output_information internet_of_things_concept iot_devices_management sar iot secure_augmented_reality_solution,currently solution based internet thing iot concept increasingly adopted several field namely industry agriculture home automation cost associated type equipment reasonably small iot device usually output peripheral display information status e g screen printer although may informative led sometimes insufficient iot device price minimalist display output display device running status e device might cost much actual iot device occasionally might become necessary visualize iot device output making necessary find solution show hardware output information real time without requiring extra equipment administrator usually order solve technological solution allows visualization iot device information actual time using augmented reality simple smartphone developed analyzed addition system created integrates security layer level ar secure shown data unwanted eye result test carried allowed u validate operation solution accessing information iot device verify operation security layer ar analyze interaction smartphones platform device check ar marker optimized use case work result secure augmented reality solution used simple smartphone monitor manage iot device industrial laboratory research environment,internet_of_things smartphones hardware_output_information internet_of_things_concept iot_devices_management sar iot secure_augmented_reality_solution c6190v_mobile _ubiquitous_and_pervasive_computing c6130s_data_security c6130v_virtual_reality internet_of_things telecommunication liberal_arts networks currently solution based internet thing iot concept increasingly adopted several field namely industry agriculture home automation cost associated type equipment reasonably small iot device usually output peripheral display information status e g screen printer although may informative led sometimes insufficient iot device price minimalist display output display device running status e device might cost much actual iot device occasionally might become necessary visualize iot device output making necessary find solution show hardware output information real time without requiring extra equipment administrator usually order solve technological solution allows visualization iot device information actual time using augmented reality simple smartphone developed analyzed addition system created integrates security layer level ar secure shown data unwanted eye result test carried allowed u validate operation solution accessing information iot device verify operation security layer ar analyze interaction smartphones platform device check ar marker optimized use case work result secure augmented reality solution used simple smartphone monitor manage iot device industrial laboratory research environment,currently solution based internet thing iot concept increasingly adopted several field namely industry agriculture home automation cost associated type equipment reasonably small iot device usually output peripheral display information status e g screen printer although may informative led sometimes insufficient iot device price minimalist display output display device running status e device might cost much actual iot device occasionally might become necessary visualize iot device output making necessary find solution show hardware output information real time without requiring extra equipment administrator usually order solve technological solution allows visualization iot device information actual time using augmented reality simple smartphone developed analyzed addition system created integrates security layer level ar secure shown data unwanted eye result test carried allowed u validate operation solution accessing information iot device verify operation security layer ar analyze interaction smartphones platform device check ar marker optimized use case work result secure augmented reality solution used simple smartphone monitor manage iot device industrial laboratory research environmentinternet_of_things smartphoneshardware_output_information internet_of_things_concept iot_devices_management sar iot secure_augmented_reality_solution
130,Memento Player: Shared Multi-Perspective Playback of Volumetrically-Captured Moments in Augmented Reality,"Liu, Y., Ritchie, J., Kratz, S., Sra, M., Smith, B. A., Monroy-Hernández, A., & Vaish, R. (2023). Memento Player: Shared Multi-Perspective Playback of Volumetrically-Captured Moments in Augmented Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585588
",10.1145/3544549.3585588,"Capturing and reliving memories allow us to record, understand and share our past experiences. Currently, the most common approach to revisiting past moments is viewing photos and videos. These 2D media capture past events that reflect a recorder's first-person perspective. The development of technology for accurately capturing 3D content presents an opportunity for new types of memory reliving, allowing greater immersion without perspective limitations. In this work, we adopt 2D and 3D moment-recording techniques and build a moment-reliving experience in AR that combines both display methods. Specifically, we use AR glasses to record 2D point-of-view (POV) videos, and volumetric capture to reconstruct 3D moments in AR. We allow seamless switching between AR and POV videos to enable immersive moment reliving and viewing of high-resolution details. Users can also navigate to a specific point in time using playback controls. Control is synchronized between multiple users for shared viewing.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130B Graphics techniques;C6130V Virtual reality",2D media capture;2D point-of-view videos;3D moment-recording techniques;augmented reality;greater immersion;immersive moment reliving;memento player;memory reliving;moment-reliving experience;perspective limitations;photos;playback controls;recorder;reliving memories;shared multiperspective playback;shared viewing;specific point;volumetric capture;volumetrically-captured moments,augmented reality;image reconstruction;image resolution;video signal processing;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Liu, Y.; (2) Ritchie, J.; (3) Kratz, S.; (1) Sra, M.; (4) Smith, B.A.; (5) Monroy-Herna&#769;ndez, A.; (3) Vaish, R.; ","(1) University of California, Santa Barbara, Computer Science, Santa Barbara, CA, United States; (2) Stanford University, Computer Science, Stanford, CA, United States; (3) Snap Inc, Venice, CA, United States; (4) Columbia University, Computer Science, New York, NY, United States; (5) Princeton University, Computer Science, Princeton, NJ, United States; ",ACM,-1,"[""image reconstruction"", ""image resolution"", ""video signal processing""]","[""image reconstruction"", ""image resolution"", ""video signal processing""]",image reconstruction;image resolution;video signal processing,construction;computer vision;graphics;sensors;data;semiconductors,technology;industries,construction;computer vision;graphics;sensors;data;semiconductors,technology;industries,image_reconstruction image_resolution video_signal_processing 2d_media_capture 2d_point of view_videos 3d_moment recording_techniques augmented_reality greater_immersion immersive_moment_reliving memento_player memory_reliving moment reliving_experience perspective_limitations photos playback_controls recorder reliving_memories shared_multiperspective_playback shared_viewing specific_point volumetric_capture volumetrically captured_moments b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality construction computer_vision graphics sensors data semiconductors,image_reconstruction image_resolution video_signal_processing,2d_media_capture 2d_point of view_videos 3d_moment recording_techniques augmented_reality greater_immersion immersive_moment_reliving memento_player memory_reliving moment reliving_experience perspective_limitations photos playback_controls recorder reliving_memories shared_multiperspective_playback shared_viewing specific_point volumetric_capture volumetrically captured_moments,capturing reliving memory allow u record understand share past experience currently common approach revisiting past moment viewing photo video 2d medium capture past event reflect recorder first person perspective development technology accurately capturing 3d content present opportunity new type memory reliving allowing greater immersion without perspective limitation work adopt 2d 3d moment recording technique build moment reliving experience ar combine display method specifically use ar glass record 2d point view pov video volumetric capture reconstruct 3d moment ar allow seamless switching ar pov video enable immersive moment reliving viewing high resolution detail user also navigate specific point time using playback control control synchronized multiple user shared viewing,image_reconstruction image_resolution video_signal_processing 2d_media_capture 2d_point of view_videos 3d_moment recording_techniques augmented_reality greater_immersion immersive_moment_reliving memento_player memory_reliving moment reliving_experience perspective_limitations photos playback_controls recorder reliving_memories shared_multiperspective_playback shared_viewing specific_point volumetric_capture volumetrically captured_moments b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality construction computer_vision graphics sensors data semiconductors capturing reliving memory allow u record understand share past experience currently common approach revisiting past moment viewing photo video 2d medium capture past event reflect recorder first person perspective development technology accurately capturing 3d content present opportunity new type memory reliving allowing greater immersion without perspective limitation work adopt 2d 3d moment recording technique build moment reliving experience ar combine display method specifically use ar glass record 2d point view pov video volumetric capture reconstruct 3d moment ar allow seamless switching ar pov video enable immersive moment reliving viewing high resolution detail user also navigate specific point time using playback control control synchronized multiple user shared viewing,capturing reliving memory allow u record understand share past experience currently common approach revisiting past moment viewing photo video 2d medium capture past event reflect recorder first person perspective development technology accurately capturing 3d content present opportunity new type memory reliving allowing greater immersion without perspective limitation work adopt 2d 3d moment recording technique build moment reliving experience ar combine display method specifically use ar glass record 2d point view pov video volumetric capture reconstruct 3d moment ar allow seamless switching ar pov video enable immersive moment reliving viewing high resolution detail user also navigate specific point time using playback control control synchronized multiple user shared viewingimage_reconstruction image_resolution video_signal_processing2d_media_capture 2d_point of view_videos 3d_moment recording_techniques augmented_reality greater_immersion immersive_moment_reliving memento_player memory_reliving moment reliving_experience perspective_limitations photos playback_controls recorder reliving_memories shared_multiperspective_playback shared_viewing specific_point volumetric_capture volumetrically captured_moments
131,Investigation of the Effectiveness of an Augmented Reality and a Dynamic Simulation System Collaboration in Oil Pump Maintenance,"Koteleva, N., Valnev, V., & Frenkel, I. (2021). Investigation of the Effectiveness of an Augmented Reality and a Dynamic Simulation System Collaboration in Oil Pump Maintenance. Applied Sciences, 12(1), 350. https://doi.org/10.3390/app12010350
",10.3390/app12010350,"The maintenance of oil pumps is a complex task for any operating organization, and for an industrial enterprise in the oil and gas sector of the economy, this issue has a high degree of urgency. One of the reasons for this is a wide spread of pumping equipment in all areas of oil and gas enterprises. At the same time, an aggressive environment, uneven load, remote facilities, and harsh climatic zones (especially in the areas of the Arctic region or production platforms) are factors that make it relevant to develop special systems that help or simplify the maintenance of pumping equipment. Dynamic modeling is one of the modern technologies which allows for solving the urgent issue of assessing the technical condition of equipment. It is the basis of systems that carry out diagnostics and prognostic calculations and allow for assessing the dynamic state of objects under various conditions of their operation, among other functions. Augmented reality technology is a technology that allows for reducing the time for equipment maintenance by reducing the time for searching and processing various information required in the maintenance process. This paper presents an investigation of the effectiveness of an augmented reality and a dynamic simulation system collaboration in oil pump maintenance. Since there is insufficient research on the joint application of these two technologies, the urgent issue is to prove the effectiveness of such collaboration. For this purpose, this paper provides a description of the system structure, gives a description of the development process of the augmented reality system application and tests the application using Microsoft HoloLens 2.",C6130G Groupware;C6130V Virtual reality;C6185 Simulation techniques;E1020 Maintenance and reliability,augmented reality system application;augmented reality technology;dynamic modeling;dynamic simulation system collaboration;equipment maintenance;gas enterprises;industrial enterprise;Microsoft HoloLens 2;oil pump maintenance;pumping equipment,augmented reality;computer simulation;gas industry;groupware;maintenance engineering;petroleum industry;pumps,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Koteleva, N.; (1) Valnev, V.; (2) Frenkel, I.; ","(1) St. Petersburg Mining University, Department of Automation of Technological Processes and Production, 2, 21 Line of Vasilyevsky Island, Russia; (2) Center for Reliability and Risk Management, Shamoon College of Engineering (SCE), Israel; ",MDPI,-1,"[""computer simulation"", ""gas industry"", ""groupware"", ""maintenance engineering"", ""petroleum industry"", ""pumps""]","[""computer simulation"", ""gas industry"", ""groupware"", ""maintenance engineering"", ""petroleum industry"", ""pumps""]",computer simulation;gas industry;groupware;maintenance engineering;petroleum industry;pumps,simulation;power and energy;collaboration;manufacturing;oil and gas,use cases;industries,simulation;power and energy;collaboration;manufacturing;oil and gas,use cases;industries,computer_simulation gas_industry groupware maintenance_engineering petroleum_industry pumps augmented_reality_system_application augmented_reality_technology dynamic_modeling dynamic_simulation_system_collaboration equipment_maintenance gas_enterprises industrial_enterprise microsoft_hololens_2 oil_pump_maintenance pumping_equipment c6130g_groupware c6130v_virtual_reality c6185_simulation_techniques e1020_maintenance_and_reliability simulation power_and_energy collaboration manufacturing oil_and_gas,computer_simulation gas_industry groupware maintenance_engineering petroleum_industry pumps,augmented_reality_system_application augmented_reality_technology dynamic_modeling dynamic_simulation_system_collaboration equipment_maintenance gas_enterprises industrial_enterprise microsoft_hololens_2 oil_pump_maintenance pumping_equipment,maintenance oil pump complex task operating organization industrial enterprise oil gas sector economy issue high degree urgency one reason wide spread pumping equipment area oil gas enterprise time aggressive environment uneven load remote facility harsh climatic zone especially area arctic region production platform factor make relevant develop special system help simplify maintenance pumping equipment dynamic modeling one modern technology allows solving urgent issue assessing technical condition equipment basis system carry diagnostics prognostic calculation allow assessing dynamic state object various condition operation among function augmented reality technology technology allows reducing time equipment maintenance reducing time searching processing various information required maintenance process paper present investigation effectiveness augmented reality dynamic simulation system collaboration oil pump maintenance since insufficient research joint application two technology urgent issue prove effectiveness collaboration purpose paper provides description system structure give description development process augmented reality system application test application using microsoft hololens 2,computer_simulation gas_industry groupware maintenance_engineering petroleum_industry pumps augmented_reality_system_application augmented_reality_technology dynamic_modeling dynamic_simulation_system_collaboration equipment_maintenance gas_enterprises industrial_enterprise microsoft_hololens_2 oil_pump_maintenance pumping_equipment c6130g_groupware c6130v_virtual_reality c6185_simulation_techniques e1020_maintenance_and_reliability simulation power_and_energy collaboration manufacturing oil_and_gas maintenance oil pump complex task operating organization industrial enterprise oil gas sector economy issue high degree urgency one reason wide spread pumping equipment area oil gas enterprise time aggressive environment uneven load remote facility harsh climatic zone especially area arctic region production platform factor make relevant develop special system help simplify maintenance pumping equipment dynamic modeling one modern technology allows solving urgent issue assessing technical condition equipment basis system carry diagnostics prognostic calculation allow assessing dynamic state object various condition operation among function augmented reality technology technology allows reducing time equipment maintenance reducing time searching processing various information required maintenance process paper present investigation effectiveness augmented reality dynamic simulation system collaboration oil pump maintenance since insufficient research joint application two technology urgent issue prove effectiveness collaboration purpose paper provides description system structure give description development process augmented reality system application test application using microsoft hololens 2,maintenance oil pump complex task operating organization industrial enterprise oil gas sector economy issue high degree urgency one reason wide spread pumping equipment area oil gas enterprise time aggressive environment uneven load remote facility harsh climatic zone especially area arctic region production platform factor make relevant develop special system help simplify maintenance pumping equipment dynamic modeling one modern technology allows solving urgent issue assessing technical condition equipment basis system carry diagnostics prognostic calculation allow assessing dynamic state object various condition operation among function augmented reality technology technology allows reducing time equipment maintenance reducing time searching processing various information required maintenance process paper present investigation effectiveness augmented reality dynamic simulation system collaboration oil pump maintenance since insufficient research joint application two technology urgent issue prove effectiveness collaboration purpose paper provides description system structure give description development process augmented reality system application test application using microsoft hololens 2computer_simulation gas_industry groupware maintenance_engineering petroleum_industry pumpsaugmented_reality_system_application augmented_reality_technology dynamic_modeling dynamic_simulation_system_collaboration equipment_maintenance gas_enterprises industrial_enterprise microsoft_hololens_2 oil_pump_maintenance pumping_equipment
132,Research On Virtual Restoration Display Of Chinese Paintings Based On Augmented Reality,"Zhong, Q., Wang, Q., Chen, H., Han, M., & Wang, G. (2023). Research On Virtual Restoration Display Of Chinese Paintings Based On Augmented Reality. 2023 4th International Conference on Computer Engineering and Application (ICCEA). https://doi.org/10.1109/iccea58433.2023.10135180
",10.1109/ICCEA58433.2023.10135180,"In response to the current problem that a large number of broken Chinese paintings cannot be exhibited, an AR restoration method is proposed that allows visitors to experience the restoration process and appreciate the restored works when they visit. Firstly, the damaged Chinese paintings are digitally restored; then the ORB(oriented fast and rotated brief) algorithm extracts more uniform feature points in terms of quantity and distribution through linear transformation image enhancement and improved adaptive thresholding to ensure the accurate overlay of AR virtual content through feature point matching; finally, the color of virtual content is corrected through histogram matching before the virtual-real overlay to ensure the consistency of AR virtual-real fusion. Finally, the color of the virtual content is corrected by histogram matching before the virtual-real superposition to ensure the consistency of AR virtual-real fusion. The experiments show that the method can effectively solve the problem that the broken paintings and calligraphy cannot be exhibited directly and can increase the participation and immersion of visitors.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality",accurate overlay;adaptive thresholding;AR restoration method;AR virtual content;AR virtual-real fusion;augmented reality;broken Chinese paintings;broken paintings;calligraphy;damaged Chinese paintings;feature point matching;histogram matching;linear transformation image enhancement;restoration process;restored works;rotated brief;uniform feature points;virtual restoration display;virtual-real overlay;virtual-real superposition,art;augmented reality;feature extraction;image enhancement;image matching;image restoration,2023,Conference article (CA),2023 4th International Conference on Computer Engineering and Application (ICCEA),"(1) Zhong, Q.; (1) Wang, Q.; (2) Chen, H.; (1) Han, M.; (1) Wang, G.; ","(1) China Agricultural University, China; (2) Beijing University of Posts and Telecommunications, China; ",IEEE,-1,"[""art"", ""feature extraction"", ""image enhancement"", ""image matching"", ""image restoration""]","[""art"", ""feature extraction"", ""image enhancement"", ""image matching"", ""image restoration""]",art;feature extraction;image enhancement;image matching;image restoration,construction;computer vision;chemical;liberal arts,technology;industries,construction;computer vision;chemical;liberal arts,technology;industries,art feature_extraction image_enhancement image_matching image_restoration accurate_overlay adaptive_thresholding ar_restoration_method ar_virtual_content ar_virtual real_fusion augmented_reality broken_chinese_paintings broken_paintings calligraphy damaged_chinese_paintings feature_point_matching histogram_matching linear_transformation_image_enhancement restoration_process restored_works rotated_brief uniform_feature_points virtual_restoration_display virtual real_overlay virtual real_superposition b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision chemical liberal_arts,art feature_extraction image_enhancement image_matching image_restoration,accurate_overlay adaptive_thresholding ar_restoration_method ar_virtual_content ar_virtual real_fusion augmented_reality broken_chinese_paintings broken_paintings calligraphy damaged_chinese_paintings feature_point_matching histogram_matching linear_transformation_image_enhancement restoration_process restored_works rotated_brief uniform_feature_points virtual_restoration_display virtual real_overlay virtual real_superposition,response current problem large number broken chinese painting cannot exhibited ar restoration method proposed allows visitor experience restoration process appreciate restored work visit firstly damaged chinese painting digitally restored orb oriented fast rotated brief algorithm extract uniform feature point term quantity distribution linear transformation image enhancement improved adaptive thresholding ensure accurate overlay ar virtual content feature point matching finally color virtual content corrected histogram matching virtual real overlay ensure consistency ar virtual real fusion finally color virtual content corrected histogram matching virtual real superposition ensure consistency ar virtual real fusion experiment show method effectively solve problem broken painting calligraphy cannot exhibited directly increase participation immersion visitor,art feature_extraction image_enhancement image_matching image_restoration accurate_overlay adaptive_thresholding ar_restoration_method ar_virtual_content ar_virtual real_fusion augmented_reality broken_chinese_paintings broken_paintings calligraphy damaged_chinese_paintings feature_point_matching histogram_matching linear_transformation_image_enhancement restoration_process restored_works rotated_brief uniform_feature_points virtual_restoration_display virtual real_overlay virtual real_superposition b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision chemical liberal_arts response current problem large number broken chinese painting cannot exhibited ar restoration method proposed allows visitor experience restoration process appreciate restored work visit firstly damaged chinese painting digitally restored orb oriented fast rotated brief algorithm extract uniform feature point term quantity distribution linear transformation image enhancement improved adaptive thresholding ensure accurate overlay ar virtual content feature point matching finally color virtual content corrected histogram matching virtual real overlay ensure consistency ar virtual real fusion finally color virtual content corrected histogram matching virtual real superposition ensure consistency ar virtual real fusion experiment show method effectively solve problem broken painting calligraphy cannot exhibited directly increase participation immersion visitor,response current problem large number broken chinese painting cannot exhibited ar restoration method proposed allows visitor experience restoration process appreciate restored work visit firstly damaged chinese painting digitally restored orb oriented fast rotated brief algorithm extract uniform feature point term quantity distribution linear transformation image enhancement improved adaptive thresholding ensure accurate overlay ar virtual content feature point matching finally color virtual content corrected histogram matching virtual real overlay ensure consistency ar virtual real fusion finally color virtual content corrected histogram matching virtual real superposition ensure consistency ar virtual real fusion experiment show method effectively solve problem broken painting calligraphy cannot exhibited directly increase participation immersion visitorart feature_extraction image_enhancement image_matching image_restorationaccurate_overlay adaptive_thresholding ar_restoration_method ar_virtual_content ar_virtual real_fusion augmented_reality broken_chinese_paintings broken_paintings calligraphy damaged_chinese_paintings feature_point_matching histogram_matching linear_transformation_image_enhancement restoration_process restored_works rotated_brief uniform_feature_points virtual_restoration_display virtual real_overlay virtual real_superposition
133,Prototype of augmented reality technology for orthodontic bracket positioning: an in vivo study,"Lo, Y.-C., Chen, G.-A., Liu, Y.-C., Chen, Y.-H., Hsu, J.-T., & Yu, J.-H. (2021). Prototype of Augmented Reality Technology for Orthodontic Bracket Positioning: An In Vivo Study. Applied Sciences, 11(5), 2315. https://doi.org/10.3390/app11052315
",10.3390/app11052315,"To improve the accuracy of bracket placement in vivo, a protocol and device were introduced, which consisted of operative procedures for accurate control, a computer-aided design, and an augmented reality-assisted bracket navigation system. The present study evaluated the accuracy of this protocol. Methods: Thirty-one incisor teeth were tested from four participators. The teeth were bonded by novice and expert orthodontists. Compared with the control group by Boone gauge and the experiment group by augmented reality-assisted bracket navigation system, our study used for brackets measurement. To evaluate the accuracy, deviations of positions for bracket placement were measured. Results: The augmented reality-assisted bracket navigation system and control group were used in the same 31 cases. The priority of bonding brackets between control group or experiment group was decided by tossing coins, and then the teeth were debonded and the other technique was used. The medium vertical (incisogingival) position deviation in the control and AR groups by the novice orthodontist was 0.90 &#177; 0.06 mm and 0.51 &#177; 0.24 mm, respectively (p &lt; 0.05), and by the expert orthodontist was 0.40 &#177; 0.29 mm and 0.29 &#177; 0.08 mm, respectively (p &lt; 0.05). No significant changes in the horizontal position deviation were noted regardless of the orthodontist experience or use of the augmented reality-assisted bracket navigation system. Conclusion: The augmented reality-assisted bracket navigation system increased the accuracy rate by the expert orthodontist in the incisogingival direction and helped the novice orthodontist guide the bracket position within an acceptable clinical error of approximately 0.5 mm.",A8770J Prosthetics and other practical applications;B7520E Prosthetics and orthotics;C6130V Virtual reality;C7330 Biology and medical computing,acceptable clinical error;augmented reality-assisted bracket navigation system;Boone gauge;bracket placement;brackets measurement;computer-aided design;control group;orthodontic bracket positioning,augmented reality;biomechanics;dentistry;medical computing;orthotics;patient treatment,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Lo, Y.-C.; (4) Chen, G.-A.; (4) Liu, Y.-C.; (2) Chen, Y.-H.; (1) Hsu, J.-T.; (1) Yu, J.-H.; ","(1) China Medical University, School of Dentistry, Taiwan; (2) China Medical University, Department of Orthodontics, Taiwan; (3) Asia University, Department of Dentistry, Taiwan; (4) Industrial Technology Research Institute, Intelligent Medical & Healthcare System Department, Taiwan; (5) Asia University, Department of Bioinformatics and Medical Engineering, Taiwan; ",MDPI,-1,"[""biomechanics"", ""dentistry"", ""medical computing"", ""orthotics"", ""patient treatment""]","[""biomechanics"", ""dentistry"", ""medical computing"", ""orthotics"", ""patient treatment""]",biomechanics;dentistry;medical computing;orthotics;patient treatment,medical,industries,medical,industries,biomechanics dentistry medical_computing orthotics patient_treatment acceptable_clinical_error augmented_reality assisted_bracket_navigation_system boone_gauge bracket_placement brackets_measurement computer aided_design control_group orthodontic_bracket_positioning a8770j_prosthetics_and_other_practical_applications b7520e_prosthetics_and_orthotics c6130v_virtual_reality c7330_biology_and_medical_computing medical,biomechanics dentistry medical_computing orthotics patient_treatment,acceptable_clinical_error augmented_reality assisted_bracket_navigation_system boone_gauge bracket_placement brackets_measurement computer aided_design control_group orthodontic_bracket_positioning,improve accuracy bracket placement vivo protocol device introduced consisted operative procedure accurate control computer aided design augmented reality assisted bracket navigation system present study evaluated accuracy protocol method thirty one incisor teeth tested four participators teeth bonded novice expert orthodontist compared control group boone gauge experiment group augmented reality assisted bracket navigation system study used bracket measurement evaluate accuracy deviation position bracket placement measured result augmented reality assisted bracket navigation system control group used 31 case priority bonding bracket control group experiment group decided tossing coin teeth debonded technique used medium vertical incisogingival position deviation control ar group novice orthodontist 0 90 177 0 06 mm 0 51 177 0 24 mm respectively p lt 0 05 expert orthodontist 0 40 177 0 29 mm 0 29 177 0 08 mm respectively p lt 0 05 significant change horizontal position deviation noted regardless orthodontist experience use augmented reality assisted bracket navigation system conclusion augmented reality assisted bracket navigation system increased accuracy rate expert orthodontist incisogingival direction helped novice orthodontist guide bracket position within acceptable clinical error approximately 0 5 mm,biomechanics dentistry medical_computing orthotics patient_treatment acceptable_clinical_error augmented_reality assisted_bracket_navigation_system boone_gauge bracket_placement brackets_measurement computer aided_design control_group orthodontic_bracket_positioning a8770j_prosthetics_and_other_practical_applications b7520e_prosthetics_and_orthotics c6130v_virtual_reality c7330_biology_and_medical_computing medical improve accuracy bracket placement vivo protocol device introduced consisted operative procedure accurate control computer aided design augmented reality assisted bracket navigation system present study evaluated accuracy protocol method thirty one incisor teeth tested four participators teeth bonded novice expert orthodontist compared control group boone gauge experiment group augmented reality assisted bracket navigation system study used bracket measurement evaluate accuracy deviation position bracket placement measured result augmented reality assisted bracket navigation system control group used 31 case priority bonding bracket control group experiment group decided tossing coin teeth debonded technique used medium vertical incisogingival position deviation control ar group novice orthodontist 0 90 177 0 06 mm 0 51 177 0 24 mm respectively p lt 0 05 expert orthodontist 0 40 177 0 29 mm 0 29 177 0 08 mm respectively p lt 0 05 significant change horizontal position deviation noted regardless orthodontist experience use augmented reality assisted bracket navigation system conclusion augmented reality assisted bracket navigation system increased accuracy rate expert orthodontist incisogingival direction helped novice orthodontist guide bracket position within acceptable clinical error approximately 0 5 mm,improve accuracy bracket placement vivo protocol device introduced consisted operative procedure accurate control computer aided design augmented reality assisted bracket navigation system present study evaluated accuracy protocol method thirty one incisor teeth tested four participators teeth bonded novice expert orthodontist compared control group boone gauge experiment group augmented reality assisted bracket navigation system study used bracket measurement evaluate accuracy deviation position bracket placement measured result augmented reality assisted bracket navigation system control group used 31 case priority bonding bracket control group experiment group decided tossing coin teeth debonded technique used medium vertical incisogingival position deviation control ar group novice orthodontist 0 90 177 0 06 mm 0 51 177 0 24 mm respectively p lt 0 05 expert orthodontist 0 40 177 0 29 mm 0 29 177 0 08 mm respectively p lt 0 05 significant change horizontal position deviation noted regardless orthodontist experience use augmented reality assisted bracket navigation system conclusion augmented reality assisted bracket navigation system increased accuracy rate expert orthodontist incisogingival direction helped novice orthodontist guide bracket position within acceptable clinical error approximately 0 5 mmbiomechanics dentistry medical_computing orthotics patient_treatmentacceptable_clinical_error augmented_reality assisted_bracket_navigation_system boone_gauge bracket_placement brackets_measurement computer aided_design control_group orthodontic_bracket_positioning
134,Designing interactive augmented reality application for student's directed learning of continuous distillation process,"Gao, S., Lu, Y., Ooi, C. H., Cai, Y., & Gunawan, P. (2023). Designing interactive augmented reality application for student’s directed learning of continuous distillation process. Computers &amp; Chemical Engineering, 169, 108086. https://doi.org/10.1016/j.compchemeng.2022.108086
",10.1016/j.compchemeng.2022.108086,"Continuous distillation is an important separation process in chemical engineering curriculum. Conventionally, it is often taught as black box diagrams that lack user visibility, thus preventing students from developing a deeper understanding and comprehension. This paper presents the technical development of the mobile AR application and its implementation in the curriculum of Chemical Engineering Unit Operations at Nanyang Technological University Singapore. The mobile AR application is to provide interactive visualization and real-time numerical simulation to promote students' active learning in the classroom. The results of the pre-test and post-test indicated that the AR application helped students gain a better understanding of the principle and fundamental concepts of the distillation process. The evaluation survey with 6-point likert scale questions shows that students had a positive experience using the mobile AR application and it has enhanced their learning experience, as suggested by a mean evaluation score of 5.18 out of 6.0. All rights reserved Elsevier.",C6130V Virtual reality;C6130B Graphics techniques;C7810C Computer-aided instruction,black box diagrams;chemical engineering curriculum;Chemical Engineering Unit Operations;continuous distillation process;designing interactive augmented reality application;important separation process;interactive visualization;learning experience;mobile AR application;Nanyang Technological University Singapore;real-time numerical simulation;student;students;technical development;user visibility,augmented reality;chemical engineering;computer aided instruction;data visualisation;distillation;educational courses;educational institutions;engineering education,2023,Journal article (JA),Comput. Chem. Eng. (Netherlands),"(1) Gao, S.; (2) Lu, Y.; (3) Ooi, C.H.; (3) Cai, Y.; (2) Gunawan, P.; ","(1) Nanyang Technological University, School of Computer Science & Engineering, 50 Nanyang Avenue, Singapore; (2) Nanyang Technological University, School of Chemistry, Singapore; (3) Nanyang Technological University, School of Mechanical & Aerospace Engineering, 50 Nanyang Avenue, Singapore; ",Elsevier B.V.,-1,"[""chemical engineering"", ""computer aided instruction"", ""data visualization"", ""distillation"", ""educational courses"", ""educational institutions"", ""engineering education""]","[""chemical engineering"", ""computer aided instruction"", ""data visualization"", ""distillation"", ""educational courses"", ""educational institutions"", ""engineering education""]",chemical engineering;computer aided instruction;data visualization;distillation;educational courses;educational institutions;engineering education,other;education;data;training,technology;other;use cases;industries,other;education;data;training,technology;other;use cases;industries,chemical_engineering computer_aided_instruction data_visualization distillation educational_courses educational_institutions engineering_education black_box_diagrams chemical_engineering_curriculum chemical_engineering_unit_operations continuous_distillation_process designing_interactive_augmented_reality_application important_separation_process interactive_visualization learning_experience mobile_ar_application nanyang_technological_university_singapore real time_numerical_simulation student students technical_development user_visibility c6130v_virtual_reality c6130b_graphics_techniques c7810c_computer aided_instruction other education data training,chemical_engineering computer_aided_instruction data_visualization distillation educational_courses educational_institutions engineering_education,black_box_diagrams chemical_engineering_curriculum chemical_engineering_unit_operations continuous_distillation_process designing_interactive_augmented_reality_application important_separation_process interactive_visualization learning_experience mobile_ar_application nanyang_technological_university_singapore real time_numerical_simulation student students technical_development user_visibility,continuous distillation important separation process chemical engineering curriculum conventionally often taught black box diagram lack user visibility thus preventing student developing deeper understanding comprehension paper present technical development mobile ar application implementation curriculum chemical engineering unit operation nanyang technological university singapore mobile ar application provide interactive visualization real time numerical simulation promote student active learning classroom result pre test post test indicated ar application helped student gain better understanding principle fundamental concept distillation process evaluation survey 6 point likert scale question show student positive experience using mobile ar application enhanced learning experience suggested mean evaluation score 5 18 6 0 right reserved elsevier,chemical_engineering computer_aided_instruction data_visualization distillation educational_courses educational_institutions engineering_education black_box_diagrams chemical_engineering_curriculum chemical_engineering_unit_operations continuous_distillation_process designing_interactive_augmented_reality_application important_separation_process interactive_visualization learning_experience mobile_ar_application nanyang_technological_university_singapore real time_numerical_simulation student students technical_development user_visibility c6130v_virtual_reality c6130b_graphics_techniques c7810c_computer aided_instruction other education data training continuous distillation important separation process chemical engineering curriculum conventionally often taught black box diagram lack user visibility thus preventing student developing deeper understanding comprehension paper present technical development mobile ar application implementation curriculum chemical engineering unit operation nanyang technological university singapore mobile ar application provide interactive visualization real time numerical simulation promote student active learning classroom result pre test post test indicated ar application helped student gain better understanding principle fundamental concept distillation process evaluation survey 6 point likert scale question show student positive experience using mobile ar application enhanced learning experience suggested mean evaluation score 5 18 6 0 right reserved elsevier,continuous distillation important separation process chemical engineering curriculum conventionally often taught black box diagram lack user visibility thus preventing student developing deeper understanding comprehension paper present technical development mobile ar application implementation curriculum chemical engineering unit operation nanyang technological university singapore mobile ar application provide interactive visualization real time numerical simulation promote student active learning classroom result pre test post test indicated ar application helped student gain better understanding principle fundamental concept distillation process evaluation survey 6 point likert scale question show student positive experience using mobile ar application enhanced learning experience suggested mean evaluation score 5 18 6 0 right reserved elsevierchemical_engineering computer_aided_instruction data_visualization distillation educational_courses educational_institutions engineering_educationblack_box_diagrams chemical_engineering_curriculum chemical_engineering_unit_operations continuous_distillation_process designing_interactive_augmented_reality_application important_separation_process interactive_visualization learning_experience mobile_ar_application nanyang_technological_university_singapore real time_numerical_simulation student students technical_development user_visibility
135,Designing an Augmented Reality Authoring Tool to Support Complex Tasks. A Design Science Study Using Cognitive Load Theory,"Hönemann, K., Konopka, B., & Wiesche, M. (2023). Designing an Augmented Reality Authoring Tool to Support Complex Tasks. A Design Science Study Using Cognitive Load Theory. Design Science Research for a New Society: Society 5.0, 87–101. https://doi.org/10.1007/978-3-031-32808-4_6
",10.1007/978-3-031-32808-4_6,"Despite the potential of augmented reality (AR) to support and guide complex industrial tasks, the technology is still not broadly applied. One possible reason for this is that the creation of AR content is highly complex and requires programming skills and deep spatial knowledge. AR authoring tools can help address this complexity by enabling non-developers to create self-sufficient AR content. Therefore, this paper proposes a theory-driven design for AR authoring tools that allows non-developers to create self-sufficient AR-based instructions to support complex tasks. Based on ten interviews with experts working with AR authoring tools and a following focus group with eight participants, we propose three design principles for future AR authoring tools in the engineering context. These design principles are instantiated in two prototypes of different richness and evaluated in an experiment with 23 students. Our study shows that the cognitive load is slightly increased when using the extensive AR authoring tool, but it also shows that significantly better results can be achieved with the extensive AR authoring tool. We contribute by providing design principles for AR authoring tools for creating AR-based instructions, which extend the existing AR authoring research in the industrial context. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;901.3 Engineering Research;912.1 Industrial Engineering",Augmented reality authoring;Augmented reality content;Authoring tool;Cognitive load theory;Complex task;Design Principles;Design science;Design-science researches;Industrial tasks;Science studies,Design;Industrial research,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) H&ouml;nemann, Kay; (1) Konopka, Bj&ouml;rn; (1) Wiesche, Manuel; ","(1) TU Dortmund University, Dortmund, Germany; ",Springer Science and Business Media Deutschland GmbH,-1,"[""design"", ""industrial research""]","[""design"", ""industrial research""]",design;industrial research,medical;education;human-computer interaction;business performance metrics,end users and user experience;business;industries,medical;education;human-computer interaction;business performance metrics,end users and user experience;business;industries,design industrial_research augmented_reality_authoring augmented_reality_content authoring_tool cognitive_load_theory complex_task design_principles design_science design science_researches industrial_tasks science_studies 723_computer_software _data_handling_and_applications 901 3_engineering_research 912 1_industrial_engineering medical education human computer_interaction business_performance_metrics,design industrial_research,augmented_reality_authoring augmented_reality_content authoring_tool cognitive_load_theory complex_task design_principles design_science design science_researches industrial_tasks science_studies,despite potential augmented reality ar support guide complex industrial task technology still broadly applied one possible reason creation ar content highly complex requires programming skill deep spatial knowledge ar authoring tool help address complexity enabling non developer create self sufficient ar content therefore paper proposes theory driven design ar authoring tool allows non developer create self sufficient ar based instruction support complex task based ten interview expert working ar authoring tool following focus group eight participant propose three design principle future ar authoring tool engineering context design principle instantiated two prototype different richness evaluated experiment 23 student study show cognitive load slightly increased using extensive ar authoring tool also show significantly better result achieved extensive ar authoring tool contribute providing design principle ar authoring tool creating ar based instruction extend existing ar authoring research industrial context copy 2023 author exclusive license springer nature switzerland ag,design industrial_research augmented_reality_authoring augmented_reality_content authoring_tool cognitive_load_theory complex_task design_principles design_science design science_researches industrial_tasks science_studies 723_computer_software _data_handling_and_applications 901 3_engineering_research 912 1_industrial_engineering medical education human computer_interaction business_performance_metrics despite potential augmented reality ar support guide complex industrial task technology still broadly applied one possible reason creation ar content highly complex requires programming skill deep spatial knowledge ar authoring tool help address complexity enabling non developer create self sufficient ar content therefore paper proposes theory driven design ar authoring tool allows non developer create self sufficient ar based instruction support complex task based ten interview expert working ar authoring tool following focus group eight participant propose three design principle future ar authoring tool engineering context design principle instantiated two prototype different richness evaluated experiment 23 student study show cognitive load slightly increased using extensive ar authoring tool also show significantly better result achieved extensive ar authoring tool contribute providing design principle ar authoring tool creating ar based instruction extend existing ar authoring research industrial context copy 2023 author exclusive license springer nature switzerland ag,despite potential augmented reality ar support guide complex industrial task technology still broadly applied one possible reason creation ar content highly complex requires programming skill deep spatial knowledge ar authoring tool help address complexity enabling non developer create self sufficient ar content therefore paper proposes theory driven design ar authoring tool allows non developer create self sufficient ar based instruction support complex task based ten interview expert working ar authoring tool following focus group eight participant propose three design principle future ar authoring tool engineering context design principle instantiated two prototype different richness evaluated experiment 23 student study show cognitive load slightly increased using extensive ar authoring tool also show significantly better result achieved extensive ar authoring tool contribute providing design principle ar authoring tool creating ar based instruction extend existing ar authoring research industrial context copy 2023 author exclusive license springer nature switzerland agdesign industrial_researchaugmented_reality_authoring augmented_reality_content authoring_tool cognitive_load_theory complex_task design_principles design_science design science_researches industrial_tasks science_studies
136,Design of Augmented Reality based Environment to Promote Spatial Imagination for Mathematics Education in Elementary School,"Javaheri, H., Lehmann, J., Altmeyer, K., Müller, L. M., Brünken, R., & Lukowicz, P. (2022). Design of Augmented Reality based Environment to Promote Spatial Imagination for Mathematics Education in Elementary School. Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3560380
",10.1145/3544793.3560380,"This paper investigates the use of augmented reality (AR) technology to deliver augmented lectures to support students in acquiring the curricular competency of using spatial imagination in mathematics education. As a very important stage in education to develop spatial abilities this paper focuses on elementary school children. Due to the challenges of working with children in experimental studies, this education level has received comparatively little attention in terms of support through ubiquitous technology. A theory-driven design approach was adopted in the development of an AR-based learning environment to visualize various virtual 3D cube buildings aligned with real blueprints. The designed environment was evaluated by a group of 1st and 2nd grade students in terms of system usability. The results showed that the theory-driven design was successful with a score of 86.56 on the System Usability test. In our future work, we aimed to assess the effectiveness of the proposed AR environment in terms of learning gains by performing more task-focused studies before and after experiment and comparing the results with the traditional teaching methods.",C7810C Computer-aided instruction;C6130B Graphics techniques;C6130V Virtual reality;C7310 Mathematics computing,1st grade students;2nd grade students;AR-based learning environment;augmented lectures;augmented reality based environment;curricular competency;education level;elementary school children;learning gains;mathematics education;spatial abilities;spatial imagination;system usability test;task-focused studies;teaching;theory-driven design approach;ubiquitous technology;virtual 3D cube buildings,augmented reality;computer aided instruction;data visualisation;educational courses;educational institutions;mathematics computing;solid modelling;teaching,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) Javaheri, H.; (2) Lehmann, J.; (2) Altmeyer, K.; (2) Mu&#776;ller, L.M.; (2) Bru&#776;nken, R.; (3) Lukowicz, P.; ","(1) German Research Centre for Artificial Intelligence, Germany; (2) Saarland University, Germany; (3) Deutsches Forschungszentrum fur Kunstliche Intelligenz GmbH, Germany; ",ACM,-1,"[""computer aided instruction"", ""data visualization"", ""educational courses"", ""educational institutions"", ""mathematics computing"", ""solid modelling"", ""teaching""]","[""computer aided instruction"", ""data visualization"", ""educational courses"", ""educational institutions"", ""mathematics computing"", ""solid modelling"", ""teaching""]",computer aided instruction;data visualization;educational courses;educational institutions;mathematics computing;solid modelling;teaching,education;training;engineering;data;manufacturing,technology;use cases;industries,education;training;engineering;data;manufacturing,technology;use cases;industries,computer_aided_instruction data_visualization educational_courses educational_institutions mathematics_computing solid_modelling teaching 1st_grade_students 2nd_grade_students ar based_learning_environment augmented_lectures augmented_reality_based_environment curricular_competency education_level elementary_school_children learning_gains mathematics_education spatial_abilities spatial_imagination system_usability_test task focused_studies teaching theory driven_design_approach ubiquitous_technology virtual_3d_cube_buildings c7810c_computer aided_instruction c6130b_graphics_techniques c6130v_virtual_reality c7310_mathematics_computing education training engineering data manufacturing,computer_aided_instruction data_visualization educational_courses educational_institutions mathematics_computing solid_modelling teaching,1st_grade_students 2nd_grade_students ar based_learning_environment augmented_lectures augmented_reality_based_environment curricular_competency education_level elementary_school_children learning_gains mathematics_education spatial_abilities spatial_imagination system_usability_test task focused_studies teaching theory driven_design_approach ubiquitous_technology virtual_3d_cube_buildings,paper investigates use augmented reality ar technology deliver augmented lecture support student acquiring curricular competency using spatial imagination mathematics education important stage education develop spatial ability paper focus elementary school child due challenge working child experimental study education level received comparatively little attention term support ubiquitous technology theory driven design approach adopted development ar based learning environment visualize various virtual 3d cube building aligned real blueprint designed environment evaluated group 1st 2nd grade student term system usability result showed theory driven design successful score 86 56 system usability test future work aimed ass effectiveness proposed ar environment term learning gain performing task focused study experiment comparing result traditional teaching method,computer_aided_instruction data_visualization educational_courses educational_institutions mathematics_computing solid_modelling teaching 1st_grade_students 2nd_grade_students ar based_learning_environment augmented_lectures augmented_reality_based_environment curricular_competency education_level elementary_school_children learning_gains mathematics_education spatial_abilities spatial_imagination system_usability_test task focused_studies teaching theory driven_design_approach ubiquitous_technology virtual_3d_cube_buildings c7810c_computer aided_instruction c6130b_graphics_techniques c6130v_virtual_reality c7310_mathematics_computing education training engineering data manufacturing paper investigates use augmented reality ar technology deliver augmented lecture support student acquiring curricular competency using spatial imagination mathematics education important stage education develop spatial ability paper focus elementary school child due challenge working child experimental study education level received comparatively little attention term support ubiquitous technology theory driven design approach adopted development ar based learning environment visualize various virtual 3d cube building aligned real blueprint designed environment evaluated group 1st 2nd grade student term system usability result showed theory driven design successful score 86 56 system usability test future work aimed ass effectiveness proposed ar environment term learning gain performing task focused study experiment comparing result traditional teaching method,paper investigates use augmented reality ar technology deliver augmented lecture support student acquiring curricular competency using spatial imagination mathematics education important stage education develop spatial ability paper focus elementary school child due challenge working child experimental study education level received comparatively little attention term support ubiquitous technology theory driven design approach adopted development ar based learning environment visualize various virtual 3d cube building aligned real blueprint designed environment evaluated group 1st 2nd grade student term system usability result showed theory driven design successful score 86 56 system usability test future work aimed ass effectiveness proposed ar environment term learning gain performing task focused study experiment comparing result traditional teaching methodcomputer_aided_instruction data_visualization educational_courses educational_institutions mathematics_computing solid_modelling teaching1st_grade_students 2nd_grade_students ar based_learning_environment augmented_lectures augmented_reality_based_environment curricular_competency education_level elementary_school_children learning_gains mathematics_education spatial_abilities spatial_imagination system_usability_test task focused_studies teaching theory driven_design_approach ubiquitous_technology virtual_3d_cube_buildings
137,"Assessing Enterprise Level, Augmented Reality Solutions for Electronics Manufacturing","Becerra, E. J., Hovanski, Y., Tenny, J., & Peterson, R. (2023). Assessing Enterprise Level, Augmented Reality Solutions for Electronics Manufacturing. SAE Technical Paper Series. https://doi.org/10.4271/2023-01-0098
",10.4271/2023-01-0098,"With the growth of Industry 4.0 in recent years, Augmented Reality (AR) technologies are changing the way operators work by increasing their efficiency and operational performance. A common use of AR is providing operators helpful work instructions for assembly by presenting relevant digital information in the context of the physical environment. These AR experiences can be viewed via several devices such as mobile, wearable, and stationary devices, each being useful for different applications. While in the experience, instructions are provided by means of 3D animation, text, images, and interactive buttons, all of which are directly overlaid onto the physical product or equipment being worked on. This work presents a closed-loop, enterprise connected, AR system for post end Printed Circuit Board (PCB) assembly work instructions. The system is designed to work with a stationary device, allows for varying types of PCB""s, provides overlaid instruction, and logs important information to an enterprise system, such as overall cycle time, step cycle time, number of errors, type of error, and who performed the assembly. A comparison was made for single cell manual assembly PCB work instructions using both an Industry 4.0 driven system and a more traditional manufacturing system which used packets, tracers, Manufacturing Execution System (MES), and PDF instructions. Discovered benefits of an enterprise connected AR system included increased throughput and utilization, improved communication between operators and support, reduced overtime costs, reduced defects, reduced non-value-added secondary inspections, nearly 50% increase in ergonomics, reduced labor due to rework, and improved corrective actions due to granularity between steps compared to total operation. This AR driven solution transformed the single cell manual assembly to be more informed, make better decisions, and help operator productivity. &copy; 2023 SAE International. All rights reserved.","723 Computer Software, Data Handling and Applications;913.4 Manufacturing",Augmented reality systems;Augmented reality technology;Cycle time;Digital information;Electronics manufacturing;Manual assembly;Operational performance;Single cells;Stationary devices;Work instructions,Assembly;Ergonomics;Industry 4.0;Printed circuit boards,2023,Conference article (CA),SAE Techni. Paper.,"(1) Becerra, Elijah James; (1) Hovanski, Yuri; (2) Tenny, Joe; (2) Peterson, Rebecca; ","(1) Brigham Young University, United States; (2) Northrop Grumman Corporation, United States; ",SAE International,-1,"[""assembly"", ""ergonomics"", ""industry 4.0"", ""printed circuit boards""]","[""assembly"", ""ergonomics"", ""industry 4.0"", ""printed circuit boards""]",assembly;ergonomics;industry 4.0;printed circuit boards,human factors;semiconductors;manufacturing;internet of things,technology;industries;end users and user experience,human factors;semiconductors;manufacturing;internet of things,technology;industries;end users and user experience,assembly ergonomics industry_4 0 printed_circuit_boards augmented_reality_systems augmented_reality_technology cycle_time digital_information electronics_manufacturing manual_assembly operational_performance single_cells stationary_devices work_instructions 723_computer_software _data_handling_and_applications 913 4_manufacturing human_factors semiconductors manufacturing internet_of_things,assembly ergonomics industry_4 0 printed_circuit_boards,augmented_reality_systems augmented_reality_technology cycle_time digital_information electronics_manufacturing manual_assembly operational_performance single_cells stationary_devices work_instructions,growth industry 4 0 recent year augmented reality ar technology changing way operator work increasing efficiency operational performance common use ar providing operator helpful work instruction assembly presenting relevant digital information context physical environment ar experience viewed via several device mobile wearable stationary device useful different application experience instruction provided mean 3d animation text image interactive button directly overlaid onto physical product equipment worked work present closed loop enterprise connected ar system post end printed circuit board pcb assembly work instruction system designed work stationary device allows varying type pcb provides overlaid instruction log important information enterprise system overall cycle time step cycle time number error type error performed assembly comparison made single cell manual assembly pcb work instruction using industry 4 0 driven system traditional manufacturing system used packet tracer manufacturing execution system me pdf instruction discovered benefit enterprise connected ar system included increased throughput utilization improved communication operator support reduced overtime cost reduced defect reduced non value added secondary inspection nearly 50 increase ergonomics reduced labor due rework improved corrective action due granularity step compared total operation ar driven solution transformed single cell manual assembly informed make better decision help operator productivity copy 2023 sae international right reserved,assembly ergonomics industry_4 0 printed_circuit_boards augmented_reality_systems augmented_reality_technology cycle_time digital_information electronics_manufacturing manual_assembly operational_performance single_cells stationary_devices work_instructions 723_computer_software _data_handling_and_applications 913 4_manufacturing human_factors semiconductors manufacturing internet_of_things growth industry 4 0 recent year augmented reality ar technology changing way operator work increasing efficiency operational performance common use ar providing operator helpful work instruction assembly presenting relevant digital information context physical environment ar experience viewed via several device mobile wearable stationary device useful different application experience instruction provided mean 3d animation text image interactive button directly overlaid onto physical product equipment worked work present closed loop enterprise connected ar system post end printed circuit board pcb assembly work instruction system designed work stationary device allows varying type pcb provides overlaid instruction log important information enterprise system overall cycle time step cycle time number error type error performed assembly comparison made single cell manual assembly pcb work instruction using industry 4 0 driven system traditional manufacturing system used packet tracer manufacturing execution system me pdf instruction discovered benefit enterprise connected ar system included increased throughput utilization improved communication operator support reduced overtime cost reduced defect reduced non value added secondary inspection nearly 50 increase ergonomics reduced labor due rework improved corrective action due granularity step compared total operation ar driven solution transformed single cell manual assembly informed make better decision help operator productivity copy 2023 sae international right reserved,growth industry 4 0 recent year augmented reality ar technology changing way operator work increasing efficiency operational performance common use ar providing operator helpful work instruction assembly presenting relevant digital information context physical environment ar experience viewed via several device mobile wearable stationary device useful different application experience instruction provided mean 3d animation text image interactive button directly overlaid onto physical product equipment worked work present closed loop enterprise connected ar system post end printed circuit board pcb assembly work instruction system designed work stationary device allows varying type pcb provides overlaid instruction log important information enterprise system overall cycle time step cycle time number error type error performed assembly comparison made single cell manual assembly pcb work instruction using industry 4 0 driven system traditional manufacturing system used packet tracer manufacturing execution system me pdf instruction discovered benefit enterprise connected ar system included increased throughput utilization improved communication operator support reduced overtime cost reduced defect reduced non value added secondary inspection nearly 50 increase ergonomics reduced labor due rework improved corrective action due granularity step compared total operation ar driven solution transformed single cell manual assembly informed make better decision help operator productivity copy 2023 sae international right reservedassembly ergonomics industry_4 0 printed_circuit_boardsaugmented_reality_systems augmented_reality_technology cycle_time digital_information electronics_manufacturing manual_assembly operational_performance single_cells stationary_devices work_instructions
138,Intraocular augmented reality display with retinal prosthesis,"Zou, S. P., Xi, N., Ye, J., Chen, C. P., Chu, Q., & Hu, H. (2023). Intraocular augmented reality display with retinal prosthesis. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2648010
",10.1117/12.2648010,"We present an intraocular augmented reality display featuring retinal prostheses in association with bionic vision processing. Unlike conventional retinal prostheses, whose electrodes are spaced equidistantly, our solution is to rearrange the electrodes to match the distribution of ganglion cells. To naturally imitate the human vision, a scheme of bionic vision processing is developed. On top of a three-dimensional eye model, our bionic vision processing is able to visualize the monocular image, binocular image fusion, and parallax-induced depth map. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;462.4 Prosthetics;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;741.1 Light/Optics",Bionic vision processing;Depthmap;Eye model;Ganglia cells;Human vision;Intraocular;Intraocular display;Monocular image;Retinal prosthesis;Vision processing,Augmented reality;Bionics;Electrodes;Image fusion;Ophthalmology;Prosthetics,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zou, Seak Pang; (1) Xi, Ning; (1) Ye, Jiaxun; (1) Chen, Chao Ping; (1) Chu, Qiang; (1) Hu, Haiyang; ","(1) Smart Display Lab, Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; ",SPIE,-1,"[""bionics"", ""electrodes"", ""image fusion"", ""ophthalmology"", ""prosthetics""]","[""bionics"", ""electrodes"", ""image fusion"", ""ophthalmology"", ""prosthetics""]",bionics;electrodes;image fusion;ophthalmology;prosthetics,medical;computer vision;other,technology;other;industries,medical;computer vision;other,technology;other;industries,bionics electrodes image_fusion ophthalmology prosthetics bionic_vision_processing depthmap eye_model ganglia_cells human_vision intraocular intraocular_display monocular_image retinal_prosthesis vision_processing 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 462 4_prosthetics 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics medical computer_vision other,bionics electrodes image_fusion ophthalmology prosthetics,bionic_vision_processing depthmap eye_model ganglia_cells human_vision intraocular intraocular_display monocular_image retinal_prosthesis vision_processing,present intraocular augmented reality display featuring retinal prosthesis association bionic vision processing unlike conventional retinal prosthesis whose electrode spaced equidistantly solution rearrange electrode match distribution ganglion cell naturally imitate human vision scheme bionic vision processing developed top three dimensional eye model bionic vision processing able visualize monocular image binocular image fusion parallax induced depth map copy 2023 spie,bionics electrodes image_fusion ophthalmology prosthetics bionic_vision_processing depthmap eye_model ganglia_cells human_vision intraocular intraocular_display monocular_image retinal_prosthesis vision_processing 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 462 4_prosthetics 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics medical computer_vision other present intraocular augmented reality display featuring retinal prosthesis association bionic vision processing unlike conventional retinal prosthesis whose electrode spaced equidistantly solution rearrange electrode match distribution ganglion cell naturally imitate human vision scheme bionic vision processing developed top three dimensional eye model bionic vision processing able visualize monocular image binocular image fusion parallax induced depth map copy 2023 spie,present intraocular augmented reality display featuring retinal prosthesis association bionic vision processing unlike conventional retinal prosthesis whose electrode spaced equidistantly solution rearrange electrode match distribution ganglion cell naturally imitate human vision scheme bionic vision processing developed top three dimensional eye model bionic vision processing able visualize monocular image binocular image fusion parallax induced depth map copy 2023 spiebionics electrodes image_fusion ophthalmology prostheticsbionic_vision_processing depthmap eye_model ganglia_cells human_vision intraocular intraocular_display monocular_image retinal_prosthesis vision_processing
139,A web-based campus navigation system with mobile augmented reality intervention,"Nordin, N., Markom, M. A., Suhaimi, F. A., & Ishak, S. (2021). A Web-Based Campus Navigation System with Mobile Augmented Reality Intervention. Journal of Physics: Conference Series, 1997(1), 012038. https://doi.org/10.1088/1742-6596/1997/1/012038
",10.1088/1742-6596/1997/1/012038,"In this era of information technology, the introduction of new and greatly improved technologies is becoming vital especially with the progressive development of computing power to fulfill current technological needs. Augmented Reality (AR) is a part of the emerging technologies that are gaining great attention and interest with new and better innovations being developed. AR is an immersive technology where it complements real-world objects together with computer-generated objects to give more details and meaning to the objects in the real world. AR has been successfully growing nowadays in many industries, mainly in gaming and entertainment, education and navigation. However, AR has not been standardized and to be widely used in navigation systems even though there are many applications developed for this purpose. This paper proposed a web-based AR-UUM Campus Navigation System using ARToolKit, that is accessible via mobile devices that uses AR to overlay the information as images of the searched location on campus, especially for indoor navigations for lecture halls, tutorial rooms, laboratories, and offices which rarely are covered by the normal maps. Based on the respondents' evaluation, they managed to successfully interact with the AR-UUM Campus Navigation System, however, some improvements are required in terms of the functions expected from the system. Nevertheless, the use of AR in a navigation system shows promising results and has the potential to be widely used due to high interest in augmented reality.","C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",education;greatly improved technologies;immersive technology;indoor navigations;information technology;mobile augmented reality intervention;mobile devices;progressive development,augmented reality;educational institutions;mobile computing,2021,Conference article (CA),"J. Phys., Conf. Ser. (UK)","(1) Nordin, N.; (2) Markom, M.A.; (1) Suhaimi, F.A.; (1) Ishak, S.; ","(1) Universiti Utara Malaysia, School of Computing, Kedah, Malaysia; (2) Universiti Malaysia Perlis, Center of Excellence, Kampus Pauh Putra, Perlis, Malaysia; ",IOP Publishing,-1,"[""educational institutions"", ""mobile computing""]","[""educational institutions"", ""mobile computing""]",educational institutions;mobile computing,education;telecommunication,industries,education;telecommunication,industries,educational_institutions mobile_computing education greatly_improved_technologies immersive_technology indoor_navigations information_technology mobile_augmented_reality_intervention mobile_devices progressive_development c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing education telecommunication,educational_institutions mobile_computing,education greatly_improved_technologies immersive_technology indoor_navigations information_technology mobile_augmented_reality_intervention mobile_devices progressive_development,era information technology introduction new greatly improved technology becoming vital especially progressive development computing power fulfill current technological need augmented reality ar part emerging technology gaining great attention interest new better innovation developed ar immersive technology complement real world object together computer generated object give detail meaning object real world ar successfully growing nowadays many industry mainly gaming entertainment education navigation however ar standardized widely used navigation system even though many application developed purpose paper proposed web based ar uum campus navigation system using artoolkit accessible via mobile device us ar overlay information image searched location campus especially indoor navigation lecture hall tutorial room laboratory office rarely covered normal map based respondent evaluation managed successfully interact ar uum campus navigation system however improvement required term function expected system nevertheless use ar navigation system show promising result potential widely used due high interest augmented reality,educational_institutions mobile_computing education greatly_improved_technologies immersive_technology indoor_navigations information_technology mobile_augmented_reality_intervention mobile_devices progressive_development c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing education telecommunication era information technology introduction new greatly improved technology becoming vital especially progressive development computing power fulfill current technological need augmented reality ar part emerging technology gaining great attention interest new better innovation developed ar immersive technology complement real world object together computer generated object give detail meaning object real world ar successfully growing nowadays many industry mainly gaming entertainment education navigation however ar standardized widely used navigation system even though many application developed purpose paper proposed web based ar uum campus navigation system using artoolkit accessible via mobile device us ar overlay information image searched location campus especially indoor navigation lecture hall tutorial room laboratory office rarely covered normal map based respondent evaluation managed successfully interact ar uum campus navigation system however improvement required term function expected system nevertheless use ar navigation system show promising result potential widely used due high interest augmented reality,era information technology introduction new greatly improved technology becoming vital especially progressive development computing power fulfill current technological need augmented reality ar part emerging technology gaining great attention interest new better innovation developed ar immersive technology complement real world object together computer generated object give detail meaning object real world ar successfully growing nowadays many industry mainly gaming entertainment education navigation however ar standardized widely used navigation system even though many application developed purpose paper proposed web based ar uum campus navigation system using artoolkit accessible via mobile device us ar overlay information image searched location campus especially indoor navigation lecture hall tutorial room laboratory office rarely covered normal map based respondent evaluation managed successfully interact ar uum campus navigation system however improvement required term function expected system nevertheless use ar navigation system show promising result potential widely used due high interest augmented realityeducational_institutions mobile_computingeducation greatly_improved_technologies immersive_technology indoor_navigations information_technology mobile_augmented_reality_intervention mobile_devices progressive_development
140,Physical and Augmented Reality based Playful Activities for Refresher Training of ASHA Workers in India,"Majhi, A., Agnihotri, S., & Mondal, A. (2022). Physical and Augmented Reality based Playful Activities for Refresher Training of ASHA Workers in India. Asian HCI Symposium ’22. https://doi.org/10.1145/3516492.3558788
",10.1145/3516492.3558788,"Recent health surveys in India highlight the alarming child malnutrition levels and lower rates of complete child immunization in many parts of India. Previous researches report that the conventional training pedagogy of the CHWs (Community Healthcare Workers) or the ASHAs (Accredited Social Health Activists) in India is ineffective in enhancing their capacity. Considering that the CHWs are getting equipped with smartphones, it calls for a rethinking of their training pedagogy using the ICT approach. Two refresher training tools were developed to make learning the child immunization schedule more exciting and conceptually engaging for ASHAs. The physical and AR (Augmented Reality) versions of designed card games were compared for effectiveness and knowledge retention, pre, and post-intervention through questionnaire tests conducted immediately before and after playing multiple sessions. The AR-based play was found to be better in learning and knowledge retention with more engagement, mainly due to its interactive and intuitive nature of play.",C7810C Computer-aided instruction;C6130V Virtual reality;C7330 Biology and medical computing,AR-based play;ASHA Workers;ASHAs;Augmented Reality;card games;child immunization schedule;child malnutrition levels;CHWs;Community Healthcare Workers;complete child immunization;conventional training pedagogy;ICT approach;India;knowledge retention;physical reality;playful activities;refresher training tools;Social Health Activists;training pedagogy,augmented reality;biomedical education;computer based training;health care;medical computing;personnel;scheduling;smart phones,2022,Conference article (CA),CHI22: Asian HCI Symposium'22,"(1) Majhi, A.; (1) Agnihotri, S.; (2) Mondal, A.; ","(1) Centre for Technology Alternatives for Rural Areas, India; (2) Centre for Policy Studies, India; ",ACM,-1,"[""biomedical education"", ""computer based training"", ""health care"", ""medical computing"", ""personnel"", ""scheduling"", ""smartphones""]","[""biomedical education"", ""computer based training"", ""health care"", ""medical computing"", ""personnel"", ""scheduling"", ""smartphones""]",biomedical education;computer based training;health care;medical computing;personnel;scheduling;smartphones,education;farming and natural science;liberal arts;medical;training;telecommunication;developers;human resources,technology;business;use cases;industries,education;farming and natural science;liberal arts;medical;training;telecommunication;developers;human resources,technology;business;use cases;industries,biomedical_education computer_based_training health_care medical_computing personnel scheduling smartphones ar based_play asha_workers ashas augmented_reality card_games child_immunization_schedule child_malnutrition_levels chws community_healthcare_workers complete_child_immunization conventional_training_pedagogy ict_approach india knowledge_retention physical_reality playful_activities refresher_training_tools social_health_activists training_pedagogy c7810c_computer aided_instruction c6130v_virtual_reality c7330_biology_and_medical_computing education farming_and_natural_science liberal_arts medical training telecommunication developers human_resources,biomedical_education computer_based_training health_care medical_computing personnel scheduling smartphones,ar based_play asha_workers ashas augmented_reality card_games child_immunization_schedule child_malnutrition_levels chws community_healthcare_workers complete_child_immunization conventional_training_pedagogy ict_approach india knowledge_retention physical_reality playful_activities refresher_training_tools social_health_activists training_pedagogy,recent health survey india highlight alarming child malnutrition level lower rate complete child immunization many part india previous research report conventional training pedagogy chws community healthcare worker ashas accredited social health activist india ineffective enhancing capacity considering chws getting equipped smartphones call rethinking training pedagogy using ict approach two refresher training tool developed make learning child immunization schedule exciting conceptually engaging ashas physical ar augmented reality version designed card game compared effectiveness knowledge retention pre post intervention questionnaire test conducted immediately playing multiple session ar based play found better learning knowledge retention engagement mainly due interactive intuitive nature play,biomedical_education computer_based_training health_care medical_computing personnel scheduling smartphones ar based_play asha_workers ashas augmented_reality card_games child_immunization_schedule child_malnutrition_levels chws community_healthcare_workers complete_child_immunization conventional_training_pedagogy ict_approach india knowledge_retention physical_reality playful_activities refresher_training_tools social_health_activists training_pedagogy c7810c_computer aided_instruction c6130v_virtual_reality c7330_biology_and_medical_computing education farming_and_natural_science liberal_arts medical training telecommunication developers human_resources recent health survey india highlight alarming child malnutrition level lower rate complete child immunization many part india previous research report conventional training pedagogy chws community healthcare worker ashas accredited social health activist india ineffective enhancing capacity considering chws getting equipped smartphones call rethinking training pedagogy using ict approach two refresher training tool developed make learning child immunization schedule exciting conceptually engaging ashas physical ar augmented reality version designed card game compared effectiveness knowledge retention pre post intervention questionnaire test conducted immediately playing multiple session ar based play found better learning knowledge retention engagement mainly due interactive intuitive nature play,recent health survey india highlight alarming child malnutrition level lower rate complete child immunization many part india previous research report conventional training pedagogy chws community healthcare worker ashas accredited social health activist india ineffective enhancing capacity considering chws getting equipped smartphones call rethinking training pedagogy using ict approach two refresher training tool developed make learning child immunization schedule exciting conceptually engaging ashas physical ar augmented reality version designed card game compared effectiveness knowledge retention pre post intervention questionnaire test conducted immediately playing multiple session ar based play found better learning knowledge retention engagement mainly due interactive intuitive nature playbiomedical_education computer_based_training health_care medical_computing personnel scheduling smartphonesar based_play asha_workers ashas augmented_reality card_games child_immunization_schedule child_malnutrition_levels chws community_healthcare_workers complete_child_immunization conventional_training_pedagogy ict_approach india knowledge_retention physical_reality playful_activities refresher_training_tools social_health_activists training_pedagogy
141,Compact digital micromirror device (DMD) based optical architecture for augmented reality (AR) glasses,"Sheng, Z., Zhou, X., & Shaw, S. A. (2023). Compact digital micromirror device (DMD)-based optical architecture for augmented reality (AR) glasses. Emerging Digital Micromirror Device Based Systems and Applications XV. https://doi.org/10.1117/12.2655671
",10.1117/12.2655671,"Size and efficacy are two of the main challenges of an AR display. A compact form factor and low power consumption are highly desirable in AR glasses. Self-emitting display technologies such as OLED and MicroLED do not need illumination thus enabling simpler and smaller optics, but their efficacy is quite low, especially for pixel sizes of 5um or below. Spatial Light Modulator (SLM) based technologies, such as DMD, LCoS (Liquid Crystal on Silicon), and LBS (Laser Beam Scanning), take advantage of high efficacy light sources and can achieve a high brightness AR display combining low power consumption and high pixel density, which is highly preferable in many applications. The DMD, together with the efficient and ever-improving LED light source, has been highly favored in the battery-powered portable projection display market, due to its high efficacy in a compact form factor as well as its insensitivity to polarization. Here we present a compact optical engine architecture for AR glasses, taking into consideration both size and efficacy. The design simplifies the traditional DMD illumination to a compact size targeting a thin profile similar to a backlit LCD. This compact size is achieved with a small compromise to engine efficacy. Multiplying the pixel density with a glass plate actuator offers a performance improvement that easily justifies the slight increase in size. This architecture offers an excellent optical engine option for AR glasses which is both compact and high performance. &copy; 2023 SPIE.","402 Buildings and Towers;706.1 Electric Power Systems;714.2 Semiconductor Devices and Integrated Circuits;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;744.8 Laser Beam Interactions;812.3 Glass;921.6 Numerical Methods",Augmented reality glass;Compact size;Digital micromirror device;Form factors;Low-power consumption;Lower-power consumption;Micro opto electro mechanical systems;Near eye display;Optical engine;Spatial light modulators,Approximation theory;Architecture;Augmented reality;Electric power utilization;Engines;Helmet mounted displays;Laser beams;Light modulation;Light modulators;Liquid crystals;Network architecture;Organic light emitting diodes (OLED);Pixels,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Sheng, Zhongyan; (1) Zhou, Xi; (1) Shaw, Steve; ","(1) Texas Instruments, Inc., 63333 TI Blvd, Dallas; TX; 75024, United States; (2) DLP&reg; Products Business Unit, United States; ",SPIE,-1,"[""approximation theory"", ""architecture"", ""electric power utilization"", ""engines"", ""helmet mounted displays"", ""laser beams"", ""light modulation"", ""light modulators"", ""liquid crystals"", ""network architecture"", ""organic light emitting diodes"", ""pixels""]","[""approximation theory"", ""architecture"", ""electric power utilization"", ""engines"", ""helmet mounted displays"", ""laser beams"", ""light modulation"", ""light modulators"", ""liquid crystals"", ""network architecture"", ""organic light emitting diodes"", ""pixels""]",approximation theory;architecture;electric power utilization;engines;helmet mounted displays;laser beams;light modulation;light modulators;liquid crystals;network architecture;organic light emitting diodes;pixels,construction;computer vision;semiconductors;graphics;input;optics;chemical;power and energy;display technology;wearables;artificial intelligence;networks,technology;displays;industries,construction;computer vision;semiconductors;graphics;input;optics;chemical;power and energy;display technology;wearables;artificial intelligence;networks,technology;displays;industries,approximation_theory architecture electric_power_utilization engines helmet_mounted_displays laser_beams light_modulation light_modulators liquid_crystals network_architecture organic_light_emitting_diodes pixels augmented_reality_glass compact_size digital_micromirror_device form_factors low power_consumption lower power_consumption micro_opto_electro_mechanical_systems near_eye_display optical_engine spatial_light_modulators 402_buildings_and_towers 706 1_electric_power_systems 714 2_semiconductor_devices_and_integrated_circuits 723_computer_software _data_handling_and_applications 741 1_light optics 744 8_laser_beam_interactions 812 3_glass 921 6_numerical_methods construction computer_vision semiconductors graphics input optics chemical power_and_energy display_technology wearables artificial_intelligence networks,approximation_theory architecture electric_power_utilization engines helmet_mounted_displays laser_beams light_modulation light_modulators liquid_crystals network_architecture organic_light_emitting_diodes pixels,augmented_reality_glass compact_size digital_micromirror_device form_factors low power_consumption lower power_consumption micro_opto_electro_mechanical_systems near_eye_display optical_engine spatial_light_modulators,size efficacy two main challenge ar display compact form factor low power consumption highly desirable ar glass self emitting display technology oled microled need illumination thus enabling simpler smaller optic efficacy quite low especially pixel size 5um spatial light modulator slm based technology dmd lcos liquid crystal silicon lb laser beam scanning take advantage high efficacy light source achieve high brightness ar display combining low power consumption high pixel density highly preferable many application dmd together efficient ever improving led light source highly favored battery powered portable projection display market due high efficacy compact form factor well insensitivity polarization present compact optical engine architecture ar glass taking consideration size efficacy design simplifies traditional dmd illumination compact size targeting thin profile similar backlit lcd compact size achieved small compromise engine efficacy multiplying pixel density glass plate actuator offer performance improvement easily justifies slight increase size architecture offer excellent optical engine option ar glass compact high performance copy 2023 spie,approximation_theory architecture electric_power_utilization engines helmet_mounted_displays laser_beams light_modulation light_modulators liquid_crystals network_architecture organic_light_emitting_diodes pixels augmented_reality_glass compact_size digital_micromirror_device form_factors low power_consumption lower power_consumption micro_opto_electro_mechanical_systems near_eye_display optical_engine spatial_light_modulators 402_buildings_and_towers 706 1_electric_power_systems 714 2_semiconductor_devices_and_integrated_circuits 723_computer_software _data_handling_and_applications 741 1_light optics 744 8_laser_beam_interactions 812 3_glass 921 6_numerical_methods construction computer_vision semiconductors graphics input optics chemical power_and_energy display_technology wearables artificial_intelligence networks size efficacy two main challenge ar display compact form factor low power consumption highly desirable ar glass self emitting display technology oled microled need illumination thus enabling simpler smaller optic efficacy quite low especially pixel size 5um spatial light modulator slm based technology dmd lcos liquid crystal silicon lb laser beam scanning take advantage high efficacy light source achieve high brightness ar display combining low power consumption high pixel density highly preferable many application dmd together efficient ever improving led light source highly favored battery powered portable projection display market due high efficacy compact form factor well insensitivity polarization present compact optical engine architecture ar glass taking consideration size efficacy design simplifies traditional dmd illumination compact size targeting thin profile similar backlit lcd compact size achieved small compromise engine efficacy multiplying pixel density glass plate actuator offer performance improvement easily justifies slight increase size architecture offer excellent optical engine option ar glass compact high performance copy 2023 spie,size efficacy two main challenge ar display compact form factor low power consumption highly desirable ar glass self emitting display technology oled microled need illumination thus enabling simpler smaller optic efficacy quite low especially pixel size 5um spatial light modulator slm based technology dmd lcos liquid crystal silicon lb laser beam scanning take advantage high efficacy light source achieve high brightness ar display combining low power consumption high pixel density highly preferable many application dmd together efficient ever improving led light source highly favored battery powered portable projection display market due high efficacy compact form factor well insensitivity polarization present compact optical engine architecture ar glass taking consideration size efficacy design simplifies traditional dmd illumination compact size targeting thin profile similar backlit lcd compact size achieved small compromise engine efficacy multiplying pixel density glass plate actuator offer performance improvement easily justifies slight increase size architecture offer excellent optical engine option ar glass compact high performance copy 2023 spieapproximation_theory architecture electric_power_utilization engines helmet_mounted_displays laser_beams light_modulation light_modulators liquid_crystals network_architecture organic_light_emitting_diodes pixelsaugmented_reality_glass compact_size digital_micromirror_device form_factors low power_consumption lower power_consumption micro_opto_electro_mechanical_systems near_eye_display optical_engine spatial_light_modulators
142,Silhouettes from Real Objects Enable Realistic Interactions with a Virtual Human in Mobile Augmented Reality,"Kim, H., Ali, G., Pastor, A., Lee, M., Kim, G. J., & Hwang, J.-I. (2021). Silhouettes from Real Objects Enable Realistic Interactions with a Virtual Human in Mobile Augmented Reality. Applied Sciences, 11(6), 2763. https://doi.org/10.3390/app11062763
",10.3390/app11062763,"Realistic interactions with real objects (e.g., animals, toys, robots) in an augmented reality (AR) environment enhances the user experience. The common AR apps on the market achieve realistic interactions by superimposing pre-modeled virtual proxies on the real objects in the AR environment. This way user perceives the interaction with virtual proxies as interaction with real objects. However, catering to environment change, shape deformation, and view update is not a trivial task. Our proposed method uses the dynamic silhouette of a real object to enable realistic interactions. Our approach is practical, lightweight, and requires no additional hardware besides the device camera. For a case study, we designed a mobile AR application to interact with real animal dolls. Our scenario included a virtual human performing four types of realistic interactions. Results demonstrated our method's stability that does not require pre-modeled virtual proxies in case of shape deformation and view update. We also conducted a pilot study using our approach and reported significant improvements in user perception of spatial awareness and presence for realistic interactions with a virtual human.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",AR environment;augmented reality environment;device camera;dynamic silhouette;environment change;mobile AR application;mobile augmented reality;pre-modeled virtual proxies;real animal dolls;real objects;realistic interactions;shape deformation;spatial awareness;user experience;user perception;view update;virtual human,augmented reality;human computer interaction;mobile computing;user experience,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Kim, H.; (1) Ali, G.; (4) Pastor, A.; (5) Lee, M.; (2) Kim, G.J.; (1) Hwang, J.-I.; ","(1) Korea Institute of Science and Technology, Center for Artificial Intelligence, Korea, Republic of; (2) Korea University, Department of Computer Science and Engineering, Korea, Republic of; (3) University of Science and Technology, Division of NT-IT, Korea, Republic of; (4) University of Nantes, LS2N, France; (5) Pusan National University, School of Computer Science and Engineering, Korea, Republic of; ",MDPI,-1,"[""human computer interaction"", ""mobile computing"", ""user experience""]","[""human computer interaction"", ""mobile computing"", ""user experience""]",human computer interaction;mobile computing;user experience,human factors;telecommunication;human-computer interaction,industries;end users and user experience,human factors;telecommunication;human-computer interaction,industries;end users and user experience,human_computer_interaction mobile_computing user_experience ar_environment augmented_reality_environment device_camera dynamic_silhouette environment_change mobile_ar_application mobile_augmented_reality pre modeled_virtual_proxies real_animal_dolls real_objects realistic_interactions shape_deformation spatial_awareness user_experience user_perception view_update virtual_human c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication human computer_interaction,human_computer_interaction mobile_computing user_experience,ar_environment augmented_reality_environment device_camera dynamic_silhouette environment_change mobile_ar_application mobile_augmented_reality pre modeled_virtual_proxies real_animal_dolls real_objects realistic_interactions shape_deformation spatial_awareness user_experience user_perception view_update virtual_human,realistic interaction real object e g animal toy robot augmented reality ar environment enhances user experience common ar apps market achieve realistic interaction superimposing pre modeled virtual proxy real object ar environment way user perceives interaction virtual proxy interaction real object however catering environment change shape deformation view update trivial task proposed method us dynamic silhouette real object enable realistic interaction approach practical lightweight requires additional hardware besides device camera case study designed mobile ar application interact real animal doll scenario included virtual human performing four type realistic interaction result demonstrated method stability require pre modeled virtual proxy case shape deformation view update also conducted pilot study using approach reported significant improvement user perception spatial awareness presence realistic interaction virtual human,human_computer_interaction mobile_computing user_experience ar_environment augmented_reality_environment device_camera dynamic_silhouette environment_change mobile_ar_application mobile_augmented_reality pre modeled_virtual_proxies real_animal_dolls real_objects realistic_interactions shape_deformation spatial_awareness user_experience user_perception view_update virtual_human c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication human computer_interaction realistic interaction real object e g animal toy robot augmented reality ar environment enhances user experience common ar apps market achieve realistic interaction superimposing pre modeled virtual proxy real object ar environment way user perceives interaction virtual proxy interaction real object however catering environment change shape deformation view update trivial task proposed method us dynamic silhouette real object enable realistic interaction approach practical lightweight requires additional hardware besides device camera case study designed mobile ar application interact real animal doll scenario included virtual human performing four type realistic interaction result demonstrated method stability require pre modeled virtual proxy case shape deformation view update also conducted pilot study using approach reported significant improvement user perception spatial awareness presence realistic interaction virtual human,realistic interaction real object e g animal toy robot augmented reality ar environment enhances user experience common ar apps market achieve realistic interaction superimposing pre modeled virtual proxy real object ar environment way user perceives interaction virtual proxy interaction real object however catering environment change shape deformation view update trivial task proposed method us dynamic silhouette real object enable realistic interaction approach practical lightweight requires additional hardware besides device camera case study designed mobile ar application interact real animal doll scenario included virtual human performing four type realistic interaction result demonstrated method stability require pre modeled virtual proxy case shape deformation view update also conducted pilot study using approach reported significant improvement user perception spatial awareness presence realistic interaction virtual humanhuman_computer_interaction mobile_computing user_experiencear_environment augmented_reality_environment device_camera dynamic_silhouette environment_change mobile_ar_application mobile_augmented_reality pre modeled_virtual_proxies real_animal_dolls real_objects realistic_interactions shape_deformation spatial_awareness user_experience user_perception view_update virtual_human
143,Exploiting deep learning and augmented reality in fused deposition modeling: a focus on registration,"Tanzi, L., Piazzolla, P., Moos, S., & Vezzetti, E. (2022). Exploiting deep learning and augmented reality in fused deposition modeling: a focus on registration. International Journal on Interactive Design and Manufacturing (IJIDeM), 17(1), 103–114. https://doi.org/10.1007/s12008-022-01107-5
",10.1007/s12008-022-01107-5,"The current study aimed to propose a Deep Learning (DL) based framework to retrieve in real-time the position and the rotation of an object in need of maintenance from live video frames only. For testing the positioning performances, we focused on intervention on a generic Fused Deposition Modeling (FDM) 3D printer maintenance. Lastly, to demonstrate a possible Augmented Reality (AR) application that can be built on top of this, we discussed a specific case study using a Prusa i3 MKS FDM printer. This method was developed using a You Only Look Once (YOLOv3) network for object detection to locate the position of the FDM 3D printer and a subsequent Rotation Convolutional Neural Network (RotationCNN), trained on a dataset of artificial images, to predict the rotations' parameters for attaching the 3D model. To train YOLOv3 we used an augmented dataset of 1653 real images, while to train the RotationCNN we utilized a dataset of 99.220 synthetic images, showing the FDM 3D Printer with different orientations, and fine-tuned it using 235 real images tagged manually. The YOLOv3 network obtained an AP (Average Precision) of 100% with Intersection Over Unit parameter of 0.5, while the RotationCNN showed a mean Geodesic Distance of 0.250 (&#963; = 0.210) and a mean accuracy to detect the correct rotationrof 0.619 (&#963; = 0.130), considering as acceptable the range [r - 10,r + 10]. We then evaluate the CAD system performances with 10 non-expert users: the average speed improved from 9.61 (&#963; = 1.53) to 5.30 (&#963; = 1.30) and the average number of actions to complete the task from 12.60 (&#963; = 2.15) to 11.00 (&#963; = 0.89). This work is a further step through the adoption of DL and AR in the assistance domain. In future works, we will overcome the limitations of this approach and develop a complete mobile CAD system that could be extended to any object that presents a 3D counterpart model.","A8770E Patient diagnostic methods and instrumentation;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets;C7330 Biology and medical computing;C7480 Production engineering computing;E0410D Industrial applications of IT;E1520R Three-dimensional printing",3D counterpart model;99.220 synthetic images;artificial images;augmented dataset;correct rotation;deep learning;FDM 3D printer;FDM 3D Printer;generic Fused Deposition Modeling 3D printer maintenance;live video frames;object detection;positioning performances;possible Augmented Reality application;Prusa i3 MKS FDM printer;RotationCNN;rotations;specific case study;subsequent Rotation Convolutional Neural Network;YOLOv3 network,augmented reality;CAD;convolutional neural nets;deep learning (artificial intelligence);feature extraction;medical image processing;object detection;printers;production engineering computing;rapid prototyping (industrial);three-dimensional printing,2023,Journal article (JA),Int. J. Interact. Des. Manuf. (Germany),"(1) Tanzi, L.; (1) Piazzolla, P.; (1) Moos, S.; (1) Vezzetti, E.; ","(1) Polytechnic University of Turin, Department of Management, Italy; ",Springer,-1,"[""cad"", ""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""medical image processing"", ""object detection"", ""printers"", ""production engineering computing"", ""rapid prototyping"", ""three-dimensional printing""]","[""cad"", ""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""medical image processing"", ""object detection"", ""printers"", ""production engineering computing"", ""rapid prototyping"", ""three-dimensional printing""]",cad;convolutional neural nets;deep learning (artificial intelligence);feature extraction;medical image processing;object detection;printers;production engineering computing;rapid prototyping;three-dimensional printing,computer vision;manufacturing;other;graphics;liberal arts;medical;chemical;display technology;engineering;developers;data;artificial intelligence;networks,technology;other;displays;industries,computer vision;manufacturing;other;graphics;liberal arts;medical;chemical;display technology;engineering;developers;data;artificial intelligence;networks,technology;other;displays;industries,cad convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction medical_image_processing object_detection printers production_engineering_computing rapid_prototyping three dimensional_printing 3d_counterpart_model 99 220_synthetic_images artificial_images augmented_dataset correct_rotation deep_learning fdm_3d_printer fdm_3d_printer generic_fused_deposition_modeling_3d_printer_maintenance live_video_frames object_detection positioning_performances possible_augmented_reality_application prusa_i3_mks_fdm_printer rotationcnn rotations specific_case_study subsequent_rotation_convolutional_neural_network yolov3_network a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets c7330_biology_and_medical_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it e1520r_three dimensional_printing computer_vision manufacturing other graphics liberal_arts medical chemical display_technology engineering developers data artificial_intelligence networks,cad convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction medical_image_processing object_detection printers production_engineering_computing rapid_prototyping three dimensional_printing,3d_counterpart_model 99 220_synthetic_images artificial_images augmented_dataset correct_rotation deep_learning fdm_3d_printer fdm_3d_printer generic_fused_deposition_modeling_3d_printer_maintenance live_video_frames object_detection positioning_performances possible_augmented_reality_application prusa_i3_mks_fdm_printer rotationcnn rotations specific_case_study subsequent_rotation_convolutional_neural_network yolov3_network,current study aimed propose deep learning dl based framework retrieve real time position rotation object need maintenance live video frame testing positioning performance focused intervention generic fused deposition modeling fdm 3d printer maintenance lastly demonstrate possible augmented reality ar application built top discussed specific case study using prusa i3 mks fdm printer method developed using look yolov3 network object detection locate position fdm 3d printer subsequent rotation convolutional neural network rotationcnn trained dataset artificial image predict rotation parameter attaching 3d model train yolov3 used augmented dataset 1653 real image train rotationcnn utilized dataset 99 220 synthetic image showing fdm 3d printer different orientation fine tuned using 235 real image tagged manually yolov3 network obtained ap average precision 100 intersection unit parameter 0 5 rotationcnn showed mean geodesic distance 0 250 963 0 210 mean accuracy detect correct rotationrof 0 619 963 0 130 considering acceptable range r 10 r 10 evaluate cad system performance 10 non expert user average speed improved 9 61 963 1 53 5 30 963 1 30 average number action complete task 12 60 963 2 15 11 00 963 0 89 work step adoption dl ar assistance domain future work overcome limitation approach develop complete mobile cad system could extended object present 3d counterpart model,cad convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction medical_image_processing object_detection printers production_engineering_computing rapid_prototyping three dimensional_printing 3d_counterpart_model 99 220_synthetic_images artificial_images augmented_dataset correct_rotation deep_learning fdm_3d_printer fdm_3d_printer generic_fused_deposition_modeling_3d_printer_maintenance live_video_frames object_detection positioning_performances possible_augmented_reality_application prusa_i3_mks_fdm_printer rotationcnn rotations specific_case_study subsequent_rotation_convolutional_neural_network yolov3_network a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets c7330_biology_and_medical_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it e1520r_three dimensional_printing computer_vision manufacturing other graphics liberal_arts medical chemical display_technology engineering developers data artificial_intelligence networks current study aimed propose deep learning dl based framework retrieve real time position rotation object need maintenance live video frame testing positioning performance focused intervention generic fused deposition modeling fdm 3d printer maintenance lastly demonstrate possible augmented reality ar application built top discussed specific case study using prusa i3 mks fdm printer method developed using look yolov3 network object detection locate position fdm 3d printer subsequent rotation convolutional neural network rotationcnn trained dataset artificial image predict rotation parameter attaching 3d model train yolov3 used augmented dataset 1653 real image train rotationcnn utilized dataset 99 220 synthetic image showing fdm 3d printer different orientation fine tuned using 235 real image tagged manually yolov3 network obtained ap average precision 100 intersection unit parameter 0 5 rotationcnn showed mean geodesic distance 0 250 963 0 210 mean accuracy detect correct rotationrof 0 619 963 0 130 considering acceptable range r 10 r 10 evaluate cad system performance 10 non expert user average speed improved 9 61 963 1 53 5 30 963 1 30 average number action complete task 12 60 963 2 15 11 00 963 0 89 work step adoption dl ar assistance domain future work overcome limitation approach develop complete mobile cad system could extended object present 3d counterpart model,current study aimed propose deep learning dl based framework retrieve real time position rotation object need maintenance live video frame testing positioning performance focused intervention generic fused deposition modeling fdm 3d printer maintenance lastly demonstrate possible augmented reality ar application built top discussed specific case study using prusa i3 mks fdm printer method developed using look yolov3 network object detection locate position fdm 3d printer subsequent rotation convolutional neural network rotationcnn trained dataset artificial image predict rotation parameter attaching 3d model train yolov3 used augmented dataset 1653 real image train rotationcnn utilized dataset 99 220 synthetic image showing fdm 3d printer different orientation fine tuned using 235 real image tagged manually yolov3 network obtained ap average precision 100 intersection unit parameter 0 5 rotationcnn showed mean geodesic distance 0 250 963 0 210 mean accuracy detect correct rotationrof 0 619 963 0 130 considering acceptable range r 10 r 10 evaluate cad system performance 10 non expert user average speed improved 9 61 963 1 53 5 30 963 1 30 average number action complete task 12 60 963 2 15 11 00 963 0 89 work step adoption dl ar assistance domain future work overcome limitation approach develop complete mobile cad system could extended object present 3d counterpart modelcad convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction medical_image_processing object_detection printers production_engineering_computing rapid_prototyping three dimensional_printing3d_counterpart_model 99 220_synthetic_images artificial_images augmented_dataset correct_rotation deep_learning fdm_3d_printer fdm_3d_printer generic_fused_deposition_modeling_3d_printer_maintenance live_video_frames object_detection positioning_performances possible_augmented_reality_application prusa_i3_mks_fdm_printer rotationcnn rotations specific_case_study subsequent_rotation_convolutional_neural_network yolov3_network
144,Augmented Reality Maintenance Assistant Using YOLOv5,"Malta, A., Mendes, M., & Farinha, T. (2021). Augmented Reality Maintenance Assistant Using YOLOv5. Applied Sciences, 11(11), 4758. https://doi.org/10.3390/app11114758
",10.3390/app11114758,"Maintenance professionals and other technical staff regularly need to learn to identify new parts in car engines and other equipment. The present work proposes a model of a task assistant based on a deep learning neural network. A YOLOv5 network is used for recognizing some of the constituent parts of an automobile. A dataset of car engine images was created and eight car parts were marked in the images. Then, the neural network was trained to detect each part. The results show that YOLOv5s is able to successfully detect the parts in real time video streams, with high accuracy, thus being useful as an aid to train professionals learning to deal with new equipment using augmented reality. The architecture of an object recognition system using augmented reality glasses is also designed.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;E1020 Maintenance and reliability",augmented reality glasses;augmented reality maintenance assistant;car engine images;car engines;car parts;constituent parts;deep learning neural network;maintenance professionals;task assistant;technical staff;time video streams;YOLOv5 network,augmented reality;human computer interaction;learning (artificial intelligence);maintenance engineering;neural nets;object recognition;video streaming,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Malta, A.; (1) Mendes, M.; (1) Farinha, T.; ","(1) Polytechnic of Coimbra, ISEC, Portugal; (2) University of Coimbra, Portugal; (3) Centre for Mechanical Engineering, Materials and Processes&#8212;CEMMPRE, Portugal; ",MDPI,-1,"[""human computer interaction"", ""learning algorithms"", ""maintenance engineering"", ""neural networks"", ""object recognition"", ""video streaming""]","[""human computer interaction"", ""learning algorithms"", ""maintenance engineering"", ""neural networks"", ""object recognition"", ""video streaming""]",human computer interaction;learning algorithms;maintenance engineering;neural networks;object recognition;video streaming,computer vision;manufacturing;medical;human factors;human-computer interaction;artificial intelligence;video,technology;industries;end users and user experience,computer vision;manufacturing;medical;human factors;human-computer interaction;artificial intelligence;video,technology;industries;end users and user experience,human_computer_interaction learning_algorithms maintenance_engineering neural_networks object_recognition video_streaming augmented_reality_glasses augmented_reality_maintenance_assistant car_engine_images car_engines car_parts constituent_parts deep_learning_neural_network maintenance_professionals task_assistant technical_staff time_video_streams yolov5_network b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces e1020_maintenance_and_reliability computer_vision manufacturing medical human_factors human computer_interaction artificial_intelligence video,human_computer_interaction learning_algorithms maintenance_engineering neural_networks object_recognition video_streaming,augmented_reality_glasses augmented_reality_maintenance_assistant car_engine_images car_engines car_parts constituent_parts deep_learning_neural_network maintenance_professionals task_assistant technical_staff time_video_streams yolov5_network,maintenance professional technical staff regularly need learn identify new part car engine equipment present work proposes model task assistant based deep learning neural network yolov5 network used recognizing constituent part automobile dataset car engine image created eight car part marked image neural network trained detect part result show yolov5s able successfully detect part real time video stream high accuracy thus useful aid train professional learning deal new equipment using augmented reality architecture object recognition system using augmented reality glass also designed,human_computer_interaction learning_algorithms maintenance_engineering neural_networks object_recognition video_streaming augmented_reality_glasses augmented_reality_maintenance_assistant car_engine_images car_engines car_parts constituent_parts deep_learning_neural_network maintenance_professionals task_assistant technical_staff time_video_streams yolov5_network b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces e1020_maintenance_and_reliability computer_vision manufacturing medical human_factors human computer_interaction artificial_intelligence video maintenance professional technical staff regularly need learn identify new part car engine equipment present work proposes model task assistant based deep learning neural network yolov5 network used recognizing constituent part automobile dataset car engine image created eight car part marked image neural network trained detect part result show yolov5s able successfully detect part real time video stream high accuracy thus useful aid train professional learning deal new equipment using augmented reality architecture object recognition system using augmented reality glass also designed,maintenance professional technical staff regularly need learn identify new part car engine equipment present work proposes model task assistant based deep learning neural network yolov5 network used recognizing constituent part automobile dataset car engine image created eight car part marked image neural network trained detect part result show yolov5s able successfully detect part real time video stream high accuracy thus useful aid train professional learning deal new equipment using augmented reality architecture object recognition system using augmented reality glass also designedhuman_computer_interaction learning_algorithms maintenance_engineering neural_networks object_recognition video_streamingaugmented_reality_glasses augmented_reality_maintenance_assistant car_engine_images car_engines car_parts constituent_parts deep_learning_neural_network maintenance_professionals task_assistant technical_staff time_video_streams yolov5_network
145,Batik AR ver.1.0: Augmented Reality application as gamification of batik design using waterfall method,"Sobandi, B., Wibawa, S. C., Triyanto, T., Syakir, S., Pandanwangi, A., Suryadi, S., Nursalim, A., & Santosa, H. (2021). Batik AR ver.1.0: Augmented Reality application as gamification of batik design using waterfall method. Journal of Physics: Conference Series, 1987(1), 012021. https://doi.org/10.1088/1742-6596/1987/1/012021
",10.1088/1742-6596/1987/1/012021,"During the Covid-19 pandemic, it's time to implement asynchronous learning. The problem is, elementary school students have difficulty learning cultural arts, especially batik design. This study aims to create an application base on augmented reality (AR) with batik design content that can be used to introduce batik design as cultural art to elementary school students. The method used in developing this application is a waterfall which consists of (1) feasibility study, (2) requirements, (3) System design, (4) Encoding, (5) Testing system, (6) Acceptance Test. The results of this study were the validators rated more than 85% of media validation consisting of the quality of visual and auditory perceptions, ease of interaction, ease of interaction, and ease of use, while user responses consisted of 80% efficiency, 85% usability, 78% cognitive absorption, and enjoyment. 87%. This implies that the AR application can provide benefits for students who learn cultural sessions, especially batik design.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C7830D Computer games,application base;Augmented Reality application;batik AR;batik design content;cultural art;elementary school students,augmented reality;cognition;computer aided instruction;diseases;educational institutions;epidemics;serious games (computing),2021,Conference article (CA),"J. Phys., Conf. Ser. (UK)","(1) Sobandi, B.; (2) Wibawa, S.C.; (3) Triyanto, T.; (3) Syakir, S.; (4) Pandanwangi, A.; (5) Suryadi, S.; (5) Nursalim, A.; (5) Santosa, H.; ","(1) Universitas Negeri Semarang, Indonesia; (2) Universitas Negeri Surabaya, Informatics Department, Indonesia; (3) Universitas Negeri Semarang, Department of Fine Arts, Indonesia; (4) Universitas Kristen Maranatha, Department of Fine Arts, Indonesia; (5) Universitas Pendidikan Indonesia, Department of Visual Arts Education, Indonesia; ",IOP Publishing,-1,"[""cognition"", ""computer aided instruction"", ""diseases"", ""educational institutions"", ""epidemics"", ""serious games""]","[""cognition"", ""computer aided instruction"", ""diseases"", ""educational institutions"", ""epidemics"", ""serious games""]",cognition;computer aided instruction;diseases;educational institutions;epidemics;serious games,education;simulation;medical;training;human factors,end users and user experience;use cases;industries,education;simulation;medical;training;human factors,end users and user experience;use cases;industries,cognition computer_aided_instruction diseases educational_institutions epidemics serious_games application_base augmented_reality_application batik_ar batik_design_content cultural_art elementary_school_students c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7830d_computer_games education simulation medical training human_factors,cognition computer_aided_instruction diseases educational_institutions epidemics serious_games,application_base augmented_reality_application batik_ar batik_design_content cultural_art elementary_school_students,covid 19 pandemic time implement asynchronous learning problem elementary school student difficulty learning cultural art especially batik design study aim create application base augmented reality ar batik design content used introduce batik design cultural art elementary school student method used developing application waterfall consists 1 feasibility study 2 requirement 3 system design 4 encoding 5 testing system 6 acceptance test result study validators rated 85 medium validation consisting quality visual auditory perception ease interaction ease interaction ease use user response consisted 80 efficiency 85 usability 78 cognitive absorption enjoyment 87 implies ar application provide benefit student learn cultural session especially batik design,cognition computer_aided_instruction diseases educational_institutions epidemics serious_games application_base augmented_reality_application batik_ar batik_design_content cultural_art elementary_school_students c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7830d_computer_games education simulation medical training human_factors covid 19 pandemic time implement asynchronous learning problem elementary school student difficulty learning cultural art especially batik design study aim create application base augmented reality ar batik design content used introduce batik design cultural art elementary school student method used developing application waterfall consists 1 feasibility study 2 requirement 3 system design 4 encoding 5 testing system 6 acceptance test result study validators rated 85 medium validation consisting quality visual auditory perception ease interaction ease interaction ease use user response consisted 80 efficiency 85 usability 78 cognitive absorption enjoyment 87 implies ar application provide benefit student learn cultural session especially batik design,covid 19 pandemic time implement asynchronous learning problem elementary school student difficulty learning cultural art especially batik design study aim create application base augmented reality ar batik design content used introduce batik design cultural art elementary school student method used developing application waterfall consists 1 feasibility study 2 requirement 3 system design 4 encoding 5 testing system 6 acceptance test result study validators rated 85 medium validation consisting quality visual auditory perception ease interaction ease interaction ease use user response consisted 80 efficiency 85 usability 78 cognitive absorption enjoyment 87 implies ar application provide benefit student learn cultural session especially batik designcognition computer_aided_instruction diseases educational_institutions epidemics serious_gamesapplication_base augmented_reality_application batik_ar batik_design_content cultural_art elementary_school_students
146,Applicability of a digitalization model based on augmented reality for building construction education in architecture,"Seyman Guray, T., & Kismet, B. (2021). Applicability of a digitalization model based on augmented reality for building construction education in architecture. Construction Innovation, 23(1), 193–212. https://doi.org/10.1108/ci-07-2021-0136
",10.1108/CI-07-2021-0136,"&lt;b&gt;Purpose &lt;/b&gt;The purpose of this paper is to introduce a digitalization model (DM) for building construction courses in architectural education as a response to the recent emerging technologies in the era of digital transformations. This DM is developed and applied through augmented reality (AR) technologies to boost perception, understandings and ability to solve building construction details. &lt;b&gt;Design/methodology/approach &lt;/b&gt;Based on a thorough review of recent technologies like AR, virtual reality (VR), building information modelling (BIM) and their applications in architectural education, the methodology involves the generation of a model, its application and evaluation. The model is based on the integration of BIM and AR which is applied into a third year ""Building Construction Project"" course. Each student has designed a residential building and accordingly prepared the construction drawings by adapting the DM. An online survey -based on Technology Acceptance Model - is conducted to evaluate the DM by quantitative data analysis from SPSS and Excel. &lt;b&gt;Findings &lt;/b&gt;The key findings of the study include the following items: determination of the proper digital tools, the definition of the steps and workflow based on the building project phases to develop construction drawings and define precise details effectively. By the help of this, the DM is generated and applied. According to the survey and results, the DM which involves BIM-based AR is considered as beneficial, highly motivating and providing better perception on construction details. &lt;b&gt;Originality/value&lt;/b&gt;I mplication of AR/VR technologies is frequently seen in design studios, whereas building construction courses state its traditional approach. However, there is a huge potential in the digitalization of building construction education by increasing the perception of students together with the increased level of communication. The study aims to close the gap of digitalization by proposing a DM, which brings a systematic approach considering each phase of building construction project as conceptual, schematic, design development and construction documents by using BIM integrated AR. Moreover, the novel model specifically brings a new approach by generation of QR codes for construction details to embed videos or simulations into the two-dimensional drawing sheets. Furthermore, the DM proposes a new approach to satisfy emerging needs and requirements of the Architecture Engineering Construction industry.",C7440 Civil and mechanical engineering computing;C6130V Virtual reality;E0410H Mechanical engineering applications of IT;E1400 Design;E2110B Building structures;E3030 Construction industry,architectural education;Architecture Engineering Construction industry;augmented reality;BIM-based AR;building construction details;building construction education;building project phases;construction courses;construction documents;construction drawings;design development;digital transformations;digitalization model;DM;information modelling;proper digital tools;recent emerging technologies;residential building;Technology Acceptance Model;virtual reality;year Building Construction Project course,architecture;augmented reality;building information modelling;building management systems;buildings (structures);construction industry;data analysis;project management;QR codes;structural engineering computing;technology acceptance model;virtual reality,2023,Journal article (JA),Constr. Innov. (UK),"(1) Guray, T.S.; (1) Kismet, B.; ","(1) Beykoz Universitesi, Department of Architecture, Turkey; ",Emerald,-1,"[""architecture"", ""building information modelling"", ""building management systems"", ""buildings"", ""construction industry"", ""data analysis"", ""project management"", ""qr codes"", ""structural engineering computing"", ""technology acceptance model""]","[""architecture"", ""building information modelling"", ""building management systems"", ""buildings"", ""construction industry"", ""data analysis"", ""project management"", ""qr codes"", ""structural engineering computing"", ""technology acceptance model""]",architecture;building information modelling;building management systems;buildings;construction industry;data analysis;project management;qr codes;structural engineering computing;technology acceptance model,construction;education;input;human factors;engineering;developers;data;human-computer interaction;business planning and management,technology;end users and user experience;business;industries,construction;education;input;human factors;engineering;developers;data;human-computer interaction;business planning and management,technology;end users and user experience;business;industries,architecture building_information_modelling building_management_systems buildings construction_industry data_analysis project_management qr_codes structural_engineering_computing technology_acceptance_model architectural_education architecture_engineering_construction_industry augmented_reality bim based_ar building_construction_details building_construction_education building_project_phases construction_courses construction_documents construction_drawings design_development digital_transformations digitalization_model dm information_modelling proper_digital_tools recent_emerging_technologies residential_building technology_acceptance_model virtual_reality year_building_construction_project_course c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e0410h_mechanical_engineering_applications_of_it e1400_design e2110b_building_structures e3030_construction_industry construction education input human_factors engineering developers data human computer_interaction business_planning_and_management,architecture building_information_modelling building_management_systems buildings construction_industry data_analysis project_management qr_codes structural_engineering_computing technology_acceptance_model,architectural_education architecture_engineering_construction_industry augmented_reality bim based_ar building_construction_details building_construction_education building_project_phases construction_courses construction_documents construction_drawings design_development digital_transformations digitalization_model dm information_modelling proper_digital_tools recent_emerging_technologies residential_building technology_acceptance_model virtual_reality year_building_construction_project_course,lt b gt purpose lt b gt purpose paper introduce digitalization model dm building construction course architectural education response recent emerging technology era digital transformation dm developed applied augmented reality ar technology boost perception understanding ability solve building construction detail lt b gt design methodology approach lt b gt based thorough review recent technology like ar virtual reality vr building information modelling bim application architectural education methodology involves generation model application evaluation model based integration bim ar applied third year building construction project course student designed residential building accordingly prepared construction drawing adapting dm online survey based technology acceptance model conducted evaluate dm quantitative data analysis spss excel lt b gt finding lt b gt key finding study include following item determination proper digital tool definition step workflow based building project phase develop construction drawing define precise detail effectively help dm generated applied according survey result dm involves bim based ar considered beneficial highly motivating providing better perception construction detail lt b gt originality value lt b gt mplication ar vr technology frequently seen design studio whereas building construction course state traditional approach however huge potential digitalization building construction education increasing perception student together increased level communication study aim close gap digitalization proposing dm brings systematic approach considering phase building construction project conceptual schematic design development construction document using bim integrated ar moreover novel model specifically brings new approach generation qr code construction detail embed video simulation two dimensional drawing sheet furthermore dm proposes new approach satisfy emerging need requirement architecture engineering construction industry,architecture building_information_modelling building_management_systems buildings construction_industry data_analysis project_management qr_codes structural_engineering_computing technology_acceptance_model architectural_education architecture_engineering_construction_industry augmented_reality bim based_ar building_construction_details building_construction_education building_project_phases construction_courses construction_documents construction_drawings design_development digital_transformations digitalization_model dm information_modelling proper_digital_tools recent_emerging_technologies residential_building technology_acceptance_model virtual_reality year_building_construction_project_course c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e0410h_mechanical_engineering_applications_of_it e1400_design e2110b_building_structures e3030_construction_industry construction education input human_factors engineering developers data human computer_interaction business_planning_and_management lt b gt purpose lt b gt purpose paper introduce digitalization model dm building construction course architectural education response recent emerging technology era digital transformation dm developed applied augmented reality ar technology boost perception understanding ability solve building construction detail lt b gt design methodology approach lt b gt based thorough review recent technology like ar virtual reality vr building information modelling bim application architectural education methodology involves generation model application evaluation model based integration bim ar applied third year building construction project course student designed residential building accordingly prepared construction drawing adapting dm online survey based technology acceptance model conducted evaluate dm quantitative data analysis spss excel lt b gt finding lt b gt key finding study include following item determination proper digital tool definition step workflow based building project phase develop construction drawing define precise detail effectively help dm generated applied according survey result dm involves bim based ar considered beneficial highly motivating providing better perception construction detail lt b gt originality value lt b gt mplication ar vr technology frequently seen design studio whereas building construction course state traditional approach however huge potential digitalization building construction education increasing perception student together increased level communication study aim close gap digitalization proposing dm brings systematic approach considering phase building construction project conceptual schematic design development construction document using bim integrated ar moreover novel model specifically brings new approach generation qr code construction detail embed video simulation two dimensional drawing sheet furthermore dm proposes new approach satisfy emerging need requirement architecture engineering construction industry,lt b gt purpose lt b gt purpose paper introduce digitalization model dm building construction course architectural education response recent emerging technology era digital transformation dm developed applied augmented reality ar technology boost perception understanding ability solve building construction detail lt b gt design methodology approach lt b gt based thorough review recent technology like ar virtual reality vr building information modelling bim application architectural education methodology involves generation model application evaluation model based integration bim ar applied third year building construction project course student designed residential building accordingly prepared construction drawing adapting dm online survey based technology acceptance model conducted evaluate dm quantitative data analysis spss excel lt b gt finding lt b gt key finding study include following item determination proper digital tool definition step workflow based building project phase develop construction drawing define precise detail effectively help dm generated applied according survey result dm involves bim based ar considered beneficial highly motivating providing better perception construction detail lt b gt originality value lt b gt mplication ar vr technology frequently seen design studio whereas building construction course state traditional approach however huge potential digitalization building construction education increasing perception student together increased level communication study aim close gap digitalization proposing dm brings systematic approach considering phase building construction project conceptual schematic design development construction document using bim integrated ar moreover novel model specifically brings new approach generation qr code construction detail embed video simulation two dimensional drawing sheet furthermore dm proposes new approach satisfy emerging need requirement architecture engineering construction industryarchitecture building_information_modelling building_management_systems buildings construction_industry data_analysis project_management qr_codes structural_engineering_computing technology_acceptance_modelarchitectural_education architecture_engineering_construction_industry augmented_reality bim based_ar building_construction_details building_construction_education building_project_phases construction_courses construction_documents construction_drawings design_development digital_transformations digitalization_model dm information_modelling proper_digital_tools recent_emerging_technologies residential_building technology_acceptance_model virtual_reality year_building_construction_project_course
147,Assessment of a Location-Based Mobile Augmented-Reality Game by Adult Users with the ARCS Model,"Sdravopoulou, K., Muñoz González, J. M., & Hidalgo-Ariza, M. D. (2021). Assessment of a Location-Based Mobile Augmented-Reality Game by Adult Users with the ARCS Model. Applied Sciences, 11(14), 6448. https://doi.org/10.3390/app11146448
",10.3390/app11146448,"In mobile augmented reality (MAR) games, learning by doing is important to supplement the theoretical knowledge with practical exercise in order to maximize the learning outcome. However, in many fields, the users are not able to apply their knowledge in practical ways, despite having achieved a good understanding of the theoretical fundamentals and this is even more important to adult learners. The aim of this research is to examine young, middle-aged and elderly adults' opinions about the location-based MAR game Ingress, by applying John Keller's ""ARCS learning motivation model"" (Attention, Relevance, Confidence and Satisfaction). The users' responses to closed questions related to Ingress were collected from 45 adult players aged 20-60 from Greece and were subsequently analyzed by means of pre- and post-quantitative measures of the four ARCS factors. The results show that: (a) game training improves all the factors of ARCS, primarily attention and satisfaction; (b) the responses of young people (20-35) agree more with those of elderly adults (&gt;52) than with those of the intermediate age group of 36-51. Our findings, therefore, highlight the potential and the applicability of the ARCS model in MAR games.","B6250F Mobile radio systems;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction;C7830D Computer games",adult learners;adult players;adult users;ARCS factors;ARCS learning motivation model;ARCS model;elderly adults;game training;Greece;location-based MAR game Ingress;location-based mobile augmented-reality game;mobile augmented reality games,augmented reality;computer aided instruction;computer games;human factors;mobile computing;mobile handsets,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Sdravopoulou, K.; (1) Mun&#771;oz gonza&#769;lez, J.M.; (1) Hidalgo-ariza, M.D.; ","(1) University of Cordoba, Department of Education, C\San Alberto Magno, S/N,, Spain; ",MDPI,-1,"[""computer aided instruction"", ""computer games"", ""human factors"", ""mobile computing"", ""mobile handsets""]","[""computer aided instruction"", ""computer games"", ""human factors"", ""mobile computing"", ""mobile handsets""]",computer aided instruction;computer games;human factors;mobile computing;mobile handsets,liberal arts;input;training;human factors;telecommunication,technology;industries;use cases;end users and user experience,liberal arts;input;training;human factors;telecommunication,technology;industries;use cases;end users and user experience,computer_aided_instruction computer_games human_factors mobile_computing mobile_handsets adult_learners adult_players adult_users arcs_factors arcs_learning_motivation_model arcs_model elderly_adults game_training greece location based_mar_game_ingress location based_mobile_augmented reality_game mobile_augmented_reality_games b6250f_mobile_radio_systems c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7830d_computer_games liberal_arts input training human_factors telecommunication,computer_aided_instruction computer_games human_factors mobile_computing mobile_handsets,adult_learners adult_players adult_users arcs_factors arcs_learning_motivation_model arcs_model elderly_adults game_training greece location based_mar_game_ingress location based_mobile_augmented reality_game mobile_augmented_reality_games,mobile augmented reality mar game learning important supplement theoretical knowledge practical exercise order maximize learning outcome however many field user able apply knowledge practical way despite achieved good understanding theoretical fundamental even important adult learner aim research examine young middle aged elderly adult opinion location based mar game ingres applying john keller arc learning motivation model attention relevance confidence satisfaction user response closed question related ingres collected 45 adult player aged 20 60 greece subsequently analyzed mean pre post quantitative measure four arc factor result show game training improves factor arc primarily attention satisfaction b response young people 20 35 agree elderly adult gt 52 intermediate age group 36 51 finding therefore highlight potential applicability arc model mar game,computer_aided_instruction computer_games human_factors mobile_computing mobile_handsets adult_learners adult_players adult_users arcs_factors arcs_learning_motivation_model arcs_model elderly_adults game_training greece location based_mar_game_ingress location based_mobile_augmented reality_game mobile_augmented_reality_games b6250f_mobile_radio_systems c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7830d_computer_games liberal_arts input training human_factors telecommunication mobile augmented reality mar game learning important supplement theoretical knowledge practical exercise order maximize learning outcome however many field user able apply knowledge practical way despite achieved good understanding theoretical fundamental even important adult learner aim research examine young middle aged elderly adult opinion location based mar game ingres applying john keller arc learning motivation model attention relevance confidence satisfaction user response closed question related ingres collected 45 adult player aged 20 60 greece subsequently analyzed mean pre post quantitative measure four arc factor result show game training improves factor arc primarily attention satisfaction b response young people 20 35 agree elderly adult gt 52 intermediate age group 36 51 finding therefore highlight potential applicability arc model mar game,mobile augmented reality mar game learning important supplement theoretical knowledge practical exercise order maximize learning outcome however many field user able apply knowledge practical way despite achieved good understanding theoretical fundamental even important adult learner aim research examine young middle aged elderly adult opinion location based mar game ingres applying john keller arc learning motivation model attention relevance confidence satisfaction user response closed question related ingres collected 45 adult player aged 20 60 greece subsequently analyzed mean pre post quantitative measure four arc factor result show game training improves factor arc primarily attention satisfaction b response young people 20 35 agree elderly adult gt 52 intermediate age group 36 51 finding therefore highlight potential applicability arc model mar gamecomputer_aided_instruction computer_games human_factors mobile_computing mobile_handsetsadult_learners adult_players adult_users arcs_factors arcs_learning_motivation_model arcs_model elderly_adults game_training greece location based_mar_game_ingress location based_mobile_augmented reality_game mobile_augmented_reality_games
148,Augmented Reality Visualization of Modal Analysis Using the Finite Element Method,"Yavuz Erkek, M., Erkek, S., Jamei, E., Seyedmahmoudian, M., Stojcevski, A., & Horan, B. (2021). Augmented Reality Visualization of Modal Analysis Using the Finite Element Method. Applied Sciences, 11(3), 1310. https://doi.org/10.3390/app11031310
",10.3390/app11031310,"Modal analysis provides the dynamic behavior of an object or structure, and is often undertaken using the Finite Element Method (FEM) due to its ability to deal with arbitrary geometries. This article investigates the use of Augmented Reality (AR) to provide the in situ visualization of a modal analysis for an aluminum impeller. Finite Element Analysis (FEA) software packages regularly use heat maps and shape deformation to visualize the outcomes of a given simulation. AR allows the superimposition of digital information on a view of the real-world environment, and provides the opportunity to overlay such simulation results onto real-world objects and environments. The presented modal analysis undertaken herein provides natural frequencies and the corresponding deformation of an aluminum impeller. The results indicate the ability for the design part and finite element analysis results to be viewed on the physical part. A mobile AR-FEA-based system was developed for Modal Analysis result visualization. This study offers designers and engineers a new way to visualize such simulation results.","B6135 Optical, image and video signal processing;B0290T Finite element analysis;C4185 Finite element analysis;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces",aluminum impeller;augmented reality visualization;finite element analysis software packages;in situ visualization;mobile AR-FEA-based system;modal analysis,augmented reality;data visualisation;deformation;finite element analysis;impellers;modal analysis,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Yavuz erkek, M.; (2) Erkek, S.; (3) Jamei, E.; (4) Seyedmahmoudian, M.; (4) Stojcevski, A.; (1) Horan, B.; ","(1) Deakin University, School of Engineering, Australia; (2) Forms Express Pty Ltd., Australia; (3) Victoria University, College of Engineering and Science, Australia; (4) Swinburne University of Technology, Faculty of Science, Engineering and Technology, Australia; ",MDPI,-1,"[""data visualization"", ""deformation"", ""finite element analysis"", ""impellers"", ""modal analysis""]","[""data visualization"", ""deformation"", ""finite element analysis"", ""impellers"", ""modal analysis""]",data visualization;deformation;finite element analysis;impellers;modal analysis,other;developers;data;graphics,technology;other,other;developers;data;graphics,technology;other,data_visualization deformation finite_element_analysis impellers modal_analysis aluminum_impeller augmented_reality_visualization finite_element_analysis_software_packages in_situ_visualization mobile_ar fea based_system modal_analysis b6135_optical _image_and_video_signal_processing b0290t_finite_element_analysis c4185_finite_element_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces other developers data graphics,data_visualization deformation finite_element_analysis impellers modal_analysis,aluminum_impeller augmented_reality_visualization finite_element_analysis_software_packages in_situ_visualization mobile_ar fea based_system modal_analysis,modal analysis provides dynamic behavior object structure often undertaken using finite element method fem due ability deal arbitrary geometry article investigates use augmented reality ar provide situ visualization modal analysis aluminum impeller finite element analysis fea software package regularly use heat map shape deformation visualize outcome given simulation ar allows superimposition digital information view real world environment provides opportunity overlay simulation result onto real world object environment presented modal analysis undertaken herein provides natural frequency corresponding deformation aluminum impeller result indicate ability design part finite element analysis result viewed physical part mobile ar fea based system developed modal analysis result visualization study offer designer engineer new way visualize simulation result,data_visualization deformation finite_element_analysis impellers modal_analysis aluminum_impeller augmented_reality_visualization finite_element_analysis_software_packages in_situ_visualization mobile_ar fea based_system modal_analysis b6135_optical _image_and_video_signal_processing b0290t_finite_element_analysis c4185_finite_element_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces other developers data graphics modal analysis provides dynamic behavior object structure often undertaken using finite element method fem due ability deal arbitrary geometry article investigates use augmented reality ar provide situ visualization modal analysis aluminum impeller finite element analysis fea software package regularly use heat map shape deformation visualize outcome given simulation ar allows superimposition digital information view real world environment provides opportunity overlay simulation result onto real world object environment presented modal analysis undertaken herein provides natural frequency corresponding deformation aluminum impeller result indicate ability design part finite element analysis result viewed physical part mobile ar fea based system developed modal analysis result visualization study offer designer engineer new way visualize simulation result,modal analysis provides dynamic behavior object structure often undertaken using finite element method fem due ability deal arbitrary geometry article investigates use augmented reality ar provide situ visualization modal analysis aluminum impeller finite element analysis fea software package regularly use heat map shape deformation visualize outcome given simulation ar allows superimposition digital information view real world environment provides opportunity overlay simulation result onto real world object environment presented modal analysis undertaken herein provides natural frequency corresponding deformation aluminum impeller result indicate ability design part finite element analysis result viewed physical part mobile ar fea based system developed modal analysis result visualization study offer designer engineer new way visualize simulation resultdata_visualization deformation finite_element_analysis impellers modal_analysisaluminum_impeller augmented_reality_visualization finite_element_analysis_software_packages in_situ_visualization mobile_ar fea based_system modal_analysis
149,Panoramic ultra-high-definition augmented reality 360&deg; color holograms as inclusive tools in transportation,"Skirnewskaja, J., Montelongo, Y., & Wilkinson, T. D. (2023). Panoramic ultra-high-definition augmented reality 360° color holograms as inclusive tools in transportation. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2657447
",10.1117/12.2657447,"Modern touch control infotainment systems in vehicles present distractions to drivers and endanger road safety. Current industrial head-up displays (HUDs) require the driver to shift the gaze from the road towards a region on the 2D windscreen. Panoramic augmented reality holographic color projections in could prevent driver distraction. This is an inclusive tool to incorporate all members of society into the transportation sector. A 4k color augmented reality holographic automotive head-up display was developed to project road obstacles in 360&deg; in the driver's field of view. This technology could be useful for drivers, including elderly and disabled populations. &copy; 2023 SPIE.","406.2 Roads and Streets;549.3 Nonferrous Metals and Alloys excluding Alkali and Alkaline Earth Metals;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;743 Holography;744.4 Solid State Lasers",3d computer-generated holography;Computer-generated holography;Head-UpDisplay;Heads-up-display;High definition;Inclusive design;LiDAR;Liquid crystal on silicon;RGB fiber laser;Ultra-high,Augmented reality;Color;Holograms;Holographic displays;Liquid crystals;Roads and streets;Silicon;Three dimensional displays,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Skirnewskaja, Jana; (2) Montelongo, Yunuen; (1) Wilkinson, Timothy D.; ","(1) Electrical Engineering Division, Department of Engineering, University of Cambridge, 9 JJ Thomson Avenue, Cambridge; CB3 0FA, United Kingdom; (2) Department of Engineering Science, University of Oxford, Parks Road, Oxford; OX1 3PJ, United Kingdom; ",SPIE,-1,"[""color"", ""holograms"", ""holographic displays"", ""liquid crystals"", ""roads and streets"", ""silicon"", ""three-dimensional displays""]","[""color"", ""holograms"", ""holographic displays"", ""liquid crystals"", ""roads and streets"", ""silicon"", ""three-dimensional displays""]",color;holograms;holographic displays;liquid crystals;roads and streets;silicon;three-dimensional displays,graphics;transportation;chemical;display technology;semiconductors,technology;displays;industries,graphics;transportation;chemical;display technology;semiconductors,technology;displays;industries,color holograms holographic_displays liquid_crystals roads_and_streets silicon three dimensional_displays 3d_computer generated_holography computer generated_holography head updisplay heads up display high_definition inclusive_design lidar liquid_crystal_on_silicon rgb_fiber_laser ultra high 406 2_roads_and_streets 549 3_nonferrous_metals_and_alloys_excluding_alkali_and_alkaline_earth_metals 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 743_holography 744 4_solid_state_lasers graphics transportation chemical display_technology semiconductors,color holograms holographic_displays liquid_crystals roads_and_streets silicon three dimensional_displays,3d_computer generated_holography computer generated_holography head updisplay heads up display high_definition inclusive_design lidar liquid_crystal_on_silicon rgb_fiber_laser ultra high,modern touch control infotainment system vehicle present distraction driver endanger road safety current industrial head display hud require driver shift gaze road towards region 2d windscreen panoramic augmented reality holographic color projection could prevent driver distraction inclusive tool incorporate member society transportation sector 4k color augmented reality holographic automotive head display developed project road obstacle 360 deg driver field view technology could useful driver including elderly disabled population copy 2023 spie,color holograms holographic_displays liquid_crystals roads_and_streets silicon three dimensional_displays 3d_computer generated_holography computer generated_holography head updisplay heads up display high_definition inclusive_design lidar liquid_crystal_on_silicon rgb_fiber_laser ultra high 406 2_roads_and_streets 549 3_nonferrous_metals_and_alloys_excluding_alkali_and_alkaline_earth_metals 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 743_holography 744 4_solid_state_lasers graphics transportation chemical display_technology semiconductors modern touch control infotainment system vehicle present distraction driver endanger road safety current industrial head display hud require driver shift gaze road towards region 2d windscreen panoramic augmented reality holographic color projection could prevent driver distraction inclusive tool incorporate member society transportation sector 4k color augmented reality holographic automotive head display developed project road obstacle 360 deg driver field view technology could useful driver including elderly disabled population copy 2023 spie,modern touch control infotainment system vehicle present distraction driver endanger road safety current industrial head display hud require driver shift gaze road towards region 2d windscreen panoramic augmented reality holographic color projection could prevent driver distraction inclusive tool incorporate member society transportation sector 4k color augmented reality holographic automotive head display developed project road obstacle 360 deg driver field view technology could useful driver including elderly disabled population copy 2023 spiecolor holograms holographic_displays liquid_crystals roads_and_streets silicon three dimensional_displays3d_computer generated_holography computer generated_holography head updisplay heads up display high_definition inclusive_design lidar liquid_crystal_on_silicon rgb_fiber_laser ultra high
150,Integrating Stand-Alone New Media Technologies Such as Games and Virtual and Augmented Reality Software into Learning Management Systems: Integrating Stand-Alone Media Software into LMSs,"Horst, R., Naraghi-Taghi-Off, R., & Dörner, R. (2022). Integrating Stand-Alone New Media Technologies Such as Games and Virtual and Augmented Reality Software into Learning Management Systems. Proceedings of the 2022 6th International Conference on Education and E-Learning. https://doi.org/10.1145/3578837.3578839
",10.1145/3578837.3578839,"Both learning management systems (LMSs) and new media technologies (NMTs, e.g., Augmented/Virtual Reality software or Serious Games) can enhance teaching and learning, however, the integration of both technologies within an E-Learning system is challenging. NMTs are often developed as bulky stand-alone applications, for example, using game engines, which make them difficult to integrate into the LMS courses. Thus, connecting middleware technologies are needed, however, various technologies exist. In this paper, we introduce three techniques (SCORM-Data, xAPI-Injection, and JSON-REST) that integrate stand-alone NMT learning software into LMSs based on existing technologies and standards from the E-Learning domain. We discuss the techniques and their underlying processes based on a prototype implementation and the results of an expert interview and point out the advantages and disadvantages of each technique to give practitioners differentiated advice on which technique to use. Although SCORM-Data has fewer technical requirements, we conclude that our JSON-REST technique was favored through applicability, simplicity, ease of integration, and efficiency.",C7810C Computer-aided instruction;C6130V Virtual reality;C6190Z Other distributed systems software;C7830D Computer games,augmented reality software;bulky stand-alone applications;e-learning system;game engines;JSON-REST technique;learning management systems;LMS courses;middleware technologies;SCORM-Data;serious games;stand-alone media software;stand-alone new media technologies;stand-alone NMT learning software;teaching;technical requirements;virtual reality software;xAPI-Injection,augmented reality;educational courses;learning management systems;middleware;serious games (computing);teaching,2022,Conference article (CA),ICEEL '22: Proceedings of the 2022 6th International Conference on Education and E-Learning,"(1) Horst, R.; (1) Naraghi-Taghi-Off, R.; (1) Do&#776;rner, R.; ","(1) RheinMain University of Applied Sciences, Department of Design, Computer Science, Media, Germany; ",ACM,-1,"[""educational courses"", ""learning management systems"", ""middleware"", ""serious games"", ""teaching""]","[""educational courses"", ""learning management systems"", ""middleware"", ""serious games"", ""teaching""]",educational courses;learning management systems;middleware;serious games;teaching,medical;education;developers;simulation,technology;use cases;industries,medical;education;developers;simulation,technology;use cases;industries,educational_courses learning_management_systems middleware serious_games teaching augmented_reality_software bulky_stand alone_applications e learning_system game_engines json rest_technique learning_management_systems lms_courses middleware_technologies scorm data serious_games stand alone_media_software stand alone_new_media_technologies stand alone_nmt_learning_software teaching technical_requirements virtual_reality_software xapi injection c7810c_computer aided_instruction c6130v_virtual_reality c6190z_other_distributed_systems_software c7830d_computer_games medical education developers simulation,educational_courses learning_management_systems middleware serious_games teaching,augmented_reality_software bulky_stand alone_applications e learning_system game_engines json rest_technique learning_management_systems lms_courses middleware_technologies scorm data serious_games stand alone_media_software stand alone_new_media_technologies stand alone_nmt_learning_software teaching technical_requirements virtual_reality_software xapi injection,learning management system lm new medium technology nmts e g augmented virtual reality software serious game enhance teaching learning however integration technology within e learning system challenging nmts often developed bulky stand alone application example using game engine make difficult integrate lm course thus connecting middleware technology needed however various technology exist paper introduce three technique scorm data xapi injection json rest integrate stand alone nmt learning software lm based existing technology standard e learning domain discus technique underlying process based prototype implementation result expert interview point advantage disadvantage technique give practitioner differentiated advice technique use although scorm data fewer technical requirement conclude json rest technique favored applicability simplicity ease integration efficiency,educational_courses learning_management_systems middleware serious_games teaching augmented_reality_software bulky_stand alone_applications e learning_system game_engines json rest_technique learning_management_systems lms_courses middleware_technologies scorm data serious_games stand alone_media_software stand alone_new_media_technologies stand alone_nmt_learning_software teaching technical_requirements virtual_reality_software xapi injection c7810c_computer aided_instruction c6130v_virtual_reality c6190z_other_distributed_systems_software c7830d_computer_games medical education developers simulation learning management system lm new medium technology nmts e g augmented virtual reality software serious game enhance teaching learning however integration technology within e learning system challenging nmts often developed bulky stand alone application example using game engine make difficult integrate lm course thus connecting middleware technology needed however various technology exist paper introduce three technique scorm data xapi injection json rest integrate stand alone nmt learning software lm based existing technology standard e learning domain discus technique underlying process based prototype implementation result expert interview point advantage disadvantage technique give practitioner differentiated advice technique use although scorm data fewer technical requirement conclude json rest technique favored applicability simplicity ease integration efficiency,learning management system lm new medium technology nmts e g augmented virtual reality software serious game enhance teaching learning however integration technology within e learning system challenging nmts often developed bulky stand alone application example using game engine make difficult integrate lm course thus connecting middleware technology needed however various technology exist paper introduce three technique scorm data xapi injection json rest integrate stand alone nmt learning software lm based existing technology standard e learning domain discus technique underlying process based prototype implementation result expert interview point advantage disadvantage technique give practitioner differentiated advice technique use although scorm data fewer technical requirement conclude json rest technique favored applicability simplicity ease integration efficiencyeducational_courses learning_management_systems middleware serious_games teachingaugmented_reality_software bulky_stand alone_applications e learning_system game_engines json rest_technique learning_management_systems lms_courses middleware_technologies scorm data serious_games stand alone_media_software stand alone_new_media_technologies stand alone_nmt_learning_software teaching technical_requirements virtual_reality_software xapi injection
151,Breaking Edge Shackles: Infrastructure-Free Collaborative Mobile Augmented Reality,"Apicharttrisorn, K., Chen, J., Sekar, V., Rowe, A., & Krishnamurthy, S. V. (2022). Breaking Edge Shackles. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568546
",10.1145/3560905.3568546,"Collaborative AR applications are gaining popularity, but have heavy computing requirements for identifying and tracking AR devices and objects in the ecosystem. Prior AR frameworks typically rely on edge infrastructure to offload AR's compute-heavy tasks. However, such infrastructure may not always be available, and continuously running AR computations on user devices can rapidly drain battery and impact application longevity. In this work, we enable infrastructure-free mobile AR with a low energy footprint, by using&lt;i&gt;collaborative time slicing&lt;/i&gt;to distribute compute-heavy AR tasks across user devices. Realizing this idea is challenging because distributed execution can result in inconsistent synchronization of the AR virtual overlays. Our framework, FreeAR, tackles this with novel lightweight techniques for tightly synchronized virtual overlay placements across user views, and low latency recovery upon disruptions. We prototype FreeAR on Android and show that it can improve the virtual overlay positioning accuracy (with respect to the IOU metric) by up to 78%, relative to state-of-the-art collaborative AR systems, while also reducing power by up to 60% relative to a direct application of those prior solutions.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",Android;AR computations;AR frameworks;AR virtual overlays;battery;breaking edge shackles;collaborative AR applications;collaborative AR systems;collaborative time slicing;compute-heavy AR tasks;distributed execution;edge infrastructure;FreeAR;inconsistent synchronization;infrastructure-free collaborative mobile augmented reality;infrastructure-free mobile AR;low energy footprint;low latency recovery;object tracking;tightly synchronized virtual overlay placements;tracking AR devices;user devices;virtual overlay positioning accuracy,Android (operating system);augmented reality;mobile computing;object tracking,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Apicharttrisorn, K.; (1) Chen, J.; (2) Sekar, V.; (2) Rowe, A.; (1) Krishnamurthy, S.V.; ","(1) University of California, Irvine, Irvine, CA, United States; (2) Carnegie Mellon University, Pittsburgh, PA, United States; ",ACM,-1,"[""android"", ""mobile computing"", ""object tracking""]","[""android"", ""mobile computing"", ""object tracking""]",android;mobile computing;object tracking,computer vision;telecommunication;developers,technology;industries,computer vision;telecommunication;developers,technology;industries,android mobile_computing object_tracking android ar_computations ar_frameworks ar_virtual_overlays battery breaking_edge_shackles collaborative_ar_applications collaborative_ar_systems collaborative_time_slicing compute heavy_ar_tasks distributed_execution edge_infrastructure freear inconsistent_synchronization infrastructure free_collaborative_mobile_augmented_reality infrastructure free_mobile_ar low_energy_footprint low_latency_recovery object_tracking tightly_synchronized_virtual_overlay_placements tracking_ar_devices user_devices virtual_overlay_positioning_accuracy c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision telecommunication developers,android mobile_computing object_tracking,android ar_computations ar_frameworks ar_virtual_overlays battery breaking_edge_shackles collaborative_ar_applications collaborative_ar_systems collaborative_time_slicing compute heavy_ar_tasks distributed_execution edge_infrastructure freear inconsistent_synchronization infrastructure free_collaborative_mobile_augmented_reality infrastructure free_mobile_ar low_energy_footprint low_latency_recovery object_tracking tightly_synchronized_virtual_overlay_placements tracking_ar_devices user_devices virtual_overlay_positioning_accuracy,collaborative ar application gaining popularity heavy computing requirement identifying tracking ar device object ecosystem prior ar framework typically rely edge infrastructure offload ar compute heavy task however infrastructure may always available continuously running ar computation user device rapidly drain battery impact application longevity work enable infrastructure free mobile ar low energy footprint using lt gt collaborative time slicing lt gt distribute compute heavy ar task across user device realizing idea challenging distributed execution result inconsistent synchronization ar virtual overlay framework freear tackle novel lightweight technique tightly synchronized virtual overlay placement across user view low latency recovery upon disruption prototype freear android show improve virtual overlay positioning accuracy respect iou metric 78 relative state art collaborative ar system also reducing power 60 relative direct application prior solution,android mobile_computing object_tracking android ar_computations ar_frameworks ar_virtual_overlays battery breaking_edge_shackles collaborative_ar_applications collaborative_ar_systems collaborative_time_slicing compute heavy_ar_tasks distributed_execution edge_infrastructure freear inconsistent_synchronization infrastructure free_collaborative_mobile_augmented_reality infrastructure free_mobile_ar low_energy_footprint low_latency_recovery object_tracking tightly_synchronized_virtual_overlay_placements tracking_ar_devices user_devices virtual_overlay_positioning_accuracy c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision telecommunication developers collaborative ar application gaining popularity heavy computing requirement identifying tracking ar device object ecosystem prior ar framework typically rely edge infrastructure offload ar compute heavy task however infrastructure may always available continuously running ar computation user device rapidly drain battery impact application longevity work enable infrastructure free mobile ar low energy footprint using lt gt collaborative time slicing lt gt distribute compute heavy ar task across user device realizing idea challenging distributed execution result inconsistent synchronization ar virtual overlay framework freear tackle novel lightweight technique tightly synchronized virtual overlay placement across user view low latency recovery upon disruption prototype freear android show improve virtual overlay positioning accuracy respect iou metric 78 relative state art collaborative ar system also reducing power 60 relative direct application prior solution,collaborative ar application gaining popularity heavy computing requirement identifying tracking ar device object ecosystem prior ar framework typically rely edge infrastructure offload ar compute heavy task however infrastructure may always available continuously running ar computation user device rapidly drain battery impact application longevity work enable infrastructure free mobile ar low energy footprint using lt gt collaborative time slicing lt gt distribute compute heavy ar task across user device realizing idea challenging distributed execution result inconsistent synchronization ar virtual overlay framework freear tackle novel lightweight technique tightly synchronized virtual overlay placement across user view low latency recovery upon disruption prototype freear android show improve virtual overlay positioning accuracy respect iou metric 78 relative state art collaborative ar system also reducing power 60 relative direct application prior solutionandroid mobile_computing object_trackingandroid ar_computations ar_frameworks ar_virtual_overlays battery breaking_edge_shackles collaborative_ar_applications collaborative_ar_systems collaborative_time_slicing compute heavy_ar_tasks distributed_execution edge_infrastructure freear inconsistent_synchronization infrastructure free_collaborative_mobile_augmented_reality infrastructure free_mobile_ar low_energy_footprint low_latency_recovery object_tracking tightly_synchronized_virtual_overlay_placements tracking_ar_devices user_devices virtual_overlay_positioning_accuracy
152,Virtual Reality (VR) Simulation and Augmented Reality (AR) Navigation in Orthognathic Surgery: A Case Report,"Jo, Y.-J., Choi, J.-S., Kim, J., Kim, H.-J., & Moon, S.-Y. (2021). Virtual Reality (VR) Simulation and Augmented Reality (AR) Navigation in Orthognathic Surgery: A Case Report. Applied Sciences, 11(12), 5673. https://doi.org/10.3390/app11125673
",10.3390/app11125673,"VR and AR technology have gradually developed to the extent that they could help operators in the surgical field. In this study, we present a case of VR simulation for preoperative planning and AR navigation applied to orthognathic surgery. The average difference between the preplanned data and the post-operative results was 3.00 mm, on average, and the standard deviation was 1.44 mm. VR simulation could provide great advantages for 3D medical simulations, with accurate manipulation and immersiveness. AR navigation has great potential in medical application; its advantages include displaying real time augmented 3D models of patients. Moreover, it is easily applied in the surgical field, without complicated 3D simulations or 3D-printed surgical guides.",A8770G Patient care and treatment;B7520 Patient care and treatment;C6130V Virtual reality;C7330 Biology and medical computing,3D medical simulations;augmented reality navigation;medical application;orthognathic surgery;post-operative results;preoperative planning;preplanned data;standard deviation;surgical field;virtual reality simulation,augmented reality;medical computing;surgery,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Jo, Y.-J.; (1) Choi, J.-S.; (1) Kim, J.; (1) Kim, H.-J.; (1) Moon, S.-Y.; ","(1) Chosun University, Department of Oral and Maxillofacial Surgery, Korea, Republic of; ",MDPI,-1,"[""medical computing"", ""surgery""]","[""medical computing"", ""surgery""]",medical computing;surgery,medical,industries,medical,industries,medical_computing surgery 3d_medical_simulations augmented_reality_navigation medical_application orthognathic_surgery post operative_results preoperative_planning preplanned_data standard_deviation surgical_field virtual_reality_simulation a8770g_patient_care_and_treatment b7520_patient_care_and_treatment c6130v_virtual_reality c7330_biology_and_medical_computing medical,medical_computing surgery,3d_medical_simulations augmented_reality_navigation medical_application orthognathic_surgery post operative_results preoperative_planning preplanned_data standard_deviation surgical_field virtual_reality_simulation,vr ar technology gradually developed extent could help operator surgical field study present case vr simulation preoperative planning ar navigation applied orthognathic surgery average difference preplanned data post operative result 3 00 mm average standard deviation 1 44 mm vr simulation could provide great advantage 3d medical simulation accurate manipulation immersiveness ar navigation great potential medical application advantage include displaying real time augmented 3d model patient moreover easily applied surgical field without complicated 3d simulation 3d printed surgical guide,medical_computing surgery 3d_medical_simulations augmented_reality_navigation medical_application orthognathic_surgery post operative_results preoperative_planning preplanned_data standard_deviation surgical_field virtual_reality_simulation a8770g_patient_care_and_treatment b7520_patient_care_and_treatment c6130v_virtual_reality c7330_biology_and_medical_computing medical vr ar technology gradually developed extent could help operator surgical field study present case vr simulation preoperative planning ar navigation applied orthognathic surgery average difference preplanned data post operative result 3 00 mm average standard deviation 1 44 mm vr simulation could provide great advantage 3d medical simulation accurate manipulation immersiveness ar navigation great potential medical application advantage include displaying real time augmented 3d model patient moreover easily applied surgical field without complicated 3d simulation 3d printed surgical guide,vr ar technology gradually developed extent could help operator surgical field study present case vr simulation preoperative planning ar navigation applied orthognathic surgery average difference preplanned data post operative result 3 00 mm average standard deviation 1 44 mm vr simulation could provide great advantage 3d medical simulation accurate manipulation immersiveness ar navigation great potential medical application advantage include displaying real time augmented 3d model patient moreover easily applied surgical field without complicated 3d simulation 3d printed surgical guidemedical_computing surgery3d_medical_simulations augmented_reality_navigation medical_application orthognathic_surgery post operative_results preoperative_planning preplanned_data standard_deviation surgical_field virtual_reality_simulation
153,A UWB-Driven Self-Actuated Projector Platform for Interactive Augmented Reality Applications,"Elsharkawy, A., Naheem, K., Koo, D., & Kim, M. S. (2021). A UWB-Driven Self-Actuated Projector Platform for Interactive Augmented Reality Applications. Applied Sciences, 11(6), 2871. https://doi.org/10.3390/app11062871
",10.3390/app11062871,"With the rapid development of interactive technology, creating systems that allow users to define their interactive envelope freely and provide multi-interactive modalities is important to build up an intuitive interactive space. We present an indoor interactive system where a human can customize and interact through a projected screen utilizing the surrounding surfaces. An ultra-wideband (UWB) wireless sensor network was used to assist human-centered interaction design and navigate the self-actuated projector platform. We developed a UWB-based calibration algorithm to facilitate the interaction with the customized projected screens, where a hand-held input device was designed to perform mid-air interactive functions. Sixteen participants were recruited to evaluate the system performance. A prototype level implementation was tested inside a simulated museum environment, where a self-actuated projector provides interactive explanatory content for the on-display artifacts under the user's command. Our results depict the applicability to designate the interactive screen efficiently indoors and interact with the augmented content with reasonable accuracy and relatively low workload. Our findings also provide valuable user experience information regarding the design of mobile and projection-based augmented reality systems, with the ability to overcome the limitations of other conventional techniques.",B6250K Wireless sensor networks;C6130V Virtual reality;C7820 Humanities computing,customized projected screens;hand-held input device;indoor interactive system;interaction design;interactive augmented reality applications;interactive envelope;interactive explanatory content;interactive screen;interactive technology;intuitive interactive space;mid-air interactive functions;mobile projection-based augmented reality systems;multiinteractive modalities;projected screen;prototype level implementation;sensor network;surrounding surfaces;system performance;UWB-based calibration algorithm;UWB-driven self-actuated projector platform;valuable user experience information,augmented reality;calibration;museums;optical projectors;wireless sensor networks,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Elsharkawy, A.; (1) Naheem, K.; (1) Koo, D.; (1) Kim, M.S.; ","(1) Gwangju Institute of Science and Technology, School of Integrated Technology, Korea, Republic of; ",MDPI,-1,"[""calibration"", ""museums"", ""optical projectors"", ""wireless sensor networks""]","[""calibration"", ""museums"", ""optical projectors"", ""wireless sensor networks""]",calibration;museums;optical projectors;wireless sensor networks,cultural heritage;sensors;optics;networks,technology;displays;industries,cultural heritage;sensors;optics;networks,technology;displays;industries,calibration museums optical_projectors wireless_sensor_networks customized_projected_screens hand held_input_device indoor_interactive_system interaction_design interactive_augmented_reality_applications interactive_envelope interactive_explanatory_content interactive_screen interactive_technology intuitive_interactive_space mid air_interactive_functions mobile_projection based_augmented_reality_systems multiinteractive_modalities projected_screen prototype_level_implementation sensor_network surrounding_surfaces system_performance uwb based_calibration_algorithm uwb driven_self actuated_projector_platform valuable_user_experience_information b6250k_wireless_sensor_networks c6130v_virtual_reality c7820_humanities_computing cultural_heritage sensors optics networks,calibration museums optical_projectors wireless_sensor_networks,customized_projected_screens hand held_input_device indoor_interactive_system interaction_design interactive_augmented_reality_applications interactive_envelope interactive_explanatory_content interactive_screen interactive_technology intuitive_interactive_space mid air_interactive_functions mobile_projection based_augmented_reality_systems multiinteractive_modalities projected_screen prototype_level_implementation sensor_network surrounding_surfaces system_performance uwb based_calibration_algorithm uwb driven_self actuated_projector_platform valuable_user_experience_information,rapid development interactive technology creating system allow user define interactive envelope freely provide multi interactive modality important build intuitive interactive space present indoor interactive system human customize interact projected screen utilizing surrounding surface ultra wideband uwb wireless sensor network used assist human centered interaction design navigate self actuated projector platform developed uwb based calibration algorithm facilitate interaction customized projected screen hand held input device designed perform mid air interactive function sixteen participant recruited evaluate system performance prototype level implementation tested inside simulated museum environment self actuated projector provides interactive explanatory content display artifact user command result depict applicability designate interactive screen efficiently indoors interact augmented content reasonable accuracy relatively low workload finding also provide valuable user experience information regarding design mobile projection based augmented reality system ability overcome limitation conventional technique,calibration museums optical_projectors wireless_sensor_networks customized_projected_screens hand held_input_device indoor_interactive_system interaction_design interactive_augmented_reality_applications interactive_envelope interactive_explanatory_content interactive_screen interactive_technology intuitive_interactive_space mid air_interactive_functions mobile_projection based_augmented_reality_systems multiinteractive_modalities projected_screen prototype_level_implementation sensor_network surrounding_surfaces system_performance uwb based_calibration_algorithm uwb driven_self actuated_projector_platform valuable_user_experience_information b6250k_wireless_sensor_networks c6130v_virtual_reality c7820_humanities_computing cultural_heritage sensors optics networks rapid development interactive technology creating system allow user define interactive envelope freely provide multi interactive modality important build intuitive interactive space present indoor interactive system human customize interact projected screen utilizing surrounding surface ultra wideband uwb wireless sensor network used assist human centered interaction design navigate self actuated projector platform developed uwb based calibration algorithm facilitate interaction customized projected screen hand held input device designed perform mid air interactive function sixteen participant recruited evaluate system performance prototype level implementation tested inside simulated museum environment self actuated projector provides interactive explanatory content display artifact user command result depict applicability designate interactive screen efficiently indoors interact augmented content reasonable accuracy relatively low workload finding also provide valuable user experience information regarding design mobile projection based augmented reality system ability overcome limitation conventional technique,rapid development interactive technology creating system allow user define interactive envelope freely provide multi interactive modality important build intuitive interactive space present indoor interactive system human customize interact projected screen utilizing surrounding surface ultra wideband uwb wireless sensor network used assist human centered interaction design navigate self actuated projector platform developed uwb based calibration algorithm facilitate interaction customized projected screen hand held input device designed perform mid air interactive function sixteen participant recruited evaluate system performance prototype level implementation tested inside simulated museum environment self actuated projector provides interactive explanatory content display artifact user command result depict applicability designate interactive screen efficiently indoors interact augmented content reasonable accuracy relatively low workload finding also provide valuable user experience information regarding design mobile projection based augmented reality system ability overcome limitation conventional techniquecalibration museums optical_projectors wireless_sensor_networkscustomized_projected_screens hand held_input_device indoor_interactive_system interaction_design interactive_augmented_reality_applications interactive_envelope interactive_explanatory_content interactive_screen interactive_technology intuitive_interactive_space mid air_interactive_functions mobile_projection based_augmented_reality_systems multiinteractive_modalities projected_screen prototype_level_implementation sensor_network surrounding_surfaces system_performance uwb based_calibration_algorithm uwb driven_self actuated_projector_platform valuable_user_experience_information
154,The role of augmented reality-based unplugged computer programming approach in the effectiveness of computational thinking,"Threekunprapa, A., & Yasri, P. (2021). The role of augmented reality-based unplugged computer programming approach in the effectiveness of computational thinking. International Journal of Mobile Learning and Organisation, 15(3), 233. https://doi.org/10.1504/ijmlo.2021.116506
",10.1504/IJMLO.2021.116506,"Recently, pedagogical approaches to promote computational thinking among 21st century learners have increasingly become a topic of interest in educational research. Studies revealed that unplugged computer programming, learning coding without a computer, can enhance students' computational thinking and positive attitudes towards computer programming. However, when dealing with complex computer science concepts, they face limitations. This study therefore developed a solution adopting unplugged coding using flowcharts integrated with Augmented Reality (AR) technology to help scaffold students (called AR semi-unplugged coding). It recruited 120 secondary students for data collection, divided into an experimental group and a control group (unplugged coding). It showed that although both exhibited improved computational thinking and increased self-efficacy after participating in their assigned activity, those in the experimental group outperformed their counterparts statistically. Moreover, the developed solution attracted a greater level of perceived usefulness by users which shows its potential to become an effective approach for promoting computational thinking.",C0220 Computing education and training;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C7810C Computer-aided instruction,AR technology;augmented reality-based unplugged computer programming approach;computational thinking;computer science concepts;pedagogical approach;perceived usefulness;semiunplugged coding;students;unplugged coding,augmented reality;computer aided instruction;computer science education;educational courses;human factors,2021,Journal article (JA),Int. J. Mob. Learn. Organ. (Switzerland),"(1) Threekunprapa, A.; (1) Yasri, P.; ","(1) Mahidol University, Institute for Innovative Learning, Thailand; ",Inderscience Publishers,-1,"[""computer aided instruction"", ""computer science education"", ""educational courses"", ""human factors""]","[""computer aided instruction"", ""computer science education"", ""educational courses"", ""human factors""]",computer aided instruction;computer science education;educational courses;human factors,human factors;education;developers;training,technology;end users and user experience;use cases;industries,human factors;education;developers;training,technology;end users and user experience;use cases;industries,computer_aided_instruction computer_science_education educational_courses human_factors ar_technology augmented_reality based_unplugged_computer_programming_approach computational_thinking computer_science_concepts pedagogical_approach perceived_usefulness semiunplugged_coding students unplugged_coding c0220_computing_education_and_training c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction human_factors education developers training,computer_aided_instruction computer_science_education educational_courses human_factors,ar_technology augmented_reality based_unplugged_computer_programming_approach computational_thinking computer_science_concepts pedagogical_approach perceived_usefulness semiunplugged_coding students unplugged_coding,recently pedagogical approach promote computational thinking among 21st century learner increasingly become topic interest educational research study revealed unplugged computer programming learning coding without computer enhance student computational thinking positive attitude towards computer programming however dealing complex computer science concept face limitation study therefore developed solution adopting unplugged coding using flowchart integrated augmented reality ar technology help scaffold student called ar semi unplugged coding recruited 120 secondary student data collection divided experimental group control group unplugged coding showed although exhibited improved computational thinking increased self efficacy participating assigned activity experimental group outperformed counterpart statistically moreover developed solution attracted greater level perceived usefulness user show potential become effective approach promoting computational thinking,computer_aided_instruction computer_science_education educational_courses human_factors ar_technology augmented_reality based_unplugged_computer_programming_approach computational_thinking computer_science_concepts pedagogical_approach perceived_usefulness semiunplugged_coding students unplugged_coding c0220_computing_education_and_training c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction human_factors education developers training recently pedagogical approach promote computational thinking among 21st century learner increasingly become topic interest educational research study revealed unplugged computer programming learning coding without computer enhance student computational thinking positive attitude towards computer programming however dealing complex computer science concept face limitation study therefore developed solution adopting unplugged coding using flowchart integrated augmented reality ar technology help scaffold student called ar semi unplugged coding recruited 120 secondary student data collection divided experimental group control group unplugged coding showed although exhibited improved computational thinking increased self efficacy participating assigned activity experimental group outperformed counterpart statistically moreover developed solution attracted greater level perceived usefulness user show potential become effective approach promoting computational thinking,recently pedagogical approach promote computational thinking among 21st century learner increasingly become topic interest educational research study revealed unplugged computer programming learning coding without computer enhance student computational thinking positive attitude towards computer programming however dealing complex computer science concept face limitation study therefore developed solution adopting unplugged coding using flowchart integrated augmented reality ar technology help scaffold student called ar semi unplugged coding recruited 120 secondary student data collection divided experimental group control group unplugged coding showed although exhibited improved computational thinking increased self efficacy participating assigned activity experimental group outperformed counterpart statistically moreover developed solution attracted greater level perceived usefulness user show potential become effective approach promoting computational thinkingcomputer_aided_instruction computer_science_education educational_courses human_factorsar_technology augmented_reality based_unplugged_computer_programming_approach computational_thinking computer_science_concepts pedagogical_approach perceived_usefulness semiunplugged_coding students unplugged_coding
155,Gamified Augmented Reality Mobile Application for Tourism in Kuching,"Tay, C. A., Dominic, B. B., Ho, H. I., Annuar, N., & Saferinor, N. E. M. (2023). Gamified Augmented Reality Mobile Application for Tourism in Kuching. Proceedings of the 9th International Conference on Computational Science and Technology, 355–366. https://doi.org/10.1007/978-981-19-8406-8_27
",10.1007/978-981-19-8406-8_27,"Augmented Reality (AR) for tourism utilizing mobile application mostly features scanning prefixed image marker by tourist in order to retrieve additional multimedia content for learning. This paper proposes the use of similar AR application for tourism that extends beyond learning to include gamification for the enhanced tourist&rsquo;s experience. Majority of tourism AR uses marker-based method like scanning QR code to load virtual objects on the screen. The current study will explore marker-less method using spatial anchor. Furthermore, functionality for site operator, an aspect often neglected in literature, like the ability to dynamically add content without relying on developer, will be categorically examined. Platforms, frameworks and services used include Unity, AR Core or AR Foundation and Azure cloud services. This would culminate in implementation and evaluation of an AR mobile application prototype that benefits both tourists and site operators towards proliferation of gamified AR tourism in Kuching city of Sarawak state in Malaysia. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications",'current;Augmented reality applications;Cloud services;Gamification;Kuching city;Mobile applications;Multimedia contents;QR codes;Spatial anchor;Virtual objects,Mobile computing;Tourism,2023,Conference article (CA),Lect. Notes Electr. Eng.,"(1) Tay, Chung Ang; (1) Dominic, Bryan Benjamin; (1) Ho, Hai Inn; (1) Annuar, Norahima; (1) Saferinor, Nur Elana Mohd; ","(1) i-CATS University College, Sarawak, Kuching, Malaysia; ",Springer Science and Business Media Deutschland GmbH,-1,"[""mobile computing"", ""tourism""]","[""mobile computing"", ""tourism""]",mobile computing;tourism,cultural heritage;telecommunication,industries,cultural heritage;telecommunication,industries,mobile_computing tourism current augmented_reality_applications cloud_services gamification kuching_city mobile_applications multimedia_contents qr_codes spatial_anchor virtual_objects 723_computer_software _data_handling_and_applications cultural_heritage telecommunication,mobile_computing tourism,current augmented_reality_applications cloud_services gamification kuching_city mobile_applications multimedia_contents qr_codes spatial_anchor virtual_objects,augmented reality ar tourism utilizing mobile application mostly feature scanning prefixed image marker tourist order retrieve additional multimedia content learning paper proposes use similar ar application tourism extends beyond learning include gamification enhanced tourist rsquo experience majority tourism ar us marker based method like scanning qr code load virtual object screen current study explore marker le method using spatial anchor furthermore functionality site operator aspect often neglected literature like ability dynamically add content without relying developer categorically examined platform framework service used include unity ar core ar foundation azure cloud service would culminate implementation evaluation ar mobile application prototype benefit tourist site operator towards proliferation gamified ar tourism kuching city sarawak state malaysia copy 2023 author exclusive license springer nature singapore pte ltd,mobile_computing tourism current augmented_reality_applications cloud_services gamification kuching_city mobile_applications multimedia_contents qr_codes spatial_anchor virtual_objects 723_computer_software _data_handling_and_applications cultural_heritage telecommunication augmented reality ar tourism utilizing mobile application mostly feature scanning prefixed image marker tourist order retrieve additional multimedia content learning paper proposes use similar ar application tourism extends beyond learning include gamification enhanced tourist rsquo experience majority tourism ar us marker based method like scanning qr code load virtual object screen current study explore marker le method using spatial anchor furthermore functionality site operator aspect often neglected literature like ability dynamically add content without relying developer categorically examined platform framework service used include unity ar core ar foundation azure cloud service would culminate implementation evaluation ar mobile application prototype benefit tourist site operator towards proliferation gamified ar tourism kuching city sarawak state malaysia copy 2023 author exclusive license springer nature singapore pte ltd,augmented reality ar tourism utilizing mobile application mostly feature scanning prefixed image marker tourist order retrieve additional multimedia content learning paper proposes use similar ar application tourism extends beyond learning include gamification enhanced tourist rsquo experience majority tourism ar us marker based method like scanning qr code load virtual object screen current study explore marker le method using spatial anchor furthermore functionality site operator aspect often neglected literature like ability dynamically add content without relying developer categorically examined platform framework service used include unity ar core ar foundation azure cloud service would culminate implementation evaluation ar mobile application prototype benefit tourist site operator towards proliferation gamified ar tourism kuching city sarawak state malaysia copy 2023 author exclusive license springer nature singapore pte ltdmobile_computing tourismcurrent augmented_reality_applications cloud_services gamification kuching_city mobile_applications multimedia_contents qr_codes spatial_anchor virtual_objects
156,More than meets the eye: In-store retail experiences with augmented reality smart glasses,"Pfeifer, P., Hilken, T., Heller, J., Alimamy, S., & Di Palma, R. (2023). More than meets the eye: In-store retail experiences with augmented reality smart glasses. Computers in Human Behavior, 146, 107816. https://doi.org/10.1016/j.chb.2023.107816
",10.1016/j.chb.2023.107816,"Augmented reality smart glasses (ARSGs) promise to enhance consumer experiences and decision-making when deployed as in-store retail technologies. However, research to date has not studied in-store use cases; instead, it has focused primarily on consumers' potential adoption of these devices for everyday use. Nor have prior studies compared ARSG uses with the now-common use of AR on touchscreen devices. The current research addresses these knowledge gaps by examining whether ARSGs outperform AR on touchscreen devices in the context of in-store retail experiences. Testing with an actual retail application (n = 308) shows that ARSGs are superior to AR on touchscreen devices for evoking consumers&rsquo; perceptions of immersion and mental intangibility. Furthermore, this superiority leads consumers to evaluate their shopping experiences more positively in terms of their decision comfort, satisfaction, and ease of evaluation, with significantly positive effects on their purchase intentions. These results highlight the relevance of implementing ARSGs in-store and provide retailers with recommendations for effective ARSG strategies. &copy; 2023 The Authors","723 Computer Software, Data Handling and Applications;812.3 Glass;912.2 Management",'current;Augmented reality smart glass;Consumer perception;Decisions makings;Embodiment;Knowledge gaps;Potential adoption;Purchase intention;Retail experience;Smart glass,Decision making;Glass;Purchasing;Sales,2023,Journal article (JA),Comput. Hum. Behav.,"(1) Pfeifer, Pauline; (1) Hilken, Tim; (1) Heller, Jonas; (2) Alimamy, Saifeddin; (1) Di Palma, Roberta; ","(1) Department of Marketing and Supply Chain Management, Maastricht University, Maastricht, Netherlands; (2) College of Business, Zayed University, Abu Dhabi, United Arab Emirates; ",Elsevier Ltd,-1,"[""decision making"", ""glass"", ""purchasing"", ""sales""]","[""decision making"", ""glass"", ""purchasing"", ""sales""]",decision making;glass;purchasing;sales,sales and marketing;human factors;chemical;logistics,end users and user experience;business;industries,sales and marketing;human factors;chemical;logistics,end users and user experience;business;industries,decision_making glass purchasing sales current augmented_reality_smart_glass consumer_perception decisions_makings embodiment knowledge_gaps potential_adoption purchase_intention retail_experience smart_glass 723_computer_software _data_handling_and_applications 812 3_glass 912 2_management sales_and_marketing human_factors chemical logistics,decision_making glass purchasing sales,current augmented_reality_smart_glass consumer_perception decisions_makings embodiment knowledge_gaps potential_adoption purchase_intention retail_experience smart_glass,augmented reality smart glass arsgs promise enhance consumer experience decision making deployed store retail technology however research date studied store use case instead focused primarily consumer potential adoption device everyday use prior study compared arsg us common use ar touchscreen device current research address knowledge gap examining whether arsgs outperform ar touchscreen device context store retail experience testing actual retail application n 308 show arsgs superior ar touchscreen device evoking consumer rsquo perception immersion mental intangibility furthermore superiority lead consumer evaluate shopping experience positively term decision comfort satisfaction ease evaluation significantly positive effect purchase intention result highlight relevance implementing arsgs store provide retailer recommendation effective arsg strategy copy 2023 author,decision_making glass purchasing sales current augmented_reality_smart_glass consumer_perception decisions_makings embodiment knowledge_gaps potential_adoption purchase_intention retail_experience smart_glass 723_computer_software _data_handling_and_applications 812 3_glass 912 2_management sales_and_marketing human_factors chemical logistics augmented reality smart glass arsgs promise enhance consumer experience decision making deployed store retail technology however research date studied store use case instead focused primarily consumer potential adoption device everyday use prior study compared arsg us common use ar touchscreen device current research address knowledge gap examining whether arsgs outperform ar touchscreen device context store retail experience testing actual retail application n 308 show arsgs superior ar touchscreen device evoking consumer rsquo perception immersion mental intangibility furthermore superiority lead consumer evaluate shopping experience positively term decision comfort satisfaction ease evaluation significantly positive effect purchase intention result highlight relevance implementing arsgs store provide retailer recommendation effective arsg strategy copy 2023 author,augmented reality smart glass arsgs promise enhance consumer experience decision making deployed store retail technology however research date studied store use case instead focused primarily consumer potential adoption device everyday use prior study compared arsg us common use ar touchscreen device current research address knowledge gap examining whether arsgs outperform ar touchscreen device context store retail experience testing actual retail application n 308 show arsgs superior ar touchscreen device evoking consumer rsquo perception immersion mental intangibility furthermore superiority lead consumer evaluate shopping experience positively term decision comfort satisfaction ease evaluation significantly positive effect purchase intention result highlight relevance implementing arsgs store provide retailer recommendation effective arsg strategy copy 2023 authordecision_making glass purchasing salescurrent augmented_reality_smart_glass consumer_perception decisions_makings embodiment knowledge_gaps potential_adoption purchase_intention retail_experience smart_glass
157,Application of Augmented Reality for the Monitoring of Parameters of Industrial Instruments,"Navas, J. L., Toapanta, J. L., & Freire, L. O. (2023). Application of Augmented Reality for the Monitoring of Parameters of Industrial Instruments. Computational Intelligence for Engineering and Management Applications, 689–701. https://doi.org/10.1007/978-981-19-8493-8_51
",10.1007/978-981-19-8493-8_51,"The development of this augmented reality application on mobile devices with Android operating system is oriented for the identification and visualization of industrial equipment and instruments, the interaction through the characteristics and labels of its parts, exploded views and assembly that make up a process of a level control panel. The generation of this mobile application was done with the use of recognition of each element through the generation of a QR code, to be subsequently focused on 3D models using CAD software linked through a multiplatform. Additionally, the simulation and visualization of data from industrial sensors in real time of the process are based on the operation of the instruments, and these generated data contribute to the development of skills for the manipulation and control of industrial processes. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;723.5 Computer Applications",Augmented reality applications;Control module;Control panels;Digitalization;Exploded views;Industrial equipment;Industrial instruments;Industrial processs;Mobile applications;QR codes,Application programs;Computer aided design;Data visualization;Mobile computing;Process control;Three dimensional computer graphics;Virtual reality;Visualization,2023,Conference article (CA),Lect. Notes Electr. Eng.,"(1) Navas, Jairo L.; (1) Toapanta, Jorge L.; (1) Freire, Luigi O.; ","(1) Universidad T&eacute;cnica de Cotopaxi, Latacunga, Ecuador; ",Springer Science and Business Media Deutschland GmbH,-1,"[""application programs"", ""computer aided design"", ""data visualization"", ""mobile computing"", ""process control"", ""three dimensional computer graphics"", ""visualization""]","[""application programs"", ""computer aided design"", ""data visualization"", ""mobile computing"", ""process control"", ""three dimensional computer graphics"", ""visualization""]",application programs;computer aided design;data visualization;mobile computing;process control;three dimensional computer graphics;visualization,graphics;industrial equipment;telecommunication;developers;data;human-computer interaction,technology;industries;end users and user experience,graphics;industrial equipment;telecommunication;developers;data;human-computer interaction,technology;industries;end users and user experience,application_programs computer_aided_design data_visualization mobile_computing process_control three_dimensional_computer_graphics visualization augmented_reality_applications control_module control_panels digitalization exploded_views industrial_equipment industrial_instruments industrial_processs mobile_applications qr_codes 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications graphics industrial_equipment telecommunication developers data human computer_interaction,application_programs computer_aided_design data_visualization mobile_computing process_control three_dimensional_computer_graphics visualization,augmented_reality_applications control_module control_panels digitalization exploded_views industrial_equipment industrial_instruments industrial_processs mobile_applications qr_codes,development augmented reality application mobile device android operating system oriented identification visualization industrial equipment instrument interaction characteristic label part exploded view assembly make process level control panel generation mobile application done use recognition element generation qr code subsequently focused 3d model using cad software linked multiplatform additionally simulation visualization data industrial sensor real time process based operation instrument generated data contribute development skill manipulation control industrial process copy 2023 author exclusive license springer nature singapore pte ltd,application_programs computer_aided_design data_visualization mobile_computing process_control three_dimensional_computer_graphics visualization augmented_reality_applications control_module control_panels digitalization exploded_views industrial_equipment industrial_instruments industrial_processs mobile_applications qr_codes 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications graphics industrial_equipment telecommunication developers data human computer_interaction development augmented reality application mobile device android operating system oriented identification visualization industrial equipment instrument interaction characteristic label part exploded view assembly make process level control panel generation mobile application done use recognition element generation qr code subsequently focused 3d model using cad software linked multiplatform additionally simulation visualization data industrial sensor real time process based operation instrument generated data contribute development skill manipulation control industrial process copy 2023 author exclusive license springer nature singapore pte ltd,development augmented reality application mobile device android operating system oriented identification visualization industrial equipment instrument interaction characteristic label part exploded view assembly make process level control panel generation mobile application done use recognition element generation qr code subsequently focused 3d model using cad software linked multiplatform additionally simulation visualization data industrial sensor real time process based operation instrument generated data contribute development skill manipulation control industrial process copy 2023 author exclusive license springer nature singapore pte ltdapplication_programs computer_aided_design data_visualization mobile_computing process_control three_dimensional_computer_graphics visualizationaugmented_reality_applications control_module control_panels digitalization exploded_views industrial_equipment industrial_instruments industrial_processs mobile_applications qr_codes
158,"Integrated optical phased arrays: augmented reality, LiDAR, and beyond","Notaros, J. (2023). Integrated optical phased arrays: augmented reality, LiDAR, and beyond. AI and Optical Data Sciences IV. https://doi.org/10.1117/12.2649394
",10.1117/12.2649394,"Integrated optical phased arrays (OPAs), fabricated in advanced silicon-photonics platforms, enable manipulation and dynamic control of free-space light in a compact form factor, at low costs, and in a non-mechanical way. In this talk, I will highlight our work on developing OPA-based platforms, devices, and systems that enable chip-based solutions to high-impact problems in areas including augmented-reality displays, LiDAR sensing for autonomous vehicles, optical trapping for biophotonics, 3D printing, and trapped-ion quantum engineering. &copy; 2023 SPIE.","655.1 Spacecraft, General;716.2 Radar Systems and Equipment;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;741.3 Optical Devices and Systems;745.1.1 Printing Equipment;931.3 Atomic and Molecular Physics",Beam-steering;Dynamic controls;Form factors;Free-space light;Integrated optical phased array;Integrated photonics;LiDAR;Low-costs;Optical phased arrays;Silicon photonics,3D printing;Augmented reality;Optical radar;Photonic devices;Space platforms;Three dimensional displays;Trapped ions,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Notaros, Jelena; ","(1) Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge; MA; 02139, United States; ",SPIE,-1,"[""3d printing"", ""optical radar"", ""photonic devices"", ""space platforms"", ""three-dimensional displays"", ""trapped ions""]","[""3d printing"", ""optical radar"", ""photonic devices"", ""space platforms"", ""three-dimensional displays"", ""trapped ions""]",3d printing;optical radar;photonic devices;space platforms;three-dimensional displays;trapped ions,other;optics;display technology;developers;geospatial;manufacturing,technology;other;displays;industries,other;optics;display technology;developers;geospatial;manufacturing,technology;other;displays;industries,3d_printing optical_radar photonic_devices space_platforms three dimensional_displays trapped_ions beam steering dynamic_controls form_factors free space_light integrated_optical_phased_array integrated_photonics lidar low costs optical_phased_arrays silicon_photonics 655 1_spacecraft _general 716 2_radar_systems_and_equipment 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 745 1 1_printing_equipment 931 3_atomic_and_molecular_physics other optics display_technology developers geospatial manufacturing,3d_printing optical_radar photonic_devices space_platforms three dimensional_displays trapped_ions,beam steering dynamic_controls form_factors free space_light integrated_optical_phased_array integrated_photonics lidar low costs optical_phased_arrays silicon_photonics,integrated optical phased array opas fabricated advanced silicon photonics platform enable manipulation dynamic control free space light compact form factor low cost non mechanical way talk highlight work developing opa based platform device system enable chip based solution high impact problem area including augmented reality display lidar sensing autonomous vehicle optical trapping biophotonics 3d printing trapped ion quantum engineering copy 2023 spie,3d_printing optical_radar photonic_devices space_platforms three dimensional_displays trapped_ions beam steering dynamic_controls form_factors free space_light integrated_optical_phased_array integrated_photonics lidar low costs optical_phased_arrays silicon_photonics 655 1_spacecraft _general 716 2_radar_systems_and_equipment 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 745 1 1_printing_equipment 931 3_atomic_and_molecular_physics other optics display_technology developers geospatial manufacturing integrated optical phased array opas fabricated advanced silicon photonics platform enable manipulation dynamic control free space light compact form factor low cost non mechanical way talk highlight work developing opa based platform device system enable chip based solution high impact problem area including augmented reality display lidar sensing autonomous vehicle optical trapping biophotonics 3d printing trapped ion quantum engineering copy 2023 spie,integrated optical phased array opas fabricated advanced silicon photonics platform enable manipulation dynamic control free space light compact form factor low cost non mechanical way talk highlight work developing opa based platform device system enable chip based solution high impact problem area including augmented reality display lidar sensing autonomous vehicle optical trapping biophotonics 3d printing trapped ion quantum engineering copy 2023 spie3d_printing optical_radar photonic_devices space_platforms three dimensional_displays trapped_ionsbeam steering dynamic_controls form_factors free space_light integrated_optical_phased_array integrated_photonics lidar low costs optical_phased_arrays silicon_photonics
159,Augmented Reality Applications in Industry 4.0 Environment,"Reljić, V., Milenković, I., Dudić, S., Šulc, J., & Bajči, B. (2021). Augmented Reality Applications in Industry 4.0 Environment. Applied Sciences, 11(12), 5592. https://doi.org/10.3390/app11125592
",10.3390/app11125592,"New technologies, such as cloud computing, the Internet of Things, wireless communications, etc., have already become part of our daily lives. This paper provides an insight into one of the new technologies, i.e., augmented reality (AR), as part of the manufacturing paradigm Industry 4.0 (I4.0). The aim of this paper is to contribute to the current state in the field of AR by assessing the main areas of the application of AR, the used devices and the tracking methods in support of the digitalization of the industry. Searches via Science Direct, Google Scholar and the Internet in general have resulted in the collection of a large number of papers. The examined works are classified according to several criteria and the most important data resulting from them are presented here. A comprehensive analysis of the literature has indicated the main areas of application of AR in I4.0 and, among these, those that stand out are maintenance, assembly and human robot collaboration. Finally, a roadmap for the application of AR in companies is proposed and the most promising future areas of research are listed.",C7480 Production engineering computing;C6130V Virtual reality;C6180R Human-robot interaction;C6190J Internet software;C7210N Information networks;E0410D Industrial applications of IT,AR application;augmented reality applications;cloud computing;Google Scholar;human robot collaboration;I4.0;Industry 4.0 environment;industry digitalization;Internet;Internet of Things;manufacturing paradigm;Science Direct;tracking methods;wireless communications,augmented reality;human-robot interaction;Internet;production engineering computing,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Reljic&#769;, V.; (1) Milenkovic&#769;, I.; (1) Dudic&#769;, S.; (1) S&#780;ulc, J.; (2) Bajc&#780;i, B.; ","(1) University of Novi Sad, Faculty of Technical Sciences, Trg D. Obradovic&#769;a 6, Serbia; (2) Continental Automotive Serbia, Narodnih heroja 3, Serbia; ",MDPI,-1,"[""human-robot interaction"", ""internet"", ""production engineering computing""]","[""human-robot interaction"", ""internet"", ""production engineering computing""]",human-robot interaction;internet;production engineering computing,manufacturing;engineering;robotics;networks,technology;industries,manufacturing;engineering;robotics;networks,technology;industries,human robot_interaction internet production_engineering_computing ar_application augmented_reality_applications cloud_computing google_scholar human_robot_collaboration i4 0 industry_4 0_environment industry_digitalization internet internet_of_things manufacturing_paradigm science_direct tracking_methods wireless_communications c7480_production_engineering_computing c6130v_virtual_reality c6180r_human robot_interaction c6190j_internet_software c7210n_information_networks e0410d_industrial_applications_of_it manufacturing engineering robotics networks,human robot_interaction internet production_engineering_computing,ar_application augmented_reality_applications cloud_computing google_scholar human_robot_collaboration i4 0 industry_4 0_environment industry_digitalization internet internet_of_things manufacturing_paradigm science_direct tracking_methods wireless_communications,new technology cloud computing internet thing wireless communication etc already become part daily life paper provides insight one new technology e augmented reality ar part manufacturing paradigm industry 4 0 i4 0 aim paper contribute current state field ar assessing main area application ar used device tracking method support digitalization industry search via science direct google scholar internet general resulted collection large number paper examined work classified according several criterion important data resulting presented comprehensive analysis literature indicated main area application ar i4 0 among stand maintenance assembly human robot collaboration finally roadmap application ar company proposed promising future area research listed,human robot_interaction internet production_engineering_computing ar_application augmented_reality_applications cloud_computing google_scholar human_robot_collaboration i4 0 industry_4 0_environment industry_digitalization internet internet_of_things manufacturing_paradigm science_direct tracking_methods wireless_communications c7480_production_engineering_computing c6130v_virtual_reality c6180r_human robot_interaction c6190j_internet_software c7210n_information_networks e0410d_industrial_applications_of_it manufacturing engineering robotics networks new technology cloud computing internet thing wireless communication etc already become part daily life paper provides insight one new technology e augmented reality ar part manufacturing paradigm industry 4 0 i4 0 aim paper contribute current state field ar assessing main area application ar used device tracking method support digitalization industry search via science direct google scholar internet general resulted collection large number paper examined work classified according several criterion important data resulting presented comprehensive analysis literature indicated main area application ar i4 0 among stand maintenance assembly human robot collaboration finally roadmap application ar company proposed promising future area research listed,new technology cloud computing internet thing wireless communication etc already become part daily life paper provides insight one new technology e augmented reality ar part manufacturing paradigm industry 4 0 i4 0 aim paper contribute current state field ar assessing main area application ar used device tracking method support digitalization industry search via science direct google scholar internet general resulted collection large number paper examined work classified according several criterion important data resulting presented comprehensive analysis literature indicated main area application ar i4 0 among stand maintenance assembly human robot collaboration finally roadmap application ar company proposed promising future area research listedhuman robot_interaction internet production_engineering_computingar_application augmented_reality_applications cloud_computing google_scholar human_robot_collaboration i4 0 industry_4 0_environment industry_digitalization internet internet_of_things manufacturing_paradigm science_direct tracking_methods wireless_communications
160,Deep-Learning-Based Adaptive Advertising with Augmented Reality,"Moreno-Armendáriz, M. A., Calvo, H., Duchanoy, C. A., Lara-Cázares, A., Ramos-Diaz, E., & Morales-Flores, V. L. (2021). Deep-Learning-Based Adaptive Advertising with Augmented Reality. Sensors, 22(1), 63. https://doi.org/10.3390/s22010063
",10.3390/s22010063,"In this work we describe a system composed of deep neural networks that analyzes characteristics of customers based on their face (age, gender, and personality), as well as the ambient temperature, with the purpose of generating a personalized signal to potential buyers who pass in front of a beverage establishment; faces are automatically detected, displaying a recommendation using deep learning methods. In order to present suitable digital posters for each person, several technologies were used: Augmented reality, estimation of age, gender, and estimation of personality through the Big Five test applied to an image. The accuracy of each one of these deep neural networks is measured separately to ensure an appropriate precision over 80%. The system has been implemented into a portable solution, and is able to generate a recommendation to one or more people at the same time.",B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets;C7170 Marketing computing,adaptive advertising;age estimation;ambient temperature;augmented reality;automatic face detection;beverage establishment;big five test;customer characteristic analysis;deep learning;deep neural networks;digital posters;gender estimation;personality estimation;personalized signal,advertising data processing;augmented reality;deep learning (artificial intelligence);face recognition,2021,Journal article (JA),Sensors (Switzerland),"(1) Moreno-Armenda&#769;riz, M.A.; (1) Calvo, H.; (2) Duchanoy, C.A.; (3) Lara-Ca&#769;zares, A.; (3) Ramos-Diaz, E.; (3) Morales-Flores, V.L.; ","(1) Centro de Investigacio&#769;n en Computacio&#769;n, Instituto Polite&#769;cnico Nacional, Mexico; (2) Gus Chat, Mexico; (3) Instituto Polite&#769;cnico Nacional, Escuela Superior de Co&#769;mputo, Mexico; ",MDPI,-1,"[""advertising data processing"", ""deep learning (artificial intelligence)"", ""face recognition""]","[""advertising data processing"", ""deep learning (artificial intelligence)"", ""face recognition""]",advertising data processing;deep learning (artificial intelligence);face recognition,other;input;liberal arts;medical;sales and marketing;human factors;data;artificial intelligence,other;business;industries;end users and user experience;technology,other;input;liberal arts;medical;sales and marketing;human factors;data;artificial intelligence,other;business;industries;end users and user experience;technology,advertising_data_processing deep_learning_ artificial_intelligence face_recognition adaptive_advertising age_estimation ambient_temperature augmented_reality automatic_face_detection beverage_establishment big_five_test customer_characteristic_analysis deep_learning deep_neural_networks digital_posters gender_estimation personality_estimation personalized_signal b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets c7170_marketing_computing other input liberal_arts medical sales_and_marketing human_factors data artificial_intelligence,advertising_data_processing deep_learning_ artificial_intelligence face_recognition,adaptive_advertising age_estimation ambient_temperature augmented_reality automatic_face_detection beverage_establishment big_five_test customer_characteristic_analysis deep_learning deep_neural_networks digital_posters gender_estimation personality_estimation personalized_signal,work describe system composed deep neural network analyzes characteristic customer based face age gender personality well ambient temperature purpose generating personalized signal potential buyer pas front beverage establishment face automatically detected displaying recommendation using deep learning method order present suitable digital poster person several technology used augmented reality estimation age gender estimation personality big five test applied image accuracy one deep neural network measured separately ensure appropriate precision 80 system implemented portable solution able generate recommendation one people time,advertising_data_processing deep_learning_ artificial_intelligence face_recognition adaptive_advertising age_estimation ambient_temperature augmented_reality automatic_face_detection beverage_establishment big_five_test customer_characteristic_analysis deep_learning deep_neural_networks digital_posters gender_estimation personality_estimation personalized_signal b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets c7170_marketing_computing other input liberal_arts medical sales_and_marketing human_factors data artificial_intelligence work describe system composed deep neural network analyzes characteristic customer based face age gender personality well ambient temperature purpose generating personalized signal potential buyer pas front beverage establishment face automatically detected displaying recommendation using deep learning method order present suitable digital poster person several technology used augmented reality estimation age gender estimation personality big five test applied image accuracy one deep neural network measured separately ensure appropriate precision 80 system implemented portable solution able generate recommendation one people time,work describe system composed deep neural network analyzes characteristic customer based face age gender personality well ambient temperature purpose generating personalized signal potential buyer pas front beverage establishment face automatically detected displaying recommendation using deep learning method order present suitable digital poster person several technology used augmented reality estimation age gender estimation personality big five test applied image accuracy one deep neural network measured separately ensure appropriate precision 80 system implemented portable solution able generate recommendation one people timeadvertising_data_processing deep_learning_ artificial_intelligence face_recognitionadaptive_advertising age_estimation ambient_temperature augmented_reality automatic_face_detection beverage_establishment big_five_test customer_characteristic_analysis deep_learning deep_neural_networks digital_posters gender_estimation personality_estimation personalized_signal
161,Design of an Augmented Reality App for Primary School Students Which Visualizes Length Units to Promote the Conversion of Units,"Mueller, L. M., & Platz, M. (2023). Design of an Augmented Reality App for Primary School Students Which Visualizes Length Units to Promote the Conversion of Units. Design Science Research for a New Society: Society 5.0, 314–328. https://doi.org/10.1007/978-3-031-32808-4_20
",10.1007/978-3-031-32808-4_20,"Insight and understanding of the structure of units can be considered one of mathematics&rsquo; most important learning areas, as it is needed in everyday life. It is essential in everyday tasks, such as trading goods, which requires dealing with monetary values and, e.g., lengths, weights, volumes, or area units. In addition, students in higher education after primary school show problems with understanding units by confusing units, especially in advanced STEM subjects, e.g., physics. The paper shows how Augmented Reality (AR) technology can be used to gain insight into understanding units by visualizing units of length using an AR app. The design of the AR app will be presented, which was developed after a theoretical grounding and practical testing with an existing AR measuring tool on the app market. Design Science Research (DSR) will be used to develop a suitable content learning environment using the AR app. The learning environment will then be tested with students again and disseminated in international workshops for teachers. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;723.5 Computer Applications;901.2 Education",Augmented reality technology;Conversion;Design-science researches;Gain insight;High educations;Learning environments;Monetary value;Primary schools;School students;Unit of length,Commerce;Computer aided instruction;Design;E-learning;Students,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) Mueller, Lea Marie; (1) Platz, Melanie; ","(1) Saarland University, Saarbruecken; 66123, Germany; ",Springer Science and Business Media Deutschland GmbH,-1,"[""commerce"", ""computer aided instruction"", ""design"", ""e-learning"", ""students""]","[""commerce"", ""computer aided instruction"", ""design"", ""e-learning"", ""students""]",commerce;computer aided instruction;design;e-learning;students,education;medical;sales and marketing;training;human-computer interaction;users,end users and user experience;business;use cases;industries,education;medical;sales and marketing;training;human-computer interaction;users,end users and user experience;business;use cases;industries,commerce computer_aided_instruction design e learning students augmented_reality_technology conversion design science_researches gain_insight high_educations learning_environments monetary_value primary_schools school_students unit_of_length 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education education medical sales_and_marketing training human computer_interaction users,commerce computer_aided_instruction design e learning students,augmented_reality_technology conversion design science_researches gain_insight high_educations learning_environments monetary_value primary_schools school_students unit_of_length,insight understanding structure unit considered one mathematics rsquo important learning area needed everyday life essential everyday task trading good requires dealing monetary value e g length weight volume area unit addition student higher education primary school show problem understanding unit confusing unit especially advanced stem subject e g physic paper show augmented reality ar technology used gain insight understanding unit visualizing unit length using ar app design ar app presented developed theoretical grounding practical testing existing ar measuring tool app market design science research dsr used develop suitable content learning environment using ar app learning environment tested student disseminated international workshop teacher copy 2023 author exclusive license springer nature switzerland ag,commerce computer_aided_instruction design e learning students augmented_reality_technology conversion design science_researches gain_insight high_educations learning_environments monetary_value primary_schools school_students unit_of_length 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education education medical sales_and_marketing training human computer_interaction users insight understanding structure unit considered one mathematics rsquo important learning area needed everyday life essential everyday task trading good requires dealing monetary value e g length weight volume area unit addition student higher education primary school show problem understanding unit confusing unit especially advanced stem subject e g physic paper show augmented reality ar technology used gain insight understanding unit visualizing unit length using ar app design ar app presented developed theoretical grounding practical testing existing ar measuring tool app market design science research dsr used develop suitable content learning environment using ar app learning environment tested student disseminated international workshop teacher copy 2023 author exclusive license springer nature switzerland ag,insight understanding structure unit considered one mathematics rsquo important learning area needed everyday life essential everyday task trading good requires dealing monetary value e g length weight volume area unit addition student higher education primary school show problem understanding unit confusing unit especially advanced stem subject e g physic paper show augmented reality ar technology used gain insight understanding unit visualizing unit length using ar app design ar app presented developed theoretical grounding practical testing existing ar measuring tool app market design science research dsr used develop suitable content learning environment using ar app learning environment tested student disseminated international workshop teacher copy 2023 author exclusive license springer nature switzerland agcommerce computer_aided_instruction design e learning studentsaugmented_reality_technology conversion design science_researches gain_insight high_educations learning_environments monetary_value primary_schools school_students unit_of_length
162,"0.37-inch UHD 11,800 PPI Liquid Crystal on Silicon Micro-Display with Embedded 4x Up-Scaler Using Micro-Mirror Space-Interpolation Pixel Circuit for Metaverse Augmented Reality Glasses","Jeong, M., Lee, J., Lee, K. soo, Kim, J., Park, S., Kim, B.-E., & Lee, K. (2023). 0.37-inch UHD, 11,800 PPI liquid crystal on silicon micro-display with embedded 4x up-scaler using micro-mirror space-interpolation pixel circuit for metaverse augmented reality glasses. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2645045
",10.1117/12.2645045,"A 0.37-inch 360 Hz field refresh rate ultra-HD 11,800PPI 2.15 &mu;m pixel pitch liquid crystal on silicon (LCoS) micro-display panel with embedded 4x up-scaler is presented. In AR glasses for metaverse, spatial resolution is very important as field of view (FoV) increases. The lack of spatial resolution interferes with the immersion of the augmented virtual space, such as limited information on image quality degradation and screen door effects. The display is proposed with new ultra-low power resolution enhancement technology of quadruple scaler to solve spatial aliasing caused by limited resolution at augmented reality (AR) glasses. The ultra-fine resolution pixel circuit is designed by new spatial interpolation technique called as micro-mirror space-interpolation (mmSI). The new micro-mirror architecture was proposed to make capacitive circuits network which produce interpolated pixel data and pixel mirror itself. The embedded spatial interpolation is done by pixel circuit itself and there are no additional circuits from video input to pixel driving. In this reason, the power consumption of driving the panel is same to full-HD resolution drivers&rsquo; which is only 100mW despite of quadruple resolution. The micro-display panel for metaverse AR glasses was fabricated using a 0.11-&mu;m CMOS process and was assembled with an LC front plane using VAN LC. The die size, active area and panel size are 11.65 mm x 7.75 mm, 8.25 x 4.64 mm2 and 13.8 x 8.5 mm2, respectively. The output video resolution is 3840 x 2160 with RGB 8-bit gray depth with 1920x1080 video input. The presented panel has 11,800 PPI with UHD video resolution only 0.37-inch diagonal active display area. The angular pixel resolution of the display is achieved at a 49 cycles per degree (cpd) resolution with 90-degree diagonal FoV for ultra-portable handheld AR glasses application. &copy; 2023 SPIE.","549.3 Nonferrous Metals and Alloys excluding Alkali and Alkaline Earth Metals;713.4 Pulse Circuits;723 Computer Software, Data Handling and Applications;741.3 Optical Devices and Systems;812.3 Glass;921.6 Numerical Methods",Liquid crystal on silicon;Low Power;Metaverses;Micro mirror;Microdisplays;Pixel circuit;Spatial resolution;UHD;Up-scaler;Wide field-ofview,Augmented reality;Image resolution;Interpolation;Liquid crystals;Mirrors;Pixels;Silicon;Timing circuits,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Jeong, Minsu; (1) Lee, Jungwhan; (1) Lee, Kwangsoo; (1) Kim, Jihoon; (1) Park, Saejin; (1) Kim, Bo-Eun; ","(1) RAONTECH Inc., 17 Seongnam-daero 779beon-gil, Bundang-gu, Seongnam-si, Gyeonggi-do; 13567, Korea, Republic of; ",SPIE,-1,"[""image resolution"", ""interpolation"", ""liquid crystals"", ""mirrors"", ""pixels"", ""silicon"", ""timing circuits""]","[""image resolution"", ""interpolation"", ""liquid crystals"", ""mirrors"", ""pixels"", ""silicon"", ""timing circuits""]",image resolution;interpolation;liquid crystals;mirrors;pixels;silicon;timing circuits,graphics;optics;chemical;engineering;data;semiconductors,technology;displays;industries,graphics;optics;chemical;engineering;data;semiconductors,technology;displays;industries,image_resolution interpolation liquid_crystals mirrors pixels silicon timing_circuits liquid_crystal_on_silicon low_power metaverses micro_mirror microdisplays pixel_circuit spatial_resolution uhd up scaler wide_field ofview 549 3_nonferrous_metals_and_alloys_excluding_alkali_and_alkaline_earth_metals 713 4_pulse_circuits 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 812 3_glass 921 6_numerical_methods graphics optics chemical engineering data semiconductors,image_resolution interpolation liquid_crystals mirrors pixels silicon timing_circuits,liquid_crystal_on_silicon low_power metaverses micro_mirror microdisplays pixel_circuit spatial_resolution uhd up scaler wide_field ofview,0 37 inch 360 hz field refresh rate ultra hd 11 800ppi 2 15 mu pixel pitch liquid crystal silicon lcos micro display panel embedded 4x scaler presented ar glass metaverse spatial resolution important field view fov increase lack spatial resolution interferes immersion augmented virtual space limited information image quality degradation screen door effect display proposed new ultra low power resolution enhancement technology quadruple scaler solve spatial aliasing caused limited resolution augmented reality ar glass ultra fine resolution pixel circuit designed new spatial interpolation technique called micro mirror space interpolation mmsi new micro mirror architecture proposed make capacitive circuit network produce interpolated pixel data pixel mirror embedded spatial interpolation done pixel circuit additional circuit video input pixel driving reason power consumption driving panel full hd resolution driver rsquo 100mw despite quadruple resolution micro display panel metaverse ar glass fabricated using 0 11 mu cmos process assembled lc front plane using van lc die size active area panel size 11 65 mm x 7 75 mm 8 25 x 4 64 mm2 13 8 x 8 5 mm2 respectively output video resolution 3840 x 2160 rgb 8 bit gray depth 1920x1080 video input presented panel 11 800 ppi uhd video resolution 0 37 inch diagonal active display area angular pixel resolution display achieved 49 cycle per degree cpd resolution 90 degree diagonal fov ultra portable handheld ar glass application copy 2023 spie,image_resolution interpolation liquid_crystals mirrors pixels silicon timing_circuits liquid_crystal_on_silicon low_power metaverses micro_mirror microdisplays pixel_circuit spatial_resolution uhd up scaler wide_field ofview 549 3_nonferrous_metals_and_alloys_excluding_alkali_and_alkaline_earth_metals 713 4_pulse_circuits 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 812 3_glass 921 6_numerical_methods graphics optics chemical engineering data semiconductors 0 37 inch 360 hz field refresh rate ultra hd 11 800ppi 2 15 mu pixel pitch liquid crystal silicon lcos micro display panel embedded 4x scaler presented ar glass metaverse spatial resolution important field view fov increase lack spatial resolution interferes immersion augmented virtual space limited information image quality degradation screen door effect display proposed new ultra low power resolution enhancement technology quadruple scaler solve spatial aliasing caused limited resolution augmented reality ar glass ultra fine resolution pixel circuit designed new spatial interpolation technique called micro mirror space interpolation mmsi new micro mirror architecture proposed make capacitive circuit network produce interpolated pixel data pixel mirror embedded spatial interpolation done pixel circuit additional circuit video input pixel driving reason power consumption driving panel full hd resolution driver rsquo 100mw despite quadruple resolution micro display panel metaverse ar glass fabricated using 0 11 mu cmos process assembled lc front plane using van lc die size active area panel size 11 65 mm x 7 75 mm 8 25 x 4 64 mm2 13 8 x 8 5 mm2 respectively output video resolution 3840 x 2160 rgb 8 bit gray depth 1920x1080 video input presented panel 11 800 ppi uhd video resolution 0 37 inch diagonal active display area angular pixel resolution display achieved 49 cycle per degree cpd resolution 90 degree diagonal fov ultra portable handheld ar glass application copy 2023 spie,0 37 inch 360 hz field refresh rate ultra hd 11 800ppi 2 15 mu pixel pitch liquid crystal silicon lcos micro display panel embedded 4x scaler presented ar glass metaverse spatial resolution important field view fov increase lack spatial resolution interferes immersion augmented virtual space limited information image quality degradation screen door effect display proposed new ultra low power resolution enhancement technology quadruple scaler solve spatial aliasing caused limited resolution augmented reality ar glass ultra fine resolution pixel circuit designed new spatial interpolation technique called micro mirror space interpolation mmsi new micro mirror architecture proposed make capacitive circuit network produce interpolated pixel data pixel mirror embedded spatial interpolation done pixel circuit additional circuit video input pixel driving reason power consumption driving panel full hd resolution driver rsquo 100mw despite quadruple resolution micro display panel metaverse ar glass fabricated using 0 11 mu cmos process assembled lc front plane using van lc die size active area panel size 11 65 mm x 7 75 mm 8 25 x 4 64 mm2 13 8 x 8 5 mm2 respectively output video resolution 3840 x 2160 rgb 8 bit gray depth 1920x1080 video input presented panel 11 800 ppi uhd video resolution 0 37 inch diagonal active display area angular pixel resolution display achieved 49 cycle per degree cpd resolution 90 degree diagonal fov ultra portable handheld ar glass application copy 2023 spieimage_resolution interpolation liquid_crystals mirrors pixels silicon timing_circuitsliquid_crystal_on_silicon low_power metaverses micro_mirror microdisplays pixel_circuit spatial_resolution uhd up scaler wide_field ofview
163,School of the Future: A Comprehensive Study on the Effectiveness of Augmented Reality as a Tool for Primary School Children's Education,"Afnan, Muhammad, K., Khan, N., Lee, M.-Y., Imran, A., & Sajjad, M. (2021). School of the Future: A Comprehensive Study on the Effectiveness of Augmented Reality as a Tool for Primary School Children’s Education. Applied Sciences, 11(11), 5277. https://doi.org/10.3390/app11115277
",10.3390/app11115277,"With the emerging technologies of augmented reality (AR) and virtual reality (VR), the learning process in today's classroom is much more effective and motivational. Overlaying virtual content into the real world makes learning methods attractive and entertaining for students while performing activities. AR techniques make the learning process easy, and fun as compared to traditional methods. These methods lack focused learning and interactivity between the educational content. To make learning effective, we propose to use handheld marker-based AR technology for primary school students. We developed a set of four applications based on students' academic course of primary school level for learning purposes of the English alphabet, decimal numbers, animals and birds, and an AR Globe for knowing about different countries around the world. These applications can be played wherever and whenever a user wants without Internet connectivity, subject to the availability of a tablet or mobile device and the required target images. These applications have performance evaluation quizzes (PEQs) for testing students' learning progress. Our study investigates the effectiveness of AR-based learning materials in terms of learning performance, motivation, attitude, and behavior towards different methods of learning. Our activity results favor AR-based learning techniques where students' learning motivation and performance are enhanced compared to the non-AR learning methods.",C7810C Computer-aided instruction;C6130V Virtual reality;C6190J Internet software,AR globe;AR techniques;AR-based learning materials;AR-based learning techniques;augmented reality;educational content;English alphabet;handheld marker-based AR technology;Internet;learning process;PEQs;performance evaluation quizzes;primary school children's education;primary school students;virtual content;virtual reality,augmented reality;computer aided instruction;Internet;learning (artificial intelligence),2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Afnan; (1) Muhammad, K.; (1) Khan, N.; (1) Lee, M.-Y.; (3) Imran, A.S.; (2) Sajjad, M.; ","(1) Sejong University, Department of Software, Korea, Republic of; (2) University of Peshawar, Department of Computer Science, Pakistan; (3) Norwegian University of Science and Technology, Department of Computer Science, Norway; ",MDPI,-1,"[""computer aided instruction"", ""internet"", ""learning algorithms""]","[""computer aided instruction"", ""internet"", ""learning algorithms""]",computer aided instruction;internet;learning algorithms,medical;artificial intelligence;training;networks,technology;use cases;industries,medical;artificial intelligence;training;networks,technology;use cases;industries,computer_aided_instruction internet learning_algorithms ar_globe ar_techniques ar based_learning_materials ar based_learning_techniques augmented_reality educational_content english_alphabet handheld_marker based_ar_technology internet learning_process peqs performance_evaluation_quizzes primary_school_children s_education primary_school_students virtual_content virtual_reality c7810c_computer aided_instruction c6130v_virtual_reality c6190j_internet_software medical artificial_intelligence training networks,computer_aided_instruction internet learning_algorithms,ar_globe ar_techniques ar based_learning_materials ar based_learning_techniques augmented_reality educational_content english_alphabet handheld_marker based_ar_technology internet learning_process peqs performance_evaluation_quizzes primary_school_children s_education primary_school_students virtual_content virtual_reality,emerging technology augmented reality ar virtual reality vr learning process today classroom much effective motivational overlaying virtual content real world make learning method attractive entertaining student performing activity ar technique make learning process easy fun compared traditional method method lack focused learning interactivity educational content make learning effective propose use handheld marker based ar technology primary school student developed set four application based student academic course primary school level learning purpose english alphabet decimal number animal bird ar globe knowing different country around world application played wherever whenever user want without internet connectivity subject availability tablet mobile device required target image application performance evaluation quiz peqs testing student learning progress study investigates effectiveness ar based learning material term learning performance motivation attitude behavior towards different method learning activity result favor ar based learning technique student learning motivation performance enhanced compared non ar learning method,computer_aided_instruction internet learning_algorithms ar_globe ar_techniques ar based_learning_materials ar based_learning_techniques augmented_reality educational_content english_alphabet handheld_marker based_ar_technology internet learning_process peqs performance_evaluation_quizzes primary_school_children s_education primary_school_students virtual_content virtual_reality c7810c_computer aided_instruction c6130v_virtual_reality c6190j_internet_software medical artificial_intelligence training networks emerging technology augmented reality ar virtual reality vr learning process today classroom much effective motivational overlaying virtual content real world make learning method attractive entertaining student performing activity ar technique make learning process easy fun compared traditional method method lack focused learning interactivity educational content make learning effective propose use handheld marker based ar technology primary school student developed set four application based student academic course primary school level learning purpose english alphabet decimal number animal bird ar globe knowing different country around world application played wherever whenever user want without internet connectivity subject availability tablet mobile device required target image application performance evaluation quiz peqs testing student learning progress study investigates effectiveness ar based learning material term learning performance motivation attitude behavior towards different method learning activity result favor ar based learning technique student learning motivation performance enhanced compared non ar learning method,emerging technology augmented reality ar virtual reality vr learning process today classroom much effective motivational overlaying virtual content real world make learning method attractive entertaining student performing activity ar technique make learning process easy fun compared traditional method method lack focused learning interactivity educational content make learning effective propose use handheld marker based ar technology primary school student developed set four application based student academic course primary school level learning purpose english alphabet decimal number animal bird ar globe knowing different country around world application played wherever whenever user want without internet connectivity subject availability tablet mobile device required target image application performance evaluation quiz peqs testing student learning progress study investigates effectiveness ar based learning material term learning performance motivation attitude behavior towards different method learning activity result favor ar based learning technique student learning motivation performance enhanced compared non ar learning methodcomputer_aided_instruction internet learning_algorithmsar_globe ar_techniques ar based_learning_materials ar based_learning_techniques augmented_reality educational_content english_alphabet handheld_marker based_ar_technology internet learning_process peqs performance_evaluation_quizzes primary_school_children s_education primary_school_students virtual_content virtual_reality
164,Network Analysis for Learners' Concept Maps While Using Mobile Augmented Reality Gaming,"Sdravopoulou, K., Muñoz González, J. M., & Hidalgo-Ariza, M. D. (2021). Network Analysis for Learners’ Concept Maps While Using Mobile Augmented Reality Gaming. Applied Sciences, 11(21), 9929. https://doi.org/10.3390/app11219929
",10.3390/app11219929,"Using mobile augmented reality games in education combines situated and active learning with pleasure. The aim of this research is to analyze the responses expressed by young, middle-aged, and elderly adults about the location-based mobile augmented reality (MAR) games using methods of content analysis, concept maps, and social network analysis (SNA). The responses to questions related to MAR game Ingress were collected from 36 adult players, aged 20-60, from Greece, and subsequently analyzed by means of content analysis, concept maps, and social network analysis. Our findings show that for question 1 (How do you feel when you endow the geographical space with personal preferences?), there was a differentiation of the answers between age groups with age groups agreeing in pairs, the first two and the last two, while for question 2 (Do you think that the game offers opportunities for learning and teaching geography, building on your previous geographical knowledge?), there was an overlap in responses of participants among age groups. It was also revealed that the MAR games foster a constructivism approach of learning, as their use learning becomes an active, socially supported process of knowledge construction.","C7830D Computer games;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7210N Information networks;C7810C Computer-aided instruction",36 adult players;active learning;active supported process;age groups;concept maps;content analysis;elderly adults;learners;learning teaching geography;location-based mobile augmented reality games;MAR game Ingress;MAR games;social network analysis;socially supported process,augmented reality;computer aided instruction;computer games;mobile computing;social networking (online);teaching,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Sdravopoulou, K.; (1) Mun&#771;oz gonza&#769;lez, J.M.; (1) Hidalgo-ariza, M.D.; ","(1) University of Cordoba, Department of Education, Spain; ",MDPI,-1,"[""computer aided instruction"", ""computer games"", ""mobile computing"", ""social networking"", ""teaching""]","[""computer aided instruction"", ""computer games"", ""mobile computing"", ""social networking"", ""teaching""]",computer aided instruction;computer games;mobile computing;social networking;teaching,education;liberal arts;training;collaboration;telecommunication,use cases;industries,education;liberal arts;training;collaboration;telecommunication,use cases;industries,computer_aided_instruction computer_games mobile_computing social_networking teaching 36_adult_players active_learning active_supported_process age_groups concept_maps content_analysis elderly_adults learners learning_teaching_geography location based_mobile_augmented_reality_games mar_game_ingress mar_games social_network_analysis socially_supported_process c7830d_computer_games c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks c7810c_computer aided_instruction education liberal_arts training collaboration telecommunication,computer_aided_instruction computer_games mobile_computing social_networking teaching,36_adult_players active_learning active_supported_process age_groups concept_maps content_analysis elderly_adults learners learning_teaching_geography location based_mobile_augmented_reality_games mar_game_ingress mar_games social_network_analysis socially_supported_process,using mobile augmented reality game education combine situated active learning pleasure aim research analyze response expressed young middle aged elderly adult location based mobile augmented reality mar game using method content analysis concept map social network analysis sna response question related mar game ingres collected 36 adult player aged 20 60 greece subsequently analyzed mean content analysis concept map social network analysis finding show question 1 feel endow geographical space personal preference differentiation answer age group age group agreeing pair first two last two question 2 think game offer opportunity learning teaching geography building previous geographical knowledge overlap response participant among age group also revealed mar game foster constructivism approach learning use learning becomes active socially supported process knowledge construction,computer_aided_instruction computer_games mobile_computing social_networking teaching 36_adult_players active_learning active_supported_process age_groups concept_maps content_analysis elderly_adults learners learning_teaching_geography location based_mobile_augmented_reality_games mar_game_ingress mar_games social_network_analysis socially_supported_process c7830d_computer_games c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks c7810c_computer aided_instruction education liberal_arts training collaboration telecommunication using mobile augmented reality game education combine situated active learning pleasure aim research analyze response expressed young middle aged elderly adult location based mobile augmented reality mar game using method content analysis concept map social network analysis sna response question related mar game ingres collected 36 adult player aged 20 60 greece subsequently analyzed mean content analysis concept map social network analysis finding show question 1 feel endow geographical space personal preference differentiation answer age group age group agreeing pair first two last two question 2 think game offer opportunity learning teaching geography building previous geographical knowledge overlap response participant among age group also revealed mar game foster constructivism approach learning use learning becomes active socially supported process knowledge construction,using mobile augmented reality game education combine situated active learning pleasure aim research analyze response expressed young middle aged elderly adult location based mobile augmented reality mar game using method content analysis concept map social network analysis sna response question related mar game ingres collected 36 adult player aged 20 60 greece subsequently analyzed mean content analysis concept map social network analysis finding show question 1 feel endow geographical space personal preference differentiation answer age group age group agreeing pair first two last two question 2 think game offer opportunity learning teaching geography building previous geographical knowledge overlap response participant among age group also revealed mar game foster constructivism approach learning use learning becomes active socially supported process knowledge constructioncomputer_aided_instruction computer_games mobile_computing social_networking teaching36_adult_players active_learning active_supported_process age_groups concept_maps content_analysis elderly_adults learners learning_teaching_geography location based_mobile_augmented_reality_games mar_game_ingress mar_games social_network_analysis socially_supported_process
165,P300 Brain-Computer Interface-Based Drone Control in Virtual and Augmented Reality,"Kim, S., Lee, S., Kang, H., Kim, S., & Ahn, M. (2021). P300 Brain–Computer Interface-Based Drone Control in Virtual and Augmented Reality. Sensors, 21(17), 5765. https://doi.org/10.3390/s21175765
",10.3390/s21175765,"Since the emergence of head-mounted displays (HMDs), researchers have attempted to introduce virtual and augmented reality (VR, AR) in brain-computer interface (BCI) studies. However, there is a lack of studies that incorporate both AR and VR to compare the performance in the two environments. Therefore, it is necessary to develop a BCI application that can be used in both VR and AR to allow BCI performance to be compared in the two environments. In this study, we developed an opensource-based drone control application using P300-based BCI, which can be used in both VR and AR. Twenty healthy subjects participated in the experiment with this application. They were asked to control the drone in two environments and filled out questionnaires before and after the experiment. We found no significant (p &gt; 0.05) difference in online performance (classification accuracy and amplitude/latency of P300 component) and user experience (satisfaction about time length, program, environment, interest, difficulty, immersion, and feeling of self-control) between VR and AR. This indicates that the P300 BCI paradigm is relatively reliable and may work well in various situations.",A8770F Electrodiagnostics and other electrical measurement techniques;A8730C Electrical activity in neurophysiological processes;B7510D Bioelectric signals;C5260 Digital signal processing;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing,augmented reality;BCI application;BCI performance;head-mounted displays;online performance;opensource-based drone control application;P300 BCI paradigm;P300 Brain-Computer Interface-Based Drone Control;P300-based BCI;virtual reality,augmented reality;brain-computer interfaces;electroencephalography;helmet mounted displays;medical signal processing,2021,Journal article (JA),Sensors (Switzerland),"(1) Kim, S.; (1) Lee, S.; (1) Kang, H.; (1) Kim, S.; (1) Ahn, M.; ","(1) Handong Global University, School of Computer Science and Electrical Engineering, Korea, Republic of; ",MDPI,-1,"[""brain-computer interfaces"", ""electroencephalography"", ""helmet mounted displays"", ""medical signal processing""]","[""brain-computer interfaces"", ""electroencephalography"", ""helmet mounted displays"", ""medical signal processing""]",brain-computer interfaces;electroencephalography;helmet mounted displays;medical signal processing,farming and natural science;medical;sensors;display technology;human factors;wearables;data,technology;end users and user experience;displays;industries,farming and natural science;medical;sensors;display technology;human factors;wearables;data,technology;end users and user experience;displays;industries,brain computer_interfaces electroencephalography helmet_mounted_displays medical_signal_processing augmented_reality bci_application bci_performance head mounted_displays online_performance opensource based_drone_control_application p300_bci_paradigm p300_brain computer_interface based_drone_control p300 based_bci virtual_reality a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8730c_electrical_activity_in_neurophysiological_processes b7510d_bioelectric_signals c5260_digital_signal_processing c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing farming_and_natural_science medical sensors display_technology human_factors wearables data,brain computer_interfaces electroencephalography helmet_mounted_displays medical_signal_processing,augmented_reality bci_application bci_performance head mounted_displays online_performance opensource based_drone_control_application p300_bci_paradigm p300_brain computer_interface based_drone_control p300 based_bci virtual_reality,since emergence head mounted display hmds researcher attempted introduce virtual augmented reality vr ar brain computer interface bci study however lack study incorporate ar vr compare performance two environment therefore necessary develop bci application used vr ar allow bci performance compared two environment study developed opensource based drone control application using p300 based bci used vr ar twenty healthy subject participated experiment application asked control drone two environment filled questionnaire experiment found significant p gt 0 05 difference online performance classification accuracy amplitude latency p300 component user experience satisfaction time length program environment interest difficulty immersion feeling self control vr ar indicates p300 bci paradigm relatively reliable may work well various situation,brain computer_interfaces electroencephalography helmet_mounted_displays medical_signal_processing augmented_reality bci_application bci_performance head mounted_displays online_performance opensource based_drone_control_application p300_bci_paradigm p300_brain computer_interface based_drone_control p300 based_bci virtual_reality a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8730c_electrical_activity_in_neurophysiological_processes b7510d_bioelectric_signals c5260_digital_signal_processing c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing farming_and_natural_science medical sensors display_technology human_factors wearables data since emergence head mounted display hmds researcher attempted introduce virtual augmented reality vr ar brain computer interface bci study however lack study incorporate ar vr compare performance two environment therefore necessary develop bci application used vr ar allow bci performance compared two environment study developed opensource based drone control application using p300 based bci used vr ar twenty healthy subject participated experiment application asked control drone two environment filled questionnaire experiment found significant p gt 0 05 difference online performance classification accuracy amplitude latency p300 component user experience satisfaction time length program environment interest difficulty immersion feeling self control vr ar indicates p300 bci paradigm relatively reliable may work well various situation,since emergence head mounted display hmds researcher attempted introduce virtual augmented reality vr ar brain computer interface bci study however lack study incorporate ar vr compare performance two environment therefore necessary develop bci application used vr ar allow bci performance compared two environment study developed opensource based drone control application using p300 based bci used vr ar twenty healthy subject participated experiment application asked control drone two environment filled questionnaire experiment found significant p gt 0 05 difference online performance classification accuracy amplitude latency p300 component user experience satisfaction time length program environment interest difficulty immersion feeling self control vr ar indicates p300 bci paradigm relatively reliable may work well various situationbrain computer_interfaces electroencephalography helmet_mounted_displays medical_signal_processingaugmented_reality bci_application bci_performance head mounted_displays online_performance opensource based_drone_control_application p300_bci_paradigm p300_brain computer_interface based_drone_control p300 based_bci virtual_reality
166,Personalized Augmented Reality Based Tourism System: Big Data and User Demographic Contexts,"Rezaee, S., Sadeghi-Niaraki, A., Shakeri, M., & Choi, S.-M. (2021). Personalized Augmented Reality Based Tourism System: Big Data and User Demographic Contexts. Applied Sciences, 11(13), 6047. https://doi.org/10.3390/app11136047
",10.3390/app11136047,"A lack of required data resources is one of the challenges of accepting the Augmented Reality (AR) to provide the right services to the users, whereas the amount of spatial information produced by people is increasing daily. This research aims to design a personalized AR that is based on a tourist system that retrieves the big data according to the users' demographic contexts in order to enrich the AR data source in tourism. This research is conducted in two main steps. First, the type of the tourist attraction where the users interest is predicted according to the user demographic contexts, which include age, gender, and education level, by using a machine learning method. Second, the correct data for the user are extracted from the big data by considering time, distance, popularity, and the neighborhood of the tourist places, by using the VIKOR and SWAR decision making methods. By about 6%, the results show better performance of the decision tree by predicting the type of tourist attraction, when compared to the SVM method. In addition, the results of the user study of the system show the overall satisfaction of the participants in terms of the ease-of-use, which is about 55%, and in terms of the systems usefulness, about 56%.",C6130V Virtual reality;C1140Z Other topics in statistics;C1160 Combinatorial mathematics;C6130 Data handling techniques;C7210N Information networks,AR data source;big data;correct data;personalized Augmented Reality;required data resources;tourism system;tourist attraction;tourist system;user demographic contexts;users interest,augmented reality;Big Data;decision making;decision trees;learning (artificial intelligence);support vector machines;travel industry,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Rezaee, S.; (1) Sadeghi-niaraki, A.; (1) Shakeri, M.; (2) Choi, S.-M.; ","(1) K.N. Toosi University of Technology, Faculty of Geodesy and Geomatics Engineering, Iran; (2) Sejong University, Deptartment of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, Korea, Republic of; ",MDPI,-1,"[""big data"", ""decision making"", ""decision trees"", ""learning algorithms"", ""support vector machines"", ""travel industry""]","[""big data"", ""decision making"", ""decision trees"", ""learning algorithms"", ""support vector machines"", ""travel industry""]",big data;decision making;decision trees;learning algorithms;support vector machines;travel industry,transportation;medical;human factors;data;artificial intelligence,technology;industries;end users and user experience,transportation;medical;human factors;data;artificial intelligence,technology;industries;end users and user experience,big_data decision_making decision_trees learning_algorithms support_vector_machines travel_industry ar_data_source big_data correct_data personalized_augmented_reality required_data_resources tourism_system tourist_attraction tourist_system user_demographic_contexts users_interest c6130v_virtual_reality c1140z_other_topics_in_statistics c1160_combinatorial_mathematics c6130_data_handling_techniques c7210n_information_networks transportation medical human_factors data artificial_intelligence,big_data decision_making decision_trees learning_algorithms support_vector_machines travel_industry,ar_data_source big_data correct_data personalized_augmented_reality required_data_resources tourism_system tourist_attraction tourist_system user_demographic_contexts users_interest,lack required data resource one challenge accepting augmented reality ar provide right service user whereas amount spatial information produced people increasing daily research aim design personalized ar based tourist system retrieves big data according user demographic context order enrich ar data source tourism research conducted two main step first type tourist attraction user interest predicted according user demographic context include age gender education level using machine learning method second correct data user extracted big data considering time distance popularity neighborhood tourist place using vikor swar decision making method 6 result show better performance decision tree predicting type tourist attraction compared svm method addition result user study system show overall satisfaction participant term ease use 55 term system usefulness 56,big_data decision_making decision_trees learning_algorithms support_vector_machines travel_industry ar_data_source big_data correct_data personalized_augmented_reality required_data_resources tourism_system tourist_attraction tourist_system user_demographic_contexts users_interest c6130v_virtual_reality c1140z_other_topics_in_statistics c1160_combinatorial_mathematics c6130_data_handling_techniques c7210n_information_networks transportation medical human_factors data artificial_intelligence lack required data resource one challenge accepting augmented reality ar provide right service user whereas amount spatial information produced people increasing daily research aim design personalized ar based tourist system retrieves big data according user demographic context order enrich ar data source tourism research conducted two main step first type tourist attraction user interest predicted according user demographic context include age gender education level using machine learning method second correct data user extracted big data considering time distance popularity neighborhood tourist place using vikor swar decision making method 6 result show better performance decision tree predicting type tourist attraction compared svm method addition result user study system show overall satisfaction participant term ease use 55 term system usefulness 56,lack required data resource one challenge accepting augmented reality ar provide right service user whereas amount spatial information produced people increasing daily research aim design personalized ar based tourist system retrieves big data according user demographic context order enrich ar data source tourism research conducted two main step first type tourist attraction user interest predicted according user demographic context include age gender education level using machine learning method second correct data user extracted big data considering time distance popularity neighborhood tourist place using vikor swar decision making method 6 result show better performance decision tree predicting type tourist attraction compared svm method addition result user study system show overall satisfaction participant term ease use 55 term system usefulness 56big_data decision_making decision_trees learning_algorithms support_vector_machines travel_industryar_data_source big_data correct_data personalized_augmented_reality required_data_resources tourism_system tourist_attraction tourist_system user_demographic_contexts users_interest
167,Wearable Haptic Device for Stiffness Rendering of Virtual Objects in Augmented Reality,"Lee, Y., Lee, S., & Lee, D. (2021). Wearable Haptic Device for Stiffness Rendering of Virtual Objects in Augmented Reality. Applied Sciences, 11(15), 6932. https://doi.org/10.3390/app11156932
",10.3390/app11156932,"We propose a novel wearable haptic device that can provide kinesthetic haptic feedback for stiffness rendering of virtual objects in augmented reality (AR). Rendering stiffness of objects using haptic feedback is crucial for realistic finger-based object manipulation, yet challenging particularly in AR due to the co-presence of a real hand, haptic device, and rendered AR objects in the scenes. By adopting passive actuation with a tendon-based transmission mechanism, the proposed haptic device can generate kinesthetic feedback strong enough for immersive manipulation and prevention of inter-penetration in a small-form-factor, while maximizing the wearability and minimizing the occlusion in AR usage. A selective locking module is adopted in the device to allow for the rendering of the elasticity of objects. We perform an experimental study of two-finger grasping to verify the efficacy of the proposed haptic device for finger-based manipulation in AR. We also quantitatively compare/articulate the effects of different types of feedbacks across haptic and visual sense (i.e., kinesthetic haptic feedback, vibrotactile haptic feedback, and visuo-haptic feedback) for stiffness rendering of virtual objects in AR for the first time.",C5540B Interactive-input devices;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces,AR objects;augmented reality;finger-based manipulation;haptic sense;kinesthetic feedback strong;kinesthetic haptic feedback;realistic finger-based object manipulation;stiffness rendering;tendon-based transmission mechanism;vibrotactile haptic feedback;virtual objects;visual sense;visuo-haptic feedback;wearable haptic device,augmented reality;elasticity;feedback;haptic interfaces;rendering (computer graphics);virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Lee, Y.; (1) Lee, S.; (1) Lee, D.; ","(1) Seoul National University, Department of Mechanical Engineering, Korea, Republic of; ",MDPI,-1,"[""elasticity"", ""feedback"", ""haptic interfaces"", ""rendering""]","[""elasticity"", ""feedback"", ""haptic interfaces"", ""rendering""]",elasticity;feedback;haptic interfaces;rendering,input;engineering;graphics;human-computer interaction,technology;end users and user experience,input;engineering;graphics;human-computer interaction,technology;end users and user experience,elasticity feedback haptic_interfaces rendering ar_objects augmented_reality finger based_manipulation haptic_sense kinesthetic_feedback_strong kinesthetic_haptic_feedback realistic_finger based_object_manipulation stiffness_rendering tendon based_transmission_mechanism vibrotactile_haptic_feedback virtual_objects visual_sense visuo haptic_feedback wearable_haptic_device c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces input engineering graphics human computer_interaction,elasticity feedback haptic_interfaces rendering,ar_objects augmented_reality finger based_manipulation haptic_sense kinesthetic_feedback_strong kinesthetic_haptic_feedback realistic_finger based_object_manipulation stiffness_rendering tendon based_transmission_mechanism vibrotactile_haptic_feedback virtual_objects visual_sense visuo haptic_feedback wearable_haptic_device,propose novel wearable haptic device provide kinesthetic haptic feedback stiffness rendering virtual object augmented reality ar rendering stiffness object using haptic feedback crucial realistic finger based object manipulation yet challenging particularly ar due co presence real hand haptic device rendered ar object scene adopting passive actuation tendon based transmission mechanism proposed haptic device generate kinesthetic feedback strong enough immersive manipulation prevention inter penetration small form factor maximizing wearability minimizing occlusion ar usage selective locking module adopted device allow rendering elasticity object perform experimental study two finger grasping verify efficacy proposed haptic device finger based manipulation ar also quantitatively compare articulate effect different type feedback across haptic visual sense e kinesthetic haptic feedback vibrotactile haptic feedback visuo haptic feedback stiffness rendering virtual object ar first time,elasticity feedback haptic_interfaces rendering ar_objects augmented_reality finger based_manipulation haptic_sense kinesthetic_feedback_strong kinesthetic_haptic_feedback realistic_finger based_object_manipulation stiffness_rendering tendon based_transmission_mechanism vibrotactile_haptic_feedback virtual_objects visual_sense visuo haptic_feedback wearable_haptic_device c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces input engineering graphics human computer_interaction propose novel wearable haptic device provide kinesthetic haptic feedback stiffness rendering virtual object augmented reality ar rendering stiffness object using haptic feedback crucial realistic finger based object manipulation yet challenging particularly ar due co presence real hand haptic device rendered ar object scene adopting passive actuation tendon based transmission mechanism proposed haptic device generate kinesthetic feedback strong enough immersive manipulation prevention inter penetration small form factor maximizing wearability minimizing occlusion ar usage selective locking module adopted device allow rendering elasticity object perform experimental study two finger grasping verify efficacy proposed haptic device finger based manipulation ar also quantitatively compare articulate effect different type feedback across haptic visual sense e kinesthetic haptic feedback vibrotactile haptic feedback visuo haptic feedback stiffness rendering virtual object ar first time,propose novel wearable haptic device provide kinesthetic haptic feedback stiffness rendering virtual object augmented reality ar rendering stiffness object using haptic feedback crucial realistic finger based object manipulation yet challenging particularly ar due co presence real hand haptic device rendered ar object scene adopting passive actuation tendon based transmission mechanism proposed haptic device generate kinesthetic feedback strong enough immersive manipulation prevention inter penetration small form factor maximizing wearability minimizing occlusion ar usage selective locking module adopted device allow rendering elasticity object perform experimental study two finger grasping verify efficacy proposed haptic device finger based manipulation ar also quantitatively compare articulate effect different type feedback across haptic visual sense e kinesthetic haptic feedback vibrotactile haptic feedback visuo haptic feedback stiffness rendering virtual object ar first timeelasticity feedback haptic_interfaces renderingar_objects augmented_reality finger based_manipulation haptic_sense kinesthetic_feedback_strong kinesthetic_haptic_feedback realistic_finger based_object_manipulation stiffness_rendering tendon based_transmission_mechanism vibrotactile_haptic_feedback virtual_objects visual_sense visuo haptic_feedback wearable_haptic_device
168,"Augmented Reality, Virtual Reality and Artificial Intelligence in Orthopedic Surgery: A Systematic Review","Longo, U. G., De Salvatore, S., Candela, V., Zollo, G., Calabrese, G., Fioravanti, S., Giannone, L., Marchetti, A., De Marinis, M. G., & Denaro, V. (2021). Augmented Reality, Virtual Reality and Artificial Intelligence in Orthopedic Surgery: A Systematic Review. Applied Sciences, 11(7), 3253. https://doi.org/10.3390/app11073253
",10.3390/app11073253,"Background: The application of virtual and augmented reality technologies to orthopaedic surgery training and practice aims to increase the safety and accuracy of procedures and reducing complications and costs. The purpose of this systematic review is to summarise the present literature on this topic while providing a detailed analysis of current flaws and benefits. Methods: A comprehensive search on the PubMed, Cochrane, CINAHL, and Embase database was conducted from inception to February 2021. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines were used to improve the reporting of the review. The Cochrane Risk of Bias Tool and the Methodological Index for Non-Randomized Studies (MINORS) was used to assess the quality and potential bias of the included randomized and non-randomized control trials, respectively. Results: Virtual reality has been proven revolutionary for both resident training and preoperative planning. Thanks to augmented reality, orthopaedic surgeons could carry out procedures faster and more accurately, improving overall safety. Artificial intelligence (AI) is a promising technology with limitless potential, but, nowadays, its use in orthopaedic surgery is limited to preoperative diagnosis. Conclusions: Extended reality technologies have the potential to reform orthopaedic training and practice, providing an opportunity for unidirectional growth towards a patient-centred approach.",A8770G Patient care and treatment;A0130R Reviews and tutorial papers; resource letters;B7520 Patient care and treatment;C6130V Virtual reality;C7140 Medical administration;C7330 Biology and medical computing,artificial intelligence;augmented reality;current flaws;extended reality technologies;meta-analyses guidelines;NonRandomized Studies;orthopaedic surgery training;orthopaedic training;orthopedic surgery;potential bias;preferred reporting items;preoperative planning;reducing complications;resident training;systematic review;virtual reality,augmented reality;biomedical equipment;medical computing;medical information systems;orthopaedics;reviews;surgery;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Longo, U.G.; (1) De salvatore, S.; (1) Candela, V.; (1) Zollo, G.; (1) Calabrese, G.; (2) Fioravanti, S.; (2) Giannone, L.; (2) Marchetti, A.; (2) De Marinis, M.G.; (1) Denaro, V.; ","(1) Campus Bio-Medico University, Department of Orthopedic and Trauma Surgery, Italy; (2) Campus Bio-Medico di Roma University, Research Unit Nursing Science, Italy; ",MDPI,-1,"[""biomedical equipment"", ""medical computing"", ""medical information systems"", ""orthopedics"", ""reviews"", ""surgery""]","[""biomedical equipment"", ""medical computing"", ""medical information systems"", ""orthopedics"", ""reviews"", ""surgery""]",biomedical equipment;medical computing;medical information systems;orthopedics;reviews;surgery,medical;education;developers;standards,technology;standards;industries,medical;education;developers;standards,technology;standards;industries,biomedical_equipment medical_computing medical_information_systems orthopedics reviews surgery artificial_intelligence augmented_reality current_flaws extended_reality_technologies meta analyses_guidelines nonrandomized_studies orthopaedic_surgery_training orthopaedic_training orthopedic_surgery potential_bias preferred_reporting_items preoperative_planning reducing_complications resident_training systematic_review virtual_reality a8770g_patient_care_and_treatment a0130r_reviews_and_tutorial_papers _resource_letters b7520_patient_care_and_treatment c6130v_virtual_reality c7140_medical_administration c7330_biology_and_medical_computing medical education developers standards,biomedical_equipment medical_computing medical_information_systems orthopedics reviews surgery,artificial_intelligence augmented_reality current_flaws extended_reality_technologies meta analyses_guidelines nonrandomized_studies orthopaedic_surgery_training orthopaedic_training orthopedic_surgery potential_bias preferred_reporting_items preoperative_planning reducing_complications resident_training systematic_review virtual_reality,background application virtual augmented reality technology orthopaedic surgery training practice aim increase safety accuracy procedure reducing complication cost purpose systematic review summarise present literature topic providing detailed analysis current flaw benefit method comprehensive search pubmed cochrane cinahl embase database conducted inception february 2021 preferred reporting item systematic review meta analysis prisma guideline used improve reporting review cochrane risk bias tool methodological index non randomized study minor used ass quality potential bias included randomized non randomized control trial respectively result virtual reality proven revolutionary resident training preoperative planning thanks augmented reality orthopaedic surgeon could carry procedure faster accurately improving overall safety artificial intelligence ai promising technology limitless potential nowadays use orthopaedic surgery limited preoperative diagnosis conclusion extended reality technology potential reform orthopaedic training practice providing opportunity unidirectional growth towards patient centred approach,biomedical_equipment medical_computing medical_information_systems orthopedics reviews surgery artificial_intelligence augmented_reality current_flaws extended_reality_technologies meta analyses_guidelines nonrandomized_studies orthopaedic_surgery_training orthopaedic_training orthopedic_surgery potential_bias preferred_reporting_items preoperative_planning reducing_complications resident_training systematic_review virtual_reality a8770g_patient_care_and_treatment a0130r_reviews_and_tutorial_papers _resource_letters b7520_patient_care_and_treatment c6130v_virtual_reality c7140_medical_administration c7330_biology_and_medical_computing medical education developers standards background application virtual augmented reality technology orthopaedic surgery training practice aim increase safety accuracy procedure reducing complication cost purpose systematic review summarise present literature topic providing detailed analysis current flaw benefit method comprehensive search pubmed cochrane cinahl embase database conducted inception february 2021 preferred reporting item systematic review meta analysis prisma guideline used improve reporting review cochrane risk bias tool methodological index non randomized study minor used ass quality potential bias included randomized non randomized control trial respectively result virtual reality proven revolutionary resident training preoperative planning thanks augmented reality orthopaedic surgeon could carry procedure faster accurately improving overall safety artificial intelligence ai promising technology limitless potential nowadays use orthopaedic surgery limited preoperative diagnosis conclusion extended reality technology potential reform orthopaedic training practice providing opportunity unidirectional growth towards patient centred approach,background application virtual augmented reality technology orthopaedic surgery training practice aim increase safety accuracy procedure reducing complication cost purpose systematic review summarise present literature topic providing detailed analysis current flaw benefit method comprehensive search pubmed cochrane cinahl embase database conducted inception february 2021 preferred reporting item systematic review meta analysis prisma guideline used improve reporting review cochrane risk bias tool methodological index non randomized study minor used ass quality potential bias included randomized non randomized control trial respectively result virtual reality proven revolutionary resident training preoperative planning thanks augmented reality orthopaedic surgeon could carry procedure faster accurately improving overall safety artificial intelligence ai promising technology limitless potential nowadays use orthopaedic surgery limited preoperative diagnosis conclusion extended reality technology potential reform orthopaedic training practice providing opportunity unidirectional growth towards patient centred approachbiomedical_equipment medical_computing medical_information_systems orthopedics reviews surgeryartificial_intelligence augmented_reality current_flaws extended_reality_technologies meta analyses_guidelines nonrandomized_studies orthopaedic_surgery_training orthopaedic_training orthopedic_surgery potential_bias preferred_reporting_items preoperative_planning reducing_complications resident_training systematic_review virtual_reality
169,Comparative Study on Brightness and Leakage Ratio Test Methods of Optical Waveguide Augmented Reality Glasses,"Di, F., Xu, Y., Chen, C., & Wu, J. (2023). Comparative study on brightness and leakage ratio test methods of optical waveguide augmented reality glasses. International Conference on Precision Instruments and Optical Engineering (PIOE 2022). https://doi.org/10.1117/12.2667900
",10.1117/12.2667900,"Because the near eye display (NED) device mainly displays its imaging effect with a unique virtual image, in essence, compared with the traditional display device, the measurement requirements and methods of brightness, light leakage ratio and other related parameters have also changed. By analyzing the imaging characteristics of optical waveguide AR display equipment, a comparative test scheme for brightness and light leakage ratio is proposed. The same type of arrayed optical waveguide NED module is experimentally measured by using equipment with different test principles, and the measurement results are compared and analyzed. The research results show that the measurement results of the ordinary aiming point luminance meter are not the luminance values in the real display. For the measurement of a certain illumination degree of the equipment, the luminance value and light leakage measured by the aiming point luminance meter have lower deviation than that measured by the two-dimensional imaging luminance meter. Therefore, in the process of testing NED, it is necessary to correctly select the measuring instrument according to its imaging characteristics, the size of the area to be tested and the test scene. &copy; 2023 SPIE.","714.3 Waveguides;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;741.3 Optical Devices and Systems",Aiming point luminance meter;AR display;Array optical waveguide AR display module;Display modules;Imaging luminance meter;Leakage ratios;Light leakage;Light leakage ratio;Luminance meters,Augmented reality;Display devices;Optical design;Optical waveguides,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Di, Fei; (2) Xu, Yingying; (2) Chen, Chi; (1) Wu, Jinjun; ","(1) China Academy of Machinery Science and Technology Group, Beijing; 100044, China; (2) National Institute of Metrology, Beijing; 100029, China; (3) Beijing Institute of Technology, Beijing; 100081, China; ",SPIE,-1,"[""display devices"", ""optical design"", ""optical waveguides""]","[""display devices"", ""optical design"", ""optical waveguides""]",display devices;optical design;optical waveguides,display technology;optics;human-computer interaction,displays;end users and user experience,display technology;optics;human-computer interaction,displays;end users and user experience,display_devices optical_design optical_waveguides aiming_point_luminance_meter ar_display array_optical_waveguide_ar_display_module display_modules imaging_luminance_meter leakage_ratios light_leakage light_leakage_ratio luminance_meters 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems display_technology optics human computer_interaction,display_devices optical_design optical_waveguides,aiming_point_luminance_meter ar_display array_optical_waveguide_ar_display_module display_modules imaging_luminance_meter leakage_ratios light_leakage light_leakage_ratio luminance_meters,near eye display ned device mainly display imaging effect unique virtual image essence compared traditional display device measurement requirement method brightness light leakage ratio related parameter also changed analyzing imaging characteristic optical waveguide ar display equipment comparative test scheme brightness light leakage ratio proposed type arrayed optical waveguide ned module experimentally measured using equipment different test principle measurement result compared analyzed research result show measurement result ordinary aiming point luminance meter luminance value real display measurement certain illumination degree equipment luminance value light leakage measured aiming point luminance meter lower deviation measured two dimensional imaging luminance meter therefore process testing ned necessary correctly select measuring instrument according imaging characteristic size area tested test scene copy 2023 spie,display_devices optical_design optical_waveguides aiming_point_luminance_meter ar_display array_optical_waveguide_ar_display_module display_modules imaging_luminance_meter leakage_ratios light_leakage light_leakage_ratio luminance_meters 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems display_technology optics human computer_interaction near eye display ned device mainly display imaging effect unique virtual image essence compared traditional display device measurement requirement method brightness light leakage ratio related parameter also changed analyzing imaging characteristic optical waveguide ar display equipment comparative test scheme brightness light leakage ratio proposed type arrayed optical waveguide ned module experimentally measured using equipment different test principle measurement result compared analyzed research result show measurement result ordinary aiming point luminance meter luminance value real display measurement certain illumination degree equipment luminance value light leakage measured aiming point luminance meter lower deviation measured two dimensional imaging luminance meter therefore process testing ned necessary correctly select measuring instrument according imaging characteristic size area tested test scene copy 2023 spie,near eye display ned device mainly display imaging effect unique virtual image essence compared traditional display device measurement requirement method brightness light leakage ratio related parameter also changed analyzing imaging characteristic optical waveguide ar display equipment comparative test scheme brightness light leakage ratio proposed type arrayed optical waveguide ned module experimentally measured using equipment different test principle measurement result compared analyzed research result show measurement result ordinary aiming point luminance meter luminance value real display measurement certain illumination degree equipment luminance value light leakage measured aiming point luminance meter lower deviation measured two dimensional imaging luminance meter therefore process testing ned necessary correctly select measuring instrument according imaging characteristic size area tested test scene copy 2023 spiedisplay_devices optical_design optical_waveguidesaiming_point_luminance_meter ar_display array_optical_waveguide_ar_display_module display_modules imaging_luminance_meter leakage_ratios light_leakage light_leakage_ratio luminance_meters
170,The Effect of Luminance on Depth Perception in Augmented Reality Guided Laparoscopic Surgery,"Reissis, A., Yoo, S., Clarkson, M. J., & Thompson, S. A. (2023). The effect of luminance on depth perception in augmented reality guided laparoscopic surgery. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2654223
",10.1117/12.2654223,"Depth perception is a major issue in surgical augmented reality (AR) with limited research conducted in this scientific area. This study establishes a relationship between luminance and depth perception. This can be used to improve visualisation design for AR overlay in laparoscopic surgery, providing surgeons a more accurate perception of the anatomy intraoperatively. Two experiments were conducted to determine this relationship. First, an online study with 59 participants from the general public, and second, an in-person study with 10 surgeons as participants. We developed 2 open-source software tools utilising SciKit-Surgery libraries to enable these studies and any future research. Our findings demonstrate that the higher the relative luminance, the closer a structure is perceived to the operating camera. Furthermore, the higher the luminance contrast between the two structures, the higher the depth distance perceived. The quantitative results from both experiments are in agreement, indicating that online recruitment of the general public can be helpful in similar studies. An observation made by the surgeons from the in-person study was that the light source used in laparoscopic surgery plays a role in depth perception. This is due to its varying positioning and brightness which could affect the perception of the overlaid AR. We found that luminance directly correlates with depth perception for both surgeons and the general public, regardless of other depth cues. Future research may focus on comparing different colours used in surgical AR and using a mock operating room (OR) with varying light sources and positions. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;723 Computer Software, Data Handling and Applications;746 Imaging Techniques",General publics;Image guidances;Laparoscopic surgery;Luminance contrast;Online studies;Open-source softwares;Quantitative result;Relative luminances;Software-tools;Visualization designs,Augmented reality;Depth perception;Laparoscopy;Light sources;Medical imaging;Mixed reality;Open source software;Open systems;Visualization,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Reissis, Athena; (1) Yoo, Soojeong; (1) Clarkson, Matthew J.; (1) Thompson, Stephen; ","(1) Wellcome/EPSRC Centre for Interventional and Surgical Science, University College London, United Kingdom; (2) UCL Interaction Centre, University College London, United Kingdom; ",SPIE,-1,"[""depth perception"", ""laparoscopy"", ""light sources"", ""medical imaging"", ""open source software"", ""open systems"", ""visualization""]","[""depth perception"", ""laparoscopy"", ""light sources"", ""medical imaging"", ""open source software"", ""open systems"", ""visualization""]",depth perception;laparoscopy;light sources;medical imaging;open source software;open systems;visualization,education;input;medical;human factors;developers;data,technology;end users and user experience;industries,education;input;medical;human factors;developers;data,technology;end users and user experience;industries,depth_perception laparoscopy light_sources medical_imaging open_source_software open_systems visualization general_publics image_guidances laparoscopic_surgery luminance_contrast online_studies open source_softwares quantitative_result relative_luminances software tools visualization_designs 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 746_imaging_techniques education input medical human_factors developers data,depth_perception laparoscopy light_sources medical_imaging open_source_software open_systems visualization,general_publics image_guidances laparoscopic_surgery luminance_contrast online_studies open source_softwares quantitative_result relative_luminances software tools visualization_designs,depth perception major issue surgical augmented reality ar limited research conducted scientific area study establishes relationship luminance depth perception used improve visualisation design ar overlay laparoscopic surgery providing surgeon accurate perception anatomy intraoperatively two experiment conducted determine relationship first online study 59 participant general public second person study 10 surgeon participant developed 2 open source software tool utilising scikit surgery library enable study future research finding demonstrate higher relative luminance closer structure perceived operating camera furthermore higher luminance contrast two structure higher depth distance perceived quantitative result experiment agreement indicating online recruitment general public helpful similar study observation made surgeon person study light source used laparoscopic surgery play role depth perception due varying positioning brightness could affect perception overlaid ar found luminance directly correlate depth perception surgeon general public regardless depth cue future research may focus comparing different colour used surgical ar using mock operating room varying light source position copy 2023 spie,depth_perception laparoscopy light_sources medical_imaging open_source_software open_systems visualization general_publics image_guidances laparoscopic_surgery luminance_contrast online_studies open source_softwares quantitative_result relative_luminances software tools visualization_designs 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 746_imaging_techniques education input medical human_factors developers data depth perception major issue surgical augmented reality ar limited research conducted scientific area study establishes relationship luminance depth perception used improve visualisation design ar overlay laparoscopic surgery providing surgeon accurate perception anatomy intraoperatively two experiment conducted determine relationship first online study 59 participant general public second person study 10 surgeon participant developed 2 open source software tool utilising scikit surgery library enable study future research finding demonstrate higher relative luminance closer structure perceived operating camera furthermore higher luminance contrast two structure higher depth distance perceived quantitative result experiment agreement indicating online recruitment general public helpful similar study observation made surgeon person study light source used laparoscopic surgery play role depth perception due varying positioning brightness could affect perception overlaid ar found luminance directly correlate depth perception surgeon general public regardless depth cue future research may focus comparing different colour used surgical ar using mock operating room varying light source position copy 2023 spie,depth perception major issue surgical augmented reality ar limited research conducted scientific area study establishes relationship luminance depth perception used improve visualisation design ar overlay laparoscopic surgery providing surgeon accurate perception anatomy intraoperatively two experiment conducted determine relationship first online study 59 participant general public second person study 10 surgeon participant developed 2 open source software tool utilising scikit surgery library enable study future research finding demonstrate higher relative luminance closer structure perceived operating camera furthermore higher luminance contrast two structure higher depth distance perceived quantitative result experiment agreement indicating online recruitment general public helpful similar study observation made surgeon person study light source used laparoscopic surgery play role depth perception due varying positioning brightness could affect perception overlaid ar found luminance directly correlate depth perception surgeon general public regardless depth cue future research may focus comparing different colour used surgical ar using mock operating room varying light source position copy 2023 spiedepth_perception laparoscopy light_sources medical_imaging open_source_software open_systems visualizationgeneral_publics image_guidances laparoscopic_surgery luminance_contrast online_studies open source_softwares quantitative_result relative_luminances software tools visualization_designs
171,Towards a New Learning Experience through a Mobile Application with Augmented Reality in Engineering Education,"Criollo-C, S., Abad-Vásquez, D., Martic-Nieto, M., Velásquez-G, F. A., Pérez-Medina, J.-L., & Luján-Mora, S. (2021). Towards a New Learning Experience through a Mobile Application with Augmented Reality in Engineering Education. Applied Sciences, 11(11), 4921. https://doi.org/10.3390/app11114921
",10.3390/app11114921,"With the rise of information technology and digitization, education has been faced with the need to adopt new learning models using technology to create innovative educational methodologies. In addition, due to pandemic restrictions and in order to help contain the spread of the virus (COVID-19), all educational institutions have been forced to switch immediately to online education. The application of augmented reality (AR) in education provides important benefits, such as increased engagement and interactivity, and can help to minimize the negative effects of the disruption of face-to-face education. Therefore, this paper focuses on describing the effect of an augmented reality mobile application (NetAR) that was developed for engineering students as a complement to traditional education. To achieve this objective, an experimental group and a control group were established to work with the application for three weeks for three hours a day. Moreover, there are a number of usability issues with AR that may impact learning effectiveness and motivation. Therefore, the usability of the application was evaluated with the IBM Computer System Usability Questionnaire (CSUQ) tool. The usability results show that users are satisfied with NetAR, and the statistical data from the control group indicate that the application positively affects learning.","B0120 Education and training;C0110 Control education and training;C0220 Computing education and training;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction;E0250 Education and training",augmented reality mobile application;COVID-19;educational institutions;engineering education;IBM Computer System Usability Questionnaire tool;IBM CSUQ tool;information technology;innovative educational methodologies;learning effectiveness;NetAR;new learning experience;pandemic restrictions;virus spreading,augmented reality;computer aided instruction;diseases;educational institutions;engineering education;epidemics;further education;microorganisms;mobile learning;user experience,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Criollo-c, S.; (1) Abad-va&#769;squez, D.; (1) Martic-nieto, M.; (1) Vela&#769;squez-g, F.A.; (1) Pe&#769;rez-medina, J.-L.; (2) Luja&#769;n-mora, S.; ","(1) Universidad de Las Ame&#769;ricas, Escuela de Ingenieri&#769;a en Tecnologi&#769;as de la Informacio&#769;n, Ecuador; (2) Universidad de Alicante, Departamento de Lenguajes y Sistemas Informa&#769;ticos, Spain; ",MDPI,-1,"[""computer aided instruction"", ""diseases"", ""educational institutions"", ""engineering education"", ""epidemics"", ""further education"", ""microorganisms"", ""mobile learning"", ""user experience""]","[""computer aided instruction"", ""diseases"", ""educational institutions"", ""engineering education"", ""epidemics"", ""further education"", ""microorganisms"", ""mobile learning"", ""user experience""]",computer aided instruction;diseases;educational institutions;engineering education;epidemics;further education;microorganisms;mobile learning;user experience,medical;human factors;education;training,end users and user experience;use cases;industries,medical;human factors;education;training,end users and user experience;use cases;industries,computer_aided_instruction diseases educational_institutions engineering_education epidemics further_education microorganisms mobile_learning user_experience augmented_reality_mobile_application covid 19 educational_institutions engineering_education ibm_computer_system_usability_questionnaire_tool ibm_csuq_tool information_technology innovative_educational_methodologies learning_effectiveness netar new_learning_experience pandemic_restrictions virus_spreading b0120_education_and_training c0110_control_education_and_training c0220_computing_education_and_training c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction e0250_education_and_training medical human_factors education training,computer_aided_instruction diseases educational_institutions engineering_education epidemics further_education microorganisms mobile_learning user_experience,augmented_reality_mobile_application covid 19 educational_institutions engineering_education ibm_computer_system_usability_questionnaire_tool ibm_csuq_tool information_technology innovative_educational_methodologies learning_effectiveness netar new_learning_experience pandemic_restrictions virus_spreading,rise information technology digitization education faced need adopt new learning model using technology create innovative educational methodology addition due pandemic restriction order help contain spread virus covid 19 educational institution forced switch immediately online education application augmented reality ar education provides important benefit increased engagement interactivity help minimize negative effect disruption face face education therefore paper focus describing effect augmented reality mobile application netar developed engineering student complement traditional education achieve objective experimental group control group established work application three week three hour day moreover number usability issue ar may impact learning effectiveness motivation therefore usability application evaluated ibm computer system usability questionnaire csuq tool usability result show user satisfied netar statistical data control group indicate application positively affect learning,computer_aided_instruction diseases educational_institutions engineering_education epidemics further_education microorganisms mobile_learning user_experience augmented_reality_mobile_application covid 19 educational_institutions engineering_education ibm_computer_system_usability_questionnaire_tool ibm_csuq_tool information_technology innovative_educational_methodologies learning_effectiveness netar new_learning_experience pandemic_restrictions virus_spreading b0120_education_and_training c0110_control_education_and_training c0220_computing_education_and_training c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction e0250_education_and_training medical human_factors education training rise information technology digitization education faced need adopt new learning model using technology create innovative educational methodology addition due pandemic restriction order help contain spread virus covid 19 educational institution forced switch immediately online education application augmented reality ar education provides important benefit increased engagement interactivity help minimize negative effect disruption face face education therefore paper focus describing effect augmented reality mobile application netar developed engineering student complement traditional education achieve objective experimental group control group established work application three week three hour day moreover number usability issue ar may impact learning effectiveness motivation therefore usability application evaluated ibm computer system usability questionnaire csuq tool usability result show user satisfied netar statistical data control group indicate application positively affect learning,rise information technology digitization education faced need adopt new learning model using technology create innovative educational methodology addition due pandemic restriction order help contain spread virus covid 19 educational institution forced switch immediately online education application augmented reality ar education provides important benefit increased engagement interactivity help minimize negative effect disruption face face education therefore paper focus describing effect augmented reality mobile application netar developed engineering student complement traditional education achieve objective experimental group control group established work application three week three hour day moreover number usability issue ar may impact learning effectiveness motivation therefore usability application evaluated ibm computer system usability questionnaire csuq tool usability result show user satisfied netar statistical data control group indicate application positively affect learningcomputer_aided_instruction diseases educational_institutions engineering_education epidemics further_education microorganisms mobile_learning user_experienceaugmented_reality_mobile_application covid 19 educational_institutions engineering_education ibm_computer_system_usability_questionnaire_tool ibm_csuq_tool information_technology innovative_educational_methodologies learning_effectiveness netar new_learning_experience pandemic_restrictions virus_spreading
172,Augmented Reality Assisted Assembly Training Oriented Dynamic Gesture Recognition and Prediction,"Dong, J., Xia, Z., & Zhao, Q. (2021). Augmented Reality Assisted Assembly Training Oriented Dynamic Gesture Recognition and Prediction. Applied Sciences, 11(21), 9789. https://doi.org/10.3390/app11219789
",10.3390/app11219789,"Augmented reality assisted assembly training (ARAAT) is an effective and affordable technique for labor training in the automobile and electronic industry. In general, most tasks of ARAAT are conducted by real-time hand operations. In this paper, we propose an algorithm of dynamic gesture recognition and prediction that aims to evaluate the standard and achievement of the hand operations for a given task in ARAAT. We consider that the given task can be decomposed into a series of hand operations and furthermore each hand operation into several continuous actions. Then, each action is related with a standard gesture based on the practical assembly task such that the standard and achievement of the actions included in the operations can be identified and predicted by the sequences of gestures instead of the performance throughout the whole task. Based on the practical industrial assembly, we specified five typical tasks, three typical operations, and six standard actions. We used Zernike moments combined histogram of oriented gradient and linear interpolation motion trajectories to represent 2D static and 3D dynamic features of standard gestures, respectively, and chose the directional pulse-coupled neural network as the classifier to recognize the gestures. In addition, we defined an action unit to reduce the dimensions of features and computational cost. During gesture recognition, we optimized the gesture boundaries iteratively by calculating the score probability density distribution to reduce interferences of invalid gestures and improve precision. The proposed algorithm was evaluated on four datasets and proved to increase recognition accuracy and reduce the computational cost from the experimental results.",B6135E Image recognition;B0240Z Other topics in statistics;B0290F Interpolation and function approximation (numerical analysis);C1140Z Other topics in statistics;C4130 Interpolation and function approximation (numerical analysis);C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6264 Neural nets,3D dynamic features;ARAAT;augmented reality assisted assembly training oriented dynamic gesture prediction;augmented reality assisted assembly training oriented dynamic gesture recognition;directional pulse-coupled neural network;histogram of oriented gradient;industrial assembly;linear interpolation motion trajectories;probability density distribution;Zernike moments,augmented reality;computer vision;feature extraction;gesture recognition;image classification;image denoising;image motion analysis;image sequences;interpolation;neural nets;object detection;probability;solid modelling,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Dong, J.; (2) Xia, Z.; (1) Zhao, Q.; ","(1) Shanghai Jiao Tong University, Department of Automation, China; (2) Shenzhen Institutes of Advanced Technology, China; ",MDPI,-1,"[""computer vision"", ""feature extraction"", ""gesture recognition"", ""image classification"", ""image denoising"", ""image motion analysis"", ""image sequences"", ""interpolation"", ""neural networks"", ""object detection"", ""probability"", ""solid modelling""]","[""computer vision"", ""feature extraction"", ""gesture recognition"", ""image classification"", ""image denoising"", ""image motion analysis"", ""image sequences"", ""interpolation"", ""neural networks"", ""object detection"", ""probability"", ""solid modelling""]",computer vision;feature extraction;gesture recognition;image classification;image denoising;image motion analysis;image sequences;interpolation;neural networks;object detection;probability;solid modelling,computer vision;manufacturing;input;chemical;human factors;data;artificial intelligence;video,technology;end users and user experience;industries,computer vision;manufacturing;input;chemical;human factors;data;artificial intelligence;video,technology;end users and user experience;industries,computer_vision feature_extraction gesture_recognition image_classification image_denoising image_motion_analysis image_sequences interpolation neural_networks object_detection probability solid_modelling 3d_dynamic_features araat augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_prediction augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_recognition directional_pulse coupled_neural_network histogram_of_oriented_gradient industrial_assembly linear_interpolation_motion_trajectories probability_density_distribution zernike_moments b6135e_image_recognition b0240z_other_topics_in_statistics b0290f_interpolation_and_function_approximation_ numerical_analysis c1140z_other_topics_in_statistics c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6264_neural_nets computer_vision manufacturing input chemical human_factors data artificial_intelligence video,computer_vision feature_extraction gesture_recognition image_classification image_denoising image_motion_analysis image_sequences interpolation neural_networks object_detection probability solid_modelling,3d_dynamic_features araat augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_prediction augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_recognition directional_pulse coupled_neural_network histogram_of_oriented_gradient industrial_assembly linear_interpolation_motion_trajectories probability_density_distribution zernike_moments,augmented reality assisted assembly training araat effective affordable technique labor training automobile electronic industry general task araat conducted real time hand operation paper propose algorithm dynamic gesture recognition prediction aim evaluate standard achievement hand operation given task araat consider given task decomposed series hand operation furthermore hand operation several continuous action action related standard gesture based practical assembly task standard achievement action included operation identified predicted sequence gesture instead performance throughout whole task based practical industrial assembly specified five typical task three typical operation six standard action used zernike moment combined histogram oriented gradient linear interpolation motion trajectory represent 2d static 3d dynamic feature standard gesture respectively chose directional pulse coupled neural network classifier recognize gesture addition defined action unit reduce dimension feature computational cost gesture recognition optimized gesture boundary iteratively calculating score probability density distribution reduce interference invalid gesture improve precision proposed algorithm evaluated four datasets proved increase recognition accuracy reduce computational cost experimental result,computer_vision feature_extraction gesture_recognition image_classification image_denoising image_motion_analysis image_sequences interpolation neural_networks object_detection probability solid_modelling 3d_dynamic_features araat augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_prediction augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_recognition directional_pulse coupled_neural_network histogram_of_oriented_gradient industrial_assembly linear_interpolation_motion_trajectories probability_density_distribution zernike_moments b6135e_image_recognition b0240z_other_topics_in_statistics b0290f_interpolation_and_function_approximation_ numerical_analysis c1140z_other_topics_in_statistics c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6264_neural_nets computer_vision manufacturing input chemical human_factors data artificial_intelligence video augmented reality assisted assembly training araat effective affordable technique labor training automobile electronic industry general task araat conducted real time hand operation paper propose algorithm dynamic gesture recognition prediction aim evaluate standard achievement hand operation given task araat consider given task decomposed series hand operation furthermore hand operation several continuous action action related standard gesture based practical assembly task standard achievement action included operation identified predicted sequence gesture instead performance throughout whole task based practical industrial assembly specified five typical task three typical operation six standard action used zernike moment combined histogram oriented gradient linear interpolation motion trajectory represent 2d static 3d dynamic feature standard gesture respectively chose directional pulse coupled neural network classifier recognize gesture addition defined action unit reduce dimension feature computational cost gesture recognition optimized gesture boundary iteratively calculating score probability density distribution reduce interference invalid gesture improve precision proposed algorithm evaluated four datasets proved increase recognition accuracy reduce computational cost experimental result,augmented reality assisted assembly training araat effective affordable technique labor training automobile electronic industry general task araat conducted real time hand operation paper propose algorithm dynamic gesture recognition prediction aim evaluate standard achievement hand operation given task araat consider given task decomposed series hand operation furthermore hand operation several continuous action action related standard gesture based practical assembly task standard achievement action included operation identified predicted sequence gesture instead performance throughout whole task based practical industrial assembly specified five typical task three typical operation six standard action used zernike moment combined histogram oriented gradient linear interpolation motion trajectory represent 2d static 3d dynamic feature standard gesture respectively chose directional pulse coupled neural network classifier recognize gesture addition defined action unit reduce dimension feature computational cost gesture recognition optimized gesture boundary iteratively calculating score probability density distribution reduce interference invalid gesture improve precision proposed algorithm evaluated four datasets proved increase recognition accuracy reduce computational cost experimental resultcomputer_vision feature_extraction gesture_recognition image_classification image_denoising image_motion_analysis image_sequences interpolation neural_networks object_detection probability solid_modelling3d_dynamic_features araat augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_prediction augmented_reality_assisted_assembly_training_oriented_dynamic_gesture_recognition directional_pulse coupled_neural_network histogram_of_oriented_gradient industrial_assembly linear_interpolation_motion_trajectories probability_density_distribution zernike_moments
173,RetroSphere: Self-Contained Passive 3D Controller Tracking for Augmented Reality,"Balaji, A. N., Kimber, C., Li, D., Wu, S., Du, R., & Kim, D. (2022). RetroSphere. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 6(4), 1–36. https://doi.org/10.1145/3569479
",10.1145/3569479,"Advanced AR/VR headsets often have a dedicated depth sensor or multiple cameras, high processing power, and a high-capacity battery to track hands or controllers. However, these approaches are not compatible with the small form factor and limited thermal capacity of lightweight AR devices. In this paper, we present RetroSphere, a self-contained 6 degree of freedom (6DoF) controller tracker that can be integrated with almost any device. RetroSphere tracks a passive controller with just 3 retroreflective spheres using a stereo pair of mass-produced infrared blob trackers, each with its own infrared LED emitters. As the sphere is completely passive, no electronics or recharging is required. Each object tracking camera provides a tiny Arduino-compatible ESP32 microcontroller with the 2D position of the spheres. A lightweight stereo depth estimation algorithm that runs on the ESP32 performs 6DoF tracking of the passive controller. Also, RetroSphere provides an auto-calibration procedure to calibrate the stereo IR tracker setup. Our work builds upon Johnny Lee's Wii remote hacks and aims to enable a community of researchers, designers, and makers to use 3D input in their projects with affordable off-the-shelf components. RetroSphere achieves a tracking accuracy of about 96.5% with errors as low as ~3.5 cm over a 100 cm tracking range, validated with ground truth 3D data obtained using a LIDAR camera while consuming around 400 mW. We provide implementation details, evaluate the accuracy of our system, and demonstrate example applications, such as mobile AR drawing, 3D measurement, etc. with our Retrosphere-enabled AR glass prototype.","B7230G Image sensors;B6135 Optical, image and video signal processing;B6320C Optical radar;C5260B Computer vision and image processing techniques;C6130V Virtual reality",100 cm tracking range;3 retroreflective spheres;augmented reality;auto-calibration procedure;dedicated depth sensor;ESP32 performs 6DoF tracking;form factor;freedom controller tracker;ground truth 3D data;high processing power;high-capacity battery;infrared LED emitters;Johnny Lee's Wii remote hacks;LIDAR camera;lightweight AR devices;lightweight stereo depth estimation algorithm;limited thermal capacity;mass-produced infrared blob trackers;multiple cameras;object tracking camera;passive 3D controller tracking;passive controller;power 400.0 mW;Retrosphere-enabled AR glass prototype;size 100.0 cm;size 3.5 cm;stereo IR tracker setup;stereo pair;tiny Arduino-compatible ESP;tracking accuracy,augmented reality;calibration;cameras;microcontrollers;object tracking;optical radar;stereo image processing;virtual reality,2022,Journal article (JA),Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. (USA),"(1) Balaji, A.N.; (2) Kimber, C.; (3) Li, D.; (2) Wu, S.; (2) Du, R.; (2) Kim, D.; ","(1) National University of Singapore, Singapore; (2) Google, Ireland; (3) University of Maryland, Baltimore, College Park, Baltimore, MD, United States; ",ACM,-1,"[""calibration"", ""cameras"", ""microcontrollers"", ""object tracking"", ""optical radar"", ""stereo image processing""]","[""calibration"", ""cameras"", ""microcontrollers"", ""object tracking"", ""optical radar"", ""stereo image processing""]",calibration;cameras;microcontrollers;object tracking;optical radar;stereo image processing,computer vision;input;optics;sensors;developers;data;human-computer interaction;geospatial,technology;displays;end users and user experience,computer vision;input;optics;sensors;developers;data;human-computer interaction;geospatial,technology;displays;end users and user experience,calibration cameras microcontrollers object_tracking optical_radar stereo_image_processing 100_cm_tracking_range 3_retroreflective_spheres augmented_reality auto calibration_procedure dedicated_depth_sensor esp32_performs_6dof_tracking form_factor freedom_controller_tracker ground_truth_3d_data high_processing_power high capacity_battery infrared_led_emitters johnny_lee s_wii_remote_hacks lidar_camera lightweight_ar_devices lightweight_stereo_depth_estimation_algorithm limited_thermal_capacity mass produced_infrared_blob_trackers multiple_cameras object_tracking_camera passive_3d_controller_tracking passive_controller power_400 0_mw retrosphere enabled_ar_glass_prototype size_100 0_cm size_3 5_cm stereo_ir_tracker_setup stereo_pair tiny_arduino compatible_esp tracking_accuracy b7230g_image_sensors b6135_optical _image_and_video_signal_processing b6320c_optical_radar c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input optics sensors developers data human computer_interaction geospatial,calibration cameras microcontrollers object_tracking optical_radar stereo_image_processing,100_cm_tracking_range 3_retroreflective_spheres augmented_reality auto calibration_procedure dedicated_depth_sensor esp32_performs_6dof_tracking form_factor freedom_controller_tracker ground_truth_3d_data high_processing_power high capacity_battery infrared_led_emitters johnny_lee s_wii_remote_hacks lidar_camera lightweight_ar_devices lightweight_stereo_depth_estimation_algorithm limited_thermal_capacity mass produced_infrared_blob_trackers multiple_cameras object_tracking_camera passive_3d_controller_tracking passive_controller power_400 0_mw retrosphere enabled_ar_glass_prototype size_100 0_cm size_3 5_cm stereo_ir_tracker_setup stereo_pair tiny_arduino compatible_esp tracking_accuracy,advanced ar vr headset often dedicated depth sensor multiple camera high processing power high capacity battery track hand controller however approach compatible small form factor limited thermal capacity lightweight ar device paper present retrosphere self contained 6 degree freedom 6dof controller tracker integrated almost device retrosphere track passive controller 3 retroreflective sphere using stereo pair mass produced infrared blob tracker infrared led emitter sphere completely passive electronics recharging required object tracking camera provides tiny arduino compatible esp32 microcontroller 2d position sphere lightweight stereo depth estimation algorithm run esp32 performs 6dof tracking passive controller also retrosphere provides auto calibration procedure calibrate stereo ir tracker setup work build upon johnny lee wii remote hack aim enable community researcher designer maker use 3d input project affordable shelf component retrosphere achieves tracking accuracy 96 5 error low 3 5 cm 100 cm tracking range validated ground truth 3d data obtained using lidar camera consuming around 400 mw provide implementation detail evaluate accuracy system demonstrate example application mobile ar drawing 3d measurement etc retrosphere enabled ar glass prototype,calibration cameras microcontrollers object_tracking optical_radar stereo_image_processing 100_cm_tracking_range 3_retroreflective_spheres augmented_reality auto calibration_procedure dedicated_depth_sensor esp32_performs_6dof_tracking form_factor freedom_controller_tracker ground_truth_3d_data high_processing_power high capacity_battery infrared_led_emitters johnny_lee s_wii_remote_hacks lidar_camera lightweight_ar_devices lightweight_stereo_depth_estimation_algorithm limited_thermal_capacity mass produced_infrared_blob_trackers multiple_cameras object_tracking_camera passive_3d_controller_tracking passive_controller power_400 0_mw retrosphere enabled_ar_glass_prototype size_100 0_cm size_3 5_cm stereo_ir_tracker_setup stereo_pair tiny_arduino compatible_esp tracking_accuracy b7230g_image_sensors b6135_optical _image_and_video_signal_processing b6320c_optical_radar c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision input optics sensors developers data human computer_interaction geospatial advanced ar vr headset often dedicated depth sensor multiple camera high processing power high capacity battery track hand controller however approach compatible small form factor limited thermal capacity lightweight ar device paper present retrosphere self contained 6 degree freedom 6dof controller tracker integrated almost device retrosphere track passive controller 3 retroreflective sphere using stereo pair mass produced infrared blob tracker infrared led emitter sphere completely passive electronics recharging required object tracking camera provides tiny arduino compatible esp32 microcontroller 2d position sphere lightweight stereo depth estimation algorithm run esp32 performs 6dof tracking passive controller also retrosphere provides auto calibration procedure calibrate stereo ir tracker setup work build upon johnny lee wii remote hack aim enable community researcher designer maker use 3d input project affordable shelf component retrosphere achieves tracking accuracy 96 5 error low 3 5 cm 100 cm tracking range validated ground truth 3d data obtained using lidar camera consuming around 400 mw provide implementation detail evaluate accuracy system demonstrate example application mobile ar drawing 3d measurement etc retrosphere enabled ar glass prototype,advanced ar vr headset often dedicated depth sensor multiple camera high processing power high capacity battery track hand controller however approach compatible small form factor limited thermal capacity lightweight ar device paper present retrosphere self contained 6 degree freedom 6dof controller tracker integrated almost device retrosphere track passive controller 3 retroreflective sphere using stereo pair mass produced infrared blob tracker infrared led emitter sphere completely passive electronics recharging required object tracking camera provides tiny arduino compatible esp32 microcontroller 2d position sphere lightweight stereo depth estimation algorithm run esp32 performs 6dof tracking passive controller also retrosphere provides auto calibration procedure calibrate stereo ir tracker setup work build upon johnny lee wii remote hack aim enable community researcher designer maker use 3d input project affordable shelf component retrosphere achieves tracking accuracy 96 5 error low 3 5 cm 100 cm tracking range validated ground truth 3d data obtained using lidar camera consuming around 400 mw provide implementation detail evaluate accuracy system demonstrate example application mobile ar drawing 3d measurement etc retrosphere enabled ar glass prototypecalibration cameras microcontrollers object_tracking optical_radar stereo_image_processing100_cm_tracking_range 3_retroreflective_spheres augmented_reality auto calibration_procedure dedicated_depth_sensor esp32_performs_6dof_tracking form_factor freedom_controller_tracker ground_truth_3d_data high_processing_power high capacity_battery infrared_led_emitters johnny_lee s_wii_remote_hacks lidar_camera lightweight_ar_devices lightweight_stereo_depth_estimation_algorithm limited_thermal_capacity mass produced_infrared_blob_trackers multiple_cameras object_tracking_camera passive_3d_controller_tracking passive_controller power_400 0_mw retrosphere enabled_ar_glass_prototype size_100 0_cm size_3 5_cm stereo_ir_tracker_setup stereo_pair tiny_arduino compatible_esp tracking_accuracy
174,Programming Robots by Demonstration Using Augmented Reality,"Soares, I., Petry, M., & Moreira, A. P. (2021). Programming Robots by Demonstration Using Augmented Reality. Sensors, 21(17), 5976. https://doi.org/10.3390/s21175976
",10.3390/s21175976,"The world is living the fourth industrial revolution, marked by the increasing intelligence and automation of manufacturing systems. Nevertheless, there are types of tasks that are too complex or too expensive to be fully automated, it would be more efficient if the machines were able to work with the human, not only by sharing the same workspace but also as useful collaborators. A possible solution to that problem is on human-robot interaction systems, understanding the applications where they can be helpful to implement and what are the challenges they face. This work proposes the development of an industrial prototype of a human-machine interaction system through Augmented Reality, in which the objective is to enable an industrial operator without any programming experience to program a robot. The system itself is divided into two different parts: the tracking system, which records the operator's hand movement, and the translator system, which writes the program to be sent to the robot that will execute the task. To demonstrate the concept, the user drew geometric figures, and the robot was able to replicate the operator's path recorded.",C3390 Robotics;C3350 Control in industrial production systems;C3355 Control applications in manufacturing processes;C6110 Systems analysis and programming;C6130V Virtual reality;C6180R Human-robot interaction;C7420 Control engineering computing;C7480 Production engineering computing;E0410D Industrial applications of IT;E1510 Manufacturing systems;E1550A Robotics,augmented reality;fourth industrial revolution;human-machine interaction system;human-robot interaction systems;industrial operator;industrial prototype;manufacturing systems;robot by demonstration programming;robot geometric figures;tracking system;translator system,augmented reality;automatic programming;control engineering computing;human-robot interaction;industrial robots;manufacturing systems;production engineering computing;robot programming,2021,Journal article (JA),Sensors (Switzerland),"(1) Soares, I.; (2) Petry, M.; (1) Moreira, A.P.; ","(1) Universidade do Porto, Department of Electrical and Computer Engineering, Portugal; (2) University of Porto, INESC TEC, Portugal; ",MDPI,-1,"[""automatic programming"", ""control engineering computing"", ""human-robot interaction"", ""industrial robots"", ""manufacturing systems"", ""production engineering computing"", ""robot programming""]","[""automatic programming"", ""control engineering computing"", ""human-robot interaction"", ""industrial robots"", ""manufacturing systems"", ""production engineering computing"", ""robot programming""]",automatic programming;control engineering computing;human-robot interaction;industrial robots;manufacturing systems;production engineering computing;robot programming,education;other;robotics;engineering;developers;manufacturing,technology;other;industries,education;other;robotics;engineering;developers;manufacturing,technology;other;industries,automatic_programming control_engineering_computing human robot_interaction industrial_robots manufacturing_systems production_engineering_computing robot_programming augmented_reality fourth_industrial_revolution human machine_interaction_system human robot_interaction_systems industrial_operator industrial_prototype manufacturing_systems robot_by_demonstration_programming robot_geometric_figures tracking_system translator_system c3390_robotics c3350_control_in_industrial_production_systems c3355_control_applications_in_manufacturing_processes c6110_systems_analysis_and_programming c6130v_virtual_reality c6180r_human robot_interaction c7420_control_engineering_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it e1510_manufacturing_systems e1550a_robotics education other robotics engineering developers manufacturing,automatic_programming control_engineering_computing human robot_interaction industrial_robots manufacturing_systems production_engineering_computing robot_programming,augmented_reality fourth_industrial_revolution human machine_interaction_system human robot_interaction_systems industrial_operator industrial_prototype manufacturing_systems robot_by_demonstration_programming robot_geometric_figures tracking_system translator_system,world living fourth industrial revolution marked increasing intelligence automation manufacturing system nevertheless type task complex expensive fully automated would efficient machine able work human sharing workspace also useful collaborator possible solution problem human robot interaction system understanding application helpful implement challenge face work proposes development industrial prototype human machine interaction system augmented reality objective enable industrial operator without programming experience program robot system divided two different part tracking system record operator hand movement translator system writes program sent robot execute task demonstrate concept user drew geometric figure robot able replicate operator path recorded,automatic_programming control_engineering_computing human robot_interaction industrial_robots manufacturing_systems production_engineering_computing robot_programming augmented_reality fourth_industrial_revolution human machine_interaction_system human robot_interaction_systems industrial_operator industrial_prototype manufacturing_systems robot_by_demonstration_programming robot_geometric_figures tracking_system translator_system c3390_robotics c3350_control_in_industrial_production_systems c3355_control_applications_in_manufacturing_processes c6110_systems_analysis_and_programming c6130v_virtual_reality c6180r_human robot_interaction c7420_control_engineering_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it e1510_manufacturing_systems e1550a_robotics education other robotics engineering developers manufacturing world living fourth industrial revolution marked increasing intelligence automation manufacturing system nevertheless type task complex expensive fully automated would efficient machine able work human sharing workspace also useful collaborator possible solution problem human robot interaction system understanding application helpful implement challenge face work proposes development industrial prototype human machine interaction system augmented reality objective enable industrial operator without programming experience program robot system divided two different part tracking system record operator hand movement translator system writes program sent robot execute task demonstrate concept user drew geometric figure robot able replicate operator path recorded,world living fourth industrial revolution marked increasing intelligence automation manufacturing system nevertheless type task complex expensive fully automated would efficient machine able work human sharing workspace also useful collaborator possible solution problem human robot interaction system understanding application helpful implement challenge face work proposes development industrial prototype human machine interaction system augmented reality objective enable industrial operator without programming experience program robot system divided two different part tracking system record operator hand movement translator system writes program sent robot execute task demonstrate concept user drew geometric figure robot able replicate operator path recordedautomatic_programming control_engineering_computing human robot_interaction industrial_robots manufacturing_systems production_engineering_computing robot_programmingaugmented_reality fourth_industrial_revolution human machine_interaction_system human robot_interaction_systems industrial_operator industrial_prototype manufacturing_systems robot_by_demonstration_programming robot_geometric_figures tracking_system translator_system
175,Multimodal Interaction Systems Based on Internet of Things and Augmented Reality: A Systematic Literature Review,"Kim, J. C., Laine, T. H., & Åhlund, C. (2021). Multimodal Interaction Systems Based on Internet of Things and Augmented Reality: A Systematic Literature Review. Applied Sciences, 11(4), 1738. https://doi.org/10.3390/app11041738
",10.3390/app11041738,"Technology developments have expanded the diversity of interaction modalities that can be used by an agent (either a human or machine) to interact with a computer system. This expansion has created the need for more natural and user-friendly interfaces in order to achieve effective user experience and usability. More than one modality can be provided to an agent for interaction with a system to accomplish this goal, which is referred to as a multimodal interaction (MI) system. The Internet of Things (IoT) and augmented reality (AR) are popular technologies that allow interaction systems to combine the real-world context of the agent and immersive AR content. However, although MI systems have been extensively studied, there are only several studies that reviewed MI systems that used IoT and AR. Therefore, this paper presents an in-depth review of studies that proposed various MI systems utilizing IoT and AR. A total of 23 studies were identified and analyzed through a rigorous systematic literature review protocol. The results of our analysis of MI system architectures, the relationship between system components, input/output interaction modalities, and open research challenges are presented and discussed to summarize the findings and identify future research and development avenues for researchers and MI developers.","C6180 User interfaces;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7330 Biology and medical computing",augmented reality;computer system;effective user experience;human machine;in-depth review;interaction systems;Internet of Things;IoT;MI developers;MI system architectures;multimodal interaction system;natural user-friendly interfaces;popular technologies;reviewed MI systems;rigorous systematic literature review protocol;system components;technology developments,augmented reality;human computer interaction;interactive systems;Internet;Internet of Things;mobile computing;user interfaces,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Kim, J.C.; (2) Laine, T.H.; (1) A&#778;hlund, C.; ","(1) Lulea&#778; University of Technology, Department of Computer Science, Electrical and Space Engineering, Sweden; (2) Ajou University, Department of Digital Media, Korea, Republic of; ",MDPI,-1,"[""human computer interaction"", ""interactive systems"", ""internet"", ""internet of things"", ""mobile computing"", ""user interfaces""]","[""human computer interaction"", ""interactive systems"", ""internet"", ""internet of things"", ""mobile computing"", ""user interfaces""]",human computer interaction;interactive systems;internet;internet of things;mobile computing;user interfaces,education;input;internet of things;telecommunication;human-computer interaction;networks,technology;end users and user experience;industries,education;input;internet of things;telecommunication;human-computer interaction;networks,technology;end users and user experience;industries,human_computer_interaction interactive_systems internet internet_of_things mobile_computing user_interfaces augmented_reality computer_system effective_user_experience human_machine in depth_review interaction_systems internet_of_things iot mi_developers mi_system_architectures multimodal_interaction_system natural_user friendly_interfaces popular_technologies reviewed_mi_systems rigorous_systematic_literature_review_protocol system_components technology_developments c6180_user_interfaces c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing education input internet_of_things telecommunication human computer_interaction networks,human_computer_interaction interactive_systems internet internet_of_things mobile_computing user_interfaces,augmented_reality computer_system effective_user_experience human_machine in depth_review interaction_systems internet_of_things iot mi_developers mi_system_architectures multimodal_interaction_system natural_user friendly_interfaces popular_technologies reviewed_mi_systems rigorous_systematic_literature_review_protocol system_components technology_developments,technology development expanded diversity interaction modality used agent either human machine interact computer system expansion created need natural user friendly interface order achieve effective user experience usability one modality provided agent interaction system accomplish goal referred multimodal interaction mi system internet thing iot augmented reality ar popular technology allow interaction system combine real world context agent immersive ar content however although mi system extensively studied several study reviewed mi system used iot ar therefore paper present depth review study proposed various mi system utilizing iot ar total 23 study identified analyzed rigorous systematic literature review protocol result analysis mi system architecture relationship system component input output interaction modality open research challenge presented discussed summarize finding identify future research development avenue researcher mi developer,human_computer_interaction interactive_systems internet internet_of_things mobile_computing user_interfaces augmented_reality computer_system effective_user_experience human_machine in depth_review interaction_systems internet_of_things iot mi_developers mi_system_architectures multimodal_interaction_system natural_user friendly_interfaces popular_technologies reviewed_mi_systems rigorous_systematic_literature_review_protocol system_components technology_developments c6180_user_interfaces c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing education input internet_of_things telecommunication human computer_interaction networks technology development expanded diversity interaction modality used agent either human machine interact computer system expansion created need natural user friendly interface order achieve effective user experience usability one modality provided agent interaction system accomplish goal referred multimodal interaction mi system internet thing iot augmented reality ar popular technology allow interaction system combine real world context agent immersive ar content however although mi system extensively studied several study reviewed mi system used iot ar therefore paper present depth review study proposed various mi system utilizing iot ar total 23 study identified analyzed rigorous systematic literature review protocol result analysis mi system architecture relationship system component input output interaction modality open research challenge presented discussed summarize finding identify future research development avenue researcher mi developer,technology development expanded diversity interaction modality used agent either human machine interact computer system expansion created need natural user friendly interface order achieve effective user experience usability one modality provided agent interaction system accomplish goal referred multimodal interaction mi system internet thing iot augmented reality ar popular technology allow interaction system combine real world context agent immersive ar content however although mi system extensively studied several study reviewed mi system used iot ar therefore paper present depth review study proposed various mi system utilizing iot ar total 23 study identified analyzed rigorous systematic literature review protocol result analysis mi system architecture relationship system component input output interaction modality open research challenge presented discussed summarize finding identify future research development avenue researcher mi developerhuman_computer_interaction interactive_systems internet internet_of_things mobile_computing user_interfacesaugmented_reality computer_system effective_user_experience human_machine in depth_review interaction_systems internet_of_things iot mi_developers mi_system_architectures multimodal_interaction_system natural_user friendly_interfaces popular_technologies reviewed_mi_systems rigorous_systematic_literature_review_protocol system_components technology_developments
176,Augmented reality assisted astronaut operations in space to upgrade the cold atom lab instrument,"Kellogg, J., Andrea-Liner, K., Jennings, J., Timms, S., Keramidas, R. C., Berry, J., DeLaCruz, T., Bryant, K., Crawford, J., Roth, K., Li, I., Kwan, S., Nuernberger, B., Croonquist, A., McArthur, M., Mohageg, M., & Oudrhiri, K. (2023). Augmented reality assisted astronaut operations in space to upgrade the cold atom lab instrument. Quantum Sensing, Imaging, and Precision Metrology. https://doi.org/10.1117/12.2650750
",10.1117/12.2650750,"The Cold Atom Lab (CAL) is a first of its kind quantum physics science instrument that utilizes the microgravity environment of the International Space Station (ISS) for ultra-cold atom fundamental physics experiments. CAL was installed into the US Destiny Lab of ISS by astronauts in May 2018. The CAL instrument was designed for a 3-year mission life and has limited capability to be serviced or upgraded on orbit. Due to its great success the CAL team was requested to upgrade a specific electronic circuit card that was never intended to be replaced on orbit. As such, the instrument was not designed to accommodate easy access to the circuit cards to enable replacement. Therefore, the CAL team at Jet Propulsion Lab (JPL) formed a collaborative team with experts from Marshall Space Flight Center (MSFC) and Johnson Space Center (JSC) to create a new capability for Augmented Reality (AR) to be utilized on ISS that enabled real time astronaut on orbit guidance for critical repair activities. For the first time ever during an Intra-Vehicular Activity (IVA) a payload developer on the ground (CAL team) was able to see a real-time astronaut perspective video stream and simultaneously direct the astronaut with virtual visual annotations in the astronaut's field of view in addition to voice commands. This AR capability enabled the complex process of accessing and replacing the circuit card and restoring the full functionality of the CAL instrument. &copy; 2023 SPIE.","655.1 Spacecraft, General;656.1 Space Flight;656.2 Space Research;723 Computer Software, Data Handling and Applications;922.2 Mathematical Statistics;931.1 Mechanics;931.2 Physical Properties of Gases, Liquids and Solids;931.3 Atomic and Molecular Physics;931.5 Gravitation, Relativity and String Theory",Bose-Einstein condensates;Circuit card;Cold atoms;Hololens;International Space stations;Lab instruments;On orbit;Quantum physics;Real- time,Atoms;Augmented reality;Bose-Einstein condensation;Laboratories;Manned space flight;Microgravity processing;Orbits;Space platforms;Space stations;Statistical mechanics,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Kellogg, James; (2) Andrea-Liner, Kathleen; (3) Jennings, Jennifer; (2) Timms, Steven; (3) Keramidas, Robert C.; (3) Berry, Johnnie; (2) DeLaCruz, Tony; (2) Bryant, Kevin; (2) Crawford, Joey; (3) Roth, Karl; (1) Li, Irena; (1) Kwan, Sandy; (1) Nuernberger, Benjamin; (1) Croonquist, Arvid; (2) McArthur, Megan; (1) Mohageg, Makan; (1) Oudrhiri, Kamal; ","(1) Jet Propulsion Laboratory, California Institute of Technology, Pasadena; CA; 91109, United States; (2) Johnson Space Center, Houston; TX; 77058, United States; (3) Marshall Space Flight Center, Huntsville; AL; 35812, United States; ",SPIE,-1,"[""atoms"", ""bose-einstein condensation"", ""laboratories"", ""manned space flight"", ""microgravity processing"", ""orbits"", ""space platforms"", ""space stations"", ""statistical mechanics""]","[""atoms"", ""bose-einstein condensation"", ""laboratories"", ""manned space flight"", ""microgravity processing"", ""orbits"", ""space platforms"", ""space stations"", ""statistical mechanics""]",atoms;bose-einstein condensation;laboratories;manned space flight;microgravity processing;orbits;space platforms;space stations;statistical mechanics,other;aviation and aerospace;input;chemical;training;data,technology;other;use cases;industries,other;aviation and aerospace;input;chemical;training;data,technology;other;use cases;industries,atoms bose einstein_condensation laboratories manned_space_flight microgravity_processing orbits space_platforms space_stations statistical_mechanics bose einstein_condensates circuit_card cold_atoms hololens international_space_stations lab_instruments on_orbit quantum_physics real _time 655 1_spacecraft _general 656 1_space_flight 656 2_space_research 723_computer_software _data_handling_and_applications 922 2_mathematical_statistics 931 1_mechanics 931 2_physical_properties_of_gases _liquids_and_solids 931 3_atomic_and_molecular_physics 931 5_gravitation _relativity_and_string_theory other aviation_and_aerospace input chemical training data,atoms bose einstein_condensation laboratories manned_space_flight microgravity_processing orbits space_platforms space_stations statistical_mechanics,bose einstein_condensates circuit_card cold_atoms hololens international_space_stations lab_instruments on_orbit quantum_physics real _time,cold atom lab cal first kind quantum physic science instrument utilizes microgravity environment international space station i ultra cold atom fundamental physic experiment cal installed u destiny lab i astronaut may 2018 cal instrument designed 3 year mission life limited capability serviced upgraded orbit due great success cal team requested upgrade specific electronic circuit card never intended replaced orbit instrument designed accommodate easy access circuit card enable replacement therefore cal team jet propulsion lab jpl formed collaborative team expert marshall space flight center msfc johnson space center jsc create new capability augmented reality ar utilized i enabled real time astronaut orbit guidance critical repair activity first time ever intra vehicular activity iva payload developer ground cal team able see real time astronaut perspective video stream simultaneously direct astronaut virtual visual annotation astronaut field view addition voice command ar capability enabled complex process accessing replacing circuit card restoring full functionality cal instrument copy 2023 spie,atoms bose einstein_condensation laboratories manned_space_flight microgravity_processing orbits space_platforms space_stations statistical_mechanics bose einstein_condensates circuit_card cold_atoms hololens international_space_stations lab_instruments on_orbit quantum_physics real _time 655 1_spacecraft _general 656 1_space_flight 656 2_space_research 723_computer_software _data_handling_and_applications 922 2_mathematical_statistics 931 1_mechanics 931 2_physical_properties_of_gases _liquids_and_solids 931 3_atomic_and_molecular_physics 931 5_gravitation _relativity_and_string_theory other aviation_and_aerospace input chemical training data cold atom lab cal first kind quantum physic science instrument utilizes microgravity environment international space station i ultra cold atom fundamental physic experiment cal installed u destiny lab i astronaut may 2018 cal instrument designed 3 year mission life limited capability serviced upgraded orbit due great success cal team requested upgrade specific electronic circuit card never intended replaced orbit instrument designed accommodate easy access circuit card enable replacement therefore cal team jet propulsion lab jpl formed collaborative team expert marshall space flight center msfc johnson space center jsc create new capability augmented reality ar utilized i enabled real time astronaut orbit guidance critical repair activity first time ever intra vehicular activity iva payload developer ground cal team able see real time astronaut perspective video stream simultaneously direct astronaut virtual visual annotation astronaut field view addition voice command ar capability enabled complex process accessing replacing circuit card restoring full functionality cal instrument copy 2023 spie,cold atom lab cal first kind quantum physic science instrument utilizes microgravity environment international space station i ultra cold atom fundamental physic experiment cal installed u destiny lab i astronaut may 2018 cal instrument designed 3 year mission life limited capability serviced upgraded orbit due great success cal team requested upgrade specific electronic circuit card never intended replaced orbit instrument designed accommodate easy access circuit card enable replacement therefore cal team jet propulsion lab jpl formed collaborative team expert marshall space flight center msfc johnson space center jsc create new capability augmented reality ar utilized i enabled real time astronaut orbit guidance critical repair activity first time ever intra vehicular activity iva payload developer ground cal team able see real time astronaut perspective video stream simultaneously direct astronaut virtual visual annotation astronaut field view addition voice command ar capability enabled complex process accessing replacing circuit card restoring full functionality cal instrument copy 2023 spieatoms bose einstein_condensation laboratories manned_space_flight microgravity_processing orbits space_platforms space_stations statistical_mechanicsbose einstein_condensates circuit_card cold_atoms hololens international_space_stations lab_instruments on_orbit quantum_physics real _time
177,An interactive method with gestures oriented toward the augmented reality electronic sand table,"Li, H., Huang, Z., & Guo, C. (2023). An interactive method with gestures oriented toward the augmented reality electronic sand table. International Conference on Electronic Information Engineering and Computer Science (EIECS 2022). https://doi.org/10.1117/12.2668367
",10.1117/12.2668367,"Traditional interaction techniques such as mouse and keyboard or gestures for a touch screen are utilized for a 2D electronic sand table, which don't have enough degrees of freedom (DoFs) for operations on a 3D graph. Gestures interaction method has received increasing attention for 3D electronic sand tables with solid terrain construction and virtual-real fusion display techniques. This paper researches an interactive feedback method with gestures based on contextual information, gestures controlling virtual targets and a gesture interaction modal are designed. Users can control virtual targets with intuitive and feasible interaction methods through the real calculation of a gesture recognition engine and a gesture understanding engine, and the displaying status of the virtual targets can be updated in real time. &copy; 2023 SPIE.","483.1 Soils and Soil Mechanics;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;931.1 Mechanics",3-D electronics;3d electronic sand table;3d graphs;Contextual information;Gesture interaction;Interaction methods;Interaction techniques;Interactive methods;Paper research;Virtual target,Augmented reality;Degrees of freedom (mechanics);Engines;Mammals;Touch screens;User interfaces,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Li, Heng; (1) Huang, Zhaonian; (1) Guo, Chen; ","(1) Wuhan Digital Engineering Institute, Wuhan, China; ",SPIE,-1,"[""degrees of freedom"", ""engines"", ""mammals"", ""touch screens"", ""user interfaces""]","[""degrees of freedom"", ""engines"", ""mammals"", ""touch screens"", ""user interfaces""]",degrees of freedom;engines;mammals;touch screens;user interfaces,input;robotics;human-computer interaction;power and energy,technology;industries;end users and user experience,input;robotics;human-computer interaction;power and energy,technology;industries;end users and user experience,degrees_of_freedom engines mammals touch_screens user_interfaces 3 d_electronics 3d_electronic_sand_table 3d_graphs contextual_information gesture_interaction interaction_methods interaction_techniques interactive_methods paper_research virtual_target 483 1_soils_and_soil_mechanics 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 931 1_mechanics input robotics human computer_interaction power_and_energy,degrees_of_freedom engines mammals touch_screens user_interfaces,3 d_electronics 3d_electronic_sand_table 3d_graphs contextual_information gesture_interaction interaction_methods interaction_techniques interactive_methods paper_research virtual_target,traditional interaction technique mouse keyboard gesture touch screen utilized 2d electronic sand table enough degree freedom dofs operation 3d graph gesture interaction method received increasing attention 3d electronic sand table solid terrain construction virtual real fusion display technique paper research interactive feedback method gesture based contextual information gesture controlling virtual target gesture interaction modal designed user control virtual target intuitive feasible interaction method real calculation gesture recognition engine gesture understanding engine displaying status virtual target updated real time copy 2023 spie,degrees_of_freedom engines mammals touch_screens user_interfaces 3 d_electronics 3d_electronic_sand_table 3d_graphs contextual_information gesture_interaction interaction_methods interaction_techniques interactive_methods paper_research virtual_target 483 1_soils_and_soil_mechanics 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 931 1_mechanics input robotics human computer_interaction power_and_energy traditional interaction technique mouse keyboard gesture touch screen utilized 2d electronic sand table enough degree freedom dofs operation 3d graph gesture interaction method received increasing attention 3d electronic sand table solid terrain construction virtual real fusion display technique paper research interactive feedback method gesture based contextual information gesture controlling virtual target gesture interaction modal designed user control virtual target intuitive feasible interaction method real calculation gesture recognition engine gesture understanding engine displaying status virtual target updated real time copy 2023 spie,traditional interaction technique mouse keyboard gesture touch screen utilized 2d electronic sand table enough degree freedom dofs operation 3d graph gesture interaction method received increasing attention 3d electronic sand table solid terrain construction virtual real fusion display technique paper research interactive feedback method gesture based contextual information gesture controlling virtual target gesture interaction modal designed user control virtual target intuitive feasible interaction method real calculation gesture recognition engine gesture understanding engine displaying status virtual target updated real time copy 2023 spiedegrees_of_freedom engines mammals touch_screens user_interfaces3 d_electronics 3d_electronic_sand_table 3d_graphs contextual_information gesture_interaction interaction_methods interaction_techniques interactive_methods paper_research virtual_target
178,Supporting Visualization Analysis in Industrial Process Tomography by Using Augmented Reality-A Case Study of an Industrial Microwave Drying System &#8224;,"Zhang, Y., Omrani, A., Yadav, R., & Fjeld, M. (2021). Supporting Visualization Analysis in Industrial Process Tomography by Using Augmented Reality—A Case Study of an Industrial Microwave Drying System. Sensors, 21(19), 6515. https://doi.org/10.3390/s21196515
",10.3390/s21196515,"Industrial process tomography (IPT) based process control is an advisable approach in industrial heating processes for improving system efficiency and quality. When using it, appropriate dataflow pipelines and visualizations are key for domain users to implement precise data acquisition and analysis. In this article, we propose a complete data processing and visualizing workflow regarding a specific case&#8212;microwave tomography (MWT) controlled industrial microwave drying system. Furthermore, we present the up-to-date augmented reality (AR) technique to support the corresponding data visualization and on-site analysis. As a pioneering study of using AR to benefit IPT systems, the proposed AR module provides straightforward and comprehensible visualizations pertaining to the process data to the related users. Inside the dataflow of the case, a time reversal imaging algorithm, a post-imaging segmentation, and a volumetric visualization module are included. For the time reversal algorithm, we exhaustively introduce each step for MWT image reconstruction and then present the simulated results. For the post-imaging segmentation, an automatic tomographic segmentation algorithm is utilized to reveal the significant information contained in the reconstructed images. For volumetric visualization, the 3D generated information is displayed. Finally, the proposed AR system is integrated with the on-going process data, including reconstructed, segmented, and volumetric images, which are used for facilitating interactive on-site data analysis for domain users. The central part of the AR system is implemented by a mobile app that is currently supported on iOS/Android platforms.","A8770E Patient diagnostic methods and instrumentation;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7330 Biology and medical computing",appropriate dataflow pipelines;AR system;augmented reality-a;automatic tomographic segmentation algorithm;complete data processing;corresponding data visualization;domain users;industrial heating processes;industrial microwave drying system;industrial process tomography;IPT systems;MWT image reconstruction;on-site analysis;on-site data analysis;post-imaging segmentation;precise data acquisition;process data;reconstructed images;specific case&#8212;microwave tomography;system efficiency;time reversal algorithm;time reversal imaging algorithm;up-to-date augmented reality;visualization analysis;visualizing workflow;volumetric images;volumetric visualization module,augmented reality;data acquisition;data analysis;data visualisation;drying;image reconstruction;image segmentation;medical image processing;mobile computing;process control;tomography,2021,Journal article (JA),Sensors (Switzerland),"(1) Zhang, Y.; (2) Omrani, A.; (3) Yadav, R.; (1) Fjeld, M.; ","(1) Chalmers University of Technology, Department of Computer Science and Engineering, Sweden; (2) Karlsruhe Institute of Technology, Institute for Pulsed Power and Microwave Technology, Germany; (3) University of Eastern Finland, Department of Applied Physics, Finland; ",MDPI,-1,"[""data acquisition"", ""data analysis"", ""data visualization"", ""drying"", ""image reconstruction"", ""image segmentation"", ""medical image processing"", ""mobile computing"", ""process control"", ""tomography""]","[""data acquisition"", ""data analysis"", ""data visualization"", ""drying"", ""image reconstruction"", ""image segmentation"", ""medical image processing"", ""mobile computing"", ""process control"", ""tomography""]",data acquisition;data analysis;data visualization;drying;image reconstruction;image segmentation;medical image processing;mobile computing;process control;tomography,construction;computer vision;other;input;industrial equipment;medical;telecommunication;data,technology;other;industries,construction;computer vision;other;input;industrial equipment;medical;telecommunication;data,technology;other;industries,data_acquisition data_analysis data_visualization drying image_reconstruction image_segmentation medical_image_processing mobile_computing process_control tomography appropriate_dataflow_pipelines ar_system augmented_reality a automatic_tomographic_segmentation_algorithm complete_data_processing corresponding_data_visualization domain_users industrial_heating_processes industrial_microwave_drying_system industrial_process_tomography ipt_systems mwt_image_reconstruction on site_analysis on site_data_analysis post imaging_segmentation precise_data_acquisition process_data reconstructed_images specific_case 8212 microwave_tomography system_efficiency time_reversal_algorithm time_reversal_imaging_algorithm up to date_augmented_reality visualization_analysis visualizing_workflow volumetric_images volumetric_visualization_module a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing construction computer_vision other input industrial_equipment medical telecommunication data,data_acquisition data_analysis data_visualization drying image_reconstruction image_segmentation medical_image_processing mobile_computing process_control tomography,appropriate_dataflow_pipelines ar_system augmented_reality a automatic_tomographic_segmentation_algorithm complete_data_processing corresponding_data_visualization domain_users industrial_heating_processes industrial_microwave_drying_system industrial_process_tomography ipt_systems mwt_image_reconstruction on site_analysis on site_data_analysis post imaging_segmentation precise_data_acquisition process_data reconstructed_images specific_case 8212 microwave_tomography system_efficiency time_reversal_algorithm time_reversal_imaging_algorithm up to date_augmented_reality visualization_analysis visualizing_workflow volumetric_images volumetric_visualization_module,industrial process tomography ipt based process control advisable approach industrial heating process improving system efficiency quality using appropriate dataflow pipeline visualization key domain user implement precise data acquisition analysis article propose complete data processing visualizing workflow regarding specific case 8212 microwave tomography mwt controlled industrial microwave drying system furthermore present date augmented reality ar technique support corresponding data visualization site analysis pioneering study using ar benefit ipt system proposed ar module provides straightforward comprehensible visualization pertaining process data related user inside dataflow case time reversal imaging algorithm post imaging segmentation volumetric visualization module included time reversal algorithm exhaustively introduce step mwt image reconstruction present simulated result post imaging segmentation automatic tomographic segmentation algorithm utilized reveal significant information contained reconstructed image volumetric visualization 3d generated information displayed finally proposed ar system integrated going process data including reconstructed segmented volumetric image used facilitating interactive site data analysis domain user central part ar system implemented mobile app currently supported io android platform,data_acquisition data_analysis data_visualization drying image_reconstruction image_segmentation medical_image_processing mobile_computing process_control tomography appropriate_dataflow_pipelines ar_system augmented_reality a automatic_tomographic_segmentation_algorithm complete_data_processing corresponding_data_visualization domain_users industrial_heating_processes industrial_microwave_drying_system industrial_process_tomography ipt_systems mwt_image_reconstruction on site_analysis on site_data_analysis post imaging_segmentation precise_data_acquisition process_data reconstructed_images specific_case 8212 microwave_tomography system_efficiency time_reversal_algorithm time_reversal_imaging_algorithm up to date_augmented_reality visualization_analysis visualizing_workflow volumetric_images volumetric_visualization_module a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing construction computer_vision other input industrial_equipment medical telecommunication data industrial process tomography ipt based process control advisable approach industrial heating process improving system efficiency quality using appropriate dataflow pipeline visualization key domain user implement precise data acquisition analysis article propose complete data processing visualizing workflow regarding specific case 8212 microwave tomography mwt controlled industrial microwave drying system furthermore present date augmented reality ar technique support corresponding data visualization site analysis pioneering study using ar benefit ipt system proposed ar module provides straightforward comprehensible visualization pertaining process data related user inside dataflow case time reversal imaging algorithm post imaging segmentation volumetric visualization module included time reversal algorithm exhaustively introduce step mwt image reconstruction present simulated result post imaging segmentation automatic tomographic segmentation algorithm utilized reveal significant information contained reconstructed image volumetric visualization 3d generated information displayed finally proposed ar system integrated going process data including reconstructed segmented volumetric image used facilitating interactive site data analysis domain user central part ar system implemented mobile app currently supported io android platform,industrial process tomography ipt based process control advisable approach industrial heating process improving system efficiency quality using appropriate dataflow pipeline visualization key domain user implement precise data acquisition analysis article propose complete data processing visualizing workflow regarding specific case 8212 microwave tomography mwt controlled industrial microwave drying system furthermore present date augmented reality ar technique support corresponding data visualization site analysis pioneering study using ar benefit ipt system proposed ar module provides straightforward comprehensible visualization pertaining process data related user inside dataflow case time reversal imaging algorithm post imaging segmentation volumetric visualization module included time reversal algorithm exhaustively introduce step mwt image reconstruction present simulated result post imaging segmentation automatic tomographic segmentation algorithm utilized reveal significant information contained reconstructed image volumetric visualization 3d generated information displayed finally proposed ar system integrated going process data including reconstructed segmented volumetric image used facilitating interactive site data analysis domain user central part ar system implemented mobile app currently supported io android platformdata_acquisition data_analysis data_visualization drying image_reconstruction image_segmentation medical_image_processing mobile_computing process_control tomographyappropriate_dataflow_pipelines ar_system augmented_reality a automatic_tomographic_segmentation_algorithm complete_data_processing corresponding_data_visualization domain_users industrial_heating_processes industrial_microwave_drying_system industrial_process_tomography ipt_systems mwt_image_reconstruction on site_analysis on site_data_analysis post imaging_segmentation precise_data_acquisition process_data reconstructed_images specific_case 8212 microwave_tomography system_efficiency time_reversal_algorithm time_reversal_imaging_algorithm up to date_augmented_reality visualization_analysis visualizing_workflow volumetric_images volumetric_visualization_module
179,How to Make Augmented Reality a Tool for Railway Maintenance Operations: Operator 4.0 Perspective,"Scheffer, S., Martinetti, A., Damgrave, R., Thiede, S., & van Dongen, L. (2021). How to Make Augmented Reality a Tool for Railway Maintenance Operations: Operator 4.0 Perspective. Applied Sciences, 11(6), 2656. https://doi.org/10.3390/app11062656
",10.3390/app11062656,"In the last few decades, several initiatives and approaches are set up to support maintenance procedures for the railway industry in adopting the principles of Industry 4.0. Contextualized maintenance technologies such as Augmented Reality (AR) overlay can integrate virtual information on physical objects to improve decision-making and action-taking processes. Operators work in a dynamic working environment requiring both high adaptive capabilities and expert knowledge. There is a need to support the operators with tailor-based information that is customized and contextualized to their expertise and experience. It calls for AR tools and approaches that combine complex methodologies with high usability requirements. The development of these AR tools could benefit from a structured approach. Therefore, the objective of this paper is to propose an adaptive architectural framework aimed at shaping and structuring the process that provides operators with tailored support when using an AR tool. Case study research is applied within a revelatory railway industry setting. It was found that the framework ensures that self-explanatory AR systems can capture the knowledge of the operator, support the operator during maintenance activities, conduct failure analysis, provide problem-solving strategies, and improve learning capabilities. This study contributes to the necessity of having a human-centered approach for the successful adaption of AR technology tools for the railway industry.",C6130V Virtual reality;C6180 User interfaces;C7480 Production engineering computing;E0410D Industrial applications of IT;E1020 Maintenance and reliability,action-taking processes;adaptive architectural framework;AR technology tools;AR tool;Augmented Reality overlay;case study research;complex methodologies;contextualized maintenance technologies;decision-making;dynamic working environment;expert knowledge;high adaptive capabilities;high usability requirements;human-centered approach;maintenance activities;maintenance procedures;operators work;physical objects;railway maintenance operations;revelatory railway industry setting;shaping structuring;structured approach;successful adaption;tailor-based information;tailored support;virtual information,augmented reality;decision making;failure analysis;maintenance engineering;production engineering computing;railways;user interfaces,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Scheffer, S.; (1) Martinetti, A.; (1) Damgrave, R.; (1) Thiede, S.; (1) Van Dongen, L.; ","(1) University of Twente, Faculty of Engineering Technology, De Horst 2, Netherlands; ",MDPI,-1,"[""decision making"", ""failure analysis"", ""maintenance engineering"", ""production engineering computing"", ""railways"", ""user interfaces""]","[""decision making"", ""failure analysis"", ""maintenance engineering"", ""production engineering computing"", ""railways"", ""user interfaces""]",decision making;failure analysis;maintenance engineering;production engineering computing;railways;user interfaces,"other;inspection, safety and quality;human factors;engineering;human-computer interaction;manufacturing",other;industries;end users and user experience;use cases;technology,"other;inspection, safety and quality;human factors;engineering;human-computer interaction;manufacturing",other;industries;end users and user experience;use cases;technology,decision_making failure_analysis maintenance_engineering production_engineering_computing railways user_interfaces action taking_processes adaptive_architectural_framework ar_technology_tools ar_tool augmented_reality_overlay case_study_research complex_methodologies contextualized_maintenance_technologies decision making dynamic_working_environment expert_knowledge high_adaptive_capabilities high_usability_requirements human centered_approach maintenance_activities maintenance_procedures operators_work physical_objects railway_maintenance_operations revelatory_railway_industry_setting shaping_structuring structured_approach successful_adaption tailor based_information tailored_support virtual_information c6130v_virtual_reality c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it e1020_maintenance_and_reliability other inspection _safety_and_quality human_factors engineering human computer_interaction manufacturing,decision_making failure_analysis maintenance_engineering production_engineering_computing railways user_interfaces,action taking_processes adaptive_architectural_framework ar_technology_tools ar_tool augmented_reality_overlay case_study_research complex_methodologies contextualized_maintenance_technologies decision making dynamic_working_environment expert_knowledge high_adaptive_capabilities high_usability_requirements human centered_approach maintenance_activities maintenance_procedures operators_work physical_objects railway_maintenance_operations revelatory_railway_industry_setting shaping_structuring structured_approach successful_adaption tailor based_information tailored_support virtual_information,last decade several initiative approach set support maintenance procedure railway industry adopting principle industry 4 0 contextualized maintenance technology augmented reality ar overlay integrate virtual information physical object improve decision making action taking process operator work dynamic working environment requiring high adaptive capability expert knowledge need support operator tailor based information customized contextualized expertise experience call ar tool approach combine complex methodology high usability requirement development ar tool could benefit structured approach therefore objective paper propose adaptive architectural framework aimed shaping structuring process provides operator tailored support using ar tool case study research applied within revelatory railway industry setting found framework ensures self explanatory ar system capture knowledge operator support operator maintenance activity conduct failure analysis provide problem solving strategy improve learning capability study contributes necessity human centered approach successful adaption ar technology tool railway industry,decision_making failure_analysis maintenance_engineering production_engineering_computing railways user_interfaces action taking_processes adaptive_architectural_framework ar_technology_tools ar_tool augmented_reality_overlay case_study_research complex_methodologies contextualized_maintenance_technologies decision making dynamic_working_environment expert_knowledge high_adaptive_capabilities high_usability_requirements human centered_approach maintenance_activities maintenance_procedures operators_work physical_objects railway_maintenance_operations revelatory_railway_industry_setting shaping_structuring structured_approach successful_adaption tailor based_information tailored_support virtual_information c6130v_virtual_reality c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it e1020_maintenance_and_reliability other inspection _safety_and_quality human_factors engineering human computer_interaction manufacturing last decade several initiative approach set support maintenance procedure railway industry adopting principle industry 4 0 contextualized maintenance technology augmented reality ar overlay integrate virtual information physical object improve decision making action taking process operator work dynamic working environment requiring high adaptive capability expert knowledge need support operator tailor based information customized contextualized expertise experience call ar tool approach combine complex methodology high usability requirement development ar tool could benefit structured approach therefore objective paper propose adaptive architectural framework aimed shaping structuring process provides operator tailored support using ar tool case study research applied within revelatory railway industry setting found framework ensures self explanatory ar system capture knowledge operator support operator maintenance activity conduct failure analysis provide problem solving strategy improve learning capability study contributes necessity human centered approach successful adaption ar technology tool railway industry,last decade several initiative approach set support maintenance procedure railway industry adopting principle industry 4 0 contextualized maintenance technology augmented reality ar overlay integrate virtual information physical object improve decision making action taking process operator work dynamic working environment requiring high adaptive capability expert knowledge need support operator tailor based information customized contextualized expertise experience call ar tool approach combine complex methodology high usability requirement development ar tool could benefit structured approach therefore objective paper propose adaptive architectural framework aimed shaping structuring process provides operator tailored support using ar tool case study research applied within revelatory railway industry setting found framework ensures self explanatory ar system capture knowledge operator support operator maintenance activity conduct failure analysis provide problem solving strategy improve learning capability study contributes necessity human centered approach successful adaption ar technology tool railway industrydecision_making failure_analysis maintenance_engineering production_engineering_computing railways user_interfacesaction taking_processes adaptive_architectural_framework ar_technology_tools ar_tool augmented_reality_overlay case_study_research complex_methodologies contextualized_maintenance_technologies decision making dynamic_working_environment expert_knowledge high_adaptive_capabilities high_usability_requirements human centered_approach maintenance_activities maintenance_procedures operators_work physical_objects railway_maintenance_operations revelatory_railway_industry_setting shaping_structuring structured_approach successful_adaption tailor based_information tailored_support virtual_information
180,Investigating the Usability of a Head-Mounted Display Augmented Reality Device in Elementary School Children,"Lauer, L., Altmeyer, K., Malone, S., Barz, M., Brünken, R., Sonntag, D., & Peschel, M. (2021). Investigating the Usability of a Head-Mounted Display Augmented Reality Device in Elementary School Children. Sensors, 21(19), 6623. https://doi.org/10.3390/s21196623
",10.3390/s21196623,"Augmenting reality via head-mounted displays (HMD-AR) is an emerging technology in education. The interactivity provided by HMD-AR devices is particularly promising for learning, but presents a challenge to human activity recognition, especially with children. Recent technological advances regarding speech and gesture recognition concerning Microsoft's HoloLens 2 may address this prevailing issue. In a within-subjects study with 47 elementary school children (2nd to 6th grade), we examined the usability of the HoloLens 2 using a standardized tutorial on multimodal interaction in AR. The overall system usability was rated ""good"". However, several behavioral metrics indicated that specific interaction modes differed in their efficiency. The results are of major importance for the development of learning applications in HMD-AR as they partially deviate from previous findings. In particular, the well-functioning recognition of children's voice commands that we observed represents a novelty. Furthermore, we found different interaction preferences in HMD-AR among the children. We also found the use of HMD-AR to have a positive effect on children's activity-related achievement emotions. Overall, our findings can serve as a basis for determining general requirements, possibilities, and limitations of the implementation of educational HMD-AR environments in elementary school classrooms.",C6180 User interfaces;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7810C Computer-aided instruction,47 elementary school children;augmenting reality;different interaction preferences;educational HMD-AR environments;elementary school classrooms;gesture recognition;head-mounted display augmented reality device;head-mounted displays;HMD-AR devices;human activity recognition;learning applications;Microsoft's HoloLens 2;multimodal interaction;prevailing issue;specific interaction modes;system usability;well-functioning recognition,augmented reality;computer aided instruction;gesture recognition;handicapped aids;helmet mounted displays;human computer interaction,2021,Journal article (JA),Sensors (Switzerland),"(1) Lauer, L.; (2) Altmeyer, K.; (2) Malone, S.; (3) Barz, M.; (2) Bru&#776;nken, R.; (3) Sonntag, D.; (1) Peschel, M.; ","(1) Saarland University, Department of Physics, Campus C6.3, Germany; (2) Saarland University, Department of Education, Campus A4.2, Germany; (3) German Research Center for Artificial Intelligence, Interactive Machine Learning Department, Stuhlsatzenhausweg 3, Saarland Informatics Campus D3_2, Germany; (4) Oldenburg University, Applied Artificial Intelligence, Marie-Curie-Str. 1, Germany; ",MDPI,-1,"[""computer aided instruction"", ""gesture recognition"", ""handicapped aids"", ""helmet mounted displays"", ""human computer interaction""]","[""computer aided instruction"", ""gesture recognition"", ""handicapped aids"", ""helmet mounted displays"", ""human computer interaction""]",computer aided instruction;gesture recognition;handicapped aids;helmet mounted displays;human computer interaction,input;medical;training;display technology;human factors;wearables;human-computer interaction,displays;industries;end users and user experience;use cases;technology,input;medical;training;display technology;human factors;wearables;human-computer interaction,displays;industries;end users and user experience;use cases;technology,computer_aided_instruction gesture_recognition handicapped_aids helmet_mounted_displays human_computer_interaction 47_elementary_school_children augmenting_reality different_interaction_preferences educational_hmd ar_environments elementary_school_classrooms gesture_recognition head mounted_display_augmented_reality_device head mounted_displays hmd ar_devices human_activity_recognition learning_applications microsoft s_hololens_2 multimodal_interaction prevailing_issue specific_interaction_modes system_usability well functioning_recognition c6180_user_interfaces c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7810c_computer aided_instruction input medical training display_technology human_factors wearables human computer_interaction,computer_aided_instruction gesture_recognition handicapped_aids helmet_mounted_displays human_computer_interaction,47_elementary_school_children augmenting_reality different_interaction_preferences educational_hmd ar_environments elementary_school_classrooms gesture_recognition head mounted_display_augmented_reality_device head mounted_displays hmd ar_devices human_activity_recognition learning_applications microsoft s_hololens_2 multimodal_interaction prevailing_issue specific_interaction_modes system_usability well functioning_recognition,augmenting reality via head mounted display hmd ar emerging technology education interactivity provided hmd ar device particularly promising learning present challenge human activity recognition especially child recent technological advance regarding speech gesture recognition concerning microsoft hololens 2 may address prevailing issue within subject study 47 elementary school child 2nd 6th grade examined usability hololens 2 using standardized tutorial multimodal interaction ar overall system usability rated good however several behavioral metric indicated specific interaction mode differed efficiency result major importance development learning application hmd ar partially deviate previous finding particular well functioning recognition child voice command observed represents novelty furthermore found different interaction preference hmd ar among child also found use hmd ar positive effect child activity related achievement emotion overall finding serve basis determining general requirement possibility limitation implementation educational hmd ar environment elementary school classroom,computer_aided_instruction gesture_recognition handicapped_aids helmet_mounted_displays human_computer_interaction 47_elementary_school_children augmenting_reality different_interaction_preferences educational_hmd ar_environments elementary_school_classrooms gesture_recognition head mounted_display_augmented_reality_device head mounted_displays hmd ar_devices human_activity_recognition learning_applications microsoft s_hololens_2 multimodal_interaction prevailing_issue specific_interaction_modes system_usability well functioning_recognition c6180_user_interfaces c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7810c_computer aided_instruction input medical training display_technology human_factors wearables human computer_interaction augmenting reality via head mounted display hmd ar emerging technology education interactivity provided hmd ar device particularly promising learning present challenge human activity recognition especially child recent technological advance regarding speech gesture recognition concerning microsoft hololens 2 may address prevailing issue within subject study 47 elementary school child 2nd 6th grade examined usability hololens 2 using standardized tutorial multimodal interaction ar overall system usability rated good however several behavioral metric indicated specific interaction mode differed efficiency result major importance development learning application hmd ar partially deviate previous finding particular well functioning recognition child voice command observed represents novelty furthermore found different interaction preference hmd ar among child also found use hmd ar positive effect child activity related achievement emotion overall finding serve basis determining general requirement possibility limitation implementation educational hmd ar environment elementary school classroom,augmenting reality via head mounted display hmd ar emerging technology education interactivity provided hmd ar device particularly promising learning present challenge human activity recognition especially child recent technological advance regarding speech gesture recognition concerning microsoft hololens 2 may address prevailing issue within subject study 47 elementary school child 2nd 6th grade examined usability hololens 2 using standardized tutorial multimodal interaction ar overall system usability rated good however several behavioral metric indicated specific interaction mode differed efficiency result major importance development learning application hmd ar partially deviate previous finding particular well functioning recognition child voice command observed represents novelty furthermore found different interaction preference hmd ar among child also found use hmd ar positive effect child activity related achievement emotion overall finding serve basis determining general requirement possibility limitation implementation educational hmd ar environment elementary school classroomcomputer_aided_instruction gesture_recognition handicapped_aids helmet_mounted_displays human_computer_interaction47_elementary_school_children augmenting_reality different_interaction_preferences educational_hmd ar_environments elementary_school_classrooms gesture_recognition head mounted_display_augmented_reality_device head mounted_displays hmd ar_devices human_activity_recognition learning_applications microsoft s_hololens_2 multimodal_interaction prevailing_issue specific_interaction_modes system_usability well functioning_recognition
181,Smart Facility Management System Based on Open BIM and Augmented Reality Technology,"Chung, S., Cho, C.-S., Song, J., Lee, K., Lee, S., & Kwon, S. (2021). Smart Facility Management System Based on Open BIM and Augmented Reality Technology. Applied Sciences, 11(21), 10283. https://doi.org/10.3390/app112110283
",10.3390/app112110283,"With the wave of the Fourth Industrial Revolution, the construction industry is also witnessing the application of numerous state-of-the-art technologies. Among these, augmented reality (AR) technology has the advantage of utilizing existing 3D models and BIM data and is thus an area of active research. However, the main area of research to date has either been in visualizing information during the design phase, where architects and project stakeholders can share viewings, or in confirming the required information for construction management through visualization during the construction phase. As such, more research is required in the application of AR during the facility management (FM) phase. Research utilizing BIM in the FM phase, which constitutes the longest period during the lifecycle of a building, has been continuously carried out but has faced challenges with regard to on-site application. The reason for this is that information required for BIM during the design, construction and FM phases is different, and the reproduced information is vast, so identifying the required BIM data for FM and interfacing with other systems is difficult. As a measure to overcome this limitation, advanced countries such as the US and UK have developed and are using Construction Operations Building information exchange (COBie), which is an open-source BIM-based information exchange system. In order to effectively convert open-source BIM data to AR data, this research defined COBie data for windows and doors, converted them to a system and validated that it could actually be applied for on-site FM. The results of this system's creation and validation showed that the proposed AR-based smart FMS demonstrated faster and easier access to information compared with existing 2D blueprint-based FM work, while information obtained through AR allowed for immediate, more visual and easier means to express the information when integrated with actual objects.",C7440 Civil and mechanical engineering computing;C6130B Graphics techniques;C6130V Virtual reality;C7480 Production engineering computing;E0410D Industrial applications of IT;E0410H Mechanical engineering applications of IT;E1010 Production management;E2110B Building structures;E3030 Construction industry,2D blueprint-based FM work;AR data;augmented reality technology;building lifecycle;COBie data;construction industry;construction management;construction operations building information exchange;design phase;facility management phase;FM phase;fourth industrial revolution;on-site application;on-site FM;open BIM;open-source BIM data;open-source BIM-based information exchange system;project stakeholders;reproduced information;smart facility management system,augmented reality;buildings (structures);civil engineering computing;construction industry;facilities management;production engineering computing;project management;solid modelling;structural engineering computing,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Chung, S.; (2) Cho, C.-S.; (1) Song, J.; (1) Lee, K.; (1) Lee, S.; (3) Kwon, S.; ","(1) Sungkyunkwan University, Department of Convergence Engineering for Future City, Korea, Republic of; (2) Khalifa University, Department of Civil Infrastructure and Environmental Engineering, United Arab Emirates; (3) Sungkyunkwan University, School of Civil, Architectural Engineering & Landscape Architecture, Korea, Republic of; ",MDPI,-1,"[""buildings"", ""civil engineering computing"", ""construction industry"", ""facilities management"", ""production engineering computing"", ""project management"", ""solid modelling"", ""structural engineering computing""]","[""buildings"", ""civil engineering computing"", ""construction industry"", ""facilities management"", ""production engineering computing"", ""project management"", ""solid modelling"", ""structural engineering computing""]",buildings;civil engineering computing;construction industry;facilities management;production engineering computing;project management;solid modelling;structural engineering computing,construction;other;engineering;manufacturing;business planning and management,technology;other;business;industries,construction;other;engineering;manufacturing;business planning and management,technology;other;business;industries,buildings civil_engineering_computing construction_industry facilities_management production_engineering_computing project_management solid_modelling structural_engineering_computing 2d_blueprint based_fm_work ar_data augmented_reality_technology building_lifecycle cobie_data construction_industry construction_management construction_operations_building_information_exchange design_phase facility_management_phase fm_phase fourth_industrial_revolution on site_application on site_fm open_bim open source_bim_data open source_bim based_information_exchange_system project_stakeholders reproduced_information smart_facility_management_system c7440_civil_and_mechanical_engineering_computing c6130b_graphics_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it e0410h_mechanical_engineering_applications_of_it e1010_production_management e2110b_building_structures e3030_construction_industry construction other engineering manufacturing business_planning_and_management,buildings civil_engineering_computing construction_industry facilities_management production_engineering_computing project_management solid_modelling structural_engineering_computing,2d_blueprint based_fm_work ar_data augmented_reality_technology building_lifecycle cobie_data construction_industry construction_management construction_operations_building_information_exchange design_phase facility_management_phase fm_phase fourth_industrial_revolution on site_application on site_fm open_bim open source_bim_data open source_bim based_information_exchange_system project_stakeholders reproduced_information smart_facility_management_system,wave fourth industrial revolution construction industry also witnessing application numerous state art technology among augmented reality ar technology advantage utilizing existing 3d model bim data thus area active research however main area research date either visualizing information design phase architect project stakeholder share viewing confirming required information construction management visualization construction phase research required application ar facility management fm phase research utilizing bim fm phase constitutes longest period lifecycle building continuously carried faced challenge regard site application reason information required bim design construction fm phase different reproduced information vast identifying required bim data fm interfacing system difficult measure overcome limitation advanced country u uk developed using construction operation building information exchange cobie open source bim based information exchange system order effectively convert open source bim data ar data research defined cobie data window door converted system validated could actually applied site fm result system creation validation showed proposed ar based smart fm demonstrated faster easier access information compared existing 2d blueprint based fm work information obtained ar allowed immediate visual easier mean express information integrated actual object,buildings civil_engineering_computing construction_industry facilities_management production_engineering_computing project_management solid_modelling structural_engineering_computing 2d_blueprint based_fm_work ar_data augmented_reality_technology building_lifecycle cobie_data construction_industry construction_management construction_operations_building_information_exchange design_phase facility_management_phase fm_phase fourth_industrial_revolution on site_application on site_fm open_bim open source_bim_data open source_bim based_information_exchange_system project_stakeholders reproduced_information smart_facility_management_system c7440_civil_and_mechanical_engineering_computing c6130b_graphics_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it e0410h_mechanical_engineering_applications_of_it e1010_production_management e2110b_building_structures e3030_construction_industry construction other engineering manufacturing business_planning_and_management wave fourth industrial revolution construction industry also witnessing application numerous state art technology among augmented reality ar technology advantage utilizing existing 3d model bim data thus area active research however main area research date either visualizing information design phase architect project stakeholder share viewing confirming required information construction management visualization construction phase research required application ar facility management fm phase research utilizing bim fm phase constitutes longest period lifecycle building continuously carried faced challenge regard site application reason information required bim design construction fm phase different reproduced information vast identifying required bim data fm interfacing system difficult measure overcome limitation advanced country u uk developed using construction operation building information exchange cobie open source bim based information exchange system order effectively convert open source bim data ar data research defined cobie data window door converted system validated could actually applied site fm result system creation validation showed proposed ar based smart fm demonstrated faster easier access information compared existing 2d blueprint based fm work information obtained ar allowed immediate visual easier mean express information integrated actual object,wave fourth industrial revolution construction industry also witnessing application numerous state art technology among augmented reality ar technology advantage utilizing existing 3d model bim data thus area active research however main area research date either visualizing information design phase architect project stakeholder share viewing confirming required information construction management visualization construction phase research required application ar facility management fm phase research utilizing bim fm phase constitutes longest period lifecycle building continuously carried faced challenge regard site application reason information required bim design construction fm phase different reproduced information vast identifying required bim data fm interfacing system difficult measure overcome limitation advanced country u uk developed using construction operation building information exchange cobie open source bim based information exchange system order effectively convert open source bim data ar data research defined cobie data window door converted system validated could actually applied site fm result system creation validation showed proposed ar based smart fm demonstrated faster easier access information compared existing 2d blueprint based fm work information obtained ar allowed immediate visual easier mean express information integrated actual objectbuildings civil_engineering_computing construction_industry facilities_management production_engineering_computing project_management solid_modelling structural_engineering_computing2d_blueprint based_fm_work ar_data augmented_reality_technology building_lifecycle cobie_data construction_industry construction_management construction_operations_building_information_exchange design_phase facility_management_phase fm_phase fourth_industrial_revolution on site_application on site_fm open_bim open source_bim_data open source_bim based_information_exchange_system project_stakeholders reproduced_information smart_facility_management_system
182,OCOsense Glasses for Facial Expressions Recognition and Contextual Affective Computing in Real World and Augmented Reality,"Mavridou, I., Archer, J. A. W., Cleal, A., Fatoorechi, M., Stankoski, S., Kiprijanovska, I., Broulidakis, J., Gjoreski, M., Nduka, C., & Gjoreski, H. (2022). OCOsense Glasses for Facial Expressions Recognition and Contextual Affective Computing in Real World and Augmented Reality. Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3560325
",10.1145/3544793.3560325,"The paper presents the novel OCOSenseTM smart glasses with integrated sensors, primarily non-contact optomyographic (OMG) OCOTM sensors, 9-axis inertial measurement unit (IMU), and an altimeter. The glasses connect with a smartphone application, which facilitates the continuous and real-time measurements of facial-muscles activation and head movement, thus allowing for the detection of facial expressions and the activities of the user in real-time. We will demonstrate how the system is used in practice, i.e., a participant will wear the OCOSenseTM glasses, which will stream the sensor data to a tablet, where the real-time visualization of the sensor data and the data interpretation will be presented such as facial expressions (smile, frown, surprise) and activities. We believe that the OCOSenseTM glasses are the next big thing in wearables, which will allow for better understanding of the user's context, activities, emotional state, and more, which can be easily coupled within Augmented and Extended Reality environments.","B6135E Image recognition;B7230 Sensing devices and transducers;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",9-axis inertial measurement unit;Augmented;contextual affective computing;continuous time measurements;data interpretation;Extended Reality environments;facial expressions recognition;facial-muscles activation;head movement;integrated sensors;noncontact optomyographic OCOTM sensors;OCOsense glasses;OCOSenseTM glasses;OCOSenseTM smart glasses;real-time measurements;real-time visualization;sensor data;smartphone application,augmented reality;emotion recognition;face recognition;smart phones;virtual reality,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) Mavridou, I.; (2) Archer, J.A.W.; (2) Cleal, A.; (3) Fatoorechi, M.; (2) Stankoski, S.; (2) Kiprijanovska, I.; (2) Broulidakis, J.; (4) Gjoreski, M.; (2) Nduka, C.; (5) Gjoreski, H.; ","(1) University of Sussex, Research & Development, United Kingdom; (2) Emteq Ltd, United Kingdom; (3) EmteqLabs, United Kingdom; (4) Universita&#768; della Svizzera italiana, Faculty of Informatics, Switzerland; (5) Ss. Cyril and Methodius University in Skopje; ",ACM,-1,"[""emotion recognition"", ""face recognition"", ""smartphones""]","[""emotion recognition"", ""face recognition"", ""smartphones""]",emotion recognition;face recognition;smartphones,human factors;telecommunication;liberal arts;input,technology;industries;end users and user experience,human factors;telecommunication;liberal arts;input,technology;industries;end users and user experience,emotion_recognition face_recognition smartphones 9 axis_inertial_measurement_unit augmented contextual_affective_computing continuous_time_measurements data_interpretation extended_reality_environments facial_expressions_recognition facial muscles_activation head_movement integrated_sensors noncontact_optomyographic_ocotm_sensors ocosense_glasses ocosensetm_glasses ocosensetm_smart_glasses real time_measurements real time_visualization sensor_data smartphone_application b6135e_image_recognition b7230_sensing_devices_and_transducers c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication liberal_arts input,emotion_recognition face_recognition smartphones,9 axis_inertial_measurement_unit augmented contextual_affective_computing continuous_time_measurements data_interpretation extended_reality_environments facial_expressions_recognition facial muscles_activation head_movement integrated_sensors noncontact_optomyographic_ocotm_sensors ocosense_glasses ocosensetm_glasses ocosensetm_smart_glasses real time_measurements real time_visualization sensor_data smartphone_application,paper present novel ocosensetm smart glass integrated sensor primarily non contact optomyographic omg ocotm sensor 9 axis inertial measurement unit imu altimeter glass connect smartphone application facilitates continuous real time measurement facial muscle activation head movement thus allowing detection facial expression activity user real time demonstrate system used practice e participant wear ocosensetm glass stream sensor data tablet real time visualization sensor data data interpretation presented facial expression smile frown surprise activity believe ocosensetm glass next big thing wearable allow better understanding user context activity emotional state easily coupled within augmented extended reality environment,emotion_recognition face_recognition smartphones 9 axis_inertial_measurement_unit augmented contextual_affective_computing continuous_time_measurements data_interpretation extended_reality_environments facial_expressions_recognition facial muscles_activation head_movement integrated_sensors noncontact_optomyographic_ocotm_sensors ocosense_glasses ocosensetm_glasses ocosensetm_smart_glasses real time_measurements real time_visualization sensor_data smartphone_application b6135e_image_recognition b7230_sensing_devices_and_transducers c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing human_factors telecommunication liberal_arts input paper present novel ocosensetm smart glass integrated sensor primarily non contact optomyographic omg ocotm sensor 9 axis inertial measurement unit imu altimeter glass connect smartphone application facilitates continuous real time measurement facial muscle activation head movement thus allowing detection facial expression activity user real time demonstrate system used practice e participant wear ocosensetm glass stream sensor data tablet real time visualization sensor data data interpretation presented facial expression smile frown surprise activity believe ocosensetm glass next big thing wearable allow better understanding user context activity emotional state easily coupled within augmented extended reality environment,paper present novel ocosensetm smart glass integrated sensor primarily non contact optomyographic omg ocotm sensor 9 axis inertial measurement unit imu altimeter glass connect smartphone application facilitates continuous real time measurement facial muscle activation head movement thus allowing detection facial expression activity user real time demonstrate system used practice e participant wear ocosensetm glass stream sensor data tablet real time visualization sensor data data interpretation presented facial expression smile frown surprise activity believe ocosensetm glass next big thing wearable allow better understanding user context activity emotional state easily coupled within augmented extended reality environmentemotion_recognition face_recognition smartphones9 axis_inertial_measurement_unit augmented contextual_affective_computing continuous_time_measurements data_interpretation extended_reality_environments facial_expressions_recognition facial muscles_activation head_movement integrated_sensors noncontact_optomyographic_ocotm_sensors ocosense_glasses ocosensetm_glasses ocosensetm_smart_glasses real time_measurements real time_visualization sensor_data smartphone_application
183,Prevalence of oculomotor changes following the near work in stereoscopic augmented reality,"Zizlane, K., Alksnis, R., & Pladere, T. (2023). Prevalence of oculomotor changes following the near work in stereoscopic augmented reality. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2668376
",10.1117/12.2668376,"Extended reality human factors studies commonly utilize an approach in which group behavior is reported. This possibly masks the true prevalence of oculomotor changes that appear in response to stereoscopic augmented reality. Thus, the study aimed to elucidate the prevalence, direction, and magnitude of oculomotor changes after the near work in stereoscopic augmented reality. The task of fifty-three subjects (18-28 years old, normal visual acuity, no vision complaints) was to type the text displayed at 60 cm as accurately and quickly as possible. Each subject participated in two sessions &ndash; the text was displayed in stereoscopic augmented reality and on the computer screen. Clinical assessments of visual parameters were performed before and immediately after 30 minutes of the task. As a result, individual variations were found in the magnitude and direction of oculomotor changes after the near work. After the use of stereoscopic augmented reality, adverse changes in vergence and accommodation were observed in about 40% of the group. Despite the prevalence of adverse oculomotor changes being similar in the case of text displayed on the computer screen, only less than 20% of the group showed a decline of visual parameters in both viewing conditions. The exploratory study highlights the necessity to consider individual variations in visual responses and identify groups that might benefit or be disadvantaged in using stereoscopic augmented reality technologies. &copy; 2023 SPIE.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing",Accommodation;Clinical assessments;Computer screens;Group behavior;Human factor studies;Near work;Phoria;Stereoscopic image;Vergences;Visual acuity,Stereo image processing,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zizlane, Kristiana; (1) Alksnis, Reinis; (1) Pladere, Tatjana; ","(1) Department of Optometry and Vision Science, Faculty of Physics, Mathematics and Optometry, University of Latvia, Riga, Latvia; ",SPIE,-1,"[""stereo image processing""]","[""stereo image processing""]",stereo image processing,computer vision;data,technology,computer vision;data,technology,stereo_image_processing accommodation clinical_assessments computer_screens group_behavior human_factor_studies near_work phoria stereoscopic_image vergences visual_acuity 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing computer_vision data,stereo_image_processing,accommodation clinical_assessments computer_screens group_behavior human_factor_studies near_work phoria stereoscopic_image vergences visual_acuity,extended reality human factor study commonly utilize approach group behavior reported possibly mask true prevalence oculomotor change appear response stereoscopic augmented reality thus study aimed elucidate prevalence direction magnitude oculomotor change near work stereoscopic augmented reality task fifty three subject 18 28 year old normal visual acuity vision complaint type text displayed 60 cm accurately quickly possible subject participated two session ndash text displayed stereoscopic augmented reality computer screen clinical assessment visual parameter performed immediately 30 minute task result individual variation found magnitude direction oculomotor change near work use stereoscopic augmented reality adverse change vergence accommodation observed 40 group despite prevalence adverse oculomotor change similar case text displayed computer screen le 20 group showed decline visual parameter viewing condition exploratory study highlight necessity consider individual variation visual response identify group might benefit disadvantaged using stereoscopic augmented reality technology copy 2023 spie,stereo_image_processing accommodation clinical_assessments computer_screens group_behavior human_factor_studies near_work phoria stereoscopic_image vergences visual_acuity 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing computer_vision data extended reality human factor study commonly utilize approach group behavior reported possibly mask true prevalence oculomotor change appear response stereoscopic augmented reality thus study aimed elucidate prevalence direction magnitude oculomotor change near work stereoscopic augmented reality task fifty three subject 18 28 year old normal visual acuity vision complaint type text displayed 60 cm accurately quickly possible subject participated two session ndash text displayed stereoscopic augmented reality computer screen clinical assessment visual parameter performed immediately 30 minute task result individual variation found magnitude direction oculomotor change near work use stereoscopic augmented reality adverse change vergence accommodation observed 40 group despite prevalence adverse oculomotor change similar case text displayed computer screen le 20 group showed decline visual parameter viewing condition exploratory study highlight necessity consider individual variation visual response identify group might benefit disadvantaged using stereoscopic augmented reality technology copy 2023 spie,extended reality human factor study commonly utilize approach group behavior reported possibly mask true prevalence oculomotor change appear response stereoscopic augmented reality thus study aimed elucidate prevalence direction magnitude oculomotor change near work stereoscopic augmented reality task fifty three subject 18 28 year old normal visual acuity vision complaint type text displayed 60 cm accurately quickly possible subject participated two session ndash text displayed stereoscopic augmented reality computer screen clinical assessment visual parameter performed immediately 30 minute task result individual variation found magnitude direction oculomotor change near work use stereoscopic augmented reality adverse change vergence accommodation observed 40 group despite prevalence adverse oculomotor change similar case text displayed computer screen le 20 group showed decline visual parameter viewing condition exploratory study highlight necessity consider individual variation visual response identify group might benefit disadvantaged using stereoscopic augmented reality technology copy 2023 spiestereo_image_processingaccommodation clinical_assessments computer_screens group_behavior human_factor_studies near_work phoria stereoscopic_image vergences visual_acuity
184,The ARETE Ecosystem for&nbsp;the&nbsp;Creation and&nbsp;Delivery of&nbsp;Open Augmented Reality Educational Resources: The PBIS Case Study,"Farella, M., Arrigo, M., Tosto, C., Seta, L., Chifari, A., Mangina, E., Psyrra, G., Domínguez, A., Pacho, G., Wild, F., Bowers, L., Hillman, R., Goei, S. L., Denaro, P., Dhrami, D., & Chiazzese, G. (2023). The ARETE Ecosystem for the Creation and Delivery of Open Augmented Reality Educational Resources: The PBIS Case Study. Communications in Computer and Information Science, 760–775. https://doi.org/10.1007/978-3-031-29800-4_57
",10.1007/978-3-031-29800-4_57,"Augmented reality (AR) is rapidly emerging as an increasingly useful technology in educational settings. In the ARETE (Augmented Reality Interactive Educational System) H2020 project, consortium members designed and implemented an ecosystem aimed at supporting teachers in building a collaborative learning environment through the use of AR in order to improve educational experiences. In particular, one of the pilot projects aims to introduce AR into school behavior lessons for the first time, leveraging the Positive Behaviour Intervention and Support (PBIS) methodology. Specifically, in this paper we will discuss the proposed architecture within the ARETE project that incorporates AR technology into the learning process of behavior lessons to support the teaching, practice and reinforcement phases of expected behaviors. Through the combination of different technologies and systems, it is possible to create an example of a technological and innovative ecosystem designed for creating behavioral lessons in AR. &copy; 2023, The Author(s).","454.3 Ecology and Ecosystems;723 Computer Software, Data Handling and Applications;723.5 Computer Applications;901.2 Education",Behavioral learning;Case-studies;Consortium members;Educational resource;Educational settings;Educational systems;Multi-user applications;Positive behavior;Positive behavior intervention and support;Teachers',Computer aided instruction;Ecosystems;Engineering education;Learning systems,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Farella, Mariella; (1) Arrigo, Marco; (1) Tosto, Crispino; (1) Seta, Luciano; (1) Chifari, Antonella; (2) Mangina, Eleni; (2) Psyrra, Georgia; (3) Dom&iacute;nguez, Ana; (3) Pacho, Guillermo; (4) Wild, Fridolin; (4) Bowers, Lisa; (4) Hillman, Robert; (5) Goei, Sui Lin; (1) Denaro, Paola; (1) Dhrami, Doriana; (1) Chiazzese, Giuseppe; ","(1) Institute for Educational Technology - National Research Council of Italy, Palermo, Italy; (2) School of Computer Science, University College Dublin, Dublin, Ireland; (3) Vicomtech Foundation, Basque Research and Technology Alliance (BRTA), San Sebasti&aacute;n, Spain; (4) Institute of Educational Technology, The Open University, Milton Keynes, United Kingdom; (5) Faculty of Behavioural and Movement Sciences, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; ",Springer Science and Business Media Deutschland GmbH,-1,"[""computer aided instruction"", ""ecosystems"", ""engineering education"", ""learning systems""]","[""computer aided instruction"", ""ecosystems"", ""engineering education"", ""learning systems""]",computer aided instruction;ecosystems;engineering education;learning systems,medical;education;farming and natural science;training,use cases;industries,medical;education;farming and natural science;training,use cases;industries,computer_aided_instruction ecosystems engineering_education learning_systems behavioral_learning case studies consortium_members educational_resource educational_settings educational_systems multi user_applications positive_behavior positive_behavior_intervention_and_support teachers 454 3_ecology_and_ecosystems 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education medical education farming_and_natural_science training,computer_aided_instruction ecosystems engineering_education learning_systems,behavioral_learning case studies consortium_members educational_resource educational_settings educational_systems multi user_applications positive_behavior positive_behavior_intervention_and_support teachers,augmented reality ar rapidly emerging increasingly useful technology educational setting arete augmented reality interactive educational system h2020 project consortium member designed implemented ecosystem aimed supporting teacher building collaborative learning environment use ar order improve educational experience particular one pilot project aim introduce ar school behavior lesson first time leveraging positive behaviour intervention support pbis methodology specifically paper discus proposed architecture within arete project incorporates ar technology learning process behavior lesson support teaching practice reinforcement phase expected behavior combination different technology system possible create example technological innovative ecosystem designed creating behavioral lesson ar copy 2023 author,computer_aided_instruction ecosystems engineering_education learning_systems behavioral_learning case studies consortium_members educational_resource educational_settings educational_systems multi user_applications positive_behavior positive_behavior_intervention_and_support teachers 454 3_ecology_and_ecosystems 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education medical education farming_and_natural_science training augmented reality ar rapidly emerging increasingly useful technology educational setting arete augmented reality interactive educational system h2020 project consortium member designed implemented ecosystem aimed supporting teacher building collaborative learning environment use ar order improve educational experience particular one pilot project aim introduce ar school behavior lesson first time leveraging positive behaviour intervention support pbis methodology specifically paper discus proposed architecture within arete project incorporates ar technology learning process behavior lesson support teaching practice reinforcement phase expected behavior combination different technology system possible create example technological innovative ecosystem designed creating behavioral lesson ar copy 2023 author,augmented reality ar rapidly emerging increasingly useful technology educational setting arete augmented reality interactive educational system h2020 project consortium member designed implemented ecosystem aimed supporting teacher building collaborative learning environment use ar order improve educational experience particular one pilot project aim introduce ar school behavior lesson first time leveraging positive behaviour intervention support pbis methodology specifically paper discus proposed architecture within arete project incorporates ar technology learning process behavior lesson support teaching practice reinforcement phase expected behavior combination different technology system possible create example technological innovative ecosystem designed creating behavioral lesson ar copy 2023 authorcomputer_aided_instruction ecosystems engineering_education learning_systemsbehavioral_learning case studies consortium_members educational_resource educational_settings educational_systems multi user_applications positive_behavior positive_behavior_intervention_and_support teachers
185,Design and Validation of an Augmented Reality Teaching System for Primary Logic Programming Education,"Tsai, C.-Y., & Lai, Y.-C. (2022). Design and Validation of an Augmented Reality Teaching System for Primary Logic Programming Education. Sensors, 22(1), 389. https://doi.org/10.3390/s22010389
",10.3390/s22010389,"Programming is a skill that requires high levels of logical thinking and problem-solving abilities. According to the Curriculum Guidelines for the 12-Year Basic Education currently implemented in Taiwan, programming has been included in the mandatory courses of middle and high schools. Nevertheless, the guidelines simply recommend that elementary schools conduct fundamental instructions in related fields during alternative learning periods. This may result in the problem of a rough transition in programming learning for middle school freshmen. To alleviate this problem, this study proposes an augmented reality (AR) logic programming teaching system that combines AR technologies and game-based teaching material designs on the basis of the fundamental concepts for seventh-grade structured programming. This system can serve as an articulation curriculum for logic programming in primary education. Thus, students are able to develop basic programming logic concepts through AR technologies by performing simple command programming. This study conducted an experiment using the factor-based quasi-experimental research design and questionnaire survey method, with 42 fifth and sixth graders enrolled as the experimental subjects. The statistical analysis showed the following results: In terms of learning effectiveness, both AR-based and traditional learning groups displayed a significant performance. However, of the two groups, the former achieved more significant effectiveness in the posttest results. Regarding learning motivation, according to the evaluation results of the Attention, Relevance, Confidence, and Satisfaction (ARCS) motivation model, the AR-based learning group manifested significantly higher levels of learning motivation than the traditional learning group, with particularly significant differences observed in the dimension of Attention. Therefore, the experimental results validate that the proposed AR-based logic programming teaching system has significant positive effects on enhancing students' learning effectiveness and motivation.",C0220 Computing education and training;C1140Z Other topics in statistics;C6110L Logic programming;C6130V Virtual reality;C7810C Computer-aided instruction,"alternative learning periods;AR-based learning group;AR-based logic programming teaching system;ARCS;articulation curriculum;attention, relevance, confidence, and satisfaction motivation model;augmented reality logic programming teaching system;Basic Education;basic programming logic concepts;Curriculum Guidelines;elementary schools;factor-based quasiexperimental research design;fundamental instructions;game-based teaching material design;high schools;logical thinking;middle school freshmen;primary education;primary logic programming education;problem-solving abilities;programming learning;questionnaire survey method;seventh-grade structured programming;simple command programming;statistical analysis;Taiwan;traditional learning group",augmented reality;computer aided instruction;computer science education;design of experiments;educational courses;educational institutions;logic programming;statistical analysis;structured programming;teaching,2021,Journal article (JA),Sensors (Switzerland),"(1) Tsai, C.-Y.; (1) Lai, Y.-C.; ","(1) Tamkang University, New Taipei City 251, Taiwan; ",MDPI,-1,"[""computer aided instruction"", ""computer science education"", ""design of experiments"", ""educational courses"", ""educational institutions"", ""logic programming"", ""statistical analysis"", ""structured programming"", ""teaching""]","[""computer aided instruction"", ""computer science education"", ""design of experiments"", ""educational courses"", ""educational institutions"", ""logic programming"", ""statistical analysis"", ""structured programming"", ""teaching""]",computer aided instruction;computer science education;design of experiments;educational courses;educational institutions;logic programming;statistical analysis;structured programming;teaching,education;other;training;human factors;developers;data;human-computer interaction,other;end users and user experience;industries;use cases;technology,education;other;training;human factors;developers;data;human-computer interaction,other;end users and user experience;industries;use cases;technology,computer_aided_instruction computer_science_education design_of_experiments educational_courses educational_institutions logic_programming statistical_analysis structured_programming teaching alternative_learning_periods ar based_learning_group ar based_logic_programming_teaching_system arcs articulation_curriculum attention _relevance _confidence _and_satisfaction_motivation_model augmented_reality_logic_programming_teaching_system basic_education basic_programming_logic_concepts curriculum_guidelines elementary_schools factor based_quasiexperimental_research_design fundamental_instructions game based_teaching_material_design high_schools logical_thinking middle_school_freshmen primary_education primary_logic_programming_education problem solving_abilities programming_learning questionnaire_survey_method seventh grade_structured_programming simple_command_programming statistical_analysis taiwan traditional_learning_group c0220_computing_education_and_training c1140z_other_topics_in_statistics c6110l_logic_programming c6130v_virtual_reality c7810c_computer aided_instruction education other training human_factors developers data human computer_interaction,computer_aided_instruction computer_science_education design_of_experiments educational_courses educational_institutions logic_programming statistical_analysis structured_programming teaching,alternative_learning_periods ar based_learning_group ar based_logic_programming_teaching_system arcs articulation_curriculum attention _relevance _confidence _and_satisfaction_motivation_model augmented_reality_logic_programming_teaching_system basic_education basic_programming_logic_concepts curriculum_guidelines elementary_schools factor based_quasiexperimental_research_design fundamental_instructions game based_teaching_material_design high_schools logical_thinking middle_school_freshmen primary_education primary_logic_programming_education problem solving_abilities programming_learning questionnaire_survey_method seventh grade_structured_programming simple_command_programming statistical_analysis taiwan traditional_learning_group,programming skill requires high level logical thinking problem solving ability according curriculum guideline 12 year basic education currently implemented taiwan programming included mandatory course middle high school nevertheless guideline simply recommend elementary school conduct fundamental instruction related field alternative learning period may result problem rough transition programming learning middle school freshman alleviate problem study proposes augmented reality ar logic programming teaching system combine ar technology game based teaching material design basis fundamental concept seventh grade structured programming system serve articulation curriculum logic programming primary education thus student able develop basic programming logic concept ar technology performing simple command programming study conducted experiment using factor based quasi experimental research design questionnaire survey method 42 fifth sixth grader enrolled experimental subject statistical analysis showed following result term learning effectiveness ar based traditional learning group displayed significant performance however two group former achieved significant effectiveness posttest result regarding learning motivation according evaluation result attention relevance confidence satisfaction arc motivation model ar based learning group manifested significantly higher level learning motivation traditional learning group particularly significant difference observed dimension attention therefore experimental result validate proposed ar based logic programming teaching system significant positive effect enhancing student learning effectiveness motivation,computer_aided_instruction computer_science_education design_of_experiments educational_courses educational_institutions logic_programming statistical_analysis structured_programming teaching alternative_learning_periods ar based_learning_group ar based_logic_programming_teaching_system arcs articulation_curriculum attention _relevance _confidence _and_satisfaction_motivation_model augmented_reality_logic_programming_teaching_system basic_education basic_programming_logic_concepts curriculum_guidelines elementary_schools factor based_quasiexperimental_research_design fundamental_instructions game based_teaching_material_design high_schools logical_thinking middle_school_freshmen primary_education primary_logic_programming_education problem solving_abilities programming_learning questionnaire_survey_method seventh grade_structured_programming simple_command_programming statistical_analysis taiwan traditional_learning_group c0220_computing_education_and_training c1140z_other_topics_in_statistics c6110l_logic_programming c6130v_virtual_reality c7810c_computer aided_instruction education other training human_factors developers data human computer_interaction programming skill requires high level logical thinking problem solving ability according curriculum guideline 12 year basic education currently implemented taiwan programming included mandatory course middle high school nevertheless guideline simply recommend elementary school conduct fundamental instruction related field alternative learning period may result problem rough transition programming learning middle school freshman alleviate problem study proposes augmented reality ar logic programming teaching system combine ar technology game based teaching material design basis fundamental concept seventh grade structured programming system serve articulation curriculum logic programming primary education thus student able develop basic programming logic concept ar technology performing simple command programming study conducted experiment using factor based quasi experimental research design questionnaire survey method 42 fifth sixth grader enrolled experimental subject statistical analysis showed following result term learning effectiveness ar based traditional learning group displayed significant performance however two group former achieved significant effectiveness posttest result regarding learning motivation according evaluation result attention relevance confidence satisfaction arc motivation model ar based learning group manifested significantly higher level learning motivation traditional learning group particularly significant difference observed dimension attention therefore experimental result validate proposed ar based logic programming teaching system significant positive effect enhancing student learning effectiveness motivation,programming skill requires high level logical thinking problem solving ability according curriculum guideline 12 year basic education currently implemented taiwan programming included mandatory course middle high school nevertheless guideline simply recommend elementary school conduct fundamental instruction related field alternative learning period may result problem rough transition programming learning middle school freshman alleviate problem study proposes augmented reality ar logic programming teaching system combine ar technology game based teaching material design basis fundamental concept seventh grade structured programming system serve articulation curriculum logic programming primary education thus student able develop basic programming logic concept ar technology performing simple command programming study conducted experiment using factor based quasi experimental research design questionnaire survey method 42 fifth sixth grader enrolled experimental subject statistical analysis showed following result term learning effectiveness ar based traditional learning group displayed significant performance however two group former achieved significant effectiveness posttest result regarding learning motivation according evaluation result attention relevance confidence satisfaction arc motivation model ar based learning group manifested significantly higher level learning motivation traditional learning group particularly significant difference observed dimension attention therefore experimental result validate proposed ar based logic programming teaching system significant positive effect enhancing student learning effectiveness motivationcomputer_aided_instruction computer_science_education design_of_experiments educational_courses educational_institutions logic_programming statistical_analysis structured_programming teachingalternative_learning_periods ar based_learning_group ar based_logic_programming_teaching_system arcs articulation_curriculum attention _relevance _confidence _and_satisfaction_motivation_model augmented_reality_logic_programming_teaching_system basic_education basic_programming_logic_concepts curriculum_guidelines elementary_schools factor based_quasiexperimental_research_design fundamental_instructions game based_teaching_material_design high_schools logical_thinking middle_school_freshmen primary_education primary_logic_programming_education problem solving_abilities programming_learning questionnaire_survey_method seventh grade_structured_programming simple_command_programming statistical_analysis taiwan traditional_learning_group
186,Augmented Reality Based Surgical Navigation of Complex Pelvic Osteotomies-A Feasibility Study on Cadavers,"Ackermann, J., Liebmann, F., Hoch, A., Snedeker, J. G., Farshad, M., Rahm, S., Zingg, P. O., & Fürnstahl, P. (2021). Augmented Reality Based Surgical Navigation of Complex Pelvic Osteotomies—A Feasibility Study on Cadavers. Applied Sciences, 11(3), 1228. https://doi.org/10.3390/app11031228
",10.3390/app11031228,"Augmented reality (AR)-based surgical navigation may offer new possibilities for safe and accurate surgical execution of complex osteotomies. In this study we investigated the feasibility of navigating the periacetabular osteotomy of Ganz (PAO), known as one of the most complex orthopedic interventions, on two cadaveric pelves under realistic operating room conditions. Preoperative planning was conducted on computed tomography (CT)-reconstructed 3D models using an in-house developed software, which allowed creating cutting plane objects for planning of the osteotomies and reorientation of the acetabular fragment. An AR application was developed comprising point-based registration, motion compensation and guidance for osteotomies as well as fragment reorientation. Navigation accuracy was evaluated on CT-reconstructed 3D models, resulting in an error of 10.8 mm for osteotomy starting points and 5.4&#176; for osteotomy directions. The reorientation errors were 6.7&#176;, 7.0&#176; and 0.9&#176; for the x-, y- and z-axis, respectively. Average postoperative error of LCE angle was 4.5&#176;. Our study demonstrated that the AR-based execution of complex osteotomies is feasible. Fragment realignment navigation needs further improvement, although it is more accurate than the state of the art in PAO surgery.","A8760J X-rays and particle beams (medical uses);A8770E Patient diagnostic methods and instrumentation;A8770J Prosthetics and other practical applications;B6135 Optical, image and video signal processing;B7510P X-ray techniques: radiography and computed tomography (biomedical imaging/measurement);B7520E Prosthetics and orthotics;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C7330 Biology and medical computing",accurate surgical execution;acetabular fragment;augmented reality-based surgical navigation;cadaveric pelves;complex orthopedic interventions;complex osteotomies;complex pelvic osteotomies-a;computed tomography-reconstructed 3D models;CT-reconstructed 3D models;fragment realignment navigation;fragment reorientation;in-house developed software;osteotomy directions;periacetabular osteotomy;point-based registration;preoperative planning;realistic operating room conditions;reorientation errors;safe execution;size 10.8 mm,augmented reality;biomechanics;bone;computerised tomography;image reconstruction;image registration;medical image processing;motion compensation;orthopaedics;prosthetics;surgery,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Ackermann, J.; (1) Liebmann, F.; (3) Hoch, A.; (2) Snedeker, J.G.; (3) Farshad, M.; (3) Rahm, S.; (3) Zingg, P.O.; (1) Fu&#776;rnstahl, P.; ","(1) Balgrist University Hospital, Research in Orthopedic Computer Science, Switzerland; (2) ETH Zurich, Laboratory for Orthopaedic Biomechanics, Switzerland; (3) University of Zurich, Department of Orthopedics, Switzerland; ",MDPI,-1,"[""biomechanics"", ""bone"", ""computerized tomography"", ""image reconstruction"", ""image registration"", ""medical image processing"", ""motion compensation"", ""orthopedics"", ""prosthetics"", ""surgery""]","[""biomechanics"", ""bone"", ""computerized tomography"", ""image reconstruction"", ""image registration"", ""medical image processing"", ""motion compensation"", ""orthopedics"", ""prosthetics"", ""surgery""]",biomechanics;bone;computerized tomography;image reconstruction;image registration;medical image processing;motion compensation;orthopedics;prosthetics;surgery,construction;computer vision;other;medical;data;artificial intelligence,technology;other;industries,construction;computer vision;other;medical;data;artificial intelligence,technology;other;industries,biomechanics bone computerized_tomography image_reconstruction image_registration medical_image_processing motion_compensation orthopedics prosthetics surgery accurate_surgical_execution acetabular_fragment augmented_reality based_surgical_navigation cadaveric_pelves complex_orthopedic_interventions complex_osteotomies complex_pelvic_osteotomies a computed_tomography reconstructed_3d_models ct reconstructed_3d_models fragment_realignment_navigation fragment_reorientation in house_developed_software osteotomy_directions periacetabular_osteotomy point based_registration preoperative_planning realistic_operating_room_conditions reorientation_errors safe_execution size_10 8_mm a8760j_x rays_and_particle_beams_ medical_uses a8770e_patient_diagnostic_methods_and_instrumentation a8770j_prosthetics_and_other_practical_applications b6135_optical _image_and_video_signal_processing b7510p_x ray_techniques _radiography_and_computed_tomography_ biomedical_imaging measurement b7520e_prosthetics_and_orthotics c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing construction computer_vision other medical data artificial_intelligence,biomechanics bone computerized_tomography image_reconstruction image_registration medical_image_processing motion_compensation orthopedics prosthetics surgery,accurate_surgical_execution acetabular_fragment augmented_reality based_surgical_navigation cadaveric_pelves complex_orthopedic_interventions complex_osteotomies complex_pelvic_osteotomies a computed_tomography reconstructed_3d_models ct reconstructed_3d_models fragment_realignment_navigation fragment_reorientation in house_developed_software osteotomy_directions periacetabular_osteotomy point based_registration preoperative_planning realistic_operating_room_conditions reorientation_errors safe_execution size_10 8_mm,augmented reality ar based surgical navigation may offer new possibility safe accurate surgical execution complex osteotomy study investigated feasibility navigating periacetabular osteotomy ganz pao known one complex orthopedic intervention two cadaveric pelvis realistic operating room condition preoperative planning conducted computed tomography ct reconstructed 3d model using house developed software allowed creating cutting plane object planning osteotomy reorientation acetabular fragment ar application developed comprising point based registration motion compensation guidance osteotomy well fragment reorientation navigation accuracy evaluated ct reconstructed 3d model resulting error 10 8 mm osteotomy starting point 5 4 176 osteotomy direction reorientation error 6 7 176 7 0 176 0 9 176 x z axis respectively average postoperative error lce angle 4 5 176 study demonstrated ar based execution complex osteotomy feasible fragment realignment navigation need improvement although accurate state art pao surgery,biomechanics bone computerized_tomography image_reconstruction image_registration medical_image_processing motion_compensation orthopedics prosthetics surgery accurate_surgical_execution acetabular_fragment augmented_reality based_surgical_navigation cadaveric_pelves complex_orthopedic_interventions complex_osteotomies complex_pelvic_osteotomies a computed_tomography reconstructed_3d_models ct reconstructed_3d_models fragment_realignment_navigation fragment_reorientation in house_developed_software osteotomy_directions periacetabular_osteotomy point based_registration preoperative_planning realistic_operating_room_conditions reorientation_errors safe_execution size_10 8_mm a8760j_x rays_and_particle_beams_ medical_uses a8770e_patient_diagnostic_methods_and_instrumentation a8770j_prosthetics_and_other_practical_applications b6135_optical _image_and_video_signal_processing b7510p_x ray_techniques _radiography_and_computed_tomography_ biomedical_imaging measurement b7520e_prosthetics_and_orthotics c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing construction computer_vision other medical data artificial_intelligence augmented reality ar based surgical navigation may offer new possibility safe accurate surgical execution complex osteotomy study investigated feasibility navigating periacetabular osteotomy ganz pao known one complex orthopedic intervention two cadaveric pelvis realistic operating room condition preoperative planning conducted computed tomography ct reconstructed 3d model using house developed software allowed creating cutting plane object planning osteotomy reorientation acetabular fragment ar application developed comprising point based registration motion compensation guidance osteotomy well fragment reorientation navigation accuracy evaluated ct reconstructed 3d model resulting error 10 8 mm osteotomy starting point 5 4 176 osteotomy direction reorientation error 6 7 176 7 0 176 0 9 176 x z axis respectively average postoperative error lce angle 4 5 176 study demonstrated ar based execution complex osteotomy feasible fragment realignment navigation need improvement although accurate state art pao surgery,augmented reality ar based surgical navigation may offer new possibility safe accurate surgical execution complex osteotomy study investigated feasibility navigating periacetabular osteotomy ganz pao known one complex orthopedic intervention two cadaveric pelvis realistic operating room condition preoperative planning conducted computed tomography ct reconstructed 3d model using house developed software allowed creating cutting plane object planning osteotomy reorientation acetabular fragment ar application developed comprising point based registration motion compensation guidance osteotomy well fragment reorientation navigation accuracy evaluated ct reconstructed 3d model resulting error 10 8 mm osteotomy starting point 5 4 176 osteotomy direction reorientation error 6 7 176 7 0 176 0 9 176 x z axis respectively average postoperative error lce angle 4 5 176 study demonstrated ar based execution complex osteotomy feasible fragment realignment navigation need improvement although accurate state art pao surgerybiomechanics bone computerized_tomography image_reconstruction image_registration medical_image_processing motion_compensation orthopedics prosthetics surgeryaccurate_surgical_execution acetabular_fragment augmented_reality based_surgical_navigation cadaveric_pelves complex_orthopedic_interventions complex_osteotomies complex_pelvic_osteotomies a computed_tomography reconstructed_3d_models ct reconstructed_3d_models fragment_realignment_navigation fragment_reorientation in house_developed_software osteotomy_directions periacetabular_osteotomy point based_registration preoperative_planning realistic_operating_room_conditions reorientation_errors safe_execution size_10 8_mm
187,Perception of Virtual Agents as Communicators in Virtual vs. Augmented Reality by a Male Sample,"Serafini, M., & Chittaro, L. (2023). Perception of Virtual Agents as Communicators in Virtual vs. Augmented Reality by a Male Sample. Lecture Notes in Computer Science, 36–49. https://doi.org/10.1007/978-3-031-30933-5_3
",10.1007/978-3-031-30933-5_3,"Virtual agents are often employed in persuasive applications, and different studies in the literature have shown that the gender of the agent may have an impact on how users perceive the agent as a communicator. This paper adds a new variable to this line of research, considering the possible effects of presenting the agent in Virtual Reality (VR) vs. Augmented Reality (AR). We measured attentional allocation, perceived affective understanding, speaker credibility and speaker strength. While attentional allocation was the same in all conditions, an interesting pattern emerged for the other variables. The transition from VR to AR apparently changed the perception of some communicator aspects to the advantage of the female virtual agent. We also found associations between participants&rsquo; personality traits (in particular, extraversion) and perception of the agent. The paper describes and discusses these findings. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications",Communicator;Condition;Personality traits;Persuasive applications;Virtual agent,Virtual reality,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) Serafini, Marta; (1) Chittaro, Luca; ","(1) HCI Lab, Department of Mathematics, Computer Science and Physics, University of Udine, via delle Scienze 206, Udine; 33100, Italy; ",Springer Science and Business Media Deutschland GmbH,-1,[],[],other,other,other,other,other,other communicator condition personality_traits persuasive_applications virtual_agent 723_computer_software _data_handling_and_applications other,other,communicator condition personality_traits persuasive_applications virtual_agent,virtual agent often employed persuasive application different study literature shown gender agent may impact user perceive agent communicator paper add new variable line research considering possible effect presenting agent virtual reality vr v augmented reality ar measured attentional allocation perceived affective understanding speaker credibility speaker strength attentional allocation condition interesting pattern emerged variable transition vr ar apparently changed perception communicator aspect advantage female virtual agent also found association participant rsquo personality trait particular extraversion perception agent paper describes discus finding copy 2023 author exclusive license springer nature switzerland ag,other communicator condition personality_traits persuasive_applications virtual_agent 723_computer_software _data_handling_and_applications other virtual agent often employed persuasive application different study literature shown gender agent may impact user perceive agent communicator paper add new variable line research considering possible effect presenting agent virtual reality vr v augmented reality ar measured attentional allocation perceived affective understanding speaker credibility speaker strength attentional allocation condition interesting pattern emerged variable transition vr ar apparently changed perception communicator aspect advantage female virtual agent also found association participant rsquo personality trait particular extraversion perception agent paper describes discus finding copy 2023 author exclusive license springer nature switzerland ag,virtual agent often employed persuasive application different study literature shown gender agent may impact user perceive agent communicator paper add new variable line research considering possible effect presenting agent virtual reality vr v augmented reality ar measured attentional allocation perceived affective understanding speaker credibility speaker strength attentional allocation condition interesting pattern emerged variable transition vr ar apparently changed perception communicator aspect advantage female virtual agent also found association participant rsquo personality trait particular extraversion perception agent paper describes discus finding copy 2023 author exclusive license springer nature switzerland agothercommunicator condition personality_traits persuasive_applications virtual_agent
188,Combining Augmented Reality and Fairy Tales to Teach Science to Primary School Students: Teachers&rsquo; Experience from the Fairy Tale Science Augmented (FAnTASIA) Project,"Chiazzese, G., Tosto, C., Seta, L., Chifari, A., Denaro, P., Dhrami, D., La Guardia, D., Arrigo, M., Farella, M., Ioannides, C., Yegorina, D., & Mangina, E. (2023). Combining Augmented Reality and Fairy Tales to Teach Science to Primary School Students: Teachers’ Experience from the Fairy Tale Science Augmented (FAnTASIA) Project. Communications in Computer and Information Science, 706–718. https://doi.org/10.1007/978-3-031-29800-4_53
",10.1007/978-3-031-29800-4_53,"The use of storytelling has long been covering a wide variety of subjects across different levels of education, from preschool and K12 to professional training. Regardless of the content being taught, storytelling methods are assumed to catch students&rsquo; attention and involve both their cognitive and affective skills. Educational literature has also collected evidence for effectiveness of the use of augmented reality (AR) technology in promoting greater academic achievement and engagement among students, com-pared with traditional and other digital media-related lessons. Based on existing research, aim of the Fairy Tale Science Augmented (FAnTASIA) project was to design a multi-lingual educational package to integrate storytelling and AR to support the teaching of science concepts and skills in children aged from 5 to 12&nbsp;years. The present paper first provides a description of the FAnTASIA project and the developed educational package. Following, the paper presents the research design implemented to evaluate the effectiveness of the package in promoting children&rsquo;s knowledge and cognitive skills and users&rsquo; (students and teachers) satisfaction with its use. In this regard, the final section describes teachers&rsquo; experience with the use of the educational kit from the results of a questionnaire specifically administered to this purpose. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","722.1 Data Storage, Equipment and Techniques;723 Computer Software, Data Handling and Applications;912.4 Personnel",Educational fairy tale;Fairy tales;Primary education;Primary schools;School students;Science teaching;Scientific skills;Storytelling;Student teachers;Teachers',Digital storage;Personnel training;Students,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Chiazzese, Giuseppe; (1) Tosto, Crispino; (1) Seta, Luciano; (1) Chifari, Antonella; (1) Denaro, Paola; (1) Dhrami, Doriana; (1) La Guardia, Dario; (1) Arrigo, Marco; (1) Farella, Mariella; (2) Ioannides, Christos; (3) Yegorina, Darya; (4) Mangina, Eleni; ","(1) Istituto per le Tecnologie Didattiche, Consiglio Nazionale delle Ricerche, Palermo; 90146, Italy; (2) Department of Primary Education, University of the Aegean, Rhodes; 85132, Greece; (3) CleverBooks Limited, Dublin, Ireland; (4) School of Computer Science, University College Dublin, Dublin; 04 V1W8, Ireland; ",Springer Science and Business Media Deutschland GmbH,-1,"[""digital storage"", ""personnel training"", ""students""]","[""digital storage"", ""personnel training"", ""students""]",digital storage;personnel training;students,farming and natural science;training;users;human resources;networks,business;end users and user experience;industries;use cases;technology,farming and natural science;training;users;human resources;networks,business;end users and user experience;industries;use cases;technology,digital_storage personnel_training students educational_fairy_tale fairy_tales primary_education primary_schools school_students science_teaching scientific_skills storytelling student_teachers teachers 722 1_data_storage _equipment_and_techniques 723_computer_software _data_handling_and_applications 912 4_personnel farming_and_natural_science training users human_resources networks,digital_storage personnel_training students,educational_fairy_tale fairy_tales primary_education primary_schools school_students science_teaching scientific_skills storytelling student_teachers teachers,use storytelling long covering wide variety subject across different level education preschool k12 professional training regardless content taught storytelling method assumed catch student rsquo attention involve cognitive affective skill educational literature also collected evidence effectiveness use augmented reality ar technology promoting greater academic achievement engagement among student com pared traditional digital medium related lesson based existing research aim fairy tale science augmented fantasia project design multi lingual educational package integrate storytelling ar support teaching science concept skill child aged 5 12 nbsp year present paper first provides description fantasia project developed educational package following paper present research design implemented evaluate effectiveness package promoting child rsquo knowledge cognitive skill user rsquo student teacher satisfaction use regard final section describes teacher rsquo experience use educational kit result questionnaire specifically administered purpose copy 2023 author exclusive license springer nature switzerland ag,digital_storage personnel_training students educational_fairy_tale fairy_tales primary_education primary_schools school_students science_teaching scientific_skills storytelling student_teachers teachers 722 1_data_storage _equipment_and_techniques 723_computer_software _data_handling_and_applications 912 4_personnel farming_and_natural_science training users human_resources networks use storytelling long covering wide variety subject across different level education preschool k12 professional training regardless content taught storytelling method assumed catch student rsquo attention involve cognitive affective skill educational literature also collected evidence effectiveness use augmented reality ar technology promoting greater academic achievement engagement among student com pared traditional digital medium related lesson based existing research aim fairy tale science augmented fantasia project design multi lingual educational package integrate storytelling ar support teaching science concept skill child aged 5 12 nbsp year present paper first provides description fantasia project developed educational package following paper present research design implemented evaluate effectiveness package promoting child rsquo knowledge cognitive skill user rsquo student teacher satisfaction use regard final section describes teacher rsquo experience use educational kit result questionnaire specifically administered purpose copy 2023 author exclusive license springer nature switzerland ag,use storytelling long covering wide variety subject across different level education preschool k12 professional training regardless content taught storytelling method assumed catch student rsquo attention involve cognitive affective skill educational literature also collected evidence effectiveness use augmented reality ar technology promoting greater academic achievement engagement among student com pared traditional digital medium related lesson based existing research aim fairy tale science augmented fantasia project design multi lingual educational package integrate storytelling ar support teaching science concept skill child aged 5 12 nbsp year present paper first provides description fantasia project developed educational package following paper present research design implemented evaluate effectiveness package promoting child rsquo knowledge cognitive skill user rsquo student teacher satisfaction use regard final section describes teacher rsquo experience use educational kit result questionnaire specifically administered purpose copy 2023 author exclusive license springer nature switzerland agdigital_storage personnel_training studentseducational_fairy_tale fairy_tales primary_education primary_schools school_students science_teaching scientific_skills storytelling student_teachers teachers
189,Non-overlayed Guidance in&nbsp;Augmented Reality: User Study in&nbsp;Radio-Pharmacy,"Simmen, Y., Eggler, T., Legath, A., Agotai, D., & Cords, H. (2023). Non-overlayed Guidance in Augmented Reality: User Study in Radio-Pharmacy. Lecture Notes in Computer Science, 516–526. https://doi.org/10.1007/978-3-031-27199-1_52
",10.1007/978-3-031-27199-1_52,"In many traditional industries, production instructions are usually provided on paper. Past research has shown the effectiveness of Augmented Reality (AR) for virtual user guidance in various cases. Usually, the main focus lies on 3D overlays and spatially anchored tokens to guide the user. Unfortunately, tracking small and moving objects is not always feasible in highly dynamic or complex environments. Additionally, the setup of anchors, 3D models and guidance procedures is often time-consuming and problem-specific. This study addresses such scenarios and provides empirical results of AR user guidance without employing overlays or object tracking. Therefore, we developed two AR concepts that guide the user using either 2D illustrations or 3D models. For evaluation, we designed a user study in the field of radio-pharmaceuticals, assessing quantitative measurements, usability and cognitive load. The conducted user study indicates that AR can also improve the effectiveness of user guidance in scenarios where direct 3D overlays or object tracking approaches are not feasible. The presented 2D and 3D AR concepts performed similarly, while both lead to fewer errors, faster execution time, and lower cognitive load than the paper instructions. Therefore, to reduce the effort required to create 3D instructions, the use of 2D illustrations could often be the more efficient choice. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications",3D models;3d-modeling;Assembly guidance;Assistive system;Manual assembly;Task guidance;User guidance;User interaction;User study;Wearable devices,Tracking (position);Wearable technology,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) Simmen, Yves; (1) Eggler, Tabea; (1) Legath, Alexander; (1) Agotai, Doris; (1) Cords, Hilko; ","(1) University of Applied Sciences and Arts Northwestern Switzerland, Bahnhofstrasse 6, Windisch; 5210, Switzerland; ",Springer Science and Business Media Deutschland GmbH,-1,"[""tracking"", ""wearable technology""]","[""tracking"", ""wearable technology""]",tracking;wearable technology,"computer vision;medical;inspection, safety and quality;wearables;human-computer interaction",displays;industries;end users and user experience;use cases;technology,"computer vision;medical;inspection, safety and quality;wearables;human-computer interaction",displays;industries;end users and user experience;use cases;technology,tracking wearable_technology 3d_models 3d modeling assembly_guidance assistive_system manual_assembly task_guidance user_guidance user_interaction user_study wearable_devices 723_computer_software _data_handling_and_applications computer_vision medical inspection _safety_and_quality wearables human computer_interaction,tracking wearable_technology,3d_models 3d modeling assembly_guidance assistive_system manual_assembly task_guidance user_guidance user_interaction user_study wearable_devices,many traditional industry production instruction usually provided paper past research shown effectiveness augmented reality ar virtual user guidance various case usually main focus lie 3d overlay spatially anchored token guide user unfortunately tracking small moving object always feasible highly dynamic complex environment additionally setup anchor 3d model guidance procedure often time consuming problem specific study address scenario provides empirical result ar user guidance without employing overlay object tracking therefore developed two ar concept guide user using either 2d illustration 3d model evaluation designed user study field radio pharmaceutical assessing quantitative measurement usability cognitive load conducted user study indicates ar also improve effectiveness user guidance scenario direct 3d overlay object tracking approach feasible presented 2d 3d ar concept performed similarly lead fewer error faster execution time lower cognitive load paper instruction therefore reduce effort required create 3d instruction use 2d illustration could often efficient choice copy 2023 author exclusive license springer nature switzerland ag,tracking wearable_technology 3d_models 3d modeling assembly_guidance assistive_system manual_assembly task_guidance user_guidance user_interaction user_study wearable_devices 723_computer_software _data_handling_and_applications computer_vision medical inspection _safety_and_quality wearables human computer_interaction many traditional industry production instruction usually provided paper past research shown effectiveness augmented reality ar virtual user guidance various case usually main focus lie 3d overlay spatially anchored token guide user unfortunately tracking small moving object always feasible highly dynamic complex environment additionally setup anchor 3d model guidance procedure often time consuming problem specific study address scenario provides empirical result ar user guidance without employing overlay object tracking therefore developed two ar concept guide user using either 2d illustration 3d model evaluation designed user study field radio pharmaceutical assessing quantitative measurement usability cognitive load conducted user study indicates ar also improve effectiveness user guidance scenario direct 3d overlay object tracking approach feasible presented 2d 3d ar concept performed similarly lead fewer error faster execution time lower cognitive load paper instruction therefore reduce effort required create 3d instruction use 2d illustration could often efficient choice copy 2023 author exclusive license springer nature switzerland ag,many traditional industry production instruction usually provided paper past research shown effectiveness augmented reality ar virtual user guidance various case usually main focus lie 3d overlay spatially anchored token guide user unfortunately tracking small moving object always feasible highly dynamic complex environment additionally setup anchor 3d model guidance procedure often time consuming problem specific study address scenario provides empirical result ar user guidance without employing overlay object tracking therefore developed two ar concept guide user using either 2d illustration 3d model evaluation designed user study field radio pharmaceutical assessing quantitative measurement usability cognitive load conducted user study indicates ar also improve effectiveness user guidance scenario direct 3d overlay object tracking approach feasible presented 2d 3d ar concept performed similarly lead fewer error faster execution time lower cognitive load paper instruction therefore reduce effort required create 3d instruction use 2d illustration could often efficient choice copy 2023 author exclusive license springer nature switzerland agtracking wearable_technology3d_models 3d modeling assembly_guidance assistive_system manual_assembly task_guidance user_guidance user_interaction user_study wearable_devices
190,A Framework for Automatic Generation of Augmented Reality Maintenance &amp; Repair Instructions based on Convolutional Neural Networks,"Mourtzis, D., Angelopoulos, J., & Panopoulos, N. (2020). A Framework for Automatic Generation of Augmented Reality Maintenance &amp; Repair Instructions based on Convolutional Neural Networks. Procedia CIRP, 93, 977–982. https://doi.org/10.1016/j.procir.2020.04.130
",10.1016/j.procir.2020.04.130,"In modern manufacturing world, MRO (Maintenance and Repair Operations) are the cornerstone for keeping industrial equipment in near-optimum condition. Successful completion of MRO has been benefited from Augmented Reality (AR), by considerably decreasing MTTR (Mean Time to Repair). To that end, AR delivers the digital tools that help on-the-field technicians to perform MRO easily and intuitively, however intense development is required for generating AR instructions. The latest advances in computer technologies, concretely in Convolutional Neural Networks, have enabled advanced computer vision. This research paper presents a framework for generating AR maintenance instructions, based on advanced computer vision and Convolutional Neural Networks (CNN). The applicability of the framework is tested in-vitro in a lab-based machine shop. [All rights reserved Elsevier].",C6130V Virtual reality;C5260B Computer vision and image processing techniques;E1020 Maintenance and reliability,advanced computer vision;AR instructions;AR maintenance instructions;automatic generation;Convolutional Neural Networks;industrial equipment;modern manufacturing world;MRO;Repair Operations;successful completion,augmented reality;building management systems;computer vision;machine shops;maintenance engineering;neural nets,2020,Journal article (JA),Procedia CIRP (Netherlands),"(1) Mourtzis, D.; (1) Angelopoulos, J.; (1) Panopoulos, N.; ","(1) University of Patras, Department of Mechanical Engineering and Aeronautics, Greece; ",Elsevier B.V.,-1,"[""building management systems"", ""computer vision"", ""machine shops"", ""maintenance engineering"", ""neural networks""]","[""building management systems"", ""computer vision"", ""machine shops"", ""maintenance engineering"", ""neural networks""]",building management systems;computer vision;machine shops;maintenance engineering;neural networks,construction;computer vision;education;manufacturing;other;artificial intelligence,technology;other;industries,construction;computer vision;education;manufacturing;other;artificial intelligence,technology;other;industries,building_management_systems computer_vision machine_shops maintenance_engineering neural_networks advanced_computer_vision ar_instructions ar_maintenance_instructions automatic_generation convolutional_neural_networks industrial_equipment modern_manufacturing_world mro repair_operations successful_completion c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques e1020_maintenance_and_reliability construction computer_vision education manufacturing other artificial_intelligence,building_management_systems computer_vision machine_shops maintenance_engineering neural_networks,advanced_computer_vision ar_instructions ar_maintenance_instructions automatic_generation convolutional_neural_networks industrial_equipment modern_manufacturing_world mro repair_operations successful_completion,modern manufacturing world mro maintenance repair operation cornerstone keeping industrial equipment near optimum condition successful completion mro benefited augmented reality ar considerably decreasing mttr mean time repair end ar delivers digital tool help field technician perform mro easily intuitively however intense development required generating ar instruction latest advance computer technology concretely convolutional neural network enabled advanced computer vision research paper present framework generating ar maintenance instruction based advanced computer vision convolutional neural network cnn applicability framework tested vitro lab based machine shop right reserved elsevier,building_management_systems computer_vision machine_shops maintenance_engineering neural_networks advanced_computer_vision ar_instructions ar_maintenance_instructions automatic_generation convolutional_neural_networks industrial_equipment modern_manufacturing_world mro repair_operations successful_completion c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques e1020_maintenance_and_reliability construction computer_vision education manufacturing other artificial_intelligence modern manufacturing world mro maintenance repair operation cornerstone keeping industrial equipment near optimum condition successful completion mro benefited augmented reality ar considerably decreasing mttr mean time repair end ar delivers digital tool help field technician perform mro easily intuitively however intense development required generating ar instruction latest advance computer technology concretely convolutional neural network enabled advanced computer vision research paper present framework generating ar maintenance instruction based advanced computer vision convolutional neural network cnn applicability framework tested vitro lab based machine shop right reserved elsevier,modern manufacturing world mro maintenance repair operation cornerstone keeping industrial equipment near optimum condition successful completion mro benefited augmented reality ar considerably decreasing mttr mean time repair end ar delivers digital tool help field technician perform mro easily intuitively however intense development required generating ar instruction latest advance computer technology concretely convolutional neural network enabled advanced computer vision research paper present framework generating ar maintenance instruction based advanced computer vision convolutional neural network cnn applicability framework tested vitro lab based machine shop right reserved elsevierbuilding_management_systems computer_vision machine_shops maintenance_engineering neural_networksadvanced_computer_vision ar_instructions ar_maintenance_instructions automatic_generation convolutional_neural_networks industrial_equipment modern_manufacturing_world mro repair_operations successful_completion
191,Augmented reality guidance platform for epicardial access: a phantom study,"Bamps, K., Bertels, J., Minten, L., Puvrez, A., Coudyzer, W., De Buck, S., & Ector, J. (2023). Augmented reality guidance platform for epicardial access: a phantom study. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2653902
",10.1117/12.2653902,"Percutaneous epicardial access for epicardial ablation and mapping of cardiac arrhythmias is being performed more and more often. Unfortunately, complications such as injury to surrounding structures have been reported. Despite the current imaging techniques, it is still difficult to guarantee sufficient ablation accuracy. Head-mounted-display (HMD) augmented reality (AR) overlay and guidance has the potential to reduce the risk of complications. The objective of this study was to evaluate the accuracy and performance of an AR-guided epicardial puncture for catheter ablation of ventricular tachycardia. An AR software tool was designed to render real-time needle trajectories and 3D patient-specific organs. Registration of preoperative data is realized by attaching four AR patterns to the skin of the patient. Needle tracking is realized by attaching one AR pattern to the end of the needle's base. The ideal trajectory through the pericardial space and patient-specific organs was planned and segmented on preoperative CT. The application's accuracy was evaluated in a phantom study. Seven operators performed needle puncture with and without the use of the AR system. Placements errors were measured on postprocedural CT. With the use of the proposed AR-based guidance, postprocedure CT revealed an error at the puncture site of 3.67&plusmn;2.78 mm. At the epicardial interface, the error increased to 7.78&plusmn;2.36 mm. The angle of the actual trajectory deviated on average 4.82&plusmn;1.48&#9702; from the planned trajectory. The execution time was on average 34.0 &plusmn; 25.1 s, hence introducing no significant delay at an overall superior performance level compared to without AR-guided puncturing. The proposed AR platform has the potential to facilitate percutaneous epicardial access for epicardial ablation and mapping of cardiac arrhythmias by improving needle insertion accuracy. &copy; 2023 SPIE.","405.3 Surveying;641.2 Heat Transfer;723 Computer Software, Data Handling and Applications;723.5 Computer Applications",Cardiac arrhythmia;Catheter ablation;Current imaging;Head-mounted-displays;Patient specific;Performance;Phantom studies;Real- time;Software-tools;Ventricular tachycardia,Ablation;Computerized tomography;Diseases;Errors;Helmet mounted displays;Mapping;Needles;Phantoms;Trajectories,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Bamps, Kobe; (2) Bertels, Jeroen; (1) Minten, Lennert; (1) Puvrez, Alexis; (3) Coudyzer, Walter; (2) De Buck, Stijn; (1) Ector, Joris; ","(1) KU Leuven, Department of Cardiovascular Sciences, Belgium; (2) KU Leuven, Department of Electrical Engineering, Belgium; (3) UZ Leuven, University Hospital Leuven, Belgium; (4) KU Leuven, Department of Radiology, Belgium; ",SPIE,-1,"[""ablation"", ""computerized tomography"", ""diseases"", ""errors"", ""helmet mounted displays"", ""mapping"", ""needles"", ""phantoms"", ""trajectories""]","[""ablation"", ""computerized tomography"", ""diseases"", ""errors"", ""helmet mounted displays"", ""mapping"", ""needles"", ""phantoms"", ""trajectories""]",ablation;computerized tomography;diseases;errors;helmet mounted displays;mapping;needles;phantoms;trajectories,medical;display technology;human factors;wearables;navigation,industries;displays;use cases;end users and user experience,medical;display technology;human factors;wearables;navigation,industries;displays;use cases;end users and user experience,ablation computerized_tomography diseases errors helmet_mounted_displays mapping needles phantoms trajectories cardiac_arrhythmia catheter_ablation current_imaging head mounted displays patient_specific performance phantom_studies real _time software tools ventricular_tachycardia 405 3_surveying 641 2_heat_transfer 723_computer_software _data_handling_and_applications 723 5_computer_applications medical display_technology human_factors wearables navigation,ablation computerized_tomography diseases errors helmet_mounted_displays mapping needles phantoms trajectories,cardiac_arrhythmia catheter_ablation current_imaging head mounted displays patient_specific performance phantom_studies real _time software tools ventricular_tachycardia,percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia performed often unfortunately complication injury surrounding structure reported despite current imaging technique still difficult guarantee sufficient ablation accuracy head mounted display hmd augmented reality ar overlay guidance potential reduce risk complication objective study evaluate accuracy performance ar guided epicardial puncture catheter ablation ventricular tachycardia ar software tool designed render real time needle trajectory 3d patient specific organ registration preoperative data realized attaching four ar pattern skin patient needle tracking realized attaching one ar pattern end needle base ideal trajectory pericardial space patient specific organ planned segmented preoperative ct application accuracy evaluated phantom study seven operator performed needle puncture without use ar system placement error measured postprocedural ct use proposed ar based guidance postprocedure ct revealed error puncture site 3 67 plusmn 2 78 mm epicardial interface error increased 7 78 plusmn 2 36 mm angle actual trajectory deviated average 4 82 plusmn 1 48 9702 planned trajectory execution time average 34 0 plusmn 25 1 hence introducing significant delay overall superior performance level compared without ar guided puncturing proposed ar platform potential facilitate percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia improving needle insertion accuracy copy 2023 spie,ablation computerized_tomography diseases errors helmet_mounted_displays mapping needles phantoms trajectories cardiac_arrhythmia catheter_ablation current_imaging head mounted displays patient_specific performance phantom_studies real _time software tools ventricular_tachycardia 405 3_surveying 641 2_heat_transfer 723_computer_software _data_handling_and_applications 723 5_computer_applications medical display_technology human_factors wearables navigation percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia performed often unfortunately complication injury surrounding structure reported despite current imaging technique still difficult guarantee sufficient ablation accuracy head mounted display hmd augmented reality ar overlay guidance potential reduce risk complication objective study evaluate accuracy performance ar guided epicardial puncture catheter ablation ventricular tachycardia ar software tool designed render real time needle trajectory 3d patient specific organ registration preoperative data realized attaching four ar pattern skin patient needle tracking realized attaching one ar pattern end needle base ideal trajectory pericardial space patient specific organ planned segmented preoperative ct application accuracy evaluated phantom study seven operator performed needle puncture without use ar system placement error measured postprocedural ct use proposed ar based guidance postprocedure ct revealed error puncture site 3 67 plusmn 2 78 mm epicardial interface error increased 7 78 plusmn 2 36 mm angle actual trajectory deviated average 4 82 plusmn 1 48 9702 planned trajectory execution time average 34 0 plusmn 25 1 hence introducing significant delay overall superior performance level compared without ar guided puncturing proposed ar platform potential facilitate percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia improving needle insertion accuracy copy 2023 spie,percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia performed often unfortunately complication injury surrounding structure reported despite current imaging technique still difficult guarantee sufficient ablation accuracy head mounted display hmd augmented reality ar overlay guidance potential reduce risk complication objective study evaluate accuracy performance ar guided epicardial puncture catheter ablation ventricular tachycardia ar software tool designed render real time needle trajectory 3d patient specific organ registration preoperative data realized attaching four ar pattern skin patient needle tracking realized attaching one ar pattern end needle base ideal trajectory pericardial space patient specific organ planned segmented preoperative ct application accuracy evaluated phantom study seven operator performed needle puncture without use ar system placement error measured postprocedural ct use proposed ar based guidance postprocedure ct revealed error puncture site 3 67 plusmn 2 78 mm epicardial interface error increased 7 78 plusmn 2 36 mm angle actual trajectory deviated average 4 82 plusmn 1 48 9702 planned trajectory execution time average 34 0 plusmn 25 1 hence introducing significant delay overall superior performance level compared without ar guided puncturing proposed ar platform potential facilitate percutaneous epicardial access epicardial ablation mapping cardiac arrhythmia improving needle insertion accuracy copy 2023 spieablation computerized_tomography diseases errors helmet_mounted_displays mapping needles phantoms trajectoriescardiac_arrhythmia catheter_ablation current_imaging head mounted displays patient_specific performance phantom_studies real _time software tools ventricular_tachycardia
192,"ReadAR, Playful Book Finding Through Peer Book Reviews for&nbsp;Multi-faceted Characters in&nbsp;AR","Wintermans, L., van Delden, R., & Reidsma, D. (2023). ReadAR, Playful Book Finding Through Peer Book Reviews for Multi-faceted Characters in AR. Lecture Notes in Computer Science, 50–64. https://doi.org/10.1007/978-3-031-30933-5_4
",10.1007/978-3-031-30933-5_4,"One important element to provide reading enjoyment and to persuade children to read (more) is providing children with books that fit their interests. We structure filtering and recommendation of books in a playful way via animated 3D characters. These characters have an unusual mix of characteristics that can be related to categories of books, while at the same time aiming for overcoming a filter bubble effect. In our Augmented Reality application the characters playfully &lsquo;structure&rsquo; the process of book review and searching. We tested the prototype during two within-subject sessions, testing reflecting on the book as well as searching for books, with respectively 18 and 15 participants. When comparing to a regular &lsquo;writing a book report&rsquo;-approach, children indicated they would more likely want to use the app again for providing feedback about the book to peers as well as for finding books. Although they wanted to look again for the books and watch the accompanying localised video reviews from their peers, almost half did not want to record videos themselves again which points out a clear challenge for future improvements. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;903.2 Information Dissemination",3D characters;AR;Augmented reality applications;Book;Book reviews;Future improvements;Kid;Localised;Play;Reading,Augmented reality;Well testing,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) Wintermans, Lars; (2) van Delden, Robby; (2) Reidsma, Dennis; ","(1) Creative Technology, University of Twente, Enschede, Netherlands; (2) Human Media Interaction, University of Twente, Drienerlolaan 5, Enschede, Netherlands; ",Springer Science and Business Media Deutschland GmbH,-1,"[""well testing""]","[""well testing""]",well testing,"utilities;inspection, safety and quality",use cases;industries,"utilities;inspection, safety and quality",use cases;industries,well_testing 3d_characters ar augmented_reality_applications book book_reviews future_improvements kid localised play reading 723_computer_software _data_handling_and_applications 903 2_information_dissemination utilities inspection _safety_and_quality,well_testing,3d_characters ar augmented_reality_applications book book_reviews future_improvements kid localised play reading,one important element provide reading enjoyment persuade child read providing child book fit interest structure filtering recommendation book playful way via animated 3d character character unusual mix characteristic related category book time aiming overcoming filter bubble effect augmented reality application character playfully lsquo structure rsquo process book review searching tested prototype two within subject session testing reflecting book well searching book respectively 18 15 participant comparing regular lsquo writing book report rsquo approach child indicated would likely want use app providing feedback book peer well finding book although wanted look book watch accompanying localised video review peer almost half want record video point clear challenge future improvement copy 2023 author exclusive license springer nature switzerland ag,well_testing 3d_characters ar augmented_reality_applications book book_reviews future_improvements kid localised play reading 723_computer_software _data_handling_and_applications 903 2_information_dissemination utilities inspection _safety_and_quality one important element provide reading enjoyment persuade child read providing child book fit interest structure filtering recommendation book playful way via animated 3d character character unusual mix characteristic related category book time aiming overcoming filter bubble effect augmented reality application character playfully lsquo structure rsquo process book review searching tested prototype two within subject session testing reflecting book well searching book respectively 18 15 participant comparing regular lsquo writing book report rsquo approach child indicated would likely want use app providing feedback book peer well finding book although wanted look book watch accompanying localised video review peer almost half want record video point clear challenge future improvement copy 2023 author exclusive license springer nature switzerland ag,one important element provide reading enjoyment persuade child read providing child book fit interest structure filtering recommendation book playful way via animated 3d character character unusual mix characteristic related category book time aiming overcoming filter bubble effect augmented reality application character playfully lsquo structure rsquo process book review searching tested prototype two within subject session testing reflecting book well searching book respectively 18 15 participant comparing regular lsquo writing book report rsquo approach child indicated would likely want use app providing feedback book peer well finding book although wanted look book watch accompanying localised video review peer almost half want record video point clear challenge future improvement copy 2023 author exclusive license springer nature switzerland agwell_testing3d_characters ar augmented_reality_applications book book_reviews future_improvements kid localised play reading
193,Identifying The Types and Platforms of the Metaverse - a Systematic Literature Review,"Suryodiningrat, S. P., Prabowo, H., Ramadhan, A., & Santoso, H. B. (2022). Identifying The Types and Platforms of the Metaverse – a Systematic Literature Review. 2022 IEEE Creative Communication and Innovative Technology (ICCIT). https://doi.org/10.1109/iccit55355.2022.10118659
",10.1109/ICCIT55355.2022.10118659,"Metaverse is gaining a lot of traction lately, especially after Mark Zuckerberg's Facebook changed its name to Meta as a preparation to enter another universe called metaverse. The eXtended Reality (XR) technology is also rapidly growing since the birth of Virtual Reality (VR), followed by Augmented Reality (AR), and Mixed Reality is the latest development of XR technology. As the XR technology is the perfect companion to support the metaverse and the understanding of the metaverse is already clear but unfortunately, there is a lot of misconception about the types of the metaverse as well as the platform for each type. This paper aims to point out the types and platforms of the metaverse. 49 articles have been collected and reviewed carefully as a quality assessment process, and 45 articles have been selected for further review. This review informs everybody that there are many types and platforms of the metaverse nowadays.",C7210N Information networks;C6130V Virtual reality,augmented reality;extended reality technology;Facebook;metaverse;virtual reality;XR technology,augmented reality;social networking (online),2022,Conference article (CA),2022 IEEE Creative Communication and Innovative Technology (ICCIT),"(1) Suryodiningrat, S.P.; (2) Prabowo, H.; (2) Ramadhan, A.; (3) Santoso, H.B.; ","(1) Bina Nusantara University, Computer Science, Indonesia; (2) Bina Nusantara University, Graduate Program, Indonesia; (3) Universitas Indonesia, Faculty of Computer Science, Indonesia; ",IEEE,-1,"[""social networking""]","[""social networking""]",social networking,collaboration,use cases,collaboration,use cases,social_networking augmented_reality extended_reality_technology facebook metaverse virtual_reality xr_technology c7210n_information_networks c6130v_virtual_reality collaboration,social_networking,augmented_reality extended_reality_technology facebook metaverse virtual_reality xr_technology,metaverse gaining lot traction lately especially mark zuckerberg facebook changed name meta preparation enter another universe called metaverse extended reality xr technology also rapidly growing since birth virtual reality vr followed augmented reality ar mixed reality latest development xr technology xr technology perfect companion support metaverse understanding metaverse already clear unfortunately lot misconception type metaverse well platform type paper aim point type platform metaverse 49 article collected reviewed carefully quality assessment process 45 article selected review review informs everybody many type platform metaverse nowadays,social_networking augmented_reality extended_reality_technology facebook metaverse virtual_reality xr_technology c7210n_information_networks c6130v_virtual_reality collaboration metaverse gaining lot traction lately especially mark zuckerberg facebook changed name meta preparation enter another universe called metaverse extended reality xr technology also rapidly growing since birth virtual reality vr followed augmented reality ar mixed reality latest development xr technology xr technology perfect companion support metaverse understanding metaverse already clear unfortunately lot misconception type metaverse well platform type paper aim point type platform metaverse 49 article collected reviewed carefully quality assessment process 45 article selected review review informs everybody many type platform metaverse nowadays,metaverse gaining lot traction lately especially mark zuckerberg facebook changed name meta preparation enter another universe called metaverse extended reality xr technology also rapidly growing since birth virtual reality vr followed augmented reality ar mixed reality latest development xr technology xr technology perfect companion support metaverse understanding metaverse already clear unfortunately lot misconception type metaverse well platform type paper aim point type platform metaverse 49 article collected reviewed carefully quality assessment process 45 article selected review review informs everybody many type platform metaverse nowadayssocial_networkingaugmented_reality extended_reality_technology facebook metaverse virtual_reality xr_technology
194,"Detection and&nbsp;Pose Estimation of&nbsp;Flat, Texture-Less Industry Objects on&nbsp;HoloLens Using Synthetic Training","Pöllabauer, T., Rücker, F., Franek, A., & Gorschlüter, F. (2023). Detection and Pose Estimation of Flat, Texture-Less Industry Objects on HoloLens Using Synthetic Training. Lecture Notes in Computer Science, 569–585. https://doi.org/10.1007/978-3-031-31438-4_37
",10.1007/978-3-031-31438-4_37,"Current state-of-the-art 6d pose estimation is too compute intensive to be deployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, both used for an increasing number of augmented reality applications. The quality of AR is greatly dependent on its capabilities to detect and overlay geometry within the scene. We propose a synthetically trained client-server-based augmented reality application, demonstrating state-of-the-art object pose estimation of metallic and texture-less industry objects on edge devices. Synthetic data enables training without real photographs, i.e. for yet-to-be-manufactured objects. Our qualitative evaluation on an AR-assisted sorting task, and quantitative evaluation on both renderings, as well as real-world data recorded on HoloLens 2, sheds light on its real-world applicability. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","512.1.2 Petroleum Deposits : Development Operations;723 Computer Software, Data Handling and Applications",'current;6d object pose estimation;Augmented reality applications;Detection estimation;MicroSoft;Object pose;Pose-estimation;Real-world;Sim2real domain gap;State of the art,Augmented reality;Petroleum reservoir evaluation;Windows operating system,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) P&ouml;llabauer, Thomas; (1) R&uuml;cker, Fabian; (1) Franek, Andreas; (1) Gorschl&uuml;ter, Felix; ","(1) Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; (2) Interactive Graphics Research Group, TU Darmstadt, Darmstadt, Germany; ",Springer Science and Business Media Deutschland GmbH,-1,"[""petroleum reservoir evaluation"", ""windows operating system""]","[""petroleum reservoir evaluation"", ""windows operating system""]",petroleum reservoir evaluation;windows operating system,construction;other;education;farming and natural science;power and energy,other;industries,construction;other;education;farming and natural science;power and energy,other;industries,petroleum_reservoir_evaluation windows_operating_system current 6d_object_pose_estimation augmented_reality_applications detection_estimation microsoft object_pose pose estimation real world sim2real_domain_gap state_of_the_art 512 1 2_petroleum_deposits_ _development_operations 723_computer_software _data_handling_and_applications construction other education farming_and_natural_science power_and_energy,petroleum_reservoir_evaluation windows_operating_system,current 6d_object_pose_estimation augmented_reality_applications detection_estimation microsoft object_pose pose estimation real world sim2real_domain_gap state_of_the_art,current state art 6d pose estimation compute intensive deployed edge device microsoft hololens 2 apple ipad used increasing number augmented reality application quality ar greatly dependent capability detect overlay geometry within scene propose synthetically trained client server based augmented reality application demonstrating state art object pose estimation metallic texture le industry object edge device synthetic data enables training without real photograph e yet manufactured object qualitative evaluation ar assisted sorting task quantitative evaluation rendering well real world data recorded hololens 2 shed light real world applicability copy 2023 author exclusive license springer nature switzerland ag,petroleum_reservoir_evaluation windows_operating_system current 6d_object_pose_estimation augmented_reality_applications detection_estimation microsoft object_pose pose estimation real world sim2real_domain_gap state_of_the_art 512 1 2_petroleum_deposits_ _development_operations 723_computer_software _data_handling_and_applications construction other education farming_and_natural_science power_and_energy current state art 6d pose estimation compute intensive deployed edge device microsoft hololens 2 apple ipad used increasing number augmented reality application quality ar greatly dependent capability detect overlay geometry within scene propose synthetically trained client server based augmented reality application demonstrating state art object pose estimation metallic texture le industry object edge device synthetic data enables training without real photograph e yet manufactured object qualitative evaluation ar assisted sorting task quantitative evaluation rendering well real world data recorded hololens 2 shed light real world applicability copy 2023 author exclusive license springer nature switzerland ag,current state art 6d pose estimation compute intensive deployed edge device microsoft hololens 2 apple ipad used increasing number augmented reality application quality ar greatly dependent capability detect overlay geometry within scene propose synthetically trained client server based augmented reality application demonstrating state art object pose estimation metallic texture le industry object edge device synthetic data enables training without real photograph e yet manufactured object qualitative evaluation ar assisted sorting task quantitative evaluation rendering well real world data recorded hololens 2 shed light real world applicability copy 2023 author exclusive license springer nature switzerland agpetroleum_reservoir_evaluation windows_operating_systemcurrent 6d_object_pose_estimation augmented_reality_applications detection_estimation microsoft object_pose pose estimation real world sim2real_domain_gap state_of_the_art
195,Impact of User Mobility on Attentional Tunneling in Handheld AR,"Parmar, M., & Silpasuwanchai, C. (2023). Impact of User Mobility on Attentional Tunneling in Handheld AR. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585692
",10.1145/3544549.3585692,"Attentional tunneling in augmented reality (AR) refers to a phenomenon where users pay disproportionately high attention to virtual content while ignoring events in the real world. Although many handheld AR applications are deployed in public places where users are expected to be attentive to their surroundings while walking freely, the effect of user mobility on attentional tunneling is not yet ascertained. To investigate the effects of user mobility, we designed a 2x3 study comparing two postures (stationary and walking) with three AR tasks (a non-cognitive baseline task, a working memory task, and a perceptual monitoring task). The results suggest that walking significantly magnifies the tunneling effect, provided the user is engaged with a task that is associated with the virtual content being viewed. We demonstrate the significance of considering user mobility when evaluating AR application usage and provide guidelines for designers to evaluate the application in such scenarios.",C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6180 User interfaces,attentional tunneling;augmented reality;handheld AR applications;user mobility;virtual content,augmented reality;human factors,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Parmar, M.; (1) Silpasuwanchai, C.; ","(1) Asian Institute of Technology, Thailand; ",ACM,-1,"[""human factors""]","[""human factors""]",human factors,human factors,end users and user experience,human factors,end users and user experience,human_factors attentional_tunneling augmented_reality handheld_ar_applications user_mobility virtual_content c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces human_factors,human_factors,attentional_tunneling augmented_reality handheld_ar_applications user_mobility virtual_content,attentional tunneling augmented reality ar refers phenomenon user pay disproportionately high attention virtual content ignoring event real world although many handheld ar application deployed public place user expected attentive surroundings walking freely effect user mobility attentional tunneling yet ascertained investigate effect user mobility designed 2x3 study comparing two posture stationary walking three ar task non cognitive baseline task working memory task perceptual monitoring task result suggest walking significantly magnifies tunneling effect provided user engaged task associated virtual content viewed demonstrate significance considering user mobility evaluating ar application usage provide guideline designer evaluate application scenario,human_factors attentional_tunneling augmented_reality handheld_ar_applications user_mobility virtual_content c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces human_factors attentional tunneling augmented reality ar refers phenomenon user pay disproportionately high attention virtual content ignoring event real world although many handheld ar application deployed public place user expected attentive surroundings walking freely effect user mobility attentional tunneling yet ascertained investigate effect user mobility designed 2x3 study comparing two posture stationary walking three ar task non cognitive baseline task working memory task perceptual monitoring task result suggest walking significantly magnifies tunneling effect provided user engaged task associated virtual content viewed demonstrate significance considering user mobility evaluating ar application usage provide guideline designer evaluate application scenario,attentional tunneling augmented reality ar refers phenomenon user pay disproportionately high attention virtual content ignoring event real world although many handheld ar application deployed public place user expected attentive surroundings walking freely effect user mobility attentional tunneling yet ascertained investigate effect user mobility designed 2x3 study comparing two posture stationary walking three ar task non cognitive baseline task working memory task perceptual monitoring task result suggest walking significantly magnifies tunneling effect provided user engaged task associated virtual content viewed demonstrate significance considering user mobility evaluating ar application usage provide guideline designer evaluate application scenariohuman_factorsattentional_tunneling augmented_reality handheld_ar_applications user_mobility virtual_content
196,Safety in the Laboratory-An Exit Game Lab Rally in Chemistry Education,"Krug, M., & Huwer, J. (2023). Safety in the Laboratory—An Exit Game Lab Rally in Chemistry Education. Computers, 12(3), 67. https://doi.org/10.3390/computers12030067
",10.3390/computers12030067,"The topic of safety in chemistry laboratories in schools is crucial, as severe accidents in labs occur worldwide, primarily due to poorly trained individuals and improper behavior. One reason for this could be that the topic is often dry and boring for students. One solution to this problem is engaging students more actively in the lesson using a game format. In this publication, we present an augmented-reality-supported exit game in the form of a laboratory rally and the results of a pilot study that examined the use of the rally in terms of technology acceptance and intrinsic motivation. The study involved 22 students from a general high school. The study results show a high level of technology acceptance for the augmented reality used, as well as good results in terms of the intrinsic motivation triggered by the lesson.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C7810C Computer-aided instruction;C7830D Computer games,augmented reality;augmented-reality-supported exit game;chemistry education;chemistry laboratories;game format;general high school;improper behavior;intrinsic motivation;laboratory rally;laboratory-an exit game lab rally;labs;lesson;poorly trained individuals;severe accidents;technology acceptance,augmented reality;computer aided instruction;educational institutions;human factors,2023,Journal article (JA),Computers (Switzerland),"(1) Krug, M.; (1) Huwer, J.; ","(1) University of Konstanz, Department of Chemistry, Germany; (2) Thurgau University of Education, Chair of Science Education, Switzerland; ",MDPI,-1,"[""computer aided instruction"", ""educational institutions"", ""human factors""]","[""computer aided instruction"", ""educational institutions"", ""human factors""]",computer aided instruction;educational institutions;human factors,human factors;education;training,end users and user experience;use cases;industries,human factors;education;training,end users and user experience;use cases;industries,computer_aided_instruction educational_institutions human_factors augmented_reality augmented reality supported_exit_game chemistry_education chemistry_laboratories game_format general_high_school improper_behavior intrinsic_motivation laboratory_rally laboratory an_exit_game_lab_rally labs lesson poorly_trained_individuals severe_accidents technology_acceptance c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction c7830d_computer_games human_factors education training,computer_aided_instruction educational_institutions human_factors,augmented_reality augmented reality supported_exit_game chemistry_education chemistry_laboratories game_format general_high_school improper_behavior intrinsic_motivation laboratory_rally laboratory an_exit_game_lab_rally labs lesson poorly_trained_individuals severe_accidents technology_acceptance,topic safety chemistry laboratory school crucial severe accident lab occur worldwide primarily due poorly trained individual improper behavior one reason could topic often dry boring student one solution problem engaging student actively lesson using game format publication present augmented reality supported exit game form laboratory rally result pilot study examined use rally term technology acceptance intrinsic motivation study involved 22 student general high school study result show high level technology acceptance augmented reality used well good result term intrinsic motivation triggered lesson,computer_aided_instruction educational_institutions human_factors augmented_reality augmented reality supported_exit_game chemistry_education chemistry_laboratories game_format general_high_school improper_behavior intrinsic_motivation laboratory_rally laboratory an_exit_game_lab_rally labs lesson poorly_trained_individuals severe_accidents technology_acceptance c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction c7830d_computer_games human_factors education training topic safety chemistry laboratory school crucial severe accident lab occur worldwide primarily due poorly trained individual improper behavior one reason could topic often dry boring student one solution problem engaging student actively lesson using game format publication present augmented reality supported exit game form laboratory rally result pilot study examined use rally term technology acceptance intrinsic motivation study involved 22 student general high school study result show high level technology acceptance augmented reality used well good result term intrinsic motivation triggered lesson,topic safety chemistry laboratory school crucial severe accident lab occur worldwide primarily due poorly trained individual improper behavior one reason could topic often dry boring student one solution problem engaging student actively lesson using game format publication present augmented reality supported exit game form laboratory rally result pilot study examined use rally term technology acceptance intrinsic motivation study involved 22 student general high school study result show high level technology acceptance augmented reality used well good result term intrinsic motivation triggered lessoncomputer_aided_instruction educational_institutions human_factorsaugmented_reality augmented reality supported_exit_game chemistry_education chemistry_laboratories game_format general_high_school improper_behavior intrinsic_motivation laboratory_rally laboratory an_exit_game_lab_rally labs lesson poorly_trained_individuals severe_accidents technology_acceptance
197,"Location-based AR for Social Justice: Case Studies, Lessons, and Open Challenges","Schroeder, H., Tokanel, R., Qian, K., & Le, K. (2023). Location-based AR for Social Justice: Case Studies, Lessons, and Open Challenges. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3573855
",10.1145/3544549.3573855,"Dear Visitor and Charleston Reconstructed were location-based augmented reality (AR) experiences created between 2018 and 2020 dealing with two controversial monument sites in the US. The projects were motivated by the ability of AR to 1) link layers of context to physical sites in ways that are otherwise difficult or impossible and 2) to visualize changes to physical spaces, potentially inspiring changes to the spaces themselves. We discuss the projects' motivations, designs, and deployments. We reflect on how physical changes to the projects' respective sites radically altered their outcomes, and we describe lessons for future work in location-based AR, particularly for projects in contested spaces.","C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7820 Humanities computing",Charleston reconstructed;controversial monument sites;location-based AR;location-based augmented reality;physical sites;physical spaces;project motivation;social justice,augmented reality;history;location based services,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schroeder, H.; (2) Tokanel, R.; (3) Qian, K.; (3) Le, K.; ","(1) Massachusetts Institute of Technology, Cambridge, MA, United States; (2) Columbia University, New York, NY, United States; (3) Stanford University, Stanford, CA, United States; ",ACM,-1,"[""history"", ""location based services""]","[""history"", ""location based services""]",history;location based services,geospatial;liberal arts,technology;industries,geospatial;liberal arts,technology;industries,history location_based_services charleston_reconstructed controversial_monument_sites location based_ar location based_augmented_reality physical_sites physical_spaces project_motivation social_justice c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing geospatial liberal_arts,history location_based_services,charleston_reconstructed controversial_monument_sites location based_ar location based_augmented_reality physical_sites physical_spaces project_motivation social_justice,dear visitor charleston reconstructed location based augmented reality ar experience created 2018 2020 dealing two controversial monument site u project motivated ability ar 1 link layer context physical site way otherwise difficult impossible 2 visualize change physical space potentially inspiring change space discus project motivation design deployment reflect physical change project respective site radically altered outcome describe lesson future work location based ar particularly project contested space,history location_based_services charleston_reconstructed controversial_monument_sites location based_ar location based_augmented_reality physical_sites physical_spaces project_motivation social_justice c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7820_humanities_computing geospatial liberal_arts dear visitor charleston reconstructed location based augmented reality ar experience created 2018 2020 dealing two controversial monument site u project motivated ability ar 1 link layer context physical site way otherwise difficult impossible 2 visualize change physical space potentially inspiring change space discus project motivation design deployment reflect physical change project respective site radically altered outcome describe lesson future work location based ar particularly project contested space,dear visitor charleston reconstructed location based augmented reality ar experience created 2018 2020 dealing two controversial monument site u project motivated ability ar 1 link layer context physical site way otherwise difficult impossible 2 visualize change physical space potentially inspiring change space discus project motivation design deployment reflect physical change project respective site radically altered outcome describe lesson future work location based ar particularly project contested spacehistory location_based_servicescharleston_reconstructed controversial_monument_sites location based_ar location based_augmented_reality physical_sites physical_spaces project_motivation social_justice
198,Gaze Depth Estimation for In-vehicle AR Displays,"Uramune, R., Sawamura, K., Ikeda, S., Ishizuka, H., & Oshiro, O. (2023). Gaze Depth Estimation for In-vehicle AR Displays. Augmented Humans Conference. https://doi.org/10.1145/3582700.3583707
",10.1145/3582700.3583707,"In our previous study, we proposed a method for judging whether the user is gazing at a semi-transparent virtual object or real objects behind it in augmented reality environments. This paper shows that the accuracy of our method can be improved by selecting the optimal thresholds for the fixation detection. Fourteen participants experienced a virtual reality environment in which there were a transparent subway map and buildings behind it in the distance of 2 m and 15 m away from each participant, respectively. As a result, the accuracy of our method has achieved 88.3 % and improved by 13.8 percentage points from the previous 74.5 %.","B6135 Optical, image and video signal processing;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces",augmented reality environments;fixation detection;gaze depth estimation;in-vehicle AR displays;optimal thresholds;semitransparent virtual object;transparent subway map;virtual reality environment,augmented reality;gaze tracking;human factors,2023,Conference article (CA),AHs23: Proceedings of the Augmented Humans Conference 2023,"(1) Uramune, R.; (1) Sawamura, K.; (1) Ikeda, S.; (1) Ishizuka, H.; (1) Oshiro, O.; ","(1) Osaka University, Japan; ",ACM,-1,"[""gaze tracking"", ""human factors""]","[""gaze tracking"", ""human factors""]",gaze tracking;human factors,computer vision;human factors;input,technology;end users and user experience,computer vision;human factors;input,technology;end users and user experience,gaze_tracking human_factors augmented_reality_environments fixation_detection gaze_depth_estimation in vehicle_ar_displays optimal_thresholds semitransparent_virtual_object transparent_subway_map virtual_reality_environment b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision human_factors input,gaze_tracking human_factors,augmented_reality_environments fixation_detection gaze_depth_estimation in vehicle_ar_displays optimal_thresholds semitransparent_virtual_object transparent_subway_map virtual_reality_environment,previous study proposed method judging whether user gazing semi transparent virtual object real object behind augmented reality environment paper show accuracy method improved selecting optimal threshold fixation detection fourteen participant experienced virtual reality environment transparent subway map building behind distance 2 15 away participant respectively result accuracy method achieved 88 3 improved 13 8 percentage point previous 74 5,gaze_tracking human_factors augmented_reality_environments fixation_detection gaze_depth_estimation in vehicle_ar_displays optimal_thresholds semitransparent_virtual_object transparent_subway_map virtual_reality_environment b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision human_factors input previous study proposed method judging whether user gazing semi transparent virtual object real object behind augmented reality environment paper show accuracy method improved selecting optimal threshold fixation detection fourteen participant experienced virtual reality environment transparent subway map building behind distance 2 15 away participant respectively result accuracy method achieved 88 3 improved 13 8 percentage point previous 74 5,previous study proposed method judging whether user gazing semi transparent virtual object real object behind augmented reality environment paper show accuracy method improved selecting optimal threshold fixation detection fourteen participant experienced virtual reality environment transparent subway map building behind distance 2 15 away participant respectively result accuracy method achieved 88 3 improved 13 8 percentage point previous 74 5gaze_tracking human_factorsaugmented_reality_environments fixation_detection gaze_depth_estimation in vehicle_ar_displays optimal_thresholds semitransparent_virtual_object transparent_subway_map virtual_reality_environment
199,Evaluating the Extension of Wall Displays with AR for Collaborative Work,"James, R., Bezerianos, A., & Chapuis, O. (2023). Evaluating the Extension of Wall Displays with AR for Collaborative Work. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580752
",10.1145/3544548.3580752,"Wall displays are well suited for collaborative work and are often placed in rooms with ample space in front of them that remains largely unused. Augmented Reality (AR) headsets can seamlessly extend the collaboration space around the Wall. Nevertheless, it is unclear if extending Walls with AR is effective and how it may affect collaboration. We first present a prototype combining a Wall and AR headsets to extend the Wall workspace. We then use this prototype to study how users utilize the virtual space created in AR. In an experiment with 24 participants, we compare how pairs solve collaborative tasks with the Wall alone and with Wall+AR. Our qualitative and quantitative results highlight that with Wall+AR, participants use the physical space in front and around the Wall extensively, and while this creates interaction overhead, it does not impact performance and improves the user experience.",B7260 Display technology;C6130G Groupware;C6130V Virtual reality;C6190Z Other distributed systems software,ample space;augmented reality headsets;collaboration space;collaborative tasks;collaborative work;interaction overhead;physical space;user experience;virtual space;wall displays;wall workspace;Wall+AR,augmented reality;display devices;groupware,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) James, R.; (1) Bezerianos, A.; (1) Chapuis, O.; ","(1) LISN, France; ",ACM,-1,"[""display devices"", ""groupware""]","[""display devices"", ""groupware""]",display devices;groupware,display technology;collaboration,displays;use cases,display technology;collaboration,displays;use cases,display_devices groupware ample_space augmented_reality_headsets collaboration_space collaborative_tasks collaborative_work interaction_overhead physical_space user_experience virtual_space wall_displays wall_workspace wall ar b7260_display_technology c6130g_groupware c6130v_virtual_reality c6190z_other_distributed_systems_software display_technology collaboration,display_devices groupware,ample_space augmented_reality_headsets collaboration_space collaborative_tasks collaborative_work interaction_overhead physical_space user_experience virtual_space wall_displays wall_workspace wall ar,wall display well suited collaborative work often placed room ample space front remains largely unused augmented reality ar headset seamlessly extend collaboration space around wall nevertheless unclear extending wall ar effective may affect collaboration first present prototype combining wall ar headset extend wall workspace use prototype study user utilize virtual space created ar experiment 24 participant compare pair solve collaborative task wall alone wall ar qualitative quantitative result highlight wall ar participant use physical space front around wall extensively creates interaction overhead impact performance improves user experience,display_devices groupware ample_space augmented_reality_headsets collaboration_space collaborative_tasks collaborative_work interaction_overhead physical_space user_experience virtual_space wall_displays wall_workspace wall ar b7260_display_technology c6130g_groupware c6130v_virtual_reality c6190z_other_distributed_systems_software display_technology collaboration wall display well suited collaborative work often placed room ample space front remains largely unused augmented reality ar headset seamlessly extend collaboration space around wall nevertheless unclear extending wall ar effective may affect collaboration first present prototype combining wall ar headset extend wall workspace use prototype study user utilize virtual space created ar experiment 24 participant compare pair solve collaborative task wall alone wall ar qualitative quantitative result highlight wall ar participant use physical space front around wall extensively creates interaction overhead impact performance improves user experience,wall display well suited collaborative work often placed room ample space front remains largely unused augmented reality ar headset seamlessly extend collaboration space around wall nevertheless unclear extending wall ar effective may affect collaboration first present prototype combining wall ar headset extend wall workspace use prototype study user utilize virtual space created ar experiment 24 participant compare pair solve collaborative task wall alone wall ar qualitative quantitative result highlight wall ar participant use physical space front around wall extensively creates interaction overhead impact performance improves user experiencedisplay_devices groupwareample_space augmented_reality_headsets collaboration_space collaborative_tasks collaborative_work interaction_overhead physical_space user_experience virtual_space wall_displays wall_workspace wall ar
200,The Second Workshop on Multiple Input Modalities and Sensations for VR/AR Interactions (MIMSVAI),"You, C.-W., Chen, Y.-C., Tsai, H.-R., & Chen, C.-Y. (2022). The Second Workshop on Multiple Input Modalities and Sensations for VR/AR Interactions (MIMSVAI). Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing. https://doi.org/10.1145/3544793.3560372
",10.1145/3544793.3560372,"With the advance of VR/AR technology, more and more VR/AR applications are emerging and have been popular among new users. Interacting with virtual reality and augmented reality technologies will require the development of alternative input modalities as well as coherent integration of multiple realistic sensations to increase the level of perceived realism. These developments will create a more immersive VR/AR experience. However, a lack of robust and intuitive interaction interfaces and realistic sensations hinders users' experience for achieving a fascinating acceptance in various application areas of VR/AR interactions. This workshop discusses the challenges and applications of designing a higher coherence between different input modalities and sensations to offer more engaging VR/AR experiences, which can create opportunities for the researchers from both UbiComp and VR/AR fields to jointly discuss and brainstorm alternative input modalities and sensations for VR/AR interactions.",C6130V Virtual reality,alternative input modalities;augmented reality technologies;different input modalities;intuitive interaction interfaces;MIMSVAI;modalities and sensations for VR/AR interactions;multiple input modalities;multiple realistic sensations;reality technologies;robust interaction interfaces;virtual reality,augmented reality,2022,Conference article (CA),UbiComp/ISWC'22 Adjunct: Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers,"(1) You, C.-W.; (2) Chen, Y.-C.; (3) Tsai, H.-R.; (4) Chen, C.-Y.; ","(1) National Tsing Hua University, Taiwan; (2) Shanghai Jiao Tong University, Computer Science and Engineering, China; (3) National Chengchi University, Taiwan; (4) Paris 8 University, France; ",ACM,-1,[],[],other,other,other,other,other,other alternative_input_modalities augmented_reality_technologies different_input_modalities intuitive_interaction_interfaces mimsvai modalities_and_sensations_for_vr ar_interactions multiple_input_modalities multiple_realistic_sensations reality_technologies robust_interaction_interfaces virtual_reality c6130v_virtual_reality other,other,alternative_input_modalities augmented_reality_technologies different_input_modalities intuitive_interaction_interfaces mimsvai modalities_and_sensations_for_vr ar_interactions multiple_input_modalities multiple_realistic_sensations reality_technologies robust_interaction_interfaces virtual_reality,advance vr ar technology vr ar application emerging popular among new user interacting virtual reality augmented reality technology require development alternative input modality well coherent integration multiple realistic sensation increase level perceived realism development create immersive vr ar experience however lack robust intuitive interaction interface realistic sensation hinders user experience achieving fascinating acceptance various application area vr ar interaction workshop discus challenge application designing higher coherence different input modality sensation offer engaging vr ar experience create opportunity researcher ubicomp vr ar field jointly discus brainstorm alternative input modality sensation vr ar interaction,other alternative_input_modalities augmented_reality_technologies different_input_modalities intuitive_interaction_interfaces mimsvai modalities_and_sensations_for_vr ar_interactions multiple_input_modalities multiple_realistic_sensations reality_technologies robust_interaction_interfaces virtual_reality c6130v_virtual_reality other advance vr ar technology vr ar application emerging popular among new user interacting virtual reality augmented reality technology require development alternative input modality well coherent integration multiple realistic sensation increase level perceived realism development create immersive vr ar experience however lack robust intuitive interaction interface realistic sensation hinders user experience achieving fascinating acceptance various application area vr ar interaction workshop discus challenge application designing higher coherence different input modality sensation offer engaging vr ar experience create opportunity researcher ubicomp vr ar field jointly discus brainstorm alternative input modality sensation vr ar interaction,advance vr ar technology vr ar application emerging popular among new user interacting virtual reality augmented reality technology require development alternative input modality well coherent integration multiple realistic sensation increase level perceived realism development create immersive vr ar experience however lack robust intuitive interaction interface realistic sensation hinders user experience achieving fascinating acceptance various application area vr ar interaction workshop discus challenge application designing higher coherence different input modality sensation offer engaging vr ar experience create opportunity researcher ubicomp vr ar field jointly discus brainstorm alternative input modality sensation vr ar interactionotheralternative_input_modalities augmented_reality_technologies different_input_modalities intuitive_interaction_interfaces mimsvai modalities_and_sensations_for_vr ar_interactions multiple_input_modalities multiple_realistic_sensations reality_technologies robust_interaction_interfaces virtual_reality
201,Beam tracking and image steering by Texas Instruments Phase Light Modulator based on camera input for lidar and AR applications,"Deng, X., Tang, C.-I., & Takashima, Y. (2023). Beam tracking and image steering by Texas Instruments phase light modulator based on camera input for lidar and AR applications. Emerging Digital Micromirror Device Based Systems and Applications XV. https://doi.org/10.1117/12.2651414
",10.1117/12.2651414,"Micro Electro Mechanical System (MEMS) spatial light modulators enables adaptive and fast beam and image steering. For lidar applications, Texas Instruments Phase Light Modulator (TI-PLM) is paired with real-time calculation and display of Computer Generated Holograms (CGH) by CUDA-OpenGL interoperability assisted by YOLOv4-tiny network model for object detection and recognition. The real-time object recognition, CGH calculation, and display framework replaces conventional raster scanning with camera-input based and foveated beam steering while having a beam scan rate beyond the frame rate of TI-PLM. For Augmented Reality (AR) application, the same framework is used for image steering based on gaze information of eye. With Texas Instruments Digital Micromirror Device (TI-DMD), image is steered into a part of field of view by following movement of eye. The diffractive image steering enabled by TI-DMD increases FOV while not sacrificing resolution of the image displayed. &copy; 2023 SPIE.","716.2 Radar Systems and Equipment;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;741.1 Light/Optics;741.3 Optical Devices and Systems;742.2 Photographic Equipment",Augmented reality applications;Augmented reality display;Beam-steering;Computergenerated holograms (CGH);Digital micromirror device;Image steering;MEMS (microelectromechanical system);Phase light modulator;Spatial light modulators;Texas Instruments',Application programming interfaces (API);Augmented reality;Cameras;Light modulation;Object detection;Object recognition;Optical radar;Three dimensional displays,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Deng, Xianyue; (1) Tang, Chin I.; (1) Takashima, Yuzuru; ","(1) James C. Wyant College of Optical Sciences, University of Arizona, 1630 E. University Blvd., Tucson; AZ; 85721, United States; ",SPIE,-1,"[""application programming interfaces"", ""cameras"", ""light modulation"", ""object detection"", ""object recognition"", ""optical radar"", ""three-dimensional displays""]","[""application programming interfaces"", ""cameras"", ""light modulation"", ""object detection"", ""object recognition"", ""optical radar"", ""three-dimensional displays""]",application programming interfaces;cameras;light modulation;object detection;object recognition;optical radar;three-dimensional displays,computer vision;input;optics;human factors;display technology;developers;geospatial,technology;displays;end users and user experience,computer vision;input;optics;human factors;display technology;developers;geospatial,technology;displays;end users and user experience,application_programming_interfaces cameras light_modulation object_detection object_recognition optical_radar three dimensional_displays augmented_reality_applications augmented_reality_display beam steering computergenerated_holograms_ cgh digital_micromirror_device image_steering mems_ microelectromechanical_system phase_light_modulator spatial_light_modulators texas_instruments 716 2_radar_systems_and_equipment 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 741 3_optical_devices_and_systems 742 2_photographic_equipment computer_vision input optics human_factors display_technology developers geospatial,application_programming_interfaces cameras light_modulation object_detection object_recognition optical_radar three dimensional_displays,augmented_reality_applications augmented_reality_display beam steering computergenerated_holograms_ cgh digital_micromirror_device image_steering mems_ microelectromechanical_system phase_light_modulator spatial_light_modulators texas_instruments,micro electro mechanical system mem spatial light modulators enables adaptive fast beam image steering lidar application texas instrument phase light modulator ti plm paired real time calculation display computer generated hologram cgh cuda opengl interoperability assisted yolov4 tiny network model object detection recognition real time object recognition cgh calculation display framework replaces conventional raster scanning camera input based foveated beam steering beam scan rate beyond frame rate ti plm augmented reality ar application framework used image steering based gaze information eye texas instrument digital micromirror device ti dmd image steered part field view following movement eye diffractive image steering enabled ti dmd increase fov sacrificing resolution image displayed copy 2023 spie,application_programming_interfaces cameras light_modulation object_detection object_recognition optical_radar three dimensional_displays augmented_reality_applications augmented_reality_display beam steering computergenerated_holograms_ cgh digital_micromirror_device image_steering mems_ microelectromechanical_system phase_light_modulator spatial_light_modulators texas_instruments 716 2_radar_systems_and_equipment 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 741 3_optical_devices_and_systems 742 2_photographic_equipment computer_vision input optics human_factors display_technology developers geospatial micro electro mechanical system mem spatial light modulators enables adaptive fast beam image steering lidar application texas instrument phase light modulator ti plm paired real time calculation display computer generated hologram cgh cuda opengl interoperability assisted yolov4 tiny network model object detection recognition real time object recognition cgh calculation display framework replaces conventional raster scanning camera input based foveated beam steering beam scan rate beyond frame rate ti plm augmented reality ar application framework used image steering based gaze information eye texas instrument digital micromirror device ti dmd image steered part field view following movement eye diffractive image steering enabled ti dmd increase fov sacrificing resolution image displayed copy 2023 spie,micro electro mechanical system mem spatial light modulators enables adaptive fast beam image steering lidar application texas instrument phase light modulator ti plm paired real time calculation display computer generated hologram cgh cuda opengl interoperability assisted yolov4 tiny network model object detection recognition real time object recognition cgh calculation display framework replaces conventional raster scanning camera input based foveated beam steering beam scan rate beyond frame rate ti plm augmented reality ar application framework used image steering based gaze information eye texas instrument digital micromirror device ti dmd image steered part field view following movement eye diffractive image steering enabled ti dmd increase fov sacrificing resolution image displayed copy 2023 spieapplication_programming_interfaces cameras light_modulation object_detection object_recognition optical_radar three dimensional_displaysaugmented_reality_applications augmented_reality_display beam steering computergenerated_holograms_ cgh digital_micromirror_device image_steering mems_ microelectromechanical_system phase_light_modulator spatial_light_modulators texas_instruments
202,Flying Names: Manipulating Name Tags in XR Social Environments for Target Selection Tasks,"Wang, F., Chang, C.-M., & Igarashi, T. (2023). Flying Names: Manipulating Name Tags in XR Social Environments for Target Selection Tasks. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585677
",10.1145/3544549.3585677,"Recent developments in Extended Reality (XR) have led to the creation of various Virtual Reality (VR) social applications that allow small groups of people to interact and participate in various activities. However, these applications are not suitable for larger-scale social scenarios. One major challenge is the lacking of effective solutions for target selection because existing methods for occluded-target selection do not apply well to humans. In this paper, we propose a method called ""Flying Names"" to improve decision-making accuracy during target selection for both VR and Augmented Reality (AR) social environments by manipulating the heights of name tags on the fly and connecting an auxiliary line from a name tag to its highlighted owner. Our user study results indicate that this proposal effectively improves the accuracy of identifying the actual target person and is better than using either one or none of manipulating heights and connecting lines.",C6130V Virtual reality,actual target person;augmented reality social environments;decision-making accuracy;extended reality;flying names;name tag;name tag manipulation;occluded-target selection;target selection tasks;virtual reality social applications;XR social environments,augmented reality;decision making,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Wang, F.; (1) Chang, C.-M.; (1) Igarashi, T.; ","(1) University of Tokyo, Japan; ",ACM,-1,"[""decision making""]","[""decision making""]",decision making,human factors,end users and user experience,human factors,end users and user experience,decision_making actual_target_person augmented_reality_social_environments decision making_accuracy extended_reality flying_names name_tag name_tag_manipulation occluded target_selection target_selection_tasks virtual_reality_social_applications xr_social_environments c6130v_virtual_reality human_factors,decision_making,actual_target_person augmented_reality_social_environments decision making_accuracy extended_reality flying_names name_tag name_tag_manipulation occluded target_selection target_selection_tasks virtual_reality_social_applications xr_social_environments,recent development extended reality xr led creation various virtual reality vr social application allow small group people interact participate various activity however application suitable larger scale social scenario one major challenge lacking effective solution target selection existing method occluded target selection apply well human paper propose method called flying name improve decision making accuracy target selection vr augmented reality ar social environment manipulating height name tag fly connecting auxiliary line name tag highlighted owner user study result indicate proposal effectively improves accuracy identifying actual target person better using either one none manipulating height connecting line,decision_making actual_target_person augmented_reality_social_environments decision making_accuracy extended_reality flying_names name_tag name_tag_manipulation occluded target_selection target_selection_tasks virtual_reality_social_applications xr_social_environments c6130v_virtual_reality human_factors recent development extended reality xr led creation various virtual reality vr social application allow small group people interact participate various activity however application suitable larger scale social scenario one major challenge lacking effective solution target selection existing method occluded target selection apply well human paper propose method called flying name improve decision making accuracy target selection vr augmented reality ar social environment manipulating height name tag fly connecting auxiliary line name tag highlighted owner user study result indicate proposal effectively improves accuracy identifying actual target person better using either one none manipulating height connecting line,recent development extended reality xr led creation various virtual reality vr social application allow small group people interact participate various activity however application suitable larger scale social scenario one major challenge lacking effective solution target selection existing method occluded target selection apply well human paper propose method called flying name improve decision making accuracy target selection vr augmented reality ar social environment manipulating height name tag fly connecting auxiliary line name tag highlighted owner user study result indicate proposal effectively improves accuracy identifying actual target person better using either one none manipulating height connecting linedecision_makingactual_target_person augmented_reality_social_environments decision making_accuracy extended_reality flying_names name_tag name_tag_manipulation occluded target_selection target_selection_tasks virtual_reality_social_applications xr_social_environments
203,Blended Collaboration: Communication and Cooperation Between Two Users Across the Reality-Virtuality Continuum,"Kruse, L., Wittig, J., Finnern, S., Gundlach, M., Iserlohe, N., Ariza, O., & Steinicke, F. (2023). Blended Collaboration: Communication and Cooperation Between Two Users Across the Reality-Virtuality Continuum. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585881
",10.1145/3544549.3585881,"Mixed reality (MR) technologies provide enormous potential for collaboration between multiple users across the Reality-Virtuality continuum. We evaluate communication in a MR-based two-user collaboration task, in which the users have to move an object through an obstacle without collision. We used a blended reality environment, in which one user is immersed in virtual reality, whereas the other uses mobile augmented reality. Both users have different abilities and information and mutually depend on each other for successful completion of the task. Communication consensus can either be achieved by using speech, visual widgets, or a combination of both. The results indicate that speech plays a fundamental role. The usage of widgets served as an extension rather than a replacement of language. However, the combination of speech and widgets improved the clearness of communication with less miscommunication. These results provide important indications about how to design blended collaboration across the Reality-Virtuality continuum.",C6130V Virtual reality;C6130G Groupware;C6180 User interfaces,blended collaboration;blended reality environment;communication consensus;mixed reality technologies;mobile augmented reality;MR technologies;multiple users;reality-virtuality continuum;two-user collaboration task;virtual reality;visual widgets,augmented reality;groupware;mobile computing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Kruse, L.; (1) Wittig, J.; (1) Finnern, S.; (1) Gundlach, M.; (1) Iserlohe, N.; (2) Ariza, O.; (1) Steinicke, F.; ","(1) Human-Computer Interaction, Germany; (2) Universita&#776;t Hamburg, Germany; ",ACM,-1,"[""groupware"", ""mobile computing""]","[""groupware"", ""mobile computing""]",groupware;mobile computing,telecommunication;collaboration,use cases;industries,telecommunication;collaboration,use cases;industries,groupware mobile_computing blended_collaboration blended_reality_environment communication_consensus mixed_reality_technologies mobile_augmented_reality mr_technologies multiple_users reality virtuality_continuum two user_collaboration_task virtual_reality visual_widgets c6130v_virtual_reality c6130g_groupware c6180_user_interfaces telecommunication collaboration,groupware mobile_computing,blended_collaboration blended_reality_environment communication_consensus mixed_reality_technologies mobile_augmented_reality mr_technologies multiple_users reality virtuality_continuum two user_collaboration_task virtual_reality visual_widgets,mixed reality mr technology provide enormous potential collaboration multiple user across reality virtuality continuum evaluate communication mr based two user collaboration task user move object obstacle without collision used blended reality environment one user immersed virtual reality whereas us mobile augmented reality user different ability information mutually depend successful completion task communication consensus either achieved using speech visual widget combination result indicate speech play fundamental role usage widget served extension rather replacement language however combination speech widget improved clearness communication le miscommunication result provide important indication design blended collaboration across reality virtuality continuum,groupware mobile_computing blended_collaboration blended_reality_environment communication_consensus mixed_reality_technologies mobile_augmented_reality mr_technologies multiple_users reality virtuality_continuum two user_collaboration_task virtual_reality visual_widgets c6130v_virtual_reality c6130g_groupware c6180_user_interfaces telecommunication collaboration mixed reality mr technology provide enormous potential collaboration multiple user across reality virtuality continuum evaluate communication mr based two user collaboration task user move object obstacle without collision used blended reality environment one user immersed virtual reality whereas us mobile augmented reality user different ability information mutually depend successful completion task communication consensus either achieved using speech visual widget combination result indicate speech play fundamental role usage widget served extension rather replacement language however combination speech widget improved clearness communication le miscommunication result provide important indication design blended collaboration across reality virtuality continuum,mixed reality mr technology provide enormous potential collaboration multiple user across reality virtuality continuum evaluate communication mr based two user collaboration task user move object obstacle without collision used blended reality environment one user immersed virtual reality whereas us mobile augmented reality user different ability information mutually depend successful completion task communication consensus either achieved using speech visual widget combination result indicate speech play fundamental role usage widget served extension rather replacement language however combination speech widget improved clearness communication le miscommunication result provide important indication design blended collaboration across reality virtuality continuumgroupware mobile_computingblended_collaboration blended_reality_environment communication_consensus mixed_reality_technologies mobile_augmented_reality mr_technologies multiple_users reality virtuality_continuum two user_collaboration_task virtual_reality visual_widgets
204,Is Education Ready To Embrace Metaverse?,"Ktoridou, D., Epaminonda, E., & Efthymiou, L. (2023). Is Education Ready To Embrace Metaverse? 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125182
",10.1109/EDUCON54358.2023.10125182,"Metaverse, an immersive virtual world that is facilitated by the use of virtual reality (VR) and augmented reality (AR), is expected to be soon part of our lives. Indeed, in some areas, such as in the game industry, this revolutionary technology is already being used. In the context of education, however, metaverse is not yet being extensively utilized and its possible usage is currently being debated. To contribute to this debate, the current study explores students' and educators' perceptions of metaverse and its potential to be used in education. To study these questions a mixed research approach was employed combining both quantitative and qualitative data collection. Specifically, an online questionnaire was distributed to students and semi structured interviews have been conducted with lecturers. Results suggest that students and teachers have a relatively good understanding of metaverse and foresee its utilization in education in the next few years. They remain open about the extent to which this will happen and divided as how fundamental a change it will be.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C7810C Computer-aided instruction;C7830D Computer games,augmented reality;education ready;educators;embrace metaverse;game industry;immersive virtual world;qualitative data collection;quantitative data collection;revolutionary technology,augmented reality;computer aided instruction;computer games;virtual reality,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Ktoridou, D.; (1) Epaminonda, E.; (1) Efthymiou, L.; ","(1) University of Nicosia, Department of Management, Cyprus; ",IEEE,-1,"[""computer aided instruction"", ""computer games""]","[""computer aided instruction"", ""computer games""]",computer aided instruction;computer games,training;liberal arts,use cases;industries,training;liberal arts,use cases;industries,computer_aided_instruction computer_games augmented_reality education_ready educators embrace_metaverse game_industry immersive_virtual_world qualitative_data_collection quantitative_data_collection revolutionary_technology c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction c7830d_computer_games training liberal_arts,computer_aided_instruction computer_games,augmented_reality education_ready educators embrace_metaverse game_industry immersive_virtual_world qualitative_data_collection quantitative_data_collection revolutionary_technology,metaverse immersive virtual world facilitated use virtual reality vr augmented reality ar expected soon part life indeed area game industry revolutionary technology already used context education however metaverse yet extensively utilized possible usage currently debated contribute debate current study explores student educator perception metaverse potential used education study question mixed research approach employed combining quantitative qualitative data collection specifically online questionnaire distributed student semi structured interview conducted lecturer result suggest student teacher relatively good understanding metaverse foresee utilization education next year remain open extent happen divided fundamental change,computer_aided_instruction computer_games augmented_reality education_ready educators embrace_metaverse game_industry immersive_virtual_world qualitative_data_collection quantitative_data_collection revolutionary_technology c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction c7830d_computer_games training liberal_arts metaverse immersive virtual world facilitated use virtual reality vr augmented reality ar expected soon part life indeed area game industry revolutionary technology already used context education however metaverse yet extensively utilized possible usage currently debated contribute debate current study explores student educator perception metaverse potential used education study question mixed research approach employed combining quantitative qualitative data collection specifically online questionnaire distributed student semi structured interview conducted lecturer result suggest student teacher relatively good understanding metaverse foresee utilization education next year remain open extent happen divided fundamental change,metaverse immersive virtual world facilitated use virtual reality vr augmented reality ar expected soon part life indeed area game industry revolutionary technology already used context education however metaverse yet extensively utilized possible usage currently debated contribute debate current study explores student educator perception metaverse potential used education study question mixed research approach employed combining quantitative qualitative data collection specifically online questionnaire distributed student semi structured interview conducted lecturer result suggest student teacher relatively good understanding metaverse foresee utilization education next year remain open extent happen divided fundamental changecomputer_aided_instruction computer_gamesaugmented_reality education_ready educators embrace_metaverse game_industry immersive_virtual_world qualitative_data_collection quantitative_data_collection revolutionary_technology
205,UX in AR-Supported Industrial Human-Robot Collaborative Tasks: A Systematic Review,"Khamaisi, R. K., Prati, E., Peruzzini, M., Raffaeli, R., & Pellicciari, M. (2021). UX in AR-Supported Industrial Human–Robot Collaborative Tasks: A Systematic Review. Applied Sciences, 11(21), 10448. https://doi.org/10.3390/app112110448
",10.3390/app112110448,"The fourth industrial revolution is promoting the Operator 4.0 paradigm, originating from a renovated attention towards human factors, growingly involved in the design of modern, human-centered processes. New technologies, such as augmented reality or collaborative robotics are thus increasingly studied and progressively applied to solve the modern operators' needs. Human-centered design approaches can help to identify user's needs and functional requirements, solving usability issues, or reducing cognitive or physical stress. The paper reviews the recent literature on augmented reality-supported collaborative robotics from a human-centered perspective. To this end, the study analyzed 21 papers selected after a quality assessment procedure and remarks the poor adoption of user-centered approaches and methodologies to drive the development of human-centered augmented reality applications to promote an efficient collaboration between humans and robots. To remedy this deficiency, the paper ultimately proposes a structured framework driven by User eXperience approaches to design augmented reality interfaces by encompassing previous research works. Future developments are discussed, stimulating fruitful reflections and a decisive standardization process.",C7160 Manufacturing and industrial administration;C0140 Ergonomic aspects of control and robotics;C6130V Virtual reality;C6180R Human-robot interaction;C7480 Production engineering computing;E0410D Industrial applications of IT;E1410 Ergonomics;E1550A Robotics,AR-supported industrial human-robot collaborative tasks;augmented reality interfaces;augmented reality-supported collaborative robotics;fourth industrial revolution;human factors;human-centered augmented reality applications;human-centered design;Operator 4.0 paradigm;user experience approaches;UX,augmented reality;human-robot interaction;industrial robots;production engineering computing;user centred design;user experience,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Khamaisi, R.K.; (1) Prati, E.; (1) Peruzzini, M.; (2) Raffaeli, R.; (2) Pellicciari, M.; ","(1) University of Modena and Reggio Emilia, Department of Engineering Enzo Ferrari, Italy; (2) University of Modena and Reggio Emilia, Department of Sciences and Methods for Engineering, Italy; ",MDPI,-1,"[""human-robot interaction"", ""industrial robots"", ""production engineering computing"", ""user centered design"", ""user experience""]","[""human-robot interaction"", ""industrial robots"", ""production engineering computing"", ""user centered design"", ""user experience""]",human-robot interaction;industrial robots;production engineering computing;user centered design;user experience,robotics;human factors;engineering;developers;human-computer interaction;manufacturing,technology;industries;end users and user experience,robotics;human factors;engineering;developers;human-computer interaction;manufacturing,technology;industries;end users and user experience,human robot_interaction industrial_robots production_engineering_computing user_centered_design user_experience ar supported_industrial_human robot_collaborative_tasks augmented_reality_interfaces augmented_reality supported_collaborative_robotics fourth_industrial_revolution human_factors human centered_augmented_reality_applications human centered_design operator_4 0_paradigm user_experience_approaches ux c7160_manufacturing_and_industrial_administration c0140_ergonomic_aspects_of_control_and_robotics c6130v_virtual_reality c6180r_human robot_interaction c7480_production_engineering_computing e0410d_industrial_applications_of_it e1410_ergonomics e1550a_robotics robotics human_factors engineering developers human computer_interaction manufacturing,human robot_interaction industrial_robots production_engineering_computing user_centered_design user_experience,ar supported_industrial_human robot_collaborative_tasks augmented_reality_interfaces augmented_reality supported_collaborative_robotics fourth_industrial_revolution human_factors human centered_augmented_reality_applications human centered_design operator_4 0_paradigm user_experience_approaches ux,fourth industrial revolution promoting operator 4 0 paradigm originating renovated attention towards human factor growingly involved design modern human centered process new technology augmented reality collaborative robotics thus increasingly studied progressively applied solve modern operator need human centered design approach help identify user need functional requirement solving usability issue reducing cognitive physical stress paper review recent literature augmented reality supported collaborative robotics human centered perspective end study analyzed 21 paper selected quality assessment procedure remark poor adoption user centered approach methodology drive development human centered augmented reality application promote efficient collaboration human robot remedy deficiency paper ultimately proposes structured framework driven user experience approach design augmented reality interface encompassing previous research work future development discussed stimulating fruitful reflection decisive standardization process,human robot_interaction industrial_robots production_engineering_computing user_centered_design user_experience ar supported_industrial_human robot_collaborative_tasks augmented_reality_interfaces augmented_reality supported_collaborative_robotics fourth_industrial_revolution human_factors human centered_augmented_reality_applications human centered_design operator_4 0_paradigm user_experience_approaches ux c7160_manufacturing_and_industrial_administration c0140_ergonomic_aspects_of_control_and_robotics c6130v_virtual_reality c6180r_human robot_interaction c7480_production_engineering_computing e0410d_industrial_applications_of_it e1410_ergonomics e1550a_robotics robotics human_factors engineering developers human computer_interaction manufacturing fourth industrial revolution promoting operator 4 0 paradigm originating renovated attention towards human factor growingly involved design modern human centered process new technology augmented reality collaborative robotics thus increasingly studied progressively applied solve modern operator need human centered design approach help identify user need functional requirement solving usability issue reducing cognitive physical stress paper review recent literature augmented reality supported collaborative robotics human centered perspective end study analyzed 21 paper selected quality assessment procedure remark poor adoption user centered approach methodology drive development human centered augmented reality application promote efficient collaboration human robot remedy deficiency paper ultimately proposes structured framework driven user experience approach design augmented reality interface encompassing previous research work future development discussed stimulating fruitful reflection decisive standardization process,fourth industrial revolution promoting operator 4 0 paradigm originating renovated attention towards human factor growingly involved design modern human centered process new technology augmented reality collaborative robotics thus increasingly studied progressively applied solve modern operator need human centered design approach help identify user need functional requirement solving usability issue reducing cognitive physical stress paper review recent literature augmented reality supported collaborative robotics human centered perspective end study analyzed 21 paper selected quality assessment procedure remark poor adoption user centered approach methodology drive development human centered augmented reality application promote efficient collaboration human robot remedy deficiency paper ultimately proposes structured framework driven user experience approach design augmented reality interface encompassing previous research work future development discussed stimulating fruitful reflection decisive standardization processhuman robot_interaction industrial_robots production_engineering_computing user_centered_design user_experiencear supported_industrial_human robot_collaborative_tasks augmented_reality_interfaces augmented_reality supported_collaborative_robotics fourth_industrial_revolution human_factors human centered_augmented_reality_applications human centered_design operator_4 0_paradigm user_experience_approaches ux
206,Realistic visualization of debris flow type landslides through virtual reality,"Alene, G. H., Vicari, H., Irshad, S., Perkis, A., Bruland, O., & Thakur, V. (2022). Realistic visualization of debris flow type landslides through virtual reality. Landslides, 20(1), 13–23. https://doi.org/10.1007/s10346-022-01948-x
",10.1007/s10346-022-01948-x,"Immersive media technologies, such as virtual and augmented reality, have recently enabled a more holistic way to comprehend natural hazards. In this work, we aim at visualizing the temporal and spatial evolution of a debris flow in a virtual reality environment. We develop a framework to integrate the output results obtained from a debris flow numerical model into virtual reality. To guide the framework, a real debris flow event, which happened in Hunnedalen (Norway) in 2016 and blocked a road network, is considered as a case study. The debris flow is back-calculated using a depth-averaged numerical model and the simulation results are imported into a dedicated game engine to construct a digital model of the debris flow event. The debris flow is visualized using a Head-Mounted Display. We therefore discuss a wide range of potential applications of virtual reality to manage and grasp landslide phenomena: training for rescue operations; improving decision-making; studying early warning systems, and educating communities affected by natural hazards. We finally provide a quantitative evaluation of the hazard perception for a road user. We show that the debris flow movement is perceived at variable delayed times from the triggering of the landslide, depending on the position along the road where the debris flow is observed. Evaluating the realistic perception time of the natural hazard may be fundamental to designing more effective road networks, signs, and mitigation measures.",C6130V Virtual reality;C1140E Game theory;C5540D Computer displays,augmented reality;debris flow numerical model;debris flow type;depth-averaged numerical model;head-mounted display;virtual reality environment,augmented reality;decision making;hazards;helmet mounted displays;virtual reality,2023,Journal article (JA),Landslides (Germany),"(1) Alene, G.H.; (3) Vicari, H.; (2) Irshad, S.; (2) Perkis, A.; (1) Bruland, O.; (1) Thakur, V.; ","(1) University of Science and Technology, Faculty of Information Engineering, Norway; (2) Norwegian University of Science and Technology, Department of Electronic Systems, Norway; (3) Norwegian Geotechnical Institute, Natural Hazards Division, Norway; ",Springer,-1,"[""decision making"", ""hazards"", ""helmet mounted displays""]","[""decision making"", ""hazards"", ""helmet mounted displays""]",decision making;hazards;helmet mounted displays,"display technology;human factors;wearables;inspection, safety and quality",displays;use cases;end users and user experience,"display technology;human factors;wearables;inspection, safety and quality",displays;use cases;end users and user experience,decision_making hazards helmet_mounted_displays augmented_reality debris_flow_numerical_model debris_flow_type depth averaged_numerical_model head mounted_display virtual_reality_environment c6130v_virtual_reality c1140e_game_theory c5540d_computer_displays display_technology human_factors wearables inspection _safety_and_quality,decision_making hazards helmet_mounted_displays,augmented_reality debris_flow_numerical_model debris_flow_type depth averaged_numerical_model head mounted_display virtual_reality_environment,immersive medium technology virtual augmented reality recently enabled holistic way comprehend natural hazard work aim visualizing temporal spatial evolution debris flow virtual reality environment develop framework integrate output result obtained debris flow numerical model virtual reality guide framework real debris flow event happened hunnedalen norway 2016 blocked road network considered case study debris flow back calculated using depth averaged numerical model simulation result imported dedicated game engine construct digital model debris flow event debris flow visualized using head mounted display therefore discus wide range potential application virtual reality manage grasp landslide phenomenon training rescue operation improving decision making studying early warning system educating community affected natural hazard finally provide quantitative evaluation hazard perception road user show debris flow movement perceived variable delayed time triggering landslide depending position along road debris flow observed evaluating realistic perception time natural hazard may fundamental designing effective road network sign mitigation measure,decision_making hazards helmet_mounted_displays augmented_reality debris_flow_numerical_model debris_flow_type depth averaged_numerical_model head mounted_display virtual_reality_environment c6130v_virtual_reality c1140e_game_theory c5540d_computer_displays display_technology human_factors wearables inspection _safety_and_quality immersive medium technology virtual augmented reality recently enabled holistic way comprehend natural hazard work aim visualizing temporal spatial evolution debris flow virtual reality environment develop framework integrate output result obtained debris flow numerical model virtual reality guide framework real debris flow event happened hunnedalen norway 2016 blocked road network considered case study debris flow back calculated using depth averaged numerical model simulation result imported dedicated game engine construct digital model debris flow event debris flow visualized using head mounted display therefore discus wide range potential application virtual reality manage grasp landslide phenomenon training rescue operation improving decision making studying early warning system educating community affected natural hazard finally provide quantitative evaluation hazard perception road user show debris flow movement perceived variable delayed time triggering landslide depending position along road debris flow observed evaluating realistic perception time natural hazard may fundamental designing effective road network sign mitigation measure,immersive medium technology virtual augmented reality recently enabled holistic way comprehend natural hazard work aim visualizing temporal spatial evolution debris flow virtual reality environment develop framework integrate output result obtained debris flow numerical model virtual reality guide framework real debris flow event happened hunnedalen norway 2016 blocked road network considered case study debris flow back calculated using depth averaged numerical model simulation result imported dedicated game engine construct digital model debris flow event debris flow visualized using head mounted display therefore discus wide range potential application virtual reality manage grasp landslide phenomenon training rescue operation improving decision making studying early warning system educating community affected natural hazard finally provide quantitative evaluation hazard perception road user show debris flow movement perceived variable delayed time triggering landslide depending position along road debris flow observed evaluating realistic perception time natural hazard may fundamental designing effective road network sign mitigation measuredecision_making hazards helmet_mounted_displaysaugmented_reality debris_flow_numerical_model debris_flow_type depth averaged_numerical_model head mounted_display virtual_reality_environment
207,Virtual and Augmented Experience in Virtual Learning Tours &dagger;,"Bosmos, F., Tzallas, A. T., Tsipouras, M. G., Glavas, E., & Giannakeas, N. (2023). Virtual and Augmented Experience in Virtual Learning Tours. Information, 14(5), 294. https://doi.org/10.3390/info14050294
",10.3390/info14050294,"The aim of this work is to highlight the possibilities of using VR applications in the informal learning process. This is attempted through the development of virtual reality cultural applications for historical monuments. For this purpose, the theoretical framework of virtual and augmented reality techniques is presented, developing as a showcase of the virtual environment of the historical bridge of Arta, in Greece. The bridge model is created through 3D software, which is then imported into virtual world environment by employing the Unity engine. The main objective of the research is the technical and empirical evaluation of the VR application by specialists, in comparison with the real environment of the monument. Accordingly, the use of the application in the learning process is evaluated by high school students. Using the conclusions of the evaluation, the environment will be enriched with multimedia elements and the application will be evaluated by secondary school students as a learning experience and process, using electroencephalography (EEG). The recording and analysis of research results can be generalized and lead to safe conclusions for the use of similar applications in the field of culture and learning. &copy; 2023 by the authors.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing",Cultural technology;Digital destination;Historical monuments;Informal learning;Learning process;Theoretical framework;Virtual and augmented reality;Virtual learning;Virtual learning tour;VR applications,3D modeling;Augmented reality;E-learning;Electroencephalography;Electrophysiology;Learning systems,2023,Journal article (JA),Information,"(1) Bosmos, Fotios; (1) Tzallas, Alexandros T.; (2) Tsipouras, Markos G.; (1) Glavas, Evripidis; (1) Giannakeas, Nikolaos; ","(1) Department of Informatics and Telecommunications, University of Ioannina, Arta; GR47150, Greece; (2) Department of Electrical and Computer Engineering, University of Western Macedonia, Kozani; GR50100, Greece; ",MDPI,-1,"[""3d modeling"", ""e-learning"", ""electroencephalography"", ""electrophysiology"", ""learning systems""]","[""3d modeling"", ""e-learning"", ""electroencephalography"", ""electrophysiology"", ""learning systems""]",3d modeling;e-learning;electroencephalography;electrophysiology;learning systems,medical;education;manufacturing,industries,medical;education;manufacturing,industries,3d_modeling e learning electroencephalography electrophysiology learning_systems cultural_technology digital_destination historical_monuments informal_learning learning_process theoretical_framework virtual_and_augmented_reality virtual_learning virtual_learning_tour vr_applications 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing medical education manufacturing,3d_modeling e learning electroencephalography electrophysiology learning_systems,cultural_technology digital_destination historical_monuments informal_learning learning_process theoretical_framework virtual_and_augmented_reality virtual_learning virtual_learning_tour vr_applications,aim work highlight possibility using vr application informal learning process attempted development virtual reality cultural application historical monument purpose theoretical framework virtual augmented reality technique presented developing showcase virtual environment historical bridge arta greece bridge model created 3d software imported virtual world environment employing unity engine main objective research technical empirical evaluation vr application specialist comparison real environment monument accordingly use application learning process evaluated high school student using conclusion evaluation environment enriched multimedia element application evaluated secondary school student learning experience process using electroencephalography eeg recording analysis research result generalized lead safe conclusion use similar application field culture learning copy 2023 author,3d_modeling e learning electroencephalography electrophysiology learning_systems cultural_technology digital_destination historical_monuments informal_learning learning_process theoretical_framework virtual_and_augmented_reality virtual_learning virtual_learning_tour vr_applications 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing medical education manufacturing aim work highlight possibility using vr application informal learning process attempted development virtual reality cultural application historical monument purpose theoretical framework virtual augmented reality technique presented developing showcase virtual environment historical bridge arta greece bridge model created 3d software imported virtual world environment employing unity engine main objective research technical empirical evaluation vr application specialist comparison real environment monument accordingly use application learning process evaluated high school student using conclusion evaluation environment enriched multimedia element application evaluated secondary school student learning experience process using electroencephalography eeg recording analysis research result generalized lead safe conclusion use similar application field culture learning copy 2023 author,aim work highlight possibility using vr application informal learning process attempted development virtual reality cultural application historical monument purpose theoretical framework virtual augmented reality technique presented developing showcase virtual environment historical bridge arta greece bridge model created 3d software imported virtual world environment employing unity engine main objective research technical empirical evaluation vr application specialist comparison real environment monument accordingly use application learning process evaluated high school student using conclusion evaluation environment enriched multimedia element application evaluated secondary school student learning experience process using electroencephalography eeg recording analysis research result generalized lead safe conclusion use similar application field culture learning copy 2023 author3d_modeling e learning electroencephalography electrophysiology learning_systemscultural_technology digital_destination historical_monuments informal_learning learning_process theoretical_framework virtual_and_augmented_reality virtual_learning virtual_learning_tour vr_applications
208,A View Direction-Driven Approach for Automatic Room Mapping in Mixed Reality,"Kim, D. J., & Li, W. (2023). A View Direction-Driven Approach for Automatic Room Mapping in Mixed Reality. Proceedings of the 2023 5th International Conference on Image Processing and Machine Vision. https://doi.org/10.1145/3582177.3582183
",10.1145/3582177.3582183,"Virtual Reality and Augmented Reality technologies have greatly improved recently, and developers are trying to make the experience as realistic as possible and close the gap between the physical world and the virtual world. In this paper, we propose an efficient and intuitive method to create an immersive Mixed Reality environment by automatically mapping your room. Our method is view direction driven, which allows the users to simply ""look at"" any indoor space to create a 3-dimensional model of the area the user is located in. This approach is easier and more intuitive for the users to use and reduces the time and effort compared to other MR environment generating methods. We use the Meta Quest 2's cameras and gyroscope sensor and the Unity engine for the ray casting and the passthrough API. We will present the mathematical details of our method and show that the proposed method achieves better results than previous methods through the user study results.",C6130V Virtual reality;C6130B Graphics techniques;C6180 User interfaces,3-dimensional model;Augmented Reality technologies;automatic room mapping;efficient method;immersive Mixed Reality environment;indoor space;intuitive method;Meta Quest 2;MR environment generating methods;physical world;user study results;view direction-driven approach;Virtual Reality;virtual world,augmented reality;gyroscopes;virtual reality,2023,Conference article (CA),IPMV '23: Proceedings of the 2023 5th International Conference on Image Processing and Machine Vision,"(1) Kim, D.J.; (1) Li, W.; ","(1) University of South Florida, Tampa, FL, United States; ",ACM,-1,"[""gyroscopes""]","[""gyroscopes""]",gyroscopes,input,technology,input,technology,gyroscopes 3 dimensional_model augmented_reality_technologies automatic_room_mapping efficient_method immersive_mixed_reality_environment indoor_space intuitive_method meta_quest_2 mr_environment_generating_methods physical_world user_study_results view_direction driven_approach virtual_reality virtual_world c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces input,gyroscopes,3 dimensional_model augmented_reality_technologies automatic_room_mapping efficient_method immersive_mixed_reality_environment indoor_space intuitive_method meta_quest_2 mr_environment_generating_methods physical_world user_study_results view_direction driven_approach virtual_reality virtual_world,virtual reality augmented reality technology greatly improved recently developer trying make experience realistic possible close gap physical world virtual world paper propose efficient intuitive method create immersive mixed reality environment automatically mapping room method view direction driven allows user simply look indoor space create 3 dimensional model area user located approach easier intuitive user use reduces time effort compared mr environment generating method use meta quest 2 camera gyroscope sensor unity engine ray casting passthrough api present mathematical detail method show proposed method achieves better result previous method user study result,gyroscopes 3 dimensional_model augmented_reality_technologies automatic_room_mapping efficient_method immersive_mixed_reality_environment indoor_space intuitive_method meta_quest_2 mr_environment_generating_methods physical_world user_study_results view_direction driven_approach virtual_reality virtual_world c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces input virtual reality augmented reality technology greatly improved recently developer trying make experience realistic possible close gap physical world virtual world paper propose efficient intuitive method create immersive mixed reality environment automatically mapping room method view direction driven allows user simply look indoor space create 3 dimensional model area user located approach easier intuitive user use reduces time effort compared mr environment generating method use meta quest 2 camera gyroscope sensor unity engine ray casting passthrough api present mathematical detail method show proposed method achieves better result previous method user study result,virtual reality augmented reality technology greatly improved recently developer trying make experience realistic possible close gap physical world virtual world paper propose efficient intuitive method create immersive mixed reality environment automatically mapping room method view direction driven allows user simply look indoor space create 3 dimensional model area user located approach easier intuitive user use reduces time effort compared mr environment generating method use meta quest 2 camera gyroscope sensor unity engine ray casting passthrough api present mathematical detail method show proposed method achieves better result previous method user study resultgyroscopes3 dimensional_model augmented_reality_technologies automatic_room_mapping efficient_method immersive_mixed_reality_environment indoor_space intuitive_method meta_quest_2 mr_environment_generating_methods physical_world user_study_results view_direction driven_approach virtual_reality virtual_world
209,Online Learning for Network Resource Allocation,"Salem, T. S. (2022). Online Learning for Network Resource Allocation. ACM SIGMETRICS Performance Evaluation Review, 50(3), 20–23. https://doi.org/10.1145/3579342.3579348
",10.1145/3579342.3579348,"Motivation. Connectivity and ubiquity of computing devices enabled a wide spectrum of network applications such as content delivery, interpersonal communication, and intervehicular communication. New use cases (e.g., autonomous driving, augmented reality, and tactile internet) require satisfying user-generated and machine-generated demand with stringent low-latency and high-bandwidth guarantees.","B6210L Computer communications;B6250F Mobile radio systems;C5620 Computer networks and techniques;C5620W Other computer networks;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7210N Information networks",augmented reality;autonomous driving;computing devices;content delivery;interpersonal communication;intervehicular communication;network applications;network resource allocation;online learning;satisfying user-generated;tactile internet,5G mobile communication;augmented reality;Internet;resource allocation,2022,Journal article (JA),ACM SIGMETRICS Perform. Eval. Rev. (USA),"(1) Salem, T.S.; ","(1) Universite&#769; Co&#770;te d'Azur, France; ",ACM,-1,"[""5g mobile communication"", ""internet"", ""resource allocation""]","[""5g mobile communication"", ""internet"", ""resource allocation""]",5g mobile communication;internet;resource allocation,input;telecommunication;geospatial;business planning and management;networks,technology;business;industries,input;telecommunication;geospatial;business planning and management;networks,technology;business;industries,5g_mobile_communication internet resource_allocation augmented_reality autonomous_driving computing_devices content_delivery interpersonal_communication intervehicular_communication network_applications network_resource_allocation online_learning satisfying_user generated tactile_internet b6210l_computer_communications b6250f_mobile_radio_systems c5620_computer_networks_and_techniques c5620w_other_computer_networks c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks input telecommunication geospatial business_planning_and_management networks,5g_mobile_communication internet resource_allocation,augmented_reality autonomous_driving computing_devices content_delivery interpersonal_communication intervehicular_communication network_applications network_resource_allocation online_learning satisfying_user generated tactile_internet,motivation connectivity ubiquity computing device enabled wide spectrum network application content delivery interpersonal communication intervehicular communication new use case e g autonomous driving augmented reality tactile internet require satisfying user generated machine generated demand stringent low latency high bandwidth guarantee,5g_mobile_communication internet resource_allocation augmented_reality autonomous_driving computing_devices content_delivery interpersonal_communication intervehicular_communication network_applications network_resource_allocation online_learning satisfying_user generated tactile_internet b6210l_computer_communications b6250f_mobile_radio_systems c5620_computer_networks_and_techniques c5620w_other_computer_networks c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7210n_information_networks input telecommunication geospatial business_planning_and_management networks motivation connectivity ubiquity computing device enabled wide spectrum network application content delivery interpersonal communication intervehicular communication new use case e g autonomous driving augmented reality tactile internet require satisfying user generated machine generated demand stringent low latency high bandwidth guarantee,motivation connectivity ubiquity computing device enabled wide spectrum network application content delivery interpersonal communication intervehicular communication new use case e g autonomous driving augmented reality tactile internet require satisfying user generated machine generated demand stringent low latency high bandwidth guarantee5g_mobile_communication internet resource_allocationaugmented_reality autonomous_driving computing_devices content_delivery interpersonal_communication intervehicular_communication network_applications network_resource_allocation online_learning satisfying_user generated tactile_internet
210,Towards More Inclusive and Accessible Virtual Reality: Conducting Large-scale Studies in the Wild,"Schmelter, T., Kruse, L., Karaosmanoglu, S., Rings, S., Steinicke, F., & Hildebrand, K. (2023). Towards More Inclusive and Accessible Virtual Reality: Conducting Large-scale Studies in the Wild. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583888
",10.1145/3544549.3583888,"In this work, we demonstrate a mobile laboratory with virtual and augmented reality (VR/AR) technology housed in a truck that enables large-scale VR/AR studies and therapies in real-world environments. This project aims to improve accessibility and inclusiveness in human-computer interaction (HCI) methods, providing a platform for researchers, medical professionals, and patients to utilize laboratory hardware and space. The mobile laboratory is equipped with motion tracking technology and other hardware to allow for a range of user groups to participate in VR studies and therapies that could otherwise never partake or benefit from these services. Our findings, applications, and experiences will be presented at the CHI interactivity track, with the goal of fostering future research opportunities.",C7330 Biology and medical computing;C6130V Virtual reality;C6180 User interfaces,AR;augmented reality;HCI interactivity track;human-computer interaction;laboratory hardware;medical professionals;mobile laboratory;motion tracking technology;patient therapies;virtual reality;VR,augmented reality;human computer interaction;interactive systems;medical computing;patient treatment,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schmelter, T.; (2) Kruse, L.; (2) Karaosmanoglu, S.; (2) Rings, S.; (2) Steinicke, F.; (1) Hildebrand, K.; ","(1) Berliner Hochschule fu&#776;r Technik, Germany; (2) Human-Computer Interaction, Germany; ",ACM,-1,"[""human computer interaction"", ""interactive systems"", ""medical computing"", ""patient treatment""]","[""human computer interaction"", ""interactive systems"", ""medical computing"", ""patient treatment""]",human computer interaction;interactive systems;medical computing;patient treatment,medical;input;education;human-computer interaction,technology;end users and user experience;industries,medical;input;education;human-computer interaction,technology;end users and user experience;industries,human_computer_interaction interactive_systems medical_computing patient_treatment ar augmented_reality hci_interactivity_track human computer_interaction laboratory_hardware medical_professionals mobile_laboratory motion_tracking_technology patient_therapies virtual_reality vr c7330_biology_and_medical_computing c6130v_virtual_reality c6180_user_interfaces medical input education human computer_interaction,human_computer_interaction interactive_systems medical_computing patient_treatment,ar augmented_reality hci_interactivity_track human computer_interaction laboratory_hardware medical_professionals mobile_laboratory motion_tracking_technology patient_therapies virtual_reality vr,work demonstrate mobile laboratory virtual augmented reality vr ar technology housed truck enables large scale vr ar study therapy real world environment project aim improve accessibility inclusiveness human computer interaction hci method providing platform researcher medical professional patient utilize laboratory hardware space mobile laboratory equipped motion tracking technology hardware allow range user group participate vr study therapy could otherwise never partake benefit service finding application experience presented chi interactivity track goal fostering future research opportunity,human_computer_interaction interactive_systems medical_computing patient_treatment ar augmented_reality hci_interactivity_track human computer_interaction laboratory_hardware medical_professionals mobile_laboratory motion_tracking_technology patient_therapies virtual_reality vr c7330_biology_and_medical_computing c6130v_virtual_reality c6180_user_interfaces medical input education human computer_interaction work demonstrate mobile laboratory virtual augmented reality vr ar technology housed truck enables large scale vr ar study therapy real world environment project aim improve accessibility inclusiveness human computer interaction hci method providing platform researcher medical professional patient utilize laboratory hardware space mobile laboratory equipped motion tracking technology hardware allow range user group participate vr study therapy could otherwise never partake benefit service finding application experience presented chi interactivity track goal fostering future research opportunity,work demonstrate mobile laboratory virtual augmented reality vr ar technology housed truck enables large scale vr ar study therapy real world environment project aim improve accessibility inclusiveness human computer interaction hci method providing platform researcher medical professional patient utilize laboratory hardware space mobile laboratory equipped motion tracking technology hardware allow range user group participate vr study therapy could otherwise never partake benefit service finding application experience presented chi interactivity track goal fostering future research opportunityhuman_computer_interaction interactive_systems medical_computing patient_treatmentar augmented_reality hci_interactivity_track human computer_interaction laboratory_hardware medical_professionals mobile_laboratory motion_tracking_technology patient_therapies virtual_reality vr
211,Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces,"Schröder, J.-H., Schacht, D., Peper, N., Hamurculu, A. M., & Jetter, H.-C. (2023). Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580879
",10.1145/3544548.3580879,"Transitional Interfaces are a yet underexplored, emerging class of cross-reality user interfaces that enable users to freely move along the reality-virtuality continuum during collaboration. To analyze and understand how such collaboration unfolds, we propose four analytical lenses derived from an exploratory study of transitional collaboration with 15 dyads. While solving a complex spatial optimization task, participants could freely switch between three contexts, each with different displays (desktop screens, tablet-based augmented reality, head-mounted virtual reality), input techniques (mouse, touch, handheld controllers), and visual representations (monoscopic and allocentric 2D/3D maps, stereoscopic egocentric views). Using the rich qualitative and quantitative data from our study, we evaluated participants' perceptions of transitional collaboration and identified commonalities and differences between dyads. We then derived four lenses including metrics and visualizations to analyze key aspects of transitional collaboration: (1) place and distance, (2) temporal patterns, (3) group use of contexts, (4) individual use of contexts.",C6130V Virtual reality;C6130B Graphics techniques;C6180 User interfaces,analytical lenses;complex spatial optimization task;cross-reality user;dyadic collaboration;enable users;head-mounted virtual reality;realities;reality-virtuality continuum;tablet-based augmented reality;transitional collaboration;transitional Interfaces;Transitional Interfaces,augmented reality;user interfaces;virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schro&#776;der, J.-H.; (1) Schacht, D.; (1) Peper, N.; (1) Hamurculu, A.M.; (1) Jetter, H.-C.; ","(1) University of Lu&#776;beck, Institute for Multimedia and Interactive Systems, Germany; ",ACM,-1,"[""user interfaces""]","[""user interfaces""]",user interfaces,human-computer interaction,end users and user experience,human-computer interaction,end users and user experience,user_interfaces analytical_lenses complex_spatial_optimization_task cross reality_user dyadic_collaboration enable_users head mounted_virtual_reality realities reality virtuality_continuum tablet based_augmented_reality transitional_collaboration transitional_interfaces transitional_interfaces c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces human computer_interaction,user_interfaces,analytical_lenses complex_spatial_optimization_task cross reality_user dyadic_collaboration enable_users head mounted_virtual_reality realities reality virtuality_continuum tablet based_augmented_reality transitional_collaboration transitional_interfaces transitional_interfaces,transitional interface yet underexplored emerging class cross reality user interface enable user freely move along reality virtuality continuum collaboration analyze understand collaboration unfolds propose four analytical lens derived exploratory study transitional collaboration 15 dyad solving complex spatial optimization task participant could freely switch three context different display desktop screen tablet based augmented reality head mounted virtual reality input technique mouse touch handheld controller visual representation monoscopic allocentric 2d 3d map stereoscopic egocentric view using rich qualitative quantitative data study evaluated participant perception transitional collaboration identified commonality difference dyad derived four lens including metric visualization analyze key aspect transitional collaboration 1 place distance 2 temporal pattern 3 group use context 4 individual use context,user_interfaces analytical_lenses complex_spatial_optimization_task cross reality_user dyadic_collaboration enable_users head mounted_virtual_reality realities reality virtuality_continuum tablet based_augmented_reality transitional_collaboration transitional_interfaces transitional_interfaces c6130v_virtual_reality c6130b_graphics_techniques c6180_user_interfaces human computer_interaction transitional interface yet underexplored emerging class cross reality user interface enable user freely move along reality virtuality continuum collaboration analyze understand collaboration unfolds propose four analytical lens derived exploratory study transitional collaboration 15 dyad solving complex spatial optimization task participant could freely switch three context different display desktop screen tablet based augmented reality head mounted virtual reality input technique mouse touch handheld controller visual representation monoscopic allocentric 2d 3d map stereoscopic egocentric view using rich qualitative quantitative data study evaluated participant perception transitional collaboration identified commonality difference dyad derived four lens including metric visualization analyze key aspect transitional collaboration 1 place distance 2 temporal pattern 3 group use context 4 individual use context,transitional interface yet underexplored emerging class cross reality user interface enable user freely move along reality virtuality continuum collaboration analyze understand collaboration unfolds propose four analytical lens derived exploratory study transitional collaboration 15 dyad solving complex spatial optimization task participant could freely switch three context different display desktop screen tablet based augmented reality head mounted virtual reality input technique mouse touch handheld controller visual representation monoscopic allocentric 2d 3d map stereoscopic egocentric view using rich qualitative quantitative data study evaluated participant perception transitional collaboration identified commonality difference dyad derived four lens including metric visualization analyze key aspect transitional collaboration 1 place distance 2 temporal pattern 3 group use context 4 individual use contextuser_interfacesanalytical_lenses complex_spatial_optimization_task cross reality_user dyadic_collaboration enable_users head mounted_virtual_reality realities reality virtuality_continuum tablet based_augmented_reality transitional_collaboration transitional_interfaces transitional_interfaces
212,Digital twin framework for real-time dynamic analysis visualization with detecting dynamic changes in structures properties using PINN,"Okuda, T., Saida, T., Matono, G., & Nishio, M. (2023). Digital twin framework for real-time dynamic analysis visualization with detecting dynamic changes in structures properties using PINN. Sensors and Smart Structures Technologies for Civil, Mechanical, and Aerospace Systems 2023. https://doi.org/10.1117/12.2658640
",10.1117/12.2658640,"This study developed a framework for real-time dynamic analysis of structural members using physics-informed neural networks (PINN). The interest in the use of augmented reality (AR) and virtual reality (VR) technologies to visualize the results of simulations is now increasing, and many researches are taking efforts to make these simulations more interactive and real-time. However, the application of structural dynamic simulations is limited due to its high computational cost. In this study, the Physics-informed neural networks (PINN) was used to conduct the real-time vibration analysis of a cantilever beam as a basic investigation. Prior to the real-time simulation, a PINN model for solving the cantilever beam undamped free vibration problem was constructed. Sequential trainings and predictions for the real-time simulation were then implemented at fine increment time steps by PINN. The distributions of displacement and bending moment, which were the outputs of the PINN simulations were visualized in AR on the real beam with converting the outputs to color contour for intuitive understanding. The RS framework based on PINN simulation and AR was then recognized to lead to the RS with data assimilation for real-time evaluation of structural condition using measurement data. &copy; 2023 SPIE.","408 Structural Design;408.1 Structural Design, General;408.2 Structural Members and Shapes;723 Computer Software, Data Handling and Applications;761 Nanotechnology;933 Solid State Physics",Augmented reality;Dynamics analysis;Free vibration problem;Neural-networks;Physic-informed neural network;Real- time;Real-time vibration analyse;Sequential training;Undamped free vibration problem;Vibrations analysis,Augmented reality;Cantilever beams;Nanocantilevers;Structural analysis;Structural dynamics,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Okuda, Toko; (2) Saida, Taisei; (2) Matono, Gen; (3) Nishio, Mayuko; ","(1) Sch of Sci and Eng, University of Tsukuba, 1-1-1 Tennodai, Ibaraki, Tsukuba; 305-8577, Japan; (2) Grad Sch of Sci and Tech, University of Tsukuba, 1-1-1 Tennodai, Ibaraki, Tsukuba; 305-8577, Japan; (3) Fac of Eng, Inf and Sys, University of Tsukuba, 1-1-1 Tennodai, Ibaraki, Tsukuba; 305-8577, Japan; ",SPIE,-1,"[""cantilever beams"", ""nanocantilevers"", ""structural analysis"", ""structural dynamics""]","[""cantilever beams"", ""nanocantilevers"", ""structural analysis"", ""structural dynamics""]",cantilever beams;nanocantilevers;structural analysis;structural dynamics,construction;computer vision;other,technology;other;industries,construction;computer vision;other,technology;other;industries,cantilever_beams nanocantilevers structural_analysis structural_dynamics augmented_reality dynamics_analysis free_vibration_problem neural networks physic informed_neural_network real _time real time_vibration_analyse sequential_training undamped_free_vibration_problem vibrations_analysis 408_structural_design 408 1_structural_design _general 408 2_structural_members_and_shapes 723_computer_software _data_handling_and_applications 761_nanotechnology 933_solid_state_physics construction computer_vision other,cantilever_beams nanocantilevers structural_analysis structural_dynamics,augmented_reality dynamics_analysis free_vibration_problem neural networks physic informed_neural_network real _time real time_vibration_analyse sequential_training undamped_free_vibration_problem vibrations_analysis,study developed framework real time dynamic analysis structural member using physic informed neural network pinn interest use augmented reality ar virtual reality vr technology visualize result simulation increasing many research taking effort make simulation interactive real time however application structural dynamic simulation limited due high computational cost study physic informed neural network pinn used conduct real time vibration analysis cantilever beam basic investigation prior real time simulation pinn model solving cantilever beam undamped free vibration problem constructed sequential training prediction real time simulation implemented fine increment time step pinn distribution displacement bending moment output pinn simulation visualized ar real beam converting output color contour intuitive understanding r framework based pinn simulation ar recognized lead r data assimilation real time evaluation structural condition using measurement data copy 2023 spie,cantilever_beams nanocantilevers structural_analysis structural_dynamics augmented_reality dynamics_analysis free_vibration_problem neural networks physic informed_neural_network real _time real time_vibration_analyse sequential_training undamped_free_vibration_problem vibrations_analysis 408_structural_design 408 1_structural_design _general 408 2_structural_members_and_shapes 723_computer_software _data_handling_and_applications 761_nanotechnology 933_solid_state_physics construction computer_vision other study developed framework real time dynamic analysis structural member using physic informed neural network pinn interest use augmented reality ar virtual reality vr technology visualize result simulation increasing many research taking effort make simulation interactive real time however application structural dynamic simulation limited due high computational cost study physic informed neural network pinn used conduct real time vibration analysis cantilever beam basic investigation prior real time simulation pinn model solving cantilever beam undamped free vibration problem constructed sequential training prediction real time simulation implemented fine increment time step pinn distribution displacement bending moment output pinn simulation visualized ar real beam converting output color contour intuitive understanding r framework based pinn simulation ar recognized lead r data assimilation real time evaluation structural condition using measurement data copy 2023 spie,study developed framework real time dynamic analysis structural member using physic informed neural network pinn interest use augmented reality ar virtual reality vr technology visualize result simulation increasing many research taking effort make simulation interactive real time however application structural dynamic simulation limited due high computational cost study physic informed neural network pinn used conduct real time vibration analysis cantilever beam basic investigation prior real time simulation pinn model solving cantilever beam undamped free vibration problem constructed sequential training prediction real time simulation implemented fine increment time step pinn distribution displacement bending moment output pinn simulation visualized ar real beam converting output color contour intuitive understanding r framework based pinn simulation ar recognized lead r data assimilation real time evaluation structural condition using measurement data copy 2023 spiecantilever_beams nanocantilevers structural_analysis structural_dynamicsaugmented_reality dynamics_analysis free_vibration_problem neural networks physic informed_neural_network real _time real time_vibration_analyse sequential_training undamped_free_vibration_problem vibrations_analysis
213,"""Picture the Audience..."": Exploring Private AR Face Filters for Online Public Speaking","Leong, J., Perteneder, F., Rajvee, M. R., & Maes, P. (2023). “Picture the Audience...”: Exploring Private AR Face Filters for Online Public Speaking. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581039
",10.1145/3544548.3581039,"Faced with public speaking anxiety, one common piece of advice is to picture the audience in a new light, using your mind's eye. With Augmented Reality (AR) face filters, it becomes possible to literally change how one sees oneself or others. In this paper, we explore privately applied AR filters during online public speaking. Private means that these effects are only visible to the speaker. To investigate this possibly controversial concept, we conducted an online survey with 100 respondents to gather a diverse set of initial impressions, possible boundaries, and guidelines. Following this, we built a prototype of a private AR web-based video-calling application, and pilot-tested it with 16 participants to gain more in-depth insights. Based on our results, we outline key user perspectives and opportunities for the private application of AR face filters during online public speaking and discuss them in the context of previous literature on this topic.",B6210P Teleconferencing;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6180 User interfaces;C7210N Information networks,AR filters;augmented reality face filters;online public speaking;private application;private AR face filters;private AR Web-based video-calling application;public speaking anxiety,augmented reality;human computer interaction;human factors;Internet;teleconferencing;video communication,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Leong, J.; (2) Perteneder, F.; (3) Rajvee, M.R.; (1) Maes, P.; ","(1) Massachusetts Institute of Technology Media Lab, Cambridge, MA, United States; (2) Independent, Austria; (3) Massachusetts Institute of Technology, Cambridge, MA, United States; ",ACM,-1,"[""human computer interaction"", ""human factors"", ""internet"", ""teleconferencing"", ""video communication""]","[""human computer interaction"", ""human factors"", ""internet"", ""teleconferencing"", ""video communication""]",human computer interaction;human factors;internet;teleconferencing;video communication,input;collaboration;human factors;human-computer interaction;video;networks,technology;use cases;end users and user experience,input;collaboration;human factors;human-computer interaction;video;networks,technology;use cases;end users and user experience,human_computer_interaction human_factors internet teleconferencing video_communication ar_filters augmented_reality_face_filters online_public_speaking private_application private_ar_face_filters private_ar_web based_video calling_application public_speaking_anxiety b6210p_teleconferencing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks input collaboration human_factors human computer_interaction video networks,human_computer_interaction human_factors internet teleconferencing video_communication,ar_filters augmented_reality_face_filters online_public_speaking private_application private_ar_face_filters private_ar_web based_video calling_application public_speaking_anxiety,faced public speaking anxiety one common piece advice picture audience new light using mind eye augmented reality ar face filter becomes possible literally change one see oneself others paper explore privately applied ar filter online public speaking private mean effect visible speaker investigate possibly controversial concept conducted online survey 100 respondent gather diverse set initial impression possible boundary guideline following built prototype private ar web based video calling application pilot tested 16 participant gain depth insight based result outline key user perspective opportunity private application ar face filter online public speaking discus context previous literature topic,human_computer_interaction human_factors internet teleconferencing video_communication ar_filters augmented_reality_face_filters online_public_speaking private_application private_ar_face_filters private_ar_web based_video calling_application public_speaking_anxiety b6210p_teleconferencing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks input collaboration human_factors human computer_interaction video networks faced public speaking anxiety one common piece advice picture audience new light using mind eye augmented reality ar face filter becomes possible literally change one see oneself others paper explore privately applied ar filter online public speaking private mean effect visible speaker investigate possibly controversial concept conducted online survey 100 respondent gather diverse set initial impression possible boundary guideline following built prototype private ar web based video calling application pilot tested 16 participant gain depth insight based result outline key user perspective opportunity private application ar face filter online public speaking discus context previous literature topic,faced public speaking anxiety one common piece advice picture audience new light using mind eye augmented reality ar face filter becomes possible literally change one see oneself others paper explore privately applied ar filter online public speaking private mean effect visible speaker investigate possibly controversial concept conducted online survey 100 respondent gather diverse set initial impression possible boundary guideline following built prototype private ar web based video calling application pilot tested 16 participant gain depth insight based result outline key user perspective opportunity private application ar face filter online public speaking discus context previous literature topichuman_computer_interaction human_factors internet teleconferencing video_communicationar_filters augmented_reality_face_filters online_public_speaking private_application private_ar_face_filters private_ar_web based_video calling_application public_speaking_anxiety
214,A Dataset and Machine Learning Approach to Classify and Augment Interface Elements of Household Appliances to Support People with Visual Impairment,"Tschakert, H., Lang, F., Wieland, M., Schmidt, A., & Machulla, T.-K. (2023). A Dataset and Machine Learning Approach to Classify and Augment Interface Elements of Household Appliances to Support People with Visual Impairment. Proceedings of the 28th International Conference on Intelligent User Interfaces. https://doi.org/10.1145/3581641.3584038
",10.1145/3581641.3584038,"Many modern household appliances are challenging to operate for people with visual impairment. Low-contrast designs and insufficient tactile feedback make it difficult to distinguish interface elements and to recognize their function. Augmented reality (AR) can be used to visually highlight such elements and provide assistance to people with residual vision. To realize this goal, we (1) created a dataset consisting of 13,702 images of interfaces from household appliances and manually labeled control elements; (2) trained a neural network to recognize control elements and to distinguish between PushButton, TouchButton, Knob, Slider, and Toggle; and (3) designed various contrast-rich and visually simple AR augmentations for these elements. The results were implemented as a screen-based assistive AR application, which we tested in a user study with six individuals with visual impairment. Participants were able to recognize control elements that were imperceptible without the assistive application. The approach was well received, especially for the potential of familiarizing oneself with novel devices. The automatic parsing and augmentation of interfaces provide an important step toward the independent interaction of people with visual impairments with their everyday environment.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C7850 Computer assistance for persons with handicaps",augment interface elements;augmented reality;automatic parsing;control elements;insufficient tactile feedback;low-contrast designs;machine learning approach;modern household appliances;screen-based assistive AR application;visual impairment,augmented reality;domestic appliances;handicapped aids;learning (artificial intelligence),2023,Conference article (CA),IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces,"(1) Tschakert, H.; (1) Lang, F.; (2) Wieland, M.; (1) Schmidt, A.; (3) Machulla, T.-K.; ","(1) Ludwig-Maximilians-Universita&#776;t Mu&#776;nchen, Germany; (2) University of Stuttgart, Germany; (3) Institute for Media Research, Germany; ",ACM,-1,"[""domestic appliances"", ""handicapped aids"", ""learning algorithms""]","[""domestic appliances"", ""handicapped aids"", ""learning algorithms""]",domestic appliances;handicapped aids;learning algorithms,medical;artificial intelligence;consumer products;collaboration,technology;use cases;industries,medical;artificial intelligence;consumer products;collaboration,technology;use cases;industries,domestic_appliances handicapped_aids learning_algorithms augment_interface_elements augmented_reality automatic_parsing control_elements insufficient_tactile_feedback low contrast_designs machine_learning_approach modern_household_appliances screen based_assistive_ar_application visual_impairment b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7850_computer_assistance_for_persons_with_handicaps medical artificial_intelligence consumer_products collaboration,domestic_appliances handicapped_aids learning_algorithms,augment_interface_elements augmented_reality automatic_parsing control_elements insufficient_tactile_feedback low contrast_designs machine_learning_approach modern_household_appliances screen based_assistive_ar_application visual_impairment,many modern household appliance challenging operate people visual impairment low contrast design insufficient tactile feedback make difficult distinguish interface element recognize function augmented reality ar used visually highlight element provide assistance people residual vision realize goal 1 created dataset consisting 13 702 image interface household appliance manually labeled control element 2 trained neural network recognize control element distinguish pushbutton touchbutton knob slider toggle 3 designed various contrast rich visually simple ar augmentation element result implemented screen based assistive ar application tested user study six individual visual impairment participant able recognize control element imperceptible without assistive application approach well received especially potential familiarizing oneself novel device automatic parsing augmentation interface provide important step toward independent interaction people visual impairment everyday environment,domestic_appliances handicapped_aids learning_algorithms augment_interface_elements augmented_reality automatic_parsing control_elements insufficient_tactile_feedback low contrast_designs machine_learning_approach modern_household_appliances screen based_assistive_ar_application visual_impairment b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7850_computer_assistance_for_persons_with_handicaps medical artificial_intelligence consumer_products collaboration many modern household appliance challenging operate people visual impairment low contrast design insufficient tactile feedback make difficult distinguish interface element recognize function augmented reality ar used visually highlight element provide assistance people residual vision realize goal 1 created dataset consisting 13 702 image interface household appliance manually labeled control element 2 trained neural network recognize control element distinguish pushbutton touchbutton knob slider toggle 3 designed various contrast rich visually simple ar augmentation element result implemented screen based assistive ar application tested user study six individual visual impairment participant able recognize control element imperceptible without assistive application approach well received especially potential familiarizing oneself novel device automatic parsing augmentation interface provide important step toward independent interaction people visual impairment everyday environment,many modern household appliance challenging operate people visual impairment low contrast design insufficient tactile feedback make difficult distinguish interface element recognize function augmented reality ar used visually highlight element provide assistance people residual vision realize goal 1 created dataset consisting 13 702 image interface household appliance manually labeled control element 2 trained neural network recognize control element distinguish pushbutton touchbutton knob slider toggle 3 designed various contrast rich visually simple ar augmentation element result implemented screen based assistive ar application tested user study six individual visual impairment participant able recognize control element imperceptible without assistive application approach well received especially potential familiarizing oneself novel device automatic parsing augmentation interface provide important step toward independent interaction people visual impairment everyday environmentdomestic_appliances handicapped_aids learning_algorithmsaugment_interface_elements augmented_reality automatic_parsing control_elements insufficient_tactile_feedback low contrast_designs machine_learning_approach modern_household_appliances screen based_assistive_ar_application visual_impairment
215,Multi-functional triboelectric nanogenerators on printed circuit board for metaverse sport interactive system,"Zhu, Y., Zhao, T., Sun, F., Jia, C., Ye, H., Jiang, Y., Wang, K., Huang, C., Xie, Y., & Mao, Y. (2023). Multi-functional triboelectric nanogenerators on printed circuit board for metaverse sport interactive system. Nano Energy, 113, 108520. https://doi.org/10.1016/j.nanoen.2023.108520
",10.1016/j.nanoen.2023.108520,"Metaverse is the society of future, which merges the physical and digital worlds by utilizing sophisticated human-machine interfaces (HMIs). In this study, a Metaverse sport interactive system based on triboelectric nanogenerators has been developed, which realizes a real-time interaction among human beings, devices, and the internet. This Metaverse sport interactive system is composed of a self-powered anaerobic power meter (APM), a wireless transmission module, personalized data analysis based on the professional Wingate anaerobic test (WAnT) method, and an augmented reality (AR) application. By leveraging the WAnT method, the power (PP), mean power (MP), and fatigue index (FI) are tested, which indeed reflect the explosive power, speed endurance, and endurance. Meanwhile, the data is transmitted to the cloud via the wireless transmission module, and the users can freely explore the Metaverse through AR application. Notably, through machine learning, the professional WAnT can not only reflect the anaerobic capacity but can also be used for athlete selection. Essentially, this work puts forward a new approach to design online competitions, sport training, and athlete selection, and in general, provides a new strategy to build the Metaverse. &copy; 2023 Elsevier Ltd","701.1 Electricity: Basic Concepts and Phenomena;705.2 Electric Generators;706.1.1 Electric Power Transmission;713.4 Pulse Circuits;723 Computer Software, Data Handling and Applications",Anaerobics;Augmented reality applications;Interactive system;Metaverses;Nanogenerators;Self-powered;Test method;Triboelectric;Wingate anerobic test;Wireless transmi-ssion modules,Augmented reality;Electric power transmission;Human computer interaction;Nanogenerators;Printed circuit boards;Sports;Triboelectricity,2023,Journal article (JA),Nano Energy,"(1) Zhu, Yongsheng; (2) Zhao, Tianming; (1) Sun, Fengxin; (1) Jia, Changjun; (3) Ye, Hui; (3) Jiang, Yawei; (5) Wang, Kuo; (5) Huang, Chaorui; (3) Xie, Yannan; (1) Mao, Yupeng; ","(1) Physical Education Department, Northeastern University, Shenyang; 110819, China; (2) State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Science, Shenyang, China; (3) Key Laboratory for Organic Electronics and Information Displays & Institute of Advanced Materials, Jiangsu Key Laboratory for Biosensors, Jiangsu National Synergetic Innovation Center for Advanced Materials, Nanjing University of Posts and Telecommunications, Jiangsu, Nanjing, China; (4) Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; (5) College of Information Science and Engineering, Northeastern University, Shenyang, China; (6) School of Strength and Conditioning Training, Beijing Sport University, Beijing, China; ",Elsevier Ltd,-1,"[""electric power transmission"", ""human computer interaction"", ""nanogenerators"", ""printed circuit boards"", ""sports"", ""triboelectricity""]","[""electric power transmission"", ""human computer interaction"", ""nanogenerators"", ""printed circuit boards"", ""sports"", ""triboelectricity""]",electric power transmission;human computer interaction;nanogenerators;printed circuit boards;sports;triboelectricity,other;cultural heritage;semiconductors;human-computer interaction,technology;other;end users and user experience;industries,other;cultural heritage;semiconductors;human-computer interaction,technology;other;end users and user experience;industries,electric_power_transmission human_computer_interaction nanogenerators printed_circuit_boards sports triboelectricity anaerobics augmented_reality_applications interactive_system metaverses nanogenerators self powered test_method triboelectric wingate_anerobic_test wireless_transmi ssion_modules 701 1_electricity _basic_concepts_and_phenomena 705 2_electric_generators 706 1 1_electric_power_transmission 713 4_pulse_circuits 723_computer_software _data_handling_and_applications other cultural_heritage semiconductors human computer_interaction,electric_power_transmission human_computer_interaction nanogenerators printed_circuit_boards sports triboelectricity,anaerobics augmented_reality_applications interactive_system metaverses nanogenerators self powered test_method triboelectric wingate_anerobic_test wireless_transmi ssion_modules,metaverse society future merges physical digital world utilizing sophisticated human machine interface hmis study metaverse sport interactive system based triboelectric nanogenerators developed realizes real time interaction among human being device internet metaverse sport interactive system composed self powered anaerobic power meter apm wireless transmission module personalized data analysis based professional wingate anaerobic test want method augmented reality ar application leveraging want method power pp mean power mp fatigue index fi tested indeed reflect explosive power speed endurance endurance meanwhile data transmitted cloud via wireless transmission module user freely explore metaverse ar application notably machine learning professional want reflect anaerobic capacity also used athlete selection essentially work put forward new approach design online competition sport training athlete selection general provides new strategy build metaverse copy 2023 elsevier ltd,electric_power_transmission human_computer_interaction nanogenerators printed_circuit_boards sports triboelectricity anaerobics augmented_reality_applications interactive_system metaverses nanogenerators self powered test_method triboelectric wingate_anerobic_test wireless_transmi ssion_modules 701 1_electricity _basic_concepts_and_phenomena 705 2_electric_generators 706 1 1_electric_power_transmission 713 4_pulse_circuits 723_computer_software _data_handling_and_applications other cultural_heritage semiconductors human computer_interaction metaverse society future merges physical digital world utilizing sophisticated human machine interface hmis study metaverse sport interactive system based triboelectric nanogenerators developed realizes real time interaction among human being device internet metaverse sport interactive system composed self powered anaerobic power meter apm wireless transmission module personalized data analysis based professional wingate anaerobic test want method augmented reality ar application leveraging want method power pp mean power mp fatigue index fi tested indeed reflect explosive power speed endurance endurance meanwhile data transmitted cloud via wireless transmission module user freely explore metaverse ar application notably machine learning professional want reflect anaerobic capacity also used athlete selection essentially work put forward new approach design online competition sport training athlete selection general provides new strategy build metaverse copy 2023 elsevier ltd,metaverse society future merges physical digital world utilizing sophisticated human machine interface hmis study metaverse sport interactive system based triboelectric nanogenerators developed realizes real time interaction among human being device internet metaverse sport interactive system composed self powered anaerobic power meter apm wireless transmission module personalized data analysis based professional wingate anaerobic test want method augmented reality ar application leveraging want method power pp mean power mp fatigue index fi tested indeed reflect explosive power speed endurance endurance meanwhile data transmitted cloud via wireless transmission module user freely explore metaverse ar application notably machine learning professional want reflect anaerobic capacity also used athlete selection essentially work put forward new approach design online competition sport training athlete selection general provides new strategy build metaverse copy 2023 elsevier ltdelectric_power_transmission human_computer_interaction nanogenerators printed_circuit_boards sports triboelectricityanaerobics augmented_reality_applications interactive_system metaverses nanogenerators self powered test_method triboelectric wingate_anerobic_test wireless_transmi ssion_modules
216,"Admission Experts based on Android+VR, AR Technology and Voice Operation","Xiao, J., Yang, W., & Li, F. (2022). Admission Experts based on Android+VR, AR Technology and Voice Operation. Proceedings of the 6th International Conference on Digital Technology in Education. https://doi.org/10.1145/3568739.3568805
",10.1145/3568739.3568805,"With the improvement of people's living standards and the increasing abundance of materials, acceptance has become an indispensable part of people's life. Nowadays, the application of smartphone is more and more widely used. A mobile APP based on Android system with the theme of acceptance is developed. Augmented Reality (AR) and Virtual Reality (VR) technologies as well as voice operation functions are applied to bring users a technological, convenient and novel experience of acceptance.","C6190V Mobile, ubiquitous and pervasive computing;C5260S Speech processing techniques;C6130V Virtual reality;C6180 User interfaces",admission experts;Android system;Android+VR;AR technology;augmented reality;mobile APP;technological experience;virtual reality technologies;voice operation functions,Android (operating system);augmented reality;mobile computing;smart phones;speech-based user interfaces,2022,Conference article (CA),ICDTE '22: Proceedings of the 6th International Conference on Digital Technology in Education,"(1) Xiao, J.; (2) Yang, W.; (1) Li, F.; ","(1) Xiangnan University, China and Hunan Engineering Research Center of Advanced Embedded Computing and Intelligent Medical Systems, China; (2) Xiangnan University, China; ",ACM,-1,"[""android"", ""mobile computing"", ""smartphones"", ""speech-based user interfaces""]","[""android"", ""mobile computing"", ""smartphones"", ""speech-based user interfaces""]",android;mobile computing;smartphones;speech-based user interfaces,input;liberal arts;telecommunication;developers;human-computer interaction,technology;industries;end users and user experience,input;liberal arts;telecommunication;developers;human-computer interaction,technology;industries;end users and user experience,android mobile_computing smartphones speech based_user_interfaces admission_experts android_system android vr ar_technology augmented_reality mobile_app technological_experience virtual_reality_technologies voice_operation_functions c6190v_mobile _ubiquitous_and_pervasive_computing c5260s_speech_processing_techniques c6130v_virtual_reality c6180_user_interfaces input liberal_arts telecommunication developers human computer_interaction,android mobile_computing smartphones speech based_user_interfaces,admission_experts android_system android vr ar_technology augmented_reality mobile_app technological_experience virtual_reality_technologies voice_operation_functions,improvement people living standard increasing abundance material acceptance become indispensable part people life nowadays application smartphone widely used mobile app based android system theme acceptance developed augmented reality ar virtual reality vr technology well voice operation function applied bring user technological convenient novel experience acceptance,android mobile_computing smartphones speech based_user_interfaces admission_experts android_system android vr ar_technology augmented_reality mobile_app technological_experience virtual_reality_technologies voice_operation_functions c6190v_mobile _ubiquitous_and_pervasive_computing c5260s_speech_processing_techniques c6130v_virtual_reality c6180_user_interfaces input liberal_arts telecommunication developers human computer_interaction improvement people living standard increasing abundance material acceptance become indispensable part people life nowadays application smartphone widely used mobile app based android system theme acceptance developed augmented reality ar virtual reality vr technology well voice operation function applied bring user technological convenient novel experience acceptance,improvement people living standard increasing abundance material acceptance become indispensable part people life nowadays application smartphone widely used mobile app based android system theme acceptance developed augmented reality ar virtual reality vr technology well voice operation function applied bring user technological convenient novel experience acceptanceandroid mobile_computing smartphones speech based_user_interfacesadmission_experts android_system android vr ar_technology augmented_reality mobile_app technological_experience virtual_reality_technologies voice_operation_functions
217,Impact of wearing a head-mounted display on localization accuracy of real sound sources,"Poirier-Quinot, D., & Lawless, M. S. (2023). Impact of wearing a head-mounted display on localization accuracy of real sound sources. Acta Acustica, 7, 3. https://doi.org/10.1051/aacus/2022055
",10.1051/aacus/2022055,"For augmented reality experiences, users wear head-mounted displays (HMD) while listening to real and virtual sound sources. This paper assesses the impact of wearing an HMD on localization accuracy of real sources. Eighteen blindfolded participants completed a localization task on 32 loudspeakers while wearing either no HMD, a bulky visor HMD, or a glass visor HMD. Results demonstrate that the HMDs had a significantly impact on participants' localization performance, increasing local great circle angle error by 0.9&#176;, and that the glass visor HMD demonstrably increased the rate of up-down confusions in the responses by 0.9-1.1%. These results suggest that wearing an HMD has a sufficiently small impact on real source localization that it can safely be considered as an HMD-free condition in most but the most demanding AR auditory localization studies.",B7260 Display technology;B6130 Speech and audio signal processing;B6450B Hi-Fi equipment and systems;B7810C Sonic and ultrasonic transducers and sensors;C5260 Digital signal processing;C5540D Computer displays;C6130V Virtual reality;C6180 User interfaces,AR auditory localization studies;augmented reality experiences;bulky visor HMD;glass visor HMD;head-mounted display;HMD-free condition;local great circle angle error;localization accuracy;localization task;participants;source localization;virtual sound sources,acoustic signal processing;augmented reality;helmet mounted displays;loudspeakers,2023,Journal article (JA),Acta Acust. (France),"(1) Poirier-Quinot, D.; (1) Lawless, M.S.; ","(1) Institut Jean Le Rond d'Alembert, France; ",EDP Sciences,-1,"[""acoustic signal processing"", ""helmet mounted displays"", ""loudspeakers""]","[""acoustic signal processing"", ""helmet mounted displays"", ""loudspeakers""]",acoustic signal processing;helmet mounted displays;loudspeakers,sensors;display technology;wearables;data;audio,technology;displays,sensors;display technology;wearables;data;audio,technology;displays,acoustic_signal_processing helmet_mounted_displays loudspeakers ar_auditory_localization_studies augmented_reality_experiences bulky_visor_hmd glass_visor_hmd head mounted_display hmd free_condition local_great_circle_angle_error localization_accuracy localization_task participants source_localization virtual_sound_sources b7260_display_technology b6130_speech_and_audio_signal_processing b6450b_hi fi_equipment_and_systems b7810c_sonic_and_ultrasonic_transducers_and_sensors c5260_digital_signal_processing c5540d_computer_displays c6130v_virtual_reality c6180_user_interfaces sensors display_technology wearables data audio,acoustic_signal_processing helmet_mounted_displays loudspeakers,ar_auditory_localization_studies augmented_reality_experiences bulky_visor_hmd glass_visor_hmd head mounted_display hmd free_condition local_great_circle_angle_error localization_accuracy localization_task participants source_localization virtual_sound_sources,augmented reality experience user wear head mounted display hmd listening real virtual sound source paper ass impact wearing hmd localization accuracy real source eighteen blindfolded participant completed localization task 32 loudspeaker wearing either hmd bulky visor hmd glass visor hmd result demonstrate hmds significantly impact participant localization performance increasing local great circle angle error 0 9 176 glass visor hmd demonstrably increased rate confusion response 0 9 1 1 result suggest wearing hmd sufficiently small impact real source localization safely considered hmd free condition demanding ar auditory localization study,acoustic_signal_processing helmet_mounted_displays loudspeakers ar_auditory_localization_studies augmented_reality_experiences bulky_visor_hmd glass_visor_hmd head mounted_display hmd free_condition local_great_circle_angle_error localization_accuracy localization_task participants source_localization virtual_sound_sources b7260_display_technology b6130_speech_and_audio_signal_processing b6450b_hi fi_equipment_and_systems b7810c_sonic_and_ultrasonic_transducers_and_sensors c5260_digital_signal_processing c5540d_computer_displays c6130v_virtual_reality c6180_user_interfaces sensors display_technology wearables data audio augmented reality experience user wear head mounted display hmd listening real virtual sound source paper ass impact wearing hmd localization accuracy real source eighteen blindfolded participant completed localization task 32 loudspeaker wearing either hmd bulky visor hmd glass visor hmd result demonstrate hmds significantly impact participant localization performance increasing local great circle angle error 0 9 176 glass visor hmd demonstrably increased rate confusion response 0 9 1 1 result suggest wearing hmd sufficiently small impact real source localization safely considered hmd free condition demanding ar auditory localization study,augmented reality experience user wear head mounted display hmd listening real virtual sound source paper ass impact wearing hmd localization accuracy real source eighteen blindfolded participant completed localization task 32 loudspeaker wearing either hmd bulky visor hmd glass visor hmd result demonstrate hmds significantly impact participant localization performance increasing local great circle angle error 0 9 176 glass visor hmd demonstrably increased rate confusion response 0 9 1 1 result suggest wearing hmd sufficiently small impact real source localization safely considered hmd free condition demanding ar auditory localization studyacoustic_signal_processing helmet_mounted_displays loudspeakersar_auditory_localization_studies augmented_reality_experiences bulky_visor_hmd glass_visor_hmd head mounted_display hmd free_condition local_great_circle_angle_error localization_accuracy localization_task participants source_localization virtual_sound_sources
218,Technologies for the preservation of cultural heritage-a systematic review of the literature,"Mendoza, M. A. D., De La Hoz Franco, E., & Gómez, J. E. G. (2023). Technologies for the Preservation of Cultural Heritage—A Systematic Review of the Literature. Sustainability, 15(2), 1059. https://doi.org/10.3390/su15021059
",10.3390/su15021059,"This work establishes the technological elements that have enabled the preservation, promotion, and dissemination of tangible and intangible cultural heritage in the period from 2018 to 2022. For this, a Systematic Literature Review (SLR) was conducted in the scientific databases Scopus, Science Direct, IEEE and Web of Science, which facilitated the identification of 146 articles related to the topic. A quantitative and qualitative analysis of the journals, authors and topics was carried out, detailing the important variables required to establish the sought-out elements; for this purpose, the following were quantified in the papers: type, topic, categorization, country, and language; in the publications, the type of heritage chosen, the place of the heritage and the type of intervention were investigated. The number of publications reporting the use of some type of technology was also identified, finding that 70% of them show a technological approach to preserve cultural heritage, while 30% refer to other types of interventions. The technologies reported to be used the most are 3D digital technologies (44% of those showing technological applications), augmented reality or virtual reality, henceforth AR/VR (15%).",C6130V Virtual reality;C7230 Publishing and reproduction;C7820 Humanities computing,3D digital technologies;augmented reality;IEEE;intangible cultural heritage;qualitative analysis;quantitative analysis;science direct;scientific databases Scopus;SLR;systematic literature review;tangible cultural heritage;technological approach;technological elements;virtual reality;Web of science,augmented reality;electronic publishing;history;three-dimensional displays,2023,Journal article (JA),Sustainability (Switzerland),"(1) Mendoza, M.A.D.; (1) De La Hoz Franco, E.; (2) Gomez, J.E.G.; ","(1) Universidad de la Costa, Department of Computer Science and Electronics, Colombia; (2) Universidad de Cordoba, Department of Systems Engineering and Telecommunications, Colombia; ",MDPI,-1,"[""electronic publishing"", ""history"", ""three-dimensional displays""]","[""electronic publishing"", ""history"", ""three-dimensional displays""]",electronic publishing;history;three-dimensional displays,display technology;education;developers;liberal arts,technology;displays;industries,display technology;education;developers;liberal arts,technology;displays;industries,electronic_publishing history three dimensional_displays 3d_digital_technologies augmented_reality ieee intangible_cultural_heritage qualitative_analysis quantitative_analysis science_direct scientific_databases_scopus slr systematic_literature_review tangible_cultural_heritage technological_approach technological_elements virtual_reality web_of_science c6130v_virtual_reality c7230_publishing_and_reproduction c7820_humanities_computing display_technology education developers liberal_arts,electronic_publishing history three dimensional_displays,3d_digital_technologies augmented_reality ieee intangible_cultural_heritage qualitative_analysis quantitative_analysis science_direct scientific_databases_scopus slr systematic_literature_review tangible_cultural_heritage technological_approach technological_elements virtual_reality web_of_science,work establishes technological element enabled preservation promotion dissemination tangible intangible cultural heritage period 2018 2022 systematic literature review slr conducted scientific database scopus science direct ieee web science facilitated identification 146 article related topic quantitative qualitative analysis journal author topic carried detailing important variable required establish sought element purpose following quantified paper type topic categorization country language publication type heritage chosen place heritage type intervention investigated number publication reporting use type technology also identified finding 70 show technological approach preserve cultural heritage 30 refer type intervention technology reported used 3d digital technology 44 showing technological application augmented reality virtual reality henceforth ar vr 15,electronic_publishing history three dimensional_displays 3d_digital_technologies augmented_reality ieee intangible_cultural_heritage qualitative_analysis quantitative_analysis science_direct scientific_databases_scopus slr systematic_literature_review tangible_cultural_heritage technological_approach technological_elements virtual_reality web_of_science c6130v_virtual_reality c7230_publishing_and_reproduction c7820_humanities_computing display_technology education developers liberal_arts work establishes technological element enabled preservation promotion dissemination tangible intangible cultural heritage period 2018 2022 systematic literature review slr conducted scientific database scopus science direct ieee web science facilitated identification 146 article related topic quantitative qualitative analysis journal author topic carried detailing important variable required establish sought element purpose following quantified paper type topic categorization country language publication type heritage chosen place heritage type intervention investigated number publication reporting use type technology also identified finding 70 show technological approach preserve cultural heritage 30 refer type intervention technology reported used 3d digital technology 44 showing technological application augmented reality virtual reality henceforth ar vr 15,work establishes technological element enabled preservation promotion dissemination tangible intangible cultural heritage period 2018 2022 systematic literature review slr conducted scientific database scopus science direct ieee web science facilitated identification 146 article related topic quantitative qualitative analysis journal author topic carried detailing important variable required establish sought element purpose following quantified paper type topic categorization country language publication type heritage chosen place heritage type intervention investigated number publication reporting use type technology also identified finding 70 show technological approach preserve cultural heritage 30 refer type intervention technology reported used 3d digital technology 44 showing technological application augmented reality virtual reality henceforth ar vr 15electronic_publishing history three dimensional_displays3d_digital_technologies augmented_reality ieee intangible_cultural_heritage qualitative_analysis quantitative_analysis science_direct scientific_databases_scopus slr systematic_literature_review tangible_cultural_heritage technological_approach technological_elements virtual_reality web_of_science
219,Exploring Immersive Interpersonal Communication via AR,"Lee, K., Li, H., Wellyanto, M. R., Tham, Y. J., Monroy-Hernández, A., Liu, F., Smith, B. A., & Vaish, R. (2023). Exploring Immersive Interpersonal Communication via AR. Proceedings of the ACM on Human-Computer Interaction, 7(CSCW1), 1–25. https://doi.org/10.1145/3579483
",10.1145/3579483,"A central challenge of social computing research is to enable people to communicate expressively with each other remotely. Augmented reality has great promise for expressive communication since it enables communication beyond texts and photos and towards immersive experiences rendered in recipients' physical environments. Little research, however, has explored AR's potential for everyday interpersonal communication. In this work, we prototype an AR messaging system, ARwand, to understand people's behaviors and perceptions around communicating with friends via AR messaging. We present our findings under four themes observed from a user study with 24 participants, including the types of immersive messages people choose to send to each other, which factors contribute to a sense of immersiveness, and what concerns arise over this new form of messaging. We discuss important implications of our findings on the design of future immersive communication systems.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6130B Graphics techniques;C6180 User interfaces;C7210N Information networks,AR messaging system;augmented reality;everyday interpersonal communication;expressive communication;future immersive communication systems;immersive experiences;immersive interpersonal communication;immersive messages people;photos;recipients;remotely;social computing research,augmented reality;rendering (computer graphics);social networking (online);virtual reality,2023,Journal article (JA),Proc. ACM Hum.-Comput. Interact. (USA),"(1) Lee, K.; (2) Li, H.; (3) Wellyanto, M.R.; (4) Tham, Y.J.; (5) Monroy-Herna&#769;ndez, A.; (6) Liu, F.; (7) Smith, B.A.; (2) Vaish, R.; ","(1) University of Maryland, Baltimore, College Park, College Park, Baltimore, MD, United States; (2) Snap, Santa Monica, CA, United States; (3) University of Illinois Urbana-Champaign, Urbana, IL, United States; (4) Snap, Inc., Seattle, WA, United States; (5) Princeton University, Princeton, NJ, United States; (6) Snap Inc, Venice, CA, United States; (7) Columbia University, New York, NY, United States; ",ACM,-1,"[""rendering"", ""social networking""]","[""rendering"", ""social networking""]",rendering;social networking,graphics;collaboration,technology;use cases,graphics;collaboration,technology;use cases,rendering social_networking ar_messaging_system augmented_reality everyday_interpersonal_communication expressive_communication future_immersive_communication_systems immersive_experiences immersive_interpersonal_communication immersive_messages_people photos recipients remotely social_computing_research c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6180_user_interfaces c7210n_information_networks graphics collaboration,rendering social_networking,ar_messaging_system augmented_reality everyday_interpersonal_communication expressive_communication future_immersive_communication_systems immersive_experiences immersive_interpersonal_communication immersive_messages_people photos recipients remotely social_computing_research,central challenge social computing research enable people communicate expressively remotely augmented reality great promise expressive communication since enables communication beyond text photo towards immersive experience rendered recipient physical environment little research however explored ar potential everyday interpersonal communication work prototype ar messaging system arwand understand people behavior perception around communicating friend via ar messaging present finding four theme observed user study 24 participant including type immersive message people choose send factor contribute sense immersiveness concern arise new form messaging discus important implication finding design future immersive communication system,rendering social_networking ar_messaging_system augmented_reality everyday_interpersonal_communication expressive_communication future_immersive_communication_systems immersive_experiences immersive_interpersonal_communication immersive_messages_people photos recipients remotely social_computing_research c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6180_user_interfaces c7210n_information_networks graphics collaboration central challenge social computing research enable people communicate expressively remotely augmented reality great promise expressive communication since enables communication beyond text photo towards immersive experience rendered recipient physical environment little research however explored ar potential everyday interpersonal communication work prototype ar messaging system arwand understand people behavior perception around communicating friend via ar messaging present finding four theme observed user study 24 participant including type immersive message people choose send factor contribute sense immersiveness concern arise new form messaging discus important implication finding design future immersive communication system,central challenge social computing research enable people communicate expressively remotely augmented reality great promise expressive communication since enables communication beyond text photo towards immersive experience rendered recipient physical environment little research however explored ar potential everyday interpersonal communication work prototype ar messaging system arwand understand people behavior perception around communicating friend via ar messaging present finding four theme observed user study 24 participant including type immersive message people choose send factor contribute sense immersiveness concern arise new form messaging discus important implication finding design future immersive communication systemrendering social_networkingar_messaging_system augmented_reality everyday_interpersonal_communication expressive_communication future_immersive_communication_systems immersive_experiences immersive_interpersonal_communication immersive_messages_people photos recipients remotely social_computing_research
220,Fusing Computer Vision and Wireless Signal for Accurate Sensor Localization in AR View,"Billah, M. F. R. M., Islam, M. M., Saoda, N., Iqbal, T., & Campbell, B. (2022). Fusing Computer Vision and Wireless Signal for Accurate Sensor Localization in AR View. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568095
",10.1145/3560905.3568095,"Recent years have seen increasing traction to enable new applications that can localize sensors on the screen of an Augmented Reality (AR) device (e.g. smartphone, tablet) so that sensors can be controlled more intuitively. Despite recent advances in this area, both wireless signal dependent and computer vision based localization solutions have seen a slow acceptance due to signal noise, multipath effect, and limited AR device-sensor interactivity. In this paper, we propose a novel solution to combine the complementary advantages of wireless signal based localization solution with the computer vision based solution to track IoT devices and sensors more accurately. Experimental result shows that our system can accurately track IoT devices with an average pixel error of 34 pixels in a 1024 &#215; 768 pixels image, which is a 75.8% improvement from the state-of-the-art model.","B6135 Optical, image and video signal processing;B6250K Wireless sensor networks;B7230G Image sensors;C5260B Computer vision and image processing techniques;C5620D Internet of Things;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",accurate sensor localization;Augmented Reality device;computer vision;device-sensor interactivity;IoT devices;localization solution;wireless signal dependent,augmented reality;computer vision;Internet of Things;robot vision;smart phones;wireless sensor networks,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Billah, M.F.R.M.; (1) Islam, M.M.; (1) Saoda, N.; (1) Iqbal, T.; (1) Campbell, B.; ","(1) University of Virginia, Charlottesville, VA, United States; ",ACM,-1,"[""computer vision"", ""internet of things"", ""robot vision"", ""smartphones"", ""wireless sensor networks""]","[""computer vision"", ""internet of things"", ""robot vision"", ""smartphones"", ""wireless sensor networks""]",computer vision;internet of things;robot vision;smartphones;wireless sensor networks,computer vision;robotics;liberal arts;sensors;internet of things;telecommunication;networks,technology;industries,computer vision;robotics;liberal arts;sensors;internet of things;telecommunication;networks,technology;industries,computer_vision internet_of_things robot_vision smartphones wireless_sensor_networks accurate_sensor_localization augmented_reality_device computer_vision device sensor_interactivity iot_devices localization_solution wireless_signal_dependent b6135_optical _image_and_video_signal_processing b6250k_wireless_sensor_networks b7230g_image_sensors c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision robotics liberal_arts sensors internet_of_things telecommunication networks,computer_vision internet_of_things robot_vision smartphones wireless_sensor_networks,accurate_sensor_localization augmented_reality_device computer_vision device sensor_interactivity iot_devices localization_solution wireless_signal_dependent,recent year seen increasing traction enable new application localize sensor screen augmented reality ar device e g smartphone tablet sensor controlled intuitively despite recent advance area wireless signal dependent computer vision based localization solution seen slow acceptance due signal noise multipath effect limited ar device sensor interactivity paper propose novel solution combine complementary advantage wireless signal based localization solution computer vision based solution track iot device sensor accurately experimental result show system accurately track iot device average pixel error 34 pixel 1024 215 768 pixel image 75 8 improvement state art model,computer_vision internet_of_things robot_vision smartphones wireless_sensor_networks accurate_sensor_localization augmented_reality_device computer_vision device sensor_interactivity iot_devices localization_solution wireless_signal_dependent b6135_optical _image_and_video_signal_processing b6250k_wireless_sensor_networks b7230g_image_sensors c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing computer_vision robotics liberal_arts sensors internet_of_things telecommunication networks recent year seen increasing traction enable new application localize sensor screen augmented reality ar device e g smartphone tablet sensor controlled intuitively despite recent advance area wireless signal dependent computer vision based localization solution seen slow acceptance due signal noise multipath effect limited ar device sensor interactivity paper propose novel solution combine complementary advantage wireless signal based localization solution computer vision based solution track iot device sensor accurately experimental result show system accurately track iot device average pixel error 34 pixel 1024 215 768 pixel image 75 8 improvement state art model,recent year seen increasing traction enable new application localize sensor screen augmented reality ar device e g smartphone tablet sensor controlled intuitively despite recent advance area wireless signal dependent computer vision based localization solution seen slow acceptance due signal noise multipath effect limited ar device sensor interactivity paper propose novel solution combine complementary advantage wireless signal based localization solution computer vision based solution track iot device sensor accurately experimental result show system accurately track iot device average pixel error 34 pixel 1024 215 768 pixel image 75 8 improvement state art modelcomputer_vision internet_of_things robot_vision smartphones wireless_sensor_networksaccurate_sensor_localization augmented_reality_device computer_vision device sensor_interactivity iot_devices localization_solution wireless_signal_dependent
221,FocalPoint: Adaptive Direct Manipulation for Selecting Small 3D Virtual Objects,"Ma, J., Qian, J., Zhou, T., & Huang, J. (2022). FocalPoint. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 7(1), 1–26. https://doi.org/10.1145/3580856
",10.1145/3580856,"We propose FocalPoint, a direct manipulation technique in smartphone augmented reality (AR) for selecting small densely-packed objects within reach, a fundamental yet challenging task in AR due to the required accuracy and precision. FocalPoint adaptively and continuously updates a cylindrical geometry for selection disambiguation based on the user's selection history and hand movements. This design is informed by a preliminary study which revealed that participants preferred selecting objects appearing in particular regions of the screen. We evaluate FocalPoint against a baseline direct manipulation technique in a 12-participant study with two tasks: selecting a 3 mm wide target from a pile of cubes and virtually decorating a house with LEGO pieces. FocalPoint was three times as accurate for selecting the correct object and 5.5 seconds faster on average; participants using FocalPoint decorated their houses more and were more satisfied with the result. We further demonstrate the finer control enabled by FocalPoint in example applications of robot repair, 3D modeling, and neural network visualizations.","C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",3D modeling;adaptive direct manipulation;baseline direct manipulation technique;cylindrical geometry;FocalPoint;hand movements;neural network visualizations;robot repair;selection disambiguation;size 3.0 mm;small 3D virtual objects;smartphone augmented reality;time 5.5 s;user selection history,augmented reality;smart phones;user interfaces,2022,Journal article (JA),Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. (USA),"(1) Ma, J.; (2) Qian, J.; (2) Zhou, T.; (2) Huang, J.; ","(1) Brown University, Stanford, CA, United States; (2) Brown University, Providence, RI, United States; ",ACM,-1,"[""smartphones"", ""user interfaces""]","[""smartphones"", ""user interfaces""]",smartphones;user interfaces,telecommunication;liberal arts;human-computer interaction,industries;end users and user experience,telecommunication;liberal arts;human-computer interaction,industries;end users and user experience,smartphones user_interfaces 3d_modeling adaptive_direct_manipulation baseline_direct_manipulation_technique cylindrical_geometry focalpoint hand_movements neural_network_visualizations robot_repair selection_disambiguation size_3 0_mm small_3d_virtual_objects smartphone_augmented_reality time_5 5_s user_selection_history c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication liberal_arts human computer_interaction,smartphones user_interfaces,3d_modeling adaptive_direct_manipulation baseline_direct_manipulation_technique cylindrical_geometry focalpoint hand_movements neural_network_visualizations robot_repair selection_disambiguation size_3 0_mm small_3d_virtual_objects smartphone_augmented_reality time_5 5_s user_selection_history,propose focalpoint direct manipulation technique smartphone augmented reality ar selecting small densely packed object within reach fundamental yet challenging task ar due required accuracy precision focalpoint adaptively continuously update cylindrical geometry selection disambiguation based user selection history hand movement design informed preliminary study revealed participant preferred selecting object appearing particular region screen evaluate focalpoint baseline direct manipulation technique 12 participant study two task selecting 3 mm wide target pile cube virtually decorating house lego piece focalpoint three time accurate selecting correct object 5 5 second faster average participant using focalpoint decorated house satisfied result demonstrate finer control enabled focalpoint example application robot repair 3d modeling neural network visualization,smartphones user_interfaces 3d_modeling adaptive_direct_manipulation baseline_direct_manipulation_technique cylindrical_geometry focalpoint hand_movements neural_network_visualizations robot_repair selection_disambiguation size_3 0_mm small_3d_virtual_objects smartphone_augmented_reality time_5 5_s user_selection_history c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication liberal_arts human computer_interaction propose focalpoint direct manipulation technique smartphone augmented reality ar selecting small densely packed object within reach fundamental yet challenging task ar due required accuracy precision focalpoint adaptively continuously update cylindrical geometry selection disambiguation based user selection history hand movement design informed preliminary study revealed participant preferred selecting object appearing particular region screen evaluate focalpoint baseline direct manipulation technique 12 participant study two task selecting 3 mm wide target pile cube virtually decorating house lego piece focalpoint three time accurate selecting correct object 5 5 second faster average participant using focalpoint decorated house satisfied result demonstrate finer control enabled focalpoint example application robot repair 3d modeling neural network visualization,propose focalpoint direct manipulation technique smartphone augmented reality ar selecting small densely packed object within reach fundamental yet challenging task ar due required accuracy precision focalpoint adaptively continuously update cylindrical geometry selection disambiguation based user selection history hand movement design informed preliminary study revealed participant preferred selecting object appearing particular region screen evaluate focalpoint baseline direct manipulation technique 12 participant study two task selecting 3 mm wide target pile cube virtually decorating house lego piece focalpoint three time accurate selecting correct object 5 5 second faster average participant using focalpoint decorated house satisfied result demonstrate finer control enabled focalpoint example application robot repair 3d modeling neural network visualizationsmartphones user_interfaces3d_modeling adaptive_direct_manipulation baseline_direct_manipulation_technique cylindrical_geometry focalpoint hand_movements neural_network_visualizations robot_repair selection_disambiguation size_3 0_mm small_3d_virtual_objects smartphone_augmented_reality time_5 5_s user_selection_history
222,E-Learning Ecosystems for People With Autism Spectrum Disorder: A Systematic Review,"Contreras-Ortiz, M. S., Marrugo, P. P., & Cesar Rodríguez Ribón, J. (2023). E-Learning Ecosystems for People With Autism Spectrum Disorder: A Systematic Review. IEEE Access, 11, 49819–49832. https://doi.org/10.1109/access.2023.3277819
",10.1109/ACCESS.2023.3277819,"E-Learning Ecosystems (ELE) offer excellent opportunities to manage teaching activities by incorporating state-of-the-art technologies, practices, and professional support, as well as learning and assessment resources that can be adaptive. Therefore, it can help people with disabilities or conditions such as Autism Spectrum Disorder (ASD) to develop skills. However, some technological factors prevent this population's implementation of support scenarios and hinder the proper learning process. This paper systematically reviews relevant studies on E-Learning Ecosystems for people with ASD, identifying the influence of Information and Communication Technologies (ICT) on forming ELE and the technological barriers that affect their development and appropriate use on people with ASD. This work conducted a systematic review using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) methodology, including a search of five scientific literature databases from 2017 to 2022. The main aspects identified were 1) a shortage in design guides for the implementation of e-learning ecosystems adapted for people with ASD, 2) technological barriers that prevent the development of ELE, and 3) recommendations that help to mitigate the limitations of this field. In addition, the authors identified that the skills with the most significant focus of interest were social, communicative, and cognitive. The most implemented technologies include virtual and augmented reality or mobile applications. Most studies involved children with ASD between 8 and 15 years, followed by works with children between 5 to 8 years. Very few researches linked adults with ASD. Very few studies mention the ASD level of the participants, but most highlight the positive results of implementing ICT in training processes.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",ASD;augmented reality;autism spectrum disorder;e-learning ecosystems;ELE;ICT;information and communication technologies;learning assessment resources;mobile applications;PRISMA;systematic review;virtual reality,augmented reality;computer aided instruction;medical disorders;mobile computing;reviews;teaching,2023,Journal article (JA),IEEE Access (USA),"(1) Contreras-Ortiz, M.S.; (1) Marrugo, P.P.; (1) Cesar Rodriguez Ribon, J.; ","(1) University of Cartagena, Department of Systems Engineering, Colombia; (2) Universidad Santo Toma&#769;s, Department of Systems Engineering, Colombia; ",IEEE,-1,"[""computer aided instruction"", ""medical disorders"", ""mobile computing"", ""reviews"", ""teaching""]","[""computer aided instruction"", ""medical disorders"", ""mobile computing"", ""reviews"", ""teaching""]",computer aided instruction;medical disorders;mobile computing;reviews;teaching,education;medical;training;telecommunication;standards,standards;use cases;industries,education;medical;training;telecommunication;standards,standards;use cases;industries,computer_aided_instruction medical_disorders mobile_computing reviews teaching asd augmented_reality autism_spectrum_disorder e learning_ecosystems ele ict information_and_communication_technologies learning_assessment_resources mobile_applications prisma systematic_review virtual_reality c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education medical training telecommunication standards,computer_aided_instruction medical_disorders mobile_computing reviews teaching,asd augmented_reality autism_spectrum_disorder e learning_ecosystems ele ict information_and_communication_technologies learning_assessment_resources mobile_applications prisma systematic_review virtual_reality,e learning ecosystem ele offer excellent opportunity manage teaching activity incorporating state art technology practice professional support well learning assessment resource adaptive therefore help people disability condition autism spectrum disorder asd develop skill however technological factor prevent population implementation support scenario hinder proper learning process paper systematically review relevant study e learning ecosystem people asd identifying influence information communication technology ict forming ele technological barrier affect development appropriate use people asd work conducted systematic review using prisma preferred reporting item systematic review meta analysis methodology including search five scientific literature database 2017 2022 main aspect identified 1 shortage design guide implementation e learning ecosystem adapted people asd 2 technological barrier prevent development ele 3 recommendation help mitigate limitation field addition author identified skill significant focus interest social communicative cognitive implemented technology include virtual augmented reality mobile application study involved child asd 8 15 year followed work child 5 8 year research linked adult asd study mention asd level participant highlight positive result implementing ict training process,computer_aided_instruction medical_disorders mobile_computing reviews teaching asd augmented_reality autism_spectrum_disorder e learning_ecosystems ele ict information_and_communication_technologies learning_assessment_resources mobile_applications prisma systematic_review virtual_reality c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing education medical training telecommunication standards e learning ecosystem ele offer excellent opportunity manage teaching activity incorporating state art technology practice professional support well learning assessment resource adaptive therefore help people disability condition autism spectrum disorder asd develop skill however technological factor prevent population implementation support scenario hinder proper learning process paper systematically review relevant study e learning ecosystem people asd identifying influence information communication technology ict forming ele technological barrier affect development appropriate use people asd work conducted systematic review using prisma preferred reporting item systematic review meta analysis methodology including search five scientific literature database 2017 2022 main aspect identified 1 shortage design guide implementation e learning ecosystem adapted people asd 2 technological barrier prevent development ele 3 recommendation help mitigate limitation field addition author identified skill significant focus interest social communicative cognitive implemented technology include virtual augmented reality mobile application study involved child asd 8 15 year followed work child 5 8 year research linked adult asd study mention asd level participant highlight positive result implementing ict training process,e learning ecosystem ele offer excellent opportunity manage teaching activity incorporating state art technology practice professional support well learning assessment resource adaptive therefore help people disability condition autism spectrum disorder asd develop skill however technological factor prevent population implementation support scenario hinder proper learning process paper systematically review relevant study e learning ecosystem people asd identifying influence information communication technology ict forming ele technological barrier affect development appropriate use people asd work conducted systematic review using prisma preferred reporting item systematic review meta analysis methodology including search five scientific literature database 2017 2022 main aspect identified 1 shortage design guide implementation e learning ecosystem adapted people asd 2 technological barrier prevent development ele 3 recommendation help mitigate limitation field addition author identified skill significant focus interest social communicative cognitive implemented technology include virtual augmented reality mobile application study involved child asd 8 15 year followed work child 5 8 year research linked adult asd study mention asd level participant highlight positive result implementing ict training processcomputer_aided_instruction medical_disorders mobile_computing reviews teachingasd augmented_reality autism_spectrum_disorder e learning_ecosystems ele ict information_and_communication_technologies learning_assessment_resources mobile_applications prisma systematic_review virtual_reality
223,Study and validation of switchable grating using liquid crystal for active waveguide addressing,"Toubi, S., Colard, M., Lee, Y., Racine, B., Suhm, A., Grosso, D., Kerzabi, B., & Martinez, C. (2023). Study and validation of switchable grating using liquid crystal for active waveguide addressing. Emerging Liquid Crystal Technologies XVIII. https://doi.org/10.1117/12.2649749
",10.1117/12.2649749,"In our Augmented Reality (AR) project, we are investigating the use of a retinal projection display based on the association of pixelated holograms and a dense distribution of waveguides. We study the use of gratings impregnated with liquid crystal to actively extract light from waveguides. We explore two extraction strategies: tuning the refractive index contrast between the grating teeth and grooves to erase the grating diffraction effect, and changing the index of the waveguide cladding to tune the evanescence of the guided mode. Firstly, we present and discuss the measurements of the diffraction efficiency of nano-imprint gratings impregnated with liquid crystal and refractive liquid index. Secondly, we discuss the results of integrated switchable extraction grating of the second strategy. &copy; 2023 SPIE.","714.3 Waveguides;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;741.3 Optical Devices and Systems;743 Holography;802.3 Chemical Operations",Active waveguides;Augmented reality/VR/MR display;Grating diffraction;Index contrasts;Liquid-crystals;Projection displays;Retinal projection displays;Switchable;Switchable gratings;Switchable waveguide extraction,Augmented reality;Diffraction;Diffraction gratings;Extraction;Holograms;Liquid crystal displays;Liquid crystals;Refractive index;Waveguides,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Toubi, Salaheddine; (1) Colard, Matthias; (1) Lee, Yann; (1) Racine, Benoit; (1) Suhm, Aurelien; (4) Grosso, David; (5) Kerzabi, Badre; (1) Martinez, Christophe; ","(1) Uni. Grenoble Alpes, CEA-LETI, France; (2) Univ. Grenoble Alpes, IMEP-LAHC, MINATEC, INPG, France; (3) IRIMAS, Univ. Haute-Alsace, France; (4) NOVA team, IM2NP, AMU, Univ. Aix-Marseille, France; (5) Solnil, 9 rue Mazenod, Marseille; 13002, France; ",SPIE,-1,"[""diffraction"", ""diffraction gratings"", ""extraction"", ""holograms"", ""liquid crystal displays"", ""liquid crystals"", ""refractive index"", ""waveguides""]","[""diffraction"", ""diffraction gratings"", ""extraction"", ""holograms"", ""liquid crystal displays"", ""liquid crystals"", ""refractive index"", ""waveguides""]",diffraction;diffraction gratings;extraction;holograms;liquid crystal displays;liquid crystals;refractive index;waveguides,graphics;input;optics;chemical;display technology,technology;displays;industries,graphics;input;optics;chemical;display technology,technology;displays;industries,diffraction diffraction_gratings extraction holograms liquid_crystal_displays liquid_crystals refractive_index waveguides active_waveguides augmented_reality vr mr_display grating_diffraction index_contrasts liquid crystals projection_displays retinal_projection_displays switchable switchable_gratings switchable_waveguide_extraction 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 743_holography 802 3_chemical_operations graphics input optics chemical display_technology,diffraction diffraction_gratings extraction holograms liquid_crystal_displays liquid_crystals refractive_index waveguides,active_waveguides augmented_reality vr mr_display grating_diffraction index_contrasts liquid crystals projection_displays retinal_projection_displays switchable switchable_gratings switchable_waveguide_extraction,augmented reality ar project investigating use retinal projection display based association pixelated hologram dense distribution waveguide study use grating impregnated liquid crystal actively extract light waveguide explore two extraction strategy tuning refractive index contrast grating teeth groove erase grating diffraction effect changing index waveguide cladding tune evanescence guided mode firstly present discus measurement diffraction efficiency nano imprint grating impregnated liquid crystal refractive liquid index secondly discus result integrated switchable extraction grating second strategy copy 2023 spie,diffraction diffraction_gratings extraction holograms liquid_crystal_displays liquid_crystals refractive_index waveguides active_waveguides augmented_reality vr mr_display grating_diffraction index_contrasts liquid crystals projection_displays retinal_projection_displays switchable switchable_gratings switchable_waveguide_extraction 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 743_holography 802 3_chemical_operations graphics input optics chemical display_technology augmented reality ar project investigating use retinal projection display based association pixelated hologram dense distribution waveguide study use grating impregnated liquid crystal actively extract light waveguide explore two extraction strategy tuning refractive index contrast grating teeth groove erase grating diffraction effect changing index waveguide cladding tune evanescence guided mode firstly present discus measurement diffraction efficiency nano imprint grating impregnated liquid crystal refractive liquid index secondly discus result integrated switchable extraction grating second strategy copy 2023 spie,augmented reality ar project investigating use retinal projection display based association pixelated hologram dense distribution waveguide study use grating impregnated liquid crystal actively extract light waveguide explore two extraction strategy tuning refractive index contrast grating teeth groove erase grating diffraction effect changing index waveguide cladding tune evanescence guided mode firstly present discus measurement diffraction efficiency nano imprint grating impregnated liquid crystal refractive liquid index secondly discus result integrated switchable extraction grating second strategy copy 2023 spiediffraction diffraction_gratings extraction holograms liquid_crystal_displays liquid_crystals refractive_index waveguidesactive_waveguides augmented_reality vr mr_display grating_diffraction index_contrasts liquid crystals projection_displays retinal_projection_displays switchable switchable_gratings switchable_waveguide_extraction
224,ProObjAR: Prototyping Spatially-aware Interactions of Smart Objects with AR-HMD,"Ye, H., Leng, J., Xiao, C., Wang, L., & Fu, H. (2023). ProObjAR: Prototyping Spatially-aware Interactions of Smart Objects with AR-HMD. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580750
",10.1145/3544548.3580750,"The rapid advances in technologies have brought new interaction paradigms of smart objects (e.g., digital devices) beyond digital device screens. By utilizing spatial properties, configurations, and movements of smart objects, designing spatial interaction, which is one of the emerging interaction paradigms, efficiently promotes engagement with digital content and physical facility. However, as an important phase of design, prototyping such interactions still remains challenging, since there is no ad-hoc approach for this emerging paradigm. Designers usually rely on methods that require fixed hardware setup and advanced coding skills to script and validate early-stage concepts. These requirements restrict the design process to a limited group of users in indoor scenes. To facilitate the prototyping to general usages, we aim to figure out the design difficulties and underlying needs of current design processes for spatially-aware object interactions by empirical studies. Besides, we explore the design space of the spatial interaction for smart objects and discuss the design space in an input-output spatial interaction model. Based on these findings, we present ProObjAR, an all-in-one novel prototyping system with an Augmented Reality Head Mounted Display (AR-HMD). Our system allows designers to easily obtain the spatial data of smart objects being prototyped, specify spatially-aware interactive behaviors from an input-output event triggering workflow, and test the prototyping results in situ. From the user study, we find that ProObjAR simplifies the design procedure and increases design efficiency to a large extent and thus advancing the development of spatially-aware applications in smart ecosystems.",C6130V Virtual reality;C6180 User interfaces,AR-HMD;augmented reality head mounted display;design difficulties;design efficiency;design space;digital device screens;input-output spatial interaction model;interaction paradigms;ProObjAR;prototyping spatially-aware interactions;smart objects;spatial data;spatial properties;spatially-aware interactive behaviors;spatially-aware object interactions,augmented reality;helmet mounted displays;interactive systems,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Ye, H.; (2) Leng, J.; (1) Xiao, C.; (2) Wang, L.; (1) Fu, H.; ","(1) City University of Hong Kong, School of Creative Media, China; (2) Beihang University, State Key Laboratory of Virtual Reality Technology and Systems, China; ",ACM,-1,"[""helmet mounted displays"", ""interactive systems""]","[""helmet mounted displays"", ""interactive systems""]",helmet mounted displays;interactive systems,display technology;education;wearables;input,technology;displays;industries,display technology;education;wearables;input,technology;displays;industries,helmet_mounted_displays interactive_systems ar hmd augmented_reality_head_mounted_display design_difficulties design_efficiency design_space digital_device_screens input output_spatial_interaction_model interaction_paradigms proobjar prototyping_spatially aware_interactions smart_objects spatial_data spatial_properties spatially aware_interactive_behaviors spatially aware_object_interactions c6130v_virtual_reality c6180_user_interfaces display_technology education wearables input,helmet_mounted_displays interactive_systems,ar hmd augmented_reality_head_mounted_display design_difficulties design_efficiency design_space digital_device_screens input output_spatial_interaction_model interaction_paradigms proobjar prototyping_spatially aware_interactions smart_objects spatial_data spatial_properties spatially aware_interactive_behaviors spatially aware_object_interactions,rapid advance technology brought new interaction paradigm smart object e g digital device beyond digital device screen utilizing spatial property configuration movement smart object designing spatial interaction one emerging interaction paradigm efficiently promotes engagement digital content physical facility however important phase design prototyping interaction still remains challenging since ad hoc approach emerging paradigm designer usually rely method require fixed hardware setup advanced coding skill script validate early stage concept requirement restrict design process limited group user indoor scene facilitate prototyping general usage aim figure design difficulty underlying need current design process spatially aware object interaction empirical study besides explore design space spatial interaction smart object discus design space input output spatial interaction model based finding present proobjar one novel prototyping system augmented reality head mounted display ar hmd system allows designer easily obtain spatial data smart object prototyped specify spatially aware interactive behavior input output event triggering workflow test prototyping result situ user study find proobjar simplifies design procedure increase design efficiency large extent thus advancing development spatially aware application smart ecosystem,helmet_mounted_displays interactive_systems ar hmd augmented_reality_head_mounted_display design_difficulties design_efficiency design_space digital_device_screens input output_spatial_interaction_model interaction_paradigms proobjar prototyping_spatially aware_interactions smart_objects spatial_data spatial_properties spatially aware_interactive_behaviors spatially aware_object_interactions c6130v_virtual_reality c6180_user_interfaces display_technology education wearables input rapid advance technology brought new interaction paradigm smart object e g digital device beyond digital device screen utilizing spatial property configuration movement smart object designing spatial interaction one emerging interaction paradigm efficiently promotes engagement digital content physical facility however important phase design prototyping interaction still remains challenging since ad hoc approach emerging paradigm designer usually rely method require fixed hardware setup advanced coding skill script validate early stage concept requirement restrict design process limited group user indoor scene facilitate prototyping general usage aim figure design difficulty underlying need current design process spatially aware object interaction empirical study besides explore design space spatial interaction smart object discus design space input output spatial interaction model based finding present proobjar one novel prototyping system augmented reality head mounted display ar hmd system allows designer easily obtain spatial data smart object prototyped specify spatially aware interactive behavior input output event triggering workflow test prototyping result situ user study find proobjar simplifies design procedure increase design efficiency large extent thus advancing development spatially aware application smart ecosystem,rapid advance technology brought new interaction paradigm smart object e g digital device beyond digital device screen utilizing spatial property configuration movement smart object designing spatial interaction one emerging interaction paradigm efficiently promotes engagement digital content physical facility however important phase design prototyping interaction still remains challenging since ad hoc approach emerging paradigm designer usually rely method require fixed hardware setup advanced coding skill script validate early stage concept requirement restrict design process limited group user indoor scene facilitate prototyping general usage aim figure design difficulty underlying need current design process spatially aware object interaction empirical study besides explore design space spatial interaction smart object discus design space input output spatial interaction model based finding present proobjar one novel prototyping system augmented reality head mounted display ar hmd system allows designer easily obtain spatial data smart object prototyped specify spatially aware interactive behavior input output event triggering workflow test prototyping result situ user study find proobjar simplifies design procedure increase design efficiency large extent thus advancing development spatially aware application smart ecosystemhelmet_mounted_displays interactive_systemsar hmd augmented_reality_head_mounted_display design_difficulties design_efficiency design_space digital_device_screens input output_spatial_interaction_model interaction_paradigms proobjar prototyping_spatially aware_interactions smart_objects spatial_data spatial_properties spatially aware_interactive_behaviors spatially aware_object_interactions
225,Dual-view holographic AR display based on Bragg mismatched reconstruction of the holographic optical element,"Qin, X., Sang, X., Li, H., Xiao, R., Zhong, C., Yan, B., Sun, Z., & Dong, Y. (2022). Dual‐view holographic AR display based on Bragg mismatched reconstruction of the holographic optical element. Journal of the Society for Information Display, 31(1), 46–56. Portico. https://doi.org/10.1002/jsid.1188
",10.1002/jsid.1188,"A method for dual-view holographic display based on Bragg mismatched reconstruction of holographic optical element (HOE) is proposed. Under the Bragg mismatched condition, the reconstructed images are guided into two separated viewing zones to realize dual-view holographic display. Meanwhile, the viewing angle of each perspective is increased to 11.2&#176;, which is almost 2.5 times as large as the traditional holographic display system. The design process of HOE is simple only by interference of plane reference wave and converging spherical signal wave, which has high practicability. Furthermore, the HOE can mix the virtual 3D image with real-world scenes, which could implement augmented reality (AR) display. Experiments validate that the proposed system can achieve dual-view holographic AR three-dimensional (3D) display with accommodation effect. &#169; 2023 Society for Information Display.","A4240E Holographic optical elements; holographic gratings;B4350 Holography;B6135 Optical, image and video signal processing;B7260 Display technology;C5260B Computer vision and image processing techniques;C6130V Virtual reality",augmented reality display;Bragg;converging spherical signal wave;dual-view holographic display;HOE;holographic optical element;plane reference wave;reconstructed images;separated viewing zones;three-dimensional display;traditional holographic display system;view holographic AR display,augmented reality;holographic displays;holographic optical elements;holography;image reconstruction,2023,Journal article (JA),J. Soc. Inf. Disp. (USA),"(1) Qin, X.; (1) Sang, X.; (2) Li, H.; (1) Xiao, R.; (1) Zhong, C.; (1) Yan, B.; (1) Sun, Z.; (1) Dong, Y.; ","(1) Beijing University of Posts and Telecommunications, State Key Laboratory of Information Photonics and Optical Communications, China; (2) Tsinghua University, Beijing National Research Center for Information Science and Technology, China; ",Wiley,-1,"[""holographic displays"", ""holographic optical elements"", ""holography"", ""image reconstruction""]","[""holographic displays"", ""holographic optical elements"", ""holography"", ""image reconstruction""]",holographic displays;holographic optical elements;holography;image reconstruction,construction;computer vision;optics;display technology,technology;displays;industries,construction;computer vision;optics;display technology,technology;displays;industries,holographic_displays holographic_optical_elements holography image_reconstruction augmented_reality_display bragg converging_spherical_signal_wave dual view_holographic_display hoe holographic_optical_element plane_reference_wave reconstructed_images separated_viewing_zones three dimensional_display traditional_holographic_display_system view_holographic_ar_display a4240e_holographic_optical_elements _holographic_gratings b4350_holography b6135_optical _image_and_video_signal_processing b7260_display_technology c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision optics display_technology,holographic_displays holographic_optical_elements holography image_reconstruction,augmented_reality_display bragg converging_spherical_signal_wave dual view_holographic_display hoe holographic_optical_element plane_reference_wave reconstructed_images separated_viewing_zones three dimensional_display traditional_holographic_display_system view_holographic_ar_display,method dual view holographic display based bragg mismatched reconstruction holographic optical element hoe proposed bragg mismatched condition reconstructed image guided two separated viewing zone realize dual view holographic display meanwhile viewing angle perspective increased 11 2 176 almost 2 5 time large traditional holographic display system design process hoe simple interference plane reference wave converging spherical signal wave high practicability furthermore hoe mix virtual 3d image real world scene could implement augmented reality ar display experiment validate proposed system achieve dual view holographic ar three dimensional 3d display accommodation effect 169 2023 society information display,holographic_displays holographic_optical_elements holography image_reconstruction augmented_reality_display bragg converging_spherical_signal_wave dual view_holographic_display hoe holographic_optical_element plane_reference_wave reconstructed_images separated_viewing_zones three dimensional_display traditional_holographic_display_system view_holographic_ar_display a4240e_holographic_optical_elements _holographic_gratings b4350_holography b6135_optical _image_and_video_signal_processing b7260_display_technology c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision optics display_technology method dual view holographic display based bragg mismatched reconstruction holographic optical element hoe proposed bragg mismatched condition reconstructed image guided two separated viewing zone realize dual view holographic display meanwhile viewing angle perspective increased 11 2 176 almost 2 5 time large traditional holographic display system design process hoe simple interference plane reference wave converging spherical signal wave high practicability furthermore hoe mix virtual 3d image real world scene could implement augmented reality ar display experiment validate proposed system achieve dual view holographic ar three dimensional 3d display accommodation effect 169 2023 society information display,method dual view holographic display based bragg mismatched reconstruction holographic optical element hoe proposed bragg mismatched condition reconstructed image guided two separated viewing zone realize dual view holographic display meanwhile viewing angle perspective increased 11 2 176 almost 2 5 time large traditional holographic display system design process hoe simple interference plane reference wave converging spherical signal wave high practicability furthermore hoe mix virtual 3d image real world scene could implement augmented reality ar display experiment validate proposed system achieve dual view holographic ar three dimensional 3d display accommodation effect 169 2023 society information displayholographic_displays holographic_optical_elements holography image_reconstructionaugmented_reality_display bragg converging_spherical_signal_wave dual view_holographic_display hoe holographic_optical_element plane_reference_wave reconstructed_images separated_viewing_zones three dimensional_display traditional_holographic_display_system view_holographic_ar_display
226,An Innovative Development with Multidisciplinary Perspective in Metaverse Integrating with Blockchain Technology with Cloud Computing Techniques,"Mandala, V., Jeyarani, M. A. R., Kousalya, A., M, P., & Arumugam, M. (2023). An Innovative Development with Multidisciplinary Perspective in Metaverse Integrating with Blockchain Technology with Cloud Computing Techniques. 2023 International Conference on Inventive Computation Technologies (ICICT). https://doi.org/10.1109/icict57646.2023.10134108
",10.1109/ICICT57646.2023.10134108,"The metaverse is a concept of creating an innovative virtual 3D environment immersed with social interconnections. This is the process of establishing the real world into a virtual environment through virtual and augmented reality. The metaverse is considered as the advanced recapitulation of the online platform. The virtual platform adopted through the digital environment helps in improvement with dilute in everyday lives. Thus the future revolution is done through the various advances and challenges in the virtual world. Hence the metaverse is the amalgamation of numerous technologies. The interconnections with the physical environment with the virtual world helps in the sharing of information in diverse field. The development of the digital environment through the exact replica of the real world helps in the overall development in social, economic and political fields. The important requirements of metaverse includes sensors, smart glasses with headsets. The necessary parameter needed to adopt is the privacy of the users in the metaverse environment. This is done through the blockchain technology with cloud computing techniques.",C6130V Virtual reality;C6130S Data security;C6160B Distributed databases;C6190J Internet software;C7210N Information networks,advanced recapitulation;augmented reality;blockchain technology;cloud computing techniques;digital environment;economic fields;innovative development;innovative virtual 3D environment;metaverse environment;metaverse integrating;multidisciplinary perspective;numerous technologies;online platform;physical environment;political fields;social fields;social interconnections;virtual environment;virtual platform;virtual reality;virtual world,augmented reality;blockchains;cloud computing;virtual reality,2023,Conference article (CA),2023 International Conference on Inventive Computation Technologies (ICICT),"(1) Mandala, V.; (2) Jeyarani, M.A.; (3) Kousalya, A.; (4) M, P.; (5) Arumugam, M.; ","(1) Indiana University, United States; (2) K. Ramakrishnan College of Technology, Department of Artificial Intelligence, India; (3) Sri Krishna College of Engineering and Technology, Department of Information Technology, India; (4) Jansons Institute of Technology, Department of Computer Science and Engineering, India; (5) Kongu Engineering College, Department of CT-PG; ",IEEE,-1,"[""blockchains"", ""cloud computing""]","[""blockchains"", ""cloud computing""]",blockchains;cloud computing,other;security;networks,technology;other,other;security;networks,technology;other,blockchains cloud_computing advanced_recapitulation augmented_reality blockchain_technology cloud_computing_techniques digital_environment economic_fields innovative_development innovative_virtual_3d_environment metaverse_environment metaverse_integrating multidisciplinary_perspective numerous_technologies online_platform physical_environment political_fields social_fields social_interconnections virtual_environment virtual_platform virtual_reality virtual_world c6130v_virtual_reality c6130s_data_security c6160b_distributed_databases c6190j_internet_software c7210n_information_networks other security networks,blockchains cloud_computing,advanced_recapitulation augmented_reality blockchain_technology cloud_computing_techniques digital_environment economic_fields innovative_development innovative_virtual_3d_environment metaverse_environment metaverse_integrating multidisciplinary_perspective numerous_technologies online_platform physical_environment political_fields social_fields social_interconnections virtual_environment virtual_platform virtual_reality virtual_world,metaverse concept creating innovative virtual 3d environment immersed social interconnection process establishing real world virtual environment virtual augmented reality metaverse considered advanced recapitulation online platform virtual platform adopted digital environment help improvement dilute everyday life thus future revolution done various advance challenge virtual world hence metaverse amalgamation numerous technology interconnection physical environment virtual world help sharing information diverse field development digital environment exact replica real world help overall development social economic political field important requirement metaverse includes sensor smart glass headset necessary parameter needed adopt privacy user metaverse environment done blockchain technology cloud computing technique,blockchains cloud_computing advanced_recapitulation augmented_reality blockchain_technology cloud_computing_techniques digital_environment economic_fields innovative_development innovative_virtual_3d_environment metaverse_environment metaverse_integrating multidisciplinary_perspective numerous_technologies online_platform physical_environment political_fields social_fields social_interconnections virtual_environment virtual_platform virtual_reality virtual_world c6130v_virtual_reality c6130s_data_security c6160b_distributed_databases c6190j_internet_software c7210n_information_networks other security networks metaverse concept creating innovative virtual 3d environment immersed social interconnection process establishing real world virtual environment virtual augmented reality metaverse considered advanced recapitulation online platform virtual platform adopted digital environment help improvement dilute everyday life thus future revolution done various advance challenge virtual world hence metaverse amalgamation numerous technology interconnection physical environment virtual world help sharing information diverse field development digital environment exact replica real world help overall development social economic political field important requirement metaverse includes sensor smart glass headset necessary parameter needed adopt privacy user metaverse environment done blockchain technology cloud computing technique,metaverse concept creating innovative virtual 3d environment immersed social interconnection process establishing real world virtual environment virtual augmented reality metaverse considered advanced recapitulation online platform virtual platform adopted digital environment help improvement dilute everyday life thus future revolution done various advance challenge virtual world hence metaverse amalgamation numerous technology interconnection physical environment virtual world help sharing information diverse field development digital environment exact replica real world help overall development social economic political field important requirement metaverse includes sensor smart glass headset necessary parameter needed adopt privacy user metaverse environment done blockchain technology cloud computing techniqueblockchains cloud_computingadvanced_recapitulation augmented_reality blockchain_technology cloud_computing_techniques digital_environment economic_fields innovative_development innovative_virtual_3d_environment metaverse_environment metaverse_integrating multidisciplinary_perspective numerous_technologies online_platform physical_environment political_fields social_fields social_interconnections virtual_environment virtual_platform virtual_reality virtual_world
227,Employing AR/MR Mockups to Imagine Future Custom Manufacturing Practices,"Franze, A. P., Caldwell, G. A., Teixeira, M. F. L. A., & Rittenbruch, M. (2022). Employing AR/MR Mockups to Imagine Future Custom Manufacturing Practices. Proceedings of the 34th Australian Conference on Human-Computer Interaction. https://doi.org/10.1145/3572921.3576201
",10.1145/3572921.3576201,"Versatile augmented reality (AR)/mixed reality (MR) technologies align with custom manufacturers' resource constraints and support their requirement for agility in responding to unique Industry 4.0 challenges. However, for Australian custom manufacturers, AR/MR uptake remains low. This modest-sized case study seeks to support resource-constrained custom manufacturers by exploring current AR/MR adoption challenges and potentials. Underpinned by a Research-through-Design (RtD) methodology and building upon Situated and Participative Enactment of Scenarios (SPES) methods, we reflect on using novel Microsoft HoloLens 2 AR/MR mockups to support in-situ enactments with domain experts to collaboratively imagine and design more productive and efficient augmented fabrication and assembly practices. In exploring new ways of making and doing through AR/MR, we find promising pathways for Australian custom manufacturers to add value across a product's lifecycle. Our findings identify five key areas for further research, which will be explored and developed through workshops around each identified AR/MR application area.",C7480 Production engineering computing;C6130V Virtual reality;E0410D Industrial applications of IT,AR-MR mockups;assembly practices;augmented fabrication;augmented reality technology;Australian custom manufacturers;future custom manufacturing practices;Industry 4.0;Microsoft HoloLens 2;mixed reality technology;Research-through-Design methodology;resource-constrained custom manufacturers;RtD;situated and participative enactment of scenarios methods;SPES,augmented reality;manufacturing systems;virtual manufacturing,2022,Conference article (CA),OzCHI '22: Proceedings of the 34th Australian Conference on Human-Computer Interaction,"(1) Franze, A.P.; (2) Caldwell, G.A.; (3) Teixeira, M.F.L.A.; (4) Rittenbruch, M.; ","(1) Queensland University of Technology, Schoole of Architecture and Built Environment, Brisbane, QLD, Australia; (2) Queensland University of Technology, QUT Design Lab, Brisbane, QLD, Australia; (3) Queensland University of Technology, School of Design, Brisbane, QLD, Australia; (4) Queensland University of Technology, Design Lab, Brisbane, QLD, Australia; ",ACM,-1,"[""manufacturing systems"", ""virtual manufacturing""]","[""manufacturing systems"", ""virtual manufacturing""]",manufacturing systems;virtual manufacturing,education;manufacturing,industries,education;manufacturing,industries,manufacturing_systems virtual_manufacturing ar mr_mockups assembly_practices augmented_fabrication augmented_reality_technology australian_custom_manufacturers future_custom_manufacturing_practices industry_4 0 microsoft_hololens_2 mixed_reality_technology research through design_methodology resource constrained_custom_manufacturers rtd situated_and_participative_enactment_of_scenarios_methods spes c7480_production_engineering_computing c6130v_virtual_reality e0410d_industrial_applications_of_it education manufacturing,manufacturing_systems virtual_manufacturing,ar mr_mockups assembly_practices augmented_fabrication augmented_reality_technology australian_custom_manufacturers future_custom_manufacturing_practices industry_4 0 microsoft_hololens_2 mixed_reality_technology research through design_methodology resource constrained_custom_manufacturers rtd situated_and_participative_enactment_of_scenarios_methods spes,versatile augmented reality ar mixed reality mr technology align custom manufacturer resource constraint support requirement agility responding unique industry 4 0 challenge however australian custom manufacturer ar mr uptake remains low modest sized case study seek support resource constrained custom manufacturer exploring current ar mr adoption challenge potential underpinned research design rtd methodology building upon situated participative enactment scenario spes method reflect using novel microsoft hololens 2 ar mr mockups support situ enactment domain expert collaboratively imagine design productive efficient augmented fabrication assembly practice exploring new way making ar mr find promising pathway australian custom manufacturer add value across product lifecycle finding identify five key area research explored developed workshop around identified ar mr application area,manufacturing_systems virtual_manufacturing ar mr_mockups assembly_practices augmented_fabrication augmented_reality_technology australian_custom_manufacturers future_custom_manufacturing_practices industry_4 0 microsoft_hololens_2 mixed_reality_technology research through design_methodology resource constrained_custom_manufacturers rtd situated_and_participative_enactment_of_scenarios_methods spes c7480_production_engineering_computing c6130v_virtual_reality e0410d_industrial_applications_of_it education manufacturing versatile augmented reality ar mixed reality mr technology align custom manufacturer resource constraint support requirement agility responding unique industry 4 0 challenge however australian custom manufacturer ar mr uptake remains low modest sized case study seek support resource constrained custom manufacturer exploring current ar mr adoption challenge potential underpinned research design rtd methodology building upon situated participative enactment scenario spes method reflect using novel microsoft hololens 2 ar mr mockups support situ enactment domain expert collaboratively imagine design productive efficient augmented fabrication assembly practice exploring new way making ar mr find promising pathway australian custom manufacturer add value across product lifecycle finding identify five key area research explored developed workshop around identified ar mr application area,versatile augmented reality ar mixed reality mr technology align custom manufacturer resource constraint support requirement agility responding unique industry 4 0 challenge however australian custom manufacturer ar mr uptake remains low modest sized case study seek support resource constrained custom manufacturer exploring current ar mr adoption challenge potential underpinned research design rtd methodology building upon situated participative enactment scenario spes method reflect using novel microsoft hololens 2 ar mr mockups support situ enactment domain expert collaboratively imagine design productive efficient augmented fabrication assembly practice exploring new way making ar mr find promising pathway australian custom manufacturer add value across product lifecycle finding identify five key area research explored developed workshop around identified ar mr application areamanufacturing_systems virtual_manufacturingar mr_mockups assembly_practices augmented_fabrication augmented_reality_technology australian_custom_manufacturers future_custom_manufacturing_practices industry_4 0 microsoft_hololens_2 mixed_reality_technology research through design_methodology resource constrained_custom_manufacturers rtd situated_and_participative_enactment_of_scenarios_methods spes
228,"Evaluation of a pixelated holographic display concept for a Near Eye Display, recent results and technological developments","Martinez, C., Colard, M., Fowler, D., Lee, Y., Meunier-Della-Gatta, S., Millard, K., Rainouard, F., & Toubi, S. (2023). Evaluation of a pixelated holographic display concept for a near-eye display: recent results and technological developments. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2650111
",10.1117/12.2650111,"The development of an ideal optical system to support Mixed Reality and Augmented Reality (AR) applications has raised a lot of interest in the scientific community in the last decades. The perfect device remains an inaccessible target and researchers have to focus on the optimization of some specific behaviors. Several years ago, we introduced a disruptive display concept to push the device integration to the limit, with the suppression of the optical system. This allows the imaging process to be considered in a different way with a specific monitoring of the field of view. With this &lsquo;smart glass&rsquo; concept, the glass is the display and the image is formed directly onto the retina with a combination of refractive and diffractive effects. This conceptual target allowed us to define a technological roadmap to support our development. Technologies involved in this concept concern principally the field of Photonic Integrated Circuits in the visible range, digital/analogic holography and Liquid Crystal devices. We will present the current state of our research with a particular focus on the holographic display element. Recent results related to analogic pixelated hologram recording validate and question both our technological and conceptual approach. We will show images formed by sparse holographic pixel distributions with controlled angular characteristics that demonstrate the mix of refractive and diffractive effects. The transmission behavior of this holographic device will also be analyzed. &copy; 2023 SPIE.","722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.3 Optical Devices and Systems;743 Holography;812.3 Glass",Augmented reality applications;Devices integration;Field of views;Imaging process;Mixed reality;Near eye device;Optimisations;Scientific community;Sparse aperture imaging;Technological development,Augmented reality;Digital devices;Glass;Holograms;Liquid crystal displays;Liquid crystals;Mixed reality;Optical systems,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Martinez, Christophe; (1) Colard, Matthias; (1) Fowler, Daivid; (1) Lee, Yann; (1) Meunier-Della-Gatta, Sylvia; (1) Millard, Kyllian; (1) Rainouard, Fabian; (1) Toubi, Salaheddine; ","(1) Univ. Grenoble Alpes, CEA, Leti, Grenoble; F-38000, France; (2) Institut de Recherche en Informatique, Math&eacute;matiques, Automatique et Signal (IRIMAS UR UHA 7499), Universit&eacute; de Haute-Alsace, Mulhouse; Cedex 68093, France; (3) Univ. Grenoble Alpes, IMEP - LAHC, MINATEC - INPG, Grenoble; 38016, France; (4) Univ. Grenoble Alpes, Laboratoire Jean Kuntzmann, Grenoble; 38400, France; ",SPIE,-1,"[""digital devices"", ""glass"", ""holograms"", ""liquid crystal displays"", ""liquid crystals"", ""optical systems""]","[""digital devices"", ""glass"", ""holograms"", ""liquid crystal displays"", ""liquid crystals"", ""optical systems""]",digital devices;glass;holograms;liquid crystal displays;liquid crystals;optical systems,education;graphics;optics;chemical;display technology,technology;displays;industries,education;graphics;optics;chemical;display technology,technology;displays;industries,digital_devices glass holograms liquid_crystal_displays liquid_crystals optical_systems augmented_reality_applications devices_integration field_of_views imaging_process mixed_reality near_eye_device optimisations scientific_community sparse_aperture_imaging technological_development 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 743_holography 812 3_glass education graphics optics chemical display_technology,digital_devices glass holograms liquid_crystal_displays liquid_crystals optical_systems,augmented_reality_applications devices_integration field_of_views imaging_process mixed_reality near_eye_device optimisations scientific_community sparse_aperture_imaging technological_development,development ideal optical system support mixed reality augmented reality ar application raised lot interest scientific community last decade perfect device remains inaccessible target researcher focus optimization specific behavior several year ago introduced disruptive display concept push device integration limit suppression optical system allows imaging process considered different way specific monitoring field view lsquo smart glass rsquo concept glass display image formed directly onto retina combination refractive diffractive effect conceptual target allowed u define technological roadmap support development technology involved concept concern principally field photonic integrated circuit visible range digital analogic holography liquid crystal device present current state research particular focus holographic display element recent result related analogic pixelated hologram recording validate question technological conceptual approach show image formed sparse holographic pixel distribution controlled angular characteristic demonstrate mix refractive diffractive effect transmission behavior holographic device also analyzed copy 2023 spie,digital_devices glass holograms liquid_crystal_displays liquid_crystals optical_systems augmented_reality_applications devices_integration field_of_views imaging_process mixed_reality near_eye_device optimisations scientific_community sparse_aperture_imaging technological_development 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 743_holography 812 3_glass education graphics optics chemical display_technology development ideal optical system support mixed reality augmented reality ar application raised lot interest scientific community last decade perfect device remains inaccessible target researcher focus optimization specific behavior several year ago introduced disruptive display concept push device integration limit suppression optical system allows imaging process considered different way specific monitoring field view lsquo smart glass rsquo concept glass display image formed directly onto retina combination refractive diffractive effect conceptual target allowed u define technological roadmap support development technology involved concept concern principally field photonic integrated circuit visible range digital analogic holography liquid crystal device present current state research particular focus holographic display element recent result related analogic pixelated hologram recording validate question technological conceptual approach show image formed sparse holographic pixel distribution controlled angular characteristic demonstrate mix refractive diffractive effect transmission behavior holographic device also analyzed copy 2023 spie,development ideal optical system support mixed reality augmented reality ar application raised lot interest scientific community last decade perfect device remains inaccessible target researcher focus optimization specific behavior several year ago introduced disruptive display concept push device integration limit suppression optical system allows imaging process considered different way specific monitoring field view lsquo smart glass rsquo concept glass display image formed directly onto retina combination refractive diffractive effect conceptual target allowed u define technological roadmap support development technology involved concept concern principally field photonic integrated circuit visible range digital analogic holography liquid crystal device present current state research particular focus holographic display element recent result related analogic pixelated hologram recording validate question technological conceptual approach show image formed sparse holographic pixel distribution controlled angular characteristic demonstrate mix refractive diffractive effect transmission behavior holographic device also analyzed copy 2023 spiedigital_devices glass holograms liquid_crystal_displays liquid_crystals optical_systemsaugmented_reality_applications devices_integration field_of_views imaging_process mixed_reality near_eye_device optimisations scientific_community sparse_aperture_imaging technological_development
229,Bridging Curatorial Intent and Visiting Experience: Using AR Guidance as a Storytelling Tool,"Gao, Z., Wang, A., Hui, P., & Braud, T. (2022). Bridging Curatorial Intent and Visiting Experience: Using AR Guidance as a Storytelling Tool. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574438
",10.1145/3574131.3574438,"Augmented Reality (AR) visits enhances the art exhibition experience by overlaying digital content. Although there has been significant interest in AR guides, few works leverage AR to bridge curatorial intent and audiences understanding. This paper focuses on integrating the curatorial intent within the AR overlays by developing the narrative layers established by the relationships between works. We develop a narrative system that identifies and links the primary art pieces of the exhibition within a digital story consistent with the curator's perspective. The system is applied to a physical exhibition composed of seven art pieces. We evaluate the impact of AR overlays through two user experiments, conducted on art professionals and general audience, respectively. Both groups considered that the AR tour system improved interactivity, self-reported learning, and user satisfaction significantly (&gt; 4/5). Besides, visitors found the system easy to get to do what they want to (4.7/5), and would use it for future visits (4.6/5). This study raises essential design considerations towards designing integrated AR museum guides that combine the perspective of artists and curators towards a better visiting experience.",C7820 Humanities computing;C6130M Multimedia;C6130V Virtual reality,AR overlays;AR tour system;art exhibition experience;art professionals;augmented reality visits;bridging curatorial intent;curator;digital story;integrated AR museum guides;narrative system;physical exhibition;primary art pieces;storytelling tool;user experiments;visiting experience,art;augmented reality;exhibitions;multimedia computing;museums,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Gao, Z.; (1) Wang, A.; (1) Hui, P.; (1) Braud, T.; ","(1) Hong Kong University of Science and Technology, China; ",ACM,-1,"[""art"", ""exhibitions"", ""multimedia computing"", ""museums""]","[""art"", ""exhibitions"", ""multimedia computing"", ""museums""]",art;exhibitions;multimedia computing;museums,sales and marketing;cultural heritage;liberal arts;education,business;industries,sales and marketing;cultural heritage;liberal arts;education,business;industries,art exhibitions multimedia_computing museums ar_overlays ar_tour_system art_exhibition_experience art_professionals augmented_reality_visits bridging_curatorial_intent curator digital_story integrated_ar_museum_guides narrative_system physical_exhibition primary_art_pieces storytelling_tool user_experiments visiting_experience c7820_humanities_computing c6130m_multimedia c6130v_virtual_reality sales_and_marketing cultural_heritage liberal_arts education,art exhibitions multimedia_computing museums,ar_overlays ar_tour_system art_exhibition_experience art_professionals augmented_reality_visits bridging_curatorial_intent curator digital_story integrated_ar_museum_guides narrative_system physical_exhibition primary_art_pieces storytelling_tool user_experiments visiting_experience,augmented reality ar visit enhances art exhibition experience overlaying digital content although significant interest ar guide work leverage ar bridge curatorial intent audience understanding paper focus integrating curatorial intent within ar overlay developing narrative layer established relationship work develop narrative system identifies link primary art piece exhibition within digital story consistent curator perspective system applied physical exhibition composed seven art piece evaluate impact ar overlay two user experiment conducted art professional general audience respectively group considered ar tour system improved interactivity self reported learning user satisfaction significantly gt 4 5 besides visitor found system easy get want 4 7 5 would use future visit 4 6 5 study raise essential design consideration towards designing integrated ar museum guide combine perspective artist curator towards better visiting experience,art exhibitions multimedia_computing museums ar_overlays ar_tour_system art_exhibition_experience art_professionals augmented_reality_visits bridging_curatorial_intent curator digital_story integrated_ar_museum_guides narrative_system physical_exhibition primary_art_pieces storytelling_tool user_experiments visiting_experience c7820_humanities_computing c6130m_multimedia c6130v_virtual_reality sales_and_marketing cultural_heritage liberal_arts education augmented reality ar visit enhances art exhibition experience overlaying digital content although significant interest ar guide work leverage ar bridge curatorial intent audience understanding paper focus integrating curatorial intent within ar overlay developing narrative layer established relationship work develop narrative system identifies link primary art piece exhibition within digital story consistent curator perspective system applied physical exhibition composed seven art piece evaluate impact ar overlay two user experiment conducted art professional general audience respectively group considered ar tour system improved interactivity self reported learning user satisfaction significantly gt 4 5 besides visitor found system easy get want 4 7 5 would use future visit 4 6 5 study raise essential design consideration towards designing integrated ar museum guide combine perspective artist curator towards better visiting experience,augmented reality ar visit enhances art exhibition experience overlaying digital content although significant interest ar guide work leverage ar bridge curatorial intent audience understanding paper focus integrating curatorial intent within ar overlay developing narrative layer established relationship work develop narrative system identifies link primary art piece exhibition within digital story consistent curator perspective system applied physical exhibition composed seven art piece evaluate impact ar overlay two user experiment conducted art professional general audience respectively group considered ar tour system improved interactivity self reported learning user satisfaction significantly gt 4 5 besides visitor found system easy get want 4 7 5 would use future visit 4 6 5 study raise essential design consideration towards designing integrated ar museum guide combine perspective artist curator towards better visiting experienceart exhibitions multimedia_computing museumsar_overlays ar_tour_system art_exhibition_experience art_professionals augmented_reality_visits bridging_curatorial_intent curator digital_story integrated_ar_museum_guides narrative_system physical_exhibition primary_art_pieces storytelling_tool user_experiments visiting_experience
230,AI Stethoscope for Home Self-Diagnosis with AR Guidance,"Hou, K., Xia, S., Wu, J., Zhao, M., Bejerano, E., & Jiang, X. (2022). AI Stethoscope for Home Self-Diagnosis with AR Guidance. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568082
",10.1145/3560905.3568082,"Cardiopulmonary ailments are a major cause of mortality. Stethoscopes are one of the most important tools that healthcare professionals use to screen patients for a variety of ailments, especially those related to the heart and lungs. Despite the growth of digital stethoscopes on the market, it takes years of training to properly use stethoscopes to listen for abnormal sounds within the body. In this demonstration, we present an intelligent stethoscope platform that makes stethoscopes more accessible to the general population. Our platform utilizes augmented reality (AR) to provide real-time guidance on where to properly place the stethoscope on the body, enabling the general population to screen themselves for ailments.",A8770E Patient diagnostic methods and instrumentation;B6140 Signal processing and detection;B7510 Biomedical measurement and imaging;C5260 Digital signal processing;C6130V Virtual reality;C6260 Machine learning (artificial intelligence);C7140 Medical administration;C7330 Biology and medical computing,AI stethoscope;AR guidance;augmented reality;cardiopulmonary ailments;digital stethoscopes;healthcare professionals;heart;home self-diagnosis;intelligent stethoscope platform;lungs,augmented reality;bioacoustics;cardiology;diseases;health care;learning (artificial intelligence);lung;medical signal processing;patient diagnosis,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Hou, K.; (1) Xia, S.; (1) Wu, J.; (1) Zhao, M.; (1) Bejerano, E.; (1) Jiang, X.; ","(1) Columbia University, New York, NY, United States; ",ACM,-1,"[""bioacoustics"", ""cardiology"", ""diseases"", ""health care"", ""learning algorithms"", ""lung"", ""medical signal processing"", ""patient diagnosis""]","[""bioacoustics"", ""cardiology"", ""diseases"", ""health care"", ""learning algorithms"", ""lung"", ""medical signal processing"", ""patient diagnosis""]",bioacoustics;cardiology;diseases;health care;learning algorithms;lung;medical signal processing;patient diagnosis,medical;sensors;data;audio;artificial intelligence,technology;industries,medical;sensors;data;audio;artificial intelligence,technology;industries,bioacoustics cardiology diseases health_care learning_algorithms lung medical_signal_processing patient_diagnosis ai_stethoscope ar_guidance augmented_reality cardiopulmonary_ailments digital_stethoscopes healthcare_professionals heart home_self diagnosis intelligent_stethoscope_platform lungs a8770e_patient_diagnostic_methods_and_instrumentation b6140_signal_processing_and_detection b7510_biomedical_measurement_and_imaging c5260_digital_signal_processing c6130v_virtual_reality c6260_machine_learning_ artificial_intelligence c7140_medical_administration c7330_biology_and_medical_computing medical sensors data audio artificial_intelligence,bioacoustics cardiology diseases health_care learning_algorithms lung medical_signal_processing patient_diagnosis,ai_stethoscope ar_guidance augmented_reality cardiopulmonary_ailments digital_stethoscopes healthcare_professionals heart home_self diagnosis intelligent_stethoscope_platform lungs,cardiopulmonary ailment major cause mortality stethoscope one important tool healthcare professional use screen patient variety ailment especially related heart lung despite growth digital stethoscope market take year training properly use stethoscope listen abnormal sound within body demonstration present intelligent stethoscope platform make stethoscope accessible general population platform utilizes augmented reality ar provide real time guidance properly place stethoscope body enabling general population screen ailment,bioacoustics cardiology diseases health_care learning_algorithms lung medical_signal_processing patient_diagnosis ai_stethoscope ar_guidance augmented_reality cardiopulmonary_ailments digital_stethoscopes healthcare_professionals heart home_self diagnosis intelligent_stethoscope_platform lungs a8770e_patient_diagnostic_methods_and_instrumentation b6140_signal_processing_and_detection b7510_biomedical_measurement_and_imaging c5260_digital_signal_processing c6130v_virtual_reality c6260_machine_learning_ artificial_intelligence c7140_medical_administration c7330_biology_and_medical_computing medical sensors data audio artificial_intelligence cardiopulmonary ailment major cause mortality stethoscope one important tool healthcare professional use screen patient variety ailment especially related heart lung despite growth digital stethoscope market take year training properly use stethoscope listen abnormal sound within body demonstration present intelligent stethoscope platform make stethoscope accessible general population platform utilizes augmented reality ar provide real time guidance properly place stethoscope body enabling general population screen ailment,cardiopulmonary ailment major cause mortality stethoscope one important tool healthcare professional use screen patient variety ailment especially related heart lung despite growth digital stethoscope market take year training properly use stethoscope listen abnormal sound within body demonstration present intelligent stethoscope platform make stethoscope accessible general population platform utilizes augmented reality ar provide real time guidance properly place stethoscope body enabling general population screen ailmentbioacoustics cardiology diseases health_care learning_algorithms lung medical_signal_processing patient_diagnosisai_stethoscope ar_guidance augmented_reality cardiopulmonary_ailments digital_stethoscopes healthcare_professionals heart home_self diagnosis intelligent_stethoscope_platform lungs
231,Performance of 802.11be Wi-Fi 7 with Multi-Link Operation on AR Applications,"Alsakati, M., Pettersson, C., Max, S., Moothedath, V. N., & Gross, J. (2023). Performance of 802.11be Wi-Fi 7 with Multi-Link Operation on AR Applications. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118866
",10.1109/WCNC55385.2023.10118866,"Since its first release in the late 1990s, Wi-Fi has been updated to keep up with evolving user needs. Recently, Wi-Fi and other radio access technologies have been pushed to their edge when serving Augmented Reality (AR) applications. AR applications require high throughput, low latency, and high reliability to ensure a high-quality user experience. The 802.11be amendment - which will be marketed as Wi-Fi 7 - introduces several features that aim to enhance its capabilities to support challenging applications like AR. One of the main features introduced in this amendment is Multi-Link Operation (MLO) which allows nodes to transmit and receive over multiple links concurrently. When using MLO, traffic is distributed among links using an implementation-specific traffic-to-link allocation policy. This paper aims to evaluate the performance of MLO, using different policies, in serving AR applications compared to Single-Link (SL). Experimental simulations using an event-based Wi-Fi simulator have been conducted. Our results show the general superiority of MLO when serving AR applications. MLO achieves lower latency and serves a higher number of AR users compared to SL with the same frequency resources. In addition, increasing the number of links can improve the performance of MLO. Regarding traffic-to-link allocation policies, we found that policies can be more susceptible to channel blocking, resulting in possible performance degradation.",B6250B Radio access systems;B6210L Computer communications;C5620L Local area networks,AR applications;augmented reality applications;event-based Wi-Fi simulator;high reliability;high-quality user experience;implementation-specific traffic-to-link allocation policy;MLO;MultiLink Operation;multiple links;Single-Link;traffic-to-link allocation policies,augmented reality;next generation networks;radio access networks;wireless LAN,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Alsakati, M.; (2) Pettersson, C.; (3) Max, S.; (1) Moothedath, V.N.; (1) Gross, J.; ","(1) KTH Royal Institute of Technology, Department of Intelligent Systems, Sweden; (2) Ericsson Research, Sweden; (3) Ericsson Research, Germany; ",IEEE,-1,"[""next generation networks"", ""radio access networks"", ""wireless lan""]","[""next generation networks"", ""radio access networks"", ""wireless lan""]",next generation networks;radio access networks;wireless lan,telecommunication;networks,technology;industries,telecommunication;networks,technology;industries,next_generation_networks radio_access_networks wireless_lan ar_applications augmented_reality_applications event based_wi fi_simulator high_reliability high quality_user_experience implementation specific_traffic to link_allocation_policy mlo multilink_operation multiple_links single link traffic to link_allocation_policies b6250b_radio_access_systems b6210l_computer_communications c5620l_local_area_networks telecommunication networks,next_generation_networks radio_access_networks wireless_lan,ar_applications augmented_reality_applications event based_wi fi_simulator high_reliability high quality_user_experience implementation specific_traffic to link_allocation_policy mlo multilink_operation multiple_links single link traffic to link_allocation_policies,since first release late 1990s wi fi updated keep evolving user need recently wi fi radio access technology pushed edge serving augmented reality ar application ar application require high throughput low latency high reliability ensure high quality user experience 802 11be amendment marketed wi fi 7 introduces several feature aim enhance capability support challenging application like ar one main feature introduced amendment multi link operation mlo allows node transmit receive multiple link concurrently using mlo traffic distributed among link using implementation specific traffic link allocation policy paper aim evaluate performance mlo using different policy serving ar application compared single link sl experimental simulation using event based wi fi simulator conducted result show general superiority mlo serving ar application mlo achieves lower latency serf higher number ar user compared sl frequency resource addition increasing number link improve performance mlo regarding traffic link allocation policy found policy susceptible channel blocking resulting possible performance degradation,next_generation_networks radio_access_networks wireless_lan ar_applications augmented_reality_applications event based_wi fi_simulator high_reliability high quality_user_experience implementation specific_traffic to link_allocation_policy mlo multilink_operation multiple_links single link traffic to link_allocation_policies b6250b_radio_access_systems b6210l_computer_communications c5620l_local_area_networks telecommunication networks since first release late 1990s wi fi updated keep evolving user need recently wi fi radio access technology pushed edge serving augmented reality ar application ar application require high throughput low latency high reliability ensure high quality user experience 802 11be amendment marketed wi fi 7 introduces several feature aim enhance capability support challenging application like ar one main feature introduced amendment multi link operation mlo allows node transmit receive multiple link concurrently using mlo traffic distributed among link using implementation specific traffic link allocation policy paper aim evaluate performance mlo using different policy serving ar application compared single link sl experimental simulation using event based wi fi simulator conducted result show general superiority mlo serving ar application mlo achieves lower latency serf higher number ar user compared sl frequency resource addition increasing number link improve performance mlo regarding traffic link allocation policy found policy susceptible channel blocking resulting possible performance degradation,since first release late 1990s wi fi updated keep evolving user need recently wi fi radio access technology pushed edge serving augmented reality ar application ar application require high throughput low latency high reliability ensure high quality user experience 802 11be amendment marketed wi fi 7 introduces several feature aim enhance capability support challenging application like ar one main feature introduced amendment multi link operation mlo allows node transmit receive multiple link concurrently using mlo traffic distributed among link using implementation specific traffic link allocation policy paper aim evaluate performance mlo using different policy serving ar application compared single link sl experimental simulation using event based wi fi simulator conducted result show general superiority mlo serving ar application mlo achieves lower latency serf higher number ar user compared sl frequency resource addition increasing number link improve performance mlo regarding traffic link allocation policy found policy susceptible channel blocking resulting possible performance degradationnext_generation_networks radio_access_networks wireless_lanar_applications augmented_reality_applications event based_wi fi_simulator high_reliability high quality_user_experience implementation specific_traffic to link_allocation_policy mlo multilink_operation multiple_links single link traffic to link_allocation_policies
232,AR-Based Resources to Train Computational Thinking Skills,"Lima, L., Saraiva, F., aes, L. G. M., Henriques, P. R., & Cardoso, A. (2023). AR-Based Resources to Train Computational Thinking Skills. Smart Innovation, Systems and Technologies, 691–702. https://doi.org/10.1007/978-981-19-6585-2_61
",10.1007/978-981-19-6585-2_61,"Learning and teaching computer programming is a challenge for everyone because it requires persistence and dedication. Nowadays, Computational Thinking is accepted as an essential skill to overcome those challenges. In this paper, we propose two Augmented Reality (AR) environments that create representations of complex programming constructs displaying engageable and playful activities that can be executed fast and do not require a great mental load. They are intended to be used as Learning Resources to train people in CT. The artifacts enable people to explore CT concepts and diverse problem-solving approaches in a subtle way. These artifacts include two simple AR-based activities, easy to handle and visualize based on ""see-through video"". We argue that by interacting with these artifacts, users can acquire CT problem-solving skills. Those two learning activities supported by AR provide visual representations and interactivity to engage students while training CT. We also describe an experiment to test both artifacts. The experiment was carried out with 12 participants of different ages and education levels. The results of feedback collected was positive.",C0220 Computing education and training;C6130V Virtual reality;C7810C Computer-aided instruction,AR-based activities;augmented reality environments;complex programming constructs;computational thinking skills;computer programming;CT concepts;CT problem-solving skills;diverse problem-solving approaches;education levels;engageable activities;essential skill;learning activities;learning resources;mental load;playful activities;visual representations,augmented reality;computer aided instruction;computer science education;teaching,2023,Conference article (CA),"Perspectives and Trends in Education and Technology: Selected Papers from ICITED 2022. Smart Innovation, Systems and Technologies (320)","(1) Lima, L.; (2) Saraiva, F.; (2) Aes, L.G.M.; (2) Henriques, P.R.; (3) Cardoso, A.; ","(1) Instituto Federal de Educacao Ciencia e Tecnologia de Brasilia, Brazil; (2) Universidade do Minho, Portugal; (3) Universidade Federal de Uberlandia, Brazil; ",Springer,-1,"[""computer aided instruction"", ""computer science education"", ""teaching""]","[""computer aided instruction"", ""computer science education"", ""teaching""]",computer aided instruction;computer science education;teaching,education;developers;training,technology;use cases;industries,education;developers;training,technology;use cases;industries,computer_aided_instruction computer_science_education teaching ar based_activities augmented_reality_environments complex_programming_constructs computational_thinking_skills computer_programming ct_concepts ct_problem solving_skills diverse_problem solving_approaches education_levels engageable_activities essential_skill learning_activities learning_resources mental_load playful_activities visual_representations c0220_computing_education_and_training c6130v_virtual_reality c7810c_computer aided_instruction education developers training,computer_aided_instruction computer_science_education teaching,ar based_activities augmented_reality_environments complex_programming_constructs computational_thinking_skills computer_programming ct_concepts ct_problem solving_skills diverse_problem solving_approaches education_levels engageable_activities essential_skill learning_activities learning_resources mental_load playful_activities visual_representations,learning teaching computer programming challenge everyone requires persistence dedication nowadays computational thinking accepted essential skill overcome challenge paper propose two augmented reality ar environment create representation complex programming construct displaying engageable playful activity executed fast require great mental load intended used learning resource train people ct artifact enable people explore ct concept diverse problem solving approach subtle way artifact include two simple ar based activity easy handle visualize based see video argue interacting artifact user acquire ct problem solving skill two learning activity supported ar provide visual representation interactivity engage student training ct also describe experiment test artifact experiment carried 12 participant different age education level result feedback collected positive,computer_aided_instruction computer_science_education teaching ar based_activities augmented_reality_environments complex_programming_constructs computational_thinking_skills computer_programming ct_concepts ct_problem solving_skills diverse_problem solving_approaches education_levels engageable_activities essential_skill learning_activities learning_resources mental_load playful_activities visual_representations c0220_computing_education_and_training c6130v_virtual_reality c7810c_computer aided_instruction education developers training learning teaching computer programming challenge everyone requires persistence dedication nowadays computational thinking accepted essential skill overcome challenge paper propose two augmented reality ar environment create representation complex programming construct displaying engageable playful activity executed fast require great mental load intended used learning resource train people ct artifact enable people explore ct concept diverse problem solving approach subtle way artifact include two simple ar based activity easy handle visualize based see video argue interacting artifact user acquire ct problem solving skill two learning activity supported ar provide visual representation interactivity engage student training ct also describe experiment test artifact experiment carried 12 participant different age education level result feedback collected positive,learning teaching computer programming challenge everyone requires persistence dedication nowadays computational thinking accepted essential skill overcome challenge paper propose two augmented reality ar environment create representation complex programming construct displaying engageable playful activity executed fast require great mental load intended used learning resource train people ct artifact enable people explore ct concept diverse problem solving approach subtle way artifact include two simple ar based activity easy handle visualize based see video argue interacting artifact user acquire ct problem solving skill two learning activity supported ar provide visual representation interactivity engage student training ct also describe experiment test artifact experiment carried 12 participant different age education level result feedback collected positivecomputer_aided_instruction computer_science_education teachingar based_activities augmented_reality_environments complex_programming_constructs computational_thinking_skills computer_programming ct_concepts ct_problem solving_skills diverse_problem solving_approaches education_levels engageable_activities essential_skill learning_activities learning_resources mental_load playful_activities visual_representations
233,Formalization of the Burning Process of Virtual Reality Objects in Adaptive Training Complexes,"Krasnyanskiy, M., Obukhov, A., & Dedov, D. (2021). Formalization of the Burning Process of Virtual Reality Objects in Adaptive Training Complexes. Journal of Imaging, 7(5), 86. https://doi.org/10.3390/jimaging7050086
",10.3390/jimaging7050086,"Within the scope of this article, the problem of the formalization of physical processes in adaptive training complexes is considered on the example of virtual objects burning. Despite a fairly complete study of this process, the existing mathematical models are not adapted for the application in training complexes, which leads to a significant increase in costs and lower productivity due to the complexity of the calculations. Therefore, an adapted mathematical model is proposed that allows us to formalize the structure of virtual objects of burning, their basic properties and the processes of changing states, starting from the flame development of an object and ending with their complete destruction or extinguishment. The article proposes the use of threshold value diagrams and rules for changing the states of virtual reality objects to solve the problem of the formalization of burning processes. This tool is quite multi-purpose, which allows you to describe various physical processes, such as smoke, flooding, the spread of toxic gases, etc. The area of the proposed formalization approach includes the design and implementation of physical processes in simulators and multimedia complexes using virtual and augmented reality. Thus, the presented scientific research can be used to formalize the physical processes in adaptive training complexes for professional ergatic systems.",C7810C Computer-aided instruction;C6130V Virtual reality,adapted mathematical model;adaptive training complexes;augmented reality;burning process;fairly complete study;formalization approach;multimedia complexes;physical processes;virtual objects;virtual reality objects,augmented reality;combustion;computer based training;costing,2021,Journal article (JA),J. Imaging (Switzerland),"(1) Krasnyanskiy, M.; (2) Obukhov, A.; (3) Dedov, D.; ","(1) Tambov State Technical University, Department of Administration, Russia; (2) Tambov State Technical University, Department of Automated Decision Support Systems, Russia; (3) Tambov State Technical University, Department of Basic and Applied Research, Russia; ",MDPI,-1,"[""combustion"", ""computer based training"", ""costing""]","[""combustion"", ""computer based training"", ""costing""]",combustion;computer based training;costing,other;farming and natural science;training;business performance metrics,other;business;use cases;industries,other;farming and natural science;training;business performance metrics,other;business;use cases;industries,combustion computer_based_training costing adapted_mathematical_model adaptive_training_complexes augmented_reality burning_process fairly_complete_study formalization_approach multimedia_complexes physical_processes virtual_objects virtual_reality_objects c7810c_computer aided_instruction c6130v_virtual_reality other farming_and_natural_science training business_performance_metrics,combustion computer_based_training costing,adapted_mathematical_model adaptive_training_complexes augmented_reality burning_process fairly_complete_study formalization_approach multimedia_complexes physical_processes virtual_objects virtual_reality_objects,within scope article problem formalization physical process adaptive training complex considered example virtual object burning despite fairly complete study process existing mathematical model adapted application training complex lead significant increase cost lower productivity due complexity calculation therefore adapted mathematical model proposed allows u formalize structure virtual object burning basic property process changing state starting flame development object ending complete destruction extinguishment article proposes use threshold value diagram rule changing state virtual reality object solve problem formalization burning process tool quite multi purpose allows describe various physical process smoke flooding spread toxic gas etc area proposed formalization approach includes design implementation physical process simulator multimedia complex using virtual augmented reality thus presented scientific research used formalize physical process adaptive training complex professional ergatic system,combustion computer_based_training costing adapted_mathematical_model adaptive_training_complexes augmented_reality burning_process fairly_complete_study formalization_approach multimedia_complexes physical_processes virtual_objects virtual_reality_objects c7810c_computer aided_instruction c6130v_virtual_reality other farming_and_natural_science training business_performance_metrics within scope article problem formalization physical process adaptive training complex considered example virtual object burning despite fairly complete study process existing mathematical model adapted application training complex lead significant increase cost lower productivity due complexity calculation therefore adapted mathematical model proposed allows u formalize structure virtual object burning basic property process changing state starting flame development object ending complete destruction extinguishment article proposes use threshold value diagram rule changing state virtual reality object solve problem formalization burning process tool quite multi purpose allows describe various physical process smoke flooding spread toxic gas etc area proposed formalization approach includes design implementation physical process simulator multimedia complex using virtual augmented reality thus presented scientific research used formalize physical process adaptive training complex professional ergatic system,within scope article problem formalization physical process adaptive training complex considered example virtual object burning despite fairly complete study process existing mathematical model adapted application training complex lead significant increase cost lower productivity due complexity calculation therefore adapted mathematical model proposed allows u formalize structure virtual object burning basic property process changing state starting flame development object ending complete destruction extinguishment article proposes use threshold value diagram rule changing state virtual reality object solve problem formalization burning process tool quite multi purpose allows describe various physical process smoke flooding spread toxic gas etc area proposed formalization approach includes design implementation physical process simulator multimedia complex using virtual augmented reality thus presented scientific research used formalize physical process adaptive training complex professional ergatic systemcombustion computer_based_training costingadapted_mathematical_model adaptive_training_complexes augmented_reality burning_process fairly_complete_study formalization_approach multimedia_complexes physical_processes virtual_objects virtual_reality_objects
234,"Versatile Immersive Virtual and Augmented Tangible OR - Using VR, AR and Tangibles to Support Surgical Practice","Reinschluessel, A. V., Muender, T., Fischer, R., Kraft, V., Uslar, V. N., Weyhe, D., Schenk, A., Zachmann, G., Döring, T., & Malaka, R. (2023). Versatile Immersive Virtual and Augmented Tangible OR – Using VR, AR and Tangibles to Support Surgical Practice. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583895
",10.1145/3544549.3583895,"Immersive technologies such as virtual reality (VR) and augmented reality (AR), in combination with advanced image segmentation and visualization, have considerable potential to improve and support a surgeon's work. We demonstrate a solution to help surgeons plan and perform surgeries and educate future medical staff using VR, AR, and tangibles. A VR planning tool improves spatial understanding of an individual's anatomy, a tangible organ model allows for intuitive interaction, and AR gives contactless access to medical images in the operating room. Additionally, we present improvements regarding point cloud representations to provide detailed visual information to a remote expert and about the remote expert. Therefore, we give an exemplary setup showing how recent interaction techniques and modalities benefit an area that can positively change the life of patients.","A8770E Patient diagnostic methods and instrumentation;A8770G Patient care and treatment;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing",advanced image segmentation;augmented reality;augmented tangible;detailed visual information;future medical staff;immersive technologies;medical images;remote expert;spatial understanding;surgeon;surgical practice;tangible organ model;tangibles;versatile immersive virtual;visualization;VR planning tool,augmented reality;data visualisation;image segmentation;medical image processing;surgery;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Reinschluessel, A.V.; (1) Muender, T.; (2) Fischer, R.; (3) Kraft, V.; (4) Uslar, V.N.; (5) Weyhe, D.; (3) Schenk, A.; (6) Zachmann, G.; (7) Do&#776;ring, T.; (1) Malaka, R.; ","(1) University of Bremen, Digital Media Lab, Germany; (2) University of Bremen, Computer Graphics and Virtual Reality Research Lab, Germany; (3) Fraunhofer MEVIS, Germany; (4) University of Oldenburg, Hospital for Visceral Surgery, Germany; (5) Pius-Hospital Oldenburg, Hospital for Visceral Surgery, Germany; (6) University of Bremen, Mathematics and Computer Science, Germany; (7) University of Bremen, Digital Media Lab., Germany; ",ACM,-1,"[""data visualization"", ""image segmentation"", ""medical image processing"", ""surgery""]","[""data visualization"", ""image segmentation"", ""medical image processing"", ""surgery""]",data visualization;image segmentation;medical image processing;surgery,medical;computer vision;data,technology;industries,medical;computer vision;data,technology;industries,data_visualization image_segmentation medical_image_processing surgery advanced_image_segmentation augmented_reality augmented_tangible detailed_visual_information future_medical_staff immersive_technologies medical_images remote_expert spatial_understanding surgeon surgical_practice tangible_organ_model tangibles versatile_immersive_virtual visualization vr_planning_tool a8770e_patient_diagnostic_methods_and_instrumentation a8770g_patient_care_and_treatment b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing medical computer_vision data,data_visualization image_segmentation medical_image_processing surgery,advanced_image_segmentation augmented_reality augmented_tangible detailed_visual_information future_medical_staff immersive_technologies medical_images remote_expert spatial_understanding surgeon surgical_practice tangible_organ_model tangibles versatile_immersive_virtual visualization vr_planning_tool,immersive technology virtual reality vr augmented reality ar combination advanced image segmentation visualization considerable potential improve support surgeon work demonstrate solution help surgeon plan perform surgery educate future medical staff using vr ar tangibles vr planning tool improves spatial understanding individual anatomy tangible organ model allows intuitive interaction ar give contactless access medical image operating room additionally present improvement regarding point cloud representation provide detailed visual information remote expert remote expert therefore give exemplary setup showing recent interaction technique modality benefit area positively change life patient,data_visualization image_segmentation medical_image_processing surgery advanced_image_segmentation augmented_reality augmented_tangible detailed_visual_information future_medical_staff immersive_technologies medical_images remote_expert spatial_understanding surgeon surgical_practice tangible_organ_model tangibles versatile_immersive_virtual visualization vr_planning_tool a8770e_patient_diagnostic_methods_and_instrumentation a8770g_patient_care_and_treatment b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing medical computer_vision data immersive technology virtual reality vr augmented reality ar combination advanced image segmentation visualization considerable potential improve support surgeon work demonstrate solution help surgeon plan perform surgery educate future medical staff using vr ar tangibles vr planning tool improves spatial understanding individual anatomy tangible organ model allows intuitive interaction ar give contactless access medical image operating room additionally present improvement regarding point cloud representation provide detailed visual information remote expert remote expert therefore give exemplary setup showing recent interaction technique modality benefit area positively change life patient,immersive technology virtual reality vr augmented reality ar combination advanced image segmentation visualization considerable potential improve support surgeon work demonstrate solution help surgeon plan perform surgery educate future medical staff using vr ar tangibles vr planning tool improves spatial understanding individual anatomy tangible organ model allows intuitive interaction ar give contactless access medical image operating room additionally present improvement regarding point cloud representation provide detailed visual information remote expert remote expert therefore give exemplary setup showing recent interaction technique modality benefit area positively change life patientdata_visualization image_segmentation medical_image_processing surgeryadvanced_image_segmentation augmented_reality augmented_tangible detailed_visual_information future_medical_staff immersive_technologies medical_images remote_expert spatial_understanding surgeon surgical_practice tangible_organ_model tangibles versatile_immersive_virtual visualization vr_planning_tool
235,Challenges of 1.0 &mu;m-pitch liquid crystal spatial light modulator for future high-quality electric holographic display,"Ishinabe, T., Chida, K., Isomae, Y., Shibata, Y., & Fujikake, H. (2023). Challenges of 1.0 μm-pitch liquid crystal spatial light modulator for future high-quality electric holographic display. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2650295
",10.1117/12.2650295,"Electronic holographic displays precisely reconstruct the wavefront of object light and have attracted considerable attention for virtual reality (VR) and augmented reality (AR) applications. To achieve a high-quality holographic display with a wide field of view, it is necessary to reduce the pixel pitch of a spatial light modulator (SLM) to about 1 &mu;m. We have achieved a precise control of liquid crystal (LC) alignment in 1 &mu;m pitch pixels by exploiting the anisotropy of pixel space due to the lattice-shaped dielectric walls. In this paper, we have investigated the effect of LC-SLM structure on the image quality of electric holographic displays. As a result, we clarified that the image quality of phase-modulation type holographic displays does not degrade even when the number of gray levels is 4 or more and established a simple pixel structure that allows independent control of 1 &mu;m pitch pixels and high image quality. &copy; 2023 SPIE.","722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;743 Holography;913.3 Quality Assurance and Control",Augmented reality applications;High image quality;High quality;Liquid crystal alignment;Liquid crystal spatial light modulators;Liquid-crystals;Pixel pitch;Precise control;Spatial light modulators;Wide field-ofview,Augmented reality;Image quality;Light modulation;Light modulators;Liquid crystals;Pixels;Quality control;Three dimensional displays,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Ishinabe, Takahiro; (1) Chida, Kazuma; (1) Isomae, Yoshitomo; (1) Shibata, Yosei; (1) Fujikake, Hideo; ","(1) Dept. of Electronic Engineering, Graduate School of Engineering, Tohoku University, Sendai; 980-8579, Japan; ",SPIE,-1,"[""image quality"", ""light modulation"", ""light modulators"", ""liquid crystals"", ""pixels"", ""quality control"", ""three-dimensional displays""]","[""image quality"", ""light modulation"", ""light modulators"", ""liquid crystals"", ""pixels"", ""quality control"", ""three-dimensional displays""]",image quality;light modulation;light modulators;liquid crystals;pixels;quality control;three-dimensional displays,"computer vision;graphics;input;chemical;inspection, safety and quality;display technology",technology;displays;use cases;industries,"computer vision;graphics;input;chemical;inspection, safety and quality;display technology",technology;displays;use cases;industries,image_quality light_modulation light_modulators liquid_crystals pixels quality_control three dimensional_displays augmented_reality_applications high_image_quality high_quality liquid_crystal_alignment liquid_crystal_spatial_light_modulators liquid crystals pixel_pitch precise_control spatial_light_modulators wide_field ofview 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 743_holography 913 3_quality_assurance_and_control computer_vision graphics input chemical inspection _safety_and_quality display_technology,image_quality light_modulation light_modulators liquid_crystals pixels quality_control three dimensional_displays,augmented_reality_applications high_image_quality high_quality liquid_crystal_alignment liquid_crystal_spatial_light_modulators liquid crystals pixel_pitch precise_control spatial_light_modulators wide_field ofview,electronic holographic display precisely reconstruct wavefront object light attracted considerable attention virtual reality vr augmented reality ar application achieve high quality holographic display wide field view necessary reduce pixel pitch spatial light modulator slm 1 mu achieved precise control liquid crystal lc alignment 1 mu pitch pixel exploiting anisotropy pixel space due lattice shaped dielectric wall paper investigated effect lc slm structure image quality electric holographic display result clarified image quality phase modulation type holographic display degrade even number gray level 4 established simple pixel structure allows independent control 1 mu pitch pixel high image quality copy 2023 spie,image_quality light_modulation light_modulators liquid_crystals pixels quality_control three dimensional_displays augmented_reality_applications high_image_quality high_quality liquid_crystal_alignment liquid_crystal_spatial_light_modulators liquid crystals pixel_pitch precise_control spatial_light_modulators wide_field ofview 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 743_holography 913 3_quality_assurance_and_control computer_vision graphics input chemical inspection _safety_and_quality display_technology electronic holographic display precisely reconstruct wavefront object light attracted considerable attention virtual reality vr augmented reality ar application achieve high quality holographic display wide field view necessary reduce pixel pitch spatial light modulator slm 1 mu achieved precise control liquid crystal lc alignment 1 mu pitch pixel exploiting anisotropy pixel space due lattice shaped dielectric wall paper investigated effect lc slm structure image quality electric holographic display result clarified image quality phase modulation type holographic display degrade even number gray level 4 established simple pixel structure allows independent control 1 mu pitch pixel high image quality copy 2023 spie,electronic holographic display precisely reconstruct wavefront object light attracted considerable attention virtual reality vr augmented reality ar application achieve high quality holographic display wide field view necessary reduce pixel pitch spatial light modulator slm 1 mu achieved precise control liquid crystal lc alignment 1 mu pitch pixel exploiting anisotropy pixel space due lattice shaped dielectric wall paper investigated effect lc slm structure image quality electric holographic display result clarified image quality phase modulation type holographic display degrade even number gray level 4 established simple pixel structure allows independent control 1 mu pitch pixel high image quality copy 2023 spieimage_quality light_modulation light_modulators liquid_crystals pixels quality_control three dimensional_displaysaugmented_reality_applications high_image_quality high_quality liquid_crystal_alignment liquid_crystal_spatial_light_modulators liquid crystals pixel_pitch precise_control spatial_light_modulators wide_field ofview
236,HeritageSite AR: An Exploration Game for Quality Education and Sustainable Cultural Heritage,"Xu, N., Liang, J., Shuai, K., Li, Y., & Yan, J. (2023). HeritageSite AR: An Exploration Game for Quality Education and Sustainable Cultural Heritage✱. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583837
",10.1145/3544549.3583837,"Cultural heritage (CH) plays an important role in realizing the Sustainable Development Goals (SDGs). In this paper, we focus on emerging technologies such as Augmented Reality (AR) and gamified learning to foster public understanding of cultural values in historical contexts. We design HeritageSite AR, an exploration game for onsite CH learning and visits with publics in Relics of Arhat Monastery and Twin Pagoda (also known as Shuangta). Based on research investigation of technical means, expert semi-structured interviews and online survey, we distill and incorporate four design goals using user journey map. The implemented game design is evaluated with respect to three design components (i.e., reality, meaning, play) and four stages (i.e., trigger, engage, consolidate, relate) in CH visits. We conclude our work with a discussion of contributions to SDGs.",C7820 Humanities computing;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C7810C Computer-aided instruction;C7830D Computer games,Augmented Reality;CH visits;cultural heritage;cultural values;design components;expert semistructured interviews;exploration game;HeritageSite AR;historical contexts;implemented game design;incorporate four design goals;online survey;public understanding;publics;quality education;research investigation;SDGs;Sustainable cultural;Sustainable Development Goals;user journey map,augmented reality;computer aided instruction;computer games;history;serious games (computing);sustainable development,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,(1) Ningning Xu; (1) Jiachen Liang; (1) Kexiang Shuai; (1) Yuwen Li; (1) Jiaqi Yan; ,"(1) Xi'an Jiaotong-Liverpool University, School of Advanced Technology, China; ",ACM,-1,"[""computer aided instruction"", ""computer games"", ""history"", ""serious games"", ""sustainable development""]","[""computer aided instruction"", ""computer games"", ""history"", ""serious games"", ""sustainable development""]",computer aided instruction;computer games;history;serious games;sustainable development,policy;training;simulation;liberal arts,business;use cases;industries,policy;training;simulation;liberal arts,business;use cases;industries,computer_aided_instruction computer_games history serious_games sustainable_development augmented_reality ch_visits cultural_heritage cultural_values design_components expert_semistructured_interviews exploration_game heritagesite_ar historical_contexts implemented_game_design incorporate_four_design_goals online_survey public_understanding publics quality_education research_investigation sdgs sustainable_cultural sustainable_development_goals user_journey_map c7820_humanities_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction c7830d_computer_games policy training simulation liberal_arts,computer_aided_instruction computer_games history serious_games sustainable_development,augmented_reality ch_visits cultural_heritage cultural_values design_components expert_semistructured_interviews exploration_game heritagesite_ar historical_contexts implemented_game_design incorporate_four_design_goals online_survey public_understanding publics quality_education research_investigation sdgs sustainable_cultural sustainable_development_goals user_journey_map,cultural heritage ch play important role realizing sustainable development goal sdgs paper focus emerging technology augmented reality ar gamified learning foster public understanding cultural value historical context design heritagesite ar exploration game onsite ch learning visit public relic arhat monastery twin pagoda also known shuangta based research investigation technical mean expert semi structured interview online survey distill incorporate four design goal using user journey map implemented game design evaluated respect three design component e reality meaning play four stage e trigger engage consolidate relate ch visit conclude work discussion contribution sdgs,computer_aided_instruction computer_games history serious_games sustainable_development augmented_reality ch_visits cultural_heritage cultural_values design_components expert_semistructured_interviews exploration_game heritagesite_ar historical_contexts implemented_game_design incorporate_four_design_goals online_survey public_understanding publics quality_education research_investigation sdgs sustainable_cultural sustainable_development_goals user_journey_map c7820_humanities_computing c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c7810c_computer aided_instruction c7830d_computer_games policy training simulation liberal_arts cultural heritage ch play important role realizing sustainable development goal sdgs paper focus emerging technology augmented reality ar gamified learning foster public understanding cultural value historical context design heritagesite ar exploration game onsite ch learning visit public relic arhat monastery twin pagoda also known shuangta based research investigation technical mean expert semi structured interview online survey distill incorporate four design goal using user journey map implemented game design evaluated respect three design component e reality meaning play four stage e trigger engage consolidate relate ch visit conclude work discussion contribution sdgs,cultural heritage ch play important role realizing sustainable development goal sdgs paper focus emerging technology augmented reality ar gamified learning foster public understanding cultural value historical context design heritagesite ar exploration game onsite ch learning visit public relic arhat monastery twin pagoda also known shuangta based research investigation technical mean expert semi structured interview online survey distill incorporate four design goal using user journey map implemented game design evaluated respect three design component e reality meaning play four stage e trigger engage consolidate relate ch visit conclude work discussion contribution sdgscomputer_aided_instruction computer_games history serious_games sustainable_developmentaugmented_reality ch_visits cultural_heritage cultural_values design_components expert_semistructured_interviews exploration_game heritagesite_ar historical_contexts implemented_game_design incorporate_four_design_goals online_survey public_understanding publics quality_education research_investigation sdgs sustainable_cultural sustainable_development_goals user_journey_map
237,Virtual Big Heads in Extended Reality: Estimation of Ideal Head Scales and Perceptual Thresholds for Comfort and Facial Cues,"Choudhary, Z., Erickson, A., Norouzi, N., Kim, K., Bruder, G., & Welch, G. (2023). Virtual Big Heads in Extended Reality: Estimation of Ideal Head Scales and Perceptual Thresholds for Comfort and Facial Cues. ACM Transactions on Applied Perception, 20(1), 1–31. https://doi.org/10.1145/3571074
",10.1145/3571074,"Extended reality (XR) technologies, such as virtual reality (VR) and augmented reality (AR), provide users, their avatars, and embodied agents a shared platform to collaborate in a spatial context. Although traditional face-to-face communication is limited by users' proximity, meaning that another human's non-verbal embodied cues become more difficult to perceive the farther one is away from that person, researchers and practitioners have started to look into ways to accentuate or amplify such embodied cues and signals to counteract the effects of distance with XR technologies. In this article, we describe and evaluate the&lt;i&gt;Big Head&lt;/i&gt;technique, in which a human's head in VR/AR is scaled up relative to their distance from the observer as a mechanism for enhancing the visibility of non-verbal facial cues, such as facial expressions or eye gaze. To better understand and explore this technique, we present two complimentary human-subject experiments in this article. In our first experiment, we conducted a VR study with a head-mounted display to understand the impact of increased or decreased head scales on participants' ability to perceive facial expressions as well as their sense of comfort and feeling of ""uncannniness"" over distances of up to 10 m. We explored two different scaling methods and compared perceptual thresholds and user preferences. Our second experiment was performed in an outdoor AR environment with an optical see-through head-mounted display. Participants were asked to estimate facial expressions and eye gaze, and identify a virtual human over large distances of 30, 60, and 90 m. In both experiments, our results show significant differences in minimum, maximum, and ideal head scales for different distances and tasks related to perceiving faces, facial expressions, and eye gaze, and we also found that participants were more comfortable with slightly bigger heads at larger distances. We discuss our findings with respect to the technologies used, and we discuss implications and guidelines for practical applications that aim to leverage XR-enhanced facial cues.",C6130V Virtual reality,augmented reality;complimentary human-subject experiments;extended reality technologies;eye gaze;facial expressions;human nonverbal embodied cues;human-subject experiments;ideal head scales;nonverbal facial cues;optical see-through head-mounted display;perceptual thresholds;scaling methods;shared platform;traditional face-to-face communication;user preferences;virtual big heads;virtual human;VR study;XR technologies;XR-enhanced facial cues,augmented reality;helmet mounted displays,2023,Journal article (JA),ACM Trans. Appl. Percept. (USA),"(1) Choudhary, Z.; (1) Erickson, A.; (1) Norouzi, N.; (2) Kim, K.; (1) Bruder, G.; (1) Welch, G.; ","(1) University of Central Florida, Central Florida Blvd, Orlando, FL, United States; (2) University of Calgary, Calgary, AB, Canada; ",ACM,-1,"[""helmet mounted displays""]","[""helmet mounted displays""]",helmet mounted displays,display technology;wearables,displays,display technology;wearables,displays,helmet_mounted_displays augmented_reality complimentary_human subject_experiments extended_reality_technologies eye_gaze facial_expressions human_nonverbal_embodied_cues human subject_experiments ideal_head_scales nonverbal_facial_cues optical_see through_head mounted_display perceptual_thresholds scaling_methods shared_platform traditional_face to face_communication user_preferences virtual_big_heads virtual_human vr_study xr_technologies xr enhanced_facial_cues c6130v_virtual_reality display_technology wearables,helmet_mounted_displays,augmented_reality complimentary_human subject_experiments extended_reality_technologies eye_gaze facial_expressions human_nonverbal_embodied_cues human subject_experiments ideal_head_scales nonverbal_facial_cues optical_see through_head mounted_display perceptual_thresholds scaling_methods shared_platform traditional_face to face_communication user_preferences virtual_big_heads virtual_human vr_study xr_technologies xr enhanced_facial_cues,extended reality xr technology virtual reality vr augmented reality ar provide user avatar embodied agent shared platform collaborate spatial context although traditional face face communication limited user proximity meaning another human non verbal embodied cue become difficult perceive farther one away person researcher practitioner started look way accentuate amplify embodied cue signal counteract effect distance xr technology article describe evaluate lt gt big head lt gt technique human head vr ar scaled relative distance observer mechanism enhancing visibility non verbal facial cue facial expression eye gaze better understand explore technique present two complimentary human subject experiment article first experiment conducted vr study head mounted display understand impact increased decreased head scale participant ability perceive facial expression well sense comfort feeling uncannniness distance 10 explored two different scaling method compared perceptual threshold user preference second experiment performed outdoor ar environment optical see head mounted display participant asked estimate facial expression eye gaze identify virtual human large distance 30 60 90 experiment result show significant difference minimum maximum ideal head scale different distance task related perceiving face facial expression eye gaze also found participant comfortable slightly bigger head larger distance discus finding respect technology used discus implication guideline practical application aim leverage xr enhanced facial cue,helmet_mounted_displays augmented_reality complimentary_human subject_experiments extended_reality_technologies eye_gaze facial_expressions human_nonverbal_embodied_cues human subject_experiments ideal_head_scales nonverbal_facial_cues optical_see through_head mounted_display perceptual_thresholds scaling_methods shared_platform traditional_face to face_communication user_preferences virtual_big_heads virtual_human vr_study xr_technologies xr enhanced_facial_cues c6130v_virtual_reality display_technology wearables extended reality xr technology virtual reality vr augmented reality ar provide user avatar embodied agent shared platform collaborate spatial context although traditional face face communication limited user proximity meaning another human non verbal embodied cue become difficult perceive farther one away person researcher practitioner started look way accentuate amplify embodied cue signal counteract effect distance xr technology article describe evaluate lt gt big head lt gt technique human head vr ar scaled relative distance observer mechanism enhancing visibility non verbal facial cue facial expression eye gaze better understand explore technique present two complimentary human subject experiment article first experiment conducted vr study head mounted display understand impact increased decreased head scale participant ability perceive facial expression well sense comfort feeling uncannniness distance 10 explored two different scaling method compared perceptual threshold user preference second experiment performed outdoor ar environment optical see head mounted display participant asked estimate facial expression eye gaze identify virtual human large distance 30 60 90 experiment result show significant difference minimum maximum ideal head scale different distance task related perceiving face facial expression eye gaze also found participant comfortable slightly bigger head larger distance discus finding respect technology used discus implication guideline practical application aim leverage xr enhanced facial cue,extended reality xr technology virtual reality vr augmented reality ar provide user avatar embodied agent shared platform collaborate spatial context although traditional face face communication limited user proximity meaning another human non verbal embodied cue become difficult perceive farther one away person researcher practitioner started look way accentuate amplify embodied cue signal counteract effect distance xr technology article describe evaluate lt gt big head lt gt technique human head vr ar scaled relative distance observer mechanism enhancing visibility non verbal facial cue facial expression eye gaze better understand explore technique present two complimentary human subject experiment article first experiment conducted vr study head mounted display understand impact increased decreased head scale participant ability perceive facial expression well sense comfort feeling uncannniness distance 10 explored two different scaling method compared perceptual threshold user preference second experiment performed outdoor ar environment optical see head mounted display participant asked estimate facial expression eye gaze identify virtual human large distance 30 60 90 experiment result show significant difference minimum maximum ideal head scale different distance task related perceiving face facial expression eye gaze also found participant comfortable slightly bigger head larger distance discus finding respect technology used discus implication guideline practical application aim leverage xr enhanced facial cuehelmet_mounted_displaysaugmented_reality complimentary_human subject_experiments extended_reality_technologies eye_gaze facial_expressions human_nonverbal_embodied_cues human subject_experiments ideal_head_scales nonverbal_facial_cues optical_see through_head mounted_display perceptual_thresholds scaling_methods shared_platform traditional_face to face_communication user_preferences virtual_big_heads virtual_human vr_study xr_technologies xr enhanced_facial_cues
238,Calculating and Analyzing Angular Head Jerk in Augmented and Virtual Reality: Effect of AR Cue Design on Angular Jerk,"Van Dam, J., Tanous, K., Werner, M., & Gabbard, J. L. (2021). Calculating and Analyzing Angular Head Jerk in Augmented and Virtual Reality: Effect of AR Cue Design on Angular Jerk. Applied Sciences, 11(21), 10082. https://doi.org/10.3390/app112110082
",10.3390/app112110082,"In this work, we propose a convenient method for evaluating levels of angular jerk in augmented reality (AR) and virtual reality (VR). Jerk is a rarely analyzed metric in usability studies, although it can be measured and calculated easily with most head-worn displays and can yield highly relevant information to designers. Here, we developed and implemented a system capable of calculating and analyzing jerk in real-time based on orientation data from an off-the-shelf head-worn display. An experiment was then carried out to determine whether the presence of AR user interface annotations results in changes to users' angular head jerk when conducting a time-pressured visual search task. Analysis of the data indicates that a decrease in jerk is significantly associated with the use of AR augmentations. As noted in the limitations section, however, the conclusions drawn from this work should be limited, as this analysis method is novel in the VR/AR space and because of methodological limitations that limited the reliability of the jerk data. The work presented herein considerably facilitates the use of jerk as a quick component measure of usability and serves as an initial point off which future research involving jerk in VR and AR can be performed.",C6130V Virtual reality;C5540D Computer displays;C6180 User interfaces,angular head jerk;angular jerk;AR augmentations;AR cue design;AR user interface;augmented reality;jerk data;off-the-shelf head-worn display;time-pressured visual search task;virtual reality,augmented reality;helmet mounted displays;user interfaces,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Van dam, J.; (1) Tanous, K.; (2) Werner, M.; (1) Gabbard, J.L.; ","(1) Virginia Tech, Department of Industrial and Systems Engineering, Blacksburg, VA VA 2406, United States; (2) Virginia Tech, Department of Aerospace and Ocean Engineering, Blacksburg, VA 24060, United States; ",MDPI,-1,"[""helmet mounted displays"", ""user interfaces""]","[""helmet mounted displays"", ""user interfaces""]",helmet mounted displays;user interfaces,display technology;wearables;human-computer interaction,displays;end users and user experience,display technology;wearables;human-computer interaction,displays;end users and user experience,helmet_mounted_displays user_interfaces angular_head_jerk angular_jerk ar_augmentations ar_cue_design ar_user_interface augmented_reality jerk_data off the shelf_head worn_display time pressured_visual_search_task virtual_reality c6130v_virtual_reality c5540d_computer_displays c6180_user_interfaces display_technology wearables human computer_interaction,helmet_mounted_displays user_interfaces,angular_head_jerk angular_jerk ar_augmentations ar_cue_design ar_user_interface augmented_reality jerk_data off the shelf_head worn_display time pressured_visual_search_task virtual_reality,work propose convenient method evaluating level angular jerk augmented reality ar virtual reality vr jerk rarely analyzed metric usability study although measured calculated easily head worn display yield highly relevant information designer developed implemented system capable calculating analyzing jerk real time based orientation data shelf head worn display experiment carried determine whether presence ar user interface annotation result change user angular head jerk conducting time pressured visual search task analysis data indicates decrease jerk significantly associated use ar augmentation noted limitation section however conclusion drawn work limited analysis method novel vr ar space methodological limitation limited reliability jerk data work presented herein considerably facilitates use jerk quick component measure usability serf initial point future research involving jerk vr ar performed,helmet_mounted_displays user_interfaces angular_head_jerk angular_jerk ar_augmentations ar_cue_design ar_user_interface augmented_reality jerk_data off the shelf_head worn_display time pressured_visual_search_task virtual_reality c6130v_virtual_reality c5540d_computer_displays c6180_user_interfaces display_technology wearables human computer_interaction work propose convenient method evaluating level angular jerk augmented reality ar virtual reality vr jerk rarely analyzed metric usability study although measured calculated easily head worn display yield highly relevant information designer developed implemented system capable calculating analyzing jerk real time based orientation data shelf head worn display experiment carried determine whether presence ar user interface annotation result change user angular head jerk conducting time pressured visual search task analysis data indicates decrease jerk significantly associated use ar augmentation noted limitation section however conclusion drawn work limited analysis method novel vr ar space methodological limitation limited reliability jerk data work presented herein considerably facilitates use jerk quick component measure usability serf initial point future research involving jerk vr ar performed,work propose convenient method evaluating level angular jerk augmented reality ar virtual reality vr jerk rarely analyzed metric usability study although measured calculated easily head worn display yield highly relevant information designer developed implemented system capable calculating analyzing jerk real time based orientation data shelf head worn display experiment carried determine whether presence ar user interface annotation result change user angular head jerk conducting time pressured visual search task analysis data indicates decrease jerk significantly associated use ar augmentation noted limitation section however conclusion drawn work limited analysis method novel vr ar space methodological limitation limited reliability jerk data work presented herein considerably facilitates use jerk quick component measure usability serf initial point future research involving jerk vr ar performedhelmet_mounted_displays user_interfacesangular_head_jerk angular_jerk ar_augmentations ar_cue_design ar_user_interface augmented_reality jerk_data off the shelf_head worn_display time pressured_visual_search_task virtual_reality
239,Volumetric Mixed Reality Telepresence for Real-time Cross Modality Collaboration,"Irlitti, A., Latifoglu, M., Zhou, Q., Reinoso, M. N., Hoang, T., Velloso, E., & Vetere, F. (2023). Volumetric Mixed Reality Telepresence for Real-time Cross Modality Collaboration. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581277
",10.1145/3544548.3581277,"Mixed-reality telepresence allows local and remote users feel as if they are present together in the same space. In this paper we report on a mixed-reality volumetric telepresence system that is adaptable, multi-user and cross-modal, i.e. combining augmented and virtual reality technologies with face-to-face interactions. The system extends state-of-art by creating full-body and environmental volumetric renderings in real-time over local enterprise networks. We report findings of an evaluation in a training scenario which was adapted for remote delivery and led by an industry professional. Analysis of interviews and observed behaviours identify varying attitudes towards virtually mediated full-body experiences and highlight the impact of volumetric mixed-reality telepresence to facilitate personal experiences of co-presence and to ground communication with interlocutors.",C6130V Virtual reality;C6130B Graphics techniques;C6130G Groupware;C6180 User interfaces,augmented reality technologies;environmental volumetric renderings;face-to-face interactions;local enterprise networks;mixed-reality volumetric telepresence system;real-time cross modality collaboration;remote delivery;virtual reality technologies,augmented reality;groupware;real-time systems;rendering (computer graphics),2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Irlitti, A.; (1) Latifoglu, M.; (1) Zhou, Q.; (1) Reinoso, M.N.; (2) Hoang, T.; (1) Velloso, E.; (1) Vetere, F.; ","(1) University of Melbourne, School of Computing and Information Systems, Melbourne, VIC, Australia; (2) Deakin University, School of Information Technology, Burwood, VIC, Australia; ",ACM,-1,"[""groupware"", ""real-time systems"", ""rendering""]","[""groupware"", ""real-time systems"", ""rendering""]",groupware;real-time systems;rendering,education;graphics;human-computer interaction;collaboration,technology;end users and user experience;use cases;industries,education;graphics;human-computer interaction;collaboration,technology;end users and user experience;use cases;industries,groupware real time_systems rendering augmented_reality_technologies environmental_volumetric_renderings face to face_interactions local_enterprise_networks mixed reality_volumetric_telepresence_system real time_cross_modality_collaboration remote_delivery virtual_reality_technologies c6130v_virtual_reality c6130b_graphics_techniques c6130g_groupware c6180_user_interfaces education graphics human computer_interaction collaboration,groupware real time_systems rendering,augmented_reality_technologies environmental_volumetric_renderings face to face_interactions local_enterprise_networks mixed reality_volumetric_telepresence_system real time_cross_modality_collaboration remote_delivery virtual_reality_technologies,mixed reality telepresence allows local remote user feel present together space paper report mixed reality volumetric telepresence system adaptable multi user cross modal e combining augmented virtual reality technology face face interaction system extends state art creating full body environmental volumetric rendering real time local enterprise network report finding evaluation training scenario adapted remote delivery led industry professional analysis interview observed behaviour identify varying attitude towards virtually mediated full body experience highlight impact volumetric mixed reality telepresence facilitate personal experience co presence ground communication interlocutor,groupware real time_systems rendering augmented_reality_technologies environmental_volumetric_renderings face to face_interactions local_enterprise_networks mixed reality_volumetric_telepresence_system real time_cross_modality_collaboration remote_delivery virtual_reality_technologies c6130v_virtual_reality c6130b_graphics_techniques c6130g_groupware c6180_user_interfaces education graphics human computer_interaction collaboration mixed reality telepresence allows local remote user feel present together space paper report mixed reality volumetric telepresence system adaptable multi user cross modal e combining augmented virtual reality technology face face interaction system extends state art creating full body environmental volumetric rendering real time local enterprise network report finding evaluation training scenario adapted remote delivery led industry professional analysis interview observed behaviour identify varying attitude towards virtually mediated full body experience highlight impact volumetric mixed reality telepresence facilitate personal experience co presence ground communication interlocutor,mixed reality telepresence allows local remote user feel present together space paper report mixed reality volumetric telepresence system adaptable multi user cross modal e combining augmented virtual reality technology face face interaction system extends state art creating full body environmental volumetric rendering real time local enterprise network report finding evaluation training scenario adapted remote delivery led industry professional analysis interview observed behaviour identify varying attitude towards virtually mediated full body experience highlight impact volumetric mixed reality telepresence facilitate personal experience co presence ground communication interlocutorgroupware real time_systems renderingaugmented_reality_technologies environmental_volumetric_renderings face to face_interactions local_enterprise_networks mixed reality_volumetric_telepresence_system real time_cross_modality_collaboration remote_delivery virtual_reality_technologies
240,Omnidirectional Haptic Stimulation System via Pneumatic Actuators for Presence Presentation,"Yoshida, S., Xie, H., & Miyata, K. (2023). Omnidirectional Haptic Stimulation System via Pneumatic Actuators for Presence Presentation. Sensors, 23(2), 584. https://doi.org/10.3390/s23020584
",10.3390/s23020584,"Recently, remote meetings and work-from-home have become more common, reducing the opportunities for face-to-face communication. To facilitate communication among remote workers, researchers have focused on virtual space technology and spatial augmented reality technology. Although these technologies can enhance immersiveness in collaborative work, they face the challenge of fostering a sense of physical contact. In this work, we aimed to foster a sense of presence through haptic stimulation using pneumatic actuators. Specifically, we developed a choker-type wearable device that presents various pressure patterns around the neck; the pattern presented depends on the message the device must convey. Various combinations of haptic presentation are achieved by pumping air to the multiple pneumatic actuators attached to the choker. In addition, we conducted experiments involving actuators of different shapes to optimize the haptic presentation. When linked with a smartphone, the proposed device can present pressure patterns to indicate incoming calls and notifications, to give warning about an obstacle that one who is texting might miss while walking, and to provide direction to a pedestrian. Furthermore, the device can be used in a wide range of applications, from those necessary in daily living to those that enhance one's experience in the realm of entertainment. For example, haptic feedback that synchronizes with the presence of a singer or with the rhythm of a song one listens to or with a performer's movements during a stage performance will immerse users in an enjoyable experience.","C6130V Virtual reality;C5540B Interactive-input devices;C6130G Groupware;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",choker-type wearable device;collaborative work;face-to-face communication;haptic feedback;haptic presentation;multiple pneumatic actuators;omnidirectional haptic stimulation system;physical contact;presence presentation;pressure patterns;remote meetings;remote workers;spatial augmented reality technology;virtual space technology;work-from-home,actuators;augmented reality;groupware;haptic interfaces;pneumatic actuators;smart phones;virtual reality,2023,Journal article (JA),Sensors (Switzerland),"(1) Yoshida, S.; (1) Xie, H.; (1) Miyata, K.; ","(1) Japan Advanced Institute of Science and Technology, School of Knowledge Science, Japan; ",MDPI,-1,"[""actuators"", ""groupware"", ""haptic interfaces"", ""pneumatic actuators"", ""smartphones""]","[""actuators"", ""groupware"", ""haptic interfaces"", ""pneumatic actuators"", ""smartphones""]",actuators;groupware;haptic interfaces;pneumatic actuators;smartphones,input;liberal arts;industrial equipment;collaboration;telecommunication;semiconductors,technology;use cases;industries,input;liberal arts;industrial equipment;collaboration;telecommunication;semiconductors,technology;use cases;industries,actuators groupware haptic_interfaces pneumatic_actuators smartphones choker type_wearable_device collaborative_work face to face_communication haptic_feedback haptic_presentation multiple_pneumatic_actuators omnidirectional_haptic_stimulation_system physical_contact presence_presentation pressure_patterns remote_meetings remote_workers spatial_augmented_reality_technology virtual_space_technology work from home c6130v_virtual_reality c5540b_interactive input_devices c6130g_groupware c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing input liberal_arts industrial_equipment collaboration telecommunication semiconductors,actuators groupware haptic_interfaces pneumatic_actuators smartphones,choker type_wearable_device collaborative_work face to face_communication haptic_feedback haptic_presentation multiple_pneumatic_actuators omnidirectional_haptic_stimulation_system physical_contact presence_presentation pressure_patterns remote_meetings remote_workers spatial_augmented_reality_technology virtual_space_technology work from home,recently remote meeting work home become common reducing opportunity face face communication facilitate communication among remote worker researcher focused virtual space technology spatial augmented reality technology although technology enhance immersiveness collaborative work face challenge fostering sense physical contact work aimed foster sense presence haptic stimulation using pneumatic actuator specifically developed choker type wearable device present various pressure pattern around neck pattern presented depends message device must convey various combination haptic presentation achieved pumping air multiple pneumatic actuator attached choker addition conducted experiment involving actuator different shape optimize haptic presentation linked smartphone proposed device present pressure pattern indicate incoming call notification give warning obstacle one texting might miss walking provide direction pedestrian furthermore device used wide range application necessary daily living enhance one experience realm entertainment example haptic feedback synchronizes presence singer rhythm song one listens performer movement stage performance immerse user enjoyable experience,actuators groupware haptic_interfaces pneumatic_actuators smartphones choker type_wearable_device collaborative_work face to face_communication haptic_feedback haptic_presentation multiple_pneumatic_actuators omnidirectional_haptic_stimulation_system physical_contact presence_presentation pressure_patterns remote_meetings remote_workers spatial_augmented_reality_technology virtual_space_technology work from home c6130v_virtual_reality c5540b_interactive input_devices c6130g_groupware c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing input liberal_arts industrial_equipment collaboration telecommunication semiconductors recently remote meeting work home become common reducing opportunity face face communication facilitate communication among remote worker researcher focused virtual space technology spatial augmented reality technology although technology enhance immersiveness collaborative work face challenge fostering sense physical contact work aimed foster sense presence haptic stimulation using pneumatic actuator specifically developed choker type wearable device present various pressure pattern around neck pattern presented depends message device must convey various combination haptic presentation achieved pumping air multiple pneumatic actuator attached choker addition conducted experiment involving actuator different shape optimize haptic presentation linked smartphone proposed device present pressure pattern indicate incoming call notification give warning obstacle one texting might miss walking provide direction pedestrian furthermore device used wide range application necessary daily living enhance one experience realm entertainment example haptic feedback synchronizes presence singer rhythm song one listens performer movement stage performance immerse user enjoyable experience,recently remote meeting work home become common reducing opportunity face face communication facilitate communication among remote worker researcher focused virtual space technology spatial augmented reality technology although technology enhance immersiveness collaborative work face challenge fostering sense physical contact work aimed foster sense presence haptic stimulation using pneumatic actuator specifically developed choker type wearable device present various pressure pattern around neck pattern presented depends message device must convey various combination haptic presentation achieved pumping air multiple pneumatic actuator attached choker addition conducted experiment involving actuator different shape optimize haptic presentation linked smartphone proposed device present pressure pattern indicate incoming call notification give warning obstacle one texting might miss walking provide direction pedestrian furthermore device used wide range application necessary daily living enhance one experience realm entertainment example haptic feedback synchronizes presence singer rhythm song one listens performer movement stage performance immerse user enjoyable experienceactuators groupware haptic_interfaces pneumatic_actuators smartphoneschoker type_wearable_device collaborative_work face to face_communication haptic_feedback haptic_presentation multiple_pneumatic_actuators omnidirectional_haptic_stimulation_system physical_contact presence_presentation pressure_patterns remote_meetings remote_workers spatial_augmented_reality_technology virtual_space_technology work from home
241,The GW Community Medi-Corps Program: A Mobile Mixed-Reality Immersive Learning Center,"Salvetti, F., Capshaw, T. L., Zanin, L., O’Connor, K. C., Zeng, Q., & Bertagni, B. (2022). The GW Community Medi-Corps Program: A Mobile Mixed-Reality Immersive Learning Center. Lecture Notes in Networks and Systems, 335–350. https://doi.org/10.1007/978-3-031-21569-8_32
",10.1007/978-3-031-21569-8_32,"The Community Medi-Corps Program-designed and implemented by the George Washington University (GW) School of Medicine and Health Sciences (SMHS) faculty with Growth and Opportunity Virginia funding (GO Virginia)-is aimed at leveraging the power of community, educational institutions, mentors, industry, and business partners to close the opportunity gap, transform student learning, and enrich the regional workforce. This program transforms educational experience through innovative virtual reality, augmented reality, and a mix between the two that is the enhanced reality (e-REAL). Students will be better prepared in the pathways they choose for high demand health and life sciences industry jobs that will help grow the economy.","C6130V Virtual reality;C0220 Computing education and training;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction",augmented reality;business partners;Community Medi-Corps Program-designed;educational experience;educational institutions;enhanced reality;George Washington University School;GO Virginia;GW Community Medi-Corps Program;high demand health;innovative virtual reality;life sciences industry jobs;mobile mixed-reality immersive learning center;opportunity gap;Opportunity Virginia funding;student learning,augmented reality;computer aided instruction;educational courses;educational institutions;mobile computing;virtual reality,2023,Conference article (CA),Innovative Approaches to Technology-Enhanced Learning for the Workplace and Higher Education: Proceedings of 'The Learning Ideas Conference' 2022. Lecture Notes in Networks and Systems (581),"(1) Salvetti, F.; (3) Capshaw, T.L.; (3) Zanin, L.; (3) O'connor, K.C.; (3) Zeng, Q.; (1) Bertagni, B.; ","(1) Centro Studi Logos, e-REAL Labs, Italy; (2) George Washington University, Houston, TX, United States; (3) George Washington University School of Medicine and Health Sciences, Washington, DC, United States; ",Springer,-1,"[""computer aided instruction"", ""educational courses"", ""educational institutions"", ""mobile computing""]","[""computer aided instruction"", ""educational courses"", ""educational institutions"", ""mobile computing""]",computer aided instruction;educational courses;educational institutions;mobile computing,education;telecommunication;training,use cases;industries,education;telecommunication;training,use cases;industries,computer_aided_instruction educational_courses educational_institutions mobile_computing augmented_reality business_partners community_medi corps_program designed educational_experience educational_institutions enhanced_reality george_washington_university_school go_virginia gw_community_medi corps_program high_demand_health innovative_virtual_reality life_sciences_industry_jobs mobile_mixed reality_immersive_learning_center opportunity_gap opportunity_virginia_funding student_learning c6130v_virtual_reality c0220_computing_education_and_training c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction education telecommunication training,computer_aided_instruction educational_courses educational_institutions mobile_computing,augmented_reality business_partners community_medi corps_program designed educational_experience educational_institutions enhanced_reality george_washington_university_school go_virginia gw_community_medi corps_program high_demand_health innovative_virtual_reality life_sciences_industry_jobs mobile_mixed reality_immersive_learning_center opportunity_gap opportunity_virginia_funding student_learning,community medi corp program designed implemented george washington university gw school medicine health science smhs faculty growth opportunity virginia funding go virginia aimed leveraging power community educational institution mentor industry business partner close opportunity gap transform student learning enrich regional workforce program transforms educational experience innovative virtual reality augmented reality mix two enhanced reality e real student better prepared pathway choose high demand health life science industry job help grow economy,computer_aided_instruction educational_courses educational_institutions mobile_computing augmented_reality business_partners community_medi corps_program designed educational_experience educational_institutions enhanced_reality george_washington_university_school go_virginia gw_community_medi corps_program high_demand_health innovative_virtual_reality life_sciences_industry_jobs mobile_mixed reality_immersive_learning_center opportunity_gap opportunity_virginia_funding student_learning c6130v_virtual_reality c0220_computing_education_and_training c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction education telecommunication training community medi corp program designed implemented george washington university gw school medicine health science smhs faculty growth opportunity virginia funding go virginia aimed leveraging power community educational institution mentor industry business partner close opportunity gap transform student learning enrich regional workforce program transforms educational experience innovative virtual reality augmented reality mix two enhanced reality e real student better prepared pathway choose high demand health life science industry job help grow economy,community medi corp program designed implemented george washington university gw school medicine health science smhs faculty growth opportunity virginia funding go virginia aimed leveraging power community educational institution mentor industry business partner close opportunity gap transform student learning enrich regional workforce program transforms educational experience innovative virtual reality augmented reality mix two enhanced reality e real student better prepared pathway choose high demand health life science industry job help grow economycomputer_aided_instruction educational_courses educational_institutions mobile_computingaugmented_reality business_partners community_medi corps_program designed educational_experience educational_institutions enhanced_reality george_washington_university_school go_virginia gw_community_medi corps_program high_demand_health innovative_virtual_reality life_sciences_industry_jobs mobile_mixed reality_immersive_learning_center opportunity_gap opportunity_virginia_funding student_learning
242,Gesture and Voice Commands to Interact With AR Windshield Display in Automated Vehicle: A Remote Elicitation Study,"Ch, N. A. N., Tosca, D., Crump, T., Ansah, A., Kun, A., & Shaer, O. (2022). Gesture and Voice Commands to Interact With AR Windshield Display in Automated Vehicle: A Remote Elicitation Study. Proceedings of the 14th International Conference on Automotive User Interfaces and Interactive Vehicular Applications. https://doi.org/10.1145/3543174.3545257
",10.1145/3543174.3545257,"Augmented reality (AR) windshield display (WSD) offers promising ways to engage in non-driving tasks in automated vehicles. Previous studies explored different ways WSD can be used to present driving and other tasks-related information and how that can affect driving performance, user experience, and performance in secondary tasks. Our goal for this study was to examine how drivers expect to use gesture and voice commands for interacting with WSD for performing complex, multi-step personal and work-related tasks in an automated vehicle. In this remote unmoderated online elicitation study, 31 participants proposed 373 gestures and 373 voice commands for performing 24 tasks. We analyzed the elicited interactions, their preferred modality of interaction, and the reasons behind this preference. Lastly, we discuss our results and their implications for designing AR WSD in automated vehicles.",C6180 User interfaces;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7445 Traffic engineering computing,373 voice commands;AR windshield display;AR WSD;augmented reality windshield display;automated vehicle;different ways WSD;elicited interactions;gesture;remote elicitation study;remote unmoderated online elicitation study;secondary tasks;tasks-related information;work-related tasks,augmented reality;driver information systems;gesture recognition;human computer interaction;Internet;user interfaces,2022,Conference article (CA),AutomotiveUI '22: 14th International Conference on Automotive User Interfaces and Interactive Vehicular Applications,"(1) Ch, N.A.N.; (2) Tosca, D.; (3) Crump, T.; (1) Ansah, A.; (1) Kun, A.; (3) Shaer, O.; ","(1) University of New Hampshire, Durham, NH, United States; (2) New York University, New York, NY, United States; (3) Wellesley College, Wellesley, MA, United States; ",ACM,-1,"[""driver information systems"", ""gesture recognition"", ""human computer interaction"", ""internet"", ""user interfaces""]","[""driver information systems"", ""gesture recognition"", ""human computer interaction"", ""internet"", ""user interfaces""]",driver information systems;gesture recognition;human computer interaction;internet;user interfaces,education;input;automotive;human factors;developers;human-computer interaction;networks,technology;end users and user experience;industries,education;input;automotive;human factors;developers;human-computer interaction;networks,technology;end users and user experience;industries,driver_information_systems gesture_recognition human_computer_interaction internet user_interfaces 373_voice_commands ar_windshield_display ar_wsd augmented_reality_windshield_display automated_vehicle different_ways_wsd elicited_interactions gesture remote_elicitation_study remote_unmoderated_online_elicitation_study secondary_tasks tasks related_information work related_tasks c6180_user_interfaces c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7445_traffic_engineering_computing education input automotive human_factors developers human computer_interaction networks,driver_information_systems gesture_recognition human_computer_interaction internet user_interfaces,373_voice_commands ar_windshield_display ar_wsd augmented_reality_windshield_display automated_vehicle different_ways_wsd elicited_interactions gesture remote_elicitation_study remote_unmoderated_online_elicitation_study secondary_tasks tasks related_information work related_tasks,augmented reality ar windshield display wsd offer promising way engage non driving task automated vehicle previous study explored different way wsd used present driving task related information affect driving performance user experience performance secondary task goal study examine driver expect use gesture voice command interacting wsd performing complex multi step personal work related task automated vehicle remote unmoderated online elicitation study 31 participant proposed 373 gesture 373 voice command performing 24 task analyzed elicited interaction preferred modality interaction reason behind preference lastly discus result implication designing ar wsd automated vehicle,driver_information_systems gesture_recognition human_computer_interaction internet user_interfaces 373_voice_commands ar_windshield_display ar_wsd augmented_reality_windshield_display automated_vehicle different_ways_wsd elicited_interactions gesture remote_elicitation_study remote_unmoderated_online_elicitation_study secondary_tasks tasks related_information work related_tasks c6180_user_interfaces c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7445_traffic_engineering_computing education input automotive human_factors developers human computer_interaction networks augmented reality ar windshield display wsd offer promising way engage non driving task automated vehicle previous study explored different way wsd used present driving task related information affect driving performance user experience performance secondary task goal study examine driver expect use gesture voice command interacting wsd performing complex multi step personal work related task automated vehicle remote unmoderated online elicitation study 31 participant proposed 373 gesture 373 voice command performing 24 task analyzed elicited interaction preferred modality interaction reason behind preference lastly discus result implication designing ar wsd automated vehicle,augmented reality ar windshield display wsd offer promising way engage non driving task automated vehicle previous study explored different way wsd used present driving task related information affect driving performance user experience performance secondary task goal study examine driver expect use gesture voice command interacting wsd performing complex multi step personal work related task automated vehicle remote unmoderated online elicitation study 31 participant proposed 373 gesture 373 voice command performing 24 task analyzed elicited interaction preferred modality interaction reason behind preference lastly discus result implication designing ar wsd automated vehicledriver_information_systems gesture_recognition human_computer_interaction internet user_interfaces373_voice_commands ar_windshield_display ar_wsd augmented_reality_windshield_display automated_vehicle different_ways_wsd elicited_interactions gesture remote_elicitation_study remote_unmoderated_online_elicitation_study secondary_tasks tasks related_information work related_tasks
243,Eye-Perspective View Management for Optical See-Through Head-Mounted Displays,"Emsenhuber, G., Langlotz, T., Kalkofen, D., Sutton, J., & Tatzgern, M. (2023). Eye-Perspective View Management for Optical See-Through Head-Mounted Displays. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581059
",10.1145/3544548.3581059,"Optical see-through (OST) head-mounted displays (HMDs) enable users to experience Augmented Reality (AR) support in the form of helpful real-world annotations. Unfortunately, the blend of the environment with virtual augmentations due to semitransparent OST displays often deteriorates the contrast and legibility of annotations. View management algorithms adapt the annotations' layout to improve legibility based on real-world information, typically captured by built-in HMD cameras. However, the camera views are different from the user's view through the OST display which decreases the final layout quality. We present eye-perspective view management that synthesizes high-fidelity renderings of the user's view to optimize annotation placement. Our method significantly improves over traditional camera-based view management in terms of annotation placement and legibility. Eye-perspective optimizations open up opportunities for further research on use cases relying on the user's true view through OST HMDs.",B7260 Display technology;C5260B Computer vision and image processing techniques;C5540D Computer displays;C6130B Graphics techniques;C6130V Virtual reality,annotation placement;Augmented Reality support;camera views;eye-perspective optimizations;eye-perspective view management;final layout quality;legibility;OST display;OST HMDs;real-world annotations;real-world information;semitransparent OST displays;traditional camera-based view management;user;view management algorithms;virtual augmentations,augmented reality;cameras;helmet mounted displays;rendering (computer graphics);virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Emsenhuber, G.; (2) Langlotz, T.; (3) Kalkofen, D.; (2) Sutton, J.; (1) Tatzgern, M.; ","(1) Salzburg University of Applied Sciences, Austria; (2) University of Otago, New Zealand; (3) Graz University of Technology, Austria; ",ACM,-1,"[""cameras"", ""helmet mounted displays"", ""rendering""]","[""cameras"", ""helmet mounted displays"", ""rendering""]",cameras;helmet mounted displays;rendering,display technology;wearables;graphics;input,technology;displays,display technology;wearables;graphics;input,technology;displays,cameras helmet_mounted_displays rendering annotation_placement augmented_reality_support camera_views eye perspective_optimizations eye perspective_view_management final_layout_quality legibility ost_display ost_hmds real world_annotations real world_information semitransparent_ost_displays traditional_camera based_view_management user view_management_algorithms virtual_augmentations b7260_display_technology c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality display_technology wearables graphics input,cameras helmet_mounted_displays rendering,annotation_placement augmented_reality_support camera_views eye perspective_optimizations eye perspective_view_management final_layout_quality legibility ost_display ost_hmds real world_annotations real world_information semitransparent_ost_displays traditional_camera based_view_management user view_management_algorithms virtual_augmentations,optical see ost head mounted display hmds enable user experience augmented reality ar support form helpful real world annotation unfortunately blend environment virtual augmentation due semitransparent ost display often deteriorates contrast legibility annotation view management algorithm adapt annotation layout improve legibility based real world information typically captured built hmd camera however camera view different user view ost display decrease final layout quality present eye perspective view management synthesizes high fidelity rendering user view optimize annotation placement method significantly improves traditional camera based view management term annotation placement legibility eye perspective optimization open opportunity research use case relying user true view ost hmds,cameras helmet_mounted_displays rendering annotation_placement augmented_reality_support camera_views eye perspective_optimizations eye perspective_view_management final_layout_quality legibility ost_display ost_hmds real world_annotations real world_information semitransparent_ost_displays traditional_camera based_view_management user view_management_algorithms virtual_augmentations b7260_display_technology c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality display_technology wearables graphics input optical see ost head mounted display hmds enable user experience augmented reality ar support form helpful real world annotation unfortunately blend environment virtual augmentation due semitransparent ost display often deteriorates contrast legibility annotation view management algorithm adapt annotation layout improve legibility based real world information typically captured built hmd camera however camera view different user view ost display decrease final layout quality present eye perspective view management synthesizes high fidelity rendering user view optimize annotation placement method significantly improves traditional camera based view management term annotation placement legibility eye perspective optimization open opportunity research use case relying user true view ost hmds,optical see ost head mounted display hmds enable user experience augmented reality ar support form helpful real world annotation unfortunately blend environment virtual augmentation due semitransparent ost display often deteriorates contrast legibility annotation view management algorithm adapt annotation layout improve legibility based real world information typically captured built hmd camera however camera view different user view ost display decrease final layout quality present eye perspective view management synthesizes high fidelity rendering user view optimize annotation placement method significantly improves traditional camera based view management term annotation placement legibility eye perspective optimization open opportunity research use case relying user true view ost hmdscameras helmet_mounted_displays renderingannotation_placement augmented_reality_support camera_views eye perspective_optimizations eye perspective_view_management final_layout_quality legibility ost_display ost_hmds real world_annotations real world_information semitransparent_ost_displays traditional_camera based_view_management user view_management_algorithms virtual_augmentations
244,Envisioning A Hyper-Learning System in the Age of Metaverse,"Wang, A., Gao, Z., Wang, Z., Hui, P., & Braud, T. (2022). Envisioning A Hyper-Learning System in the Age of Metaverse. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574427
",10.1145/3574131.3574427,"The digital technologies, such as interactive interfaces, augmented reality (AR), and virtual reality (VR), are emerging as the latest examples of an ongoing trend of digitizing learning in the metaverse. Their pervasive impact requires us to rethink the notion of information gathering and learning [Pokhrel and Chhetri 2021]. Although much research has been devoted to AR/VR/metaverse education, there is little research on the pedagogical interactions of pre-learning information in the metaverse. Pre-learning refers to the preparatory activity performed before formal learning. Whether we use pre-learning to discover new concepts, or as a travel guide throughout a deeper understanding of a topic, pre-learning requires massive information access. Currently, information presentation remains simple, constrained by the access media. For instance, web pages are mostly arranged in tabs as a form of listing, which does not enable users to organize the information well in relation to each other. With instant online information access updated constantly, the severity of these problems is becoming more signi&#58907;cant. Although information organization tools like Miro are now available to create associations and hierarchies and custom edits, they remain constrained to the 2 dimensions of the computer screen. By introducing a third dimension, immersive technologies and the metaverse help us present this information in a hybrid 3D way thatis more diverse and aesthetic. Therefore, we design a prototype of an extended reality (XR) learning interactive system in the metaverse. The system relies on custom catalogs to guide the user through the pre-learning process, allowing categorization and custom combinations of primary and secondary information in a virtual reality environment. It addresses the need for personalization and browsing categorization of web-based information access in pre-learning. The research gives acritical lens of the interaction with information interface in the process of pre-learning in the metaverse.",C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces;C7210N Information networks,augmented reality;digital technologies;extended reality learning interactive system;hyper-learning system;immersive technologies;information interface;information organization tools;metaverse education;online information access;pre-learning;virtual reality;Web-based information access;XR learning interactive system,augmented reality;computer aided instruction;Internet;user interfaces,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Wang, A.; (1) Gao, Z.; (1) Wang, Z.; (1) Hui, P.; (1) Braud, T.; ","(1) Hong Kong University of Science and Technology, China; ",ACM,-1,"[""computer aided instruction"", ""internet"", ""user interfaces""]","[""computer aided instruction"", ""internet"", ""user interfaces""]",computer aided instruction;internet;user interfaces,training;human-computer interaction;networks,technology;use cases;end users and user experience,training;human-computer interaction;networks,technology;use cases;end users and user experience,computer_aided_instruction internet user_interfaces augmented_reality digital_technologies extended_reality_learning_interactive_system hyper learning_system immersive_technologies information_interface information_organization_tools metaverse_education online_information_access pre learning virtual_reality web based_information_access xr_learning_interactive_system c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks training human computer_interaction networks,computer_aided_instruction internet user_interfaces,augmented_reality digital_technologies extended_reality_learning_interactive_system hyper learning_system immersive_technologies information_interface information_organization_tools metaverse_education online_information_access pre learning virtual_reality web based_information_access xr_learning_interactive_system,digital technology interactive interface augmented reality ar virtual reality vr emerging latest example ongoing trend digitizing learning metaverse pervasive impact requires u rethink notion information gathering learning pokhrel chhetri 2021 although much research devoted ar vr metaverse education little research pedagogical interaction pre learning information metaverse pre learning refers preparatory activity performed formal learning whether use pre learning discover new concept travel guide throughout deeper understanding topic pre learning requires massive information access currently information presentation remains simple constrained access medium instance web page mostly arranged tab form listing enable user organize information well relation instant online information access updated constantly severity problem becoming signi 58907 cant although information organization tool like miro available create association hierarchy custom edits remain constrained 2 dimension computer screen introducing third dimension immersive technology metaverse help u present information hybrid 3d way thatis diverse aesthetic therefore design prototype extended reality xr learning interactive system metaverse system relies custom catalog guide user pre learning process allowing categorization custom combination primary secondary information virtual reality environment address need personalization browsing categorization web based information access pre learning research give acritical lens interaction information interface process pre learning metaverse,computer_aided_instruction internet user_interfaces augmented_reality digital_technologies extended_reality_learning_interactive_system hyper learning_system immersive_technologies information_interface information_organization_tools metaverse_education online_information_access pre learning virtual_reality web based_information_access xr_learning_interactive_system c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks training human computer_interaction networks digital technology interactive interface augmented reality ar virtual reality vr emerging latest example ongoing trend digitizing learning metaverse pervasive impact requires u rethink notion information gathering learning pokhrel chhetri 2021 although much research devoted ar vr metaverse education little research pedagogical interaction pre learning information metaverse pre learning refers preparatory activity performed formal learning whether use pre learning discover new concept travel guide throughout deeper understanding topic pre learning requires massive information access currently information presentation remains simple constrained access medium instance web page mostly arranged tab form listing enable user organize information well relation instant online information access updated constantly severity problem becoming signi 58907 cant although information organization tool like miro available create association hierarchy custom edits remain constrained 2 dimension computer screen introducing third dimension immersive technology metaverse help u present information hybrid 3d way thatis diverse aesthetic therefore design prototype extended reality xr learning interactive system metaverse system relies custom catalog guide user pre learning process allowing categorization custom combination primary secondary information virtual reality environment address need personalization browsing categorization web based information access pre learning research give acritical lens interaction information interface process pre learning metaverse,digital technology interactive interface augmented reality ar virtual reality vr emerging latest example ongoing trend digitizing learning metaverse pervasive impact requires u rethink notion information gathering learning pokhrel chhetri 2021 although much research devoted ar vr metaverse education little research pedagogical interaction pre learning information metaverse pre learning refers preparatory activity performed formal learning whether use pre learning discover new concept travel guide throughout deeper understanding topic pre learning requires massive information access currently information presentation remains simple constrained access medium instance web page mostly arranged tab form listing enable user organize information well relation instant online information access updated constantly severity problem becoming signi 58907 cant although information organization tool like miro available create association hierarchy custom edits remain constrained 2 dimension computer screen introducing third dimension immersive technology metaverse help u present information hybrid 3d way thatis diverse aesthetic therefore design prototype extended reality xr learning interactive system metaverse system relies custom catalog guide user pre learning process allowing categorization custom combination primary secondary information virtual reality environment address need personalization browsing categorization web based information access pre learning research give acritical lens interaction information interface process pre learning metaversecomputer_aided_instruction internet user_interfacesaugmented_reality digital_technologies extended_reality_learning_interactive_system hyper learning_system immersive_technologies information_interface information_organization_tools metaverse_education online_information_access pre learning virtual_reality web based_information_access xr_learning_interactive_system
245,Experimental investigation of the tropospheric temperature gradient with Flightradar24,"Vogt, P., & Kasper, L. (2023). Experimental investigation of the tropospheric temperature gradient with Flightradar24. The Physics Teacher, 61(2), 148–149. https://doi.org/10.1119/5.0141246
",10.1119/5.0141246,"Sitting on the terrace on a warm summer evening and looking up at the sky, we often wonder where an airplane is going to fly. Based on the observed flight direction, we can make assumptions, but rarely check if they are really correct. The app Flightradar24 offers the possibility to confirm our assumptions. For this purpose, you just need to target the aircraft with your smartphone or tablet and then you will get augmented reality (AR) information for the flight displayed in the live image (Fig. 1): takeoff and destination, distance to the observer, airline, and type and photo of the aircraft. By tapping on the AR window, more detailed information on the flight times, the distance traveled, and the exact flight route is displayed on a map (Fig. 2). In this way, data of particular physical interest can also be retrieved, namely the aircraft's current altitude, its speed, its position, the prevailing wind speed, and the outside temperature. This corresponds to a retrieval of measurement data, so that the app can also be used for physical quasi-experiments. At this point, the investigation of the temperature profile of the troposphere will be described. Many further quantitative analyses can be found in Ref. 2. This approach to modeling also provides an example of handling real data in the sense of data literacy. [The copyright for the referenced work is owned by Author(s). Copies of full-text articles should only be made or obtained from the publisher or authorized sources.]","A9260G Winds and their effects in the lower atmosphere;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",aircraft;airline;airplane;app Flightradar24;AR window;augmented reality;data literacy;exact flight route;flight times;live image;measurement data;observed flight direction;observer;particular physical interest;physical quasiexperiments;prevailing wind speed;smartphone;takeoff;temperature profile;terrace;troposphere;tropospheric temperature gradient;warm summer evening,aircraft;aircraft displays;atmospheric temperature;augmented reality;travel industry;troposphere;wind,2023,Journal article (JA),Phys. Teach. (USA),"(1) Vogt, P.; (2) Kasper, L.; ","(1) Pedagogical Institute of Rhineland-Palatinate, Germany; (2) Padagogische Hochschule Schwabisch Gmund, Germany; ",AIP Publishing,-1,"[""aircraft"", ""aircraft displays"", ""atmospheric temperature"", ""travel industry"", ""troposphere"", ""wind""]","[""aircraft"", ""aircraft displays"", ""atmospheric temperature"", ""travel industry"", ""troposphere"", ""wind""]",aircraft;aircraft displays;atmospheric temperature;travel industry;troposphere;wind,farming and natural science;other;aviation and aerospace;transportation;display technology;engineering,technology;other;displays;industries,farming and natural science;other;aviation and aerospace;transportation;display technology;engineering,technology;other;displays;industries,aircraft aircraft_displays atmospheric_temperature travel_industry troposphere wind aircraft airline airplane app_flightradar24 ar_window augmented_reality data_literacy exact_flight_route flight_times live_image measurement_data observed_flight_direction observer particular_physical_interest physical_quasiexperiments prevailing_wind_speed smartphone takeoff temperature_profile terrace troposphere tropospheric_temperature_gradient warm_summer_evening a9260g_winds_and_their_effects_in_the_lower_atmosphere b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality farming_and_natural_science other aviation_and_aerospace transportation display_technology engineering,aircraft aircraft_displays atmospheric_temperature travel_industry troposphere wind,aircraft airline airplane app_flightradar24 ar_window augmented_reality data_literacy exact_flight_route flight_times live_image measurement_data observed_flight_direction observer particular_physical_interest physical_quasiexperiments prevailing_wind_speed smartphone takeoff temperature_profile terrace troposphere tropospheric_temperature_gradient warm_summer_evening,sitting terrace warm summer evening looking sky often wonder airplane going fly based observed flight direction make assumption rarely check really correct app flightradar24 offer possibility confirm assumption purpose need target aircraft smartphone tablet get augmented reality ar information flight displayed live image fig 1 takeoff destination distance observer airline type photo aircraft tapping ar window detailed information flight time distance traveled exact flight route displayed map fig 2 way data particular physical interest also retrieved namely aircraft current altitude speed position prevailing wind speed outside temperature corresponds retrieval measurement data app also used physical quasi experiment point investigation temperature profile troposphere described many quantitative analysis found ref 2 approach modeling also provides example handling real data sense data literacy copyright referenced work owned author copy full text article made obtained publisher authorized source,aircraft aircraft_displays atmospheric_temperature travel_industry troposphere wind aircraft airline airplane app_flightradar24 ar_window augmented_reality data_literacy exact_flight_route flight_times live_image measurement_data observed_flight_direction observer particular_physical_interest physical_quasiexperiments prevailing_wind_speed smartphone takeoff temperature_profile terrace troposphere tropospheric_temperature_gradient warm_summer_evening a9260g_winds_and_their_effects_in_the_lower_atmosphere b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality farming_and_natural_science other aviation_and_aerospace transportation display_technology engineering sitting terrace warm summer evening looking sky often wonder airplane going fly based observed flight direction make assumption rarely check really correct app flightradar24 offer possibility confirm assumption purpose need target aircraft smartphone tablet get augmented reality ar information flight displayed live image fig 1 takeoff destination distance observer airline type photo aircraft tapping ar window detailed information flight time distance traveled exact flight route displayed map fig 2 way data particular physical interest also retrieved namely aircraft current altitude speed position prevailing wind speed outside temperature corresponds retrieval measurement data app also used physical quasi experiment point investigation temperature profile troposphere described many quantitative analysis found ref 2 approach modeling also provides example handling real data sense data literacy copyright referenced work owned author copy full text article made obtained publisher authorized source,sitting terrace warm summer evening looking sky often wonder airplane going fly based observed flight direction make assumption rarely check really correct app flightradar24 offer possibility confirm assumption purpose need target aircraft smartphone tablet get augmented reality ar information flight displayed live image fig 1 takeoff destination distance observer airline type photo aircraft tapping ar window detailed information flight time distance traveled exact flight route displayed map fig 2 way data particular physical interest also retrieved namely aircraft current altitude speed position prevailing wind speed outside temperature corresponds retrieval measurement data app also used physical quasi experiment point investigation temperature profile troposphere described many quantitative analysis found ref 2 approach modeling also provides example handling real data sense data literacy copyright referenced work owned author copy full text article made obtained publisher authorized sourceaircraft aircraft_displays atmospheric_temperature travel_industry troposphere windaircraft airline airplane app_flightradar24 ar_window augmented_reality data_literacy exact_flight_route flight_times live_image measurement_data observed_flight_direction observer particular_physical_interest physical_quasiexperiments prevailing_wind_speed smartphone takeoff temperature_profile terrace troposphere tropospheric_temperature_gradient warm_summer_evening
246,"Mixed, Augmented and Virtual, Reality Applied to the Teaching of Mathematics for Architects","Cabero-Almenara, J., Barroso-Osuna, J., & Martinez-Roig, R. (2021). Mixed, Augmented and Virtual, Reality Applied to the Teaching of Mathematics for Architects. Applied Sciences, 11(15), 7125. https://doi.org/10.3390/app11157125
",10.3390/app11157125,"This paper examines the possibilities of Mixed Reality, the combination of two emerging technologies&#8212;Augmented Reality and Virtual Reality&#8212;in university education. For this purpose, an object was elaborated in Mixed Reality that underwent the evaluation of 44 first-year students from the degree in architecture who were enrolled in the subject ""Mathematical Foundations for Architecture."" The instrument utilized was based on the TAM model, which analyzes the degree of acceptance of the technology used. The analysis of the responses provided by students supported the 23 hypotheses formulated in this study. It was found that MR significantly influences the perceived usefulness and ease of use. The results imply that MR utilization has positive effects on the mathematical teaching-learning processes in architecture from the students' perception of their mastery of technology. It becomes necessary to offer support to those university teachers who promote the use of active MR-based methodologies in classrooms.",C7810C Computer-aided instruction;C0220 Computing education and training;C6130V Virtual reality;C7110 Educational administration;C7310 Mathematics computing,augmented reality;instrument utilized;mathematical teaching learning process;mixed reality;MR utilization;reality applied;student perception;subject mathematical foundations;university education;university teachers;virtual reality,augmented reality;computer aided instruction;educational institutions;mathematics computing;teaching,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Cabero-almenara, J.; (1) Barroso-osuna, J.; (2) Martinez-roig, R.; ","(1) University of Seville, Department of Didactics and Educational Organization, Spain; (2) University of Alicante, Department of General Didactics and Specific Didactics, Spain; ",MDPI,-1,"[""computer aided instruction"", ""educational institutions"", ""mathematics computing"", ""teaching""]","[""computer aided instruction"", ""educational institutions"", ""mathematics computing"", ""teaching""]",computer aided instruction;educational institutions;mathematics computing;teaching,education;engineering;training,technology;use cases;industries,education;engineering;training,technology;use cases;industries,computer_aided_instruction educational_institutions mathematics_computing teaching augmented_reality instrument_utilized mathematical_teaching_learning_process mixed_reality mr_utilization reality_applied student_perception subject_mathematical_foundations university_education university_teachers virtual_reality c7810c_computer aided_instruction c0220_computing_education_and_training c6130v_virtual_reality c7110_educational_administration c7310_mathematics_computing education engineering training,computer_aided_instruction educational_institutions mathematics_computing teaching,augmented_reality instrument_utilized mathematical_teaching_learning_process mixed_reality mr_utilization reality_applied student_perception subject_mathematical_foundations university_education university_teachers virtual_reality,paper examines possibility mixed reality combination two emerging technology 8212 augmented reality virtual reality 8212 university education purpose object elaborated mixed reality underwent evaluation 44 first year student degree architecture enrolled subject mathematical foundation architecture instrument utilized based tam model analyzes degree acceptance technology used analysis response provided student supported 23 hypothesis formulated study found mr significantly influence perceived usefulness ease use result imply mr utilization positive effect mathematical teaching learning process architecture student perception mastery technology becomes necessary offer support university teacher promote use active mr based methodology classroom,computer_aided_instruction educational_institutions mathematics_computing teaching augmented_reality instrument_utilized mathematical_teaching_learning_process mixed_reality mr_utilization reality_applied student_perception subject_mathematical_foundations university_education university_teachers virtual_reality c7810c_computer aided_instruction c0220_computing_education_and_training c6130v_virtual_reality c7110_educational_administration c7310_mathematics_computing education engineering training paper examines possibility mixed reality combination two emerging technology 8212 augmented reality virtual reality 8212 university education purpose object elaborated mixed reality underwent evaluation 44 first year student degree architecture enrolled subject mathematical foundation architecture instrument utilized based tam model analyzes degree acceptance technology used analysis response provided student supported 23 hypothesis formulated study found mr significantly influence perceived usefulness ease use result imply mr utilization positive effect mathematical teaching learning process architecture student perception mastery technology becomes necessary offer support university teacher promote use active mr based methodology classroom,paper examines possibility mixed reality combination two emerging technology 8212 augmented reality virtual reality 8212 university education purpose object elaborated mixed reality underwent evaluation 44 first year student degree architecture enrolled subject mathematical foundation architecture instrument utilized based tam model analyzes degree acceptance technology used analysis response provided student supported 23 hypothesis formulated study found mr significantly influence perceived usefulness ease use result imply mr utilization positive effect mathematical teaching learning process architecture student perception mastery technology becomes necessary offer support university teacher promote use active mr based methodology classroomcomputer_aided_instruction educational_institutions mathematics_computing teachingaugmented_reality instrument_utilized mathematical_teaching_learning_process mixed_reality mr_utilization reality_applied student_perception subject_mathematical_foundations university_education university_teachers virtual_reality
247,Embossing micro-fabrication-based epidermal electrode with a CNT-composed metal film as human&ndash;machine interface,"Liu, G., Xu, C., Ren, J., Liu, Y., Yao, L., Xie, Y., Zhang, T., & Liu, Y. (2023). Embossing micro-fabrication-based epidermal electrode with a CNT-composed metal film as human–machine interface. Journal of Materials Science: Materials in Electronics, 34(16). https://doi.org/10.1007/s10854-023-10599-0
",10.1007/s10854-023-10599-0,"Recent years witness the rapid development of the internet of things and artificial intelligence, which ignites the worldwide research needs for flexible electronics to fulfill intelligent human&ndash;machine interfaces. As a promising future technology, the flexible epidermal electrode attracts great research enthusiasm in the field of intelligent robots, human&ndash;machine interfaces, virtual and augmented reality, medical treatment, health monitoring, and other emerging applications. However, it is still the main challenge to enhance the vertical charge conduction bridging the interface of metal electrode and human skin, which constructs an insurmountable obstacle for wide usage. In this article, a low-cost embossing fabrication is introduced to pattern a stretchable epidermal electrode device that consists of a carbon-nanotube (CNT)-composed metal thin film. Benefited from the excellent flexibility and stretchability, the fabricated electrode can conformably attach to the skin and collect high-quality bioelectrical signals. Moreover, this epidermal electrode features good conductivity along the vertical path for acquiring the epidermal charge, due to conductive CNTs bridging the interface of skin and this epidermal electrode. With this device structure configuration, the impedance between skin and epidermal electrode could effectively reduce by more than 50%. The conformal contact mechanism relies upon an ultra-thin metal film on skin texture, which makes the device achieves high sensitivity and durability in a human&ndash;machine interface. The electrocardiogram (ECG) and electromyography (EMG) demonstration and gesture recognition further conclude that this technology has a chance to bring up the potential of clinical applications as a human&ndash;machine interface. &copy; 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","461.6 Medicine and Pharmacology;701.1 Electricity: Basic Concepts and Phenomena;715 Electronic Equipment, General Purpose and Industrial;723 Computer Software, Data Handling and Applications;731.6 Robot Applications;761 Nanotechnology;933.1 Crystalline Solids",A-carbon;Future technologies;Health monitoring;Human Machine Interface;Intelligent human-machine interface;Medical treatment;Metal-films;Micro-fabrication;Research needs;Virtual and augmented reality,Augmented reality;Carbon nanotubes;Electrocardiography;Fabrication;Flexible electronics;Intelligent robots;Metallic films;Nanocrystals;Textures;Thin films;Virtual reality;Wearable technology,2023,Journal article (JA),J Mater Sci Mater Electron,"(1) Liu, Geng; (2) Xu, Chuanbin; (1) Ren, Jie; (3) Liu, Ying; (3) Yao, Liang; (2) Xie, Ying; (2) Zhang, Tong; (2) Liu, Yijian; ","(1) Beijing Smart-Chip Microelectronics Technology Co., Ltd., Beijing, China; (2) College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, China; (3) Smart Shine Microelectronics Technology Co., Ltd., Qingdao, China; ",Springer,-1,"[""carbon nanotubes"", ""electrocardiography"", ""fabrication"", ""flexible electronics"", ""intelligent robots"", ""metallic films"", ""nanocrystals"", ""textures"", ""thin films"", ""wearable technology""]","[""carbon nanotubes"", ""electrocardiography"", ""fabrication"", ""flexible electronics"", ""intelligent robots"", ""metallic films"", ""nanocrystals"", ""textures"", ""thin films"", ""wearable technology""]",carbon nanotubes;electrocardiography;fabrication;flexible electronics;intelligent robots;metallic films;nanocrystals;textures;thin films;wearable technology,"other;robotics;input;medical;inspection, safety and quality;display technology;wearables;human-computer interaction;manufacturing",other;displays;industries;end users and user experience;use cases;technology,"other;robotics;input;medical;inspection, safety and quality;display technology;wearables;human-computer interaction;manufacturing",other;displays;industries;end users and user experience;use cases;technology,carbon_nanotubes electrocardiography fabrication flexible_electronics intelligent_robots metallic_films nanocrystals textures thin_films wearable_technology a carbon future_technologies health_monitoring human_machine_interface intelligent_human machine_interface medical_treatment metal films micro fabrication research_needs virtual_and_augmented_reality 461 6_medicine_and_pharmacology 701 1_electricity _basic_concepts_and_phenomena 715_electronic_equipment _general_purpose_and_industrial 723_computer_software _data_handling_and_applications 731 6_robot_applications 761_nanotechnology 933 1_crystalline_solids other robotics input medical inspection _safety_and_quality display_technology wearables human computer_interaction manufacturing,carbon_nanotubes electrocardiography fabrication flexible_electronics intelligent_robots metallic_films nanocrystals textures thin_films wearable_technology,a carbon future_technologies health_monitoring human_machine_interface intelligent_human machine_interface medical_treatment metal films micro fabrication research_needs virtual_and_augmented_reality,recent year witness rapid development internet thing artificial intelligence ignites worldwide research need flexible electronics fulfill intelligent human ndash machine interface promising future technology flexible epidermal electrode attracts great research enthusiasm field intelligent robot human ndash machine interface virtual augmented reality medical treatment health monitoring emerging application however still main challenge enhance vertical charge conduction bridging interface metal electrode human skin construct insurmountable obstacle wide usage article low cost embossing fabrication introduced pattern stretchable epidermal electrode device consists carbon nanotube cnt composed metal thin film benefited excellent flexibility stretchability fabricated electrode conformably attach skin collect high quality bioelectrical signal moreover epidermal electrode feature good conductivity along vertical path acquiring epidermal charge due conductive cnts bridging interface skin epidermal electrode device structure configuration impedance skin epidermal electrode could effectively reduce 50 conformal contact mechanism relies upon ultra thin metal film skin texture make device achieves high sensitivity durability human ndash machine interface electrocardiogram ecg electromyography emg demonstration gesture recognition conclude technology chance bring potential clinical application human ndash machine interface copy 2023 author exclusive licence springer science business medium llc part springer nature,carbon_nanotubes electrocardiography fabrication flexible_electronics intelligent_robots metallic_films nanocrystals textures thin_films wearable_technology a carbon future_technologies health_monitoring human_machine_interface intelligent_human machine_interface medical_treatment metal films micro fabrication research_needs virtual_and_augmented_reality 461 6_medicine_and_pharmacology 701 1_electricity _basic_concepts_and_phenomena 715_electronic_equipment _general_purpose_and_industrial 723_computer_software _data_handling_and_applications 731 6_robot_applications 761_nanotechnology 933 1_crystalline_solids other robotics input medical inspection _safety_and_quality display_technology wearables human computer_interaction manufacturing recent year witness rapid development internet thing artificial intelligence ignites worldwide research need flexible electronics fulfill intelligent human ndash machine interface promising future technology flexible epidermal electrode attracts great research enthusiasm field intelligent robot human ndash machine interface virtual augmented reality medical treatment health monitoring emerging application however still main challenge enhance vertical charge conduction bridging interface metal electrode human skin construct insurmountable obstacle wide usage article low cost embossing fabrication introduced pattern stretchable epidermal electrode device consists carbon nanotube cnt composed metal thin film benefited excellent flexibility stretchability fabricated electrode conformably attach skin collect high quality bioelectrical signal moreover epidermal electrode feature good conductivity along vertical path acquiring epidermal charge due conductive cnts bridging interface skin epidermal electrode device structure configuration impedance skin epidermal electrode could effectively reduce 50 conformal contact mechanism relies upon ultra thin metal film skin texture make device achieves high sensitivity durability human ndash machine interface electrocardiogram ecg electromyography emg demonstration gesture recognition conclude technology chance bring potential clinical application human ndash machine interface copy 2023 author exclusive licence springer science business medium llc part springer nature,recent year witness rapid development internet thing artificial intelligence ignites worldwide research need flexible electronics fulfill intelligent human ndash machine interface promising future technology flexible epidermal electrode attracts great research enthusiasm field intelligent robot human ndash machine interface virtual augmented reality medical treatment health monitoring emerging application however still main challenge enhance vertical charge conduction bridging interface metal electrode human skin construct insurmountable obstacle wide usage article low cost embossing fabrication introduced pattern stretchable epidermal electrode device consists carbon nanotube cnt composed metal thin film benefited excellent flexibility stretchability fabricated electrode conformably attach skin collect high quality bioelectrical signal moreover epidermal electrode feature good conductivity along vertical path acquiring epidermal charge due conductive cnts bridging interface skin epidermal electrode device structure configuration impedance skin epidermal electrode could effectively reduce 50 conformal contact mechanism relies upon ultra thin metal film skin texture make device achieves high sensitivity durability human ndash machine interface electrocardiogram ecg electromyography emg demonstration gesture recognition conclude technology chance bring potential clinical application human ndash machine interface copy 2023 author exclusive licence springer science business medium llc part springer naturecarbon_nanotubes electrocardiography fabrication flexible_electronics intelligent_robots metallic_films nanocrystals textures thin_films wearable_technologya carbon future_technologies health_monitoring human_machine_interface intelligent_human machine_interface medical_treatment metal films micro fabrication research_needs virtual_and_augmented_reality
248,ARound the Smartphone: Investigating the Effects of Virtually-Extended Display Size on Spatial Memory,"Hubenschmid, S., Zagermann, J., Leicht, D., Reiterer, H., & Feuchtner, T. (2023). ARound the Smartphone: Investigating the Effects of Virtually-Extended Display Size on Spatial Memory. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581438
",10.1145/3544548.3581438,"Smartphones conveniently place large information spaces in the palms of our hands. While research has shown that larger screens positively affect spatial memory, workload, and user experience, smartphones remain fairly compact for the sake of device ergonomics and portability. Thus, we investigate the use of hybrid user interfaces to virtually increase the available display size by complementing the smartphone with an augmented reality head-worn display. We thereby combine the benefits of familiar touch interaction with the near-infinite visual display space afforded by augmented reality. To better understand the potential of virtually-extended displays and the possible issues of splitting the user's visual attention between two screens (real and virtual), we conducted a within-subjects experiment with 24 participants completing navigation tasks using different virtually-augmented display sizes. Our findings reveal that a desktop monitor size represents a ""sweet spot"" for extending smartphones with augmented reality, informing the design of hybrid user interfaces.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C5540B Interactive-input devices;C5540D Computer displays;C6130B Graphics techniques;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",augmented reality head-worn display;available display size;desktop monitor size;device ergonomics;hybrid user interfaces;information spaces;larger screens;near-infinite visual display space;portability;smartphone;spatial memory;splitting the user;user experience;virtually-augmented display;virtually-extended display size;virtually-extended displays,augmented reality;computer displays;data visualisation;ergonomics;human computer interaction;mobile computing;smart phones;user experience;user interfaces;virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Hubenschmid, S.; (1) Zagermann, J.; (1) Leicht, D.; (1) Reiterer, H.; (2) Feuchtner, T.; ","(1) University of Konstanz, HCI Group, Germany; (2) Aarhus University, Germany and Department of Computer Science, Denmark; ",ACM,-1,"[""computer displays"", ""data visualization"", ""ergonomics"", ""human computer interaction"", ""mobile computing"", ""smartphones"", ""user experience"", ""user interfaces""]","[""computer displays"", ""data visualization"", ""ergonomics"", ""human computer interaction"", ""mobile computing"", ""smartphones"", ""user experience"", ""user interfaces""]",computer displays;data visualization;ergonomics;human computer interaction;mobile computing;smartphones;user experience;user interfaces,liberal arts;display technology;human factors;telecommunication;data;human-computer interaction,technology;industries;displays;end users and user experience,liberal arts;display technology;human factors;telecommunication;data;human-computer interaction,technology;industries;displays;end users and user experience,computer_displays data_visualization ergonomics human_computer_interaction mobile_computing smartphones user_experience user_interfaces augmented_reality_head worn_display available_display_size desktop_monitor_size device_ergonomics hybrid_user_interfaces information_spaces larger_screens near infinite_visual_display_space portability smartphone spatial_memory splitting_the_user user_experience virtually augmented_display virtually extended_display_size virtually extended_displays c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing liberal_arts display_technology human_factors telecommunication data human computer_interaction,computer_displays data_visualization ergonomics human_computer_interaction mobile_computing smartphones user_experience user_interfaces,augmented_reality_head worn_display available_display_size desktop_monitor_size device_ergonomics hybrid_user_interfaces information_spaces larger_screens near infinite_visual_display_space portability smartphone spatial_memory splitting_the_user user_experience virtually augmented_display virtually extended_display_size virtually extended_displays,smartphones conveniently place large information space palm hand research shown larger screen positively affect spatial memory workload user experience smartphones remain fairly compact sake device ergonomics portability thus investigate use hybrid user interface virtually increase available display size complementing smartphone augmented reality head worn display thereby combine benefit familiar touch interaction near infinite visual display space afforded augmented reality better understand potential virtually extended display possible issue splitting user visual attention two screen real virtual conducted within subject experiment 24 participant completing navigation task using different virtually augmented display size finding reveal desktop monitor size represents sweet spot extending smartphones augmented reality informing design hybrid user interface,computer_displays data_visualization ergonomics human_computer_interaction mobile_computing smartphones user_experience user_interfaces augmented_reality_head worn_display available_display_size desktop_monitor_size device_ergonomics hybrid_user_interfaces information_spaces larger_screens near infinite_visual_display_space portability smartphone spatial_memory splitting_the_user user_experience virtually augmented_display virtually extended_display_size virtually extended_displays c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing liberal_arts display_technology human_factors telecommunication data human computer_interaction smartphones conveniently place large information space palm hand research shown larger screen positively affect spatial memory workload user experience smartphones remain fairly compact sake device ergonomics portability thus investigate use hybrid user interface virtually increase available display size complementing smartphone augmented reality head worn display thereby combine benefit familiar touch interaction near infinite visual display space afforded augmented reality better understand potential virtually extended display possible issue splitting user visual attention two screen real virtual conducted within subject experiment 24 participant completing navigation task using different virtually augmented display size finding reveal desktop monitor size represents sweet spot extending smartphones augmented reality informing design hybrid user interface,smartphones conveniently place large information space palm hand research shown larger screen positively affect spatial memory workload user experience smartphones remain fairly compact sake device ergonomics portability thus investigate use hybrid user interface virtually increase available display size complementing smartphone augmented reality head worn display thereby combine benefit familiar touch interaction near infinite visual display space afforded augmented reality better understand potential virtually extended display possible issue splitting user visual attention two screen real virtual conducted within subject experiment 24 participant completing navigation task using different virtually augmented display size finding reveal desktop monitor size represents sweet spot extending smartphones augmented reality informing design hybrid user interfacecomputer_displays data_visualization ergonomics human_computer_interaction mobile_computing smartphones user_experience user_interfacesaugmented_reality_head worn_display available_display_size desktop_monitor_size device_ergonomics hybrid_user_interfaces information_spaces larger_screens near infinite_visual_display_space portability smartphone spatial_memory splitting_the_user user_experience virtually augmented_display virtually extended_display_size virtually extended_displays
249,Metaverse -An overview of daily usage and risks,"Yaqob, M., & Hafez, M. M. (2023). Metaverse -An overview of daily usage and risks. 2022 OPJU International Technology Conference on Emerging Technologies for Sustainable Development (OTCON). https://doi.org/10.1109/otcon56053.2023.10113922
",10.1109/OTCON56053.2023.10113922,"Metaverse is a new technology that is in rapid development. The new technology is a digital revolution that integrates into every facet of our physical existence. The term ""metaverse"" was coined to fit this revolutionary vision. Social networks, video conferencing, 3D virtual worlds (such as virtual reality chat), augmented reality applications (such as Poke&#769;mon Go), and artificial avatars are just a few examples of computer-mediated virtual environments (such as Upland). Metaverse is composed of two words: Meta: is a Greek prefix that means ""after"" or ""beyond"" and Universe. In other words, the Metaverse is a post-reality world, a multiuser environment that integrates actual reality with digital virtuality and describes a possible synthetic ecosystem with physical linkages. This research study provides an overview of the Metaverse's daily usage, risks, and practical uses. Finally, you will see some provided case studies as suggested improvements that can enhance the Metaverse experience, to make it even more practical.",C6130V Virtual reality;C7210N Information networks;C7830D Computer games,3D virtual worlds;actual reality;artificial avatars;augmented reality applications;computer-mediated virtual environments;digital revolution;digital virtuality;Metaverse -An;Metaverse experience;Metaverse's daily usage;multiuser environment;physical existence;physical linkages;post-reality world;revolutionary vision;social networks;video conferencing;virtual reality chat,augmented reality;avatars;computer games;human computer interaction;social networking (online);teleconferencing;virtual reality,2023,Conference article (CA),2022 OPJU International Technology Conference on Emerging Technologies for Sustainable Development (OTCON),"(1) Yaqob, M.; (1) Hafez, M.M.; ","(1) Arab Academy for Science Technology and Maritime Transport, Department of Software Engineering, Egypt; ",IEEE,-1,"[""avatars"", ""computer games"", ""human computer interaction"", ""social networking"", ""teleconferencing""]","[""avatars"", ""computer games"", ""human computer interaction"", ""social networking"", ""teleconferencing""]",avatars;computer games;human computer interaction;social networking;teleconferencing,liberal arts;presence;human-computer interaction;collaboration,industries;use cases;end users and user experience,liberal arts;presence;human-computer interaction;collaboration,industries;use cases;end users and user experience,avatars computer_games human_computer_interaction social_networking teleconferencing 3d_virtual_worlds actual_reality artificial_avatars augmented_reality_applications computer mediated_virtual_environments digital_revolution digital_virtuality metaverse_ an metaverse_experience metaverse s_daily_usage multiuser_environment physical_existence physical_linkages post reality_world revolutionary_vision social_networks video_conferencing virtual_reality_chat c6130v_virtual_reality c7210n_information_networks c7830d_computer_games liberal_arts presence human computer_interaction collaboration,avatars computer_games human_computer_interaction social_networking teleconferencing,3d_virtual_worlds actual_reality artificial_avatars augmented_reality_applications computer mediated_virtual_environments digital_revolution digital_virtuality metaverse_ an metaverse_experience metaverse s_daily_usage multiuser_environment physical_existence physical_linkages post reality_world revolutionary_vision social_networks video_conferencing virtual_reality_chat,metaverse new technology rapid development new technology digital revolution integrates every facet physical existence term metaverse coined fit revolutionary vision social network video conferencing 3d virtual world virtual reality chat augmented reality application poke 769 mon go artificial avatar example computer mediated virtual environment upland metaverse composed two word meta greek prefix mean beyond universe word metaverse post reality world multiuser environment integrates actual reality digital virtuality describes possible synthetic ecosystem physical linkage research study provides overview metaverse daily usage risk practical us finally see provided case study suggested improvement enhance metaverse experience make even practical,avatars computer_games human_computer_interaction social_networking teleconferencing 3d_virtual_worlds actual_reality artificial_avatars augmented_reality_applications computer mediated_virtual_environments digital_revolution digital_virtuality metaverse_ an metaverse_experience metaverse s_daily_usage multiuser_environment physical_existence physical_linkages post reality_world revolutionary_vision social_networks video_conferencing virtual_reality_chat c6130v_virtual_reality c7210n_information_networks c7830d_computer_games liberal_arts presence human computer_interaction collaboration metaverse new technology rapid development new technology digital revolution integrates every facet physical existence term metaverse coined fit revolutionary vision social network video conferencing 3d virtual world virtual reality chat augmented reality application poke 769 mon go artificial avatar example computer mediated virtual environment upland metaverse composed two word meta greek prefix mean beyond universe word metaverse post reality world multiuser environment integrates actual reality digital virtuality describes possible synthetic ecosystem physical linkage research study provides overview metaverse daily usage risk practical us finally see provided case study suggested improvement enhance metaverse experience make even practical,metaverse new technology rapid development new technology digital revolution integrates every facet physical existence term metaverse coined fit revolutionary vision social network video conferencing 3d virtual world virtual reality chat augmented reality application poke 769 mon go artificial avatar example computer mediated virtual environment upland metaverse composed two word meta greek prefix mean beyond universe word metaverse post reality world multiuser environment integrates actual reality digital virtuality describes possible synthetic ecosystem physical linkage research study provides overview metaverse daily usage risk practical us finally see provided case study suggested improvement enhance metaverse experience make even practicalavatars computer_games human_computer_interaction social_networking teleconferencing3d_virtual_worlds actual_reality artificial_avatars augmented_reality_applications computer mediated_virtual_environments digital_revolution digital_virtuality metaverse_ an metaverse_experience metaverse s_daily_usage multiuser_environment physical_existence physical_linkages post reality_world revolutionary_vision social_networks video_conferencing virtual_reality_chat
250,"Gaze &amp; Tongue: A Subtle, Hands-Free Interaction for Head-Worn Devices","Gemicioglu, T., Winters, R. M., Wang, Y.-T., Gable, T. M., Paradiso, A., & Tashev, I. J. (2023). Gaze &amp; Tongue: A Subtle, Hands-Free Interaction for Head-Worn Devices. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583930
",10.1145/3544549.3583930,"Gaze tracking allows hands-free and voice-free interaction with computers, and has gained more use recently in virtual and augmented reality headsets. However, it traditionally uses dwell time for selection tasks, which suffers from the Midas Touch problem. Tongue gestures are subtle, accessible and can be sensed non-intrusively using an IMU at the back of the ear, PPG and EEG. We demonstrate a novel interaction method combining gaze tracking with tongue gestures for gaze-based selection faster than dwell time and multiple selection options. We showcase its usage as a point-and-click interface in three hands-free games and a musical instrument.",A8770F Electrodiagnostics and other electrical measurement techniques;A8730C Electrical activity in neurophysiological processes;B7510D Bioelectric signals;C5260 Digital signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing,augmented reality headsets;gaze &amp; tongue;gaze tracking;gaze-based selection;hands-free games;head-worn devices;Midas Touch problem;multiple selection options;novel interaction method;selection tasks;subtle hands-free interaction;tongue gestures;virtual reality headsets;voice-free interaction,augmented reality;electroencephalography;gaze tracking;gesture recognition;human computer interaction;medical signal processing;musical instruments;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Gemicioglu, T.; (2) Winters, R.M.; (2) Wang, Y.-T.; (3) Gable, T.M.; (4) Paradiso, A.; (2) Tashev, I.J.; ","(1) Georgia Institute of Technology, United States and Microsoft Research, Atlanta, GA, United States; (2) Microsoft Research, Redmond, WA, United States; (3) Microsoft, United States; (4) Microsoft Research, Enable Group, Redmond, WA, United States; ",ACM,-1,"[""electroencephalography"", ""gaze tracking"", ""gesture recognition"", ""human computer interaction"", ""medical signal processing"", ""musical instruments""]","[""electroencephalography"", ""gaze tracking"", ""gesture recognition"", ""human computer interaction"", ""medical signal processing"", ""musical instruments""]",electroencephalography;gaze tracking;gesture recognition;human computer interaction;medical signal processing;musical instruments,computer vision;input;medical;sensors;human factors;data;human-computer interaction;audio,technology;industries;end users and user experience,computer vision;input;medical;sensors;human factors;data;human-computer interaction;audio,technology;industries;end users and user experience,electroencephalography gaze_tracking gesture_recognition human_computer_interaction medical_signal_processing musical_instruments augmented_reality_headsets gaze_ amp _tongue gaze_tracking gaze based_selection hands free_games head worn_devices midas_touch_problem multiple_selection_options novel_interaction_method selection_tasks subtle_hands free_interaction tongue_gestures virtual_reality_headsets voice free_interaction a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8730c_electrical_activity_in_neurophysiological_processes b7510d_bioelectric_signals c5260_digital_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing computer_vision input medical sensors human_factors data human computer_interaction audio,electroencephalography gaze_tracking gesture_recognition human_computer_interaction medical_signal_processing musical_instruments,augmented_reality_headsets gaze_ amp _tongue gaze_tracking gaze based_selection hands free_games head worn_devices midas_touch_problem multiple_selection_options novel_interaction_method selection_tasks subtle_hands free_interaction tongue_gestures virtual_reality_headsets voice free_interaction,gaze tracking allows hand free voice free interaction computer gained use recently virtual augmented reality headset however traditionally us dwell time selection task suffers midas touch problem tongue gesture subtle accessible sensed non intrusively using imu back ear ppg eeg demonstrate novel interaction method combining gaze tracking tongue gesture gaze based selection faster dwell time multiple selection option showcase usage point click interface three hand free game musical instrument,electroencephalography gaze_tracking gesture_recognition human_computer_interaction medical_signal_processing musical_instruments augmented_reality_headsets gaze_ amp _tongue gaze_tracking gaze based_selection hands free_games head worn_devices midas_touch_problem multiple_selection_options novel_interaction_method selection_tasks subtle_hands free_interaction tongue_gestures virtual_reality_headsets voice free_interaction a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8730c_electrical_activity_in_neurophysiological_processes b7510d_bioelectric_signals c5260_digital_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing computer_vision input medical sensors human_factors data human computer_interaction audio gaze tracking allows hand free voice free interaction computer gained use recently virtual augmented reality headset however traditionally us dwell time selection task suffers midas touch problem tongue gesture subtle accessible sensed non intrusively using imu back ear ppg eeg demonstrate novel interaction method combining gaze tracking tongue gesture gaze based selection faster dwell time multiple selection option showcase usage point click interface three hand free game musical instrument,gaze tracking allows hand free voice free interaction computer gained use recently virtual augmented reality headset however traditionally us dwell time selection task suffers midas touch problem tongue gesture subtle accessible sensed non intrusively using imu back ear ppg eeg demonstrate novel interaction method combining gaze tracking tongue gesture gaze based selection faster dwell time multiple selection option showcase usage point click interface three hand free game musical instrumentelectroencephalography gaze_tracking gesture_recognition human_computer_interaction medical_signal_processing musical_instrumentsaugmented_reality_headsets gaze_ amp _tongue gaze_tracking gaze based_selection hands free_games head worn_devices midas_touch_problem multiple_selection_options novel_interaction_method selection_tasks subtle_hands free_interaction tongue_gestures virtual_reality_headsets voice free_interaction
251,AI for Immersive Metaverse Experience,"Dubey, A., Bhardwaj, N., Upadhyay, A., & Ramnani, R. (2023). AI for Immersive Metaverse Experience. Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD). https://doi.org/10.1145/3570991.3571045
",10.1145/3570991.3571045,"Metaverse has received a huge attention in recent times with several Big Techs having invested in this concept. Accenture defines the metaverse as ""an evolution of the Internet that enables a user to move beyond 'browsing' to 'inhabiting' in a persistent, shared experience that spans the spectrum of our real world to the fully virtual and in between"". The evolution that Metaverse brings can be seen along three dimensions: 1) shift towards spatial experiences: which includes 2D, 3D, augmented, virtual, and mixed reality immersive experiences, 2) shared co-presence: where users experience a persistent shared space with a sense of co-presence with others, and 3) trusted identities and transactions to address challenges of fake identities, products, and transactions as present in today's internet. For example, a retail marketplace, on Metaverse could be seen as an immersive spatial experience where users can shop along with their families and friends who join virtually in the same environment. The sense of shared co-presence gives them the ability to discuss about products in real time and persistency gives them ability to come back to the same space. This evolution opens an enormous opportunity to rethink the digital experiences future applications would offer to the people. AI would be the core engine behind making these experiences richer, immersive, and engaging. The role of AI, in the Metaverse, is broad; however, in this tutorial, we will focus on two areas where AI will play a major role in shaping up the form and function of the Metaverse by: 1) bringing more realism in Metaverse with high fidelity immersive content generated through AI techniques and 2) enhancing user interactions by bringing more intelligence in the interaction modes.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C6210 Knowledge based systems;C7210N Information networks,2D immersive experience;3D immersive experience;AI;augmented reality immersive experience;digital experiences future applications;immersive metaverse experience;immersive spatial experience;Internet;mixed reality immersive experiences;persistent shared experience;persistent shared space;shared co-presence;user interactions;virtual reality immersive experience,artificial intelligence;augmented reality;Internet;user experience,2023,Conference article (CA),CODS-COMAD '23: Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD),"(1) Dubey, A.; (1) Bhardwaj, N.; (1) Upadhyay, A.; (1) Ramnani, R.; ","(1) Accenture, Accenture Labs, India; ",ACM,-1,"[""artificial intelligence"", ""internet"", ""user experience""]","[""artificial intelligence"", ""internet"", ""user experience""]",artificial intelligence;internet;user experience,human factors;artificial intelligence;liberal arts;networks,technology;industries;end users and user experience,human factors;artificial intelligence;liberal arts;networks,technology;industries;end users and user experience,artificial_intelligence internet user_experience 2d_immersive_experience 3d_immersive_experience ai augmented_reality_immersive_experience digital_experiences_future_applications immersive_metaverse_experience immersive_spatial_experience internet mixed_reality_immersive_experiences persistent_shared_experience persistent_shared_space shared_co presence user_interactions virtual_reality_immersive_experience c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6210_knowledge_based_systems c7210n_information_networks human_factors artificial_intelligence liberal_arts networks,artificial_intelligence internet user_experience,2d_immersive_experience 3d_immersive_experience ai augmented_reality_immersive_experience digital_experiences_future_applications immersive_metaverse_experience immersive_spatial_experience internet mixed_reality_immersive_experiences persistent_shared_experience persistent_shared_space shared_co presence user_interactions virtual_reality_immersive_experience,metaverse received huge attention recent time several big tech invested concept accenture defines metaverse evolution internet enables user move beyond browsing inhabiting persistent shared experience span spectrum real world fully virtual evolution metaverse brings seen along three dimension 1 shift towards spatial experience includes 2d 3d augmented virtual mixed reality immersive experience 2 shared co presence user experience persistent shared space sense co presence others 3 trusted identity transaction address challenge fake identity product transaction present today internet example retail marketplace metaverse could seen immersive spatial experience user shop along family friend join virtually environment sense shared co presence give ability discus product real time persistency give ability come back space evolution open enormous opportunity rethink digital experience future application would offer people ai would core engine behind making experience richer immersive engaging role ai metaverse broad however tutorial focus two area ai play major role shaping form function metaverse 1 bringing realism metaverse high fidelity immersive content generated ai technique 2 enhancing user interaction bringing intelligence interaction mode,artificial_intelligence internet user_experience 2d_immersive_experience 3d_immersive_experience ai augmented_reality_immersive_experience digital_experiences_future_applications immersive_metaverse_experience immersive_spatial_experience internet mixed_reality_immersive_experiences persistent_shared_experience persistent_shared_space shared_co presence user_interactions virtual_reality_immersive_experience c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c6210_knowledge_based_systems c7210n_information_networks human_factors artificial_intelligence liberal_arts networks metaverse received huge attention recent time several big tech invested concept accenture defines metaverse evolution internet enables user move beyond browsing inhabiting persistent shared experience span spectrum real world fully virtual evolution metaverse brings seen along three dimension 1 shift towards spatial experience includes 2d 3d augmented virtual mixed reality immersive experience 2 shared co presence user experience persistent shared space sense co presence others 3 trusted identity transaction address challenge fake identity product transaction present today internet example retail marketplace metaverse could seen immersive spatial experience user shop along family friend join virtually environment sense shared co presence give ability discus product real time persistency give ability come back space evolution open enormous opportunity rethink digital experience future application would offer people ai would core engine behind making experience richer immersive engaging role ai metaverse broad however tutorial focus two area ai play major role shaping form function metaverse 1 bringing realism metaverse high fidelity immersive content generated ai technique 2 enhancing user interaction bringing intelligence interaction mode,metaverse received huge attention recent time several big tech invested concept accenture defines metaverse evolution internet enables user move beyond browsing inhabiting persistent shared experience span spectrum real world fully virtual evolution metaverse brings seen along three dimension 1 shift towards spatial experience includes 2d 3d augmented virtual mixed reality immersive experience 2 shared co presence user experience persistent shared space sense co presence others 3 trusted identity transaction address challenge fake identity product transaction present today internet example retail marketplace metaverse could seen immersive spatial experience user shop along family friend join virtually environment sense shared co presence give ability discus product real time persistency give ability come back space evolution open enormous opportunity rethink digital experience future application would offer people ai would core engine behind making experience richer immersive engaging role ai metaverse broad however tutorial focus two area ai play major role shaping form function metaverse 1 bringing realism metaverse high fidelity immersive content generated ai technique 2 enhancing user interaction bringing intelligence interaction modeartificial_intelligence internet user_experience2d_immersive_experience 3d_immersive_experience ai augmented_reality_immersive_experience digital_experiences_future_applications immersive_metaverse_experience immersive_spatial_experience internet mixed_reality_immersive_experiences persistent_shared_experience persistent_shared_space shared_co presence user_interactions virtual_reality_immersive_experience
252,AR in the Architecture Domain: State of the Art,"Russo, M. (2021). AR in the Architecture Domain: State of the Art. Applied Sciences, 11(15), 6800. https://doi.org/10.3390/app11156800
",10.3390/app11156800,"Augmented reality (AR) allows the real and digital worlds to converge and overlap in a new way of observation and understanding. The architectural field can significantly benefit from AR applications, due to their systemic complexity in terms of knowledge and process management. Global interest and many research challenges are focused on this field, thanks to the conjunction of technological and algorithmic developments from one side, and the massive digitization of built data. A significant quantity of research in the AEC and educational fields describes this state of the art. Moreover, it is a very fragmented domain, in which specific advances or case studies are often described without considering the complexity of the whole development process. The article illustrates the entire AR pipeline development in architecture, from the conceptual phase to its application, highlighting each step's specific aspects. This storytelling aims to provide a general overview to a non-expert, deepening the topic and stimulating a democratization process. The aware and extended use of AR in multiple areas of application can lead a new way forward for environmental understanding, bridging the gap between real and virtual space in an innovative perception of architecture.",C7100 Business and administrative computing;C6110B Software engineering techniques;C6130V Virtual reality,algorithmic developments;AR applications;AR pipeline development;architectural field;architecture domain;augmented reality;built data;conceptual phase;democratization process;digital worlds;educational fields;environmental understanding;fragmented domain;global interest;knowledge management;massive digitization;nonexpert;process management;real worlds;systemic complexity;technological developments,augmented reality;knowledge management;software architecture,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Russo, M.; ","(1) Sapienza University of Rome, Department of History, 7/a, Italy; ",MDPI,-1,"[""knowledge management"", ""software architecture""]","[""knowledge management"", ""software architecture""]",knowledge management;software architecture,construction;developers;human resources,technology;business;industries,construction;developers;human resources,technology;business;industries,knowledge_management software_architecture algorithmic_developments ar_applications ar_pipeline_development architectural_field architecture_domain augmented_reality built_data conceptual_phase democratization_process digital_worlds educational_fields environmental_understanding fragmented_domain global_interest knowledge_management massive_digitization nonexpert process_management real_worlds systemic_complexity technological_developments c7100_business_and_administrative_computing c6110b_software_engineering_techniques c6130v_virtual_reality construction developers human_resources,knowledge_management software_architecture,algorithmic_developments ar_applications ar_pipeline_development architectural_field architecture_domain augmented_reality built_data conceptual_phase democratization_process digital_worlds educational_fields environmental_understanding fragmented_domain global_interest knowledge_management massive_digitization nonexpert process_management real_worlds systemic_complexity technological_developments,augmented reality ar allows real digital world converge overlap new way observation understanding architectural field significantly benefit ar application due systemic complexity term knowledge process management global interest many research challenge focused field thanks conjunction technological algorithmic development one side massive digitization built data significant quantity research aec educational field describes state art moreover fragmented domain specific advance case study often described without considering complexity whole development process article illustrates entire ar pipeline development architecture conceptual phase application highlighting step specific aspect storytelling aim provide general overview non expert deepening topic stimulating democratization process aware extended use ar multiple area application lead new way forward environmental understanding bridging gap real virtual space innovative perception architecture,knowledge_management software_architecture algorithmic_developments ar_applications ar_pipeline_development architectural_field architecture_domain augmented_reality built_data conceptual_phase democratization_process digital_worlds educational_fields environmental_understanding fragmented_domain global_interest knowledge_management massive_digitization nonexpert process_management real_worlds systemic_complexity technological_developments c7100_business_and_administrative_computing c6110b_software_engineering_techniques c6130v_virtual_reality construction developers human_resources augmented reality ar allows real digital world converge overlap new way observation understanding architectural field significantly benefit ar application due systemic complexity term knowledge process management global interest many research challenge focused field thanks conjunction technological algorithmic development one side massive digitization built data significant quantity research aec educational field describes state art moreover fragmented domain specific advance case study often described without considering complexity whole development process article illustrates entire ar pipeline development architecture conceptual phase application highlighting step specific aspect storytelling aim provide general overview non expert deepening topic stimulating democratization process aware extended use ar multiple area application lead new way forward environmental understanding bridging gap real virtual space innovative perception architecture,augmented reality ar allows real digital world converge overlap new way observation understanding architectural field significantly benefit ar application due systemic complexity term knowledge process management global interest many research challenge focused field thanks conjunction technological algorithmic development one side massive digitization built data significant quantity research aec educational field describes state art moreover fragmented domain specific advance case study often described without considering complexity whole development process article illustrates entire ar pipeline development architecture conceptual phase application highlighting step specific aspect storytelling aim provide general overview non expert deepening topic stimulating democratization process aware extended use ar multiple area application lead new way forward environmental understanding bridging gap real virtual space innovative perception architectureknowledge_management software_architecturealgorithmic_developments ar_applications ar_pipeline_development architectural_field architecture_domain augmented_reality built_data conceptual_phase democratization_process digital_worlds educational_fields environmental_understanding fragmented_domain global_interest knowledge_management massive_digitization nonexpert process_management real_worlds systemic_complexity technological_developments
253,Using Physiological Signals and Machine Learning Algorithms to Measure Attentiveness During Robot-Assisted Social Skills Intervention: A Case Study of Two Children with Autism Spectrum Disorder,"Welch, K. C., Pennington, R., Vanaparthy, S., Do, H. M., Narayanan, R., Popa, D., Barnes, G., & Kuravackel, G. (2023). Using Physiological Signals and Machine Learning Algorithms to Measure Attentiveness During Robot-Assisted Social Skills Intervention: A Case Study of Two Children with Autism Spectrum Disorder. IEEE Instrumentation &amp; Measurement Magazine, 26(3), 39–45. https://doi.org/10.1109/mim.2023.10121412
",10.1109/MIM.2023.10121412,"Individuals with autism spectrum disorder (ASD) often face barriers in accessing opportunities across a range of educational, employment, and social contexts. One of these barriers is the development of effective communication skills sufficient for navigating the social demands of everyday environments. Fortunately, researchers have established evidence-based practices (EBP) for teaching critical communication skills to individuals with ASD [1]. One EBP that has received a great deal of attention over the last few decades is technology-aided instruction and intervention (TAII) [1], [2]. TAII is an instructional practice in which technology is an essential component and is used to facilitate behavior change. Further, it encompasses a wide range of applications including computer-assisted instruction, virtual and augmented reality, augmentative and alternative communication, and robot-assisted intervention [2].",A8770 Biomedical engineering;B6140 Signal processing and detection;B7510D Bioelectric signals;C3390 Robotics;C5260 Digital signal processing;C6130V Virtual reality;C6260 Machine learning (artificial intelligence);C7330 Biology and medical computing;C7810C Computer-aided instruction,alternative communication;ASD;augmentative communication;augmented reality;autism spectrum disorder;critical communication skills;EBP;educational employment;evidence-based practices;instructional practice;machine learning algorithms;physiological signals;robot-assisted intervention;robot-assisted social skills intervention;social contexts;social demands;technology-aided instruction;technology-aided instruction and intervention,augmented reality;computer aided instruction;learning (artificial intelligence);medical disorders;medical robotics;medical signal processing;teaching,2023,Journal article (JA),IEEE Instrum. Meas. Mag. (USA),"(None) Welch, K.C.; (None) Pennington, R.; (None) Vanaparthy, S.; (None) Do, H.M.; (None) Narayanan, R.; (None) Popa, D.; (None) Barnes, G.; (None) Kuravackel, G.; ",,IEEE,-1,"[""computer aided instruction"", ""learning algorithms"", ""medical disorders"", ""medical robotics"", ""medical signal processing"", ""teaching""]","[""computer aided instruction"", ""learning algorithms"", ""medical disorders"", ""medical robotics"", ""medical signal processing"", ""teaching""]",computer aided instruction;learning algorithms;medical disorders;medical robotics;medical signal processing;teaching,education;robotics;medical;sensors;training;data;artificial intelligence,technology;use cases;industries,education;robotics;medical;sensors;training;data;artificial intelligence,technology;use cases;industries,computer_aided_instruction learning_algorithms medical_disorders medical_robotics medical_signal_processing teaching alternative_communication asd augmentative_communication augmented_reality autism_spectrum_disorder critical_communication_skills ebp educational_employment evidence based_practices instructional_practice machine_learning_algorithms physiological_signals robot assisted_intervention robot assisted_social_skills_intervention social_contexts social_demands technology aided_instruction technology aided_instruction_and_intervention a8770_biomedical_engineering b6140_signal_processing_and_detection b7510d_bioelectric_signals c3390_robotics c5260_digital_signal_processing c6130v_virtual_reality c6260_machine_learning_ artificial_intelligence c7330_biology_and_medical_computing c7810c_computer aided_instruction education robotics medical sensors training data artificial_intelligence,computer_aided_instruction learning_algorithms medical_disorders medical_robotics medical_signal_processing teaching,alternative_communication asd augmentative_communication augmented_reality autism_spectrum_disorder critical_communication_skills ebp educational_employment evidence based_practices instructional_practice machine_learning_algorithms physiological_signals robot assisted_intervention robot assisted_social_skills_intervention social_contexts social_demands technology aided_instruction technology aided_instruction_and_intervention,individual autism spectrum disorder asd often face barrier accessing opportunity across range educational employment social context one barrier development effective communication skill sufficient navigating social demand everyday environment fortunately researcher established evidence based practice ebp teaching critical communication skill individual asd 1 one ebp received great deal attention last decade technology aided instruction intervention taii 1 2 taii instructional practice technology essential component used facilitate behavior change encompasses wide range application including computer assisted instruction virtual augmented reality augmentative alternative communication robot assisted intervention 2,computer_aided_instruction learning_algorithms medical_disorders medical_robotics medical_signal_processing teaching alternative_communication asd augmentative_communication augmented_reality autism_spectrum_disorder critical_communication_skills ebp educational_employment evidence based_practices instructional_practice machine_learning_algorithms physiological_signals robot assisted_intervention robot assisted_social_skills_intervention social_contexts social_demands technology aided_instruction technology aided_instruction_and_intervention a8770_biomedical_engineering b6140_signal_processing_and_detection b7510d_bioelectric_signals c3390_robotics c5260_digital_signal_processing c6130v_virtual_reality c6260_machine_learning_ artificial_intelligence c7330_biology_and_medical_computing c7810c_computer aided_instruction education robotics medical sensors training data artificial_intelligence individual autism spectrum disorder asd often face barrier accessing opportunity across range educational employment social context one barrier development effective communication skill sufficient navigating social demand everyday environment fortunately researcher established evidence based practice ebp teaching critical communication skill individual asd 1 one ebp received great deal attention last decade technology aided instruction intervention taii 1 2 taii instructional practice technology essential component used facilitate behavior change encompasses wide range application including computer assisted instruction virtual augmented reality augmentative alternative communication robot assisted intervention 2,individual autism spectrum disorder asd often face barrier accessing opportunity across range educational employment social context one barrier development effective communication skill sufficient navigating social demand everyday environment fortunately researcher established evidence based practice ebp teaching critical communication skill individual asd 1 one ebp received great deal attention last decade technology aided instruction intervention taii 1 2 taii instructional practice technology essential component used facilitate behavior change encompasses wide range application including computer assisted instruction virtual augmented reality augmentative alternative communication robot assisted intervention 2computer_aided_instruction learning_algorithms medical_disorders medical_robotics medical_signal_processing teachingalternative_communication asd augmentative_communication augmented_reality autism_spectrum_disorder critical_communication_skills ebp educational_employment evidence based_practices instructional_practice machine_learning_algorithms physiological_signals robot assisted_intervention robot assisted_social_skills_intervention social_contexts social_demands technology aided_instruction technology aided_instruction_and_intervention
254,Developing Cargo Loading Software for Navy and Marine Aircraft,"Ludwig, J., Presnell, B., & Tuohy, D. (2023). Developing Cargo Loading Software for Navy and Marine Aircraft. 2023 IEEE Aerospace Conference. https://doi.org/10.1109/aero55745.2023.10115709
",10.1109/AERO55745.2023.10115709,"Managing cargo loading for U.S. Navy and Marine Corps aircraft is a challenging task, requiring an understanding of elements such as aircraft limitations, aircraft center of gravity, cargo space dimensions, and tie-down procedures to name a few. These loading requirements are specified in each aircraft's lengthy Cargo Loading Guide (CLG). To address the problem of efficiently and effectively stowing cargo, the U.S. Navy has proposed the development of an Android app that assists aircrew in completing their loadmaster duties. This paper describes the Aircraft Cargo Evaluator app, which uses three specific capabilities to perform calculations and provide feedback to help achieve efficient and effective cargo loading. The first creates 3D models for novel cargo using Augmented Reality. The second allows the user to develop scenarios that include 3D models of aircraft, cargo, and tie-down patterns, and then analyzes the tie-downs according to CLG-defined rules. The third uses genetic algorithms to automatically search for and efficient and effective tie-down patterns for a scenario. The primary contribution of this work is summarizing how existing tools from augmented reality, computer games, and artificial intelligence were brought together to rapidly prototype an end-to-end solution in this challenging domain - and then following what happens as this research prototype takes the first steps towards the reality of operational use.","C7460 Aerospace engineering computing;C0240 Ergonomic aspects of computing;C1180 Optimisation techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C6210 Knowledge based systems;C7830D Computer games;E3650C Aerospace industry",aircraft cargo evaluator app;aircraft limitations;Android app;artificial intelligence;augmented reality;cargo loading guide;cargo loading software;CLG-defined rules;computer games;genetic algorithms;marine aircraft;marine corps aircraft;tie-down patterns;U.S. Navy,aerospace computing;aircraft;Android (operating system);artificial intelligence;augmented reality;computer games;freight handling;genetic algorithms;human factors;military aircraft;mobile computing,2023,Conference article (CA),2023 IEEE Aerospace Conference,"(1) Ludwig, J.; (1) Presnell, B.; (1) Tuohy, D.; ","(1) Stottler Henke Associates, Inc., San Mateo, CA 94402, United States; ",IEEE,-1,"[""aerospace computing"", ""aircraft"", ""android"", ""artificial intelligence"", ""computer games"", ""freight handling"", ""genetic algorithms"", ""human factors"", ""military aircraft"", ""mobile computing""]","[""aerospace computing"", ""aircraft"", ""android"", ""artificial intelligence"", ""computer games"", ""freight handling"", ""genetic algorithms"", ""human factors"", ""military aircraft"", ""mobile computing""]",aerospace computing;aircraft;android;artificial intelligence;computer games;freight handling;genetic algorithms;human factors;military aircraft;mobile computing,other;aviation and aerospace;liberal arts;government;human factors;telecommunication;developers;human-computer interaction;artificial intelligence,technology;other;end users and user experience;industries,other;aviation and aerospace;liberal arts;government;human factors;telecommunication;developers;human-computer interaction;artificial intelligence,technology;other;end users and user experience;industries,aerospace_computing aircraft android artificial_intelligence computer_games freight_handling genetic_algorithms human_factors military_aircraft mobile_computing aircraft_cargo_evaluator_app aircraft_limitations android_app artificial_intelligence augmented_reality cargo_loading_guide cargo_loading_software clg defined_rules computer_games genetic_algorithms marine_aircraft marine_corps_aircraft tie down_patterns u s _navy c7460_aerospace_engineering_computing c0240_ergonomic_aspects_of_computing c1180_optimisation_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6210_knowledge_based_systems c7830d_computer_games e3650c_aerospace_industry other aviation_and_aerospace liberal_arts government human_factors telecommunication developers human computer_interaction artificial_intelligence,aerospace_computing aircraft android artificial_intelligence computer_games freight_handling genetic_algorithms human_factors military_aircraft mobile_computing,aircraft_cargo_evaluator_app aircraft_limitations android_app artificial_intelligence augmented_reality cargo_loading_guide cargo_loading_software clg defined_rules computer_games genetic_algorithms marine_aircraft marine_corps_aircraft tie down_patterns u s _navy,managing cargo loading u navy marine corp aircraft challenging task requiring understanding element aircraft limitation aircraft center gravity cargo space dimension tie procedure name loading requirement specified aircraft lengthy cargo loading guide clg address problem efficiently effectively stowing cargo u navy proposed development android app assist aircrew completing loadmaster duty paper describes aircraft cargo evaluator app us three specific capability perform calculation provide feedback help achieve efficient effective cargo loading first creates 3d model novel cargo using augmented reality second allows user develop scenario include 3d model aircraft cargo tie pattern analyzes tie down according clg defined rule third us genetic algorithm automatically search efficient effective tie pattern scenario primary contribution work summarizing existing tool augmented reality computer game artificial intelligence brought together rapidly prototype end end solution challenging domain following happens research prototype take first step towards reality operational use,aerospace_computing aircraft android artificial_intelligence computer_games freight_handling genetic_algorithms human_factors military_aircraft mobile_computing aircraft_cargo_evaluator_app aircraft_limitations android_app artificial_intelligence augmented_reality cargo_loading_guide cargo_loading_software clg defined_rules computer_games genetic_algorithms marine_aircraft marine_corps_aircraft tie down_patterns u s _navy c7460_aerospace_engineering_computing c0240_ergonomic_aspects_of_computing c1180_optimisation_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6210_knowledge_based_systems c7830d_computer_games e3650c_aerospace_industry other aviation_and_aerospace liberal_arts government human_factors telecommunication developers human computer_interaction artificial_intelligence managing cargo loading u navy marine corp aircraft challenging task requiring understanding element aircraft limitation aircraft center gravity cargo space dimension tie procedure name loading requirement specified aircraft lengthy cargo loading guide clg address problem efficiently effectively stowing cargo u navy proposed development android app assist aircrew completing loadmaster duty paper describes aircraft cargo evaluator app us three specific capability perform calculation provide feedback help achieve efficient effective cargo loading first creates 3d model novel cargo using augmented reality second allows user develop scenario include 3d model aircraft cargo tie pattern analyzes tie down according clg defined rule third us genetic algorithm automatically search efficient effective tie pattern scenario primary contribution work summarizing existing tool augmented reality computer game artificial intelligence brought together rapidly prototype end end solution challenging domain following happens research prototype take first step towards reality operational use,managing cargo loading u navy marine corp aircraft challenging task requiring understanding element aircraft limitation aircraft center gravity cargo space dimension tie procedure name loading requirement specified aircraft lengthy cargo loading guide clg address problem efficiently effectively stowing cargo u navy proposed development android app assist aircrew completing loadmaster duty paper describes aircraft cargo evaluator app us three specific capability perform calculation provide feedback help achieve efficient effective cargo loading first creates 3d model novel cargo using augmented reality second allows user develop scenario include 3d model aircraft cargo tie pattern analyzes tie down according clg defined rule third us genetic algorithm automatically search efficient effective tie pattern scenario primary contribution work summarizing existing tool augmented reality computer game artificial intelligence brought together rapidly prototype end end solution challenging domain following happens research prototype take first step towards reality operational useaerospace_computing aircraft android artificial_intelligence computer_games freight_handling genetic_algorithms human_factors military_aircraft mobile_computingaircraft_cargo_evaluator_app aircraft_limitations android_app artificial_intelligence augmented_reality cargo_loading_guide cargo_loading_software clg defined_rules computer_games genetic_algorithms marine_aircraft marine_corps_aircraft tie down_patterns u s _navy
255,Deep Convolutional Neural Networks applied to Hand Keypoints Estimation,"Santos, B. M., Pais, P., Ribeiro, F. M., Lima, J., Gonçalves, G., & Pinto, V. H. (2023). Deep Convolutional Neural Networks applied to Hand Keypoints Estimation. 2023 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC). https://doi.org/10.1109/icarsc58346.2023.10129621
",10.1109/ICARSC58346.2023.10129621,"Accurate estimation of hand shape and position is an important task in various applications, such as human-computer interaction, human-robot interaction, and virtual and augmented reality. In this paper, it is proposed a method to estimate the hand keypoints from single and colored images utilizing the pre-trained deep convolutional neural networks VGG-16 and VGG-19. The method is evaluated on the FreiHAND dataset, and the performance of the two neural networks is compared. The best results were achieved by the VGG-19, with average estimation errors of 7.40 pixels and 11.36 millimeters for the best cases of two-dimensional and three-dimensional hand keypoints estimation, respectively.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180R Human-robot interaction;C6264 Neural nets",augmented reality;average estimation errors;colored images;FreiHAND dataset;hand shape;human-computer interaction;human-robot interaction;pre-trained deep convolutional neural networks;single images;three-dimensional hand keypoints estimation;VGG-19;virtual reality,augmented reality;convolutional neural nets;deep learning (artificial intelligence);feature extraction;human-robot interaction;image classification;image colour analysis;pose estimation,2023,Conference article (CA),2023 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),"(1) Santos, B.M.; (2) Pais, P.; (1) Ribeiro, F.M.; (3) Lima, J.; (1) Goncalves, G.; (1) Pinto, V.H.; ","(1) Univ. do Porto, ARISE & ECE Department, Portugal; (2) University do Porto, ECE Department, Portugal; (3) Instituto Polite&#769;cnico de Braganca, Portugal; ",IEEE,-1,"[""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""human-robot interaction"", ""image classification"", ""image colour analysis"", ""pose estimation""]","[""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""human-robot interaction"", ""image classification"", ""image colour analysis"", ""pose estimation""]",convolutional neural nets;deep learning (artificial intelligence);feature extraction;human-robot interaction;image classification;image colour analysis;pose estimation,computer vision;other;graphics;robotics;liberal arts;medical;chemical;artificial intelligence;networks,technology;other;industries,computer vision;other;graphics;robotics;liberal arts;medical;chemical;artificial intelligence;networks,technology;other;industries,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction human robot_interaction image_classification image_colour_analysis pose_estimation augmented_reality average_estimation_errors colored_images freihand_dataset hand_shape human computer_interaction human robot_interaction pre trained_deep_convolutional_neural_networks single_images three dimensional_hand_keypoints_estimation vgg 19 virtual_reality b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180r_human robot_interaction c6264_neural_nets computer_vision other graphics robotics liberal_arts medical chemical artificial_intelligence networks,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction human robot_interaction image_classification image_colour_analysis pose_estimation,augmented_reality average_estimation_errors colored_images freihand_dataset hand_shape human computer_interaction human robot_interaction pre trained_deep_convolutional_neural_networks single_images three dimensional_hand_keypoints_estimation vgg 19 virtual_reality,accurate estimation hand shape position important task various application human computer interaction human robot interaction virtual augmented reality paper proposed method estimate hand keypoints single colored image utilizing pre trained deep convolutional neural network vgg 16 vgg 19 method evaluated freihand dataset performance two neural network compared best result achieved vgg 19 average estimation error 7 40 pixel 11 36 millimeter best case two dimensional three dimensional hand keypoints estimation respectively,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction human robot_interaction image_classification image_colour_analysis pose_estimation augmented_reality average_estimation_errors colored_images freihand_dataset hand_shape human computer_interaction human robot_interaction pre trained_deep_convolutional_neural_networks single_images three dimensional_hand_keypoints_estimation vgg 19 virtual_reality b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180r_human robot_interaction c6264_neural_nets computer_vision other graphics robotics liberal_arts medical chemical artificial_intelligence networks accurate estimation hand shape position important task various application human computer interaction human robot interaction virtual augmented reality paper proposed method estimate hand keypoints single colored image utilizing pre trained deep convolutional neural network vgg 16 vgg 19 method evaluated freihand dataset performance two neural network compared best result achieved vgg 19 average estimation error 7 40 pixel 11 36 millimeter best case two dimensional three dimensional hand keypoints estimation respectively,accurate estimation hand shape position important task various application human computer interaction human robot interaction virtual augmented reality paper proposed method estimate hand keypoints single colored image utilizing pre trained deep convolutional neural network vgg 16 vgg 19 method evaluated freihand dataset performance two neural network compared best result achieved vgg 19 average estimation error 7 40 pixel 11 36 millimeter best case two dimensional three dimensional hand keypoints estimation respectivelyconvolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction human robot_interaction image_classification image_colour_analysis pose_estimationaugmented_reality average_estimation_errors colored_images freihand_dataset hand_shape human computer_interaction human robot_interaction pre trained_deep_convolutional_neural_networks single_images three dimensional_hand_keypoints_estimation vgg 19 virtual_reality
256,Pensieve 5G: Implementation of RL-based ABR Algorithm for UHD 4K/8K Content Delivery on Commercial 5G SA/NR-DC Network,"Arunruangsirilert, K., Wei, B., Song, H., & Katto, J. (2023). Pensieve 5G: Implementation of RL-based ABR Algorithm for UHD 4K/8K Content Delivery on Commercial 5G SA/NR-DC Network. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118834
",10.1109/WCNC55385.2023.10118834,"While the rollout of the fifth-generation mobile network (5G) is underway across the globe with the intention to deliver 4K/8K UHD videos, Augmented Reality (AR), and Virtual Reality (VR) content to the mass amounts of users, the coverage and throughput are still one of the most significant issues, especially in the rural areas, where only 5G in the low-frequency band are being deployed. This called for a highperformance adaptive bitrate (ABR) algorithm that can maximize the user quality of experience given 5G network characteristics and data rate of UHD contents.Recently, many of the newly proposed ABR techniques were machine-learning based. Among that, Pensieve is one of the state-of-the-art techniques, which utilized reinforcement-learning to generate an ABR algorithm based on observation of past decision performance. By incorporating the context of the 5G network and UHD content, Pensieve has been optimized into Pensieve 5G. New QoE metrics that more accurately represent the QoE of UHD video streaming on the different types of devices were proposed and used to evaluate Pensieve 5G against other ABR techniques including the original Pensieve. The results from the simulation based on the real 5G Standalone (SA) network throughput shows that Pensieve 5G outperforms both conventional algorithms and Pensieve with the average QoE improvement of 8.8% and 14.2%, respectively. Additionally, Pensieve 5G also performed well on the commercial 5G NR-NR Dual Connectivity (NR-DC) Network, despite the training being done solely using the data from the 5G Standalone (SA) network.","B6250F Mobile radio systems;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C6263 Reinforcement learning",4K-8K UHD videos;5G NR-NR dual connectivity;5G SA-NR-DC network;5G standalone network;adaptive bitrate algorithm;AR;augmented reality;fifth-generation mobile network;machine-learning;QoE metrics;reinforcement-learning;RL-based ABR algorithm;UHD contents;video streaming;virtual reality;VR,5G mobile communication;augmented reality;mobile computing;quality of experience;reinforcement learning;video streaming,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Arunruangsirilert, K.; (1) Wei, B.; (2) Song, H.; (1) Katto, J.; ","(1) Waseda University, Department of Computer Science and Communications Engineering, Japan; (2) Tokyo Institute of Technology, Department of Transdisciplinary Science and Engineering, Japan; ",IEEE,-1,"[""5g mobile communication"", ""mobile computing"", ""quality of experience"", ""reinforcement learning"", ""video streaming""]","[""5g mobile communication"", ""mobile computing"", ""quality of experience"", ""reinforcement learning"", ""video streaming""]",5g mobile communication;mobile computing;quality of experience;reinforcement learning;video streaming,"input;medical;inspection, safety and quality;telecommunication;artificial intelligence;video",technology;use cases;industries,"input;medical;inspection, safety and quality;telecommunication;artificial intelligence;video",technology;use cases;industries,5g_mobile_communication mobile_computing quality_of_experience reinforcement_learning video_streaming 4k 8k_uhd_videos 5g_nr nr_dual_connectivity 5g_sa nr dc_network 5g_standalone_network adaptive_bitrate_algorithm ar augmented_reality fifth generation_mobile_network machine learning qoe_metrics reinforcement learning rl based_abr_algorithm uhd_contents video_streaming virtual_reality vr b6250f_mobile_radio_systems c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6263_reinforcement_learning input medical inspection _safety_and_quality telecommunication artificial_intelligence video,5g_mobile_communication mobile_computing quality_of_experience reinforcement_learning video_streaming,4k 8k_uhd_videos 5g_nr nr_dual_connectivity 5g_sa nr dc_network 5g_standalone_network adaptive_bitrate_algorithm ar augmented_reality fifth generation_mobile_network machine learning qoe_metrics reinforcement learning rl based_abr_algorithm uhd_contents video_streaming virtual_reality vr,rollout fifth generation mobile network 5g underway across globe intention deliver 4k 8k uhd video augmented reality ar virtual reality vr content mass amount user coverage throughput still one significant issue especially rural area 5g low frequency band deployed called highperformance adaptive bitrate abr algorithm maximize user quality experience given 5g network characteristic data rate uhd content recently many newly proposed abr technique machine learning based among pensieve one state art technique utilized reinforcement learning generate abr algorithm based observation past decision performance incorporating context 5g network uhd content pensieve optimized pensieve 5g new qoe metric accurately represent qoe uhd video streaming different type device proposed used evaluate pensieve 5g abr technique including original pensieve result simulation based real 5g standalone sa network throughput show pensieve 5g outperforms conventional algorithm pensieve average qoe improvement 8 8 14 2 respectively additionally pensieve 5g also performed well commercial 5g nr nr dual connectivity nr dc network despite training done solely using data 5g standalone sa network,5g_mobile_communication mobile_computing quality_of_experience reinforcement_learning video_streaming 4k 8k_uhd_videos 5g_nr nr_dual_connectivity 5g_sa nr dc_network 5g_standalone_network adaptive_bitrate_algorithm ar augmented_reality fifth generation_mobile_network machine learning qoe_metrics reinforcement learning rl based_abr_algorithm uhd_contents video_streaming virtual_reality vr b6250f_mobile_radio_systems c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6263_reinforcement_learning input medical inspection _safety_and_quality telecommunication artificial_intelligence video rollout fifth generation mobile network 5g underway across globe intention deliver 4k 8k uhd video augmented reality ar virtual reality vr content mass amount user coverage throughput still one significant issue especially rural area 5g low frequency band deployed called highperformance adaptive bitrate abr algorithm maximize user quality experience given 5g network characteristic data rate uhd content recently many newly proposed abr technique machine learning based among pensieve one state art technique utilized reinforcement learning generate abr algorithm based observation past decision performance incorporating context 5g network uhd content pensieve optimized pensieve 5g new qoe metric accurately represent qoe uhd video streaming different type device proposed used evaluate pensieve 5g abr technique including original pensieve result simulation based real 5g standalone sa network throughput show pensieve 5g outperforms conventional algorithm pensieve average qoe improvement 8 8 14 2 respectively additionally pensieve 5g also performed well commercial 5g nr nr dual connectivity nr dc network despite training done solely using data 5g standalone sa network,rollout fifth generation mobile network 5g underway across globe intention deliver 4k 8k uhd video augmented reality ar virtual reality vr content mass amount user coverage throughput still one significant issue especially rural area 5g low frequency band deployed called highperformance adaptive bitrate abr algorithm maximize user quality experience given 5g network characteristic data rate uhd content recently many newly proposed abr technique machine learning based among pensieve one state art technique utilized reinforcement learning generate abr algorithm based observation past decision performance incorporating context 5g network uhd content pensieve optimized pensieve 5g new qoe metric accurately represent qoe uhd video streaming different type device proposed used evaluate pensieve 5g abr technique including original pensieve result simulation based real 5g standalone sa network throughput show pensieve 5g outperforms conventional algorithm pensieve average qoe improvement 8 8 14 2 respectively additionally pensieve 5g also performed well commercial 5g nr nr dual connectivity nr dc network despite training done solely using data 5g standalone sa network5g_mobile_communication mobile_computing quality_of_experience reinforcement_learning video_streaming4k 8k_uhd_videos 5g_nr nr_dual_connectivity 5g_sa nr dc_network 5g_standalone_network adaptive_bitrate_algorithm ar augmented_reality fifth generation_mobile_network machine learning qoe_metrics reinforcement learning rl based_abr_algorithm uhd_contents video_streaming virtual_reality vr
257,Efficient resource allocation and scheduling mechanism of XR traffic,"Xin, J., Li, Y., Liu, T., Xing, Z., & Xu, S. (2023). Efficient resource allocation and scheduling mechanism of XR traffic. 2023 7th International Conference on Control Engineering and Artificial Intelligence. https://doi.org/10.1145/3580219.3580243
",10.1145/3580219.3580243,"EXtended reality (XR) has become one of the most important 5G and 5G-Advance media applications in the industry. Specifically, XR is a broad term covering augmented reality, mixed reality and virtual reality. Although XR traffic has some similar characteristics with URLLC traffic, there are also some differences, such as multiple periodic data streams, variable packets sizes and so on. Therefore, based on the analysis of XR-specific traffic, the paper aims to investigate efficient resource allocation and scheduling mechanism of XR traffic. For instance, with the configured grant (CG) transmission, the latency of uplink (UL) XR data flows can be reduced. In order to improve the reliability, K-repeated CG configuration can be considered. To help the gNB make efficient scheduling, the UE can also use the assistance information to indicate XR traffics' quality requirements and time-aligned transmission to gNB. After that, the paper analyses and evaluates the efficiency of the UL grants allocation method. It shows that with the assistance information, the gNB can make priority classification and efficient resource allocation, which can reduce resources by up to 81%.",B6250F Mobile radio systems;B0170N Reliability;C6130V Virtual reality;C6190P Parallel software;C7410F Communications computing,5G-Advance media applications;augmented reality;extended reality;K-repeated CG configuration;K-repeated configured grant transmission;mixed reality;resource allocation;scheduling mechanism;UL grants allocation method;uplink XR data flows;URLLC traffic;virtual reality;XR traffic,5G mobile communication;augmented reality;data flow computing;resource allocation;telecommunication computing;telecommunication network reliability;telecommunication scheduling;telecommunication traffic,2023,Conference article (CA),CCEAI'23: Proceedings of the 7th International Conference on Control Engineering and Artificial Intelligence,"(1) Xin, J.; (1) Li, Y.; (2) Liu, T.; (2) Xing, Z.; (1) Xu, S.; ","(1) China Telecom, China; (2) China Telecom (China), China; ",ACM,-1,"[""5g mobile communication"", ""data flow computing"", ""resource allocation"", ""telecommunication computing"", ""telecommunication network reliability"", ""telecommunication scheduling"", ""telecommunication traffic""]","[""5g mobile communication"", ""data flow computing"", ""resource allocation"", ""telecommunication computing"", ""telecommunication network reliability"", ""telecommunication scheduling"", ""telecommunication traffic""]",5g mobile communication;data flow computing;resource allocation;telecommunication computing;telecommunication network reliability;telecommunication scheduling;telecommunication traffic,other;input;telecommunication;developers;data;geospatial;business planning and management,technology;other;business;industries,other;input;telecommunication;developers;data;geospatial;business planning and management,technology;other;business;industries,5g_mobile_communication data_flow_computing resource_allocation telecommunication_computing telecommunication_network_reliability telecommunication_scheduling telecommunication_traffic 5g advance_media_applications augmented_reality extended_reality k repeated_cg_configuration k repeated_configured_grant_transmission mixed_reality resource_allocation scheduling_mechanism ul_grants_allocation_method uplink_xr_data_flows urllc_traffic virtual_reality xr_traffic b6250f_mobile_radio_systems b0170n_reliability c6130v_virtual_reality c6190p_parallel_software c7410f_communications_computing other input telecommunication developers data geospatial business_planning_and_management,5g_mobile_communication data_flow_computing resource_allocation telecommunication_computing telecommunication_network_reliability telecommunication_scheduling telecommunication_traffic,5g advance_media_applications augmented_reality extended_reality k repeated_cg_configuration k repeated_configured_grant_transmission mixed_reality resource_allocation scheduling_mechanism ul_grants_allocation_method uplink_xr_data_flows urllc_traffic virtual_reality xr_traffic,extended reality xr become one important 5g 5g advance medium application industry specifically xr broad term covering augmented reality mixed reality virtual reality although xr traffic similar characteristic urllc traffic also difference multiple periodic data stream variable packet size therefore based analysis xr specific traffic paper aim investigate efficient resource allocation scheduling mechanism xr traffic instance configured grant cg transmission latency uplink ul xr data flow reduced order improve reliability k repeated cg configuration considered help gnb make efficient scheduling ue also use assistance information indicate xr traffic quality requirement time aligned transmission gnb paper analysis evaluates efficiency ul grant allocation method show assistance information gnb make priority classification efficient resource allocation reduce resource 81,5g_mobile_communication data_flow_computing resource_allocation telecommunication_computing telecommunication_network_reliability telecommunication_scheduling telecommunication_traffic 5g advance_media_applications augmented_reality extended_reality k repeated_cg_configuration k repeated_configured_grant_transmission mixed_reality resource_allocation scheduling_mechanism ul_grants_allocation_method uplink_xr_data_flows urllc_traffic virtual_reality xr_traffic b6250f_mobile_radio_systems b0170n_reliability c6130v_virtual_reality c6190p_parallel_software c7410f_communications_computing other input telecommunication developers data geospatial business_planning_and_management extended reality xr become one important 5g 5g advance medium application industry specifically xr broad term covering augmented reality mixed reality virtual reality although xr traffic similar characteristic urllc traffic also difference multiple periodic data stream variable packet size therefore based analysis xr specific traffic paper aim investigate efficient resource allocation scheduling mechanism xr traffic instance configured grant cg transmission latency uplink ul xr data flow reduced order improve reliability k repeated cg configuration considered help gnb make efficient scheduling ue also use assistance information indicate xr traffic quality requirement time aligned transmission gnb paper analysis evaluates efficiency ul grant allocation method show assistance information gnb make priority classification efficient resource allocation reduce resource 81,extended reality xr become one important 5g 5g advance medium application industry specifically xr broad term covering augmented reality mixed reality virtual reality although xr traffic similar characteristic urllc traffic also difference multiple periodic data stream variable packet size therefore based analysis xr specific traffic paper aim investigate efficient resource allocation scheduling mechanism xr traffic instance configured grant cg transmission latency uplink ul xr data flow reduced order improve reliability k repeated cg configuration considered help gnb make efficient scheduling ue also use assistance information indicate xr traffic quality requirement time aligned transmission gnb paper analysis evaluates efficiency ul grant allocation method show assistance information gnb make priority classification efficient resource allocation reduce resource 815g_mobile_communication data_flow_computing resource_allocation telecommunication_computing telecommunication_network_reliability telecommunication_scheduling telecommunication_traffic5g advance_media_applications augmented_reality extended_reality k repeated_cg_configuration k repeated_configured_grant_transmission mixed_reality resource_allocation scheduling_mechanism ul_grants_allocation_method uplink_xr_data_flows urllc_traffic virtual_reality xr_traffic
258,Edge Computing Unloading Technology Based on Electric Vehicle Charging Pile,"Xue, L., Zhang, T., Wang, K., Han, C., Jia, B., Zhou, L., & Zhou, K. (2023). Edge Computing Unloading Technology Based on Electric Vehicle Charging Pile. 2023 8th Asia Conference on Power and Electrical Engineering (ACPEE). https://doi.org/10.1109/acpee56931.2023.10135587
",10.1109/ACPEE56931.2023.10135587,"With the rapid development of the new energy vehicle industry, more and more people choose electric vehicles as their means of travel, and the corresponding computing tasks are also increasing. The functions derived from it are also becoming more and more complex, such as the very popular augmented reality, driverless and other emerging technologies in recent years. For this reason, edge computing unloading technology is introduced into the Internet of Vehicles, which sinks the pressure of vehicle computing to the edge network of charging piles. Vehicle tasks are unloaded to the nearby charging pile server, improving vehicle computing capacity and reducing computing costs. To sum up, in order to solve the huge problem of vehicle task calculation and reduce the cost of charging piles, this paper proposes a edge computing unloading strategy based on electric vehicle charging piles.Set the server in the electric vehicle charging pile to meet the calculation task delay requirements of vehicles near the charging pile. The experimental results show that the edge computing unloading strategy based on the EV charging pile can increase the task delay by more than 31.7% compared with the vehicle itself.",B8520B Automobile electronics and electrics;B6210L Computer communications;B6250F Mobile radio systems;C5620D Internet of Things;C6130V Virtual reality;C7410B Power engineering computing,augmented reality;driverless emerging technologies;edge computing unloading technology;edge network;electric vehicle charging pile;energy vehicle industry;EV charging pile;Internet of Vehicles;nearby charging pile server;vehicle computing capacity;vehicle task calculation,augmented reality;battery powered vehicles;edge computing;electric vehicle charging;Internet of Things;power engineering computing;vehicular ad hoc networks,2023,Conference article (CA),2023 8th Asia Conference on Power and Electrical Engineering (ACPEE),"(1) Xue, L.; (1) Zhang, T.; (1) Wang, K.; (1) Han, C.; (1) Jia, B.; (1) Zhou, L.; (1) Zhou, K.; ","(1) State Grid Hebei Electric Power Co., Ltd, Xiong'an New Area Power Supply Company, China; ",IEEE,-1,"[""battery powered vehicles"", ""edge computing"", ""electric vehicle charging"", ""internet of things"", ""power engineering computing"", ""vehicular ad hoc networks""]","[""battery powered vehicles"", ""edge computing"", ""electric vehicle charging"", ""internet of things"", ""power engineering computing"", ""vehicular ad hoc networks""]",battery powered vehicles;edge computing;electric vehicle charging;internet of things;power engineering computing;vehicular ad hoc networks,other;automotive;power and energy;internet of things;engineering;networks,technology;other;industries,other;automotive;power and energy;internet of things;engineering;networks,technology;other;industries,battery_powered_vehicles edge_computing electric_vehicle_charging internet_of_things power_engineering_computing vehicular_ad_hoc_networks augmented_reality driverless_emerging_technologies edge_computing_unloading_technology edge_network electric_vehicle_charging_pile energy_vehicle_industry ev_charging_pile internet_of_vehicles nearby_charging_pile_server vehicle_computing_capacity vehicle_task_calculation b8520b_automobile_electronics_and_electrics b6210l_computer_communications b6250f_mobile_radio_systems c5620d_internet_of_things c6130v_virtual_reality c7410b_power_engineering_computing other automotive power_and_energy internet_of_things engineering networks,battery_powered_vehicles edge_computing electric_vehicle_charging internet_of_things power_engineering_computing vehicular_ad_hoc_networks,augmented_reality driverless_emerging_technologies edge_computing_unloading_technology edge_network electric_vehicle_charging_pile energy_vehicle_industry ev_charging_pile internet_of_vehicles nearby_charging_pile_server vehicle_computing_capacity vehicle_task_calculation,rapid development new energy vehicle industry people choose electric vehicle mean travel corresponding computing task also increasing function derived also becoming complex popular augmented reality driverless emerging technology recent year reason edge computing unloading technology introduced internet vehicle sink pressure vehicle computing edge network charging pile vehicle task unloaded nearby charging pile server improving vehicle computing capacity reducing computing cost sum order solve huge problem vehicle task calculation reduce cost charging pile paper proposes edge computing unloading strategy based electric vehicle charging pile set server electric vehicle charging pile meet calculation task delay requirement vehicle near charging pile experimental result show edge computing unloading strategy based ev charging pile increase task delay 31 7 compared vehicle,battery_powered_vehicles edge_computing electric_vehicle_charging internet_of_things power_engineering_computing vehicular_ad_hoc_networks augmented_reality driverless_emerging_technologies edge_computing_unloading_technology edge_network electric_vehicle_charging_pile energy_vehicle_industry ev_charging_pile internet_of_vehicles nearby_charging_pile_server vehicle_computing_capacity vehicle_task_calculation b8520b_automobile_electronics_and_electrics b6210l_computer_communications b6250f_mobile_radio_systems c5620d_internet_of_things c6130v_virtual_reality c7410b_power_engineering_computing other automotive power_and_energy internet_of_things engineering networks rapid development new energy vehicle industry people choose electric vehicle mean travel corresponding computing task also increasing function derived also becoming complex popular augmented reality driverless emerging technology recent year reason edge computing unloading technology introduced internet vehicle sink pressure vehicle computing edge network charging pile vehicle task unloaded nearby charging pile server improving vehicle computing capacity reducing computing cost sum order solve huge problem vehicle task calculation reduce cost charging pile paper proposes edge computing unloading strategy based electric vehicle charging pile set server electric vehicle charging pile meet calculation task delay requirement vehicle near charging pile experimental result show edge computing unloading strategy based ev charging pile increase task delay 31 7 compared vehicle,rapid development new energy vehicle industry people choose electric vehicle mean travel corresponding computing task also increasing function derived also becoming complex popular augmented reality driverless emerging technology recent year reason edge computing unloading technology introduced internet vehicle sink pressure vehicle computing edge network charging pile vehicle task unloaded nearby charging pile server improving vehicle computing capacity reducing computing cost sum order solve huge problem vehicle task calculation reduce cost charging pile paper proposes edge computing unloading strategy based electric vehicle charging pile set server electric vehicle charging pile meet calculation task delay requirement vehicle near charging pile experimental result show edge computing unloading strategy based ev charging pile increase task delay 31 7 compared vehiclebattery_powered_vehicles edge_computing electric_vehicle_charging internet_of_things power_engineering_computing vehicular_ad_hoc_networksaugmented_reality driverless_emerging_technologies edge_computing_unloading_technology edge_network electric_vehicle_charging_pile energy_vehicle_industry ev_charging_pile internet_of_vehicles nearby_charging_pile_server vehicle_computing_capacity vehicle_task_calculation
259,Practical Saccade Prediction for Head-Mounted Displays: Towards a Comprehensive Model,"Arabadzhiyska, E., Tursun, C., Seidel, H.-P., & Didyk, P. (2023). Practical Saccade Prediction for Head-Mounted Displays: Towards a Comprehensive Model. ACM Transactions on Applied Perception, 20(1), 1–23. https://doi.org/10.1145/3568311
",10.1145/3568311,"Eye-tracking technology has started to become an integral component of new display devices such as virtual and augmented reality headsets. Applications of gaze information range from new interaction techniques that exploit eye patterns to gaze-contingent digital content creation. However, system latency is still a significant issue in many of these applications because it breaks the synchronization between the current and measured gaze positions. Consequently, it may lead to unwanted visual artifacts and degradation of the user experience. In this work, we focus on foveated rendering applications where the quality of an image is reduced towards the periphery for computational savings. In foveated rendering, the presence of system latency leads to delayed updates to the rendered frame, making the quality degradation visible to the user. To address this issue and to combat system latency, recent work proposes using saccade landing position prediction to extrapolate gaze information from delayed eye tracking samples. Although the benefits of such a strategy have already been demonstrated, the solutions range from simple and efficient ones, which make several assumptions about the saccadic eye movements, to more complex and costly ones, which use machine learning techniques. However, it is unclear to what extent the prediction can benefit from accounting for additional factors and how more complex predictions can be performed efficiently to respect the latency requirements. This paper presents a series of experiments investigating the importance of different factors for saccades prediction in common virtual and augmented reality applications. In particular, we investigate the effects of saccade orientation in 3D space and &lt;b&gt;smooth pursuit eye-motion (SPEM) &lt;/b&gt;and how their influence compares to the variability across users. We also present a simple, yet efficient post-hoc correction method that adapts existing saccade prediction methods to handle these factors without performing extensive data collection. Furthermore, our investigation and the correction technique may also help future developments of machine-learning-based techniques by limiting the required amount of training data.","B6135 Optical, image and video signal processing;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C5540D Computer displays;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces",3D space;augmented reality applications;augmented reality headsets;comprehensive model;correction technique;delayed eye tracking samples;display devices;efficient post-hoc correction method;eye patterns;eye-tracking technology;foveated rendering applications;gaze-contingent digital content creation;head-mounted displays;interaction techniques;machine learning techniques;machine-learning-based techniques;post-hoc correction method;practical saccade prediction;saccade landing position prediction;saccade orientation;saccade prediction methods;saccadic eye movements;smooth pursuit eye-motion;SPEM;unwanted visual artifacts;user experience;virtual reality applications;virtual reality headsets,augmented reality;biomechanics;eye;gaze tracking;helmet mounted displays;human factors;learning (artificial intelligence);rendering (computer graphics);user experience;visual perception,2023,Journal article (JA),ACM Trans. Appl. Percept. (USA),"(1) Arabadzhiyska, E.; (2) Tursun, C.; (1) Seidel, H.-P.; (3) Didyk, P.; ","(1) Max-Planck-Institut fur Informatik, Germany; (2) University of Groningen, Netherlands; (3) Universita&#768; della Svizzera italiana, Switzerland; ",ACM,-1,"[""biomechanics"", ""eye"", ""gaze tracking"", ""helmet mounted displays"", ""human factors"", ""learning algorithms"", ""rendering"", ""user experience"", ""visual perception""]","[""biomechanics"", ""eye"", ""gaze tracking"", ""helmet mounted displays"", ""human factors"", ""learning algorithms"", ""rendering"", ""user experience"", ""visual perception""]",biomechanics;eye;gaze tracking;helmet mounted displays;human factors;learning algorithms;rendering;user experience;visual perception,computer vision;graphics;input;medical;human factors;display technology;wearables;artificial intelligence,technology;industries;displays;end users and user experience,computer vision;graphics;input;medical;human factors;display technology;wearables;artificial intelligence,technology;industries;displays;end users and user experience,biomechanics eye gaze_tracking helmet_mounted_displays human_factors learning_algorithms rendering user_experience visual_perception 3d_space augmented_reality_applications augmented_reality_headsets comprehensive_model correction_technique delayed_eye_tracking_samples display_devices efficient_post hoc_correction_method eye_patterns eye tracking_technology foveated_rendering_applications gaze contingent_digital_content_creation head mounted_displays interaction_techniques machine_learning_techniques machine learning based_techniques post hoc_correction_method practical_saccade_prediction saccade_landing_position_prediction saccade_orientation saccade_prediction_methods saccadic_eye_movements smooth_pursuit_eye motion spem unwanted_visual_artifacts user_experience virtual_reality_applications virtual_reality_headsets b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision graphics input medical human_factors display_technology wearables artificial_intelligence,biomechanics eye gaze_tracking helmet_mounted_displays human_factors learning_algorithms rendering user_experience visual_perception,3d_space augmented_reality_applications augmented_reality_headsets comprehensive_model correction_technique delayed_eye_tracking_samples display_devices efficient_post hoc_correction_method eye_patterns eye tracking_technology foveated_rendering_applications gaze contingent_digital_content_creation head mounted_displays interaction_techniques machine_learning_techniques machine learning based_techniques post hoc_correction_method practical_saccade_prediction saccade_landing_position_prediction saccade_orientation saccade_prediction_methods saccadic_eye_movements smooth_pursuit_eye motion spem unwanted_visual_artifacts user_experience virtual_reality_applications virtual_reality_headsets,eye tracking technology started become integral component new display device virtual augmented reality headset application gaze information range new interaction technique exploit eye pattern gaze contingent digital content creation however system latency still significant issue many application break synchronization current measured gaze position consequently may lead unwanted visual artifact degradation user experience work focus foveated rendering application quality image reduced towards periphery computational saving foveated rendering presence system latency lead delayed update rendered frame making quality degradation visible user address issue combat system latency recent work proposes using saccade landing position prediction extrapolate gaze information delayed eye tracking sample although benefit strategy already demonstrated solution range simple efficient one make several assumption saccadic eye movement complex costly one use machine learning technique however unclear extent prediction benefit accounting additional factor complex prediction performed efficiently respect latency requirement paper present series experiment investigating importance different factor saccade prediction common virtual augmented reality application particular investigate effect saccade orientation 3d space lt b gt smooth pursuit eye motion spem lt b gt influence compare variability across user also present simple yet efficient post hoc correction method adapts existing saccade prediction method handle factor without performing extensive data collection furthermore investigation correction technique may also help future development machine learning based technique limiting required amount training data,biomechanics eye gaze_tracking helmet_mounted_displays human_factors learning_algorithms rendering user_experience visual_perception 3d_space augmented_reality_applications augmented_reality_headsets comprehensive_model correction_technique delayed_eye_tracking_samples display_devices efficient_post hoc_correction_method eye_patterns eye tracking_technology foveated_rendering_applications gaze contingent_digital_content_creation head mounted_displays interaction_techniques machine_learning_techniques machine learning based_techniques post hoc_correction_method practical_saccade_prediction saccade_landing_position_prediction saccade_orientation saccade_prediction_methods saccadic_eye_movements smooth_pursuit_eye motion spem unwanted_visual_artifacts user_experience virtual_reality_applications virtual_reality_headsets b6135_optical _image_and_video_signal_processing c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision graphics input medical human_factors display_technology wearables artificial_intelligence eye tracking technology started become integral component new display device virtual augmented reality headset application gaze information range new interaction technique exploit eye pattern gaze contingent digital content creation however system latency still significant issue many application break synchronization current measured gaze position consequently may lead unwanted visual artifact degradation user experience work focus foveated rendering application quality image reduced towards periphery computational saving foveated rendering presence system latency lead delayed update rendered frame making quality degradation visible user address issue combat system latency recent work proposes using saccade landing position prediction extrapolate gaze information delayed eye tracking sample although benefit strategy already demonstrated solution range simple efficient one make several assumption saccadic eye movement complex costly one use machine learning technique however unclear extent prediction benefit accounting additional factor complex prediction performed efficiently respect latency requirement paper present series experiment investigating importance different factor saccade prediction common virtual augmented reality application particular investigate effect saccade orientation 3d space lt b gt smooth pursuit eye motion spem lt b gt influence compare variability across user also present simple yet efficient post hoc correction method adapts existing saccade prediction method handle factor without performing extensive data collection furthermore investigation correction technique may also help future development machine learning based technique limiting required amount training data,eye tracking technology started become integral component new display device virtual augmented reality headset application gaze information range new interaction technique exploit eye pattern gaze contingent digital content creation however system latency still significant issue many application break synchronization current measured gaze position consequently may lead unwanted visual artifact degradation user experience work focus foveated rendering application quality image reduced towards periphery computational saving foveated rendering presence system latency lead delayed update rendered frame making quality degradation visible user address issue combat system latency recent work proposes using saccade landing position prediction extrapolate gaze information delayed eye tracking sample although benefit strategy already demonstrated solution range simple efficient one make several assumption saccadic eye movement complex costly one use machine learning technique however unclear extent prediction benefit accounting additional factor complex prediction performed efficiently respect latency requirement paper present series experiment investigating importance different factor saccade prediction common virtual augmented reality application particular investigate effect saccade orientation 3d space lt b gt smooth pursuit eye motion spem lt b gt influence compare variability across user also present simple yet efficient post hoc correction method adapts existing saccade prediction method handle factor without performing extensive data collection furthermore investigation correction technique may also help future development machine learning based technique limiting required amount training databiomechanics eye gaze_tracking helmet_mounted_displays human_factors learning_algorithms rendering user_experience visual_perception3d_space augmented_reality_applications augmented_reality_headsets comprehensive_model correction_technique delayed_eye_tracking_samples display_devices efficient_post hoc_correction_method eye_patterns eye tracking_technology foveated_rendering_applications gaze contingent_digital_content_creation head mounted_displays interaction_techniques machine_learning_techniques machine learning based_techniques post hoc_correction_method practical_saccade_prediction saccade_landing_position_prediction saccade_orientation saccade_prediction_methods saccadic_eye_movements smooth_pursuit_eye motion spem unwanted_visual_artifacts user_experience virtual_reality_applications virtual_reality_headsets
260,A Study on Contextual Task Performance of Simulated Homonymous Hemianopia Patients with Computational Glasses-based Compensation,"Ge, C., Zhu, Z., Ichinose, K., Fujishiro, I., Toyoura, M., Go, K., Kashiwagi, K., & Mao, X. (2022). A Study on Contextual Task Performance of Simulated Homonymous Hemianopia Patients with Computational Glasses-based Compensation. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574441
",10.1145/3574131.3574441,"People with Homonymous Hemianopia (HH) suffer from losing ipsilateral half side of visual field in both eyes, which results in failing to obtain visual information in the lost field. Making using of the remaining of the visual field, the state-of-the-art studies proposed Overlaid Overview Window (OOW) and Edge Indicator (EI) on the basis of Augmented-Reality (AR) glasses for compensation. However, experiments conducted in these studies investigate user performance with tasks involving events in lost field or remaining field singly. On the other hand, both studies recruited normal individuals for mock experiment, while their way to simulate HH, which requiring the participants to fix their view angles, were not practical to real HH patients. In this study, we conduct a contextual information experiment to investigate the user performance involving in the task requiring the information across both the visible and invisible sides of HH, with the compensation of OOW and Flicker-based EI (FEI). At the same time, we also recruit volunteers with normal vision for mock experiment, while the participants in our study are allowed to move their gaze freely, because we simulate the invisible field of HH on AR glasses with eye tracking. The experiment results showed that OOW is better for the task that related to move something from the remaining FoV to the lost FoV, while FEI is better for moving something from the lost FoV to the remaining FoV.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C7330 Biology and medical computing,AR glasses;Augmented-Reality glasses;computational glasses-based compensation;contextual information experiment;contextual task performance;Edge Indicator;Flicker-based EI;HH patients;invisible field;lost field;lost FoV;mock experiment;normal individuals;OOW;Overlaid Overview Window;remaining field;remaining FoV;simulated Homonymous Hemianopia patients;state-of-the-art studies;user performance;visual field;visual information,augmented reality;eye;gaze tracking;vision defects;visual perception,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Ge, C.; (1) Zhu, Z.; (1) Ichinose, K.; (2) Fujishiro, I.; (1) Toyoura, M.; (1) Go, K.; (3) Kashiwagi, K.; (1) Mao, X.; ","(1) University of Yamanashi, Department of Computer Science and Engineering, Japan; (2) Keio University, Department of Information Science, Japan; (3) University of Yamanashi, Department of Ophthalmology, Japan; ",ACM,-1,"[""eye"", ""gaze tracking"", ""vision defects"", ""visual perception""]","[""eye"", ""gaze tracking"", ""vision defects"", ""visual perception""]",eye;gaze tracking;vision defects;visual perception,"inspection, safety and quality;computer vision;human factors;input",technology;use cases;end users and user experience,"inspection, safety and quality;computer vision;human factors;input",technology;use cases;end users and user experience,eye gaze_tracking vision_defects visual_perception ar_glasses augmented reality_glasses computational_glasses based_compensation contextual_information_experiment contextual_task_performance edge_indicator flicker based_ei hh_patients invisible_field lost_field lost_fov mock_experiment normal_individuals oow overlaid_overview_window remaining_field remaining_fov simulated_homonymous_hemianopia_patients state of the art_studies user_performance visual_field visual_information c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c7330_biology_and_medical_computing inspection _safety_and_quality computer_vision human_factors input,eye gaze_tracking vision_defects visual_perception,ar_glasses augmented reality_glasses computational_glasses based_compensation contextual_information_experiment contextual_task_performance edge_indicator flicker based_ei hh_patients invisible_field lost_field lost_fov mock_experiment normal_individuals oow overlaid_overview_window remaining_field remaining_fov simulated_homonymous_hemianopia_patients state of the art_studies user_performance visual_field visual_information,people homonymous hemianopia hh suffer losing ipsilateral half side visual field eye result failing obtain visual information lost field making using remaining visual field state art study proposed overlaid overview window oow edge indicator ei basis augmented reality ar glass compensation however experiment conducted study investigate user performance task involving event lost field remaining field singly hand study recruited normal individual mock experiment way simulate hh requiring participant fix view angle practical real hh patient study conduct contextual information experiment investigate user performance involving task requiring information across visible invisible side hh compensation oow flicker based ei fei time also recruit volunteer normal vision mock experiment participant study allowed move gaze freely simulate invisible field hh ar glass eye tracking experiment result showed oow better task related move something remaining fov lost fov fei better moving something lost fov remaining fov,eye gaze_tracking vision_defects visual_perception ar_glasses augmented reality_glasses computational_glasses based_compensation contextual_information_experiment contextual_task_performance edge_indicator flicker based_ei hh_patients invisible_field lost_field lost_fov mock_experiment normal_individuals oow overlaid_overview_window remaining_field remaining_fov simulated_homonymous_hemianopia_patients state of the art_studies user_performance visual_field visual_information c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c7330_biology_and_medical_computing inspection _safety_and_quality computer_vision human_factors input people homonymous hemianopia hh suffer losing ipsilateral half side visual field eye result failing obtain visual information lost field making using remaining visual field state art study proposed overlaid overview window oow edge indicator ei basis augmented reality ar glass compensation however experiment conducted study investigate user performance task involving event lost field remaining field singly hand study recruited normal individual mock experiment way simulate hh requiring participant fix view angle practical real hh patient study conduct contextual information experiment investigate user performance involving task requiring information across visible invisible side hh compensation oow flicker based ei fei time also recruit volunteer normal vision mock experiment participant study allowed move gaze freely simulate invisible field hh ar glass eye tracking experiment result showed oow better task related move something remaining fov lost fov fei better moving something lost fov remaining fov,people homonymous hemianopia hh suffer losing ipsilateral half side visual field eye result failing obtain visual information lost field making using remaining visual field state art study proposed overlaid overview window oow edge indicator ei basis augmented reality ar glass compensation however experiment conducted study investigate user performance task involving event lost field remaining field singly hand study recruited normal individual mock experiment way simulate hh requiring participant fix view angle practical real hh patient study conduct contextual information experiment investigate user performance involving task requiring information across visible invisible side hh compensation oow flicker based ei fei time also recruit volunteer normal vision mock experiment participant study allowed move gaze freely simulate invisible field hh ar glass eye tracking experiment result showed oow better task related move something remaining fov lost fov fei better moving something lost fov remaining foveye gaze_tracking vision_defects visual_perceptionar_glasses augmented reality_glasses computational_glasses based_compensation contextual_information_experiment contextual_task_performance edge_indicator flicker based_ei hh_patients invisible_field lost_field lost_fov mock_experiment normal_individuals oow overlaid_overview_window remaining_field remaining_fov simulated_homonymous_hemianopia_patients state of the art_studies user_performance visual_field visual_information
261,WARM: Wearable AR and Tablet-Based Assistant Systems for Bus Maintenance,"Borro, D., Suescun, Á., Brazález, A., González, J. M., Ortega, E., & González, E. (2021). WARM: Wearable AR and Tablet-Based Assistant Systems for Bus Maintenance. Applied Sciences, 11(4), 1443. https://doi.org/10.3390/app11041443
",10.3390/app11041443,"This paper shows two developed digital systems as an example of intelligent garage and maintenance that targets the applicability of augmented reality and wearable devices technologies to the maintenance of bus fleets. Both solutions are designed to improve the maintenance process based on verification of tasks checklist. The main contribution of the paper focuses on the implementation of the prototypes in the company's facilities in an operational environment with real users and address the difficulties inherent in the transfer of a technology to a real work environment, such as a mechanical workshop. The experiments have been conducted in real operation thanks to the involvement of the public transport operator DBUS, which operates public transport buses in the city of Donostia&#8212;San Sebastian (Spain). Two solutions have been developed and compared against the traditional process: one based on Tablet and another one based on Microsoft HoloLens. The results show objective metrics (Key Performance Indicators, KPI) as well as subjective metrics based on questionnaires comparing the two technological approaches against the traditional one based on manual work and paper.",C7440 Civil and mechanical engineering computing;C6130V Virtual reality;E0410H Mechanical engineering applications of IT;E1020 Maintenance and reliability;E2220 Vehicle mechanics;E3650A Automobile industry,augmented reality;bus fleets;bus maintenance;DBUS;digital systems;Donostia&#8212;San Sebastian;intelligent garage;key performance indicators;KPI;maintenance process;mechanical workshop;Microsoft HoloLens;operational environment;public transport buses;public transport operator;tablet-based assistant systems;WARM;wearable devices technologies,augmented reality;automotive engineering;maintenance engineering;road vehicles,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Borro, D.; (1) Suescun, A.; (1) Braza&#769;lez, A.; (1) Gonza&#769;lez, J.M.; (3) Ortega, E.; (4) Gonza&#769;lez, E.; ","(1) CEIT-Basque Research and Technology Alliance (BRTA), Manuel Lardiza&#769;bal 15, Spain; (2) Universidad de Navarra, Tecnun, Manuel Lardiza&#769;bal 13, Spain; (3) TCMAN, Passeig de Maragall 120, Spain; (4) DBUS&#8212;Compan&#771;i&#769;a del Tranvi&#769;a de San Sebastia&#769;n, Fernando Sasiain 7, Spain; ",MDPI,-1,"[""automotive engineering"", ""maintenance engineering"", ""road vehicles""]","[""automotive engineering"", ""maintenance engineering"", ""road vehicles""]",automotive engineering;maintenance engineering;road vehicles,manufacturing;automotive,industries,manufacturing;automotive,industries,automotive_engineering maintenance_engineering road_vehicles augmented_reality bus_fleets bus_maintenance dbus digital_systems donostia 8212 san_sebastian intelligent_garage key_performance_indicators kpi maintenance_process mechanical_workshop microsoft_hololens operational_environment public_transport_buses public_transport_operator tablet based_assistant_systems warm wearable_devices_technologies c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e0410h_mechanical_engineering_applications_of_it e1020_maintenance_and_reliability e2220_vehicle_mechanics e3650a_automobile_industry manufacturing automotive,automotive_engineering maintenance_engineering road_vehicles,augmented_reality bus_fleets bus_maintenance dbus digital_systems donostia 8212 san_sebastian intelligent_garage key_performance_indicators kpi maintenance_process mechanical_workshop microsoft_hololens operational_environment public_transport_buses public_transport_operator tablet based_assistant_systems warm wearable_devices_technologies,paper show two developed digital system example intelligent garage maintenance target applicability augmented reality wearable device technology maintenance bus fleet solution designed improve maintenance process based verification task checklist main contribution paper focus implementation prototype company facility operational environment real user address difficulty inherent transfer technology real work environment mechanical workshop experiment conducted real operation thanks involvement public transport operator dbus operates public transport bus city donostia 8212 san sebastian spain two solution developed compared traditional process one based tablet another one based microsoft hololens result show objective metric key performance indicator kpi well subjective metric based questionnaire comparing two technological approach traditional one based manual work paper,automotive_engineering maintenance_engineering road_vehicles augmented_reality bus_fleets bus_maintenance dbus digital_systems donostia 8212 san_sebastian intelligent_garage key_performance_indicators kpi maintenance_process mechanical_workshop microsoft_hololens operational_environment public_transport_buses public_transport_operator tablet based_assistant_systems warm wearable_devices_technologies c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e0410h_mechanical_engineering_applications_of_it e1020_maintenance_and_reliability e2220_vehicle_mechanics e3650a_automobile_industry manufacturing automotive paper show two developed digital system example intelligent garage maintenance target applicability augmented reality wearable device technology maintenance bus fleet solution designed improve maintenance process based verification task checklist main contribution paper focus implementation prototype company facility operational environment real user address difficulty inherent transfer technology real work environment mechanical workshop experiment conducted real operation thanks involvement public transport operator dbus operates public transport bus city donostia 8212 san sebastian spain two solution developed compared traditional process one based tablet another one based microsoft hololens result show objective metric key performance indicator kpi well subjective metric based questionnaire comparing two technological approach traditional one based manual work paper,paper show two developed digital system example intelligent garage maintenance target applicability augmented reality wearable device technology maintenance bus fleet solution designed improve maintenance process based verification task checklist main contribution paper focus implementation prototype company facility operational environment real user address difficulty inherent transfer technology real work environment mechanical workshop experiment conducted real operation thanks involvement public transport operator dbus operates public transport bus city donostia 8212 san sebastian spain two solution developed compared traditional process one based tablet another one based microsoft hololens result show objective metric key performance indicator kpi well subjective metric based questionnaire comparing two technological approach traditional one based manual work paperautomotive_engineering maintenance_engineering road_vehiclesaugmented_reality bus_fleets bus_maintenance dbus digital_systems donostia 8212 san_sebastian intelligent_garage key_performance_indicators kpi maintenance_process mechanical_workshop microsoft_hololens operational_environment public_transport_buses public_transport_operator tablet based_assistant_systems warm wearable_devices_technologies
262,Development of interactive learning multimedia for mathematics subjects for grade 5 elementary schools,"Firmansyah, F. H., Sari, I. P., Permana, F. C., & Rinjani, D. (2021). Development of interactive learning multimedia for mathematics subjects for grade 5 elementary schools. Journal of Physics: Conference Series, 1987(1), 012017. https://doi.org/10.1088/1742-6596/1987/1/012017
",10.1088/1742-6596/1987/1/012017,"The learning process during a pandemic requires teachers to be more interactive in making online learning media. The government has designed the Covid Emergency Curriculum, which is that educational units in their current condition can choose one of the several components needed in the learning process, namely still referring to the national curriculum, using the emergency curriculum, or making curriculum simplification independently. For curriculum simplification, only the main material in learning activities needs to be conveyed, while for practice it can be independently or through an application media. This study aims to create an augmented reality-based learning media on geometry in mathematics subjects for grade 5 elementary school. This media can make it easier for students to understand the shapes with augmented reality and there is a learning video feature that also explains the material presented by the teacher. With the black box white box method, the application is developed by adjusting the curriculum simplification planned by the government. Features in the application include objectives and materials, learning videos, augmented reality simulations and integrated with Google Classroom as a learning evaluation platform. The results of this research are digital applications that can be accessed from the web or android applications.","C7810C Computer-aided instruction;C6130M Multimedia;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7330 Biology and medical computing",application media;augmented reality simulations;black box white box method;Covid Emergency Curriculum;curriculum simplification;educational units;government;grade 5 elementary school;interactive learning multimedia;learning evaluation platform;learning process;learning video feature;main material;mathematics subjects;national curriculum;online learning media,augmented reality;computer aided instruction;educational courses;educational institutions;epidemics;medical computing,2021,Conference article (CA),"J. Phys., Conf. Ser. (UK)","(1) Firmansyah, F.H.; (1) Sari, I.P.; (1) Permana, F.C.; (1) Rinjani, D.; ","(1) Universitas Pendidikan Indonesia, Indonesia; ",IOP Publishing,-1,"[""computer aided instruction"", ""educational courses"", ""educational institutions"", ""epidemics"", ""medical computing""]","[""computer aided instruction"", ""educational courses"", ""educational institutions"", ""epidemics"", ""medical computing""]",computer aided instruction;educational courses;educational institutions;epidemics;medical computing,medical;education;training,use cases;industries,medical;education;training,use cases;industries,computer_aided_instruction educational_courses educational_institutions epidemics medical_computing application_media augmented_reality_simulations black_box_white_box_method covid_emergency_curriculum curriculum_simplification educational_units government grade_5_elementary_school interactive_learning_multimedia learning_evaluation_platform learning_process learning_video_feature main_material mathematics_subjects national_curriculum online_learning_media c7810c_computer aided_instruction c6130m_multimedia c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing medical education training,computer_aided_instruction educational_courses educational_institutions epidemics medical_computing,application_media augmented_reality_simulations black_box_white_box_method covid_emergency_curriculum curriculum_simplification educational_units government grade_5_elementary_school interactive_learning_multimedia learning_evaluation_platform learning_process learning_video_feature main_material mathematics_subjects national_curriculum online_learning_media,learning process pandemic requires teacher interactive making online learning medium government designed covid emergency curriculum educational unit current condition choose one several component needed learning process namely still referring national curriculum using emergency curriculum making curriculum simplification independently curriculum simplification main material learning activity need conveyed practice independently application medium study aim create augmented reality based learning medium geometry mathematics subject grade 5 elementary school medium make easier student understand shape augmented reality learning video feature also explains material presented teacher black box white box method application developed adjusting curriculum simplification planned government feature application include objective material learning video augmented reality simulation integrated google classroom learning evaluation platform result research digital application accessed web android application,computer_aided_instruction educational_courses educational_institutions epidemics medical_computing application_media augmented_reality_simulations black_box_white_box_method covid_emergency_curriculum curriculum_simplification educational_units government grade_5_elementary_school interactive_learning_multimedia learning_evaluation_platform learning_process learning_video_feature main_material mathematics_subjects national_curriculum online_learning_media c7810c_computer aided_instruction c6130m_multimedia c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing medical education training learning process pandemic requires teacher interactive making online learning medium government designed covid emergency curriculum educational unit current condition choose one several component needed learning process namely still referring national curriculum using emergency curriculum making curriculum simplification independently curriculum simplification main material learning activity need conveyed practice independently application medium study aim create augmented reality based learning medium geometry mathematics subject grade 5 elementary school medium make easier student understand shape augmented reality learning video feature also explains material presented teacher black box white box method application developed adjusting curriculum simplification planned government feature application include objective material learning video augmented reality simulation integrated google classroom learning evaluation platform result research digital application accessed web android application,learning process pandemic requires teacher interactive making online learning medium government designed covid emergency curriculum educational unit current condition choose one several component needed learning process namely still referring national curriculum using emergency curriculum making curriculum simplification independently curriculum simplification main material learning activity need conveyed practice independently application medium study aim create augmented reality based learning medium geometry mathematics subject grade 5 elementary school medium make easier student understand shape augmented reality learning video feature also explains material presented teacher black box white box method application developed adjusting curriculum simplification planned government feature application include objective material learning video augmented reality simulation integrated google classroom learning evaluation platform result research digital application accessed web android applicationcomputer_aided_instruction educational_courses educational_institutions epidemics medical_computingapplication_media augmented_reality_simulations black_box_white_box_method covid_emergency_curriculum curriculum_simplification educational_units government grade_5_elementary_school interactive_learning_multimedia learning_evaluation_platform learning_process learning_video_feature main_material mathematics_subjects national_curriculum online_learning_media
263,Perceptual Visibility Model for Temporal Contrast Changes in Periphery,"Tursun, C., & Didyk, P. (2022). Perceptual Visibility Model for Temporal Contrast Changes in Periphery. ACM Transactions on Graphics, 42(2), 1–16. https://doi.org/10.1145/3564241
",10.1145/3564241,"Modeling perception is critical for many applications and developments in computer graphics to optimize and evaluate content generation techniques. Most of the work to date has focused on central (foveal) vision. However, this is insufficient for novel wide-field-of-view display devices, such as virtual and augmented reality headsets. Furthermore, the perceptual models proposed for the fovea do not readily extend to the off-center, peripheral visual field, where human perception is drastically different. In this article, we focus on modeling the temporal aspect of visual perception in the periphery. We present new psychophysical experiments that measure the sensitivity of human observers to different spatio-temporal stimuli across a wide field of view. We use the collected data to build a perceptual model for the visibility of temporal changes at different eccentricities in complex video content. Finally, we discuss, demonstrate, and evaluate several problems that can be addressed using our technique. First, we show how our model enables injecting new content into the periphery without distracting the viewer, and we discuss the link between the model and human attention. Second, we demonstrate how foveated rendering methods can be evaluated and optimized to limit the visibility of temporal aliasing.","A8732S Psychophysics of vision, visual perception, binocular vision;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130B Graphics techniques;C6130V Virtual reality",augmented reality headsets;central vision;complex video content;computer graphics;content generation techniques;different eccentricities;different spatio-temporal stimuli;human attention;human observers;human perception;modeling perception;novel wide-field-of-view display devices;perceptual model;perceptual visibility model;peripheral visual field;temporal aliasing;temporal aspect;temporal changes;temporal contrast changes;virtual reality headsets;visual perception,augmented reality;display devices;rendering (computer graphics);spatiotemporal phenomena;virtual reality;visual perception,2023,Journal article (JA),ACM Trans. Graph. (USA),"(1) Tursun, C.; (2) Didyk, P.; ","(1) University of Groningen, Netherlands; (2) Universita&#768; della Svizzera italiana, Switzerland; ",ACM,-1,"[""display devices"", ""rendering"", ""spatiotemporal phenomena"", ""visual perception""]","[""display devices"", ""rendering"", ""spatiotemporal phenomena"", ""visual perception""]",display devices;rendering;spatiotemporal phenomena;visual perception,geospatial;display technology;graphics;input,technology;displays,geospatial;display technology;graphics;input,technology;displays,display_devices rendering spatiotemporal_phenomena visual_perception augmented_reality_headsets central_vision complex_video_content computer_graphics content_generation_techniques different_eccentricities different_spatio temporal_stimuli human_attention human_observers human_perception modeling_perception novel_wide field of view_display_devices perceptual_model perceptual_visibility_model peripheral_visual_field temporal_aliasing temporal_aspect temporal_changes temporal_contrast_changes virtual_reality_headsets visual_perception a8732s_psychophysics_of_vision _visual_perception _binocular_vision c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality geospatial display_technology graphics input,display_devices rendering spatiotemporal_phenomena visual_perception,augmented_reality_headsets central_vision complex_video_content computer_graphics content_generation_techniques different_eccentricities different_spatio temporal_stimuli human_attention human_observers human_perception modeling_perception novel_wide field of view_display_devices perceptual_model perceptual_visibility_model peripheral_visual_field temporal_aliasing temporal_aspect temporal_changes temporal_contrast_changes virtual_reality_headsets visual_perception,modeling perception critical many application development computer graphic optimize evaluate content generation technique work date focused central foveal vision however insufficient novel wide field view display device virtual augmented reality headset furthermore perceptual model proposed fovea readily extend center peripheral visual field human perception drastically different article focus modeling temporal aspect visual perception periphery present new psychophysical experiment measure sensitivity human observer different spatio temporal stimulus across wide field view use collected data build perceptual model visibility temporal change different eccentricity complex video content finally discus demonstrate evaluate several problem addressed using technique first show model enables injecting new content periphery without distracting viewer discus link model human attention second demonstrate foveated rendering method evaluated optimized limit visibility temporal aliasing,display_devices rendering spatiotemporal_phenomena visual_perception augmented_reality_headsets central_vision complex_video_content computer_graphics content_generation_techniques different_eccentricities different_spatio temporal_stimuli human_attention human_observers human_perception modeling_perception novel_wide field of view_display_devices perceptual_model perceptual_visibility_model peripheral_visual_field temporal_aliasing temporal_aspect temporal_changes temporal_contrast_changes virtual_reality_headsets visual_perception a8732s_psychophysics_of_vision _visual_perception _binocular_vision c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality geospatial display_technology graphics input modeling perception critical many application development computer graphic optimize evaluate content generation technique work date focused central foveal vision however insufficient novel wide field view display device virtual augmented reality headset furthermore perceptual model proposed fovea readily extend center peripheral visual field human perception drastically different article focus modeling temporal aspect visual perception periphery present new psychophysical experiment measure sensitivity human observer different spatio temporal stimulus across wide field view use collected data build perceptual model visibility temporal change different eccentricity complex video content finally discus demonstrate evaluate several problem addressed using technique first show model enables injecting new content periphery without distracting viewer discus link model human attention second demonstrate foveated rendering method evaluated optimized limit visibility temporal aliasing,modeling perception critical many application development computer graphic optimize evaluate content generation technique work date focused central foveal vision however insufficient novel wide field view display device virtual augmented reality headset furthermore perceptual model proposed fovea readily extend center peripheral visual field human perception drastically different article focus modeling temporal aspect visual perception periphery present new psychophysical experiment measure sensitivity human observer different spatio temporal stimulus across wide field view use collected data build perceptual model visibility temporal change different eccentricity complex video content finally discus demonstrate evaluate several problem addressed using technique first show model enables injecting new content periphery without distracting viewer discus link model human attention second demonstrate foveated rendering method evaluated optimized limit visibility temporal aliasingdisplay_devices rendering spatiotemporal_phenomena visual_perceptionaugmented_reality_headsets central_vision complex_video_content computer_graphics content_generation_techniques different_eccentricities different_spatio temporal_stimuli human_attention human_observers human_perception modeling_perception novel_wide field of view_display_devices perceptual_model perceptual_visibility_model peripheral_visual_field temporal_aliasing temporal_aspect temporal_changes temporal_contrast_changes virtual_reality_headsets visual_perception
264,Task offloading and parameters optimization of MAR in multi-access edge computing,"Li, Y., Zhu, X., Song, S., Ma, S., Yang, F., & Zhai, L. (2023). Task offloading and parameters optimization of MAR in multi-access edge computing. Expert Systems with Applications, 215, 119379. https://doi.org/10.1016/j.eswa.2022.119379
",10.1016/j.eswa.2022.119379,"With the development of mobile augmented reality (MAR) technology, the demand for MAR applications is increasing. However, MAR is rarely used in mobile devices due to its high computational and energy consumption. In this paper, we study the task offloading and parameters optimization of MAR applied to mobile devices in mobile edge computing. Considering the influence of the MAR client energy consumption, service delay and detection accuracy in the task offloading and parameters optimization process, we design a function to evaluate MAR client energy efficiency. The problem of task offloading and parameters optimization is formulated to minimize energy efficiency function under the limitation of MAR task completion time and wireless bandwidth resources. To solve this problem, we propose a server selection and parameters optimization (SSPO) algorithm to realize client task offloading and parameters optimization. The SSPO algorithm first generates priority queue of tasks. Based on the order of priority queue, tasks are offloaded to appropriate mobile edge server according to the analytic hierarchy process. After that, the parameters are calculated and the tasks are redistributed according to the completion time until the energy efficiency function converges. Simulation results show that the proposed algorithm is better than the comparison algorithm. All rights reserved Elsevier.","A8620X Telecommunication systems (energy utilisation);B0260 Optimisation techniques;B6210L Computer communications;B6250F Mobile radio systems;C1180 Optimisation techniques;C5620 Computer networks and techniques;C6130V Virtual reality;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing",appropriate mobile edge server;client task offloading;energy efficiency function converges;high computational energy consumption;MAR applications;MAR client energy consumption;MAR client energy efficiency;MAR task completion time;mobile augmented reality;mobile devices;mobile edge computing;multiaccess edge computing;parameters optimization,augmented reality;edge computing;energy conservation;energy consumption;mobile computing;optimisation;resource allocation;telecommunication power management;telecommunication scheduling,2023,Journal article (JA),Expert Syst. Appl. (Netherlands),"(1) Li, Y.; (1) Zhu, X.; (1) Song, S.; (1) Ma, S.; (1) Yang, F.; (1) Zhai, L.; ","(1) Shandong Normal University, School of Information Science and Engineering, China; ",Elsevier B.V.,-1,"[""edge computing"", ""energy conservation"", ""energy consumption"", ""mobile computing"", ""optimization"", ""resource allocation"", ""telecommunication power management"", ""telecommunication scheduling""]","[""edge computing"", ""energy conservation"", ""energy consumption"", ""mobile computing"", ""optimization"", ""resource allocation"", ""telecommunication power management"", ""telecommunication scheduling""]",edge computing;energy conservation;energy consumption;mobile computing;optimization;resource allocation;telecommunication power management;telecommunication scheduling,farming and natural science;input;business performance metrics;power and energy;telecommunication;developers;geospatial;business planning and management;networks,technology;business;industries,farming and natural science;input;business performance metrics;power and energy;telecommunication;developers;geospatial;business planning and management;networks,technology;business;industries,edge_computing energy_conservation energy_consumption mobile_computing optimization resource_allocation telecommunication_power_management telecommunication_scheduling appropriate_mobile_edge_server client_task_offloading energy_efficiency_function_converges high_computational_energy_consumption mar_applications mar_client_energy_consumption mar_client_energy_efficiency mar_task_completion_time mobile_augmented_reality mobile_devices mobile_edge_computing multiaccess_edge_computing parameters_optimization a8620x_telecommunication_systems_ energy_utilisation b0260_optimisation_techniques b6210l_computer_communications b6250f_mobile_radio_systems c1180_optimisation_techniques c5620_computer_networks_and_techniques c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing farming_and_natural_science input business_performance_metrics power_and_energy telecommunication developers geospatial business_planning_and_management networks,edge_computing energy_conservation energy_consumption mobile_computing optimization resource_allocation telecommunication_power_management telecommunication_scheduling,appropriate_mobile_edge_server client_task_offloading energy_efficiency_function_converges high_computational_energy_consumption mar_applications mar_client_energy_consumption mar_client_energy_efficiency mar_task_completion_time mobile_augmented_reality mobile_devices mobile_edge_computing multiaccess_edge_computing parameters_optimization,development mobile augmented reality mar technology demand mar application increasing however mar rarely used mobile device due high computational energy consumption paper study task offloading parameter optimization mar applied mobile device mobile edge computing considering influence mar client energy consumption service delay detection accuracy task offloading parameter optimization process design function evaluate mar client energy efficiency problem task offloading parameter optimization formulated minimize energy efficiency function limitation mar task completion time wireless bandwidth resource solve problem propose server selection parameter optimization sspo algorithm realize client task offloading parameter optimization sspo algorithm first generates priority queue task based order priority queue task offloaded appropriate mobile edge server according analytic hierarchy process parameter calculated task redistributed according completion time energy efficiency function converges simulation result show proposed algorithm better comparison algorithm right reserved elsevier,edge_computing energy_conservation energy_consumption mobile_computing optimization resource_allocation telecommunication_power_management telecommunication_scheduling appropriate_mobile_edge_server client_task_offloading energy_efficiency_function_converges high_computational_energy_consumption mar_applications mar_client_energy_consumption mar_client_energy_efficiency mar_task_completion_time mobile_augmented_reality mobile_devices mobile_edge_computing multiaccess_edge_computing parameters_optimization a8620x_telecommunication_systems_ energy_utilisation b0260_optimisation_techniques b6210l_computer_communications b6250f_mobile_radio_systems c1180_optimisation_techniques c5620_computer_networks_and_techniques c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing farming_and_natural_science input business_performance_metrics power_and_energy telecommunication developers geospatial business_planning_and_management networks development mobile augmented reality mar technology demand mar application increasing however mar rarely used mobile device due high computational energy consumption paper study task offloading parameter optimization mar applied mobile device mobile edge computing considering influence mar client energy consumption service delay detection accuracy task offloading parameter optimization process design function evaluate mar client energy efficiency problem task offloading parameter optimization formulated minimize energy efficiency function limitation mar task completion time wireless bandwidth resource solve problem propose server selection parameter optimization sspo algorithm realize client task offloading parameter optimization sspo algorithm first generates priority queue task based order priority queue task offloaded appropriate mobile edge server according analytic hierarchy process parameter calculated task redistributed according completion time energy efficiency function converges simulation result show proposed algorithm better comparison algorithm right reserved elsevier,development mobile augmented reality mar technology demand mar application increasing however mar rarely used mobile device due high computational energy consumption paper study task offloading parameter optimization mar applied mobile device mobile edge computing considering influence mar client energy consumption service delay detection accuracy task offloading parameter optimization process design function evaluate mar client energy efficiency problem task offloading parameter optimization formulated minimize energy efficiency function limitation mar task completion time wireless bandwidth resource solve problem propose server selection parameter optimization sspo algorithm realize client task offloading parameter optimization sspo algorithm first generates priority queue task based order priority queue task offloaded appropriate mobile edge server according analytic hierarchy process parameter calculated task redistributed according completion time energy efficiency function converges simulation result show proposed algorithm better comparison algorithm right reserved elsevieredge_computing energy_conservation energy_consumption mobile_computing optimization resource_allocation telecommunication_power_management telecommunication_schedulingappropriate_mobile_edge_server client_task_offloading energy_efficiency_function_converges high_computational_energy_consumption mar_applications mar_client_energy_consumption mar_client_energy_efficiency mar_task_completion_time mobile_augmented_reality mobile_devices mobile_edge_computing multiaccess_edge_computing parameters_optimization
265,Recording a hologram transmitted over a communication channel on one sideband,"Shoydin, S., Odinokov, S., Pazoev, A., Tsyganov, I., & Drozdova, E. (2021). Recording a Hologram Transmitted over a Communication Channel on One Sideband. Applied Sciences, 11(23), 11468. https://doi.org/10.3390/app112311468
",10.3390/app112311468,"The paper presents experimental results on the recording and restoration of 3D holographic frames suitable for transmitting 3D holographic images with the frame rate required for TV images and a resolution of the Full HD standard and higher. The Patent RF No. 2707582 proposed a method for compressing holographic information and transmitting it using a procedure similar to SSB over conventional communication channels. In this work, the holographic information of a 3D portrait of a person, transmitted and received via the Wi-Fi communication channel, was restored in the form of a rainbow hologram, as one of a variety of holograms, by the computer addition of the carrier spatial frequency, and then hologram was actually produced on a photoresist. This technology can be used to create a holographic phototelegraph or, if there is a dynamic holographic display, to create a holographic television and 3D augmented reality.",B6135C Image and video coding;B4350 Holography;B6250 Radio links and equipment;C5260B Computer vision and image processing techniques;C6130V Virtual reality,3D augmented reality;3D holographic frames;3D holographic images;dynamic holographic display;frame rate;Full HD standard;holographic information;holographic phototelegraph;holographic television;rainbow hologram;TV images;Wi-Fi communication channel,augmented reality;holography;image coding;image resolution;image restoration;telecommunication channels;wireless LAN,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Shoydin, S.A.; (3) Odinokov, S.B.; (1) Pazoev, A.L.; (3) Tsyganov, I.K.; (3) Drozdova, E.A.; ","(1) Siberian State University of Geosystems and Technologies, Department of Photonics and Device Engineering, 10 Plakhotnogo St., Russia; (2) Voevodsky Institute of Chemical Kinetics and Combustion, Laboratory of Dispersed Systems, 3 Institutskaya St., Russia; (3) Bauman Moscow State Technical University, Laser and Optoelectronic Systems Department, 5/1 2nd Baumanskaya St., Russia; ",MDPI,-1,"[""holography"", ""image coding"", ""image resolution"", ""image restoration"", ""telecommunication channels"", ""wireless lan""]","[""holography"", ""image coding"", ""image resolution"", ""image restoration"", ""telecommunication channels"", ""wireless lan""]",holography;image coding;image resolution;image restoration;telecommunication channels;wireless lan,construction;computer vision;other;graphics;input;display technology;human-computer interaction;networks,other;displays;end users and user experience;industries;technology,construction;computer vision;other;graphics;input;display technology;human-computer interaction;networks,other;displays;end users and user experience;industries;technology,holography image_coding image_resolution image_restoration telecommunication_channels wireless_lan 3d_augmented_reality 3d_holographic_frames 3d_holographic_images dynamic_holographic_display frame_rate full_hd_standard holographic_information holographic_phototelegraph holographic_television rainbow_hologram tv_images wi fi_communication_channel b6135c_image_and_video_coding b4350_holography b6250_radio_links_and_equipment c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision other graphics input display_technology human computer_interaction networks,holography image_coding image_resolution image_restoration telecommunication_channels wireless_lan,3d_augmented_reality 3d_holographic_frames 3d_holographic_images dynamic_holographic_display frame_rate full_hd_standard holographic_information holographic_phototelegraph holographic_television rainbow_hologram tv_images wi fi_communication_channel,paper present experimental result recording restoration 3d holographic frame suitable transmitting 3d holographic image frame rate required tv image resolution full hd standard higher patent rf 2707582 proposed method compressing holographic information transmitting using procedure similar ssb conventional communication channel work holographic information 3d portrait person transmitted received via wi fi communication channel restored form rainbow hologram one variety hologram computer addition carrier spatial frequency hologram actually produced photoresist technology used create holographic phototelegraph dynamic holographic display create holographic television 3d augmented reality,holography image_coding image_resolution image_restoration telecommunication_channels wireless_lan 3d_augmented_reality 3d_holographic_frames 3d_holographic_images dynamic_holographic_display frame_rate full_hd_standard holographic_information holographic_phototelegraph holographic_television rainbow_hologram tv_images wi fi_communication_channel b6135c_image_and_video_coding b4350_holography b6250_radio_links_and_equipment c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision other graphics input display_technology human computer_interaction networks paper present experimental result recording restoration 3d holographic frame suitable transmitting 3d holographic image frame rate required tv image resolution full hd standard higher patent rf 2707582 proposed method compressing holographic information transmitting using procedure similar ssb conventional communication channel work holographic information 3d portrait person transmitted received via wi fi communication channel restored form rainbow hologram one variety hologram computer addition carrier spatial frequency hologram actually produced photoresist technology used create holographic phototelegraph dynamic holographic display create holographic television 3d augmented reality,paper present experimental result recording restoration 3d holographic frame suitable transmitting 3d holographic image frame rate required tv image resolution full hd standard higher patent rf 2707582 proposed method compressing holographic information transmitting using procedure similar ssb conventional communication channel work holographic information 3d portrait person transmitted received via wi fi communication channel restored form rainbow hologram one variety hologram computer addition carrier spatial frequency hologram actually produced photoresist technology used create holographic phototelegraph dynamic holographic display create holographic television 3d augmented realityholography image_coding image_resolution image_restoration telecommunication_channels wireless_lan3d_augmented_reality 3d_holographic_frames 3d_holographic_images dynamic_holographic_display frame_rate full_hd_standard holographic_information holographic_phototelegraph holographic_television rainbow_hologram tv_images wi fi_communication_channel
266,A Low-Power mmWave Platform for the Internet of Things,"Mazaheri, M., & Abari, O. (2023). A Low-Power mmWave Platform for the Internet of Things. GetMobile: Mobile Computing and Communications, 26(4), 14–18. https://doi.org/10.1145/3583571.3583575
",10.1145/3583571.3583575,"With the advancement of the Internet of Things (IoT), billions of devices will be connected to the Internet, enabling new applications such as digital twin, augmented reality, and smart home. These applications have placed a huge strain on today's wireless network. mmWave technology is promising to solve this problem by providing a large bandwidth over the very-high-frequency spectrum band. However, most mmWave radios and platforms have much higher power consumption than what IoT devices and their applications can afford. Hence, mmWave networks cannot be utilized in most IoT applications today. In this work, we present a novel low-power mmWave platform, which brings this technology to IoT applications. Our approach to design this platform is to take a holistic view and optimize the whole wireless system by considering practical challenges in mmWave communication. Our lowcost and low-power platform not only brings mmWave communication to IoT applications, but also enables researchers that do not have hardware background to work on mmWave research.","A8620X Telecommunication systems (energy utilisation);B6210L Computer communications;B6250 Radio links and equipment;B6250F Mobile radio systems;C5620D Internet of Things;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",augmented reality;digital twin;higher power consumption;huge strain;IoT applications today;IoT devices;low-power platform;lowcost;mmWave communication;mmWave research;mmWave technology;novel low-power mmWave platform;smart home;very-high-frequency spectrum band;wireless network;wireless system,5G mobile communication;augmented reality;digital twins;Internet of Things;millimetre wave communication;power consumption;telecommunication power management,2022,Journal article (JA),"GetMob., Mob. Comput. Commun. (USA)","(1) Mazaheri, M.; (1) Abari, O.; ","(1) University of California Los Angeles, Los Angeles, CA, United States; ",ACM,-1,"[""5g mobile communication"", ""digital twins"", ""internet of things"", ""millimetre wave communication"", ""power consumption"", ""telecommunication power management""]","[""5g mobile communication"", ""digital twins"", ""internet of things"", ""millimetre wave communication"", ""power consumption"", ""telecommunication power management""]",5g mobile communication;digital twins;internet of things;millimetre wave communication;power consumption;telecommunication power management,other;input;internet of things;telecommunication;smart cities;device energy management;networks,other;displays;industries;use cases;technology,other;input;internet of things;telecommunication;smart cities;device energy management;networks,other;displays;industries;use cases;technology,5g_mobile_communication digital_twins internet_of_things millimetre_wave_communication power_consumption telecommunication_power_management augmented_reality digital_twin higher_power_consumption huge_strain iot_applications_today iot_devices low power_platform lowcost mmwave_communication mmwave_research mmwave_technology novel_low power_mmwave_platform smart_home very high frequency_spectrum_band wireless_network wireless_system a8620x_telecommunication_systems_ energy_utilisation b6210l_computer_communications b6250_radio_links_and_equipment b6250f_mobile_radio_systems c5620d_internet_of_things c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing other input internet_of_things telecommunication smart_cities device_energy_management networks,5g_mobile_communication digital_twins internet_of_things millimetre_wave_communication power_consumption telecommunication_power_management,augmented_reality digital_twin higher_power_consumption huge_strain iot_applications_today iot_devices low power_platform lowcost mmwave_communication mmwave_research mmwave_technology novel_low power_mmwave_platform smart_home very high frequency_spectrum_band wireless_network wireless_system,advancement internet thing iot billion device connected internet enabling new application digital twin augmented reality smart home application placed huge strain today wireless network mmwave technology promising solve problem providing large bandwidth high frequency spectrum band however mmwave radio platform much higher power consumption iot device application afford hence mmwave network cannot utilized iot application today work present novel low power mmwave platform brings technology iot application approach design platform take holistic view optimize whole wireless system considering practical challenge mmwave communication lowcost low power platform brings mmwave communication iot application also enables researcher hardware background work mmwave research,5g_mobile_communication digital_twins internet_of_things millimetre_wave_communication power_consumption telecommunication_power_management augmented_reality digital_twin higher_power_consumption huge_strain iot_applications_today iot_devices low power_platform lowcost mmwave_communication mmwave_research mmwave_technology novel_low power_mmwave_platform smart_home very high frequency_spectrum_band wireless_network wireless_system a8620x_telecommunication_systems_ energy_utilisation b6210l_computer_communications b6250_radio_links_and_equipment b6250f_mobile_radio_systems c5620d_internet_of_things c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing other input internet_of_things telecommunication smart_cities device_energy_management networks advancement internet thing iot billion device connected internet enabling new application digital twin augmented reality smart home application placed huge strain today wireless network mmwave technology promising solve problem providing large bandwidth high frequency spectrum band however mmwave radio platform much higher power consumption iot device application afford hence mmwave network cannot utilized iot application today work present novel low power mmwave platform brings technology iot application approach design platform take holistic view optimize whole wireless system considering practical challenge mmwave communication lowcost low power platform brings mmwave communication iot application also enables researcher hardware background work mmwave research,advancement internet thing iot billion device connected internet enabling new application digital twin augmented reality smart home application placed huge strain today wireless network mmwave technology promising solve problem providing large bandwidth high frequency spectrum band however mmwave radio platform much higher power consumption iot device application afford hence mmwave network cannot utilized iot application today work present novel low power mmwave platform brings technology iot application approach design platform take holistic view optimize whole wireless system considering practical challenge mmwave communication lowcost low power platform brings mmwave communication iot application also enables researcher hardware background work mmwave research5g_mobile_communication digital_twins internet_of_things millimetre_wave_communication power_consumption telecommunication_power_managementaugmented_reality digital_twin higher_power_consumption huge_strain iot_applications_today iot_devices low power_platform lowcost mmwave_communication mmwave_research mmwave_technology novel_low power_mmwave_platform smart_home very high frequency_spectrum_band wireless_network wireless_system
267,"CultReal&#8212;A Rapid Development Platform for AR Cultural Spaces, with Fused Localization","Morar, A., Băluțoiu, M.-A., Moldoveanu, A., Moldoveanu, F., & Butean, A. (2021). CultReal—A Rapid Development Platform for AR Cultural Spaces, with Fused Localization. Sensors, 21(19), 6618. https://doi.org/10.3390/s21196618
",10.3390/s21196618,"Virtual and augmented reality technologies have known an impressive market evolution due to their potential to provide immersive experiences. However, they still have significant difficulties to enable fully fledged, consumer-ready applications that can handle complex tasks such as multi-user collaboration or time-persistent experiences. In this context, CultReal is a rapid creation and deployment platform for augmented reality (AR), aiming to revitalize cultural spaces. The platform's content management system stores a representation of the environment, together with a database of multimedia objects that can be associated with a location. The localization component fuses data from beacons and from video cameras, providing an accurate estimation of the position and orientation of the visitor's smartphone. A mobile application running the localization component displays the augmented content, which is seamlessly integrated with the real world. The paper focuses on the series of steps required to compute the position and orientation of the user's mobile device, providing a comprehensive evaluation with both virtual and real data. Pilot implementations of the system are also described in the paper, revealing the potential of the platform to enable rapid deployment in new cultural spaces. Offering these functionalities, CultReal will allow for the fast development of AR solutions in any location.","C6130V Virtual reality;C6130G Groupware;C6190V Mobile, ubiquitous and pervasive computing",AR cultural spaces;augmented content;augmented reality;consumer-ready applications;content management system stores;CultReal&#8212;a rapid development platform;deployment platform;fused localization;immersive experiences;impressive market evolution;localization component fuses data;mobile application;multimedia objects;multiuser collaboration;rapid creation;reality technologies;significant difficulties;time-persistent experiences;user;video cameras;visitor,augmented reality;content management;groupware;mobile computing;virtual reality,2021,Journal article (JA),Sensors (Switzerland),"(1) Morar, A.; (1) Ba&#774;lutoiu, M.-A.; (1) Moldoveanu, A.; (1) Moldoveanu, F.; (2) Butean, A.; ","(1) University Politehnica of Bucharest, Faculty of Automatic Control and Computers, Romania; (2) Lucian Blaga University of Sibiu, Faculty of Engineering, Romania; (3) S.C. INDUSTRIAL SOFTWARE S.R.L, Romania; ",MDPI,-1,"[""content management"", ""groupware"", ""mobile computing""]","[""content management"", ""groupware"", ""mobile computing""]",content management;groupware;mobile computing,telecommunication;developers;collaboration,technology;use cases;industries,telecommunication;developers;collaboration,technology;use cases;industries,content_management groupware mobile_computing ar_cultural_spaces augmented_content augmented_reality consumer ready_applications content_management_system_stores cultreal 8212 a_rapid_development_platform deployment_platform fused_localization immersive_experiences impressive_market_evolution localization_component_fuses_data mobile_application multimedia_objects multiuser_collaboration rapid_creation reality_technologies significant_difficulties time persistent_experiences user video_cameras visitor c6130v_virtual_reality c6130g_groupware c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication developers collaboration,content_management groupware mobile_computing,ar_cultural_spaces augmented_content augmented_reality consumer ready_applications content_management_system_stores cultreal 8212 a_rapid_development_platform deployment_platform fused_localization immersive_experiences impressive_market_evolution localization_component_fuses_data mobile_application multimedia_objects multiuser_collaboration rapid_creation reality_technologies significant_difficulties time persistent_experiences user video_cameras visitor,virtual augmented reality technology known impressive market evolution due potential provide immersive experience however still significant difficulty enable fully fledged consumer ready application handle complex task multi user collaboration time persistent experience context cultreal rapid creation deployment platform augmented reality ar aiming revitalize cultural space platform content management system store representation environment together database multimedia object associated location localization component fuse data beacon video camera providing accurate estimation position orientation visitor smartphone mobile application running localization component display augmented content seamlessly integrated real world paper focus series step required compute position orientation user mobile device providing comprehensive evaluation virtual real data pilot implementation system also described paper revealing potential platform enable rapid deployment new cultural space offering functionality cultreal allow fast development ar solution location,content_management groupware mobile_computing ar_cultural_spaces augmented_content augmented_reality consumer ready_applications content_management_system_stores cultreal 8212 a_rapid_development_platform deployment_platform fused_localization immersive_experiences impressive_market_evolution localization_component_fuses_data mobile_application multimedia_objects multiuser_collaboration rapid_creation reality_technologies significant_difficulties time persistent_experiences user video_cameras visitor c6130v_virtual_reality c6130g_groupware c6190v_mobile _ubiquitous_and_pervasive_computing telecommunication developers collaboration virtual augmented reality technology known impressive market evolution due potential provide immersive experience however still significant difficulty enable fully fledged consumer ready application handle complex task multi user collaboration time persistent experience context cultreal rapid creation deployment platform augmented reality ar aiming revitalize cultural space platform content management system store representation environment together database multimedia object associated location localization component fuse data beacon video camera providing accurate estimation position orientation visitor smartphone mobile application running localization component display augmented content seamlessly integrated real world paper focus series step required compute position orientation user mobile device providing comprehensive evaluation virtual real data pilot implementation system also described paper revealing potential platform enable rapid deployment new cultural space offering functionality cultreal allow fast development ar solution location,virtual augmented reality technology known impressive market evolution due potential provide immersive experience however still significant difficulty enable fully fledged consumer ready application handle complex task multi user collaboration time persistent experience context cultreal rapid creation deployment platform augmented reality ar aiming revitalize cultural space platform content management system store representation environment together database multimedia object associated location localization component fuse data beacon video camera providing accurate estimation position orientation visitor smartphone mobile application running localization component display augmented content seamlessly integrated real world paper focus series step required compute position orientation user mobile device providing comprehensive evaluation virtual real data pilot implementation system also described paper revealing potential platform enable rapid deployment new cultural space offering functionality cultreal allow fast development ar solution locationcontent_management groupware mobile_computingar_cultural_spaces augmented_content augmented_reality consumer ready_applications content_management_system_stores cultreal 8212 a_rapid_development_platform deployment_platform fused_localization immersive_experiences impressive_market_evolution localization_component_fuses_data mobile_application multimedia_objects multiuser_collaboration rapid_creation reality_technologies significant_difficulties time persistent_experiences user video_cameras visitor
268,Functional overview of integration of AIML with 5G and beyond the network,"Srinivas, K., Aswini., J., Patro, P., & Kumar, D. (2023). Functional overview of integration of AIML with 5G and beyond the network. 2023 International Conference on Computer Communication and Informatics (ICCCI). https://doi.org/10.1109/iccci56745.2023.10128466
",10.1109/ICCCI56745.2023.10128466,"4 G/LTE mobile networks resolved this issue. Strong physical layer and adaptable network design enable high-capacity mobile broadband Internet. Despite this, the prevalence of bandwidth-intensive technologies like virtual reality, augmented reality, and others has grown. In addition, the rising popularity of new services places astrain on mobile infrastructure. Applications requiring high availability and low latency, such Internet-of-Vehicles or communications between vehicles (IoV). With the advent of the new 5G technology with its massive MIMO radio interface, these problems are no longer a concern. Networks protected by software-defined networking (SDN)and NFV have added a new level of flexibility that allows network operators to serve services with very high requirements across several industries. Network operators must increase and diversify their intelligence to fully comprehend the operational environment, user behaviours, and user demands. A further goal is to become(self-) networkable proactively and effectively. This chapter will look at how AI may help us in the modern world. Next-generation mobile networks that are both efficient and adaptable may benefit greatly from machine learning in the 5G era and beyond. The evolution of AI and ML in network applications.",B6250F Mobile radio systems;B6210L Computer communications;C5620 Computer networks and techniques;C6130S Data security;C6130V Virtual reality,adaptable network design;augmented reality;bandwidth-intensive technologies;high-capacity mobile broadband Internet;Internet-of-Vehicles;massive MIMO radio interface;mobile infrastructure;network applications;network operators;next-generation mobile networks;operational environment;rising popularity;services places;strong physical layer;virtual reality,5G mobile communication;augmented reality;computer network security;Internet;Long Term Evolution;MIMO communication;software defined networking;virtual reality;virtualisation,2023,Conference article (CA),2023 International Conference on Computer Communication and Informatics (ICCCI),"(1) Srinivas, K.; (2) Aswini., J.; (3) Patro, P.; (4) Kumar, D.; ","(1) VNR Vignana Jyothi Institute Of Engineering & Technology, Department Of Information Technology, India; (2) Anna University, Department of AIML, India; (3) Koneru Lakshmaiah Education Foundation, Department of Engineering Mathematics College of Engineering, India; (4) Department of Computer Applications, ABES Engineering College, India; ",IEEE,-1,"[""5g mobile communication"", ""computer network security"", ""internet"", ""long term evolution"", ""mimo communication"", ""software defined networking"", ""virtualization""]","[""5g mobile communication"", ""computer network security"", ""internet"", ""long term evolution"", ""mimo communication"", ""software defined networking"", ""virtualization""]",5g mobile communication;computer network security;internet;long term evolution;mimo communication;software defined networking;virtualization,security;simulation;input;telecommunication;networks,technology;use cases;industries,security;simulation;input;telecommunication;networks,technology;use cases;industries,5g_mobile_communication computer_network_security internet long_term_evolution mimo_communication software_defined_networking virtualization adaptable_network_design augmented_reality bandwidth intensive_technologies high capacity_mobile_broadband_internet internet of vehicles massive_mimo_radio_interface mobile_infrastructure network_applications network_operators next generation_mobile_networks operational_environment rising_popularity services_places strong_physical_layer virtual_reality b6250f_mobile_radio_systems b6210l_computer_communications c5620_computer_networks_and_techniques c6130s_data_security c6130v_virtual_reality security simulation input telecommunication networks,5g_mobile_communication computer_network_security internet long_term_evolution mimo_communication software_defined_networking virtualization,adaptable_network_design augmented_reality bandwidth intensive_technologies high capacity_mobile_broadband_internet internet of vehicles massive_mimo_radio_interface mobile_infrastructure network_applications network_operators next generation_mobile_networks operational_environment rising_popularity services_places strong_physical_layer virtual_reality,4 g lte mobile network resolved issue strong physical layer adaptable network design enable high capacity mobile broadband internet despite prevalence bandwidth intensive technology like virtual reality augmented reality others grown addition rising popularity new service place astrain mobile infrastructure application requiring high availability low latency internet vehicle communication vehicle iov advent new 5g technology massive mimo radio interface problem longer concern network protected software defined networking sdn nfv added new level flexibility allows network operator serve service high requirement across several industry network operator must increase diversify intelligence fully comprehend operational environment user behaviour user demand goal become self networkable proactively effectively chapter look ai may help u modern world next generation mobile network efficient adaptable may benefit greatly machine learning 5g era beyond evolution ai ml network application,5g_mobile_communication computer_network_security internet long_term_evolution mimo_communication software_defined_networking virtualization adaptable_network_design augmented_reality bandwidth intensive_technologies high capacity_mobile_broadband_internet internet of vehicles massive_mimo_radio_interface mobile_infrastructure network_applications network_operators next generation_mobile_networks operational_environment rising_popularity services_places strong_physical_layer virtual_reality b6250f_mobile_radio_systems b6210l_computer_communications c5620_computer_networks_and_techniques c6130s_data_security c6130v_virtual_reality security simulation input telecommunication networks 4 g lte mobile network resolved issue strong physical layer adaptable network design enable high capacity mobile broadband internet despite prevalence bandwidth intensive technology like virtual reality augmented reality others grown addition rising popularity new service place astrain mobile infrastructure application requiring high availability low latency internet vehicle communication vehicle iov advent new 5g technology massive mimo radio interface problem longer concern network protected software defined networking sdn nfv added new level flexibility allows network operator serve service high requirement across several industry network operator must increase diversify intelligence fully comprehend operational environment user behaviour user demand goal become self networkable proactively effectively chapter look ai may help u modern world next generation mobile network efficient adaptable may benefit greatly machine learning 5g era beyond evolution ai ml network application,4 g lte mobile network resolved issue strong physical layer adaptable network design enable high capacity mobile broadband internet despite prevalence bandwidth intensive technology like virtual reality augmented reality others grown addition rising popularity new service place astrain mobile infrastructure application requiring high availability low latency internet vehicle communication vehicle iov advent new 5g technology massive mimo radio interface problem longer concern network protected software defined networking sdn nfv added new level flexibility allows network operator serve service high requirement across several industry network operator must increase diversify intelligence fully comprehend operational environment user behaviour user demand goal become self networkable proactively effectively chapter look ai may help u modern world next generation mobile network efficient adaptable may benefit greatly machine learning 5g era beyond evolution ai ml network application5g_mobile_communication computer_network_security internet long_term_evolution mimo_communication software_defined_networking virtualizationadaptable_network_design augmented_reality bandwidth intensive_technologies high capacity_mobile_broadband_internet internet of vehicles massive_mimo_radio_interface mobile_infrastructure network_applications network_operators next generation_mobile_networks operational_environment rising_popularity services_places strong_physical_layer virtual_reality
269,Multi-Robot Preemptive Task Scheduling with Fault Recovery: A Novel Approach to Automatic Logistics of Smart Factories,"Kalempa, V. C., Piardi, L., Limeira, M., & de Oliveira, A. S. (2021). Multi-Robot Preemptive Task Scheduling with Fault Recovery: A Novel Approach to Automatic Logistics of Smart Factories. Sensors, 21(19), 6536. https://doi.org/10.3390/s21196536
",10.3390/s21196536,"This paper presents a novel approach for Multi-Robot Task Allocation (MRTA) that introduces priority policies on preemptive task scheduling and considers dependencies between tasks, and tolerates faults. The approach is referred to as Multi-Robot Preemptive Task Scheduling with Fault Recovery (MRPF). It considers the interaction between running processes and their tasks for management at each new event, prioritizing the more relevant tasks without idleness and latency. The benefit of this approach is the optimization of production in smart factories, where autonomous robots are being employed to improve efficiency and increase flexibility. The evaluation of MRPF is performed through experimentation in small-scale warehouse logistics, referred to as Augmented Reality to Enhanced Experimentation in Smart Warehouses (ARENA). An analysis of priority scheduling, task preemption, and fault recovery is presented to show the benefits of the proposed approach.",C7180 Retailing and distribution computing;C3390C Mobile robots;C6130V Virtual reality;E0410D Industrial applications of IT;E1010 Production management;E1820 Warehousing and storage,ARENA;augmented reality to enhanced experimentation in smart warehouses;autonomous robots;fault recovery;MRPF;MRTA;multirobot preemptive task scheduling with fault recovery;multirobot task allocation;priority scheduling;small-scale warehouse logistics;smart factories;task preemption,augmented reality;logistics;mobile robots;multi-robot systems;scheduling;task analysis;warehouse automation,2021,Journal article (JA),Sensors (Switzerland),"(1) Kalempa, V.C.; (1) Piardi, L.; (1) Limeira, M.; (1) De Oliveira, A.S.; ","(1) Universidade Tecnolo&#769;gica Federal do Parana&#769;, Graduate Program in Electrical and Computer Engineering, Av. Sete de Setembro, Brazil; (2) Universidade do Estado de Santa Catarina, Department of Information Systems, Luiz Fernando Hastreiter St., Brazil; (3) Instituto Polite&#769;cnico de Braganc&#807;a, Research Center in Digitalization and Intelligent Robotics, Portugal; ",MDPI,-1,"[""logistics"", ""mobile robots"", ""multi-robot systems"", ""scheduling"", ""task analysis"", ""warehouse automation""]","[""logistics"", ""mobile robots"", ""multi-robot systems"", ""scheduling"", ""task analysis"", ""warehouse automation""]",logistics;mobile robots;multi-robot systems;scheduling;task analysis;warehouse automation,education;robotics;human factors;logistics;developers;manufacturing,technology;end users and user experience;business;industries,education;robotics;human factors;logistics;developers;manufacturing,technology;end users and user experience;business;industries,logistics mobile_robots multi robot_systems scheduling task_analysis warehouse_automation arena augmented_reality_to_enhanced_experimentation_in_smart_warehouses autonomous_robots fault_recovery mrpf mrta multirobot_preemptive_task_scheduling_with_fault_recovery multirobot_task_allocation priority_scheduling small scale_warehouse_logistics smart_factories task_preemption c7180_retailing_and_distribution_computing c3390c_mobile_robots c6130v_virtual_reality e0410d_industrial_applications_of_it e1010_production_management e1820_warehousing_and_storage education robotics human_factors logistics developers manufacturing,logistics mobile_robots multi robot_systems scheduling task_analysis warehouse_automation,arena augmented_reality_to_enhanced_experimentation_in_smart_warehouses autonomous_robots fault_recovery mrpf mrta multirobot_preemptive_task_scheduling_with_fault_recovery multirobot_task_allocation priority_scheduling small scale_warehouse_logistics smart_factories task_preemption,paper present novel approach multi robot task allocation mrta introduces priority policy preemptive task scheduling considers dependency task tolerates fault approach referred multi robot preemptive task scheduling fault recovery mrpf considers interaction running process task management new event prioritizing relevant task without idleness latency benefit approach optimization production smart factory autonomous robot employed improve efficiency increase flexibility evaluation mrpf performed experimentation small scale warehouse logistics referred augmented reality enhanced experimentation smart warehouse arena analysis priority scheduling task preemption fault recovery presented show benefit proposed approach,logistics mobile_robots multi robot_systems scheduling task_analysis warehouse_automation arena augmented_reality_to_enhanced_experimentation_in_smart_warehouses autonomous_robots fault_recovery mrpf mrta multirobot_preemptive_task_scheduling_with_fault_recovery multirobot_task_allocation priority_scheduling small scale_warehouse_logistics smart_factories task_preemption c7180_retailing_and_distribution_computing c3390c_mobile_robots c6130v_virtual_reality e0410d_industrial_applications_of_it e1010_production_management e1820_warehousing_and_storage education robotics human_factors logistics developers manufacturing paper present novel approach multi robot task allocation mrta introduces priority policy preemptive task scheduling considers dependency task tolerates fault approach referred multi robot preemptive task scheduling fault recovery mrpf considers interaction running process task management new event prioritizing relevant task without idleness latency benefit approach optimization production smart factory autonomous robot employed improve efficiency increase flexibility evaluation mrpf performed experimentation small scale warehouse logistics referred augmented reality enhanced experimentation smart warehouse arena analysis priority scheduling task preemption fault recovery presented show benefit proposed approach,paper present novel approach multi robot task allocation mrta introduces priority policy preemptive task scheduling considers dependency task tolerates fault approach referred multi robot preemptive task scheduling fault recovery mrpf considers interaction running process task management new event prioritizing relevant task without idleness latency benefit approach optimization production smart factory autonomous robot employed improve efficiency increase flexibility evaluation mrpf performed experimentation small scale warehouse logistics referred augmented reality enhanced experimentation smart warehouse arena analysis priority scheduling task preemption fault recovery presented show benefit proposed approachlogistics mobile_robots multi robot_systems scheduling task_analysis warehouse_automationarena augmented_reality_to_enhanced_experimentation_in_smart_warehouses autonomous_robots fault_recovery mrpf mrta multirobot_preemptive_task_scheduling_with_fault_recovery multirobot_task_allocation priority_scheduling small scale_warehouse_logistics smart_factories task_preemption
270,Research on virtual reality fusion method based on spatial Marker location,"Li, S., Li, D., Du, L., Guo, H., & Wang, H. (2023). Research on virtual reality fusion method based on spatial marker location. Ninth Symposium on Novel Photoelectronic Detection Technology and Applications. https://doi.org/10.1117/12.2666620
",10.1117/12.2666620,"Virtual reality fusion based on augmented reality has become a research hotspot, which is widely used in cultural relics exhibition, medical care and other fields. Spatial projection mapping matrix is the basis for projection equipment to project the prefabricated image onto the target surface. However, in practical operation, it is necessary to determine the relative position relationship between the projection equipment and the actual scene based on complex spatial target calibration. This paper aims to solve the problem of projection information dislocation and realize real-time tracking projection. A high-precision center positioning method based on the invariable characteristic of concentric circle intersection ratio is designed, and the mapping matrix from projection equipment to target is calculated based on PNP method. Finally, the distortion parameters of the lens are used to generate a projection pattern that can offset the projection distortion, so as to optimize the coincidence between the projection pattern and the real object, and achieve efficient and high-precision virtual reality fusion projection. &copy; 2023 SPIE.","405.3 Surveying;723 Computer Software, Data Handling and Applications",Distortions corrections;Fusion methods;High-precision;Mapping matrix;Marker location.;PNP algorithm;Projection patterns;Ratio invariance;Source map reverse distortion correction technology;Virtual-real fusion,Augmented reality;Mapping,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Li, Shengyong; (2) Li, Dongxue; (1) Du, Linqing; (1) Guo, Haoqian; (1) Wang, Hongyu; ","(1) Shenyang University of Technology, Shenyang; 110870, China; (2) Beijing Institute of Computer Technology and Application, Beijing; 100854, China; ",SPIE,-1,"[""mapping""]","[""mapping""]",mapping,navigation,use cases,navigation,use cases,mapping distortions_corrections fusion_methods high precision mapping_matrix marker_location pnp_algorithm projection_patterns ratio_invariance source_map_reverse_distortion_correction_technology virtual real_fusion 405 3_surveying 723_computer_software _data_handling_and_applications navigation,mapping,distortions_corrections fusion_methods high precision mapping_matrix marker_location pnp_algorithm projection_patterns ratio_invariance source_map_reverse_distortion_correction_technology virtual real_fusion,virtual reality fusion based augmented reality become research hotspot widely used cultural relic exhibition medical care field spatial projection mapping matrix basis projection equipment project prefabricated image onto target surface however practical operation necessary determine relative position relationship projection equipment actual scene based complex spatial target calibration paper aim solve problem projection information dislocation realize real time tracking projection high precision center positioning method based invariable characteristic concentric circle intersection ratio designed mapping matrix projection equipment target calculated based pnp method finally distortion parameter lens used generate projection pattern offset projection distortion optimize coincidence projection pattern real object achieve efficient high precision virtual reality fusion projection copy 2023 spie,mapping distortions_corrections fusion_methods high precision mapping_matrix marker_location pnp_algorithm projection_patterns ratio_invariance source_map_reverse_distortion_correction_technology virtual real_fusion 405 3_surveying 723_computer_software _data_handling_and_applications navigation virtual reality fusion based augmented reality become research hotspot widely used cultural relic exhibition medical care field spatial projection mapping matrix basis projection equipment project prefabricated image onto target surface however practical operation necessary determine relative position relationship projection equipment actual scene based complex spatial target calibration paper aim solve problem projection information dislocation realize real time tracking projection high precision center positioning method based invariable characteristic concentric circle intersection ratio designed mapping matrix projection equipment target calculated based pnp method finally distortion parameter lens used generate projection pattern offset projection distortion optimize coincidence projection pattern real object achieve efficient high precision virtual reality fusion projection copy 2023 spie,virtual reality fusion based augmented reality become research hotspot widely used cultural relic exhibition medical care field spatial projection mapping matrix basis projection equipment project prefabricated image onto target surface however practical operation necessary determine relative position relationship projection equipment actual scene based complex spatial target calibration paper aim solve problem projection information dislocation realize real time tracking projection high precision center positioning method based invariable characteristic concentric circle intersection ratio designed mapping matrix projection equipment target calculated based pnp method finally distortion parameter lens used generate projection pattern offset projection distortion optimize coincidence projection pattern real object achieve efficient high precision virtual reality fusion projection copy 2023 spiemappingdistortions_corrections fusion_methods high precision mapping_matrix marker_location pnp_algorithm projection_patterns ratio_invariance source_map_reverse_distortion_correction_technology virtual real_fusion
271,Model-driven Cluster Resource Management for AI Workloads in Edge Clouds,"Liang, Q., Hanafy, W. A., Ali-Eldin, A., & Shenoy, P. (2023). Model-driven Cluster Resource Management for AI Workloads in Edge Clouds. ACM Transactions on Autonomous and Adaptive Systems, 18(1), 1–26. https://doi.org/10.1145/3582080
",10.1145/3582080,"Since emerging edge applications such as Internet of Things (IoT) analytics and augmented reality have tight latency constraints, hardware AI accelerators have been recently proposed to speed up deep neural network (DNN) inference run by these applications. Resource-constrained edge servers and accelerators tend to be multiplexed across multiple IoT applications, introducing the potential for performance interference between latency-sensitive workloads. In this article, we design analytic models to capture the performance of DNN inference workloads on shared edge accelerators, such as GPU and edgeTPU, under different multiplexing and concurrency behaviors. After validating our models using extensive experiments, we use them to design various cluster resource management algorithms to intelligently manage multiple applications on edge accelerators while respecting their latency constraints. We implement a prototype of our system in Kubernetes and show that our system can host 2.3&#215; more DNN applications in heterogeneous multi-tenant edge clusters with no latency violations when compared to traditional knapsack hosting algorithms.","B6210L Computer communications;C5620D Internet of Things;C6130V Virtual reality;C6150J Operating systems;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing;C6264 Neural nets;C7410F Communications computing",AI workloads;augmented reality;cluster resource management algorithms;concurrency behaviors;deep neural network inference run;design analytic models;different multiplexing;DNN applications;DNN inference workloads;edge applications;edge clouds;hardware AI accelerators;heterogeneous multitenant edge clusters;latency constraints;latency violations;latency-sensitive workloads;model-driven cluster resource management;multiple IoT applications;performance interference;shared edge accelerators;Things analytics,augmented reality;cloud computing;deep learning (artificial intelligence);inference mechanisms;Internet of Things;resource allocation;telecommunication computing,2023,Journal article (JA),ACM Trans. Auton. Adapt. Syst. (USA),"(1) Liang, Q.; (1) Hanafy, W.A.; (1) Ali-Eldin, A.; (1) Shenoy, P.; ","(1) University of Massachusetts Amherst, Amherst Center, MA, United States; ",ACM,-1,"[""cloud computing"", ""deep learning (artificial intelligence)"", ""inference mechanisms"", ""internet of things"", ""resource allocation"", ""telecommunication computing""]","[""cloud computing"", ""deep learning (artificial intelligence)"", ""inference mechanisms"", ""internet of things"", ""resource allocation"", ""telecommunication computing""]",cloud computing;deep learning (artificial intelligence);inference mechanisms;internet of things;resource allocation;telecommunication computing,other;input;liberal arts;medical;internet of things;telecommunication;geospatial;artificial intelligence;business planning and management;networks,technology;other;business;industries,other;input;liberal arts;medical;internet of things;telecommunication;geospatial;artificial intelligence;business planning and management;networks,technology;other;business;industries,cloud_computing deep_learning_ artificial_intelligence inference_mechanisms internet_of_things resource_allocation telecommunication_computing ai_workloads augmented_reality cluster_resource_management_algorithms concurrency_behaviors deep_neural_network_inference_run design_analytic_models different_multiplexing dnn_applications dnn_inference_workloads edge_applications edge_clouds hardware_ai_accelerators heterogeneous_multitenant_edge_clusters latency_constraints latency_violations latency sensitive_workloads model driven_cluster_resource_management multiple_iot_applications performance_interference shared_edge_accelerators things_analytics b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c6150j_operating_systems c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets c7410f_communications_computing other input liberal_arts medical internet_of_things telecommunication geospatial artificial_intelligence business_planning_and_management networks,cloud_computing deep_learning_ artificial_intelligence inference_mechanisms internet_of_things resource_allocation telecommunication_computing,ai_workloads augmented_reality cluster_resource_management_algorithms concurrency_behaviors deep_neural_network_inference_run design_analytic_models different_multiplexing dnn_applications dnn_inference_workloads edge_applications edge_clouds hardware_ai_accelerators heterogeneous_multitenant_edge_clusters latency_constraints latency_violations latency sensitive_workloads model driven_cluster_resource_management multiple_iot_applications performance_interference shared_edge_accelerators things_analytics,since emerging edge application internet thing iot analytics augmented reality tight latency constraint hardware ai accelerator recently proposed speed deep neural network dnn inference run application resource constrained edge server accelerator tend multiplexed across multiple iot application introducing potential performance interference latency sensitive workload article design analytic model capture performance dnn inference workload shared edge accelerator gpu edgetpu different multiplexing concurrency behavior validating model using extensive experiment use design various cluster resource management algorithm intelligently manage multiple application edge accelerator respecting latency constraint implement prototype system kubernetes show system host 2 3 215 dnn application heterogeneous multi tenant edge cluster latency violation compared traditional knapsack hosting algorithm,cloud_computing deep_learning_ artificial_intelligence inference_mechanisms internet_of_things resource_allocation telecommunication_computing ai_workloads augmented_reality cluster_resource_management_algorithms concurrency_behaviors deep_neural_network_inference_run design_analytic_models different_multiplexing dnn_applications dnn_inference_workloads edge_applications edge_clouds hardware_ai_accelerators heterogeneous_multitenant_edge_clusters latency_constraints latency_violations latency sensitive_workloads model driven_cluster_resource_management multiple_iot_applications performance_interference shared_edge_accelerators things_analytics b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c6150j_operating_systems c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets c7410f_communications_computing other input liberal_arts medical internet_of_things telecommunication geospatial artificial_intelligence business_planning_and_management networks since emerging edge application internet thing iot analytics augmented reality tight latency constraint hardware ai accelerator recently proposed speed deep neural network dnn inference run application resource constrained edge server accelerator tend multiplexed across multiple iot application introducing potential performance interference latency sensitive workload article design analytic model capture performance dnn inference workload shared edge accelerator gpu edgetpu different multiplexing concurrency behavior validating model using extensive experiment use design various cluster resource management algorithm intelligently manage multiple application edge accelerator respecting latency constraint implement prototype system kubernetes show system host 2 3 215 dnn application heterogeneous multi tenant edge cluster latency violation compared traditional knapsack hosting algorithm,since emerging edge application internet thing iot analytics augmented reality tight latency constraint hardware ai accelerator recently proposed speed deep neural network dnn inference run application resource constrained edge server accelerator tend multiplexed across multiple iot application introducing potential performance interference latency sensitive workload article design analytic model capture performance dnn inference workload shared edge accelerator gpu edgetpu different multiplexing concurrency behavior validating model using extensive experiment use design various cluster resource management algorithm intelligently manage multiple application edge accelerator respecting latency constraint implement prototype system kubernetes show system host 2 3 215 dnn application heterogeneous multi tenant edge cluster latency violation compared traditional knapsack hosting algorithmcloud_computing deep_learning_ artificial_intelligence inference_mechanisms internet_of_things resource_allocation telecommunication_computingai_workloads augmented_reality cluster_resource_management_algorithms concurrency_behaviors deep_neural_network_inference_run design_analytic_models different_multiplexing dnn_applications dnn_inference_workloads edge_applications edge_clouds hardware_ai_accelerators heterogeneous_multitenant_edge_clusters latency_constraints latency_violations latency sensitive_workloads model driven_cluster_resource_management multiple_iot_applications performance_interference shared_edge_accelerators things_analytics
272,Examining the Impact of Teaching Electronics Fundamentals in different Learning Environments on Student's Conceptual Knowledge,"Kaur, R., Mantri, A., Nagabhushan, P., & Singh, G. (2023). Examining the Impact of Teaching Electronics Fundamentals in different Learning Environments on Student’s Conceptual Knowledge. 2023 2nd Edition of IEEE Delhi Section Flagship Conference (DELCON). https://doi.org/10.1109/delcon57910.2023.10127276
",10.1109/DELCON57910.2023.10127276,"Electronics Engineering is impeded when fundamental concepts are taught without practical experience. Teachers of electronics lab courses had to deal with this difficulty during the pandemic. Although live simulations and video capture were alternatives to this problem, practical expertise was lacking. In order to close this gap, engineering education's technical advancement serves as a catalyst. In order to keep students engaged even when they are studying at home, engineering education today utilizes labs, augmented reality, and virtual reality applications. The implications of teaching a basic electronics course to students in various learning contexts are presented in this study. One group took the course online, while another group studied in a hybrid format. While online students have studied only in a virtual setting, blended learning students have exposure to subject through online mode, face-to-face instruction, virtual laboratories, and practical kits. According to the findings, students who studied in a hybrid mode had a greater conceptual grasp than those who studied online. The crucial aspect to note in this scenario is that, in order to increase learning motivation and engagement, students who took a basic electronics course online completed hands-on projects while at home.",B0120 Education and training;C0220 Computing education and training;C6130V Virtual reality;C7410D Electronic engineering computing;C7810C Computer-aided instruction,augmented reality;basic electronics course online;blended learning students;Electronics Engineering;electronics lab courses;engineering education today;face-to-face instruction;fundamental concepts;hybrid format;learning contexts;learning motivation;live simulations;online mode;online students;practical expertise;practical kits;student conceptual knowledge;teaching electronics fundamentals;video capture;virtual laboratories;virtual reality applications;virtual setting,augmented reality;blended learning;educational courses;electronic engineering computing;electronic engineering education;engineering education;teaching;virtual reality,2023,Conference article (CA),2023 2nd Edition of IEEE Delhi Section Flagship Conference (DELCON),"(1) Kaur, R.; (1) Mantri, A.; (2) Nagabhushan, P.; (1) Singh, G.; ","(1) Chitkara University, India; (2) St. Mary MacKillop College, Department of Psychology, Australia; ",IEEE,-1,"[""blended learning"", ""educational courses"", ""electronic engineering computing"", ""electronic engineering education"", ""engineering education"", ""teaching""]","[""blended learning"", ""educational courses"", ""electronic engineering computing"", ""electronic engineering education"", ""engineering education"", ""teaching""]",blended learning;educational courses;electronic engineering computing;electronic engineering education;engineering education;teaching,other;education;medical;optics;engineering,technology;other;displays;industries,other;education;medical;optics;engineering,technology;other;displays;industries,blended_learning educational_courses electronic_engineering_computing electronic_engineering_education engineering_education teaching augmented_reality basic_electronics_course_online blended_learning_students electronics_engineering electronics_lab_courses engineering_education_today face to face_instruction fundamental_concepts hybrid_format learning_contexts learning_motivation live_simulations online_mode online_students practical_expertise practical_kits student_conceptual_knowledge teaching_electronics_fundamentals video_capture virtual_laboratories virtual_reality_applications virtual_setting b0120_education_and_training c0220_computing_education_and_training c6130v_virtual_reality c7410d_electronic_engineering_computing c7810c_computer aided_instruction other education medical optics engineering,blended_learning educational_courses electronic_engineering_computing electronic_engineering_education engineering_education teaching,augmented_reality basic_electronics_course_online blended_learning_students electronics_engineering electronics_lab_courses engineering_education_today face to face_instruction fundamental_concepts hybrid_format learning_contexts learning_motivation live_simulations online_mode online_students practical_expertise practical_kits student_conceptual_knowledge teaching_electronics_fundamentals video_capture virtual_laboratories virtual_reality_applications virtual_setting,electronics engineering impeded fundamental concept taught without practical experience teacher electronics lab course deal difficulty pandemic although live simulation video capture alternative problem practical expertise lacking order close gap engineering education technical advancement serf catalyst order keep student engaged even studying home engineering education today utilizes lab augmented reality virtual reality application implication teaching basic electronics course student various learning context presented study one group took course online another group studied hybrid format online student studied virtual setting blended learning student exposure subject online mode face face instruction virtual laboratory practical kit according finding student studied hybrid mode greater conceptual grasp studied online crucial aspect note scenario order increase learning motivation engagement student took basic electronics course online completed hand project home,blended_learning educational_courses electronic_engineering_computing electronic_engineering_education engineering_education teaching augmented_reality basic_electronics_course_online blended_learning_students electronics_engineering electronics_lab_courses engineering_education_today face to face_instruction fundamental_concepts hybrid_format learning_contexts learning_motivation live_simulations online_mode online_students practical_expertise practical_kits student_conceptual_knowledge teaching_electronics_fundamentals video_capture virtual_laboratories virtual_reality_applications virtual_setting b0120_education_and_training c0220_computing_education_and_training c6130v_virtual_reality c7410d_electronic_engineering_computing c7810c_computer aided_instruction other education medical optics engineering electronics engineering impeded fundamental concept taught without practical experience teacher electronics lab course deal difficulty pandemic although live simulation video capture alternative problem practical expertise lacking order close gap engineering education technical advancement serf catalyst order keep student engaged even studying home engineering education today utilizes lab augmented reality virtual reality application implication teaching basic electronics course student various learning context presented study one group took course online another group studied hybrid format online student studied virtual setting blended learning student exposure subject online mode face face instruction virtual laboratory practical kit according finding student studied hybrid mode greater conceptual grasp studied online crucial aspect note scenario order increase learning motivation engagement student took basic electronics course online completed hand project home,electronics engineering impeded fundamental concept taught without practical experience teacher electronics lab course deal difficulty pandemic although live simulation video capture alternative problem practical expertise lacking order close gap engineering education technical advancement serf catalyst order keep student engaged even studying home engineering education today utilizes lab augmented reality virtual reality application implication teaching basic electronics course student various learning context presented study one group took course online another group studied hybrid format online student studied virtual setting blended learning student exposure subject online mode face face instruction virtual laboratory practical kit according finding student studied hybrid mode greater conceptual grasp studied online crucial aspect note scenario order increase learning motivation engagement student took basic electronics course online completed hand project homeblended_learning educational_courses electronic_engineering_computing electronic_engineering_education engineering_education teachingaugmented_reality basic_electronics_course_online blended_learning_students electronics_engineering electronics_lab_courses engineering_education_today face to face_instruction fundamental_concepts hybrid_format learning_contexts learning_motivation live_simulations online_mode online_students practical_expertise practical_kits student_conceptual_knowledge teaching_electronics_fundamentals video_capture virtual_laboratories virtual_reality_applications virtual_setting
273,"Digital Transformation, Applications, and Vulnerabilities in Maritime and Shipbuilding Ecosystems","Diaz, R., Smith, K., Bertagna, S., & Bucci, V. (2023). Digital Transformation, Applications, and Vulnerabilities in Maritime and Shipbuilding Ecosystems. Procedia Computer Science, 217, 1396–1405. https://doi.org/10.1016/j.procs.2022.12.338
",10.1016/j.procs.2022.12.338,"The evolution of maritime and shipbuilding supply chains toward digital ecosystems increases operational complexity and needs reliable communication and coordination. As labor and suppliers shift to digital platforms, interconnection, information transparency, and decentralized choices become ubiquitous. In this sense, Industry 4.0 enables ""smart digitalization"" in these environments. Many applications exist in two distinct but interrelated areas related to shipbuilding design and shipyard operational performance. New digital tools, such as virtual prototypes and augmented reality, begin to be used in the design phases, during the commissioning/quality control activities, and for training workers and crews. An application relates to using Virtual Prototypes and Augmented Reality during all the design and construction phases. Another application relates to the cybersecurity protection of operational networks that support shipbuilding supply chains that ensures the flow of material and labor to the shipyards. This protection requires a holistic approach to evaluate their vulnerability and understand ripple effects. This paper presents the applications of Industry 4.0 for the areas mentioned above. The first case in shipbuilding design is an example of how the virtual prototype of a ship, together with wearable devices enabling augmented reality, can be used for the quality control of the construction of ship systems. For the second case, we propose developing an artificial intelligence-based cybersecurity supply network framework that characterizes and monitors shipbuilding supply networks and determines ripple effects from disruptions caused by cyberattacks. This framework extends a novel risk management framework developed by Diaz and Smith and Smith and Diaz that considers complex tiered networks. All rights reserved Elsevier.",C7480 Production engineering computing;C6130S Data security;C6130V Virtual reality;C6210 Knowledge based systems;E0120M Human resource management;E0250 Education and training;E0410D Industrial applications of IT;E1010 Production management;E1400 Design;E3650H Ship building and marine industry,artificial intelligence;augmented reality;commissioning;cyberattacks;cybersecurity protection;cybersecurity supply network;digital ecosystems;digital platforms;digital tools;digital transformation;Industry 4.0;information transparency;maritime ecosystem;operational networks;quality control;ripple effects;risk management;shipbuilding design;shipbuilding supply chains;shipbuilding supply networks;shipyard operational performance;smart digitalization;virtual prototype;vulnerability;worker training,artificial intelligence;augmented reality;computer crime;design engineering;industrial training;marine engineering;personnel;production engineering computing;quality control;risk management;shipbuilding industry;supply chain management,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Diaz, R.; (1) Smith, K.; (2) Bertagna, S.; (2) Bucci, V.; ","(1) Old Dominion University, Norfolk, VA 23529, United States; (2) University of Trieste, Italy; ",Elsevier B.V.,-1,"[""artificial intelligence"", ""computer crime"", ""design engineering"", ""industrial training"", ""marine engineering"", ""personnel"", ""production engineering computing"", ""quality control"", ""risk management"", ""shipbuilding industry"", ""supply chain management""]","[""artificial intelligence"", ""computer crime"", ""design engineering"", ""industrial training"", ""marine engineering"", ""personnel"", ""production engineering computing"", ""quality control"", ""risk management"", ""shipbuilding industry"", ""supply chain management""]",artificial intelligence;computer crime;design engineering;industrial training;marine engineering;personnel;production engineering computing;quality control;risk management;shipbuilding industry;supply chain management,"farming and natural science;manufacturing;security;liberal arts;inspection, safety and quality;training;logistics;engineering;human-computer interaction;marine;artificial intelligence;human resources",business;end users and user experience;industries;use cases;technology,"farming and natural science;manufacturing;security;liberal arts;inspection, safety and quality;training;logistics;engineering;human-computer interaction;marine;artificial intelligence;human resources",business;end users and user experience;industries;use cases;technology,artificial_intelligence computer_crime design_engineering industrial_training marine_engineering personnel production_engineering_computing quality_control risk_management shipbuilding_industry supply_chain_management artificial_intelligence augmented_reality commissioning cyberattacks cybersecurity_protection cybersecurity_supply_network digital_ecosystems digital_platforms digital_tools digital_transformation industry_4 0 information_transparency maritime_ecosystem operational_networks quality_control ripple_effects risk_management shipbuilding_design shipbuilding_supply_chains shipbuilding_supply_networks shipyard_operational_performance smart_digitalization virtual_prototype vulnerability worker_training c7480_production_engineering_computing c6130s_data_security c6130v_virtual_reality c6210_knowledge_based_systems e0120m_human_resource_management e0250_education_and_training e0410d_industrial_applications_of_it e1010_production_management e1400_design e3650h_ship_building_and_marine_industry farming_and_natural_science manufacturing security liberal_arts inspection _safety_and_quality training logistics engineering human computer_interaction marine artificial_intelligence human_resources,artificial_intelligence computer_crime design_engineering industrial_training marine_engineering personnel production_engineering_computing quality_control risk_management shipbuilding_industry supply_chain_management,artificial_intelligence augmented_reality commissioning cyberattacks cybersecurity_protection cybersecurity_supply_network digital_ecosystems digital_platforms digital_tools digital_transformation industry_4 0 information_transparency maritime_ecosystem operational_networks quality_control ripple_effects risk_management shipbuilding_design shipbuilding_supply_chains shipbuilding_supply_networks shipyard_operational_performance smart_digitalization virtual_prototype vulnerability worker_training,evolution maritime shipbuilding supply chain toward digital ecosystem increase operational complexity need reliable communication coordination labor supplier shift digital platform interconnection information transparency decentralized choice become ubiquitous sense industry 4 0 enables smart digitalization environment many application exist two distinct interrelated area related shipbuilding design shipyard operational performance new digital tool virtual prototype augmented reality begin used design phase commissioning quality control activity training worker crew application relates using virtual prototype augmented reality design construction phase another application relates cybersecurity protection operational network support shipbuilding supply chain ensures flow material labor shipyard protection requires holistic approach evaluate vulnerability understand ripple effect paper present application industry 4 0 area mentioned first case shipbuilding design example virtual prototype ship together wearable device enabling augmented reality used quality control construction ship system second case propose developing artificial intelligence based cybersecurity supply network framework characterizes monitor shipbuilding supply network determines ripple effect disruption caused cyberattacks framework extends novel risk management framework developed diaz smith smith diaz considers complex tiered network right reserved elsevier,artificial_intelligence computer_crime design_engineering industrial_training marine_engineering personnel production_engineering_computing quality_control risk_management shipbuilding_industry supply_chain_management artificial_intelligence augmented_reality commissioning cyberattacks cybersecurity_protection cybersecurity_supply_network digital_ecosystems digital_platforms digital_tools digital_transformation industry_4 0 information_transparency maritime_ecosystem operational_networks quality_control ripple_effects risk_management shipbuilding_design shipbuilding_supply_chains shipbuilding_supply_networks shipyard_operational_performance smart_digitalization virtual_prototype vulnerability worker_training c7480_production_engineering_computing c6130s_data_security c6130v_virtual_reality c6210_knowledge_based_systems e0120m_human_resource_management e0250_education_and_training e0410d_industrial_applications_of_it e1010_production_management e1400_design e3650h_ship_building_and_marine_industry farming_and_natural_science manufacturing security liberal_arts inspection _safety_and_quality training logistics engineering human computer_interaction marine artificial_intelligence human_resources evolution maritime shipbuilding supply chain toward digital ecosystem increase operational complexity need reliable communication coordination labor supplier shift digital platform interconnection information transparency decentralized choice become ubiquitous sense industry 4 0 enables smart digitalization environment many application exist two distinct interrelated area related shipbuilding design shipyard operational performance new digital tool virtual prototype augmented reality begin used design phase commissioning quality control activity training worker crew application relates using virtual prototype augmented reality design construction phase another application relates cybersecurity protection operational network support shipbuilding supply chain ensures flow material labor shipyard protection requires holistic approach evaluate vulnerability understand ripple effect paper present application industry 4 0 area mentioned first case shipbuilding design example virtual prototype ship together wearable device enabling augmented reality used quality control construction ship system second case propose developing artificial intelligence based cybersecurity supply network framework characterizes monitor shipbuilding supply network determines ripple effect disruption caused cyberattacks framework extends novel risk management framework developed diaz smith smith diaz considers complex tiered network right reserved elsevier,evolution maritime shipbuilding supply chain toward digital ecosystem increase operational complexity need reliable communication coordination labor supplier shift digital platform interconnection information transparency decentralized choice become ubiquitous sense industry 4 0 enables smart digitalization environment many application exist two distinct interrelated area related shipbuilding design shipyard operational performance new digital tool virtual prototype augmented reality begin used design phase commissioning quality control activity training worker crew application relates using virtual prototype augmented reality design construction phase another application relates cybersecurity protection operational network support shipbuilding supply chain ensures flow material labor shipyard protection requires holistic approach evaluate vulnerability understand ripple effect paper present application industry 4 0 area mentioned first case shipbuilding design example virtual prototype ship together wearable device enabling augmented reality used quality control construction ship system second case propose developing artificial intelligence based cybersecurity supply network framework characterizes monitor shipbuilding supply network determines ripple effect disruption caused cyberattacks framework extends novel risk management framework developed diaz smith smith diaz considers complex tiered network right reserved elsevierartificial_intelligence computer_crime design_engineering industrial_training marine_engineering personnel production_engineering_computing quality_control risk_management shipbuilding_industry supply_chain_managementartificial_intelligence augmented_reality commissioning cyberattacks cybersecurity_protection cybersecurity_supply_network digital_ecosystems digital_platforms digital_tools digital_transformation industry_4 0 information_transparency maritime_ecosystem operational_networks quality_control ripple_effects risk_management shipbuilding_design shipbuilding_supply_chains shipbuilding_supply_networks shipyard_operational_performance smart_digitalization virtual_prototype vulnerability worker_training
274,Self-supervised Multi-Modal Video Forgery Attack Detection,"Zhao, C., Li, X., & Younes, R. (2023). Self-supervised Multi-Modal Video Forgery Attack Detection. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118664
",10.1109/WCNC55385.2023.10118664,"Video forgery attacks threaten surveillance systems by replacing the video captures with unrealistic synthesis, which can be powered by the latest augmented reality and virtual reality technologies. From the machine perception aspect, visual objects often have RF signatures that are naturally synchronized with them during recording. In contrast to video captures, the RF signatures are more difficult to attack given their concealed and ubiquitous nature. In this work, we investigate multimodal video forgery attack detection methods using both visual and wireless modalities. Since wireless signal-based human perception is environmentally sensitive, we propose a self-supervised training strategy to enable the system to work without external annotation and thus adapt to different environments. Our method achieves a perfect human detection accuracy and a high forgery attack detection accuracy of 94.38% which is comparable with supervised methods. The code is publicly available at: https://github.com/ChuiZhao/Secure-Mask.git","B6135 Optical, image and video signal processing;B6210L Computer communications;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130S Data security;C6130V Virtual reality",attack detection methods;concealed nature;high forgery attack detection accuracy;latest augmented reality;machine perception aspect;perfect human detection accuracy;RF signatures;self-supervised multimodal video forgery attack detection;self-supervised training strategy;supervised methods;surveillance systems;ubiquitous nature;unrealistic synthesis;video captures;video forgery attacks;virtual reality technologies;visual modalities;visual objects;wireless modalities;wireless signal-based human perception,augmented reality;computer network security;feature extraction;learning (artificial intelligence);object detection;supervised learning;video signal processing;virtual reality,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Zhao, C.; (2) Li, X.; (3) Younes, R.; ","(1) University of Michigan, Department of Electrical and Computer Engineering, United States; (2) Carnegia Mellon University, Department of Electrical and Computer Engineering, United States; (3) Duke University, Department of Electrical and Computer Engineering, United States; ",IEEE,-1,"[""computer network security"", ""feature extraction"", ""learning algorithms"", ""object detection"", ""supervised learning"", ""video signal processing""]","[""computer network security"", ""feature extraction"", ""learning algorithms"", ""object detection"", ""supervised learning"", ""video signal processing""]",computer network security;feature extraction;learning algorithms;object detection;supervised learning;video signal processing,computer vision;semiconductors;security;medical;chemical;sensors;data;artificial intelligence,technology;industries,computer vision;semiconductors;security;medical;chemical;sensors;data;artificial intelligence,technology;industries,computer_network_security feature_extraction learning_algorithms object_detection supervised_learning video_signal_processing attack_detection_methods concealed_nature high_forgery_attack_detection_accuracy latest_augmented_reality machine_perception_aspect perfect_human_detection_accuracy rf_signatures self supervised_multimodal_video_forgery_attack_detection self supervised_training_strategy supervised_methods surveillance_systems ubiquitous_nature unrealistic_synthesis video_captures video_forgery_attacks virtual_reality_technologies visual_modalities visual_objects wireless_modalities wireless_signal based_human_perception b6135_optical _image_and_video_signal_processing b6210l_computer_communications c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130s_data_security c6130v_virtual_reality computer_vision semiconductors security medical chemical sensors data artificial_intelligence,computer_network_security feature_extraction learning_algorithms object_detection supervised_learning video_signal_processing,attack_detection_methods concealed_nature high_forgery_attack_detection_accuracy latest_augmented_reality machine_perception_aspect perfect_human_detection_accuracy rf_signatures self supervised_multimodal_video_forgery_attack_detection self supervised_training_strategy supervised_methods surveillance_systems ubiquitous_nature unrealistic_synthesis video_captures video_forgery_attacks virtual_reality_technologies visual_modalities visual_objects wireless_modalities wireless_signal based_human_perception,video forgery attack threaten surveillance system replacing video capture unrealistic synthesis powered latest augmented reality virtual reality technology machine perception aspect visual object often rf signature naturally synchronized recording contrast video capture rf signature difficult attack given concealed ubiquitous nature work investigate multimodal video forgery attack detection method using visual wireless modality since wireless signal based human perception environmentally sensitive propose self supervised training strategy enable system work without external annotation thus adapt different environment method achieves perfect human detection accuracy high forgery attack detection accuracy 94 38 comparable supervised method code publicly available http github com chuizhao secure mask git,computer_network_security feature_extraction learning_algorithms object_detection supervised_learning video_signal_processing attack_detection_methods concealed_nature high_forgery_attack_detection_accuracy latest_augmented_reality machine_perception_aspect perfect_human_detection_accuracy rf_signatures self supervised_multimodal_video_forgery_attack_detection self supervised_training_strategy supervised_methods surveillance_systems ubiquitous_nature unrealistic_synthesis video_captures video_forgery_attacks virtual_reality_technologies visual_modalities visual_objects wireless_modalities wireless_signal based_human_perception b6135_optical _image_and_video_signal_processing b6210l_computer_communications c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130s_data_security c6130v_virtual_reality computer_vision semiconductors security medical chemical sensors data artificial_intelligence video forgery attack threaten surveillance system replacing video capture unrealistic synthesis powered latest augmented reality virtual reality technology machine perception aspect visual object often rf signature naturally synchronized recording contrast video capture rf signature difficult attack given concealed ubiquitous nature work investigate multimodal video forgery attack detection method using visual wireless modality since wireless signal based human perception environmentally sensitive propose self supervised training strategy enable system work without external annotation thus adapt different environment method achieves perfect human detection accuracy high forgery attack detection accuracy 94 38 comparable supervised method code publicly available http github com chuizhao secure mask git,video forgery attack threaten surveillance system replacing video capture unrealistic synthesis powered latest augmented reality virtual reality technology machine perception aspect visual object often rf signature naturally synchronized recording contrast video capture rf signature difficult attack given concealed ubiquitous nature work investigate multimodal video forgery attack detection method using visual wireless modality since wireless signal based human perception environmentally sensitive propose self supervised training strategy enable system work without external annotation thus adapt different environment method achieves perfect human detection accuracy high forgery attack detection accuracy 94 38 comparable supervised method code publicly available http github com chuizhao secure mask gitcomputer_network_security feature_extraction learning_algorithms object_detection supervised_learning video_signal_processingattack_detection_methods concealed_nature high_forgery_attack_detection_accuracy latest_augmented_reality machine_perception_aspect perfect_human_detection_accuracy rf_signatures self supervised_multimodal_video_forgery_attack_detection self supervised_training_strategy supervised_methods surveillance_systems ubiquitous_nature unrealistic_synthesis video_captures video_forgery_attacks virtual_reality_technologies visual_modalities visual_objects wireless_modalities wireless_signal based_human_perception
275,Computer-based learning: 3D visualization and animation as content development for digital learning materials for traditional Indonesian cloth (Songket Palembang),"Sari, I. P., Permana, F. C., Firmansyah, F. H., & Hernawan, A. H. (2021). Computer-based learning: 3D visualization and animation as content development for digital learning materials for traditional Indonesian cloth (Songket Palembang). Journal of Physics: Conference Series, 1987(1), 012003. https://doi.org/10.1088/1742-6596/1987/1/012003
",10.1088/1742-6596/1987/1/012003,"The animation is currently developing very rapidly, especially in 3D animation. Animated 3D visualization not only develops in the field of film, but also develops in digital-based learning such as interactive applications, presentation slides, e-books, and games, as well as supporting content for immersive technology, such as Augmented Reality, Virtual Reality, Mix Reality, and others. The development of 3D animation nowadays, but not accompanied by the use of animation as the delivery of information with local cultural content. The young generation's lack of interest in local cultural arts is accompanied by a lack of digital learning materials and the delivery of interesting information for the younger generation. Therefore, the researcher aims to create 3D animated visualization assets that can motivate students to learn Indonesian cultural arts. Researchers applying the method Subdivision Surface, UV-mapping, 3d Painting, and walk cycle animation in the 3D visualization animation production process. The final result of this research is 3D Visualization and Animation as Content Development for Digital Learning Material for Indonesian Traditional Fabrics: Songket Palembang based on cloud for elementary school students.",C6130B Graphics techniques;C6130V Virtual reality;C7810C Computer-aided instruction;C7820 Humanities computing,3D animated visualization assets;3d Painting;3D visualization animation production process;animated 3D visualization;Augmented Reality;content development;cycle animation;Digital Learning Material;digital learning materials;Indonesian cultural arts;Indonesian Traditional Fabrics;local cultural arts;local cultural content;Mix Reality;Songket Palembang;traditional Indonesian cloth;Virtual Reality;young generation,augmented reality;computer aided instruction;computer animation;solid modelling;virtual reality,2021,Conference article (CA),"J. Phys., Conf. Ser. (UK)","(1) Sari, I.P.; (1) Permana, F.C.; (1) Firmansyah, F.H.; (1) Hernawan, A.H.; ","(1) Universitas Pendidikan Indonesia, Jl Raya Cibiru KM 15, Indonesia; ",IOP Publishing,-1,"[""computer aided instruction"", ""computer animation"", ""solid modelling""]","[""computer aided instruction"", ""computer animation"", ""solid modelling""]",computer aided instruction;computer animation;solid modelling,manufacturing;graphics;training,technology;use cases;industries,manufacturing;graphics;training,technology;use cases;industries,computer_aided_instruction computer_animation solid_modelling 3d_animated_visualization_assets 3d_painting 3d_visualization_animation_production_process animated_3d_visualization augmented_reality content_development cycle_animation digital_learning_material digital_learning_materials indonesian_cultural_arts indonesian_traditional_fabrics local_cultural_arts local_cultural_content mix_reality songket_palembang traditional_indonesian_cloth virtual_reality young_generation c6130b_graphics_techniques c6130v_virtual_reality c7810c_computer aided_instruction c7820_humanities_computing manufacturing graphics training,computer_aided_instruction computer_animation solid_modelling,3d_animated_visualization_assets 3d_painting 3d_visualization_animation_production_process animated_3d_visualization augmented_reality content_development cycle_animation digital_learning_material digital_learning_materials indonesian_cultural_arts indonesian_traditional_fabrics local_cultural_arts local_cultural_content mix_reality songket_palembang traditional_indonesian_cloth virtual_reality young_generation,animation currently developing rapidly especially 3d animation animated 3d visualization develops field film also develops digital based learning interactive application presentation slide e book game well supporting content immersive technology augmented reality virtual reality mix reality others development 3d animation nowadays accompanied use animation delivery information local cultural content young generation lack interest local cultural art accompanied lack digital learning material delivery interesting information younger generation therefore researcher aim create 3d animated visualization asset motivate student learn indonesian cultural art researcher applying method subdivision surface uv mapping 3d painting walk cycle animation 3d visualization animation production process final result research 3d visualization animation content development digital learning material indonesian traditional fabric songket palembang based cloud elementary school student,computer_aided_instruction computer_animation solid_modelling 3d_animated_visualization_assets 3d_painting 3d_visualization_animation_production_process animated_3d_visualization augmented_reality content_development cycle_animation digital_learning_material digital_learning_materials indonesian_cultural_arts indonesian_traditional_fabrics local_cultural_arts local_cultural_content mix_reality songket_palembang traditional_indonesian_cloth virtual_reality young_generation c6130b_graphics_techniques c6130v_virtual_reality c7810c_computer aided_instruction c7820_humanities_computing manufacturing graphics training animation currently developing rapidly especially 3d animation animated 3d visualization develops field film also develops digital based learning interactive application presentation slide e book game well supporting content immersive technology augmented reality virtual reality mix reality others development 3d animation nowadays accompanied use animation delivery information local cultural content young generation lack interest local cultural art accompanied lack digital learning material delivery interesting information younger generation therefore researcher aim create 3d animated visualization asset motivate student learn indonesian cultural art researcher applying method subdivision surface uv mapping 3d painting walk cycle animation 3d visualization animation production process final result research 3d visualization animation content development digital learning material indonesian traditional fabric songket palembang based cloud elementary school student,animation currently developing rapidly especially 3d animation animated 3d visualization develops field film also develops digital based learning interactive application presentation slide e book game well supporting content immersive technology augmented reality virtual reality mix reality others development 3d animation nowadays accompanied use animation delivery information local cultural content young generation lack interest local cultural art accompanied lack digital learning material delivery interesting information younger generation therefore researcher aim create 3d animated visualization asset motivate student learn indonesian cultural art researcher applying method subdivision surface uv mapping 3d painting walk cycle animation 3d visualization animation production process final result research 3d visualization animation content development digital learning material indonesian traditional fabric songket palembang based cloud elementary school studentcomputer_aided_instruction computer_animation solid_modelling3d_animated_visualization_assets 3d_painting 3d_visualization_animation_production_process animated_3d_visualization augmented_reality content_development cycle_animation digital_learning_material digital_learning_materials indonesian_cultural_arts indonesian_traditional_fabrics local_cultural_arts local_cultural_content mix_reality songket_palembang traditional_indonesian_cloth virtual_reality young_generation
276,Employing Emerging Technologies to Develop and Evaluate In-Vehicle Intelligent Systems for Driver Support: Infotainment AR HUD Case Study,"Charissis, V., Falah, J., Lagoo, R., Alfalah, S. F. M., Khan, S., Wang, S., Altarteer, S., Larbi, K. B., & Drikakis, D. (2021). Employing Emerging Technologies to Develop and Evaluate In-Vehicle Intelligent Systems for Driver Support: Infotainment AR HUD Case Study. Applied Sciences, 11(4), 1397. https://doi.org/10.3390/app11041397
",10.3390/app11041397,"The plurality of current infotainment devices within the in-vehicle space produces an unprecedented volume of incoming data that overwhelm the typical driver, leading to higher collision probability. This work presents an investigation to an alternative option which aims to manage the incoming information while offering an uncluttered and timely manner of presenting and interacting with the incoming data safely. The latter is achieved through the use of an augmented reality (AR) head-up display (HUD) system, which projects the information within the driver's field of view. An uncluttered gesture recognition interface provides the interaction with the AR visuals. For the assessment of the system's effectiveness, we developed a full-scale virtual reality driving simulator which immerses the drivers in challenging, collision-prone, scenarios. The scenarios unfold within a digital twin model of the surrounding motorways of the city of Glasgow. The proposed system was evaluated in contrast to a typical head-down display (HDD) interface system by 30 users, showing promising results that are discussed in detail.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6180 User interfaces,alternative option;augmented reality head-up display system;collision-prone;current infotainment devices;driver support;employing emerging technologies;full-scale virtual reality driving simulator;higher collision probability;in-vehicle space;incoming information;infotainment AR HUD case study;plurality;presenting interacting;typical driver;typical head-down display interface system;uncluttered gesture recognition interface;uncluttered manner;unprecedented volume,augmented reality;gesture recognition;head-up displays;probability;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Charissis, V.; (2) Falah, J.; (1) Lagoo, R.; (3) Alfalah, S.F.M.; (1) Khan, S.; (4) Wang, S.; (5) Altarteer, S.; (1) Larbi, K.B.; (6) Drikakis, D.; ","(1) Glasgow Caledonian University, School of Computing, Engineering and Built Environment, United Kingdom; (2) Al-Balqa Applied University, Department of Autonomous Systems, Jordan; (3) University of Jordan, King Abdullah II School of Information Technology, Jordan; (4) Volkswagen, Research and Development, China; (5) Dar Al-Hekma University, School of Design and Architecture, Saudi Arabia; (6) University of Nicosia, Defence and Security Research Institute, Cyprus; ",MDPI,-1,"[""gesture recognition"", ""head up displays"", ""probability""]","[""gesture recognition"", ""head up displays"", ""probability""]",gesture recognition;head up displays;probability,display technology;human factors;video;input,technology;displays;end users and user experience,display technology;human factors;video;input,technology;displays;end users and user experience,gesture_recognition head_up_displays probability alternative_option augmented_reality_head up_display_system collision prone current_infotainment_devices driver_support employing_emerging_technologies full scale_virtual_reality_driving_simulator higher_collision_probability in vehicle_space incoming_information infotainment_ar_hud_case_study plurality presenting_interacting typical_driver typical_head down_display_interface_system uncluttered_gesture_recognition_interface uncluttered_manner unprecedented_volume c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces display_technology human_factors video input,gesture_recognition head_up_displays probability,alternative_option augmented_reality_head up_display_system collision prone current_infotainment_devices driver_support employing_emerging_technologies full scale_virtual_reality_driving_simulator higher_collision_probability in vehicle_space incoming_information infotainment_ar_hud_case_study plurality presenting_interacting typical_driver typical_head down_display_interface_system uncluttered_gesture_recognition_interface uncluttered_manner unprecedented_volume,plurality current infotainment device within vehicle space produce unprecedented volume incoming data overwhelm typical driver leading higher collision probability work present investigation alternative option aim manage incoming information offering uncluttered timely manner presenting interacting incoming data safely latter achieved use augmented reality ar head display hud system project information within driver field view uncluttered gesture recognition interface provides interaction ar visuals assessment system effectiveness developed full scale virtual reality driving simulator immerses driver challenging collision prone scenario scenario unfold within digital twin model surrounding motorway city glasgow proposed system evaluated contrast typical head display hdd interface system 30 user showing promising result discussed detail,gesture_recognition head_up_displays probability alternative_option augmented_reality_head up_display_system collision prone current_infotainment_devices driver_support employing_emerging_technologies full scale_virtual_reality_driving_simulator higher_collision_probability in vehicle_space incoming_information infotainment_ar_hud_case_study plurality presenting_interacting typical_driver typical_head down_display_interface_system uncluttered_gesture_recognition_interface uncluttered_manner unprecedented_volume c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces display_technology human_factors video input plurality current infotainment device within vehicle space produce unprecedented volume incoming data overwhelm typical driver leading higher collision probability work present investigation alternative option aim manage incoming information offering uncluttered timely manner presenting interacting incoming data safely latter achieved use augmented reality ar head display hud system project information within driver field view uncluttered gesture recognition interface provides interaction ar visuals assessment system effectiveness developed full scale virtual reality driving simulator immerses driver challenging collision prone scenario scenario unfold within digital twin model surrounding motorway city glasgow proposed system evaluated contrast typical head display hdd interface system 30 user showing promising result discussed detail,plurality current infotainment device within vehicle space produce unprecedented volume incoming data overwhelm typical driver leading higher collision probability work present investigation alternative option aim manage incoming information offering uncluttered timely manner presenting interacting incoming data safely latter achieved use augmented reality ar head display hud system project information within driver field view uncluttered gesture recognition interface provides interaction ar visuals assessment system effectiveness developed full scale virtual reality driving simulator immerses driver challenging collision prone scenario scenario unfold within digital twin model surrounding motorway city glasgow proposed system evaluated contrast typical head display hdd interface system 30 user showing promising result discussed detailgesture_recognition head_up_displays probabilityalternative_option augmented_reality_head up_display_system collision prone current_infotainment_devices driver_support employing_emerging_technologies full scale_virtual_reality_driving_simulator higher_collision_probability in vehicle_space incoming_information infotainment_ar_hud_case_study plurality presenting_interacting typical_driver typical_head down_display_interface_system uncluttered_gesture_recognition_interface uncluttered_manner unprecedented_volume
277,Ultrasound for Gaze Estimation&#8212;A Modeling and Empirical Study,"Golard, A., & Talathi, S. S. (2021). Ultrasound for Gaze Estimation—A Modeling and Empirical Study. Sensors, 21(13), 4502. https://doi.org/10.3390/s21134502
",10.3390/s21134502,"Most eye tracking methods are light-based. As such, they can suffer from ambient light changes when used outdoors, especially for use cases where eye trackers are embedded in Augmented Reality glasses. It has been recently suggested that ultrasound could provide a low power, fast, light-insensitive alternative to camera-based sensors for eye tracking. Here, we report on our work on modeling ultrasound sensor integration into a glasses form factor AR device to evaluate the feasibility of estimating eye-gaze in various configurations. Next, we designed a benchtop experimental setup to collect empirical data on time of flight and amplitude signals for reflected ultrasound waves for a range of gaze angles of a model eye. We used this data as input for a low-complexity gradient-boosted tree machine learning regression model and demonstrate that we can effectively estimate gaze (gaze RMSE error of 0.965 &#177; 0.178 degrees with an adjusted R2 score of 90.2 &#177; 4.6).","B6135 Optical, image and video signal processing;B0240V Regression analysis;B0290F Interpolation and function approximation (numerical analysis);B7230G Image sensors;C1140V Regression analysis;C4130 Interpolation and function approximation (numerical analysis);C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C6260 Machine learning (artificial intelligence)",ambient light changes;amplitude signals;augmented reality glasses;camera-based sensors;eye trackers;eye tracking methods;eye-gaze;gaze angles;glasses form factor AR device;light-insensitive alternative;low-complexity gradient-boosted tree machine learning regression model;reflected ultrasound waves;regression model;ultrasound sensor integration,augmented reality;cameras;eye;gradient methods;human computer interaction;learning (artificial intelligence);regression analysis,2021,Journal article (JA),Sensors (Switzerland),"(1) Golard, A.; (1) Talathi, S.S.; ","(1) Facebook Reality Labs, Redmond, WA 98052, United States; ",MDPI,-1,"[""cameras"", ""eye"", ""gradient methods"", ""human computer interaction"", ""learning algorithms"", ""regression analysis""]","[""cameras"", ""eye"", ""gradient methods"", ""human computer interaction"", ""learning algorithms"", ""regression analysis""]",cameras;eye;gradient methods;human computer interaction;learning algorithms;regression analysis,medical;input;artificial intelligence;human-computer interaction,technology;industries;end users and user experience,medical;input;artificial intelligence;human-computer interaction,technology;industries;end users and user experience,cameras eye gradient_methods human_computer_interaction learning_algorithms regression_analysis ambient_light_changes amplitude_signals augmented_reality_glasses camera based_sensors eye_trackers eye_tracking_methods eye gaze gaze_angles glasses_form_factor_ar_device light insensitive_alternative low complexity_gradient boosted_tree_machine_learning_regression_model reflected_ultrasound_waves regression_model ultrasound_sensor_integration b6135_optical _image_and_video_signal_processing b0240v_regression_analysis b0290f_interpolation_and_function_approximation_ numerical_analysis b7230g_image_sensors c1140v_regression_analysis c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6260_machine_learning_ artificial_intelligence medical input artificial_intelligence human computer_interaction,cameras eye gradient_methods human_computer_interaction learning_algorithms regression_analysis,ambient_light_changes amplitude_signals augmented_reality_glasses camera based_sensors eye_trackers eye_tracking_methods eye gaze gaze_angles glasses_form_factor_ar_device light insensitive_alternative low complexity_gradient boosted_tree_machine_learning_regression_model reflected_ultrasound_waves regression_model ultrasound_sensor_integration,eye tracking method light based suffer ambient light change used outdoors especially use case eye tracker embedded augmented reality glass recently suggested ultrasound could provide low power fast light insensitive alternative camera based sensor eye tracking report work modeling ultrasound sensor integration glass form factor ar device evaluate feasibility estimating eye gaze various configuration next designed benchtop experimental setup collect empirical data time flight amplitude signal reflected ultrasound wave range gaze angle model eye used data input low complexity gradient boosted tree machine learning regression model demonstrate effectively estimate gaze gaze rmse error 0 965 177 0 178 degree adjusted r2 score 90 2 177 4 6,cameras eye gradient_methods human_computer_interaction learning_algorithms regression_analysis ambient_light_changes amplitude_signals augmented_reality_glasses camera based_sensors eye_trackers eye_tracking_methods eye gaze gaze_angles glasses_form_factor_ar_device light insensitive_alternative low complexity_gradient boosted_tree_machine_learning_regression_model reflected_ultrasound_waves regression_model ultrasound_sensor_integration b6135_optical _image_and_video_signal_processing b0240v_regression_analysis b0290f_interpolation_and_function_approximation_ numerical_analysis b7230g_image_sensors c1140v_regression_analysis c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6260_machine_learning_ artificial_intelligence medical input artificial_intelligence human computer_interaction eye tracking method light based suffer ambient light change used outdoors especially use case eye tracker embedded augmented reality glass recently suggested ultrasound could provide low power fast light insensitive alternative camera based sensor eye tracking report work modeling ultrasound sensor integration glass form factor ar device evaluate feasibility estimating eye gaze various configuration next designed benchtop experimental setup collect empirical data time flight amplitude signal reflected ultrasound wave range gaze angle model eye used data input low complexity gradient boosted tree machine learning regression model demonstrate effectively estimate gaze gaze rmse error 0 965 177 0 178 degree adjusted r2 score 90 2 177 4 6,eye tracking method light based suffer ambient light change used outdoors especially use case eye tracker embedded augmented reality glass recently suggested ultrasound could provide low power fast light insensitive alternative camera based sensor eye tracking report work modeling ultrasound sensor integration glass form factor ar device evaluate feasibility estimating eye gaze various configuration next designed benchtop experimental setup collect empirical data time flight amplitude signal reflected ultrasound wave range gaze angle model eye used data input low complexity gradient boosted tree machine learning regression model demonstrate effectively estimate gaze gaze rmse error 0 965 177 0 178 degree adjusted r2 score 90 2 177 4 6cameras eye gradient_methods human_computer_interaction learning_algorithms regression_analysisambient_light_changes amplitude_signals augmented_reality_glasses camera based_sensors eye_trackers eye_tracking_methods eye gaze gaze_angles glasses_form_factor_ar_device light insensitive_alternative low complexity_gradient boosted_tree_machine_learning_regression_model reflected_ultrasound_waves regression_model ultrasound_sensor_integration
278,"Enabling Ultra-Compact, High-Quality 3D Displays with Neural Holography","Gopakumar, M., Choi, S., Kim, J., Peng, E. Y., & Wetzstein, G. (2023). Enabling ultra-compact, high-quality 3D displays with neural holography. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2655127
",10.1117/12.2655127,"Holographic near-eye displays have the potential to overcome many long-standing challenges for virtual and augmented reality (VR/AR) systems; they can reproduce full 3D depth cues, improve power efficiency, enable compact display systems, and correct for optical aberrations. Despite these remarkable benefits, this technology has been held back from widespread usage due to the limited image quality achieved by traditional holographic displays, the slow algorithms for computer-generated holography (CGH), and current bulky optical setups. Here, we review recent advances in CGH that utilize artificial intelligence (AI) techniques to solve these challenges. &copy; 2023 SPIE.","722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;723.4 Artificial Intelligence;723.5 Computer Applications;743 Holography;743.1 Holographic Techniques",3-D displays;3D-displays;Augmented reality systems;Computational display;Computer-generated holography;Depth cue;High quality;Power-efficiency;Virtual and augmented reality;Virtual reality system,Aberrations;Artificial intelligence;Computer generated holography;Holographic displays;Three dimensional displays;Virtual reality,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Gopakumar, Manu; (1) Choi, Suyeon; (2) Kim, Jonghyun; (3) Peng, Yifan; (1) Wetzstein, Gordon; ","(1) Electrical Engineering Department, Stanford University, Stanford; CA; 94305, United States; (2) NVIDIA, 2788 San Tomas Expressway, Santa Clara; CA; 95051, United States; (3) Department of Electrical and Electronic Engineering, The University of Hong Kong, Pokfulam Rd., Hong Kong; ",SPIE,-1,"[""aberrations"", ""artificial intelligence"", ""computer-generated holography"", ""holographic displays"", ""three-dimensional displays""]","[""aberrations"", ""artificial intelligence"", ""computer-generated holography"", ""holographic displays"", ""three-dimensional displays""]",aberrations;artificial intelligence;computer-generated holography;holographic displays;three-dimensional displays,graphics;liberal arts;optics;display technology;artificial intelligence,technology;displays;industries,graphics;liberal arts;optics;display technology;artificial intelligence,technology;displays;industries,aberrations artificial_intelligence computer generated_holography holographic_displays three dimensional_displays 3 d_displays 3d displays augmented_reality_systems computational_display computer generated_holography depth_cue high_quality power efficiency virtual_and_augmented_reality virtual_reality_system 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 5_computer_applications 743_holography 743 1_holographic_techniques graphics liberal_arts optics display_technology artificial_intelligence,aberrations artificial_intelligence computer generated_holography holographic_displays three dimensional_displays,3 d_displays 3d displays augmented_reality_systems computational_display computer generated_holography depth_cue high_quality power efficiency virtual_and_augmented_reality virtual_reality_system,holographic near eye display potential overcome many long standing challenge virtual augmented reality vr ar system reproduce full 3d depth cue improve power efficiency enable compact display system correct optical aberration despite remarkable benefit technology held back widespread usage due limited image quality achieved traditional holographic display slow algorithm computer generated holography cgh current bulky optical setup review recent advance cgh utilize artificial intelligence ai technique solve challenge copy 2023 spie,aberrations artificial_intelligence computer generated_holography holographic_displays three dimensional_displays 3 d_displays 3d displays augmented_reality_systems computational_display computer generated_holography depth_cue high_quality power efficiency virtual_and_augmented_reality virtual_reality_system 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 5_computer_applications 743_holography 743 1_holographic_techniques graphics liberal_arts optics display_technology artificial_intelligence holographic near eye display potential overcome many long standing challenge virtual augmented reality vr ar system reproduce full 3d depth cue improve power efficiency enable compact display system correct optical aberration despite remarkable benefit technology held back widespread usage due limited image quality achieved traditional holographic display slow algorithm computer generated holography cgh current bulky optical setup review recent advance cgh utilize artificial intelligence ai technique solve challenge copy 2023 spie,holographic near eye display potential overcome many long standing challenge virtual augmented reality vr ar system reproduce full 3d depth cue improve power efficiency enable compact display system correct optical aberration despite remarkable benefit technology held back widespread usage due limited image quality achieved traditional holographic display slow algorithm computer generated holography cgh current bulky optical setup review recent advance cgh utilize artificial intelligence ai technique solve challenge copy 2023 spieaberrations artificial_intelligence computer generated_holography holographic_displays three dimensional_displays3 d_displays 3d displays augmented_reality_systems computational_display computer generated_holography depth_cue high_quality power efficiency virtual_and_augmented_reality virtual_reality_system
279,Scalable Extended Reality: A Future Research Agenda,"Memmesheimer, V. M., & Ebert, A. (2022). Scalable Extended Reality: A Future Research Agenda. Big Data and Cognitive Computing, 6(1), 12. https://doi.org/10.3390/bdcc6010012
",10.3390/bdcc6010012,"Extensive research has outlined the potential of augmented, mixed, and virtual reality applications. However, little attention has been paid to scalability enhancements fostering practical adoption. In this paper, we introduce the concept of scalable extended reality (XRS), i.e., spaces scaling between different displays and degrees of virtuality that can be entered by multiple, possibly distributed users. The development of such XRSspaces concerns several research fields. To provide bidirectional interaction and maintain consistency with the real environment, virtual reconstructions of physical scenes need to be segmented semantically and adapted dynamically. Moreover, scalable interaction techniques for selection, manipulation, and navigation as well as a world-stabilized rendering of 2D annotations in 3D space are needed to let users intuitively switch between handheld and head-mounted displays. Collaborative settings should further integrate access control and awareness cues indicating the collaborators' locations and actions. While many of these topics were investigated by previous research, very few have considered their integration to enhance scalability. Addressing this gap, we review related previous research, list current barriers to the development of XRSspaces, and highlight dependencies between them.","C6130V Virtual reality;C5540D Computer displays;C6130G Groupware;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",2D annotations;3D space;augmented reality applications;bidirectional interaction;collaborative settings;handheld display;head-mounted displays;mixed reality applications;scalable extended reality;scalable interaction techniques;virtual reality applications;virtual reconstructions;XRSspaces,augmented reality;groupware;helmet mounted displays;human computer interaction;mobile computing,2021,Journal article (JA),Big Data Cogn. Comput. (Switzerland),"(1) Memmesheimer, V.M.; (1) Ebert, A.; ","(1) Technische Universita&#776;t Kaiserslautern, Department of Computer Science, Germany; ",MDPI,-1,"[""groupware"", ""helmet mounted displays"", ""human computer interaction"", ""mobile computing""]","[""groupware"", ""helmet mounted displays"", ""human computer interaction"", ""mobile computing""]",groupware;helmet mounted displays;human computer interaction;mobile computing,collaboration;display technology;telecommunication;wearables;human-computer interaction,industries;displays;use cases;end users and user experience,collaboration;display technology;telecommunication;wearables;human-computer interaction,industries;displays;use cases;end users and user experience,groupware helmet_mounted_displays human_computer_interaction mobile_computing 2d_annotations 3d_space augmented_reality_applications bidirectional_interaction collaborative_settings handheld_display head mounted_displays mixed_reality_applications scalable_extended_reality scalable_interaction_techniques virtual_reality_applications virtual_reconstructions xrsspaces c6130v_virtual_reality c5540d_computer_displays c6130g_groupware c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing collaboration display_technology telecommunication wearables human computer_interaction,groupware helmet_mounted_displays human_computer_interaction mobile_computing,2d_annotations 3d_space augmented_reality_applications bidirectional_interaction collaborative_settings handheld_display head mounted_displays mixed_reality_applications scalable_extended_reality scalable_interaction_techniques virtual_reality_applications virtual_reconstructions xrsspaces,extensive research outlined potential augmented mixed virtual reality application however little attention paid scalability enhancement fostering practical adoption paper introduce concept scalable extended reality xrs e space scaling different display degree virtuality entered multiple possibly distributed user development xrsspaces concern several research field provide bidirectional interaction maintain consistency real environment virtual reconstruction physical scene need segmented semantically adapted dynamically moreover scalable interaction technique selection manipulation navigation well world stabilized rendering 2d annotation 3d space needed let user intuitively switch handheld head mounted display collaborative setting integrate access control awareness cue indicating collaborator location action many topic investigated previous research considered integration enhance scalability addressing gap review related previous research list current barrier development xrsspaces highlight dependency,groupware helmet_mounted_displays human_computer_interaction mobile_computing 2d_annotations 3d_space augmented_reality_applications bidirectional_interaction collaborative_settings handheld_display head mounted_displays mixed_reality_applications scalable_extended_reality scalable_interaction_techniques virtual_reality_applications virtual_reconstructions xrsspaces c6130v_virtual_reality c5540d_computer_displays c6130g_groupware c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing collaboration display_technology telecommunication wearables human computer_interaction extensive research outlined potential augmented mixed virtual reality application however little attention paid scalability enhancement fostering practical adoption paper introduce concept scalable extended reality xrs e space scaling different display degree virtuality entered multiple possibly distributed user development xrsspaces concern several research field provide bidirectional interaction maintain consistency real environment virtual reconstruction physical scene need segmented semantically adapted dynamically moreover scalable interaction technique selection manipulation navigation well world stabilized rendering 2d annotation 3d space needed let user intuitively switch handheld head mounted display collaborative setting integrate access control awareness cue indicating collaborator location action many topic investigated previous research considered integration enhance scalability addressing gap review related previous research list current barrier development xrsspaces highlight dependency,extensive research outlined potential augmented mixed virtual reality application however little attention paid scalability enhancement fostering practical adoption paper introduce concept scalable extended reality xrs e space scaling different display degree virtuality entered multiple possibly distributed user development xrsspaces concern several research field provide bidirectional interaction maintain consistency real environment virtual reconstruction physical scene need segmented semantically adapted dynamically moreover scalable interaction technique selection manipulation navigation well world stabilized rendering 2d annotation 3d space needed let user intuitively switch handheld head mounted display collaborative setting integrate access control awareness cue indicating collaborator location action many topic investigated previous research considered integration enhance scalability addressing gap review related previous research list current barrier development xrsspaces highlight dependencygroupware helmet_mounted_displays human_computer_interaction mobile_computing2d_annotations 3d_space augmented_reality_applications bidirectional_interaction collaborative_settings handheld_display head mounted_displays mixed_reality_applications scalable_extended_reality scalable_interaction_techniques virtual_reality_applications virtual_reconstructions xrsspaces
280,Aaron: Compile-Time Kernel Adaptation for Multi-DNN Inference Acceleration on Edge GPU,"Zhao, Z., Ling, N., Guan, N., & Xing, G. (2022). Aaron. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568050
",10.1145/3560905.3568050,"AI applications powered by deep learning are increasingly running on edge devices. Meanwhile, many real-world IoT applications demand multiple real-time tasks to run on the same device, for example, to achieve both object tracking and image segmentation simultaneously on an augmented reality glass. However, the current solutions can not yet support such multi-tenant real-time DNN inference on edge devices. Techniques such as on-device model compression trade inference accuracy for speed, while traditional DNN compilers mainly focus on single-tenant DNN model optimization. To fill this gap, we propose Aaron, which leverages DNN compiling techniques to accelerate multi-DNN inference on edge GPU based on compile-time kernel adaptation with no accuracy loss. Aaron integrates both DNN graph and kernel optimization to maximize on-device parallelism and minimize contention brought by concurrent inference.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C5620D Internet of Things;C6130V Virtual reality;C6250 Reasoning and inference techniques;C6264 Neural nets",Aaron;AI applications;augmented reality glass;compile-time kernel adaptation;concurrent inference;deep learning;edge devices;edge GPU;image segmentation;kernel optimization;multiDNN inference acceleration;multitenant real-time DNN inference;object tracking;on-device model compression trade inference accuracy;on-device parallelism;real-time tasks;real-world IoT applications;single-tenant DNN model optimization;traditional DNN compilers,augmented reality;cloud computing;deep learning (artificial intelligence);graphics processing units;image segmentation;inference mechanisms;Internet of Things;object tracking;optimisation,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Zhao, Z.; (1) Ling, N.; (2) Guan, N.; (1) Xing, G.; ","(1) Chinese University of Hong Kong, China; (2) City University of Hong Kong, China; ",ACM,-1,"[""cloud computing"", ""deep learning (artificial intelligence)"", ""graphics processing units"", ""image segmentation"", ""inference mechanisms"", ""internet of things"", ""object tracking"", ""optimization""]","[""cloud computing"", ""deep learning (artificial intelligence)"", ""graphics processing units"", ""image segmentation"", ""inference mechanisms"", ""internet of things"", ""object tracking"", ""optimization""]",cloud computing;deep learning (artificial intelligence);graphics processing units;image segmentation;inference mechanisms;internet of things;object tracking;optimization,computer vision;semiconductors;other;liberal arts;medical;business performance metrics;internet of things;data;artificial intelligence;networks,technology;other;business;industries,computer vision;semiconductors;other;liberal arts;medical;business performance metrics;internet of things;data;artificial intelligence;networks,technology;other;business;industries,cloud_computing deep_learning_ artificial_intelligence graphics_processing_units image_segmentation inference_mechanisms internet_of_things object_tracking optimization aaron ai_applications augmented_reality_glass compile time_kernel_adaptation concurrent_inference deep_learning edge_devices edge_gpu image_segmentation kernel_optimization multidnn_inference_acceleration multitenant_real time_dnn_inference object_tracking on device_model_compression_trade_inference_accuracy on device_parallelism real time_tasks real world_iot_applications single tenant_dnn_model_optimization traditional_dnn_compilers b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130v_virtual_reality c6250_reasoning_and_inference_techniques c6264_neural_nets computer_vision semiconductors other liberal_arts medical business_performance_metrics internet_of_things data artificial_intelligence networks,cloud_computing deep_learning_ artificial_intelligence graphics_processing_units image_segmentation inference_mechanisms internet_of_things object_tracking optimization,aaron ai_applications augmented_reality_glass compile time_kernel_adaptation concurrent_inference deep_learning edge_devices edge_gpu image_segmentation kernel_optimization multidnn_inference_acceleration multitenant_real time_dnn_inference object_tracking on device_model_compression_trade_inference_accuracy on device_parallelism real time_tasks real world_iot_applications single tenant_dnn_model_optimization traditional_dnn_compilers,ai application powered deep learning increasingly running edge device meanwhile many real world iot application demand multiple real time task run device example achieve object tracking image segmentation simultaneously augmented reality glass however current solution yet support multi tenant real time dnn inference edge device technique device model compression trade inference accuracy speed traditional dnn compiler mainly focus single tenant dnn model optimization fill gap propose aaron leverage dnn compiling technique accelerate multi dnn inference edge gpu based compile time kernel adaptation accuracy loss aaron integrates dnn graph kernel optimization maximize device parallelism minimize contention brought concurrent inference,cloud_computing deep_learning_ artificial_intelligence graphics_processing_units image_segmentation inference_mechanisms internet_of_things object_tracking optimization aaron ai_applications augmented_reality_glass compile time_kernel_adaptation concurrent_inference deep_learning edge_devices edge_gpu image_segmentation kernel_optimization multidnn_inference_acceleration multitenant_real time_dnn_inference object_tracking on device_model_compression_trade_inference_accuracy on device_parallelism real time_tasks real world_iot_applications single tenant_dnn_model_optimization traditional_dnn_compilers b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5620d_internet_of_things c6130v_virtual_reality c6250_reasoning_and_inference_techniques c6264_neural_nets computer_vision semiconductors other liberal_arts medical business_performance_metrics internet_of_things data artificial_intelligence networks ai application powered deep learning increasingly running edge device meanwhile many real world iot application demand multiple real time task run device example achieve object tracking image segmentation simultaneously augmented reality glass however current solution yet support multi tenant real time dnn inference edge device technique device model compression trade inference accuracy speed traditional dnn compiler mainly focus single tenant dnn model optimization fill gap propose aaron leverage dnn compiling technique accelerate multi dnn inference edge gpu based compile time kernel adaptation accuracy loss aaron integrates dnn graph kernel optimization maximize device parallelism minimize contention brought concurrent inference,ai application powered deep learning increasingly running edge device meanwhile many real world iot application demand multiple real time task run device example achieve object tracking image segmentation simultaneously augmented reality glass however current solution yet support multi tenant real time dnn inference edge device technique device model compression trade inference accuracy speed traditional dnn compiler mainly focus single tenant dnn model optimization fill gap propose aaron leverage dnn compiling technique accelerate multi dnn inference edge gpu based compile time kernel adaptation accuracy loss aaron integrates dnn graph kernel optimization maximize device parallelism minimize contention brought concurrent inferencecloud_computing deep_learning_ artificial_intelligence graphics_processing_units image_segmentation inference_mechanisms internet_of_things object_tracking optimizationaaron ai_applications augmented_reality_glass compile time_kernel_adaptation concurrent_inference deep_learning edge_devices edge_gpu image_segmentation kernel_optimization multidnn_inference_acceleration multitenant_real time_dnn_inference object_tracking on device_model_compression_trade_inference_accuracy on device_parallelism real time_tasks real world_iot_applications single tenant_dnn_model_optimization traditional_dnn_compilers
281,Correlation and comparison between digital twin and cyber physical systems,"Khan, A. U., & Huang, L. (2023). Correlation and comparison between digital twin and cyber physical systems. ECPPM 2022 - EWork and EBusiness in Architecture, Engineering and Construction 2022, 268–274. https://doi.org/10.1201/9781003354222-35
",10.1201/9781003354222-35,"Advanced technologies such as Internet of things (IoTs), Artificial Intelligence (AI), blockchain, Augmented Reality (AR), data analytics etc., have significantly accelerated the development process of smart manufacturing. Manufacturers are promptly using cyber&ndash;physical integration as a prerequisite for smart production. Cyber&ndash;physical systems (CPS) and digital twins (DTs) are two popular technologies that are used as a preferred mean of integration. Regardless of their differences, both technologies have several commonalities that cause them to be misunderstood. Therefore, it is important to distinguish these two technologies in order to consolidate future research direction. Through a systematic analysis, this paper compares and contrasts CPS and DTs from several angles in order to highlight the differences and correlations between them. &copy; 2023 the Author(s).","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing",Advanced technology;Block-chain;Cybe-physical systems;Cyber physicals;Cyber-physical systems;Data analytics;Development process;Future research directions;Smart manufacturing;Systematic analysis,Augmented reality;Data Analytics;Embedded systems,2023,Conference article (CA),"eWork eBus. Archit., Eng. Constr. - Proc. Eur. Conf. Prod. Process Model.","(1) Khan, A.U.; (1) Huang, L.; ","(1) NTNU, Gj&oslash;vik, Norway; ",CRC Press/Balkema,-1,"[""data analytics"", ""embedded systems""]","[""data analytics"", ""embedded systems""]",data analytics;embedded systems,education;semiconductors;data,technology;industries,education;semiconductors;data,technology;industries,data_analytics embedded_systems advanced_technology block chain cybe physical_systems cyber_physicals cyber physical_systems data_analytics development_process future_research_directions smart_manufacturing systematic_analysis 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing education semiconductors data,data_analytics embedded_systems,advanced_technology block chain cybe physical_systems cyber_physicals cyber physical_systems data_analytics development_process future_research_directions smart_manufacturing systematic_analysis,advanced technology internet thing iots artificial intelligence ai blockchain augmented reality ar data analytics etc significantly accelerated development process smart manufacturing manufacturer promptly using cyber ndash physical integration prerequisite smart production cyber ndash physical system cps digital twin dts two popular technology used preferred mean integration regardless difference technology several commonality cause misunderstood therefore important distinguish two technology order consolidate future research direction systematic analysis paper compare contrast cps dts several angle order highlight difference correlation copy 2023 author,data_analytics embedded_systems advanced_technology block chain cybe physical_systems cyber_physicals cyber physical_systems data_analytics development_process future_research_directions smart_manufacturing systematic_analysis 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing education semiconductors data advanced technology internet thing iots artificial intelligence ai blockchain augmented reality ar data analytics etc significantly accelerated development process smart manufacturing manufacturer promptly using cyber ndash physical integration prerequisite smart production cyber ndash physical system cps digital twin dts two popular technology used preferred mean integration regardless difference technology several commonality cause misunderstood therefore important distinguish two technology order consolidate future research direction systematic analysis paper compare contrast cps dts several angle order highlight difference correlation copy 2023 author,advanced technology internet thing iots artificial intelligence ai blockchain augmented reality ar data analytics etc significantly accelerated development process smart manufacturing manufacturer promptly using cyber ndash physical integration prerequisite smart production cyber ndash physical system cps digital twin dts two popular technology used preferred mean integration regardless difference technology several commonality cause misunderstood therefore important distinguish two technology order consolidate future research direction systematic analysis paper compare contrast cps dts several angle order highlight difference correlation copy 2023 authordata_analytics embedded_systemsadvanced_technology block chain cybe physical_systems cyber_physicals cyber physical_systems data_analytics development_process future_research_directions smart_manufacturing systematic_analysis
282,Toward Baggage-free airport terminals: a case study of London City Airport,"Jiang, Y., Yang, R., Zang, C., Wei, Z., Thompson, J., Tran, T. H., Encinas-Oropesa, A., & Williams, L. (2021). Toward Baggage-Free Airport Terminals: A Case Study of London City Airport. Sustainability, 14(1), 212. https://doi.org/10.3390/su14010212
",10.3390/su14010212,"Nowadays, the aviation industry pays more attention to emission reduction toward the net-zero carbon goals. However, the volume of global passengers and baggage is exponentially increasing, which leads to challenges for sustainable airports. A baggage-free airport terminal is considered a potential solution in solving this issue. Removing the baggage operation away from the passenger terminals will reduce workload for airport operators and promote passengers to use public transport to airport terminals. As a result, it will bring a significant impact on energy and the environment, leading to a reduction of fuel consumption and mitigation of carbon emission. This paper studies a baggage collection network design problem using vehicle routing strategies and augmented reality for baggage-free airport terminals. We use a spreadsheet solver tool, based on the integration of the modified Clark and Wright savings heuristic and density-based clustering algorithm, for optimizing the location of logistic hubs and planning the vehicle routes for baggage collection. This tool is applied for the case study at London City Airport to analyze the impacts of the strategies on carbon emission quantitatively. The result indicates that the proposed baggage collection network can significantly reduce 290.10 tonnes of carbon emissions annually.",C7460 Aerospace engineering computing;C1160 Combinatorial mathematics;C1180 Optimisation techniques;C6130V Virtual reality;C7102 Decision support systems,airport operators;augmented reality;baggage collection network design problem;baggage operation;baggage-free airport terminal;carbon emission;density-based clustering;London City Airport;mass 290.1 tonne;net-zero carbon goals;passenger terminals;public transport;spreadsheet solver tool;sustainable airports,air pollution control;airports;augmented reality;logistics;optimisation;pattern clustering;public transport;spreadsheet programs;sustainable development;vehicle routing,2021,Journal article (JA),Sustainability (Switzerland),"(1) Jiang, Y.; (1) Yang, R.; (1) Zang, C.; (1) Wei, Z.; (1) Thompson, J.; (1) Tran, T.H.; (1) Encinas-oropesa, A.; (1) Williams, L.; ","(1) Cranfield University, School of Water, Energy and Environment, United Kingdom; ",MDPI,-1,"[""air pollution control"", ""airports"", ""logistics"", ""optimization"", ""pattern clustering"", ""public transport"", ""spreadsheet programs"", ""sustainable development"", ""vehicle routing""]","[""air pollution control"", ""airports"", ""logistics"", ""optimization"", ""pattern clustering"", ""public transport"", ""spreadsheet programs"", ""sustainable development"", ""vehicle routing""]",air pollution control;airports;logistics;optimization;pattern clustering;public transport;spreadsheet programs;sustainable development;vehicle routing,computer vision;other;aviation and aerospace;transportation;cultural heritage;automotive;business performance metrics;logistics;policy;developers;data,technology;other;business;industries,computer vision;other;aviation and aerospace;transportation;cultural heritage;automotive;business performance metrics;logistics;policy;developers;data,technology;other;business;industries,air_pollution_control airports logistics optimization pattern_clustering public_transport spreadsheet_programs sustainable_development vehicle_routing airport_operators augmented_reality baggage_collection_network_design_problem baggage_operation baggage free_airport_terminal carbon_emission density based_clustering london_city_airport mass_290 1_tonne net zero_carbon_goals passenger_terminals public_transport spreadsheet_solver_tool sustainable_airports c7460_aerospace_engineering_computing c1160_combinatorial_mathematics c1180_optimisation_techniques c6130v_virtual_reality c7102_decision_support_systems computer_vision other aviation_and_aerospace transportation cultural_heritage automotive business_performance_metrics logistics policy developers data,air_pollution_control airports logistics optimization pattern_clustering public_transport spreadsheet_programs sustainable_development vehicle_routing,airport_operators augmented_reality baggage_collection_network_design_problem baggage_operation baggage free_airport_terminal carbon_emission density based_clustering london_city_airport mass_290 1_tonne net zero_carbon_goals passenger_terminals public_transport spreadsheet_solver_tool sustainable_airports,nowadays aviation industry pay attention emission reduction toward net zero carbon goal however volume global passenger baggage exponentially increasing lead challenge sustainable airport baggage free airport terminal considered potential solution solving issue removing baggage operation away passenger terminal reduce workload airport operator promote passenger use public transport airport terminal result bring significant impact energy environment leading reduction fuel consumption mitigation carbon emission paper study baggage collection network design problem using vehicle routing strategy augmented reality baggage free airport terminal use spreadsheet solver tool based integration modified clark wright saving heuristic density based clustering algorithm optimizing location logistic hub planning vehicle route baggage collection tool applied case study london city airport analyze impact strategy carbon emission quantitatively result indicates proposed baggage collection network significantly reduce 290 10 tonne carbon emission annually,air_pollution_control airports logistics optimization pattern_clustering public_transport spreadsheet_programs sustainable_development vehicle_routing airport_operators augmented_reality baggage_collection_network_design_problem baggage_operation baggage free_airport_terminal carbon_emission density based_clustering london_city_airport mass_290 1_tonne net zero_carbon_goals passenger_terminals public_transport spreadsheet_solver_tool sustainable_airports c7460_aerospace_engineering_computing c1160_combinatorial_mathematics c1180_optimisation_techniques c6130v_virtual_reality c7102_decision_support_systems computer_vision other aviation_and_aerospace transportation cultural_heritage automotive business_performance_metrics logistics policy developers data nowadays aviation industry pay attention emission reduction toward net zero carbon goal however volume global passenger baggage exponentially increasing lead challenge sustainable airport baggage free airport terminal considered potential solution solving issue removing baggage operation away passenger terminal reduce workload airport operator promote passenger use public transport airport terminal result bring significant impact energy environment leading reduction fuel consumption mitigation carbon emission paper study baggage collection network design problem using vehicle routing strategy augmented reality baggage free airport terminal use spreadsheet solver tool based integration modified clark wright saving heuristic density based clustering algorithm optimizing location logistic hub planning vehicle route baggage collection tool applied case study london city airport analyze impact strategy carbon emission quantitatively result indicates proposed baggage collection network significantly reduce 290 10 tonne carbon emission annually,nowadays aviation industry pay attention emission reduction toward net zero carbon goal however volume global passenger baggage exponentially increasing lead challenge sustainable airport baggage free airport terminal considered potential solution solving issue removing baggage operation away passenger terminal reduce workload airport operator promote passenger use public transport airport terminal result bring significant impact energy environment leading reduction fuel consumption mitigation carbon emission paper study baggage collection network design problem using vehicle routing strategy augmented reality baggage free airport terminal use spreadsheet solver tool based integration modified clark wright saving heuristic density based clustering algorithm optimizing location logistic hub planning vehicle route baggage collection tool applied case study london city airport analyze impact strategy carbon emission quantitatively result indicates proposed baggage collection network significantly reduce 290 10 tonne carbon emission annuallyair_pollution_control airports logistics optimization pattern_clustering public_transport spreadsheet_programs sustainable_development vehicle_routingairport_operators augmented_reality baggage_collection_network_design_problem baggage_operation baggage free_airport_terminal carbon_emission density based_clustering london_city_airport mass_290 1_tonne net zero_carbon_goals passenger_terminals public_transport spreadsheet_solver_tool sustainable_airports
283,CNN - Forest Based Person Identification and Head Pose Estimation for AI Based Applications,"Anitta, D., & Annis Fathima, A. (2023). CNN — Forest Based Person Identification and Head Pose Estimation for AI Based Applications. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 31(Supp01), 47–63. https://doi.org/10.1142/s0218488523400044
",10.1142/S0218488523400044,"Face recognition and head posture estimation have aroused a lot of academic interest recently since the inherent information improves the performance of face-related applications such as face alignment, augmented reality, healthcare applications, and emotion detection. The proposed work explores the challenges of identifying people and determining head posture. An analysis of the features produced at intermediate layers by limiting the number of kernals is performed and improved the performance of detecting the person. In addition, the learned features are sent to forest trees in order to determine the exact head attitude of the detected person. The proposed Forest CNN (FCNN) architecture is tested for head pose estimation methods on the Pointing 04 and Facepix benchmark databases. &copy; 2023 World Scientific Publishing Company.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing",Face alignment;Head pose;Head Pose Estimation;Head posture;Health care application;Performance;Person identification;Pose-estimation;Posture estimation;Random forests,Augmented reality;Emotion Recognition;Feature extraction,2023,Journal article (JA),Int. J. Uncertainty Fuzziness Knowledge Based Syst.,"(1) Anitta, D.; (1) Annis Fathima, A.; ","(1) School of Electronics Engineering, VIT University, Tamilnadu, Chennai, India; ",World Scientific,-1,"[""emotion recognition"", ""feature extraction""]","[""emotion recognition"", ""feature extraction""]",emotion recognition;feature extraction,computer vision;human factors;chemical;input,technology;end users and user experience;industries,computer vision;human factors;chemical;input,technology;end users and user experience;industries,emotion_recognition feature_extraction face_alignment head_pose head_pose_estimation head_posture health_care_application performance person_identification pose estimation posture_estimation random_forests 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing computer_vision human_factors chemical input,emotion_recognition feature_extraction,face_alignment head_pose head_pose_estimation head_posture health_care_application performance person_identification pose estimation posture_estimation random_forests,face recognition head posture estimation aroused lot academic interest recently since inherent information improves performance face related application face alignment augmented reality healthcare application emotion detection proposed work explores challenge identifying people determining head posture analysis feature produced intermediate layer limiting number kernals performed improved performance detecting person addition learned feature sent forest tree order determine exact head attitude detected person proposed forest cnn fcnn architecture tested head pose estimation method pointing 04 facepix benchmark database copy 2023 world scientific publishing company,emotion_recognition feature_extraction face_alignment head_pose head_pose_estimation head_posture health_care_application performance person_identification pose estimation posture_estimation random_forests 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing computer_vision human_factors chemical input face recognition head posture estimation aroused lot academic interest recently since inherent information improves performance face related application face alignment augmented reality healthcare application emotion detection proposed work explores challenge identifying people determining head posture analysis feature produced intermediate layer limiting number kernals performed improved performance detecting person addition learned feature sent forest tree order determine exact head attitude detected person proposed forest cnn fcnn architecture tested head pose estimation method pointing 04 facepix benchmark database copy 2023 world scientific publishing company,face recognition head posture estimation aroused lot academic interest recently since inherent information improves performance face related application face alignment augmented reality healthcare application emotion detection proposed work explores challenge identifying people determining head posture analysis feature produced intermediate layer limiting number kernals performed improved performance detecting person addition learned feature sent forest tree order determine exact head attitude detected person proposed forest cnn fcnn architecture tested head pose estimation method pointing 04 facepix benchmark database copy 2023 world scientific publishing companyemotion_recognition feature_extractionface_alignment head_pose head_pose_estimation head_posture health_care_application performance person_identification pose estimation posture_estimation random_forests
284,Interactive multi-sensory and volumetric content integration for music education applications,"Ho, C.-L., Lin, T.-G., & Chang, C.-R. (2022). Interactive multi-sensory and volumetric content integration for music education applications. Multimedia Tools and Applications, 82(4), 4847–4862. https://doi.org/10.1007/s11042-022-12314-3
",10.1007/s11042-022-12314-3,"Taiwan's heritage in terms of the local music culture has been gradually fading in recent years. Thus, boosting and passing on the local music culture to pre-school and elementary school students are urgent requirements. This study proposes an interactive integration of multi-sensory and volumetric content for music education in Taiwan into applications for children. Further, the study introduces a technological multi-sensory pop-up sketch book created in collaboration with the National Taiwan Symphony Orchestra (NTSO) and Industrial Technology Research Institute (ITRI). Both organizations collaborate to integrate emerging media technologies, including augmented reality (AR) and volumetric capture for content production, and creative music teaching methods, derived from traditional pop-up sketch books. The final product featured 3D animated videos to achieve interactive learning with digital formation additional to the real worlds. This AR multi-sensory pop-up sketch book utilizes advanced volumetric capture technology to capture the motions of main actors in vivid 3D animation. Besides, modularized pop-up cards of musical instruments provide a haptic experience to complement the story. The book targets children aged between 3 and 12 years. An actual reading survey was conducted on 497 students from five kindergartens in Taiwan. Satisfaction with the book was rated using a five-rank scale. The cluster random sampling method was used for data analysis. Results of t-test produced an average score of 4.9980, which indicated that the target audience ranked the book with high levels of satisfaction. The results also confirmed that the story line was familiar among young children within the target age range. Additionally, using digital audio-visual augmented reality technology will be conducive to young children in terms of acceptance and recognition of traditional music culture. 3D animations of famous intellectual property characters aroused the interest of readers in learning about music through interactive contents. Moreover, this study provided evidence that the STEAM education model, which represents a cross-curricular approach that integrates Science, Technology, Engineering, Art, and Mathematics, is applicable to the inheritance and development of the local music culture.",C7810C Computer-aided instruction;C6130B Graphics techniques;C6130M Multimedia;C6130V Virtual reality;C6180 User interfaces;C7820 Humanities computing,3D animated videos;AR multisensory pop-up sketch book utilizes;audio-visual augmented reality technology;cluster random sampling method;content production;creative music teaching methods;data analysis;elementary school students;Industrial Technology Research Institute;interactive learning;ITRI;local music culture;media technologies;modularized pop-up cards;music education applications;musical instruments;National Taiwan Symphony Orchestra;NTSO;STEAM education model;Taiwan heritage;traditional pop-up sketch books;volumetric capture technology;volumetric content integration,augmented reality;computer aided instruction;computer animation;data analysis;educational institutions;multimedia computing;music;musical instruments;sampling methods;STEM;teaching,2023,Journal article (JA),Multimed. Tools Appl. (Germany),"(1) Ho, C.-L.; (3) Lin, T.-G.; (3) Chang, C.-R.; ","(1) National Taiwan Symphony Orchestra, Taiwan; (2) Chaoyang University of Technology, Taiwan; (3) Industrial Technology Research Institute, Service Systems Technology Center, Taiwan; (4) Interplan International Corporation, Taiwan; ",Springer,-1,"[""computer aided instruction"", ""computer animation"", ""data analysis"", ""educational institutions"", ""multimedia computing"", ""music"", ""musical instruments"", ""sampling methods"", ""stem"", ""teaching""]","[""computer aided instruction"", ""computer animation"", ""data analysis"", ""educational institutions"", ""multimedia computing"", ""music"", ""musical instruments"", ""sampling methods"", ""stem"", ""teaching""]",computer aided instruction;computer animation;data analysis;educational institutions;multimedia computing;music;musical instruments;sampling methods;stem;teaching,education;graphics;training;data;audio,technology;use cases;industries,education;graphics;training;data;audio,technology;use cases;industries,computer_aided_instruction computer_animation data_analysis educational_institutions multimedia_computing music musical_instruments sampling_methods stem teaching 3d_animated_videos ar_multisensory_pop up_sketch_book_utilizes audio visual_augmented_reality_technology cluster_random_sampling_method content_production creative_music_teaching_methods data_analysis elementary_school_students industrial_technology_research_institute interactive_learning itri local_music_culture media_technologies modularized_pop up_cards music_education_applications musical_instruments national_taiwan_symphony_orchestra ntso steam_education_model taiwan_heritage traditional_pop up_sketch_books volumetric_capture_technology volumetric_content_integration c7810c_computer aided_instruction c6130b_graphics_techniques c6130m_multimedia c6130v_virtual_reality c6180_user_interfaces c7820_humanities_computing education graphics training data audio,computer_aided_instruction computer_animation data_analysis educational_institutions multimedia_computing music musical_instruments sampling_methods stem teaching,3d_animated_videos ar_multisensory_pop up_sketch_book_utilizes audio visual_augmented_reality_technology cluster_random_sampling_method content_production creative_music_teaching_methods data_analysis elementary_school_students industrial_technology_research_institute interactive_learning itri local_music_culture media_technologies modularized_pop up_cards music_education_applications musical_instruments national_taiwan_symphony_orchestra ntso steam_education_model taiwan_heritage traditional_pop up_sketch_books volumetric_capture_technology volumetric_content_integration,taiwan heritage term local music culture gradually fading recent year thus boosting passing local music culture pre school elementary school student urgent requirement study proposes interactive integration multi sensory volumetric content music education taiwan application child study introduces technological multi sensory pop sketch book created collaboration national taiwan symphony orchestra ntso industrial technology research institute itri organization collaborate integrate emerging medium technology including augmented reality ar volumetric capture content production creative music teaching method derived traditional pop sketch book final product featured 3d animated video achieve interactive learning digital formation additional real world ar multi sensory pop sketch book utilizes advanced volumetric capture technology capture motion main actor vivid 3d animation besides modularized pop card musical instrument provide haptic experience complement story book target child aged 3 12 year actual reading survey conducted 497 student five kindergarten taiwan satisfaction book rated using five rank scale cluster random sampling method used data analysis result test produced average score 4 9980 indicated target audience ranked book high level satisfaction result also confirmed story line familiar among young child within target age range additionally using digital audio visual augmented reality technology conducive young child term acceptance recognition traditional music culture 3d animation famous intellectual property character aroused interest reader learning music interactive content moreover study provided evidence steam education model represents cross curricular approach integrates science technology engineering art mathematics applicable inheritance development local music culture,computer_aided_instruction computer_animation data_analysis educational_institutions multimedia_computing music musical_instruments sampling_methods stem teaching 3d_animated_videos ar_multisensory_pop up_sketch_book_utilizes audio visual_augmented_reality_technology cluster_random_sampling_method content_production creative_music_teaching_methods data_analysis elementary_school_students industrial_technology_research_institute interactive_learning itri local_music_culture media_technologies modularized_pop up_cards music_education_applications musical_instruments national_taiwan_symphony_orchestra ntso steam_education_model taiwan_heritage traditional_pop up_sketch_books volumetric_capture_technology volumetric_content_integration c7810c_computer aided_instruction c6130b_graphics_techniques c6130m_multimedia c6130v_virtual_reality c6180_user_interfaces c7820_humanities_computing education graphics training data audio taiwan heritage term local music culture gradually fading recent year thus boosting passing local music culture pre school elementary school student urgent requirement study proposes interactive integration multi sensory volumetric content music education taiwan application child study introduces technological multi sensory pop sketch book created collaboration national taiwan symphony orchestra ntso industrial technology research institute itri organization collaborate integrate emerging medium technology including augmented reality ar volumetric capture content production creative music teaching method derived traditional pop sketch book final product featured 3d animated video achieve interactive learning digital formation additional real world ar multi sensory pop sketch book utilizes advanced volumetric capture technology capture motion main actor vivid 3d animation besides modularized pop card musical instrument provide haptic experience complement story book target child aged 3 12 year actual reading survey conducted 497 student five kindergarten taiwan satisfaction book rated using five rank scale cluster random sampling method used data analysis result test produced average score 4 9980 indicated target audience ranked book high level satisfaction result also confirmed story line familiar among young child within target age range additionally using digital audio visual augmented reality technology conducive young child term acceptance recognition traditional music culture 3d animation famous intellectual property character aroused interest reader learning music interactive content moreover study provided evidence steam education model represents cross curricular approach integrates science technology engineering art mathematics applicable inheritance development local music culture,taiwan heritage term local music culture gradually fading recent year thus boosting passing local music culture pre school elementary school student urgent requirement study proposes interactive integration multi sensory volumetric content music education taiwan application child study introduces technological multi sensory pop sketch book created collaboration national taiwan symphony orchestra ntso industrial technology research institute itri organization collaborate integrate emerging medium technology including augmented reality ar volumetric capture content production creative music teaching method derived traditional pop sketch book final product featured 3d animated video achieve interactive learning digital formation additional real world ar multi sensory pop sketch book utilizes advanced volumetric capture technology capture motion main actor vivid 3d animation besides modularized pop card musical instrument provide haptic experience complement story book target child aged 3 12 year actual reading survey conducted 497 student five kindergarten taiwan satisfaction book rated using five rank scale cluster random sampling method used data analysis result test produced average score 4 9980 indicated target audience ranked book high level satisfaction result also confirmed story line familiar among young child within target age range additionally using digital audio visual augmented reality technology conducive young child term acceptance recognition traditional music culture 3d animation famous intellectual property character aroused interest reader learning music interactive content moreover study provided evidence steam education model represents cross curricular approach integrates science technology engineering art mathematics applicable inheritance development local music culturecomputer_aided_instruction computer_animation data_analysis educational_institutions multimedia_computing music musical_instruments sampling_methods stem teaching3d_animated_videos ar_multisensory_pop up_sketch_book_utilizes audio visual_augmented_reality_technology cluster_random_sampling_method content_production creative_music_teaching_methods data_analysis elementary_school_students industrial_technology_research_institute interactive_learning itri local_music_culture media_technologies modularized_pop up_cards music_education_applications musical_instruments national_taiwan_symphony_orchestra ntso steam_education_model taiwan_heritage traditional_pop up_sketch_books volumetric_capture_technology volumetric_content_integration
285,Intraoperative zoom lens calibration for high magnification surgical microscope,"Jeung, D., Choi, H., Ha, H.-G., Oh, S.-H., & Hong, J. (2023). Intraoperative zoom lens calibration for high magnification surgical microscope. Computer Methods and Programs in Biomedicine, 238, 107618. https://doi.org/10.1016/j.cmpb.2023.107618
",10.1016/j.cmpb.2023.107618,"Background and objectives: An augmented reality (AR)-based surgical guidance system is often used with high-magnification zoom lens systems such as a surgical microscope, particularly in neurology or otolaryngology. To superimpose the internal structures of relevant organs on the microscopy image, an accurate calibration process to obtain the camera intrinsic and hand&ndash;eye parameters of the microscope is essential. However, conventional calibration methods are unsuitable for surgical microscopes because of their narrow depth of focus at high magnifications. To realize AR-based surgical guidance with a high-magnification surgical microscope, we herein propose a new calibration method that is applicable to the highest magnification levels as well as low magnifications. Methods: The key idea of the proposed method is to find the relationship between the focal length and the hand&ndash;eye parameters, which remains constant regardless of the magnification level. Based on this, even if the magnification changes arbitrarily during surgery, the intrinsic and hand&ndash;eye parameters are recalculated quickly and accurately with one or two pictures of the pattern. We also developed a dedicated calibration tool with a prism to take focused pattern images without interfering with the surgery. Results: The proposed calibration method ensured an AR error of &lt; 1 mm for all magnification levels. In addition, the variation of focal length was within 1% regardless of the magnification level, and the corresponding variation with the conventional calibration method exceeded 20% at high magnification levels. Conclusions: The comparative study showed that the proposed method has outstanding accuracy and reproducibility for a high-magnification surgical microscope. The proposed calibration method is applicable to various endoscope or microscope systems with zoom lens. &copy; 2023 Elsevier B.V.","461.6 Medicine and Pharmacology;723 Computer Software, Data Handling and Applications;741.3 Optical Devices and Systems",Calibration method;Eye parameters;Focal lengths;High magnifications;Image guided surgery;Prism-based calibration;Surgical guidance;Surgical microscopes;Zoom lens;Zoom lens calibration,Augmented reality;Microscopes;Prisms;Surgery,2023,Journal article (JA),Comput. Methods Programs Biomed.,"(1) Jeung, Deokgi; (2) Choi, Hyunseok; (3) Ha, Ho-Gun; (4) Oh, Seung-Ha; (1) Hong, Jaesung; ","(1) Department of Robotics and Mechatronics Engineering, DGIST, 333 Techno Jungang-Daero, Daegu; 42988, Korea, Republic of; (2) DIGITRACK Inc., Daegu, Korea, Republic of; (3) Division of Intelligent Robot, DGIST, Daegu, Korea, Republic of; (4) Department of Otorhinolaryngology-Head and Neck Surgery, Seoul National University College of Medicine, Seoul, Korea, Republic of; (5) Sensory Organ Research Institute, Seoul National University Medical Research Center, Seoul, Korea, Republic of; ",Elsevier Ireland Ltd,-1,"[""microscopes"", ""prisms"", ""surgery""]","[""microscopes"", ""prisms"", ""surgery""]",microscopes;prisms;surgery,medical;other,other;industries,medical;other,other;industries,microscopes prisms surgery calibration_method eye_parameters focal_lengths high_magnifications image_guided_surgery prism based_calibration surgical_guidance surgical_microscopes zoom_lens zoom_lens_calibration 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems medical other,microscopes prisms surgery,calibration_method eye_parameters focal_lengths high_magnifications image_guided_surgery prism based_calibration surgical_guidance surgical_microscopes zoom_lens zoom_lens_calibration,background objective augmented reality ar based surgical guidance system often used high magnification zoom lens system surgical microscope particularly neurology otolaryngology superimpose internal structure relevant organ microscopy image accurate calibration process obtain camera intrinsic hand ndash eye parameter microscope essential however conventional calibration method unsuitable surgical microscope narrow depth focus high magnification realize ar based surgical guidance high magnification surgical microscope herein propose new calibration method applicable highest magnification level well low magnification method key idea proposed method find relationship focal length hand ndash eye parameter remains constant regardless magnification level based even magnification change arbitrarily surgery intrinsic hand ndash eye parameter recalculated quickly accurately one two picture pattern also developed dedicated calibration tool prism take focused pattern image without interfering surgery result proposed calibration method ensured ar error lt 1 mm magnification level addition variation focal length within 1 regardless magnification level corresponding variation conventional calibration method exceeded 20 high magnification level conclusion comparative study showed proposed method outstanding accuracy reproducibility high magnification surgical microscope proposed calibration method applicable various endoscope microscope system zoom lens copy 2023 elsevier b v,microscopes prisms surgery calibration_method eye_parameters focal_lengths high_magnifications image_guided_surgery prism based_calibration surgical_guidance surgical_microscopes zoom_lens zoom_lens_calibration 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems medical other background objective augmented reality ar based surgical guidance system often used high magnification zoom lens system surgical microscope particularly neurology otolaryngology superimpose internal structure relevant organ microscopy image accurate calibration process obtain camera intrinsic hand ndash eye parameter microscope essential however conventional calibration method unsuitable surgical microscope narrow depth focus high magnification realize ar based surgical guidance high magnification surgical microscope herein propose new calibration method applicable highest magnification level well low magnification method key idea proposed method find relationship focal length hand ndash eye parameter remains constant regardless magnification level based even magnification change arbitrarily surgery intrinsic hand ndash eye parameter recalculated quickly accurately one two picture pattern also developed dedicated calibration tool prism take focused pattern image without interfering surgery result proposed calibration method ensured ar error lt 1 mm magnification level addition variation focal length within 1 regardless magnification level corresponding variation conventional calibration method exceeded 20 high magnification level conclusion comparative study showed proposed method outstanding accuracy reproducibility high magnification surgical microscope proposed calibration method applicable various endoscope microscope system zoom lens copy 2023 elsevier b v,background objective augmented reality ar based surgical guidance system often used high magnification zoom lens system surgical microscope particularly neurology otolaryngology superimpose internal structure relevant organ microscopy image accurate calibration process obtain camera intrinsic hand ndash eye parameter microscope essential however conventional calibration method unsuitable surgical microscope narrow depth focus high magnification realize ar based surgical guidance high magnification surgical microscope herein propose new calibration method applicable highest magnification level well low magnification method key idea proposed method find relationship focal length hand ndash eye parameter remains constant regardless magnification level based even magnification change arbitrarily surgery intrinsic hand ndash eye parameter recalculated quickly accurately one two picture pattern also developed dedicated calibration tool prism take focused pattern image without interfering surgery result proposed calibration method ensured ar error lt 1 mm magnification level addition variation focal length within 1 regardless magnification level corresponding variation conventional calibration method exceeded 20 high magnification level conclusion comparative study showed proposed method outstanding accuracy reproducibility high magnification surgical microscope proposed calibration method applicable various endoscope microscope system zoom lens copy 2023 elsevier b vmicroscopes prisms surgerycalibration_method eye_parameters focal_lengths high_magnifications image_guided_surgery prism based_calibration surgical_guidance surgical_microscopes zoom_lens zoom_lens_calibration
286,Designing Procedure Execution Tools with Emerging Technologies for Future Astronauts,"Karasinski, J. A., Torron Valverde, I. C., Brosnahan, H. L., Gale, J. W., Kim, R., Yashar, M., & Marquez, J. J. (2021). Designing Procedure Execution Tools with Emerging Technologies for Future Astronauts. Applied Sciences, 11(4), 1607. https://doi.org/10.3390/app11041607
",10.3390/app11041607,"NASA's human spaceflight efforts are moving towards long-duration exploration missions requiring asynchronous communication between onboard crew and an increasingly remote ground support. In current missions aboard the International Space Station, there is a near real-time communication loop between Mission Control Center and astronauts. This communication is essential today to support operations, maintenance, and science requirements onboard, without which many tasks would no longer be feasible. As NASA takes the next leap into a new era of human space exploration, new methods and tools compensating for the lack of continuous, real-time communication must be explored. The Human-Computer Interaction Group at NASA Ames Research Center has been investigating emerging technologies and their applicability to increase crew autonomy in missions beyond low Earth orbit. Interactions using augmented reality and the Internet of Things have been researched as possibilities to facilitate usability within procedure execution operations. This paper outlines four research efforts that included technology demonstrations and usability studies with prototype procedure tools implementing emerging technologies. The studies address habitat feedback integration, analogous procedure testing, task completion management, and crew training. Through these technology demonstrations and usability studies, we find that low- to medium-fidelity prototypes, evaluated early in the design process, are both effective for garnering stakeholder buy-in and developing requirements for future systems. In this paper, we present the findings of the usability studies for each project and discuss ways in which these emerging technologies can be integrated into future human spaceflight operations.","C7460 Aerospace engineering computing;C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",analogous procedure testing;asynchronous communication;augmented reality;crew training;current missions;future astronauts;human space exploration;human spaceflight operations;human-computer interaction group;International Space Station;Internet of Things;long-duration exploration missions;NASA Ames Research Center;onboard crew;procedure execution tools;real-time communication loop;remote ground support;science requirements,aerospace computing;augmented reality;human computer interaction;Internet of Things;space research;space vehicles,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Karasinski, J.A.; (2) Torron valverde, I.C.; (1) Brosnahan, H.L.; (1) Gale, J.W.; (2) Kim, R.; (2) Yashar, M.; (1) Marquez, J.J.; ","(1) NASA Ames Research Center, Moffett Field, CA 94035, United States; (2) San Jose&#769; State University Research Foundation, Moffett Field, CA 94035, United States; ",MDPI,-1,"[""aerospace computing"", ""human computer interaction"", ""internet of things"", ""space research"", ""space vehicles""]","[""aerospace computing"", ""human computer interaction"", ""internet of things"", ""space research"", ""space vehicles""]",aerospace computing;human computer interaction;internet of things;space research;space vehicles,education;aviation and aerospace;medical;automotive;internet of things;human-computer interaction;networks,technology;end users and user experience;industries,education;aviation and aerospace;medical;automotive;internet of things;human-computer interaction;networks,technology;end users and user experience;industries,aerospace_computing human_computer_interaction internet_of_things space_research space_vehicles analogous_procedure_testing asynchronous_communication augmented_reality crew_training current_missions future_astronauts human_space_exploration human_spaceflight_operations human computer_interaction_group international_space_station internet_of_things long duration_exploration_missions nasa_ames_research_center onboard_crew procedure_execution_tools real time_communication_loop remote_ground_support science_requirements c7460_aerospace_engineering_computing c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing education aviation_and_aerospace medical automotive internet_of_things human computer_interaction networks,aerospace_computing human_computer_interaction internet_of_things space_research space_vehicles,analogous_procedure_testing asynchronous_communication augmented_reality crew_training current_missions future_astronauts human_space_exploration human_spaceflight_operations human computer_interaction_group international_space_station internet_of_things long duration_exploration_missions nasa_ames_research_center onboard_crew procedure_execution_tools real time_communication_loop remote_ground_support science_requirements,nasa human spaceflight effort moving towards long duration exploration mission requiring asynchronous communication onboard crew increasingly remote ground support current mission aboard international space station near real time communication loop mission control center astronaut communication essential today support operation maintenance science requirement onboard without many task would longer feasible nasa take next leap new era human space exploration new method tool compensating lack continuous real time communication must explored human computer interaction group nasa ames research center investigating emerging technology applicability increase crew autonomy mission beyond low earth orbit interaction using augmented reality internet thing researched possibility facilitate usability within procedure execution operation paper outline four research effort included technology demonstration usability study prototype procedure tool implementing emerging technology study address habitat feedback integration analogous procedure testing task completion management crew training technology demonstration usability study find low medium fidelity prototype evaluated early design process effective garnering stakeholder buy developing requirement future system paper present finding usability study project discus way emerging technology integrated future human spaceflight operation,aerospace_computing human_computer_interaction internet_of_things space_research space_vehicles analogous_procedure_testing asynchronous_communication augmented_reality crew_training current_missions future_astronauts human_space_exploration human_spaceflight_operations human computer_interaction_group international_space_station internet_of_things long duration_exploration_missions nasa_ames_research_center onboard_crew procedure_execution_tools real time_communication_loop remote_ground_support science_requirements c7460_aerospace_engineering_computing c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing education aviation_and_aerospace medical automotive internet_of_things human computer_interaction networks nasa human spaceflight effort moving towards long duration exploration mission requiring asynchronous communication onboard crew increasingly remote ground support current mission aboard international space station near real time communication loop mission control center astronaut communication essential today support operation maintenance science requirement onboard without many task would longer feasible nasa take next leap new era human space exploration new method tool compensating lack continuous real time communication must explored human computer interaction group nasa ames research center investigating emerging technology applicability increase crew autonomy mission beyond low earth orbit interaction using augmented reality internet thing researched possibility facilitate usability within procedure execution operation paper outline four research effort included technology demonstration usability study prototype procedure tool implementing emerging technology study address habitat feedback integration analogous procedure testing task completion management crew training technology demonstration usability study find low medium fidelity prototype evaluated early design process effective garnering stakeholder buy developing requirement future system paper present finding usability study project discus way emerging technology integrated future human spaceflight operation,nasa human spaceflight effort moving towards long duration exploration mission requiring asynchronous communication onboard crew increasingly remote ground support current mission aboard international space station near real time communication loop mission control center astronaut communication essential today support operation maintenance science requirement onboard without many task would longer feasible nasa take next leap new era human space exploration new method tool compensating lack continuous real time communication must explored human computer interaction group nasa ames research center investigating emerging technology applicability increase crew autonomy mission beyond low earth orbit interaction using augmented reality internet thing researched possibility facilitate usability within procedure execution operation paper outline four research effort included technology demonstration usability study prototype procedure tool implementing emerging technology study address habitat feedback integration analogous procedure testing task completion management crew training technology demonstration usability study find low medium fidelity prototype evaluated early design process effective garnering stakeholder buy developing requirement future system paper present finding usability study project discus way emerging technology integrated future human spaceflight operationaerospace_computing human_computer_interaction internet_of_things space_research space_vehiclesanalogous_procedure_testing asynchronous_communication augmented_reality crew_training current_missions future_astronauts human_space_exploration human_spaceflight_operations human computer_interaction_group international_space_station internet_of_things long duration_exploration_missions nasa_ames_research_center onboard_crew procedure_execution_tools real time_communication_loop remote_ground_support science_requirements
287,Smart Sensors for Augmented Electrical Experiments,"Kapp, S., Lauer, F., Beil, F., Rheinländer, C. C., Wehn, N., & Kuhn, J. (2021). Smart Sensors for Augmented Electrical Experiments. Sensors, 22(1), 256. https://doi.org/10.3390/s22010256
",10.3390/s22010256,"With the recent increase in the use of augmented reality (AR) in educational laboratory settings, there is a need for new intelligent sensor systems capturing all aspects of the real environment. We present a smart sensor system meeting these requirements for STEM (science, technology, engineering, and mathematics) experiments in electrical circuits. The system consists of custom experiment boxes and cables combined with an application for the Microsoft HoloLens 2, which creates an AR experiment environment. The boxes combine sensors for measuring the electrical voltage and current at the integrated electrical components as well as a reconstruction of the currently constructed electrical circuit and the position of the sensor box on a table. Combing these data, the AR application visualizes the measurement data spatially and temporally coherent to the real experiment boxes, thus fulfilling demands derived from traditional multimedia learning theory. Following an evaluation of the accuracy and precision of the presented sensors, the usability of the system was evaluated with n=20 pupils in a German high school. In this evaluation, the usability of the system was rated with a system usability score of 94 out of 100.",B0120 Education and training;B7230S Intelligent sensors;C6130M Multimedia;C6130V Virtual reality;C7410 Electrical engineering computing;C7810C Computer-aided instruction,"AR experiment environment;augmented electrical experiments;augmented reality;custom experiment boxes;educational laboratory settings;electrical circuit;German high school;integrated electrical components;intelligent sensor systems;measurement data visualization;Microsoft HoloLens 2;science, technology, engineering, and mathematics;sensor box;smart sensor system;STEM experiments;system usability score;traditional multimedia learning theory",augmented reality;computer aided instruction;electrical engineering computing;electrical engineering education;intelligent sensors;laboratories;multimedia computing;STEM,2021,Journal article (JA),Sensors (Switzerland),"(1) Kapp, S.; (2) Lauer, F.; (1) Beil, F.; (2) Rheinla&#776;nder, C.C.; (2) Wehn, N.; (1) Kuhn, J.; ","(1) Technische Universita&#776;t Kaiserslautern, Department of Physics, Germany; (2) Technische Universita&#776;t Kaiserslautern, Department of Electrical and Computer Engineering, Germany; ",MDPI,-1,"[""computer aided instruction"", ""electrical engineering computing"", ""electrical engineering education"", ""intelligent sensors"", ""laboratories"", ""multimedia computing"", ""stem""]","[""computer aided instruction"", ""electrical engineering computing"", ""electrical engineering education"", ""intelligent sensors"", ""laboratories"", ""multimedia computing"", ""stem""]",computer aided instruction;electrical engineering computing;electrical engineering education;intelligent sensors;laboratories;multimedia computing;stem,education;engineering;training;sensors,technology;use cases;industries,education;engineering;training;sensors,technology;use cases;industries,computer_aided_instruction electrical_engineering_computing electrical_engineering_education intelligent_sensors laboratories multimedia_computing stem ar_experiment_environment augmented_electrical_experiments augmented_reality custom_experiment_boxes educational_laboratory_settings electrical_circuit german_high_school integrated_electrical_components intelligent_sensor_systems measurement_data_visualization microsoft_hololens_2 science _technology _engineering _and_mathematics sensor_box smart_sensor_system stem_experiments system_usability_score traditional_multimedia_learning_theory b0120_education_and_training b7230s_intelligent_sensors c6130m_multimedia c6130v_virtual_reality c7410_electrical_engineering_computing c7810c_computer aided_instruction education engineering training sensors,computer_aided_instruction electrical_engineering_computing electrical_engineering_education intelligent_sensors laboratories multimedia_computing stem,ar_experiment_environment augmented_electrical_experiments augmented_reality custom_experiment_boxes educational_laboratory_settings electrical_circuit german_high_school integrated_electrical_components intelligent_sensor_systems measurement_data_visualization microsoft_hololens_2 science _technology _engineering _and_mathematics sensor_box smart_sensor_system stem_experiments system_usability_score traditional_multimedia_learning_theory,recent increase use augmented reality ar educational laboratory setting need new intelligent sensor system capturing aspect real environment present smart sensor system meeting requirement stem science technology engineering mathematics experiment electrical circuit system consists custom experiment box cable combined application microsoft hololens 2 creates ar experiment environment box combine sensor measuring electrical voltage current integrated electrical component well reconstruction currently constructed electrical circuit position sensor box table combing data ar application visualizes measurement data spatially temporally coherent real experiment box thus fulfilling demand derived traditional multimedia learning theory following evaluation accuracy precision presented sensor usability system evaluated n 20 pupil german high school evaluation usability system rated system usability score 94 100,computer_aided_instruction electrical_engineering_computing electrical_engineering_education intelligent_sensors laboratories multimedia_computing stem ar_experiment_environment augmented_electrical_experiments augmented_reality custom_experiment_boxes educational_laboratory_settings electrical_circuit german_high_school integrated_electrical_components intelligent_sensor_systems measurement_data_visualization microsoft_hololens_2 science _technology _engineering _and_mathematics sensor_box smart_sensor_system stem_experiments system_usability_score traditional_multimedia_learning_theory b0120_education_and_training b7230s_intelligent_sensors c6130m_multimedia c6130v_virtual_reality c7410_electrical_engineering_computing c7810c_computer aided_instruction education engineering training sensors recent increase use augmented reality ar educational laboratory setting need new intelligent sensor system capturing aspect real environment present smart sensor system meeting requirement stem science technology engineering mathematics experiment electrical circuit system consists custom experiment box cable combined application microsoft hololens 2 creates ar experiment environment box combine sensor measuring electrical voltage current integrated electrical component well reconstruction currently constructed electrical circuit position sensor box table combing data ar application visualizes measurement data spatially temporally coherent real experiment box thus fulfilling demand derived traditional multimedia learning theory following evaluation accuracy precision presented sensor usability system evaluated n 20 pupil german high school evaluation usability system rated system usability score 94 100,recent increase use augmented reality ar educational laboratory setting need new intelligent sensor system capturing aspect real environment present smart sensor system meeting requirement stem science technology engineering mathematics experiment electrical circuit system consists custom experiment box cable combined application microsoft hololens 2 creates ar experiment environment box combine sensor measuring electrical voltage current integrated electrical component well reconstruction currently constructed electrical circuit position sensor box table combing data ar application visualizes measurement data spatially temporally coherent real experiment box thus fulfilling demand derived traditional multimedia learning theory following evaluation accuracy precision presented sensor usability system evaluated n 20 pupil german high school evaluation usability system rated system usability score 94 100computer_aided_instruction electrical_engineering_computing electrical_engineering_education intelligent_sensors laboratories multimedia_computing stemar_experiment_environment augmented_electrical_experiments augmented_reality custom_experiment_boxes educational_laboratory_settings electrical_circuit german_high_school integrated_electrical_components intelligent_sensor_systems measurement_data_visualization microsoft_hololens_2 science _technology _engineering _and_mathematics sensor_box smart_sensor_system stem_experiments system_usability_score traditional_multimedia_learning_theory
288,AR HUD Interface Optimization Model for Balancing Driver's Visual Sensitivity and Fatigue,"Dou, J., Xu, C., Chen, S., Xue, C., & Li, X. (2022). AR HUD Interface Optimization Model for Balancing Driver’s Visual Sensitivity and Fatigue. Procedia Computer Science, 214, 1568–1580. https://doi.org/10.1016/j.procs.2022.11.345
",10.1016/j.procs.2022.11.345,"With the wide application of intelligent driving assistance system, the augmented reality head-up display (AR HUD) interface plays an increasingly important role in drivers' real-time perception of traffic environment. As the AR HUD is vulnerable to be affected by changed ambient light, it weakens the legibility of the virtual interface and driver's visual comfort to a certain extent. The content color, as one of interface visual design elements, directly affects the performance of driver, which include the visual sensitivity and fatigue and further influences the vehicle safety. The selection between luminance contrast (affects sensitive and number of applicable environments) and driver performance (affects fatigue) are contradictory issues. In order to solve this contradictory problem in the design of AR HUD interface, and balance the cognitive load and situation awareness of driver, an extended analysis and optimization method of interface element was proposed. This method quantifies the discrete interface elements and makes the opposition problem consistent. The content color selection models under two conditions are constructed, which describe the distance from the chosen color to the optimal interval. It has been proved to be effective in finding the best answer for driver performance in interface design. Other interface elements in AR HUD can also be further optimized based on this method. All rights reserved Elsevier.",B7260 Display technology;C0240 Ergonomic aspects of computing;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7445 Traffic engineering computing,applicable environments;AR HUD interface optimization model;augmented reality head-up display interface;balancing driver;changed ambient light;cognitive load;content color selection models;contradictory issues;contradictory problem;discrete interface elements;driver performance;extended analysis;fatigue;intelligent driving assistance system;interface design;interface element;interface visual design elements;optimal interval;optimization method;real-time perception;traffic environment;virtual interface;visual sensitivity,augmented reality;cognition;data visualisation;driver information systems;head-up displays;helmet mounted displays;human factors;optimisation;road safety;user interfaces,2022,Journal article (JA),Procedia Comput. Sci. (Netherlands),(1) Jinzhen Dou; (2) Chang Xu; (1) Shanguang Chen; (1) Chengqi Xue; (3) Xingsen Li; ,"(1) Southeast University, School of Mechanical Engineering, China; (2) Donghua University, College of Mechanical Engineering, China; (3) Guangdong University of Technology, Research Institute Extenics and Innovative Methods, China; ",Elsevier B.V.,-1,"[""cognition"", ""data visualization"", ""driver information systems"", ""head up displays"", ""helmet mounted displays"", ""human factors"", ""optimization"", ""road safety"", ""user interfaces""]","[""cognition"", ""data visualization"", ""driver information systems"", ""head up displays"", ""helmet mounted displays"", ""human factors"", ""optimization"", ""road safety"", ""user interfaces""]",cognition;data visualization;driver information systems;head up displays;helmet mounted displays;human factors;optimization;road safety;user interfaces,"education;transportation;automotive;inspection, safety and quality;business performance metrics;display technology;human factors;wearables;developers;data;human-computer interaction",displays;business;end users and user experience;industries;use cases;technology,"education;transportation;automotive;inspection, safety and quality;business performance metrics;display technology;human factors;wearables;developers;data;human-computer interaction",displays;business;end users and user experience;industries;use cases;technology,cognition data_visualization driver_information_systems head_up_displays helmet_mounted_displays human_factors optimization road_safety user_interfaces applicable_environments ar_hud_interface_optimization_model augmented_reality_head up_display_interface balancing_driver changed_ambient_light cognitive_load content_color_selection_models contradictory_issues contradictory_problem discrete_interface_elements driver_performance extended_analysis fatigue intelligent_driving_assistance_system interface_design interface_element interface_visual_design_elements optimal_interval optimization_method real time_perception traffic_environment virtual_interface visual_sensitivity b7260_display_technology c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7445_traffic_engineering_computing education transportation automotive inspection _safety_and_quality business_performance_metrics display_technology human_factors wearables developers data human computer_interaction,cognition data_visualization driver_information_systems head_up_displays helmet_mounted_displays human_factors optimization road_safety user_interfaces,applicable_environments ar_hud_interface_optimization_model augmented_reality_head up_display_interface balancing_driver changed_ambient_light cognitive_load content_color_selection_models contradictory_issues contradictory_problem discrete_interface_elements driver_performance extended_analysis fatigue intelligent_driving_assistance_system interface_design interface_element interface_visual_design_elements optimal_interval optimization_method real time_perception traffic_environment virtual_interface visual_sensitivity,wide application intelligent driving assistance system augmented reality head display ar hud interface play increasingly important role driver real time perception traffic environment ar hud vulnerable affected changed ambient light weakens legibility virtual interface driver visual comfort certain extent content color one interface visual design element directly affect performance driver include visual sensitivity fatigue influence vehicle safety selection luminance contrast affect sensitive number applicable environment driver performance affect fatigue contradictory issue order solve contradictory problem design ar hud interface balance cognitive load situation awareness driver extended analysis optimization method interface element proposed method quantifies discrete interface element make opposition problem consistent content color selection model two condition constructed describe distance chosen color optimal interval proved effective finding best answer driver performance interface design interface element ar hud also optimized based method right reserved elsevier,cognition data_visualization driver_information_systems head_up_displays helmet_mounted_displays human_factors optimization road_safety user_interfaces applicable_environments ar_hud_interface_optimization_model augmented_reality_head up_display_interface balancing_driver changed_ambient_light cognitive_load content_color_selection_models contradictory_issues contradictory_problem discrete_interface_elements driver_performance extended_analysis fatigue intelligent_driving_assistance_system interface_design interface_element interface_visual_design_elements optimal_interval optimization_method real time_perception traffic_environment virtual_interface visual_sensitivity b7260_display_technology c0240_ergonomic_aspects_of_computing c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7445_traffic_engineering_computing education transportation automotive inspection _safety_and_quality business_performance_metrics display_technology human_factors wearables developers data human computer_interaction wide application intelligent driving assistance system augmented reality head display ar hud interface play increasingly important role driver real time perception traffic environment ar hud vulnerable affected changed ambient light weakens legibility virtual interface driver visual comfort certain extent content color one interface visual design element directly affect performance driver include visual sensitivity fatigue influence vehicle safety selection luminance contrast affect sensitive number applicable environment driver performance affect fatigue contradictory issue order solve contradictory problem design ar hud interface balance cognitive load situation awareness driver extended analysis optimization method interface element proposed method quantifies discrete interface element make opposition problem consistent content color selection model two condition constructed describe distance chosen color optimal interval proved effective finding best answer driver performance interface design interface element ar hud also optimized based method right reserved elsevier,wide application intelligent driving assistance system augmented reality head display ar hud interface play increasingly important role driver real time perception traffic environment ar hud vulnerable affected changed ambient light weakens legibility virtual interface driver visual comfort certain extent content color one interface visual design element directly affect performance driver include visual sensitivity fatigue influence vehicle safety selection luminance contrast affect sensitive number applicable environment driver performance affect fatigue contradictory issue order solve contradictory problem design ar hud interface balance cognitive load situation awareness driver extended analysis optimization method interface element proposed method quantifies discrete interface element make opposition problem consistent content color selection model two condition constructed describe distance chosen color optimal interval proved effective finding best answer driver performance interface design interface element ar hud also optimized based method right reserved elseviercognition data_visualization driver_information_systems head_up_displays helmet_mounted_displays human_factors optimization road_safety user_interfacesapplicable_environments ar_hud_interface_optimization_model augmented_reality_head up_display_interface balancing_driver changed_ambient_light cognitive_load content_color_selection_models contradictory_issues contradictory_problem discrete_interface_elements driver_performance extended_analysis fatigue intelligent_driving_assistance_system interface_design interface_element interface_visual_design_elements optimal_interval optimization_method real time_perception traffic_environment virtual_interface visual_sensitivity
289,Strategic Information System Planning in the Industry 4.0 Era: A Systematic Literature Review,"Mahendra, I., Ramadhan, A., Trisetyarso, A., Abdurachman, E., & Zarlis, M. (2022). Strategic Information System Planning in the Industry 4.0 Era: A Systematic Literature Review. 2022 IEEE Creative Communication and Innovative Technology (ICCIT). https://doi.org/10.1109/iccit55355.2022.10119002
",10.1109/ICCIT55355.2022.10119002,"Information systems and technology have an important role in building the Company's competitive advantage in facing the Industrial Era 4.0. Strategic Information System Planning (SISP) helps companies formulate reliable information systems that are aligned with business strategies. The academic world should contribute in this regard, but currently, the amount of research related to SISP is very limited. This research is a systematic literature review, which aims to find out more about SISP research trends, research motivations and backgrounds, industries that have been handled, and the methods used in developing SISP. This research is expected to be a trigger for the emergence of new research to support the successful development of SISP in companies in various industries. The results of this research show that several topics are widely researched and need to be improved in the future, namely the alignment of IS strategies with business strategies, the development of specific SISPs in various industries, and the reliability of IS strategies by considering the application of the latest information technology, such as blockchain, artificial intelligence, big data, augmented reality, Internet of Things, and cloud computing. In addition, it is also necessary to develop a SISP framework that is more accommodating to changes in the business environment that is increasingly fast, agile, and collaborative, which includes aspects of business architecture, data/information architecture, technology architecture, information system security, governance, and human resources.","C7160 Manufacturing and industrial administration;C6130J Big Data;C6130S Data security;C6130V Virtual reality;C6160B Distributed databases;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing;C6210 Knowledge based systems;E0120D Planning;E0410D Industrial applications of IT;E0410F Business applications of IT",artificial intelligence;augmented reality;Big Data;blockchain;business architecture;business environment;business strategies;cloud computing;data architecture;governance;human resources;industry 4.0 Era;information architecture;information system security;information technology;Internet of Things;IS strategies;reliable information systems;research motivations;SISP framework;SISP research trends;strategic information system planning;systematic literature review;technology architecture,artificial intelligence;augmented reality;Big Data;blockchains;business data processing;cloud computing;information systems;Internet of Things;production engineering computing;strategic planning,2022,Conference article (CA),2022 IEEE Creative Communication and Innovative Technology (ICCIT),"(1) Mahendra, I.; (3) Ramadhan, A.; (3) Trisetyarso, A.; (3) Abdurachman, E.; (3) Zarlis, M.; ","(1) Bina Nusantara University, Indonesia; (2) Nusa Mandiri University, Information Technology Faculty, Indonesia; (3) Bina Nusantara University, Computer Science Department, Indonesia; ",IEEE,-1,"[""artificial intelligence"", ""big data"", ""blockchains"", ""business data processing"", ""cloud computing"", ""information systems"", ""internet of things"", ""production engineering computing"", ""strategic planning""]","[""artificial intelligence"", ""big data"", ""blockchains"", ""business data processing"", ""cloud computing"", ""information systems"", ""internet of things"", ""production engineering computing"", ""strategic planning""]",artificial intelligence;big data;blockchains;business data processing;cloud computing;information systems;internet of things;production engineering computing;strategic planning,education;manufacturing;security;other;liberal arts;business performance metrics;internet of things;engineering;developers;data;artificial intelligence;business planning and management;networks,technology;other;business;industries,education;manufacturing;security;other;liberal arts;business performance metrics;internet of things;engineering;developers;data;artificial intelligence;business planning and management;networks,technology;other;business;industries,artificial_intelligence big_data blockchains business_data_processing cloud_computing information_systems internet_of_things production_engineering_computing strategic_planning artificial_intelligence augmented_reality big_data blockchain business_architecture business_environment business_strategies cloud_computing data_architecture governance human_resources industry_4 0_era information_architecture information_system_security information_technology internet_of_things is_strategies reliable_information_systems research_motivations sisp_framework sisp_research_trends strategic_information_system_planning systematic_literature_review technology_architecture c7160_manufacturing_and_industrial_administration c6130j_big_data c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c6210_knowledge_based_systems e0120d_planning e0410d_industrial_applications_of_it e0410f_business_applications_of_it education manufacturing security other liberal_arts business_performance_metrics internet_of_things engineering developers data artificial_intelligence business_planning_and_management networks,artificial_intelligence big_data blockchains business_data_processing cloud_computing information_systems internet_of_things production_engineering_computing strategic_planning,artificial_intelligence augmented_reality big_data blockchain business_architecture business_environment business_strategies cloud_computing data_architecture governance human_resources industry_4 0_era information_architecture information_system_security information_technology internet_of_things is_strategies reliable_information_systems research_motivations sisp_framework sisp_research_trends strategic_information_system_planning systematic_literature_review technology_architecture,information system technology important role building company competitive advantage facing industrial era 4 0 strategic information system planning sisp help company formulate reliable information system aligned business strategy academic world contribute regard currently amount research related sisp limited research systematic literature review aim find sisp research trend research motivation background industry handled method used developing sisp research expected trigger emergence new research support successful development sisp company various industry result research show several topic widely researched need improved future namely alignment strategy business strategy development specific sisps various industry reliability strategy considering application latest information technology blockchain artificial intelligence big data augmented reality internet thing cloud computing addition also necessary develop sisp framework accommodating change business environment increasingly fast agile collaborative includes aspect business architecture data information architecture technology architecture information system security governance human resource,artificial_intelligence big_data blockchains business_data_processing cloud_computing information_systems internet_of_things production_engineering_computing strategic_planning artificial_intelligence augmented_reality big_data blockchain business_architecture business_environment business_strategies cloud_computing data_architecture governance human_resources industry_4 0_era information_architecture information_system_security information_technology internet_of_things is_strategies reliable_information_systems research_motivations sisp_framework sisp_research_trends strategic_information_system_planning systematic_literature_review technology_architecture c7160_manufacturing_and_industrial_administration c6130j_big_data c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c6210_knowledge_based_systems e0120d_planning e0410d_industrial_applications_of_it e0410f_business_applications_of_it education manufacturing security other liberal_arts business_performance_metrics internet_of_things engineering developers data artificial_intelligence business_planning_and_management networks information system technology important role building company competitive advantage facing industrial era 4 0 strategic information system planning sisp help company formulate reliable information system aligned business strategy academic world contribute regard currently amount research related sisp limited research systematic literature review aim find sisp research trend research motivation background industry handled method used developing sisp research expected trigger emergence new research support successful development sisp company various industry result research show several topic widely researched need improved future namely alignment strategy business strategy development specific sisps various industry reliability strategy considering application latest information technology blockchain artificial intelligence big data augmented reality internet thing cloud computing addition also necessary develop sisp framework accommodating change business environment increasingly fast agile collaborative includes aspect business architecture data information architecture technology architecture information system security governance human resource,information system technology important role building company competitive advantage facing industrial era 4 0 strategic information system planning sisp help company formulate reliable information system aligned business strategy academic world contribute regard currently amount research related sisp limited research systematic literature review aim find sisp research trend research motivation background industry handled method used developing sisp research expected trigger emergence new research support successful development sisp company various industry result research show several topic widely researched need improved future namely alignment strategy business strategy development specific sisps various industry reliability strategy considering application latest information technology blockchain artificial intelligence big data augmented reality internet thing cloud computing addition also necessary develop sisp framework accommodating change business environment increasingly fast agile collaborative includes aspect business architecture data information architecture technology architecture information system security governance human resourceartificial_intelligence big_data blockchains business_data_processing cloud_computing information_systems internet_of_things production_engineering_computing strategic_planningartificial_intelligence augmented_reality big_data blockchain business_architecture business_environment business_strategies cloud_computing data_architecture governance human_resources industry_4 0_era information_architecture information_system_security information_technology internet_of_things is_strategies reliable_information_systems research_motivations sisp_framework sisp_research_trends strategic_information_system_planning systematic_literature_review technology_architecture
290,Optical Image Processing of 2-D and 3-D Objects using Digital Holography,"Smith, E., & Banerjee, P. P. (2023). Optical image processing of 2-D and 3-D objects using digital holography. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2660594
",10.1117/12.2660594,"Traditional computer vision (CV) approaches are the norm when attempting to extract edge information from an imaged object. These discrete approaches are almost always performed on 2D intensity imagery and at times can be computationally expensive depending on the algorithm. Digital holography (DH) provides access to the 3D object information. By manipulation of the Fourier transform of the hologram, which is also needed for isolating the real or virtual image in off-axis DH, edge information can be extracted by high pass spatial filtering of the pertinent cropped and centered spectrum. We show simple simulations utilizing 2-D and 3-D objects to show edge enhancement qualities using this approach, and compare its performance to conventional CV techniques. The same technique can be used to perform other image processing functions, such as image sharpening, blurring, and others so long as the correct filters are applied. Developments in ultra-high definition displays have either incorporated DH or have overlapping areas of interest currently, including 3-D television and augmented reality. &copy; 2023 SPIE.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;741.1 Light/Optics;743 Holography;903.1 Information Sources and Analysis",3D imaging;3D object;Digital holography;Edge information;High definition;Images processing;Optical image processing;Traditional computers;Ultra high-definition;Ultra-high,Augmented reality;Geometrical optics;Holograms;Information filtering,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Smith, Eric; (1) Banerjee, Partha; ","(1) Department of Electro-Optics and Photonics, University of Dayton, Dayton; OH; 45469, United States; ",SPIE,-1,"[""geometrical optics"", ""holograms"", ""information filtering""]","[""geometrical optics"", ""holograms"", ""information filtering""]",geometrical optics;holograms;information filtering,optics;developers;graphics,technology;displays,optics;developers;graphics,technology;displays,geometrical_optics holograms information_filtering 3d_imaging 3d_object digital_holography edge_information high_definition images_processing optical_image_processing traditional_computers ultra_high definition ultra high 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 743_holography 903 1_information_sources_and_analysis optics developers graphics,geometrical_optics holograms information_filtering,3d_imaging 3d_object digital_holography edge_information high_definition images_processing optical_image_processing traditional_computers ultra_high definition ultra high,traditional computer vision cv approach norm attempting extract edge information imaged object discrete approach almost always performed 2d intensity imagery time computationally expensive depending algorithm digital holography dh provides access 3d object information manipulation fourier transform hologram also needed isolating real virtual image axis dh edge information extracted high pas spatial filtering pertinent cropped centered spectrum show simple simulation utilizing 2 3 object show edge enhancement quality using approach compare performance conventional cv technique technique used perform image processing function image sharpening blurring others long correct filter applied development ultra high definition display either incorporated dh overlapping area interest currently including 3 television augmented reality copy 2023 spie,geometrical_optics holograms information_filtering 3d_imaging 3d_object digital_holography edge_information high_definition images_processing optical_image_processing traditional_computers ultra_high definition ultra high 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 743_holography 903 1_information_sources_and_analysis optics developers graphics traditional computer vision cv approach norm attempting extract edge information imaged object discrete approach almost always performed 2d intensity imagery time computationally expensive depending algorithm digital holography dh provides access 3d object information manipulation fourier transform hologram also needed isolating real virtual image axis dh edge information extracted high pas spatial filtering pertinent cropped centered spectrum show simple simulation utilizing 2 3 object show edge enhancement quality using approach compare performance conventional cv technique technique used perform image processing function image sharpening blurring others long correct filter applied development ultra high definition display either incorporated dh overlapping area interest currently including 3 television augmented reality copy 2023 spie,traditional computer vision cv approach norm attempting extract edge information imaged object discrete approach almost always performed 2d intensity imagery time computationally expensive depending algorithm digital holography dh provides access 3d object information manipulation fourier transform hologram also needed isolating real virtual image axis dh edge information extracted high pas spatial filtering pertinent cropped centered spectrum show simple simulation utilizing 2 3 object show edge enhancement quality using approach compare performance conventional cv technique technique used perform image processing function image sharpening blurring others long correct filter applied development ultra high definition display either incorporated dh overlapping area interest currently including 3 television augmented reality copy 2023 spiegeometrical_optics holograms information_filtering3d_imaging 3d_object digital_holography edge_information high_definition images_processing optical_image_processing traditional_computers ultra_high definition ultra high
291,Robotics and sensing technologies in red meat processing: A review,"Aly, B. A., Low, T., Long, D., Baillie, C., & Brett, P. (2023). Robotics and sensing technologies in red meat processing: A review. Trends in Food Science &amp; Technology, 137, 142–155. https://doi.org/10.1016/j.tifs.2023.05.015
",10.1016/j.tifs.2023.05.015,"Background: The red meat processing industry has a harsh work environment where tasks performed in abattoirs are physically and mentally demanding. In addition, the high financial costs associated with employing skilled labour, the shortage of such workers, and the rise in worldwide meat consumption, there has been a growing push towards integrating automation as a potential solution for the industry. Scope and approach: This paper describes the complexities of implementing robotics technology in red meat processing. The complexity when processing deformable natural meat mediums is significantly sensitive to the variations of workpieces caused by mechanical properties, physical shape and the position of tissues. These differences hinder conventional robotic systems from succeeding. Experimental and commercial robotic systems in red meat processing are shown to perform cutting tasks in the deboning room, whose systems capabilities are limited by executing cuts requiring little to no adaptability during the process. The review shows that X-ray, optical probes, and ultrasonic are the most effective sensing technologies in determining the cutting trajectories prior to the task. Some experimental systems utilised tactile sensing to follow more complex cutting paths but have not yet produced a commercially viable product. The evaluation of these sensing technologies' applicability to guide a robotic system in real-time is critical to tackling more complex cuts. Key findings and conclusions: A combination of preoperative scanning and real-time perception for adaptive control is recommended to automate tasks in red meat cutting. Also, it is recommended that to fully automate the meat cutting process, a gradual approach should be taken by shifting abattoirs by first utilising assistive technologies such as cobots, exoskeletons augmented reality, and virtual reality. &copy; 2023 The Authors","723 Computer Software, Data Handling and Applications;731.1 Control Systems;731.5 Robotics;822.3 Food Products",Adaptive Control;Cutting task;Financial costs;Meat-processing industry;Red-meat-processing;Robotic systems;Robotic technologies;Sensing technology;Skilled labor;Work environments,Augmented reality;Cutting;Exoskeleton (Robotics);Meats,2023,Journal article (JA),Trends Food Sci. Technol.,"(1) Aly, Basem Adel; (2) Low, Tobias; (1) Long, Derek; (3) Baillie, Craig; (1) Brett, Peter; ","(1) Center for Agricultural Engineering, University of Southern Queensland, Australia; (2) School of Engineering, University of Southern Queensland, Australia; (3) School of Agriculture and Environment Science, University of Southern Queensland, Australia; ",Elsevier Ltd,-1,"[""cutting"", ""exoskeleton"", ""meats""]","[""cutting"", ""exoskeleton"", ""meats""]",cutting;exoskeleton;meats,other;manufacturing;robotics,technology;other;industries,other;manufacturing;robotics,technology;other;industries,cutting exoskeleton meats adaptive_control cutting_task financial_costs meat processing_industry red meat processing robotic_systems robotic_technologies sensing_technology skilled_labor work_environments 723_computer_software _data_handling_and_applications 731 1_control_systems 731 5_robotics 822 3_food_products other manufacturing robotics,cutting exoskeleton meats,adaptive_control cutting_task financial_costs meat processing_industry red meat processing robotic_systems robotic_technologies sensing_technology skilled_labor work_environments,background red meat processing industry harsh work environment task performed abattoir physically mentally demanding addition high financial cost associated employing skilled labour shortage worker rise worldwide meat consumption growing push towards integrating automation potential solution industry scope approach paper describes complexity implementing robotics technology red meat processing complexity processing deformable natural meat medium significantly sensitive variation workpiece caused mechanical property physical shape position tissue difference hinder conventional robotic system succeeding experimental commercial robotic system red meat processing shown perform cutting task deboning room whose system capability limited executing cut requiring little adaptability process review show x ray optical probe ultrasonic effective sensing technology determining cutting trajectory prior task experimental system utilised tactile sensing follow complex cutting path yet produced commercially viable product evaluation sensing technology applicability guide robotic system real time critical tackling complex cut key finding conclusion combination preoperative scanning real time perception adaptive control recommended automate task red meat cutting also recommended fully automate meat cutting process gradual approach taken shifting abattoir first utilising assistive technology cobots exoskeleton augmented reality virtual reality copy 2023 author,cutting exoskeleton meats adaptive_control cutting_task financial_costs meat processing_industry red meat processing robotic_systems robotic_technologies sensing_technology skilled_labor work_environments 723_computer_software _data_handling_and_applications 731 1_control_systems 731 5_robotics 822 3_food_products other manufacturing robotics background red meat processing industry harsh work environment task performed abattoir physically mentally demanding addition high financial cost associated employing skilled labour shortage worker rise worldwide meat consumption growing push towards integrating automation potential solution industry scope approach paper describes complexity implementing robotics technology red meat processing complexity processing deformable natural meat medium significantly sensitive variation workpiece caused mechanical property physical shape position tissue difference hinder conventional robotic system succeeding experimental commercial robotic system red meat processing shown perform cutting task deboning room whose system capability limited executing cut requiring little adaptability process review show x ray optical probe ultrasonic effective sensing technology determining cutting trajectory prior task experimental system utilised tactile sensing follow complex cutting path yet produced commercially viable product evaluation sensing technology applicability guide robotic system real time critical tackling complex cut key finding conclusion combination preoperative scanning real time perception adaptive control recommended automate task red meat cutting also recommended fully automate meat cutting process gradual approach taken shifting abattoir first utilising assistive technology cobots exoskeleton augmented reality virtual reality copy 2023 author,background red meat processing industry harsh work environment task performed abattoir physically mentally demanding addition high financial cost associated employing skilled labour shortage worker rise worldwide meat consumption growing push towards integrating automation potential solution industry scope approach paper describes complexity implementing robotics technology red meat processing complexity processing deformable natural meat medium significantly sensitive variation workpiece caused mechanical property physical shape position tissue difference hinder conventional robotic system succeeding experimental commercial robotic system red meat processing shown perform cutting task deboning room whose system capability limited executing cut requiring little adaptability process review show x ray optical probe ultrasonic effective sensing technology determining cutting trajectory prior task experimental system utilised tactile sensing follow complex cutting path yet produced commercially viable product evaluation sensing technology applicability guide robotic system real time critical tackling complex cut key finding conclusion combination preoperative scanning real time perception adaptive control recommended automate task red meat cutting also recommended fully automate meat cutting process gradual approach taken shifting abattoir first utilising assistive technology cobots exoskeleton augmented reality virtual reality copy 2023 authorcutting exoskeleton meatsadaptive_control cutting_task financial_costs meat processing_industry red meat processing robotic_systems robotic_technologies sensing_technology skilled_labor work_environments
292,"Designing Immersive, Narrative-Based Interfaces to Guide Outdoor Learning","Cheng, A. Y., Ritchie, J., Agrawal, N., Childs, E., DeVeaux, C., Jee, Y., Leon, T., Maples, B., Cuadra, A., & Landay, J. A. (2023). Designing Immersive, Narrative-Based Interfaces to Guide Outdoor Learning. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581365
",10.1145/3544548.3581365,"Outdoor learning experiences, such as field trips, can improve children's science achievement and engagement, but these experiences are often difficult to deliver without extensive support. Narrative in educational experiences can provide needed structure, while also increasing engagement. We created a narrative-based, mobile application to investigate how to guide young learners in interacting with their local, outdoor environment. In a second variant, we added augmented reality and image classification to explore the value of these features. A study (n = 44) found that participants using our system demonstrated learning gains and found the experience engaging. Our findings identified several major themes, including participant excitement for hands-on interactions with nature, curiosity about the characters, and enthusiasm toward typing their thoughts and observations. We offer a set of design implications for supporting narrative-based, outdoor learning with immersive technology.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces,children;design implications;educational experiences;extensive support;field trips;guide outdoor learning;hands-on interactions;image classification;immersive technology;learning experiences;local environment;mobile application;narrative-based;outdoor environment;participant excitement;young learners,augmented reality;computer aided instruction;image classification,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Cheng, A.Y.; (1) Ritchie, J.; (1) Agrawal, N.; (2) Childs, E.; (3) Deveaux, C.; (1) Jee, Y.; (1) Leon, T.; (4) Maples, B.; (1) Cuadra, A.; (1) Landay, J.A.; ","(1) Stanford University, Computer Science Department, Stanford, CA, United States; (2) Stanford University, Mechanical Engineering Department, Stanford, CA, United States; (3) Stanford University, Communication Department, Stanford, CA, United States; (4) Stanford University, Graduate School of Education, Stanford, CA, United States; ",ACM,-1,"[""computer aided instruction"", ""image classification""]","[""computer aided instruction"", ""image classification""]",computer aided instruction;image classification,computer vision;training,technology;use cases,computer vision;training,technology;use cases,computer_aided_instruction image_classification children design_implications educational_experiences extensive_support field_trips guide_outdoor_learning hands on_interactions image_classification immersive_technology learning_experiences local_environment mobile_application narrative based outdoor_environment participant_excitement young_learners c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision training,computer_aided_instruction image_classification,children design_implications educational_experiences extensive_support field_trips guide_outdoor_learning hands on_interactions image_classification immersive_technology learning_experiences local_environment mobile_application narrative based outdoor_environment participant_excitement young_learners,outdoor learning experience field trip improve child science achievement engagement experience often difficult deliver without extensive support narrative educational experience provide needed structure also increasing engagement created narrative based mobile application investigate guide young learner interacting local outdoor environment second variant added augmented reality image classification explore value feature study n 44 found participant using system demonstrated learning gain found experience engaging finding identified several major theme including participant excitement hand interaction nature curiosity character enthusiasm toward typing thought observation offer set design implication supporting narrative based outdoor learning immersive technology,computer_aided_instruction image_classification children design_implications educational_experiences extensive_support field_trips guide_outdoor_learning hands on_interactions image_classification immersive_technology learning_experiences local_environment mobile_application narrative based outdoor_environment participant_excitement young_learners c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces computer_vision training outdoor learning experience field trip improve child science achievement engagement experience often difficult deliver without extensive support narrative educational experience provide needed structure also increasing engagement created narrative based mobile application investigate guide young learner interacting local outdoor environment second variant added augmented reality image classification explore value feature study n 44 found participant using system demonstrated learning gain found experience engaging finding identified several major theme including participant excitement hand interaction nature curiosity character enthusiasm toward typing thought observation offer set design implication supporting narrative based outdoor learning immersive technology,outdoor learning experience field trip improve child science achievement engagement experience often difficult deliver without extensive support narrative educational experience provide needed structure also increasing engagement created narrative based mobile application investigate guide young learner interacting local outdoor environment second variant added augmented reality image classification explore value feature study n 44 found participant using system demonstrated learning gain found experience engaging finding identified several major theme including participant excitement hand interaction nature curiosity character enthusiasm toward typing thought observation offer set design implication supporting narrative based outdoor learning immersive technologycomputer_aided_instruction image_classificationchildren design_implications educational_experiences extensive_support field_trips guide_outdoor_learning hands on_interactions image_classification immersive_technology learning_experiences local_environment mobile_application narrative based outdoor_environment participant_excitement young_learners
293,Design of a Hybrid Total-internal-reflection Collimator,"Zhou, Y., Fang, F., & Zhang, J. (2022). Design of a hybrid Total-internal-reflection Collimator. 2022 8th International Conference on Nanomanufacturing &amp; 4th AET Symposium on ACSM and Digital Manufacturing (Nanoman-AETS). https://doi.org/10.1109/nanoman-aets56035.2022.10119463
",10.1109/Nanoman-AETS56035.2022.10119463,"A hybrid structural total internal reflection (TIR) collimator is designed based on Snell's law for the secondary light distribution for the projectors. The performance of the system were evaluated through simulation. The illumination uniformity of the system reached over 94% and the luminous flux utilization rate was over 91% based on simulation using by LightTools software. The axial-symmetrical collimating system has various impressive features, for instance, simple and compact structure, small size, lightweight, and high illumination uniformity, which can meet the requirements of the augmented reality (AR) glasses or projectors.",A4215E Optical system design;A4280A Optical lenses and mirrors;A4280J Optical collimators and autocollimators;B4190 Other optical system components;C6130V Virtual reality,axial-symmetrical collimating system;compact structure;high illumination uniformity;hybrid structural total internal reflection collimator;luminous flux utilization rate;projectors;secondary light distribution;simple structure;Snell's law;total-internal-reflection collimator,augmented reality;optical design techniques;optical projectors,2022,Conference article (CA),2022 8th International Conference on Nanomanufacturing &amp; 4th AET Symposium on ACSM and Digital Manufacturing (Nanoman-AETS),"(1) Zhou, Y.; (1) Fang, F.; (1) Zhang, J.; ","(1) University College Dublin, School of Mechanical and Materials Engineering, Ireland; (2) Tianjin University, State Key Laboratory of Precision Measuring Technology and Instruments, China; ",IEEE,-1,"[""optical design techniques"", ""optical projectors""]","[""optical design techniques"", ""optical projectors""]",optical design techniques;optical projectors,optics;human-computer interaction,displays;end users and user experience,optics;human-computer interaction,displays;end users and user experience,optical_design_techniques optical_projectors axial symmetrical_collimating_system compact_structure high_illumination_uniformity hybrid_structural_total_internal_reflection_collimator luminous_flux_utilization_rate projectors secondary_light_distribution simple_structure snell s_law total internal reflection_collimator a4215e_optical_system_design a4280a_optical_lenses_and_mirrors a4280j_optical_collimators_and_autocollimators b4190_other_optical_system_components c6130v_virtual_reality optics human computer_interaction,optical_design_techniques optical_projectors,axial symmetrical_collimating_system compact_structure high_illumination_uniformity hybrid_structural_total_internal_reflection_collimator luminous_flux_utilization_rate projectors secondary_light_distribution simple_structure snell s_law total internal reflection_collimator,hybrid structural total internal reflection tir collimator designed based snell law secondary light distribution projector performance system evaluated simulation illumination uniformity system reached 94 luminous flux utilization rate 91 based simulation using lighttools software axial symmetrical collimating system various impressive feature instance simple compact structure small size lightweight high illumination uniformity meet requirement augmented reality ar glass projector,optical_design_techniques optical_projectors axial symmetrical_collimating_system compact_structure high_illumination_uniformity hybrid_structural_total_internal_reflection_collimator luminous_flux_utilization_rate projectors secondary_light_distribution simple_structure snell s_law total internal reflection_collimator a4215e_optical_system_design a4280a_optical_lenses_and_mirrors a4280j_optical_collimators_and_autocollimators b4190_other_optical_system_components c6130v_virtual_reality optics human computer_interaction hybrid structural total internal reflection tir collimator designed based snell law secondary light distribution projector performance system evaluated simulation illumination uniformity system reached 94 luminous flux utilization rate 91 based simulation using lighttools software axial symmetrical collimating system various impressive feature instance simple compact structure small size lightweight high illumination uniformity meet requirement augmented reality ar glass projector,hybrid structural total internal reflection tir collimator designed based snell law secondary light distribution projector performance system evaluated simulation illumination uniformity system reached 94 luminous flux utilization rate 91 based simulation using lighttools software axial symmetrical collimating system various impressive feature instance simple compact structure small size lightweight high illumination uniformity meet requirement augmented reality ar glass projectoroptical_design_techniques optical_projectorsaxial symmetrical_collimating_system compact_structure high_illumination_uniformity hybrid_structural_total_internal_reflection_collimator luminous_flux_utilization_rate projectors secondary_light_distribution simple_structure snell s_law total internal reflection_collimator
294,Hybrid Spine Simulator Prototype for X-ray Free Pedicle Screws Fixation Training,"Condino, S., Turini, G., Mamone, V., Parchi, P. D., & Ferrari, V. (2021). Hybrid Spine Simulator Prototype for X-ray Free Pedicle Screws Fixation Training. Applied Sciences, 11(3), 1038. https://doi.org/10.3390/app11031038
",10.3390/app11031038,"Simulation for surgical training is increasingly being considered a valuable addition to traditional teaching methods. 3D-printed physical simulators can be used for preoperative planning and rehearsal in spine surgery to improve surgical workflows and postoperative patient outcomes. This paper proposes an innovative strategy to build a hybrid simulation platform for training of pedicle screws fixation: the proposed method combines 3D-printed patient-specific spine models with augmented reality functionalities and virtual X-ray visualization, thus avoiding any exposure to harmful radiation during the simulation. Software functionalities are implemented by using a low-cost tracking strategy based on fiducial marker detection. Quantitative tests demonstrate the accuracy of the method to track the vertebral model and surgical tools, and to coherently visualize them in either the augmented reality or virtual fluoroscopic modalities. The obtained results encourage further research and clinical validation towards the use of the simulator as an effective tool for training in pedicle screws insertion in lumbar vertebrae.","A8770E Patient diagnostic methods and instrumentation;A8760J X-rays and particle beams (medical uses);A8770G Patient care and treatment;A8770J Prosthetics and other practical applications;B6135 Optical, image and video signal processing;B7510P X-ray techniques: radiography and computed tomography (biomedical imaging/measurement);B7520 Patient care and treatment;B7520E Prosthetics and orthotics;C3385 Biological and medical control systems;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7330 Biology and medical computing",3D-printed physical simulators;augmented reality functionalities;fiducial marker detection;hybrid simulation platform;hybrid spine simulator prototype;innovative strategy;low-cost tracking strategy;patient-specific spine models;pedicle screws insertion;postoperative patient outcomes;preoperative planning;rehearsal;software functionalities;spine surgery;surgical tools;surgical training;surgical workflows;valuable addition;vertebral model;virtual fluoroscopic modalities;virtual X-ray visualization;X-ray free pedicle screws fixation training,augmented reality;biomechanics;bone;computerised tomography;diagnostic radiography;medical computing;medical image processing;medical robotics;neurophysiology;orthopaedics;prosthetics;surgery,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Condino, S.; (2) Turini, G.; (1) Mamone, V.; (3) Parchi, P.D.; (1) Ferrari, V.; ","(1) University of Pisa, Information Engineering Department, Italy; (2) Kettering University, Department of Computer Science, Flint, MI 48504, United States; (3) University of Pisa, Department of Translational Research and of New Surgical and Medical Technologies, Italy; ",MDPI,-1,"[""biomechanics"", ""bone"", ""computerized tomography"", ""diagnostic radiography"", ""medical computing"", ""medical image processing"", ""medical robotics"", ""neurophysiology"", ""orthopedics"", ""prosthetics"", ""surgery""]","[""biomechanics"", ""bone"", ""computerized tomography"", ""diagnostic radiography"", ""medical computing"", ""medical image processing"", ""medical robotics"", ""neurophysiology"", ""orthopedics"", ""prosthetics"", ""surgery""]",biomechanics;bone;computerized tomography;diagnostic radiography;medical computing;medical image processing;medical robotics;neurophysiology;orthopedics;prosthetics;surgery,computer vision;robotics;medical;telecommunication;data,technology;industries,computer vision;robotics;medical;telecommunication;data,technology;industries,biomechanics bone computerized_tomography diagnostic_radiography medical_computing medical_image_processing medical_robotics neurophysiology orthopedics prosthetics surgery 3d printed_physical_simulators augmented_reality_functionalities fiducial_marker_detection hybrid_simulation_platform hybrid_spine_simulator_prototype innovative_strategy low cost_tracking_strategy patient specific_spine_models pedicle_screws_insertion postoperative_patient_outcomes preoperative_planning rehearsal software_functionalities spine_surgery surgical_tools surgical_training surgical_workflows valuable_addition vertebral_model virtual_fluoroscopic_modalities virtual_x ray_visualization x ray_free_pedicle_screws_fixation_training a8770e_patient_diagnostic_methods_and_instrumentation a8760j_x rays_and_particle_beams_ medical_uses a8770g_patient_care_and_treatment a8770j_prosthetics_and_other_practical_applications b6135_optical _image_and_video_signal_processing b7510p_x ray_techniques _radiography_and_computed_tomography_ biomedical_imaging measurement b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision robotics medical telecommunication data,biomechanics bone computerized_tomography diagnostic_radiography medical_computing medical_image_processing medical_robotics neurophysiology orthopedics prosthetics surgery,3d printed_physical_simulators augmented_reality_functionalities fiducial_marker_detection hybrid_simulation_platform hybrid_spine_simulator_prototype innovative_strategy low cost_tracking_strategy patient specific_spine_models pedicle_screws_insertion postoperative_patient_outcomes preoperative_planning rehearsal software_functionalities spine_surgery surgical_tools surgical_training surgical_workflows valuable_addition vertebral_model virtual_fluoroscopic_modalities virtual_x ray_visualization x ray_free_pedicle_screws_fixation_training,simulation surgical training increasingly considered valuable addition traditional teaching method 3d printed physical simulator used preoperative planning rehearsal spine surgery improve surgical workflow postoperative patient outcome paper proposes innovative strategy build hybrid simulation platform training pedicle screw fixation proposed method combine 3d printed patient specific spine model augmented reality functionality virtual x ray visualization thus avoiding exposure harmful radiation simulation software functionality implemented using low cost tracking strategy based fiducial marker detection quantitative test demonstrate accuracy method track vertebral model surgical tool coherently visualize either augmented reality virtual fluoroscopic modality obtained result encourage research clinical validation towards use simulator effective tool training pedicle screw insertion lumbar vertebra,biomechanics bone computerized_tomography diagnostic_radiography medical_computing medical_image_processing medical_robotics neurophysiology orthopedics prosthetics surgery 3d printed_physical_simulators augmented_reality_functionalities fiducial_marker_detection hybrid_simulation_platform hybrid_spine_simulator_prototype innovative_strategy low cost_tracking_strategy patient specific_spine_models pedicle_screws_insertion postoperative_patient_outcomes preoperative_planning rehearsal software_functionalities spine_surgery surgical_tools surgical_training surgical_workflows valuable_addition vertebral_model virtual_fluoroscopic_modalities virtual_x ray_visualization x ray_free_pedicle_screws_fixation_training a8770e_patient_diagnostic_methods_and_instrumentation a8760j_x rays_and_particle_beams_ medical_uses a8770g_patient_care_and_treatment a8770j_prosthetics_and_other_practical_applications b6135_optical _image_and_video_signal_processing b7510p_x ray_techniques _radiography_and_computed_tomography_ biomedical_imaging measurement b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision robotics medical telecommunication data simulation surgical training increasingly considered valuable addition traditional teaching method 3d printed physical simulator used preoperative planning rehearsal spine surgery improve surgical workflow postoperative patient outcome paper proposes innovative strategy build hybrid simulation platform training pedicle screw fixation proposed method combine 3d printed patient specific spine model augmented reality functionality virtual x ray visualization thus avoiding exposure harmful radiation simulation software functionality implemented using low cost tracking strategy based fiducial marker detection quantitative test demonstrate accuracy method track vertebral model surgical tool coherently visualize either augmented reality virtual fluoroscopic modality obtained result encourage research clinical validation towards use simulator effective tool training pedicle screw insertion lumbar vertebra,simulation surgical training increasingly considered valuable addition traditional teaching method 3d printed physical simulator used preoperative planning rehearsal spine surgery improve surgical workflow postoperative patient outcome paper proposes innovative strategy build hybrid simulation platform training pedicle screw fixation proposed method combine 3d printed patient specific spine model augmented reality functionality virtual x ray visualization thus avoiding exposure harmful radiation simulation software functionality implemented using low cost tracking strategy based fiducial marker detection quantitative test demonstrate accuracy method track vertebral model surgical tool coherently visualize either augmented reality virtual fluoroscopic modality obtained result encourage research clinical validation towards use simulator effective tool training pedicle screw insertion lumbar vertebrabiomechanics bone computerized_tomography diagnostic_radiography medical_computing medical_image_processing medical_robotics neurophysiology orthopedics prosthetics surgery3d printed_physical_simulators augmented_reality_functionalities fiducial_marker_detection hybrid_simulation_platform hybrid_spine_simulator_prototype innovative_strategy low cost_tracking_strategy patient specific_spine_models pedicle_screws_insertion postoperative_patient_outcomes preoperative_planning rehearsal software_functionalities spine_surgery surgical_tools surgical_training surgical_workflows valuable_addition vertebral_model virtual_fluoroscopic_modalities virtual_x ray_visualization x ray_free_pedicle_screws_fixation_training
295,Large-Area Scatterometry for Nanoscale Metrology,"Gómez Rivas, J., Ramezani, M., Verschuuren, M. A., & Castellanos Gonzalez, G. (2023). Large-area scatterometry for nanoscale metrology. Advanced Fabrication Technologies for Micro/Nano Optics and Photonics XVI. https://doi.org/10.1117/12.2649342
",10.1117/12.2649342,"Many applications across photonics and semiconductor industries require the fabrication of nanostructures with non-trivial geometries with a precision and reproducibility down to the nanometer scale. Slanted gratings and metamaterials are examples of such designs that have vast applications in Augmented Reality and LiDAR. State-of-the-art lithography techniques, such as nanoimprint lithography or UV lithography, can provide such levels of fabrication precision for high-volume production. However, a rapid in-line quality inspection method for such complex patterns is required to monitor the fabrication process, verify the sample quality, and to ensure reproducibility. Here, we demonstrate a novel technique that allows us to inspect the quality of the samples in a non-destructive and fast manner, and to extract geometrical parameters of the nanostructures over large areas, generating spatial variations maps across wafers. &copy; 2023 SPIE.","714.2 Semiconductor Devices and Integrated Circuits;723 Computer Software, Data Handling and Applications;745.2 Reproduction, Copying;761 Nanotechnology;921 Mathematics;933 Solid State Physics",Nano-meter-scale;Nanoscale metrologies;Non-trivial;Photonics industry;Reproducibilities;Scatterometry;Semiconductor industry;Slanted gratings;State of the art;UV lithography,Augmented reality;Geometry;Nanoimprint lithography;Semiconductor device manufacture,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Rivas, Jaime G&oacute;mez; (1) Ramezani, Mohammad; (3) Verschuuren, Marc; (1) Castellanos, Gabriel; ","(1) TeraNova B.V., Groene Loper 19, Eindhoven; 5612AP, Netherlands; (2) Eindhoven University of Technology, PO Box 513, Eindhoven; 5600MB, Netherlands; (3) SCIL Nanoimprint Solutions, HTC 11a, Eindhoven; 5656 AE, Netherlands; ",SPIE,-1,"[""geometry"", ""nanoimprint lithography"", ""semiconductor device manufacture""]","[""geometry"", ""nanoimprint lithography"", ""semiconductor device manufacture""]",geometry;nanoimprint lithography;semiconductor device manufacture,manufacturing;other;graphics;chemical;semiconductors,technology;other;industries,manufacturing;other;graphics;chemical;semiconductors,technology;other;industries,geometry nanoimprint_lithography semiconductor_device_manufacture nano meter scale nanoscale_metrologies non trivial photonics_industry reproducibilities scatterometry semiconductor_industry slanted_gratings state_of_the_art uv_lithography 714 2_semiconductor_devices_and_integrated_circuits 723_computer_software _data_handling_and_applications 745 2_reproduction _copying 761_nanotechnology 921_mathematics 933_solid_state_physics manufacturing other graphics chemical semiconductors,geometry nanoimprint_lithography semiconductor_device_manufacture,nano meter scale nanoscale_metrologies non trivial photonics_industry reproducibilities scatterometry semiconductor_industry slanted_gratings state_of_the_art uv_lithography,many application across photonics semiconductor industry require fabrication nanostructures non trivial geometry precision reproducibility nanometer scale slanted grating metamaterials example design vast application augmented reality lidar state art lithography technique nanoimprint lithography uv lithography provide level fabrication precision high volume production however rapid line quality inspection method complex pattern required monitor fabrication process verify sample quality ensure reproducibility demonstrate novel technique allows u inspect quality sample non destructive fast manner extract geometrical parameter nanostructures large area generating spatial variation map across wafer copy 2023 spie,geometry nanoimprint_lithography semiconductor_device_manufacture nano meter scale nanoscale_metrologies non trivial photonics_industry reproducibilities scatterometry semiconductor_industry slanted_gratings state_of_the_art uv_lithography 714 2_semiconductor_devices_and_integrated_circuits 723_computer_software _data_handling_and_applications 745 2_reproduction _copying 761_nanotechnology 921_mathematics 933_solid_state_physics manufacturing other graphics chemical semiconductors many application across photonics semiconductor industry require fabrication nanostructures non trivial geometry precision reproducibility nanometer scale slanted grating metamaterials example design vast application augmented reality lidar state art lithography technique nanoimprint lithography uv lithography provide level fabrication precision high volume production however rapid line quality inspection method complex pattern required monitor fabrication process verify sample quality ensure reproducibility demonstrate novel technique allows u inspect quality sample non destructive fast manner extract geometrical parameter nanostructures large area generating spatial variation map across wafer copy 2023 spie,many application across photonics semiconductor industry require fabrication nanostructures non trivial geometry precision reproducibility nanometer scale slanted grating metamaterials example design vast application augmented reality lidar state art lithography technique nanoimprint lithography uv lithography provide level fabrication precision high volume production however rapid line quality inspection method complex pattern required monitor fabrication process verify sample quality ensure reproducibility demonstrate novel technique allows u inspect quality sample non destructive fast manner extract geometrical parameter nanostructures large area generating spatial variation map across wafer copy 2023 spiegeometry nanoimprint_lithography semiconductor_device_manufacturenano meter scale nanoscale_metrologies non trivial photonics_industry reproducibilities scatterometry semiconductor_industry slanted_gratings state_of_the_art uv_lithography
296,"Unreality- Tangible learning anytime, anywhere","Thomas, C., Koshy, A., Samal, A., & Hanspal, A. K. (2023). Unreality– Tangible learning anytime, anywhere. Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction. https://doi.org/10.1145/3569009.3576221
",10.1145/3569009.3576221,"This article intends to explain the project ""Unreality"", which is a system developed to make learning remotely and physically more tangibly, socially, and emotionally efficient. Using Augmented Reality (AR) and Extended Reality (XR), interactive holograms will be introduced, and will enable the remotely and physically present students to interact as they normally would. Emotion Tree and Emotion bracelet are designed to encourage more discussions pertaining to their emotional health. Lastly, the Note-Making system takes into account the different learning styles of every student who may not thrive under the traditional learning techniques. The use of Unreality application to input the required data increases ease of access. The report would also explain each element used in the system and its process of how they would be used while learning.","C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",different learning styles;emotional health;interactive holograms;Note-Making system;physically present students;project Unreality;remotely students;traditional learning techniques;Unreality application;Unreality- tangible learning;XR,augmented reality;computer aided instruction;learning (artificial intelligence),2023,Conference article (CA),"TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction","(1) Thomas, C.; (1) Koshy, A.; (1) Samal, A.; (1) Hanspal, A.K.; ","(1) Delhi Private School Sharjah, United Arab Emirates; ",ACM,-1,"[""computer aided instruction"", ""learning algorithms""]","[""computer aided instruction"", ""learning algorithms""]",computer aided instruction;learning algorithms,medical;artificial intelligence;training,technology;use cases;industries,medical;artificial intelligence;training,technology;use cases;industries,computer_aided_instruction learning_algorithms different_learning_styles emotional_health interactive_holograms note making_system physically_present_students project_unreality remotely_students traditional_learning_techniques unreality_application unreality _tangible_learning xr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing medical artificial_intelligence training,computer_aided_instruction learning_algorithms,different_learning_styles emotional_health interactive_holograms note making_system physically_present_students project_unreality remotely_students traditional_learning_techniques unreality_application unreality _tangible_learning xr,article intends explain project unreality system developed make learning remotely physically tangibly socially emotionally efficient using augmented reality ar extended reality xr interactive hologram introduced enable remotely physically present student interact normally would emotion tree emotion bracelet designed encourage discussion pertaining emotional health lastly note making system take account different learning style every student may thrive traditional learning technique use unreality application input required data increase ease access report would also explain element used system process would used learning,computer_aided_instruction learning_algorithms different_learning_styles emotional_health interactive_holograms note making_system physically_present_students project_unreality remotely_students traditional_learning_techniques unreality_application unreality _tangible_learning xr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing medical artificial_intelligence training article intends explain project unreality system developed make learning remotely physically tangibly socially emotionally efficient using augmented reality ar extended reality xr interactive hologram introduced enable remotely physically present student interact normally would emotion tree emotion bracelet designed encourage discussion pertaining emotional health lastly note making system take account different learning style every student may thrive traditional learning technique use unreality application input required data increase ease access report would also explain element used system process would used learning,article intends explain project unreality system developed make learning remotely physically tangibly socially emotionally efficient using augmented reality ar extended reality xr interactive hologram introduced enable remotely physically present student interact normally would emotion tree emotion bracelet designed encourage discussion pertaining emotional health lastly note making system take account different learning style every student may thrive traditional learning technique use unreality application input required data increase ease access report would also explain element used system process would used learningcomputer_aided_instruction learning_algorithmsdifferent_learning_styles emotional_health interactive_holograms note making_system physically_present_students project_unreality remotely_students traditional_learning_techniques unreality_application unreality _tangible_learning xr
297,Bias and Repeatability of Measurements from 3D Scans Made Using iOS-Based Lidar,"Heinrichs, B. E., & Yang, M. (2021). Bias and Repeatability of Measurements from 3D Scans Made Using iOS-Based Lidar. SAE International Journal of Advances and Current Practices in Mobility, 3(5), 2219–2226. https://doi.org/10.4271/2021-01-0891
",10.4271/2021-01-0891,"Apple introduced a lidar-based depth sensor and enhanced Augmented Reality (AR) application programming interface (API) to the 2020 iPad Pro and iPhone 12 Pro, making widespread use of 3D scanning possible. Here we quantified the bias and repeatability of the 3D scans made using this system. The exterior and interior of a single vehicle and the exterior of a filing cabinet were scanned four times by eight different operators. Each operator then extracted four measurements from each of the exterior scans, five measurements from each of the interior scans, and three measurements from each of the filing cabinet scans. Hand measurements using a string and tape measure were used as reference values to estimate the bias. The values extracted from the 3D scans were biased between 0.9 and 9.3 cm below the actual exterior measurements and between 2.2 cm below and 0.3 cm above the actual interior measurements. The repeatability standard deviation varied from 1.8 to 5.8 cm for the exterior measurements and from 0.6 to 1.4 cm for the interior measurements. Based on the measurements we used here, the interior 3D scans were more accurate than the exterior scans, with the interior scans having a similar bias, though larger variance, to hand measurements.","B6320C Optical radar;B7230 Sensing devices and transducers;C3240F Nonelectric transducers and sensing devices;C5540B Interactive-input devices;C6150E General utility programs;C6150J Operating systems;C6190V Mobile, ubiquitous and pervasive computing",2020 iPad Pro;API;Apple;enhanced augmented reality application programming interface;exterior 3D scanning;exterior measurements;filing cabinet scans;interior 3D scanning;interior measurements;iOS-based lidar;iPhone 12 Pro;lidar-based depth sensor;repeatability standard deviation;size 0.3 cm;size 0.6 cm to 1.4 cm;size 0.9 cm to 9.3 cm;size 1.8 cm to 5.8 cm;tape measure,application program interfaces;augmented reality;iOS (operating system);optical radar;optical scanners;optical sensors;radar receivers,2021,Journal article (JA),SAE Int. J. Adv. Curr. Pract. Mobil. (USA),"(1) Heinrichs, B.E.; (1) Yang, M.; ","(1) STEM Forward, Milwaukee, WI, United States; ",SAE International,-1,"[""application program interfaces"", ""ios"", ""optical radar"", ""optical scanners"", ""optical sensors"", ""radar receivers""]","[""application program interfaces"", ""ios"", ""optical radar"", ""optical scanners"", ""optical sensors"", ""radar receivers""]",application program interfaces;ios;optical radar;optical scanners;optical sensors;radar receivers,other;optics;sensors;telecommunication;developers;geospatial,technology;other;displays;industries,other;optics;sensors;telecommunication;developers;geospatial,technology;other;displays;industries,application_program_interfaces ios optical_radar optical_scanners optical_sensors radar_receivers 2020_ipad_pro api apple enhanced_augmented_reality_application_programming_interface exterior_3d_scanning exterior_measurements filing_cabinet_scans interior_3d_scanning interior_measurements ios based_lidar iphone_12_pro lidar based_depth_sensor repeatability_standard_deviation size_0 3_cm size_0 6_cm_to_1 4_cm size_0 9_cm_to_9 3_cm size_1 8_cm_to_5 8_cm tape_measure b6320c_optical_radar b7230_sensing_devices_and_transducers c3240f_nonelectric_transducers_and_sensing_devices c5540b_interactive input_devices c6150e_general_utility_programs c6150j_operating_systems c6190v_mobile _ubiquitous_and_pervasive_computing other optics sensors telecommunication developers geospatial,application_program_interfaces ios optical_radar optical_scanners optical_sensors radar_receivers,2020_ipad_pro api apple enhanced_augmented_reality_application_programming_interface exterior_3d_scanning exterior_measurements filing_cabinet_scans interior_3d_scanning interior_measurements ios based_lidar iphone_12_pro lidar based_depth_sensor repeatability_standard_deviation size_0 3_cm size_0 6_cm_to_1 4_cm size_0 9_cm_to_9 3_cm size_1 8_cm_to_5 8_cm tape_measure,apple introduced lidar based depth sensor enhanced augmented reality ar application programming interface api 2020 ipad pro iphone 12 pro making widespread use 3d scanning possible quantified bias repeatability 3d scan made using system exterior interior single vehicle exterior filing cabinet scanned four time eight different operator operator extracted four measurement exterior scan five measurement interior scan three measurement filing cabinet scan hand measurement using string tape measure used reference value estimate bias value extracted 3d scan biased 0 9 9 3 cm actual exterior measurement 2 2 cm 0 3 cm actual interior measurement repeatability standard deviation varied 1 8 5 8 cm exterior measurement 0 6 1 4 cm interior measurement based measurement used interior 3d scan accurate exterior scan interior scan similar bias though larger variance hand measurement,application_program_interfaces ios optical_radar optical_scanners optical_sensors radar_receivers 2020_ipad_pro api apple enhanced_augmented_reality_application_programming_interface exterior_3d_scanning exterior_measurements filing_cabinet_scans interior_3d_scanning interior_measurements ios based_lidar iphone_12_pro lidar based_depth_sensor repeatability_standard_deviation size_0 3_cm size_0 6_cm_to_1 4_cm size_0 9_cm_to_9 3_cm size_1 8_cm_to_5 8_cm tape_measure b6320c_optical_radar b7230_sensing_devices_and_transducers c3240f_nonelectric_transducers_and_sensing_devices c5540b_interactive input_devices c6150e_general_utility_programs c6150j_operating_systems c6190v_mobile _ubiquitous_and_pervasive_computing other optics sensors telecommunication developers geospatial apple introduced lidar based depth sensor enhanced augmented reality ar application programming interface api 2020 ipad pro iphone 12 pro making widespread use 3d scanning possible quantified bias repeatability 3d scan made using system exterior interior single vehicle exterior filing cabinet scanned four time eight different operator operator extracted four measurement exterior scan five measurement interior scan three measurement filing cabinet scan hand measurement using string tape measure used reference value estimate bias value extracted 3d scan biased 0 9 9 3 cm actual exterior measurement 2 2 cm 0 3 cm actual interior measurement repeatability standard deviation varied 1 8 5 8 cm exterior measurement 0 6 1 4 cm interior measurement based measurement used interior 3d scan accurate exterior scan interior scan similar bias though larger variance hand measurement,apple introduced lidar based depth sensor enhanced augmented reality ar application programming interface api 2020 ipad pro iphone 12 pro making widespread use 3d scanning possible quantified bias repeatability 3d scan made using system exterior interior single vehicle exterior filing cabinet scanned four time eight different operator operator extracted four measurement exterior scan five measurement interior scan three measurement filing cabinet scan hand measurement using string tape measure used reference value estimate bias value extracted 3d scan biased 0 9 9 3 cm actual exterior measurement 2 2 cm 0 3 cm actual interior measurement repeatability standard deviation varied 1 8 5 8 cm exterior measurement 0 6 1 4 cm interior measurement based measurement used interior 3d scan accurate exterior scan interior scan similar bias though larger variance hand measurementapplication_program_interfaces ios optical_radar optical_scanners optical_sensors radar_receivers2020_ipad_pro api apple enhanced_augmented_reality_application_programming_interface exterior_3d_scanning exterior_measurements filing_cabinet_scans interior_3d_scanning interior_measurements ios based_lidar iphone_12_pro lidar based_depth_sensor repeatability_standard_deviation size_0 3_cm size_0 6_cm_to_1 4_cm size_0 9_cm_to_9 3_cm size_1 8_cm_to_5 8_cm tape_measure
298,Serverless Functions in the Cloud-Edge Continuum: Challenges and Opportunities,"Russo, G. R., Cardellini, V., & Presti, F. L. (2023). Serverless Functions in the Cloud-Edge Continuum: Challenges and Opportunities. 2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP). https://doi.org/10.1109/pdp59025.2023.00056
",10.1109/PDP59025.2023.00056,"The Function-as-a-Service (FaaS) paradigm is increasingly adopted for the development of Cloud-native applications, which especially benefit from the seamless scalability and attractive pricing models of serverless deployments. With the continuous emergence of latency-sensitive applications and services, including Internet-of-Things and augmented reality, it is now natural to wonder whether and how the FaaS paradigm can be efficiently exploited in the Cloud-Edge Continuum, where serverless functions may benefit from reduced network delay between their invoking users and the FaaS platform. In this paper, we illustrate the key challenges that must be faced to effectively deploy serverless functions in the Cloud-Edge Continuum and review recent contributions proposed by the research community towards overcoming those challenges. We also discuss the key issues that currently remain unsolved and highlight a few research opportunities for better support of FaaS in the Compute Continuum.",B6210L Computer communications;C5620D Internet of Things;C6130V Virtual reality;C6190J Internet software,attractive pricing models;Cloud-Edge Continuum;Cloud-native applications;FaaS paradigm;FaaS platform;Function-as-a-Service paradigm;latency-sensitive applications;serverless deployments;serverless functions,augmented reality;cloud computing;Internet;Internet of Things,2023,Conference article (CA),"2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","(1) Russo, G.R.; (1) Cardellini, V.; (1) Presti, F.L.; ","(1) University of Rome Tor Vergata, Italy; ",IEEE,-1,"[""cloud computing"", ""internet"", ""internet of things""]","[""cloud computing"", ""internet"", ""internet of things""]",cloud computing;internet;internet of things,internet of things;networks,technology,internet of things;networks,technology,cloud_computing internet internet_of_things attractive_pricing_models cloud edge_continuum cloud native_applications faas_paradigm faas_platform function as a service_paradigm latency sensitive_applications serverless_deployments serverless_functions b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c6190j_internet_software internet_of_things networks,cloud_computing internet internet_of_things,attractive_pricing_models cloud edge_continuum cloud native_applications faas_paradigm faas_platform function as a service_paradigm latency sensitive_applications serverless_deployments serverless_functions,function service faa paradigm increasingly adopted development cloud native application especially benefit seamless scalability attractive pricing model serverless deployment continuous emergence latency sensitive application service including internet thing augmented reality natural wonder whether faa paradigm efficiently exploited cloud edge continuum serverless function may benefit reduced network delay invoking user faa platform paper illustrate key challenge must faced effectively deploy serverless function cloud edge continuum review recent contribution proposed research community towards overcoming challenge also discus key issue currently remain unsolved highlight research opportunity better support faa compute continuum,cloud_computing internet internet_of_things attractive_pricing_models cloud edge_continuum cloud native_applications faas_paradigm faas_platform function as a service_paradigm latency sensitive_applications serverless_deployments serverless_functions b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c6190j_internet_software internet_of_things networks function service faa paradigm increasingly adopted development cloud native application especially benefit seamless scalability attractive pricing model serverless deployment continuous emergence latency sensitive application service including internet thing augmented reality natural wonder whether faa paradigm efficiently exploited cloud edge continuum serverless function may benefit reduced network delay invoking user faa platform paper illustrate key challenge must faced effectively deploy serverless function cloud edge continuum review recent contribution proposed research community towards overcoming challenge also discus key issue currently remain unsolved highlight research opportunity better support faa compute continuum,function service faa paradigm increasingly adopted development cloud native application especially benefit seamless scalability attractive pricing model serverless deployment continuous emergence latency sensitive application service including internet thing augmented reality natural wonder whether faa paradigm efficiently exploited cloud edge continuum serverless function may benefit reduced network delay invoking user faa platform paper illustrate key challenge must faced effectively deploy serverless function cloud edge continuum review recent contribution proposed research community towards overcoming challenge also discus key issue currently remain unsolved highlight research opportunity better support faa compute continuumcloud_computing internet internet_of_thingsattractive_pricing_models cloud edge_continuum cloud native_applications faas_paradigm faas_platform function as a service_paradigm latency sensitive_applications serverless_deployments serverless_functions
299,Individualization Of Head Related Transfer Function Based On PCA And RBF Network,"Chen, W., Zhang, H., Yu, J., & Luo, F. (2022). Individualization Of Head Related Transfer Function Based On PCA And RBF Network. Proceedings of the 2022 11th International Conference on Networks, Communication and Computing. https://doi.org/10.1145/3579895.3579912
",10.1145/3579895.3579912,"Head-Related Transfer Function (HRTF) describes the acoustic reflection and diffraction effect caused by the influence of the human body (head, torso, etc.) in the transmission of sound waves to the human ear. In Virtual Reality(VR) / Augmented Reality(AR), HRTF is often used to generate virtual 3D audio due to its ability to recreate perceptions of natural sound scenes realistically. However, HRTF varies from person to person due to the differences in anthropometric features. Using non-individualized HRTF to produce 3D sounds may lead to hearing localization bias in users. Therefore, how to obtain individualized HRTF is a hot topic in the field of VR / AR. This paper proposes an effective method to establish the relationship between anthropometric features and HRTF. At first, a method based on multimodal principal component analysis is proposed for the representation of HRTF models with low dimensions. Then a nonlinear mapping representation model between the low-dimensional features of HRTF and anthropometric features is established using Radial Basis Function Neural Network (RBFNN). Objective experiments show that the proposed HRTF Individualization method can reduce the spectral distortion as low as 4.48 dB. The subjective listening experiments based on the principal sagittal plane show that the individualized HRTF obtained using this method can effectively improve the accuracy of subjective listening (about 33%).","A4360 Acoustic signal processing;A0250 Probability theory, stochastic processes, and statistics;B0240P Principal component analysis;B6130 Speech and audio signal processing;C1140P Principal component analysis;C5260 Digital signal processing;C6130B Graphics techniques;C6130V Virtual reality;C6264 Neural nets",3D sounds;acoustic reflection;anthropometric features;augmented reality;diffraction effect;Head-Related Transfer Function;hearing localization bias;HRTF individualization method;HRTF models;human body;human ear;low-dimensional features;multimodal principal component analysis;natural sound scenes;nonindividualized HRTF;nonlinear mapping representation model;objective experiments;PCA;principal sagittal plane;Radial Basis Function Neural Network;RBFNN;sound wave transmission;spectral distortion;subjective listening experiments;virtual 3D audio generation;virtual reality,acoustic signal processing;anthropometry;audio signal processing;augmented reality;hearing;principal component analysis;radial basis function networks;signal representation;transfer functions,2022,Conference article (CA),"ICNCC '22: Proceedings of the 2022 11th International Conference on Networks, Communication and Computing","(1) Chen, W.; (2) Zhang, H.; (2) Yu, J.; (1) Luo, F.; ","(1) Henan Polytechnic University, School of Software, China; (2) Henan Polytechnic University, School of Computer Science and Technology, China; ",ACM,-1,"[""acoustic signal processing"", ""anthropometry"", ""audio signal processing"", ""hearing"", ""principal component analysis"", ""radial basis function networks"", ""signal representation"", ""transfer functions""]","[""acoustic signal processing"", ""anthropometry"", ""audio signal processing"", ""hearing"", ""principal component analysis"", ""radial basis function networks"", ""signal representation"", ""transfer functions""]",acoustic signal processing;anthropometry;audio signal processing;hearing;principal component analysis;radial basis function networks;signal representation;transfer functions,other;medical;sensors;human factors;engineering;developers;data;audio;artificial intelligence,technology;other;industries;end users and user experience,other;medical;sensors;human factors;engineering;developers;data;audio;artificial intelligence,technology;other;industries;end users and user experience,acoustic_signal_processing anthropometry audio_signal_processing hearing principal_component_analysis radial_basis_function_networks signal_representation transfer_functions 3d_sounds acoustic_reflection anthropometric_features augmented_reality diffraction_effect head related_transfer_function hearing_localization_bias hrtf_individualization_method hrtf_models human_body human_ear low dimensional_features multimodal_principal_component_analysis natural_sound_scenes nonindividualized_hrtf nonlinear_mapping_representation_model objective_experiments pca principal_sagittal_plane radial_basis_function_neural_network rbfnn sound_wave_transmission spectral_distortion subjective_listening_experiments virtual_3d_audio_generation virtual_reality a4360_acoustic_signal_processing a0250_probability_theory _stochastic_processes _and_statistics b0240p_principal_component_analysis b6130_speech_and_audio_signal_processing c1140p_principal_component_analysis c5260_digital_signal_processing c6130b_graphics_techniques c6130v_virtual_reality c6264_neural_nets other medical sensors human_factors engineering developers data audio artificial_intelligence,acoustic_signal_processing anthropometry audio_signal_processing hearing principal_component_analysis radial_basis_function_networks signal_representation transfer_functions,3d_sounds acoustic_reflection anthropometric_features augmented_reality diffraction_effect head related_transfer_function hearing_localization_bias hrtf_individualization_method hrtf_models human_body human_ear low dimensional_features multimodal_principal_component_analysis natural_sound_scenes nonindividualized_hrtf nonlinear_mapping_representation_model objective_experiments pca principal_sagittal_plane radial_basis_function_neural_network rbfnn sound_wave_transmission spectral_distortion subjective_listening_experiments virtual_3d_audio_generation virtual_reality,head related transfer function hrtf describes acoustic reflection diffraction effect caused influence human body head torso etc transmission sound wave human ear virtual reality vr augmented reality ar hrtf often used generate virtual 3d audio due ability recreate perception natural sound scene realistically however hrtf varies person person due difference anthropometric feature using non individualized hrtf produce 3d sound may lead hearing localization bias user therefore obtain individualized hrtf hot topic field vr ar paper proposes effective method establish relationship anthropometric feature hrtf first method based multimodal principal component analysis proposed representation hrtf model low dimension nonlinear mapping representation model low dimensional feature hrtf anthropometric feature established using radial basis function neural network rbfnn objective experiment show proposed hrtf individualization method reduce spectral distortion low 4 48 db subjective listening experiment based principal sagittal plane show individualized hrtf obtained using method effectively improve accuracy subjective listening 33,acoustic_signal_processing anthropometry audio_signal_processing hearing principal_component_analysis radial_basis_function_networks signal_representation transfer_functions 3d_sounds acoustic_reflection anthropometric_features augmented_reality diffraction_effect head related_transfer_function hearing_localization_bias hrtf_individualization_method hrtf_models human_body human_ear low dimensional_features multimodal_principal_component_analysis natural_sound_scenes nonindividualized_hrtf nonlinear_mapping_representation_model objective_experiments pca principal_sagittal_plane radial_basis_function_neural_network rbfnn sound_wave_transmission spectral_distortion subjective_listening_experiments virtual_3d_audio_generation virtual_reality a4360_acoustic_signal_processing a0250_probability_theory _stochastic_processes _and_statistics b0240p_principal_component_analysis b6130_speech_and_audio_signal_processing c1140p_principal_component_analysis c5260_digital_signal_processing c6130b_graphics_techniques c6130v_virtual_reality c6264_neural_nets other medical sensors human_factors engineering developers data audio artificial_intelligence head related transfer function hrtf describes acoustic reflection diffraction effect caused influence human body head torso etc transmission sound wave human ear virtual reality vr augmented reality ar hrtf often used generate virtual 3d audio due ability recreate perception natural sound scene realistically however hrtf varies person person due difference anthropometric feature using non individualized hrtf produce 3d sound may lead hearing localization bias user therefore obtain individualized hrtf hot topic field vr ar paper proposes effective method establish relationship anthropometric feature hrtf first method based multimodal principal component analysis proposed representation hrtf model low dimension nonlinear mapping representation model low dimensional feature hrtf anthropometric feature established using radial basis function neural network rbfnn objective experiment show proposed hrtf individualization method reduce spectral distortion low 4 48 db subjective listening experiment based principal sagittal plane show individualized hrtf obtained using method effectively improve accuracy subjective listening 33,head related transfer function hrtf describes acoustic reflection diffraction effect caused influence human body head torso etc transmission sound wave human ear virtual reality vr augmented reality ar hrtf often used generate virtual 3d audio due ability recreate perception natural sound scene realistically however hrtf varies person person due difference anthropometric feature using non individualized hrtf produce 3d sound may lead hearing localization bias user therefore obtain individualized hrtf hot topic field vr ar paper proposes effective method establish relationship anthropometric feature hrtf first method based multimodal principal component analysis proposed representation hrtf model low dimension nonlinear mapping representation model low dimensional feature hrtf anthropometric feature established using radial basis function neural network rbfnn objective experiment show proposed hrtf individualization method reduce spectral distortion low 4 48 db subjective listening experiment based principal sagittal plane show individualized hrtf obtained using method effectively improve accuracy subjective listening 33acoustic_signal_processing anthropometry audio_signal_processing hearing principal_component_analysis radial_basis_function_networks signal_representation transfer_functions3d_sounds acoustic_reflection anthropometric_features augmented_reality diffraction_effect head related_transfer_function hearing_localization_bias hrtf_individualization_method hrtf_models human_body human_ear low dimensional_features multimodal_principal_component_analysis natural_sound_scenes nonindividualized_hrtf nonlinear_mapping_representation_model objective_experiments pca principal_sagittal_plane radial_basis_function_neural_network rbfnn sound_wave_transmission spectral_distortion subjective_listening_experiments virtual_3d_audio_generation virtual_reality
300,Quality Assessment of 3D Synthesized Images Based on Textural and Structural Distortion Estimation,"Alvi, H. M. U. H., Farid, M. S., Khan, M. H., & Grzegorzek, M. (2021). Quality Assessment of 3D Synthesized Images Based on Textural and Structural Distortion Estimation. Applied Sciences, 11(6), 2666. https://doi.org/10.3390/app11062666
",10.3390/app11062666,"Emerging 3D-related technologies such as augmented reality, virtual reality, mixed reality, and stereoscopy have gained remarkable growth due to their numerous applications in the entertainment, gaming, and electromedical industries. In particular, the 3D television (3DTV) and free-viewpoint television (FTV) enhance viewers' television experience by providing immersion. They need an infinite number of views to provide a full parallax to the viewer, which is not practical due to various financial and technological constraints. Therefore, novel 3D views are generated from a set of available views and their depth maps using depth-image-based rendering (DIBR) techniques. The quality of a DIBR-synthesized image may be compromised for several reasons, e.g., inaccurate depth estimation. Since depth is important in this application, inaccuracies in depth maps lead to different textural and structural distortions that degrade the quality of the generated image and result in a poor quality of experience (QoE). Therefore, quality assessment DIBR-generated images are essential to guarantee an appreciative QoE. This paper aims at estimating the quality of DIBR-synthesized images and proposes a novel 3D objective image quality metric. The proposed algorithm aims to measure both textural and structural distortions in the DIBR image by exploiting the contrast sensitivity and the Hausdorff distance, respectively. The two measures are combined to estimate an overall quality score. The experimental evaluations performed on the benchmark MCL-3D dataset show that the proposed metric is reliable and accurate, and performs better than existing 2D and 3D quality assessment metrics.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130B Graphics techniques;C6130V Virtual reality",3D-related technologies;3DTV;augmented reality;available views;benchmark MCL-3D dataset show;depth maps;depth-image-based;DIBR image;DIBR-synthesized image;different textural;financial constraints;free-viewpoint television;inaccurate depth estimation;mixed reality;novel 3D objective image quality metric;providing immersion;quality assessment DIBR-generated images;quality score;remarkable growth;structural distortion estimation;structural distortions;technological constraints;viewers;virtual reality,augmented reality;rendering (computer graphics);stereo image processing;three-dimensional television;video signal processing;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Alvi, H.M.U.H.; (1) Farid, M.S.; (1) Khan, M.H.; (2) Grzegorzek, M.; ","(1) University of the Punjab, Punjab University College of Information Technology, Pakistan; (2) University of Lu&#776;beck, Institute of Medical Informatics, Ratzeburger Allee 160, Germany; ",MDPI,-1,"[""rendering"", ""stereo image processing"", ""three-dimensional television"", ""video signal processing""]","[""rendering"", ""stereo image processing"", ""three-dimensional television"", ""video signal processing""]",rendering;stereo image processing;three-dimensional television;video signal processing,computer vision;other;graphics;sensors;data;users;semiconductors,technology;other;end users and user experience,computer vision;other;graphics;sensors;data;users;semiconductors,technology;other;end users and user experience,rendering stereo_image_processing three dimensional_television video_signal_processing 3d related_technologies 3dtv augmented_reality available_views benchmark_mcl 3d_dataset_show depth_maps depth image based dibr_image dibr synthesized_image different_textural financial_constraints free viewpoint_television inaccurate_depth_estimation mixed_reality novel_3d_objective_image_quality_metric providing_immersion quality_assessment_dibr generated_images quality_score remarkable_growth structural_distortion_estimation structural_distortions technological_constraints viewers virtual_reality b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality computer_vision other graphics sensors data users semiconductors,rendering stereo_image_processing three dimensional_television video_signal_processing,3d related_technologies 3dtv augmented_reality available_views benchmark_mcl 3d_dataset_show depth_maps depth image based dibr_image dibr synthesized_image different_textural financial_constraints free viewpoint_television inaccurate_depth_estimation mixed_reality novel_3d_objective_image_quality_metric providing_immersion quality_assessment_dibr generated_images quality_score remarkable_growth structural_distortion_estimation structural_distortions technological_constraints viewers virtual_reality,emerging 3d related technology augmented reality virtual reality mixed reality stereoscopy gained remarkable growth due numerous application entertainment gaming electromedical industry particular 3d television 3dtv free viewpoint television ftv enhance viewer television experience providing immersion need infinite number view provide full parallax viewer practical due various financial technological constraint therefore novel 3d view generated set available view depth map using depth image based rendering dibr technique quality dibr synthesized image may compromised several reason e g inaccurate depth estimation since depth important application inaccuracy depth map lead different textural structural distortion degrade quality generated image result poor quality experience qoe therefore quality assessment dibr generated image essential guarantee appreciative qoe paper aim estimating quality dibr synthesized image proposes novel 3d objective image quality metric proposed algorithm aim measure textural structural distortion dibr image exploiting contrast sensitivity hausdorff distance respectively two measure combined estimate overall quality score experimental evaluation performed benchmark mcl 3d dataset show proposed metric reliable accurate performs better existing 2d 3d quality assessment metric,rendering stereo_image_processing three dimensional_television video_signal_processing 3d related_technologies 3dtv augmented_reality available_views benchmark_mcl 3d_dataset_show depth_maps depth image based dibr_image dibr synthesized_image different_textural financial_constraints free viewpoint_television inaccurate_depth_estimation mixed_reality novel_3d_objective_image_quality_metric providing_immersion quality_assessment_dibr generated_images quality_score remarkable_growth structural_distortion_estimation structural_distortions technological_constraints viewers virtual_reality b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130b_graphics_techniques c6130v_virtual_reality computer_vision other graphics sensors data users semiconductors emerging 3d related technology augmented reality virtual reality mixed reality stereoscopy gained remarkable growth due numerous application entertainment gaming electromedical industry particular 3d television 3dtv free viewpoint television ftv enhance viewer television experience providing immersion need infinite number view provide full parallax viewer practical due various financial technological constraint therefore novel 3d view generated set available view depth map using depth image based rendering dibr technique quality dibr synthesized image may compromised several reason e g inaccurate depth estimation since depth important application inaccuracy depth map lead different textural structural distortion degrade quality generated image result poor quality experience qoe therefore quality assessment dibr generated image essential guarantee appreciative qoe paper aim estimating quality dibr synthesized image proposes novel 3d objective image quality metric proposed algorithm aim measure textural structural distortion dibr image exploiting contrast sensitivity hausdorff distance respectively two measure combined estimate overall quality score experimental evaluation performed benchmark mcl 3d dataset show proposed metric reliable accurate performs better existing 2d 3d quality assessment metric,emerging 3d related technology augmented reality virtual reality mixed reality stereoscopy gained remarkable growth due numerous application entertainment gaming electromedical industry particular 3d television 3dtv free viewpoint television ftv enhance viewer television experience providing immersion need infinite number view provide full parallax viewer practical due various financial technological constraint therefore novel 3d view generated set available view depth map using depth image based rendering dibr technique quality dibr synthesized image may compromised several reason e g inaccurate depth estimation since depth important application inaccuracy depth map lead different textural structural distortion degrade quality generated image result poor quality experience qoe therefore quality assessment dibr generated image essential guarantee appreciative qoe paper aim estimating quality dibr synthesized image proposes novel 3d objective image quality metric proposed algorithm aim measure textural structural distortion dibr image exploiting contrast sensitivity hausdorff distance respectively two measure combined estimate overall quality score experimental evaluation performed benchmark mcl 3d dataset show proposed metric reliable accurate performs better existing 2d 3d quality assessment metricrendering stereo_image_processing three dimensional_television video_signal_processing3d related_technologies 3dtv augmented_reality available_views benchmark_mcl 3d_dataset_show depth_maps depth image based dibr_image dibr synthesized_image different_textural financial_constraints free viewpoint_television inaccurate_depth_estimation mixed_reality novel_3d_objective_image_quality_metric providing_immersion quality_assessment_dibr generated_images quality_score remarkable_growth structural_distortion_estimation structural_distortions technological_constraints viewers virtual_reality
301,Multi-Shape Free-Form Deformation Framework for Efficient Data Transmission in AR-Based Medical Training Simulators,"Kim, M., & Bello, F. (2021). Multi-Shape Free-Form Deformation Framework for Efficient Data Transmission in AR-Based Medical Training Simulators. Applied Sciences, 11(21), 9925. https://doi.org/10.3390/app11219925
",10.3390/app11219925,"Augmented reality medical training simulators can provide a realistic and immersive experience by overlapping the virtual scene on to the real world. Latency in augmented reality (AR) medical training simulators is an important issue as it can lead to motion sickness for users. This paper proposes a framework that can achieve real-time rendering of the 3D scene aligned to the real world using a head-mounted display (HMD). Model deformation in the 3D scene is categorised into local deformation derived from user interaction and global deformation determined by the simulation scenario. Target shapes are predefined by a simulation scenario, and control points are placed to embed the predefined shapes. Free-form deformation (FFD) is applied to multiple shapes to efficiently transfer the simulated model to the HMD. Global deformation is computed by blending a mapping matrix of each FFD with an assigned weighting value. The local and global deformation are then transferred through the control points updated from a deformed surface mesh and its corresponding weighting value. The proposed framework is verified in terms of latency caused by data transmission and the accuracy of a transmitted surface mesh in a vaginal examination (VE) training simulation. The average latency is reduced to 7 ms, less than the latency causing motion sickness in virtual reality simulations. The maximum relative error is less than 3%. Our framework allows seamless rendering of a virtual scene to the real world with substantially reduced latency and without the need for an external tracking system.",C7330 Biology and medical computing;C5540B Interactive-input devices;C5540D Computer displays;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7810C Computer-aided instruction,AR-based medical training;assigned weighting value;augmented reality medical training simulators;average latency;control points;deformed surface mesh;FFD;global deformation;head-mounted display;HMD;immersive experience;local deformation;model deformation;motion sickness;multishape free-form deformation framework;predefined shapes;real-time rendering;realistic experience;simulated model;simulation scenario;target shapes;user interaction;vaginal examination training simulation;virtual reality simulations;virtual scene;weighting value,augmented reality;computer based training;helmet mounted displays;image registration;medical computing;rendering (computer graphics);solid modelling;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Kim, M.; (1) Bello, F.; ","(1) Imperial College London, Department of Surgery and Cancer, United Kingdom; ",MDPI,-1,"[""computer based training"", ""helmet mounted displays"", ""image registration"", ""medical computing"", ""rendering"", ""solid modelling""]","[""computer based training"", ""helmet mounted displays"", ""image registration"", ""medical computing"", ""rendering"", ""solid modelling""]",computer based training;helmet mounted displays;image registration;medical computing;rendering;solid modelling,computer vision;farming and natural science;graphics;medical;training;display technology;wearables;manufacturing,technology;displays;use cases;industries,computer vision;farming and natural science;graphics;medical;training;display technology;wearables;manufacturing,technology;displays;use cases;industries,computer_based_training helmet_mounted_displays image_registration medical_computing rendering solid_modelling ar based_medical_training assigned_weighting_value augmented_reality_medical_training_simulators average_latency control_points deformed_surface_mesh ffd global_deformation head mounted_display hmd immersive_experience local_deformation model_deformation motion_sickness multishape_free form_deformation_framework predefined_shapes real time_rendering realistic_experience simulated_model simulation_scenario target_shapes user_interaction vaginal_examination_training_simulation virtual_reality_simulations virtual_scene weighting_value c7330_biology_and_medical_computing c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction computer_vision farming_and_natural_science graphics medical training display_technology wearables manufacturing,computer_based_training helmet_mounted_displays image_registration medical_computing rendering solid_modelling,ar based_medical_training assigned_weighting_value augmented_reality_medical_training_simulators average_latency control_points deformed_surface_mesh ffd global_deformation head mounted_display hmd immersive_experience local_deformation model_deformation motion_sickness multishape_free form_deformation_framework predefined_shapes real time_rendering realistic_experience simulated_model simulation_scenario target_shapes user_interaction vaginal_examination_training_simulation virtual_reality_simulations virtual_scene weighting_value,augmented reality medical training simulator provide realistic immersive experience overlapping virtual scene real world latency augmented reality ar medical training simulator important issue lead motion sickness user paper proposes framework achieve real time rendering 3d scene aligned real world using head mounted display hmd model deformation 3d scene categorised local deformation derived user interaction global deformation determined simulation scenario target shape predefined simulation scenario control point placed embed predefined shape free form deformation ffd applied multiple shape efficiently transfer simulated model hmd global deformation computed blending mapping matrix ffd assigned weighting value local global deformation transferred control point updated deformed surface mesh corresponding weighting value proposed framework verified term latency caused data transmission accuracy transmitted surface mesh vaginal examination training simulation average latency reduced 7 m le latency causing motion sickness virtual reality simulation maximum relative error le 3 framework allows seamless rendering virtual scene real world substantially reduced latency without need external tracking system,computer_based_training helmet_mounted_displays image_registration medical_computing rendering solid_modelling ar based_medical_training assigned_weighting_value augmented_reality_medical_training_simulators average_latency control_points deformed_surface_mesh ffd global_deformation head mounted_display hmd immersive_experience local_deformation model_deformation motion_sickness multishape_free form_deformation_framework predefined_shapes real time_rendering realistic_experience simulated_model simulation_scenario target_shapes user_interaction vaginal_examination_training_simulation virtual_reality_simulations virtual_scene weighting_value c7330_biology_and_medical_computing c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction computer_vision farming_and_natural_science graphics medical training display_technology wearables manufacturing augmented reality medical training simulator provide realistic immersive experience overlapping virtual scene real world latency augmented reality ar medical training simulator important issue lead motion sickness user paper proposes framework achieve real time rendering 3d scene aligned real world using head mounted display hmd model deformation 3d scene categorised local deformation derived user interaction global deformation determined simulation scenario target shape predefined simulation scenario control point placed embed predefined shape free form deformation ffd applied multiple shape efficiently transfer simulated model hmd global deformation computed blending mapping matrix ffd assigned weighting value local global deformation transferred control point updated deformed surface mesh corresponding weighting value proposed framework verified term latency caused data transmission accuracy transmitted surface mesh vaginal examination training simulation average latency reduced 7 m le latency causing motion sickness virtual reality simulation maximum relative error le 3 framework allows seamless rendering virtual scene real world substantially reduced latency without need external tracking system,augmented reality medical training simulator provide realistic immersive experience overlapping virtual scene real world latency augmented reality ar medical training simulator important issue lead motion sickness user paper proposes framework achieve real time rendering 3d scene aligned real world using head mounted display hmd model deformation 3d scene categorised local deformation derived user interaction global deformation determined simulation scenario target shape predefined simulation scenario control point placed embed predefined shape free form deformation ffd applied multiple shape efficiently transfer simulated model hmd global deformation computed blending mapping matrix ffd assigned weighting value local global deformation transferred control point updated deformed surface mesh corresponding weighting value proposed framework verified term latency caused data transmission accuracy transmitted surface mesh vaginal examination training simulation average latency reduced 7 m le latency causing motion sickness virtual reality simulation maximum relative error le 3 framework allows seamless rendering virtual scene real world substantially reduced latency without need external tracking systemcomputer_based_training helmet_mounted_displays image_registration medical_computing rendering solid_modellingar based_medical_training assigned_weighting_value augmented_reality_medical_training_simulators average_latency control_points deformed_surface_mesh ffd global_deformation head mounted_display hmd immersive_experience local_deformation model_deformation motion_sickness multishape_free form_deformation_framework predefined_shapes real time_rendering realistic_experience simulated_model simulation_scenario target_shapes user_interaction vaginal_examination_training_simulation virtual_reality_simulations virtual_scene weighting_value
302,Effects of minimum content in cultural informatics,"Antoniou, A., Theodoropoulos, A., Rompa, J., Giannakopoulou, F., Lepouras, G., & Triantafyllou, I. (2022). Effects of minimum content in cultural informatics. Proceedings of the 26th Pan-Hellenic Conference on Informatics. https://doi.org/10.1145/3575879.3575996
",10.1145/3575879.3575996,"Over the last years our research group has been working with a novel concept for HCI in Cultural Informatics, that of minimum content. Responding to the cognitive overload and the museum fatigue that is well documented in the literature, the concept of minimum meaningful content was introduced and studied, with regards to the user experience, concerning possible learning benefits and overall satisfaction. The present work presents findings from different past efforts that explored the effects of minimum content on cultural heritage visitors. Minimum content was tested with visitors of different sites and lab experiment participants, focusing on augmented reality, games, and photography. The results reveal the potential of minimum content in cultural visits. The implications for HCI and future works are also discussed.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces;C7820 Humanities computing;C7830D Computer games,cultural informatics;minimum content;minimum meaningful content,augmented reality;history;human computer interaction;museums,2022,Conference article (CA),PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics,"(1) Antoniou, A.; (2) Theodoropoulos, A.; (2) Rompa, J.; (1) Giannakopoulou, F.; (2) Lepouras, G.; (1) Triantafyllou, I.; ","(1) University of West Attica, Greece; (2) University of Peloponnese, Greece; ",ACM,-1,"[""history"", ""human computer interaction"", ""museums""]","[""history"", ""human computer interaction"", ""museums""]",history;human computer interaction;museums,cultural heritage;liberal arts;human-computer interaction,end users and user experience;industries,cultural heritage;liberal arts;human-computer interaction,end users and user experience;industries,history human_computer_interaction museums cultural_informatics minimum_content minimum_meaningful_content c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7820_humanities_computing c7830d_computer_games cultural_heritage liberal_arts human computer_interaction,history human_computer_interaction museums,cultural_informatics minimum_content minimum_meaningful_content,last year research group working novel concept hci cultural informatics minimum content responding cognitive overload museum fatigue well documented literature concept minimum meaningful content introduced studied regard user experience concerning possible learning benefit overall satisfaction present work present finding different past effort explored effect minimum content cultural heritage visitor minimum content tested visitor different site lab experiment participant focusing augmented reality game photography result reveal potential minimum content cultural visit implication hci future work also discussed,history human_computer_interaction museums cultural_informatics minimum_content minimum_meaningful_content c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces c7820_humanities_computing c7830d_computer_games cultural_heritage liberal_arts human computer_interaction last year research group working novel concept hci cultural informatics minimum content responding cognitive overload museum fatigue well documented literature concept minimum meaningful content introduced studied regard user experience concerning possible learning benefit overall satisfaction present work present finding different past effort explored effect minimum content cultural heritage visitor minimum content tested visitor different site lab experiment participant focusing augmented reality game photography result reveal potential minimum content cultural visit implication hci future work also discussed,last year research group working novel concept hci cultural informatics minimum content responding cognitive overload museum fatigue well documented literature concept minimum meaningful content introduced studied regard user experience concerning possible learning benefit overall satisfaction present work present finding different past effort explored effect minimum content cultural heritage visitor minimum content tested visitor different site lab experiment participant focusing augmented reality game photography result reveal potential minimum content cultural visit implication hci future work also discussedhistory human_computer_interaction museumscultural_informatics minimum_content minimum_meaningful_content
303,UnMapped: Leveraging Experts' Situated Experiences to Ease Remote Guidance in Collaborative Mixed Reality,"Johnson, J. G., Sharkey, T., Butarbutar, I. C., Xiong, D., Huang, R., Sy, L., & Weibel, N. (2023). UnMapped: Leveraging Experts’ Situated Experiences to Ease Remote Guidance in Collaborative Mixed Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581444
",10.1145/3544548.3581444,"Collaborative Mixed Reality (MR) systems that help extend expertise for physical tasks to remote environments often situate experts in an immersive view of the task environment to bring the collaboration closer to collocated settings. In this paper, we design UnMapped, an alternative interface for remote experts that combines a live 3D view of the active space within the novice's environment with a static 3D recreation of the expert's own workspace to leverage their existing spatial memories within it. We evaluate the impact of this approach on single and repeated use of collaborative MR systems for remote guidance through a comparative study. Our results indicate that despite having a limited understanding of the novice's environment, using an UnMapped interface increased performance and communication efficiency while reducing experts' task load. We also outline the various affordances of providing remote experts with a familiar and spatially-stable environment to assist novices.",C6130V Virtual reality;C6130G Groupware,alternative interface;collaborative mixed reality systems;collaborative MR systems;collocated settings;immersive view;live 3D view;physical tasks;remote environments;remote experts;remote guidance;spatial memories;spatially-stable environment;static 3D recreation;task environment;UnMapped interface,augmented reality;groupware,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Johnson, J.G.; (1) Sharkey, T.; (1) Butarbutar, I.C.; (1) Xiong, D.; (2) Huang, R.; (3) Sy, L.; (4) Weibel, N.; ","(1) Computer Science and Engineering, San Diego, CA, United States; (2) University of California, San Diego, Department of Psychology, San Diego, CA, United States; (3) University of California, San Diego, Department of Cognitive Science, San Diego, CA, United States; (4) Computer Science and Engineering & Design Lab, San Diego, CA, United States; ",ACM,-1,"[""groupware""]","[""groupware""]",groupware,collaboration,use cases,collaboration,use cases,groupware alternative_interface collaborative_mixed_reality_systems collaborative_mr_systems collocated_settings immersive_view live_3d_view physical_tasks remote_environments remote_experts remote_guidance spatial_memories spatially stable_environment static_3d_recreation task_environment unmapped_interface c6130v_virtual_reality c6130g_groupware collaboration,groupware,alternative_interface collaborative_mixed_reality_systems collaborative_mr_systems collocated_settings immersive_view live_3d_view physical_tasks remote_environments remote_experts remote_guidance spatial_memories spatially stable_environment static_3d_recreation task_environment unmapped_interface,collaborative mixed reality mr system help extend expertise physical task remote environment often situate expert immersive view task environment bring collaboration closer collocated setting paper design unmapped alternative interface remote expert combine live 3d view active space within novice environment static 3d recreation expert workspace leverage existing spatial memory within evaluate impact approach single repeated use collaborative mr system remote guidance comparative study result indicate despite limited understanding novice environment using unmapped interface increased performance communication efficiency reducing expert task load also outline various affordances providing remote expert familiar spatially stable environment assist novice,groupware alternative_interface collaborative_mixed_reality_systems collaborative_mr_systems collocated_settings immersive_view live_3d_view physical_tasks remote_environments remote_experts remote_guidance spatial_memories spatially stable_environment static_3d_recreation task_environment unmapped_interface c6130v_virtual_reality c6130g_groupware collaboration collaborative mixed reality mr system help extend expertise physical task remote environment often situate expert immersive view task environment bring collaboration closer collocated setting paper design unmapped alternative interface remote expert combine live 3d view active space within novice environment static 3d recreation expert workspace leverage existing spatial memory within evaluate impact approach single repeated use collaborative mr system remote guidance comparative study result indicate despite limited understanding novice environment using unmapped interface increased performance communication efficiency reducing expert task load also outline various affordances providing remote expert familiar spatially stable environment assist novice,collaborative mixed reality mr system help extend expertise physical task remote environment often situate expert immersive view task environment bring collaboration closer collocated setting paper design unmapped alternative interface remote expert combine live 3d view active space within novice environment static 3d recreation expert workspace leverage existing spatial memory within evaluate impact approach single repeated use collaborative mr system remote guidance comparative study result indicate despite limited understanding novice environment using unmapped interface increased performance communication efficiency reducing expert task load also outline various affordances providing remote expert familiar spatially stable environment assist novicegroupwarealternative_interface collaborative_mixed_reality_systems collaborative_mr_systems collocated_settings immersive_view live_3d_view physical_tasks remote_environments remote_experts remote_guidance spatial_memories spatially stable_environment static_3d_recreation task_environment unmapped_interface
304,Partially Blended Realities: Aligning Dissimilar Spaces for Distributed Mixed Reality Meetings,"Grønbæk, J. E. S., Pfeuffer, K., Velloso, E., Astrup, M., Pedersen, M. I. S., Kjær, M., Leiva, G., & Gellersen, H. (2023). Partially Blended Realities: Aligning Dissimilar Spaces for Distributed Mixed Reality Meetings. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581515
",10.1145/3544548.3581515,"Mixed Reality allows for distributed meetings where people's local physical spaces are virtually aligned into blended interaction spaces. In many cases, people's physical rooms are dissimilar, making it challenging to design a coherent blended space. We introduce the concept of Partially Blended Realities (PBR) - using Mixed Reality to support remote collaborators in partially aligning their physical spaces. As physical surfaces are central in collaborative work, PBR supports users in transitioning between different configurations of tables and whiteboard surfaces. In this paper, we 1) describe the design space of PBR, 2) present RealityBlender to explore interaction techniques for how users may configure and transition between blended spaces, and 3) provide insights from a study on how users experience transitions in a remote collaboration task. With this work, we demonstrate new potential for using partial solutions to tackle the alignment problem of dissimilar spaces in distributed Mixed Reality meetings.",C6130V Virtual reality;C6130G Groupware,alignment problem;blended interaction spaces;design space;dissimilar spaces;distributed mixed reality meetings;partially blended realities;PBR;physical surfaces;remote collaboration task;remote collaborators;tables surfaces;whiteboard surfaces,augmented reality;groupware,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Gr&#248;nb&#230;k, J.E.S.; (1) Pfeuffer, K.; (2) Velloso, E.; (1) Astrup, M.; (1) Pedersen, M.I.S.; (1) Kjaer, M.; (3) Leiva, G.; (4) Gellersen, H.; ","(1) Aarhus University, Department of Computer Science, Denmark; (2) University of Melbourne, School of Computing and Information Systems, Melbourne, VIC, Australia; (3) Aarhus University, Digital Design and Information Studies, Denmark; (4) Lancaster University, United Kingdom; ",ACM,-1,"[""groupware""]","[""groupware""]",groupware,collaboration,use cases,collaboration,use cases,groupware alignment_problem blended_interaction_spaces design_space dissimilar_spaces distributed_mixed_reality_meetings partially_blended_realities pbr physical_surfaces remote_collaboration_task remote_collaborators tables_surfaces whiteboard_surfaces c6130v_virtual_reality c6130g_groupware collaboration,groupware,alignment_problem blended_interaction_spaces design_space dissimilar_spaces distributed_mixed_reality_meetings partially_blended_realities pbr physical_surfaces remote_collaboration_task remote_collaborators tables_surfaces whiteboard_surfaces,mixed reality allows distributed meeting people local physical space virtually aligned blended interaction space many case people physical room dissimilar making challenging design coherent blended space introduce concept partially blended reality pbr using mixed reality support remote collaborator partially aligning physical space physical surface central collaborative work pbr support user transitioning different configuration table whiteboard surface paper 1 describe design space pbr 2 present realityblender explore interaction technique user may configure transition blended space 3 provide insight study user experience transition remote collaboration task work demonstrate new potential using partial solution tackle alignment problem dissimilar space distributed mixed reality meeting,groupware alignment_problem blended_interaction_spaces design_space dissimilar_spaces distributed_mixed_reality_meetings partially_blended_realities pbr physical_surfaces remote_collaboration_task remote_collaborators tables_surfaces whiteboard_surfaces c6130v_virtual_reality c6130g_groupware collaboration mixed reality allows distributed meeting people local physical space virtually aligned blended interaction space many case people physical room dissimilar making challenging design coherent blended space introduce concept partially blended reality pbr using mixed reality support remote collaborator partially aligning physical space physical surface central collaborative work pbr support user transitioning different configuration table whiteboard surface paper 1 describe design space pbr 2 present realityblender explore interaction technique user may configure transition blended space 3 provide insight study user experience transition remote collaboration task work demonstrate new potential using partial solution tackle alignment problem dissimilar space distributed mixed reality meeting,mixed reality allows distributed meeting people local physical space virtually aligned blended interaction space many case people physical room dissimilar making challenging design coherent blended space introduce concept partially blended reality pbr using mixed reality support remote collaborator partially aligning physical space physical surface central collaborative work pbr support user transitioning different configuration table whiteboard surface paper 1 describe design space pbr 2 present realityblender explore interaction technique user may configure transition blended space 3 provide insight study user experience transition remote collaboration task work demonstrate new potential using partial solution tackle alignment problem dissimilar space distributed mixed reality meetinggroupwarealignment_problem blended_interaction_spaces design_space dissimilar_spaces distributed_mixed_reality_meetings partially_blended_realities pbr physical_surfaces remote_collaboration_task remote_collaborators tables_surfaces whiteboard_surfaces
305,Memory Manipulations in Extended Reality,"Bonnail, E., Tseng, W.-J., Mcgill, M., Lecolinet, E., Huron, S., & Gugenheimer, J. (2023). Memory Manipulations in Extended Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580988
",10.1145/3544548.3580988,"Human memory has notable limitations (e.g., forgetting) which have necessitated a variety of memory aids (e.g., calendars). As we grow closer to mass adoption of everyday Extended Reality (XR), which is frequently leveraging perceptual limitations (e.g., redirected walking), it becomes pertinent to consider how XR could leverage memory limitations (forgetting, distorting, persistence) to induce memory manipulations. As memories highly impact our self-perception, social interactions, and behaviors, there is a pressing need to understand XR Memory Manipulations (XRMMs). We ran three speculative design workshops (n=12), with XR and memory researchers creating 48 XRMM scenarios. Through thematic analysis, we define XRMMs, present a framework of their core components and reveal three classes (at encoding, pre-retrieval, at retrieval). Each class differs in terms of technology (AR, VR) and impact on memory (influencing quality of memories, inducing forgetting, distorting memories). We raise ethical concerns and discuss opportunities of perceptual and memory manipulations in XR.",C6130V Virtual reality;C0240 Ergonomic aspects of computing,extended reality;human memory;memory aids;memory researchers;perceptual limitations;XR memory manipulations,augmented reality;ethical aspects,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Bonnail, E.; (1) Tseng, W.-J.; (2) Mcgill, M.; (1) Lecolinet, E.; (3) Huron, S.; (4) Gugenheimer, J.; ","(1) Institut Polytechnique de Paris, LTCI, France; (2) University of Glasgow, School of Computing Science, United Kingdom; (3) Institut Polytechnique de Paris, SES, France; (4) TU-Darmstadt, Germany; ",ACM,-1,"[""ethical aspects""]","[""ethical aspects""]",ethical aspects,policy,business,policy,business,ethical_aspects extended_reality human_memory memory_aids memory_researchers perceptual_limitations xr_memory_manipulations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing policy,ethical_aspects,extended_reality human_memory memory_aids memory_researchers perceptual_limitations xr_memory_manipulations,human memory notable limitation e g forgetting necessitated variety memory aid e g calendar grow closer mass adoption everyday extended reality xr frequently leveraging perceptual limitation e g redirected walking becomes pertinent consider xr could leverage memory limitation forgetting distorting persistence induce memory manipulation memory highly impact self perception social interaction behavior pressing need understand xr memory manipulation xrmms ran three speculative design workshop n 12 xr memory researcher creating 48 xrmm scenario thematic analysis define xrmms present framework core component reveal three class encoding pre retrieval retrieval class differs term technology ar vr impact memory influencing quality memory inducing forgetting distorting memory raise ethical concern discus opportunity perceptual memory manipulation xr,ethical_aspects extended_reality human_memory memory_aids memory_researchers perceptual_limitations xr_memory_manipulations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing policy human memory notable limitation e g forgetting necessitated variety memory aid e g calendar grow closer mass adoption everyday extended reality xr frequently leveraging perceptual limitation e g redirected walking becomes pertinent consider xr could leverage memory limitation forgetting distorting persistence induce memory manipulation memory highly impact self perception social interaction behavior pressing need understand xr memory manipulation xrmms ran three speculative design workshop n 12 xr memory researcher creating 48 xrmm scenario thematic analysis define xrmms present framework core component reveal three class encoding pre retrieval retrieval class differs term technology ar vr impact memory influencing quality memory inducing forgetting distorting memory raise ethical concern discus opportunity perceptual memory manipulation xr,human memory notable limitation e g forgetting necessitated variety memory aid e g calendar grow closer mass adoption everyday extended reality xr frequently leveraging perceptual limitation e g redirected walking becomes pertinent consider xr could leverage memory limitation forgetting distorting persistence induce memory manipulation memory highly impact self perception social interaction behavior pressing need understand xr memory manipulation xrmms ran three speculative design workshop n 12 xr memory researcher creating 48 xrmm scenario thematic analysis define xrmms present framework core component reveal three class encoding pre retrieval retrieval class differs term technology ar vr impact memory influencing quality memory inducing forgetting distorting memory raise ethical concern discus opportunity perceptual memory manipulation xrethical_aspectsextended_reality human_memory memory_aids memory_researchers perceptual_limitations xr_memory_manipulations
306,Experiences of web-based extended reality technologies for physics education,"Zatarain‐Cabada, R., Barrón‐Estrada, M. L., Cárdenas‐Sainz, B. A., & Chavez‐Echeagaray, M. E. (2022). Experiences of web‐based extended reality technologies for physics education. Computer Applications in Engineering Education, 31(1), 63–82. Portico. https://doi.org/10.1002/cae.22571
",10.1002/cae.22571,"Extended reality (XR) technologies such as augmented reality (AR) and virtual reality (VR) are being increasingly used for education and skill development through the development of interactive learning environments (ILEs) with XR implementations. For physics education, these ILEs with XR are capable of improving the visual representation of educational content, as well as stimulating the cognitive process of learning with interactive experiences. In this study, we focused on evaluating students' perceptions of the usage of web-based XR technologies for education, through a learning tool that implements virtual reality and augmented reality environments, with the purpose of providing students the necessary didactic material to learn physics. An experimental process was carried out with a sample of 70 undergrad students who used FisicARtivo, a web-based learning tool on kinematics and dynamics concepts that incorporates XR. After working with the tool, students completed a comprehensive survey about their motivational perceptions regarding the use of XR technologies for physics education. According to the results, both VR and AR showed significant effects on motivation. However, there was a higher positive impact on students' learning motivation when they used FisicARtivo in AR mode in comparison to VR mode. &#169; 2023 Wiley Periodicals LLC.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C7810C Computer-aided instruction,70 undergrad students;educational content;ILEs;implements virtual reality;interactive experiences;interactive learning environments;learning tool;physics education;reality environments;skill development;web-based extended reality technologies;web-based XR technologies;XR implementations,augmented reality;cognition;computer aided instruction;human factors;physics education;virtual reality,2023,Journal article (JA),Comput. Appl. Eng. Educ. (USA),"(1) Zatarain-cabada, R.; (1) Barro&#769;n-estrada, M.L.; (1) Ca&#769;rdenas-sainz, B.A.; (2) Chavez-echeagaray, M.E.; ","(1) Instituto Tecnolo&#769;gico de Culiaca&#769;n, Mexico; (2) Arizona State University, Tempe, AZ, United States; ",Wiley,-1,"[""cognition"", ""computer aided instruction"", ""human factors"", ""physics education""]","[""cognition"", ""computer aided instruction"", ""human factors"", ""physics education""]",cognition;computer aided instruction;human factors;physics education,human factors;education;engineering;training,technology;end users and user experience;use cases;industries,human factors;education;engineering;training,technology;end users and user experience;use cases;industries,cognition computer_aided_instruction human_factors physics_education 70_undergrad_students educational_content iles implements_virtual_reality interactive_experiences interactive_learning_environments learning_tool physics_education reality_environments skill_development web based_extended_reality_technologies web based_xr_technologies xr_implementations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education engineering training,cognition computer_aided_instruction human_factors physics_education,70_undergrad_students educational_content iles implements_virtual_reality interactive_experiences interactive_learning_environments learning_tool physics_education reality_environments skill_development web based_extended_reality_technologies web based_xr_technologies xr_implementations,extended reality xr technology augmented reality ar virtual reality vr increasingly used education skill development development interactive learning environment iles xr implementation physic education iles xr capable improving visual representation educational content well stimulating cognitive process learning interactive experience study focused evaluating student perception usage web based xr technology education learning tool implement virtual reality augmented reality environment purpose providing student necessary didactic material learn physic experimental process carried sample 70 undergrad student used fisicartivo web based learning tool kinematics dynamic concept incorporates xr working tool student completed comprehensive survey motivational perception regarding use xr technology physic education according result vr ar showed significant effect motivation however higher positive impact student learning motivation used fisicartivo ar mode comparison vr mode 169 2023 wiley periodical llc,cognition computer_aided_instruction human_factors physics_education 70_undergrad_students educational_content iles implements_virtual_reality interactive_experiences interactive_learning_environments learning_tool physics_education reality_environments skill_development web based_extended_reality_technologies web based_xr_technologies xr_implementations c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c7810c_computer aided_instruction human_factors education engineering training extended reality xr technology augmented reality ar virtual reality vr increasingly used education skill development development interactive learning environment iles xr implementation physic education iles xr capable improving visual representation educational content well stimulating cognitive process learning interactive experience study focused evaluating student perception usage web based xr technology education learning tool implement virtual reality augmented reality environment purpose providing student necessary didactic material learn physic experimental process carried sample 70 undergrad student used fisicartivo web based learning tool kinematics dynamic concept incorporates xr working tool student completed comprehensive survey motivational perception regarding use xr technology physic education according result vr ar showed significant effect motivation however higher positive impact student learning motivation used fisicartivo ar mode comparison vr mode 169 2023 wiley periodical llc,extended reality xr technology augmented reality ar virtual reality vr increasingly used education skill development development interactive learning environment iles xr implementation physic education iles xr capable improving visual representation educational content well stimulating cognitive process learning interactive experience study focused evaluating student perception usage web based xr technology education learning tool implement virtual reality augmented reality environment purpose providing student necessary didactic material learn physic experimental process carried sample 70 undergrad student used fisicartivo web based learning tool kinematics dynamic concept incorporates xr working tool student completed comprehensive survey motivational perception regarding use xr technology physic education according result vr ar showed significant effect motivation however higher positive impact student learning motivation used fisicartivo ar mode comparison vr mode 169 2023 wiley periodical llccognition computer_aided_instruction human_factors physics_education70_undergrad_students educational_content iles implements_virtual_reality interactive_experiences interactive_learning_environments learning_tool physics_education reality_environments skill_development web based_extended_reality_technologies web based_xr_technologies xr_implementations
307,A First-Priority Set of&nbsp;Telepresence Services and&nbsp;a&nbsp;Model Network for&nbsp;Research and&nbsp;Education,"Koucheryavy, A. E., Makolkina, M. A., Paramonov, A. I., Vybornova, A. I., Muthanna, A. S. A., Dunaytsev, R. A., Vladimirov, S. S., Elagin, V. S., Markelov, O. A., Vorozheykina, O. I., Marochkina, A. V., Gorbacheva, L. S., Pankov, B. O., & Anvarzhonov, B. N. (2023). A First-Priority Set of Telepresence Services and a Model Network for Research and Education. Distributed Computer and Communication Networks, 208–219. https://doi.org/10.1007/978-3-031-30648-8_17
",10.1007/978-3-031-30648-8_17,"A first-priority set of telepresence services is proposed, and the delay requirements and fault probabilities for these services are defined. The end-to-end latency and reliability requirements are derived from analysis of ITU-T, 3GPP, ETSI standards and recommendations. The characteristics of a next-generation model network for research and education in the field of telepresence services are discussed. The model network is based on a DWDM core, a variety of server equipment, holographic fans, 3D cameras and projectors, avatar robots and multifunctional robots, and augmented reality terminal devices. The results of the first tests on the model network are presented. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;723.5 Computer Applications;731.5 Robotics;743 Holography;746 Imaging Techniques",3D camera;Avatar robot;End to end latencies;End-to-end reliabilities;Fault probabilities;Holographic communication;Model networks;Multifunctional robots;Reliability requirements;Telepresence,Augmented reality;Holography;Mobile telecommunication systems;Reliability analysis;Three dimensional computer graphics,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Koucheryavy, A.E.; (1) Makolkina, M.A.; (1) Paramonov, A.I.; (1) Vybornova, A.I.; (1) Muthanna, A.S.A.; (1) Dunaytsev, R.A.; (1) Vladimirov, S.S.; (1) Elagin, V.S.; (2) Markelov, O.A.; (1) Vorozheykina, O.I.; (1) Marochkina, A.V.; (1) Gorbacheva, L.S.; (1) Pankov, B.O.; (1) Anvarzhonov, B.N.; ","(1) Department of Communication Networks and Data Transmission, The Bonch-Bruevich Saint Petersburg State University of Telecommunications, 22 Prospect Bolshevikov, Saint Petersburg; 193232, Russia; (2) Radio Systems Department, Saint Petersburg Electrotechnical University ""LETI"", 5 Professora Popova Str., Saint Petersburg; 197376, Russia; ",Springer Science and Business Media Deutschland GmbH,-1,"[""holography"", ""mobile telecommunication systems"", ""reliability analysis"", ""three dimensional computer graphics""]","[""holography"", ""mobile telecommunication systems"", ""reliability analysis"", ""three dimensional computer graphics""]",holography;mobile telecommunication systems;reliability analysis;three dimensional computer graphics,"education;graphics;input;inspection, safety and quality;display technology;telecommunication;data",technology;displays;use cases;industries,"education;graphics;input;inspection, safety and quality;display technology;telecommunication;data",technology;displays;use cases;industries,holography mobile_telecommunication_systems reliability_analysis three_dimensional_computer_graphics 3d_camera avatar_robot end_to_end_latencies end to end_reliabilities fault_probabilities holographic_communication model_networks multifunctional_robots reliability_requirements telepresence 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications 731 5_robotics 743_holography 746_imaging_techniques education graphics input inspection _safety_and_quality display_technology telecommunication data,holography mobile_telecommunication_systems reliability_analysis three_dimensional_computer_graphics,3d_camera avatar_robot end_to_end_latencies end to end_reliabilities fault_probabilities holographic_communication model_networks multifunctional_robots reliability_requirements telepresence,first priority set telepresence service proposed delay requirement fault probability service defined end end latency reliability requirement derived analysis itu 3gpp etsi standard recommendation characteristic next generation model network research education field telepresence service discussed model network based dwdm core variety server equipment holographic fan 3d camera projector avatar robot multifunctional robot augmented reality terminal device result first test model network presented copy 2023 author exclusive license springer nature switzerland ag,holography mobile_telecommunication_systems reliability_analysis three_dimensional_computer_graphics 3d_camera avatar_robot end_to_end_latencies end to end_reliabilities fault_probabilities holographic_communication model_networks multifunctional_robots reliability_requirements telepresence 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications 731 5_robotics 743_holography 746_imaging_techniques education graphics input inspection _safety_and_quality display_technology telecommunication data first priority set telepresence service proposed delay requirement fault probability service defined end end latency reliability requirement derived analysis itu 3gpp etsi standard recommendation characteristic next generation model network research education field telepresence service discussed model network based dwdm core variety server equipment holographic fan 3d camera projector avatar robot multifunctional robot augmented reality terminal device result first test model network presented copy 2023 author exclusive license springer nature switzerland ag,first priority set telepresence service proposed delay requirement fault probability service defined end end latency reliability requirement derived analysis itu 3gpp etsi standard recommendation characteristic next generation model network research education field telepresence service discussed model network based dwdm core variety server equipment holographic fan 3d camera projector avatar robot multifunctional robot augmented reality terminal device result first test model network presented copy 2023 author exclusive license springer nature switzerland agholography mobile_telecommunication_systems reliability_analysis three_dimensional_computer_graphics3d_camera avatar_robot end_to_end_latencies end to end_reliabilities fault_probabilities holographic_communication model_networks multifunctional_robots reliability_requirements telepresence
308,When XR and AI Meet - A Scoping Review on Extended Reality and Artificial Intelligence,"Hirzle, T., Müller, F., Draxler, F., Schmitz, M., Knierim, P., & Hornbæk, K. (2023). When XR and AI Meet - A Scoping Review on Extended Reality and Artificial Intelligence. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581072
",10.1145/3544548.3581072,"Research on Extended Reality (XR) and Artificial Intelligence (AI) is booming, which has led to an emerging body of literature in their intersection. However, the main topics in this intersection are unclear, as are the benefits of combining XR and AI. This paper presents a scoping review that highlights how XR is applied in AI research and vice versa. We screened 2619 publications from 203 international venues published between 2017 and 2021, followed by an in-depth review of 311 papers. Based on our review, we identify five main topics at the intersection of XR and AI, showing how research at the intersection can benefit each other. Furthermore, we present a list of commonly used datasets, software, libraries, and models to help researchers interested in this intersection. Finally, we present 13 research opportunities and recommendations for future work in XR and AI research.",C6210 Knowledge based systems;C6130V Virtual reality,AI research;artificial intelligence;extended reality;XR,artificial intelligence;augmented reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Hirzle, T.; (2) Mu&#776;ller, F.; (2) Draxler, F.; (3) Schmitz, M.; (4) Knierim, P.; (1) Hornb&#230;k, K.; ","(1) University of Copenhagen, Department of Computer Science, Denmark; (2) Ludwig-Maximilians-Universita&#776;t Mu&#776;nchen, Germany; (3) Saarland University, Germany; (4) Universitat der Bundeswehr Munchen, Germany; ",ACM,-1,"[""artificial intelligence""]","[""artificial intelligence""]",artificial intelligence,artificial intelligence;liberal arts,technology;industries,artificial intelligence;liberal arts,technology;industries,artificial_intelligence ai_research artificial_intelligence extended_reality xr c6210_knowledge_based_systems c6130v_virtual_reality artificial_intelligence liberal_arts,artificial_intelligence,ai_research artificial_intelligence extended_reality xr,research extended reality xr artificial intelligence ai booming led emerging body literature intersection however main topic intersection unclear benefit combining xr ai paper present scoping review highlight xr applied ai research vice versa screened 2619 publication 203 international venue published 2017 2021 followed depth review 311 paper based review identify five main topic intersection xr ai showing research intersection benefit furthermore present list commonly used datasets software library model help researcher interested intersection finally present 13 research opportunity recommendation future work xr ai research,artificial_intelligence ai_research artificial_intelligence extended_reality xr c6210_knowledge_based_systems c6130v_virtual_reality artificial_intelligence liberal_arts research extended reality xr artificial intelligence ai booming led emerging body literature intersection however main topic intersection unclear benefit combining xr ai paper present scoping review highlight xr applied ai research vice versa screened 2619 publication 203 international venue published 2017 2021 followed depth review 311 paper based review identify five main topic intersection xr ai showing research intersection benefit furthermore present list commonly used datasets software library model help researcher interested intersection finally present 13 research opportunity recommendation future work xr ai research,research extended reality xr artificial intelligence ai booming led emerging body literature intersection however main topic intersection unclear benefit combining xr ai paper present scoping review highlight xr applied ai research vice versa screened 2619 publication 203 international venue published 2017 2021 followed depth review 311 paper based review identify five main topic intersection xr ai showing research intersection benefit furthermore present list commonly used datasets software library model help researcher interested intersection finally present 13 research opportunity recommendation future work xr ai researchartificial_intelligenceai_research artificial_intelligence extended_reality xr
309,StandARone: Infrared-Watermarked Documents as Portable Containers of AR Interaction and Personalization,"Dogan, M. D., Siu, A. F., Healey, J., Wigington, C., Xiao, C., & Sun, T. (2023). StandARone: Infrared-Watermarked Documents as Portable Containers of AR Interaction and Personalization. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585905
",10.1145/3544549.3585905,"Hybrid paper interfaces leverage augmented reality (AR) to combine the desired tangibility of paper documents with the affordances of interactive digital media. Typically, the instructions for how the virtual content should be generated are not an intrinsic part of the document but rather accessed through a link to remote resources. To enable hybrid documents to be portable containers of also the AR content, we introduce StandARone documents. Using our system, a document author can define AR content and embed it invisibly on the document using a standard inkjet printer and infrared-absorbing ink. A document consumer can interact with the embedded content using a smartphone with a NIR camera without requiring a network connection. We demonstrate several use cases of StandARone including personalized offline menus, interactive visualizations, and location-aware packaging.","B6135C Image and video coding;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130D Document processing and analysis techniques;C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",AR content;desired tangibility;document author;document consumer;embedded content;hybrid documents;hybrid paper interfaces leverage;infrared-absorbing ink;infrared-watermarked documents;interactive digital media;interactive visualizations;intrinsic part;portable containers;remote resources;standard inkjet printer;StandARone documents;StandARone including personalized offline menus;virtual content,augmented reality;data visualisation;image watermarking;smart phones;user interfaces;watermarking,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Dogan, M.D.; (1) Siu, A.F.; (1) Healey, J.; (1) Wigington, C.; (1) Xiao, C.; (1) Sun, T.; ","(1) Adobe Research, United States; ",ACM,-1,"[""data visualization"", ""image watermarking"", ""smartphones"", ""user interfaces"", ""watermarking""]","[""data visualization"", ""image watermarking"", ""smartphones"", ""user interfaces"", ""watermarking""]",data visualization;image watermarking;smartphones;user interfaces;watermarking,other;liberal arts;telecommunication;data;human-computer interaction,technology;other;industries;end users and user experience,other;liberal arts;telecommunication;data;human-computer interaction,technology;other;industries;end users and user experience,data_visualization image_watermarking smartphones user_interfaces watermarking ar_content desired_tangibility document_author document_consumer embedded_content hybrid_documents hybrid_paper_interfaces_leverage infrared absorbing_ink infrared watermarked_documents interactive_digital_media interactive_visualizations intrinsic_part portable_containers remote_resources standard_inkjet_printer standarone_documents standarone_including_personalized_offline_menus virtual_content b6135c_image_and_video_coding c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing other liberal_arts telecommunication data human computer_interaction,data_visualization image_watermarking smartphones user_interfaces watermarking,ar_content desired_tangibility document_author document_consumer embedded_content hybrid_documents hybrid_paper_interfaces_leverage infrared absorbing_ink infrared watermarked_documents interactive_digital_media interactive_visualizations intrinsic_part portable_containers remote_resources standard_inkjet_printer standarone_documents standarone_including_personalized_offline_menus virtual_content,hybrid paper interface leverage augmented reality ar combine desired tangibility paper document affordances interactive digital medium typically instruction virtual content generated intrinsic part document rather accessed link remote resource enable hybrid document portable container also ar content introduce standarone document using system document author define ar content embed invisibly document using standard inkjet printer infrared absorbing ink document consumer interact embedded content using smartphone nir camera without requiring network connection demonstrate several use case standarone including personalized offline menu interactive visualization location aware packaging,data_visualization image_watermarking smartphones user_interfaces watermarking ar_content desired_tangibility document_author document_consumer embedded_content hybrid_documents hybrid_paper_interfaces_leverage infrared absorbing_ink infrared watermarked_documents interactive_digital_media interactive_visualizations intrinsic_part portable_containers remote_resources standard_inkjet_printer standarone_documents standarone_including_personalized_offline_menus virtual_content b6135c_image_and_video_coding c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing other liberal_arts telecommunication data human computer_interaction hybrid paper interface leverage augmented reality ar combine desired tangibility paper document affordances interactive digital medium typically instruction virtual content generated intrinsic part document rather accessed link remote resource enable hybrid document portable container also ar content introduce standarone document using system document author define ar content embed invisibly document using standard inkjet printer infrared absorbing ink document consumer interact embedded content using smartphone nir camera without requiring network connection demonstrate several use case standarone including personalized offline menu interactive visualization location aware packaging,hybrid paper interface leverage augmented reality ar combine desired tangibility paper document affordances interactive digital medium typically instruction virtual content generated intrinsic part document rather accessed link remote resource enable hybrid document portable container also ar content introduce standarone document using system document author define ar content embed invisibly document using standard inkjet printer infrared absorbing ink document consumer interact embedded content using smartphone nir camera without requiring network connection demonstrate several use case standarone including personalized offline menu interactive visualization location aware packagingdata_visualization image_watermarking smartphones user_interfaces watermarkingar_content desired_tangibility document_author document_consumer embedded_content hybrid_documents hybrid_paper_interfaces_leverage infrared absorbing_ink infrared watermarked_documents interactive_digital_media interactive_visualizations intrinsic_part portable_containers remote_resources standard_inkjet_printer standarone_documents standarone_including_personalized_offline_menus virtual_content
310,Build a Smart Sustainable Windhoek: An AR game,"Makosa, I., Nuunyango, C., & Uchezuba, K. C. (2023). Build a Smart Sustainable Windhoek: An AR game. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583841
",10.1145/3544549.3583841,"The City of Windhoek is dedicated to become a Smart, Sustainable City, in alignment with sustainable development goal 11. Local officials strive to include residents to guide smart and sustainable initiatives and strategies, but lack tools and techniques to engage those unfamiliar with smart city concepts. We proposed a Build a Smart Sustainable Windhoek game, which educates and raises awareness while sharing citizen needs and desires to inform smart and sustainable city strategies. It is an interactive hybrid game combining physical interactions with boxes and augmented reality. The game was co-designed with unemployed youth from an informal settlement in the capital. It was played by 8 teams, each consisting of three Windhoek residents from different backgrounds, during a half-day smart city event. The survey results show that participants enjoyed the role of a town planner and building their own city having been teamed up with fellow residents from different suburbs. Moreover, they considered the game to be most informative in creating awareness on Smart City topics.","C7130 Public administration;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7485 Smart cities;C7830D Computer games;E0230 Environmental issues",AR game;half-day smart city event;interactive hybrid game;local officials;smart city concepts;Smart City topics;Smart Sustainable Windhoek game;sustainable city strategies;sustainable development goal 11;sustainable initiatives;Windhoek residents,augmented reality;smart cities;sustainable development;town and country planning,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Makosa, I.; (1) Nuunyango, C.; (1) Uchezuba, K.C.; ","(1) Namibia University of Science and Technology, Faculty of Computing and Informatics, Namibia; ",ACM,-1,"[""smart cities"", ""sustainable development"", ""town and country planning""]","[""smart cities"", ""sustainable development"", ""town and country planning""]",smart cities;sustainable development;town and country planning,policy;smart cities;business planning and management;liberal arts,business;use cases;industries,policy;smart cities;business planning and management;liberal arts,business;use cases;industries,smart_cities sustainable_development town_and_country_planning ar_game half day_smart_city_event interactive_hybrid_game local_officials smart_city_concepts smart_city_topics smart_sustainable_windhoek_game sustainable_city_strategies sustainable_development_goal_11 sustainable_initiatives windhoek_residents c7130_public_administration c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7485_smart_cities c7830d_computer_games e0230_environmental_issues policy smart_cities business_planning_and_management liberal_arts,smart_cities sustainable_development town_and_country_planning,ar_game half day_smart_city_event interactive_hybrid_game local_officials smart_city_concepts smart_city_topics smart_sustainable_windhoek_game sustainable_city_strategies sustainable_development_goal_11 sustainable_initiatives windhoek_residents,city windhoek dedicated become smart sustainable city alignment sustainable development goal 11 local official strive include resident guide smart sustainable initiative strategy lack tool technique engage unfamiliar smart city concept proposed build smart sustainable windhoek game educates raise awareness sharing citizen need desire inform smart sustainable city strategy interactive hybrid game combining physical interaction box augmented reality game co designed unemployed youth informal settlement capital played 8 team consisting three windhoek resident different background half day smart city event survey result show participant enjoyed role town planner building city teamed fellow resident different suburb moreover considered game informative creating awareness smart city topic,smart_cities sustainable_development town_and_country_planning ar_game half day_smart_city_event interactive_hybrid_game local_officials smart_city_concepts smart_city_topics smart_sustainable_windhoek_game sustainable_city_strategies sustainable_development_goal_11 sustainable_initiatives windhoek_residents c7130_public_administration c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7485_smart_cities c7830d_computer_games e0230_environmental_issues policy smart_cities business_planning_and_management liberal_arts city windhoek dedicated become smart sustainable city alignment sustainable development goal 11 local official strive include resident guide smart sustainable initiative strategy lack tool technique engage unfamiliar smart city concept proposed build smart sustainable windhoek game educates raise awareness sharing citizen need desire inform smart sustainable city strategy interactive hybrid game combining physical interaction box augmented reality game co designed unemployed youth informal settlement capital played 8 team consisting three windhoek resident different background half day smart city event survey result show participant enjoyed role town planner building city teamed fellow resident different suburb moreover considered game informative creating awareness smart city topic,city windhoek dedicated become smart sustainable city alignment sustainable development goal 11 local official strive include resident guide smart sustainable initiative strategy lack tool technique engage unfamiliar smart city concept proposed build smart sustainable windhoek game educates raise awareness sharing citizen need desire inform smart sustainable city strategy interactive hybrid game combining physical interaction box augmented reality game co designed unemployed youth informal settlement capital played 8 team consisting three windhoek resident different background half day smart city event survey result show participant enjoyed role town planner building city teamed fellow resident different suburb moreover considered game informative creating awareness smart city topicsmart_cities sustainable_development town_and_country_planningar_game half day_smart_city_event interactive_hybrid_game local_officials smart_city_concepts smart_city_topics smart_sustainable_windhoek_game sustainable_city_strategies sustainable_development_goal_11 sustainable_initiatives windhoek_residents
311,A petri net architecture for real-time human activity recognition in work systems,"Herrmann, J.-P., Atanasyan, A., Casser, F., & Tackenberg, S. (2023). A Petri Net Architecture for Real-Time Human Activity Recognition in Work Systems. Procedia Computer Science, 217, 1188–1199. https://doi.org/10.1016/j.procs.2022.12.317
",10.1016/j.procs.2022.12.317,"Real-time human-centered assistance in industrial processes depends on the individual history of the work person's activities in the work system and requires adequate methods for tracking the person's actions. Most research in human activity recognition is based on recognizing actions from video data using computer vision methods. Digital equipment, standardized machine data interfaces, and smart wearable devices extend the possibilities to describe the current state of the work system. Petri nets have already been applied to human activity recognition, however, without the requirement of detecting actions in real-time. This paper proposes a Petri net architecture that enables hierarchical description-based human activity recognition in industrial work processes. We present an extension, a Partitioned Colored Petri Net, based on the colored Petri net formalism that infers activities from state transitions of the work system in real-time. In a case study, we demonstrate the Petri net's application for an error-based learning system that visualizes error consequences in augmented reality using experimentable digital twins. All rights reserved Elsevier.",C1160 Combinatorial mathematics;C5260B Computer vision and image processing techniques;C6130V Virtual reality,colored Petri net formalism;computer vision methods;hierarchical description-based human activity recognition;industrial work processes;infers activities;Partitioned Colored Petri Net;petri net architecture;Petri nets;real-time human activity recognition;recognizing actions;standardized machine data interfaces;work person;work system,augmented reality;computer vision;digital twins;human activity recognition;Petri nets,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Herrmann, J.-P.; (2) Atanasyan, A.; (2) Casser, F.; (1) Tackenberg, S.; ","(1) OWL University of Applied Sciences and Arts, Campusallee 12, Germany; (2) RWTH Aachen University, Templergraben 55, Germany; ",Elsevier B.V.,-1,"[""computer vision"", ""digital twins"", ""human activity recognition"", ""petri nets""]","[""computer vision"", ""digital twins"", ""human activity recognition"", ""petri nets""]",computer vision;digital twins;human activity recognition;petri nets,computer vision;human factors;smart cities;other,technology;other;use cases;end users and user experience,computer vision;human factors;smart cities;other,technology;other;use cases;end users and user experience,computer_vision digital_twins human_activity_recognition petri_nets colored_petri_net_formalism computer_vision_methods hierarchical_description based_human_activity_recognition industrial_work_processes infers_activities partitioned_colored_petri_net petri_net_architecture petri_nets real time_human_activity_recognition recognizing_actions standardized_machine_data_interfaces work_person work_system c1160_combinatorial_mathematics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision human_factors smart_cities other,computer_vision digital_twins human_activity_recognition petri_nets,colored_petri_net_formalism computer_vision_methods hierarchical_description based_human_activity_recognition industrial_work_processes infers_activities partitioned_colored_petri_net petri_net_architecture petri_nets real time_human_activity_recognition recognizing_actions standardized_machine_data_interfaces work_person work_system,real time human centered assistance industrial process depends individual history work person activity work system requires adequate method tracking person action research human activity recognition based recognizing action video data using computer vision method digital equipment standardized machine data interface smart wearable device extend possibility describe current state work system petri net already applied human activity recognition however without requirement detecting action real time paper proposes petri net architecture enables hierarchical description based human activity recognition industrial work process present extension partitioned colored petri net based colored petri net formalism infers activity state transition work system real time case study demonstrate petri net application error based learning system visualizes error consequence augmented reality using experimentable digital twin right reserved elsevier,computer_vision digital_twins human_activity_recognition petri_nets colored_petri_net_formalism computer_vision_methods hierarchical_description based_human_activity_recognition industrial_work_processes infers_activities partitioned_colored_petri_net petri_net_architecture petri_nets real time_human_activity_recognition recognizing_actions standardized_machine_data_interfaces work_person work_system c1160_combinatorial_mathematics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision human_factors smart_cities other real time human centered assistance industrial process depends individual history work person activity work system requires adequate method tracking person action research human activity recognition based recognizing action video data using computer vision method digital equipment standardized machine data interface smart wearable device extend possibility describe current state work system petri net already applied human activity recognition however without requirement detecting action real time paper proposes petri net architecture enables hierarchical description based human activity recognition industrial work process present extension partitioned colored petri net based colored petri net formalism infers activity state transition work system real time case study demonstrate petri net application error based learning system visualizes error consequence augmented reality using experimentable digital twin right reserved elsevier,real time human centered assistance industrial process depends individual history work person activity work system requires adequate method tracking person action research human activity recognition based recognizing action video data using computer vision method digital equipment standardized machine data interface smart wearable device extend possibility describe current state work system petri net already applied human activity recognition however without requirement detecting action real time paper proposes petri net architecture enables hierarchical description based human activity recognition industrial work process present extension partitioned colored petri net based colored petri net formalism infers activity state transition work system real time case study demonstrate petri net application error based learning system visualizes error consequence augmented reality using experimentable digital twin right reserved elseviercomputer_vision digital_twins human_activity_recognition petri_netscolored_petri_net_formalism computer_vision_methods hierarchical_description based_human_activity_recognition industrial_work_processes infers_activities partitioned_colored_petri_net petri_net_architecture petri_nets real time_human_activity_recognition recognizing_actions standardized_machine_data_interfaces work_person work_system
312,Educational Robotics in Teaching Programming in Primary School,"Stoffová, V., & Zboran, M. (2023). Educational Robotics in Teaching Programming in Primary School. Proceedings of International Conference on Recent Innovations in Computing, 669–682. https://doi.org/10.1007/978-981-19-9876-8_51
",10.1007/978-981-19-9876-8_51,"Learning at Slovak primary schools in the last school years takes place in a combined form due to the COVID-19 pandemic. With the distance form of teaching, it was possible to reduce the teaching hours and omit some parts of the study plan. Parts of the subjects often omitted were tied to practical lessons in special facilities, possibly to the use of specific equipment or tools, such as laboratory exercises and experiments, building and construction of robots, programming and physical education. Teachers opted the path of least resistance and often preferred to skip such topics. According to the state educational program in elementary school, it is necessary to develop algorithmic and programming thinking. For this purpose, thematic units focused on algorithmic problem solving and programming are used. The article brings the experience of the authors from the programming of robots in elementary school, which can be equally successfully implemented face-to-face as well as remotely using real or virtual robots. To revive learning and increase its effectiveness, the authors used modern teaching aid and digital educational technologies, which have also proven themselves in the distance form of education. We used virtual and augmented reality, worked in remote laboratories and used implementation of laboratory experiments using visualized simulation models and environments and emulation techniques. The authors report on their experience of teaching programming in primary schools using programmable toys, robots and microcontrollers. Simple tools (buttons marked with symbols) and an interactive environment that offers block or icon programming are used to program the movement and control the activities of such objects&mdash;robot toys and own constructed robots. Compiling a functional program does not require high analytical and abstract thinking. The program can be easily and interactively assembled from the offered building elements. This method makes programming more fun for elementary school students and ensures their rapid progress and the joy of success. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","405.1 Construction Equipment;723 Computer Software, Data Handling and Applications;723.1 Computer Programming;731.5 Robotics;731.6 Robot Applications;732.1 Control Equipment;903.1 Information Sources and Analysis",Elementary schools;Laboratory experiments;Learning programming;Primary schools;Programmable robot toy;Programming;Programming robots;Robot toys;Teaching and learning;Teaching programming,Abstracting;Augmented reality;Construction equipment;Controllers;Educational robots;Microcontrollers,2023,Conference article (CA),Lect. Notes Electr. Eng.,"(1) Stoffov&aacute;, Veronika; (2) Zboran, Martin; ","(1) Faculty of Education of Trnava University in Trnava, Trnava, Slovakia; (2) Faculty of Mathematics, Physics and Informatics, Comenius University in Bratislava, Bratislava, Slovakia; ",Springer Science and Business Media Deutschland GmbH,-1,"[""abstracting"", ""construction equipment"", ""controllers"", ""educational robots"", ""microcontrollers""]","[""abstracting"", ""construction equipment"", ""controllers"", ""educational robots"", ""microcontrollers""]",abstracting;construction equipment;controllers;educational robots;microcontrollers,construction;education;robotics;input;human-computer interaction;video,technology;end users and user experience;industries,construction;education;robotics;input;human-computer interaction;video,technology;end users and user experience;industries,abstracting construction_equipment controllers educational_robots microcontrollers elementary_schools laboratory_experiments learning_programming primary_schools programmable_robot_toy programming programming_robots robot_toys teaching_and_learning teaching_programming 405 1_construction_equipment 723_computer_software _data_handling_and_applications 723 1_computer_programming 731 5_robotics 731 6_robot_applications 732 1_control_equipment 903 1_information_sources_and_analysis construction education robotics input human computer_interaction video,abstracting construction_equipment controllers educational_robots microcontrollers,elementary_schools laboratory_experiments learning_programming primary_schools programmable_robot_toy programming programming_robots robot_toys teaching_and_learning teaching_programming,learning slovak primary school last school year take place combined form due covid 19 pandemic distance form teaching possible reduce teaching hour omit part study plan part subject often omitted tied practical lesson special facility possibly use specific equipment tool laboratory exercise experiment building construction robot programming physical education teacher opted path least resistance often preferred skip topic according state educational program elementary school necessary develop algorithmic programming thinking purpose thematic unit focused algorithmic problem solving programming used article brings experience author programming robot elementary school equally successfully implemented face face well remotely using real virtual robot revive learning increase effectiveness author used modern teaching aid digital educational technology also proven distance form education used virtual augmented reality worked remote laboratory used implementation laboratory experiment using visualized simulation model environment emulation technique author report experience teaching programming primary school using programmable toy robot microcontrollers simple tool button marked symbol interactive environment offer block icon programming used program movement control activity object mdash robot toy constructed robot compiling functional program require high analytical abstract thinking program easily interactively assembled offered building element method make programming fun elementary school student ensures rapid progress joy success copy 2023 author exclusive license springer nature singapore pte ltd,abstracting construction_equipment controllers educational_robots microcontrollers elementary_schools laboratory_experiments learning_programming primary_schools programmable_robot_toy programming programming_robots robot_toys teaching_and_learning teaching_programming 405 1_construction_equipment 723_computer_software _data_handling_and_applications 723 1_computer_programming 731 5_robotics 731 6_robot_applications 732 1_control_equipment 903 1_information_sources_and_analysis construction education robotics input human computer_interaction video learning slovak primary school last school year take place combined form due covid 19 pandemic distance form teaching possible reduce teaching hour omit part study plan part subject often omitted tied practical lesson special facility possibly use specific equipment tool laboratory exercise experiment building construction robot programming physical education teacher opted path least resistance often preferred skip topic according state educational program elementary school necessary develop algorithmic programming thinking purpose thematic unit focused algorithmic problem solving programming used article brings experience author programming robot elementary school equally successfully implemented face face well remotely using real virtual robot revive learning increase effectiveness author used modern teaching aid digital educational technology also proven distance form education used virtual augmented reality worked remote laboratory used implementation laboratory experiment using visualized simulation model environment emulation technique author report experience teaching programming primary school using programmable toy robot microcontrollers simple tool button marked symbol interactive environment offer block icon programming used program movement control activity object mdash robot toy constructed robot compiling functional program require high analytical abstract thinking program easily interactively assembled offered building element method make programming fun elementary school student ensures rapid progress joy success copy 2023 author exclusive license springer nature singapore pte ltd,learning slovak primary school last school year take place combined form due covid 19 pandemic distance form teaching possible reduce teaching hour omit part study plan part subject often omitted tied practical lesson special facility possibly use specific equipment tool laboratory exercise experiment building construction robot programming physical education teacher opted path least resistance often preferred skip topic according state educational program elementary school necessary develop algorithmic programming thinking purpose thematic unit focused algorithmic problem solving programming used article brings experience author programming robot elementary school equally successfully implemented face face well remotely using real virtual robot revive learning increase effectiveness author used modern teaching aid digital educational technology also proven distance form education used virtual augmented reality worked remote laboratory used implementation laboratory experiment using visualized simulation model environment emulation technique author report experience teaching programming primary school using programmable toy robot microcontrollers simple tool button marked symbol interactive environment offer block icon programming used program movement control activity object mdash robot toy constructed robot compiling functional program require high analytical abstract thinking program easily interactively assembled offered building element method make programming fun elementary school student ensures rapid progress joy success copy 2023 author exclusive license springer nature singapore pte ltdabstracting construction_equipment controllers educational_robots microcontrollerselementary_schools laboratory_experiments learning_programming primary_schools programmable_robot_toy programming programming_robots robot_toys teaching_and_learning teaching_programming
313,HMDspeller: Fast and Hands-free Text Entry System for Head Mount Displays using Silent Spelling Recognition,"Asano, K., Kimura, N., & Rekimoto, J. (2023). HMDspeller: Fast and Hands-free Text Entry System for Head Mount Displays using Silent Spelling Recognition. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583910
",10.1145/3544549.3583910,"As virtual reality and augmented reality technology become more popular in office and communication contexts, the need for simple and efficient text input methods for these devices becomes more evident. We propose the use of an HMDspeller, which allows for text input at a speed of more than 30 words per minute without the need of using hands. Our method utilizes a technique called ""silent spelling,"" which serves as a compromise between text entry and silent speech. The HMDspeller uses an infrared camera to capture the user's silent spelling and decode the words, achieving a character error rate of 13.9% for seen words and 26.6% for unseen words without using language models or dictionaries.",B6130E Speech recognition and synthesis;C5260S Speech processing techniques;C5540B Interactive-input devices;C6130D Document processing and analysis techniques;C6130V Virtual reality;C6180 User interfaces;C6180N Natural language interfaces;C7820N Natural language processing;C7850 Computer assistance for persons with handicaps,communication contexts;efficient text input methods;hands-free text entry system;head mount displays;HMDspeller;office;reality technology;silent speech;silent spelling recognition;simple text input methods;unseen words;virtual reality,augmented reality;helmet mounted displays;natural language processing;text analysis;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Asano, K.; (2) Kimura, N.; (2) Rekimoto, J.; ","(1) Columbia University, New York, NY, United States; (2) University of Tokyo, Japan; ",ACM,-1,"[""helmet mounted displays"", ""natural language processing"", ""text analysis""]","[""helmet mounted displays"", ""natural language processing"", ""text analysis""]",helmet mounted displays;natural language processing;text analysis,input;display technology;wearables;data;artificial intelligence,technology;displays,input;display technology;wearables;data;artificial intelligence,technology;displays,helmet_mounted_displays natural_language_processing text_analysis communication_contexts efficient_text_input_methods hands free_text_entry_system head_mount_displays hmdspeller office reality_technology silent_speech silent_spelling_recognition simple_text_input_methods unseen_words virtual_reality b6130e_speech_recognition_and_synthesis c5260s_speech_processing_techniques c5540b_interactive input_devices c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6180_user_interfaces c6180n_natural_language_interfaces c7820n_natural_language_processing c7850_computer_assistance_for_persons_with_handicaps input display_technology wearables data artificial_intelligence,helmet_mounted_displays natural_language_processing text_analysis,communication_contexts efficient_text_input_methods hands free_text_entry_system head_mount_displays hmdspeller office reality_technology silent_speech silent_spelling_recognition simple_text_input_methods unseen_words virtual_reality,virtual reality augmented reality technology become popular office communication context need simple efficient text input method device becomes evident propose use hmdspeller allows text input speed 30 word per minute without need using hand method utilizes technique called silent spelling serf compromise text entry silent speech hmdspeller us infrared camera capture user silent spelling decode word achieving character error rate 13 9 seen word 26 6 unseen word without using language model dictionary,helmet_mounted_displays natural_language_processing text_analysis communication_contexts efficient_text_input_methods hands free_text_entry_system head_mount_displays hmdspeller office reality_technology silent_speech silent_spelling_recognition simple_text_input_methods unseen_words virtual_reality b6130e_speech_recognition_and_synthesis c5260s_speech_processing_techniques c5540b_interactive input_devices c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6180_user_interfaces c6180n_natural_language_interfaces c7820n_natural_language_processing c7850_computer_assistance_for_persons_with_handicaps input display_technology wearables data artificial_intelligence virtual reality augmented reality technology become popular office communication context need simple efficient text input method device becomes evident propose use hmdspeller allows text input speed 30 word per minute without need using hand method utilizes technique called silent spelling serf compromise text entry silent speech hmdspeller us infrared camera capture user silent spelling decode word achieving character error rate 13 9 seen word 26 6 unseen word without using language model dictionary,virtual reality augmented reality technology become popular office communication context need simple efficient text input method device becomes evident propose use hmdspeller allows text input speed 30 word per minute without need using hand method utilizes technique called silent spelling serf compromise text entry silent speech hmdspeller us infrared camera capture user silent spelling decode word achieving character error rate 13 9 seen word 26 6 unseen word without using language model dictionaryhelmet_mounted_displays natural_language_processing text_analysiscommunication_contexts efficient_text_input_methods hands free_text_entry_system head_mount_displays hmdspeller office reality_technology silent_speech silent_spelling_recognition simple_text_input_methods unseen_words virtual_reality
314,When Realities Interweave: Exploring the Design Space of Immersive Tangible XR,"Uhl, J. C., Schrom-Feiertag, H., Regal, G., Hirsch, L., Weiss, Y., & Tscheligi, M. (2023). When Realities Interweave: Exploring the Design Space of Immersive Tangible XR. Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction. https://doi.org/10.1145/3569009.3571843
",10.1145/3569009.3571843,"Tangible devices and interaction in Extended Reality (XR) increase immersion and enable users to perform tasks more intuitively, accurately and joyfully across the reality-virtuality continuum. Upon reviewing the literature, we noticed no clear trend for a publication venue, as well as no standard in evaluating the effects of tangible XR. To position the topic of tangible XR in the TEI community, we propose a hands-on studio, where participants will bring in their own ideas for tangible XR from their application fields, and develop prototypes with the cutting-edge technology and a selection of virtual assets provided. Additionally, we will collectively reflect upon evaluation methods on tangible XR, and aim to find a consensus of a core evaluation suite. With this, we aim to foster a practical understanding and spark new developments in tangible XR and its use cases within the TEI community.",C6130V Virtual reality;C6180 User interfaces,design space;extended reality;immersive tangible XR;reality-virtuality continuum;virtual assets,augmented reality;human computer interaction,2023,Conference article (CA),"TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction","(1) Uhl, J.C.; (1) Schrom-Feiertag, H.; (1) Regal, G.; (2) Hirsch, L.; (2) Weiss, Y.; (3) Tscheligi, M.; ","(1) Austrian Institute of Technology, Center for Technology Experience, Austria; (2) Ludwig Maximilian University, Germany; (3) Paris Lodron Universitat, Austria; ",ACM,-1,"[""human computer interaction""]","[""human computer interaction""]",human computer interaction,human-computer interaction,end users and user experience,human-computer interaction,end users and user experience,human_computer_interaction design_space extended_reality immersive_tangible_xr reality virtuality_continuum virtual_assets c6130v_virtual_reality c6180_user_interfaces human computer_interaction,human_computer_interaction,design_space extended_reality immersive_tangible_xr reality virtuality_continuum virtual_assets,tangible device interaction extended reality xr increase immersion enable user perform task intuitively accurately joyfully across reality virtuality continuum upon reviewing literature noticed clear trend publication venue well standard evaluating effect tangible xr position topic tangible xr tei community propose hand studio participant bring idea tangible xr application field develop prototype cutting edge technology selection virtual asset provided additionally collectively reflect upon evaluation method tangible xr aim find consensus core evaluation suite aim foster practical understanding spark new development tangible xr use case within tei community,human_computer_interaction design_space extended_reality immersive_tangible_xr reality virtuality_continuum virtual_assets c6130v_virtual_reality c6180_user_interfaces human computer_interaction tangible device interaction extended reality xr increase immersion enable user perform task intuitively accurately joyfully across reality virtuality continuum upon reviewing literature noticed clear trend publication venue well standard evaluating effect tangible xr position topic tangible xr tei community propose hand studio participant bring idea tangible xr application field develop prototype cutting edge technology selection virtual asset provided additionally collectively reflect upon evaluation method tangible xr aim find consensus core evaluation suite aim foster practical understanding spark new development tangible xr use case within tei community,tangible device interaction extended reality xr increase immersion enable user perform task intuitively accurately joyfully across reality virtuality continuum upon reviewing literature noticed clear trend publication venue well standard evaluating effect tangible xr position topic tangible xr tei community propose hand studio participant bring idea tangible xr application field develop prototype cutting edge technology selection virtual asset provided additionally collectively reflect upon evaluation method tangible xr aim find consensus core evaluation suite aim foster practical understanding spark new development tangible xr use case within tei communityhuman_computer_interactiondesign_space extended_reality immersive_tangible_xr reality virtuality_continuum virtual_assets
315,The Use of Industry 4.0 Technologies in Maintenance: A Systematic Literature Review,"Essalih, S., Haouat, Z. E., Ramadany, M., Bennouna, F., & Amegouz, D. (2023). The Use of Industry 4.0 Technologies in Maintenance: A Systematic Literature Review. Lecture Notes in Networks and Systems, 811–821. https://doi.org/10.1007/978-3-031-29857-8_81
",10.1007/978-3-031-29857-8_81,"In the Industry 4.0 era, where competitiveness in the industrial sector is increasingly tough, maintenance optimization is an undeniable tool to stand out in this fierce context. To minimize costs, increase productivity, improve quality and facilitate decision-making in maintenance activities, companies are resorting to the deployment of digital technologies of the fourth industrial revolution, including the Internet of Things (IoT), Big Data, Additive Manufacturing (AM), Augmented Reality (AR), Cloud Computing, etc. The main goal of this paper is to assess the impact of Industry 4.0 in maintenance, to identify which technologies are used by companies in maintenance, what are the reasons that push companies to use these tools, and what are their benefits. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","722.3 Data Communication, Equipment and Techniques;722.4 Digital Computers and Systems;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;911.2 Industrial Economics;912.2 Management;913.4 Manufacturing;913.5 Maintenance",Cloud-computing;Cost-increases;Decisions makings;Digital technologies;Industrial revolutions;Industrial sector;Maintenance activity;Maintenance optimization;Predictive maintenance;Systematic literature review,Augmented reality;Big data;Cloud computing;Competition;Decision making;Internet of things;Maintenance,2023,Conference article (CA),Lect. Notes Networks Syst.,"(1) Essalih, Safaa; (1) Haouat, Zineb El; (2) Ramadany, Mohamed; (3) Bennouna, Fatima; (1) Amegouz, Driss; ","(1) Higher School of Technology Sidi Mohammed Ben Abdellah University, Fez; 30050, Morocco; (2) Faculty of Sciences and Techniques Sidi Mohammed, Ben Abdellah University, Fez; 30050, Morocco; (3) National School of Applied Sciences, Sidi Mohammed Ben Abdellah University, Fez; 30050, Morocco; ",Springer Science and Business Media Deutschland GmbH,-1,"[""big data"", ""cloud computing"", ""competition"", ""decision making"", ""internet of things"", ""maintenance""]","[""big data"", ""cloud computing"", ""competition"", ""decision making"", ""internet of things"", ""maintenance""]",big data;cloud computing;competition;decision making;internet of things;maintenance,business performance metrics;human factors;internet of things;data;manufacturing;networks,technology;industries;business;end users and user experience,business performance metrics;human factors;internet of things;data;manufacturing;networks,technology;industries;business;end users and user experience,big_data cloud_computing competition decision_making internet_of_things maintenance cloud computing cost increases decisions_makings digital_technologies industrial_revolutions industrial_sector maintenance_activity maintenance_optimization predictive_maintenance systematic_literature_review 722 3_data_communication _equipment_and_techniques 722 4_digital_computers_and_systems 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 911 2_industrial_economics 912 2_management 913 4_manufacturing 913 5_maintenance business_performance_metrics human_factors internet_of_things data manufacturing networks,big_data cloud_computing competition decision_making internet_of_things maintenance,cloud computing cost increases decisions_makings digital_technologies industrial_revolutions industrial_sector maintenance_activity maintenance_optimization predictive_maintenance systematic_literature_review,industry 4 0 era competitiveness industrial sector increasingly tough maintenance optimization undeniable tool stand fierce context minimize cost increase productivity improve quality facilitate decision making maintenance activity company resorting deployment digital technology fourth industrial revolution including internet thing iot big data additive manufacturing augmented reality ar cloud computing etc main goal paper ass impact industry 4 0 maintenance identify technology used company maintenance reason push company use tool benefit copy 2023 author exclusive license springer nature switzerland ag,big_data cloud_computing competition decision_making internet_of_things maintenance cloud computing cost increases decisions_makings digital_technologies industrial_revolutions industrial_sector maintenance_activity maintenance_optimization predictive_maintenance systematic_literature_review 722 3_data_communication _equipment_and_techniques 722 4_digital_computers_and_systems 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 911 2_industrial_economics 912 2_management 913 4_manufacturing 913 5_maintenance business_performance_metrics human_factors internet_of_things data manufacturing networks industry 4 0 era competitiveness industrial sector increasingly tough maintenance optimization undeniable tool stand fierce context minimize cost increase productivity improve quality facilitate decision making maintenance activity company resorting deployment digital technology fourth industrial revolution including internet thing iot big data additive manufacturing augmented reality ar cloud computing etc main goal paper ass impact industry 4 0 maintenance identify technology used company maintenance reason push company use tool benefit copy 2023 author exclusive license springer nature switzerland ag,industry 4 0 era competitiveness industrial sector increasingly tough maintenance optimization undeniable tool stand fierce context minimize cost increase productivity improve quality facilitate decision making maintenance activity company resorting deployment digital technology fourth industrial revolution including internet thing iot big data additive manufacturing augmented reality ar cloud computing etc main goal paper ass impact industry 4 0 maintenance identify technology used company maintenance reason push company use tool benefit copy 2023 author exclusive license springer nature switzerland agbig_data cloud_computing competition decision_making internet_of_things maintenancecloud computing cost increases decisions_makings digital_technologies industrial_revolutions industrial_sector maintenance_activity maintenance_optimization predictive_maintenance systematic_literature_review
316,Bringing AR/VR to everyday life - a wireless localization perspective,"Garg, N., Shahid, I., Sankar, K., Dasari, M., Sheshadri, R. K., Sundaresan, K., & Roy, N. (2023). Bringing AR/VR to Everyday Life - a Wireless Localization Perspective. Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications. https://doi.org/10.1145/3572864.3581589
",10.1145/3572864.3581589,"Augmented reality (AR) and virtual reality (VR) have the potential to revolutionize the way we interact with the environment around us. These technologies allow us to experience and collaborate with people in an immersive and intuitive way. Today, AR/VR is no longer limited to gaming and entertainment, rather it's blending into our everyday lives with applications in medical fields, education, grocery shopping, virtual try-ons etc. While a lot of progress has been made in visual rendering and scene understanding, little work is done on multi-user localization. To fully realize the potential of collaboration and multi-user applications, it is important to have an accurate and real-time 3D localization. Current 3D localization frameworks use cameras to create a relative coordinate system but these visual technologies struggle in low light conditions, and also require all devices to share an overlap of visual features which limit the applications to line-of-sight and room-level.We propose a new peer-to-peer localization framework that utilizes Ultra-Wideband (UWB) radio to create a wireless network of nodes and measure the range and angle-of-arrival (AoA) between them. A common approach to this problem is Multidimensional Scaling (MDS) [1], which involves formulating a least squares problem and minimizing the difference between measured distances and euclidean distances from estimated coordinates. However, this approach becomes challenging when the network topology is highly dynamic and reconfigurable, especially in real-time applications like AR/VR. To address this challenge, we developed a new algorithm that selects key edges to measure and incorporates angle information along with distance measurements.",B6250 Radio links and equipment;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality,accurate time 3D localization;angle-of-arrival;current 3D localization frameworks;distance measurements;entertainment;estimated coordinates;euclidean distances;grocery shopping;line-of-sight;low light conditions;measured distances;medical fields;multiuser applications;multiuser localization;peer-to-peer localization framework;real-time 3D localization;real-time applications;relative coordinate system;room-level;scene understanding;squares problem;Ultra-Wideband radio;virtual reality;virtual try-ons;visual features;visual rendering;visual technologies struggle;wireless localization perspective,augmented reality;cameras;data visualisation;rendering (computer graphics);virtual reality,2023,Conference article (CA),HotMobile '23: Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications,"(1) Garg, N.; (1) Shahid, I.; (1) Sankar, K.; (2) Dasari, M.; (2) Sheshadri, R.K.; (3) Sundaresan, K.; (1) Roy, N.; ","(1) University of Maryland, Baltimore, College Park, Baltimore, MD, United States; (2) NEC Labs America, United States; (3) Georgia Institute of Technology, Atlanta, GA, United States; ",ACM,-1,"[""cameras"", ""data visualization"", ""rendering""]","[""cameras"", ""data visualization"", ""rendering""]",cameras;data visualization;rendering,graphics;data;input,technology,graphics;data;input,technology,cameras data_visualization rendering accurate_time_3d_localization angle of arrival current_3d_localization_frameworks distance_measurements entertainment estimated_coordinates euclidean_distances grocery_shopping line of sight low_light_conditions measured_distances medical_fields multiuser_applications multiuser_localization peer to peer_localization_framework real time_3d_localization real time_applications relative_coordinate_system room level scene_understanding squares_problem ultra wideband_radio virtual_reality virtual_try ons visual_features visual_rendering visual_technologies_struggle wireless_localization_perspective b6250_radio_links_and_equipment c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality graphics data input,cameras data_visualization rendering,accurate_time_3d_localization angle of arrival current_3d_localization_frameworks distance_measurements entertainment estimated_coordinates euclidean_distances grocery_shopping line of sight low_light_conditions measured_distances medical_fields multiuser_applications multiuser_localization peer to peer_localization_framework real time_3d_localization real time_applications relative_coordinate_system room level scene_understanding squares_problem ultra wideband_radio virtual_reality virtual_try ons visual_features visual_rendering visual_technologies_struggle wireless_localization_perspective,augmented reality ar virtual reality vr potential revolutionize way interact environment around u technology allow u experience collaborate people immersive intuitive way today ar vr longer limited gaming entertainment rather blending everyday life application medical field education grocery shopping virtual try ons etc lot progress made visual rendering scene understanding little work done multi user localization fully realize potential collaboration multi user application important accurate real time 3d localization current 3d localization framework use camera create relative coordinate system visual technology struggle low light condition also require device share overlap visual feature limit application line sight room level propose new peer peer localization framework utilizes ultra wideband uwb radio create wireless network node measure range angle arrival aoa common approach problem multidimensional scaling md 1 involves formulating least square problem minimizing difference measured distance euclidean distance estimated coordinate however approach becomes challenging network topology highly dynamic reconfigurable especially real time application like ar vr address challenge developed new algorithm selects key edge measure incorporates angle information along distance measurement,cameras data_visualization rendering accurate_time_3d_localization angle of arrival current_3d_localization_frameworks distance_measurements entertainment estimated_coordinates euclidean_distances grocery_shopping line of sight low_light_conditions measured_distances medical_fields multiuser_applications multiuser_localization peer to peer_localization_framework real time_3d_localization real time_applications relative_coordinate_system room level scene_understanding squares_problem ultra wideband_radio virtual_reality virtual_try ons visual_features visual_rendering visual_technologies_struggle wireless_localization_perspective b6250_radio_links_and_equipment c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality graphics data input augmented reality ar virtual reality vr potential revolutionize way interact environment around u technology allow u experience collaborate people immersive intuitive way today ar vr longer limited gaming entertainment rather blending everyday life application medical field education grocery shopping virtual try ons etc lot progress made visual rendering scene understanding little work done multi user localization fully realize potential collaboration multi user application important accurate real time 3d localization current 3d localization framework use camera create relative coordinate system visual technology struggle low light condition also require device share overlap visual feature limit application line sight room level propose new peer peer localization framework utilizes ultra wideband uwb radio create wireless network node measure range angle arrival aoa common approach problem multidimensional scaling md 1 involves formulating least square problem minimizing difference measured distance euclidean distance estimated coordinate however approach becomes challenging network topology highly dynamic reconfigurable especially real time application like ar vr address challenge developed new algorithm selects key edge measure incorporates angle information along distance measurement,augmented reality ar virtual reality vr potential revolutionize way interact environment around u technology allow u experience collaborate people immersive intuitive way today ar vr longer limited gaming entertainment rather blending everyday life application medical field education grocery shopping virtual try ons etc lot progress made visual rendering scene understanding little work done multi user localization fully realize potential collaboration multi user application important accurate real time 3d localization current 3d localization framework use camera create relative coordinate system visual technology struggle low light condition also require device share overlap visual feature limit application line sight room level propose new peer peer localization framework utilizes ultra wideband uwb radio create wireless network node measure range angle arrival aoa common approach problem multidimensional scaling md 1 involves formulating least square problem minimizing difference measured distance euclidean distance estimated coordinate however approach becomes challenging network topology highly dynamic reconfigurable especially real time application like ar vr address challenge developed new algorithm selects key edge measure incorporates angle information along distance measurementcameras data_visualization renderingaccurate_time_3d_localization angle of arrival current_3d_localization_frameworks distance_measurements entertainment estimated_coordinates euclidean_distances grocery_shopping line of sight low_light_conditions measured_distances medical_fields multiuser_applications multiuser_localization peer to peer_localization_framework real time_3d_localization real time_applications relative_coordinate_system room level scene_understanding squares_problem ultra wideband_radio virtual_reality virtual_try ons visual_features visual_rendering visual_technologies_struggle wireless_localization_perspective
317,Optimized silicon antennas for optical phased arrays,"Farheen, H., Strauch, A., Scheytt, J. C., Myroshnychenko, V., & Förstner, J. (2023). Optimized silicon antennas for optical phased arrays. Integrated Optics: Devices, Materials, and Technologies XXVII. https://doi.org/10.1117/12.2658716
",10.1117/12.2658716,"We demonstrate a large-scale two dimensional silicon-based optical phased array (OPA) composed of nanoantennas with circular gratings that are balanced in power and aligned in phase, required for producing desired radiation patterns in the far-field. The OPAs are numerically optimized to have an upward efficiency of up to 90%, targeting radiation concentration mainly in the field of view. We envision that our OPAs have the ability of generating complex holographic images, rendering them an attractive candidate for a wide range of applications like LiDAR sensors, optical trapping, optogenetic stimulation and augmented-reality displays. &copy; 2023 SPIE.","461.2 Biological Materials and Tissue Engineering;716 Telecommunication; Radar, Radio and Television;716.2 Radar Systems and Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;741.3 Optical Devices and Systems;761 Nanotechnology",Directivity;Field of views;Large-scales;Optical antennas;Optical phased arrays;Phased-arrays;Silicon antennas;Silicon photonics;Silicon-based;Two-dimensional,Antenna phased arrays;Augmented reality;Directional patterns (antenna);Nanoantennas;Optical radar;Radiation efficiency,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Farheen, H.; (1) Strauch, A.; (2) Scheytt, J.C.; (1) Myroshnychenko, V.; (1) F&ouml;rstner, J.; ","(1) Paderborn University, Theoretical Electrical Engineering, Warburger Str. 100, Paderborn; 33098, Germany; (2) Paderborn University, System and Circuit Technology, Fuerstenallee 11, Paderborn; 33102, Germany; ",SPIE,-1,"[""antenna phased arrays"", ""directional patterns"", ""nanoantennas"", ""optical radar"", ""radiation efficiency""]","[""antenna phased arrays"", ""directional patterns"", ""nanoantennas"", ""optical radar"", ""radiation efficiency""]",antenna phased arrays;directional patterns;nanoantennas;optical radar;radiation efficiency,other;optics;telecommunication;developers;human-computer interaction;geospatial;networks,other;displays;industries;end users and user experience;technology,other;optics;telecommunication;developers;human-computer interaction;geospatial;networks,other;displays;industries;end users and user experience;technology,antenna_phased_arrays directional_patterns nanoantennas optical_radar radiation_efficiency directivity field_of_views large scales optical_antennas optical_phased_arrays phased arrays silicon_antennas silicon_photonics silicon based two dimensional 461 2_biological_materials_and_tissue_engineering 716_telecommunication _radar _radio_and_television 716 2_radar_systems_and_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 761_nanotechnology other optics telecommunication developers human computer_interaction geospatial networks,antenna_phased_arrays directional_patterns nanoantennas optical_radar radiation_efficiency,directivity field_of_views large scales optical_antennas optical_phased_arrays phased arrays silicon_antennas silicon_photonics silicon based two dimensional,demonstrate large scale two dimensional silicon based optical phased array opa composed nanoantennas circular grating balanced power aligned phase required producing desired radiation pattern far field opas numerically optimized upward efficiency 90 targeting radiation concentration mainly field view envision opas ability generating complex holographic image rendering attractive candidate wide range application like lidar sensor optical trapping optogenetic stimulation augmented reality display copy 2023 spie,antenna_phased_arrays directional_patterns nanoantennas optical_radar radiation_efficiency directivity field_of_views large scales optical_antennas optical_phased_arrays phased arrays silicon_antennas silicon_photonics silicon based two dimensional 461 2_biological_materials_and_tissue_engineering 716_telecommunication _radar _radio_and_television 716 2_radar_systems_and_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 3_optical_devices_and_systems 761_nanotechnology other optics telecommunication developers human computer_interaction geospatial networks demonstrate large scale two dimensional silicon based optical phased array opa composed nanoantennas circular grating balanced power aligned phase required producing desired radiation pattern far field opas numerically optimized upward efficiency 90 targeting radiation concentration mainly field view envision opas ability generating complex holographic image rendering attractive candidate wide range application like lidar sensor optical trapping optogenetic stimulation augmented reality display copy 2023 spie,demonstrate large scale two dimensional silicon based optical phased array opa composed nanoantennas circular grating balanced power aligned phase required producing desired radiation pattern far field opas numerically optimized upward efficiency 90 targeting radiation concentration mainly field view envision opas ability generating complex holographic image rendering attractive candidate wide range application like lidar sensor optical trapping optogenetic stimulation augmented reality display copy 2023 spieantenna_phased_arrays directional_patterns nanoantennas optical_radar radiation_efficiencydirectivity field_of_views large scales optical_antennas optical_phased_arrays phased arrays silicon_antennas silicon_photonics silicon based two dimensional
318,Semantic-assisted Unified Network for Feature Point Extraction and Matching,"Ji, D., You, W., Chen, Y., Wang, G., & Li, S. (2022). Semantic-assisted Unified Network for Feature Point Extraction and Matching. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574433
",10.1145/3574131.3574433,"Feature point matching between two images is an essential part of 3D reconstruction, augmented reality, panorama stitching, etc. The quality of the initial feature point matching stage greatly affects the overall performance of a system. We present a unified feature point extraction-matching method, making use of semantic segmentation results to constrain feature point matching. To integrate high-level semantic information into feature points efficiently, we propose a unified feature point extraction and matching network, called SP-Net, which can detect feature points and generate feature descriptors simultaneously and perform feature point matching with accurate outcomes. Compared with previous works, our method can extract multi-scale context of the image, including shallow information and high-level semantic information of the local area, which is more stable when handling complex conditions such as changing illumination or large viewpoint. In evaluating the feature-matching benchmark, our method shows superior performance over the state-of-art method. As further validation, we propose SP-Net++ as an extension for 3D reconstruction. The experimental results show that our neural network can obtain accurate feature point positioning and robust feature matching to recover more cameras and get a well-shaped point cloud. Our semantic-assisted method can improve the stability of feature points as well as specific applicability for complex scenes.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130V Virtual reality",accurate feature point positioning;feature descriptors;feature points;feature-matching benchmark;high-level semantic information;initial feature point matching;matching network;robust feature matching;unified feature point extraction-matching method;well-shaped point cloud,augmented reality;feature extraction;image matching;image reconstruction;image segmentation,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Ji, D.; (1) You, W.; (2) Chen, Y.; (2) Wang, G.; (2) Li, S.; ","(1) Peking University, China; (2) Peking University, School of Computer Science, China; ",ACM,-1,"[""feature extraction"", ""image matching"", ""image reconstruction"", ""image segmentation""]","[""feature extraction"", ""image matching"", ""image reconstruction"", ""image segmentation""]",feature extraction;image matching;image reconstruction;image segmentation,construction;computer vision;chemical,technology;industries,construction;computer vision;chemical,technology;industries,feature_extraction image_matching image_reconstruction image_segmentation accurate_feature_point_positioning feature_descriptors feature_points feature matching_benchmark high level_semantic_information initial_feature_point_matching matching_network robust_feature_matching unified_feature_point_extraction matching_method well shaped_point_cloud b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision chemical,feature_extraction image_matching image_reconstruction image_segmentation,accurate_feature_point_positioning feature_descriptors feature_points feature matching_benchmark high level_semantic_information initial_feature_point_matching matching_network robust_feature_matching unified_feature_point_extraction matching_method well shaped_point_cloud,feature point matching two image essential part 3d reconstruction augmented reality panorama stitching etc quality initial feature point matching stage greatly affect overall performance system present unified feature point extraction matching method making use semantic segmentation result constrain feature point matching integrate high level semantic information feature point efficiently propose unified feature point extraction matching network called sp net detect feature point generate feature descriptor simultaneously perform feature point matching accurate outcome compared previous work method extract multi scale context image including shallow information high level semantic information local area stable handling complex condition changing illumination large viewpoint evaluating feature matching benchmark method show superior performance state art method validation propose sp net extension 3d reconstruction experimental result show neural network obtain accurate feature point positioning robust feature matching recover camera get well shaped point cloud semantic assisted method improve stability feature point well specific applicability complex scene,feature_extraction image_matching image_reconstruction image_segmentation accurate_feature_point_positioning feature_descriptors feature_points feature matching_benchmark high level_semantic_information initial_feature_point_matching matching_network robust_feature_matching unified_feature_point_extraction matching_method well shaped_point_cloud b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality construction computer_vision chemical feature point matching two image essential part 3d reconstruction augmented reality panorama stitching etc quality initial feature point matching stage greatly affect overall performance system present unified feature point extraction matching method making use semantic segmentation result constrain feature point matching integrate high level semantic information feature point efficiently propose unified feature point extraction matching network called sp net detect feature point generate feature descriptor simultaneously perform feature point matching accurate outcome compared previous work method extract multi scale context image including shallow information high level semantic information local area stable handling complex condition changing illumination large viewpoint evaluating feature matching benchmark method show superior performance state art method validation propose sp net extension 3d reconstruction experimental result show neural network obtain accurate feature point positioning robust feature matching recover camera get well shaped point cloud semantic assisted method improve stability feature point well specific applicability complex scene,feature point matching two image essential part 3d reconstruction augmented reality panorama stitching etc quality initial feature point matching stage greatly affect overall performance system present unified feature point extraction matching method making use semantic segmentation result constrain feature point matching integrate high level semantic information feature point efficiently propose unified feature point extraction matching network called sp net detect feature point generate feature descriptor simultaneously perform feature point matching accurate outcome compared previous work method extract multi scale context image including shallow information high level semantic information local area stable handling complex condition changing illumination large viewpoint evaluating feature matching benchmark method show superior performance state art method validation propose sp net extension 3d reconstruction experimental result show neural network obtain accurate feature point positioning robust feature matching recover camera get well shaped point cloud semantic assisted method improve stability feature point well specific applicability complex scenefeature_extraction image_matching image_reconstruction image_segmentationaccurate_feature_point_positioning feature_descriptors feature_points feature matching_benchmark high level_semantic_information initial_feature_point_matching matching_network robust_feature_matching unified_feature_point_extraction matching_method well shaped_point_cloud
319,Here and Now: Creating Improvisational Dance Movements with a Mixed Reality Mirror,"Zhou, Q., Grebel, L., Irlitti, A., Minaai, J. A., Goncalves, J., & Velloso, E. (2023). Here and Now: Creating Improvisational Dance Movements with a Mixed Reality Mirror. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580666
",10.1145/3544548.3580666,"This paper explores using mixed reality (MR) mirrors for supporting improvisational dance making. Motivated by the prevalence of mirrors in dance studios and inspired by Forsythe's Improvisation Technologies, we conducted workshops with 13 dancers and choreographers to inform the design of future MR visualisation and annotation tools for dance. The workshops involved using a prototype MR mirror as a technology probe that reveals the spatial and temporal relationships between the reflected dancing body and its surroundings during improvisation; speed dating group interviews around future design ideas; follow-up surveys and extended interviews with a digital media dance artist and a dance educator. Our findings highlight how the MR mirror enriches dancers' temporal and spatial perception, creates multi-layered presence, and affords appropriation by dancers. We also discuss the unique place of MR mirrors in the theoretical context of dance and in the history of movement visualisation, and distil lessons for broader HCI research.",C7820 Humanities computing;C6130V Virtual reality;C6180 User interfaces,annotation tools;dance educator;dance studios;dancer spatial perception;dancer temporal perception;digital media dance artist;Forsythe improvisation technologies;HCI research;improvisational dance making;improvisational dance movements;mixed reality mirror;movement visualisation;multilayered presence;prototype MR mirror;reflected dancing body;speed dating group interviews;technology probe,augmented reality;human computer interaction;humanities,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Zhou, Q.; (2) Grebel, L.; (1) Irlitti, A.; (3) Minaai, J.A.; (1) Goncalves, J.; (1) Velloso, E.; ","(1) University of Melbourne, School of Computing and Information Systems, Melbourne, VIC, Australia; (2) Universite Paris-Saclay, France; (3) University of Melbourne, Faculty of Fine Arts and Music, Melbourne, VIC, Australia; ",ACM,-1,"[""human computer interaction"", ""humanities""]","[""human computer interaction"", ""humanities""]",human computer interaction;humanities,liberal arts;human-computer interaction,industries;end users and user experience,liberal arts;human-computer interaction,industries;end users and user experience,human_computer_interaction humanities annotation_tools dance_educator dance_studios dancer_spatial_perception dancer_temporal_perception digital_media_dance_artist forsythe_improvisation_technologies hci_research improvisational_dance_making improvisational_dance_movements mixed_reality_mirror movement_visualisation multilayered_presence prototype_mr_mirror reflected_dancing_body speed_dating_group_interviews technology_probe c7820_humanities_computing c6130v_virtual_reality c6180_user_interfaces liberal_arts human computer_interaction,human_computer_interaction humanities,annotation_tools dance_educator dance_studios dancer_spatial_perception dancer_temporal_perception digital_media_dance_artist forsythe_improvisation_technologies hci_research improvisational_dance_making improvisational_dance_movements mixed_reality_mirror movement_visualisation multilayered_presence prototype_mr_mirror reflected_dancing_body speed_dating_group_interviews technology_probe,paper explores using mixed reality mr mirror supporting improvisational dance making motivated prevalence mirror dance studio inspired forsythe improvisation technology conducted workshop 13 dancer choreographer inform design future mr visualisation annotation tool dance workshop involved using prototype mr mirror technology probe reveals spatial temporal relationship reflected dancing body surroundings improvisation speed dating group interview around future design idea follow survey extended interview digital medium dance artist dance educator finding highlight mr mirror enriches dancer temporal spatial perception creates multi layered presence affords appropriation dancer also discus unique place mr mirror theoretical context dance history movement visualisation distil lesson broader hci research,human_computer_interaction humanities annotation_tools dance_educator dance_studios dancer_spatial_perception dancer_temporal_perception digital_media_dance_artist forsythe_improvisation_technologies hci_research improvisational_dance_making improvisational_dance_movements mixed_reality_mirror movement_visualisation multilayered_presence prototype_mr_mirror reflected_dancing_body speed_dating_group_interviews technology_probe c7820_humanities_computing c6130v_virtual_reality c6180_user_interfaces liberal_arts human computer_interaction paper explores using mixed reality mr mirror supporting improvisational dance making motivated prevalence mirror dance studio inspired forsythe improvisation technology conducted workshop 13 dancer choreographer inform design future mr visualisation annotation tool dance workshop involved using prototype mr mirror technology probe reveals spatial temporal relationship reflected dancing body surroundings improvisation speed dating group interview around future design idea follow survey extended interview digital medium dance artist dance educator finding highlight mr mirror enriches dancer temporal spatial perception creates multi layered presence affords appropriation dancer also discus unique place mr mirror theoretical context dance history movement visualisation distil lesson broader hci research,paper explores using mixed reality mr mirror supporting improvisational dance making motivated prevalence mirror dance studio inspired forsythe improvisation technology conducted workshop 13 dancer choreographer inform design future mr visualisation annotation tool dance workshop involved using prototype mr mirror technology probe reveals spatial temporal relationship reflected dancing body surroundings improvisation speed dating group interview around future design idea follow survey extended interview digital medium dance artist dance educator finding highlight mr mirror enriches dancer temporal spatial perception creates multi layered presence affords appropriation dancer also discus unique place mr mirror theoretical context dance history movement visualisation distil lesson broader hci researchhuman_computer_interaction humanitiesannotation_tools dance_educator dance_studios dancer_spatial_perception dancer_temporal_perception digital_media_dance_artist forsythe_improvisation_technologies hci_research improvisational_dance_making improvisational_dance_movements mixed_reality_mirror movement_visualisation multilayered_presence prototype_mr_mirror reflected_dancing_body speed_dating_group_interviews technology_probe
320,The Effects of Mobile Technology on Learning Performance and Motivation in Mathematics Education,"Poçan, S., Altay, B., & Yaşaroğlu, C. (2022). The Effects of Mobile Technology on Learning Performance and Motivation in Mathematics Education. Education and Information Technologies, 28(1), 683–712. https://doi.org/10.1007/s10639-022-11166-6
",10.1007/s10639-022-11166-6,"Due to rapid developments, mobile technologies started to play an essential role in designing seamless learning environments. Due to the availability of mobile technologies, students can access learning materials without being bound by time and place. On the grounds that these applications allow information exchange, time and space limitations such as classrooms or school bells have been eliminated. Therefore, this study aims to assess mobile-assisted seamless learning environments' effects on students' success and motivation in the secondary school 7th grade mathematics class algebra unit and student opinions about the application. The research is designed using the descriptive pattern of mixed-method research. The sample of the study is 73 middle school students (30 male and 43 female) in Turkey. Augmented Reality (AR) applications developed in teaching algebra to support individual learning and to utilize mobile technologies, WhatsApp groups were created. Algebra Achievement Test (AAT), Mathematics Motivation Scale (MMS), and semi-structured interview forms were used as data collection tools in the research. The results of the study showed that there were statistically significant differences in favor of the experiment group in AAT and MMS scores. However, no significant difference was found between the groups in intrinsic goal orientation and test anxiety scores, which are motivation sub-dimensions. The findings obtained from AAT, MMS, and the students' opinions showed that mobile technology applications used in out-of-school learning environments positively affect the learning process.","C7810C Computer-aided instruction;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",73 middle school students;individual learning;learning materials;learning process;Mathematics education;Mathematics Motivation Scale;mobile technology applications;out-of-school learning environments;seamless learning environments;secondary school 7th grade mathematics class algebra unit;space limitations;student opinions,augmented reality;computer aided instruction;educational institutions;human factors;mobile learning;teaching,2023,Journal article (JA),Educ. Inf. Technol. (Germany),"(1) Poc&#807;an, S.; (2) Altay, B.; (2) Yas&#807;arog&#774;lu, C.; ","(1) Bingo&#776;l University, Genc&#807; Vocational School, Turkey; (2) Inonu University, Faculty of Education, Turkey; ",Springer,-1,"[""computer aided instruction"", ""educational institutions"", ""human factors"", ""mobile learning"", ""teaching""]","[""computer aided instruction"", ""educational institutions"", ""human factors"", ""mobile learning"", ""teaching""]",computer aided instruction;educational institutions;human factors;mobile learning;teaching,medical;human factors;education;training,end users and user experience;use cases;industries,medical;human factors;education;training,end users and user experience;use cases;industries,computer_aided_instruction educational_institutions human_factors mobile_learning teaching 73_middle_school_students individual_learning learning_materials learning_process mathematics_education mathematics_motivation_scale mobile_technology_applications out of school_learning_environments seamless_learning_environments secondary_school_7th_grade_mathematics_class_algebra_unit space_limitations student_opinions c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing medical human_factors education training,computer_aided_instruction educational_institutions human_factors mobile_learning teaching,73_middle_school_students individual_learning learning_materials learning_process mathematics_education mathematics_motivation_scale mobile_technology_applications out of school_learning_environments seamless_learning_environments secondary_school_7th_grade_mathematics_class_algebra_unit space_limitations student_opinions,due rapid development mobile technology started play essential role designing seamless learning environment due availability mobile technology student access learning material without bound time place ground application allow information exchange time space limitation classroom school bell eliminated therefore study aim ass mobile assisted seamless learning environment effect student success motivation secondary school 7th grade mathematics class algebra unit student opinion application research designed using descriptive pattern mixed method research sample study 73 middle school student 30 male 43 female turkey augmented reality ar application developed teaching algebra support individual learning utilize mobile technology whatsapp group created algebra achievement test aat mathematics motivation scale mm semi structured interview form used data collection tool research result study showed statistically significant difference favor experiment group aat mm score however significant difference found group intrinsic goal orientation test anxiety score motivation sub dimension finding obtained aat mm student opinion showed mobile technology application used school learning environment positively affect learning process,computer_aided_instruction educational_institutions human_factors mobile_learning teaching 73_middle_school_students individual_learning learning_materials learning_process mathematics_education mathematics_motivation_scale mobile_technology_applications out of school_learning_environments seamless_learning_environments secondary_school_7th_grade_mathematics_class_algebra_unit space_limitations student_opinions c7810c_computer aided_instruction c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing medical human_factors education training due rapid development mobile technology started play essential role designing seamless learning environment due availability mobile technology student access learning material without bound time place ground application allow information exchange time space limitation classroom school bell eliminated therefore study aim ass mobile assisted seamless learning environment effect student success motivation secondary school 7th grade mathematics class algebra unit student opinion application research designed using descriptive pattern mixed method research sample study 73 middle school student 30 male 43 female turkey augmented reality ar application developed teaching algebra support individual learning utilize mobile technology whatsapp group created algebra achievement test aat mathematics motivation scale mm semi structured interview form used data collection tool research result study showed statistically significant difference favor experiment group aat mm score however significant difference found group intrinsic goal orientation test anxiety score motivation sub dimension finding obtained aat mm student opinion showed mobile technology application used school learning environment positively affect learning process,due rapid development mobile technology started play essential role designing seamless learning environment due availability mobile technology student access learning material without bound time place ground application allow information exchange time space limitation classroom school bell eliminated therefore study aim ass mobile assisted seamless learning environment effect student success motivation secondary school 7th grade mathematics class algebra unit student opinion application research designed using descriptive pattern mixed method research sample study 73 middle school student 30 male 43 female turkey augmented reality ar application developed teaching algebra support individual learning utilize mobile technology whatsapp group created algebra achievement test aat mathematics motivation scale mm semi structured interview form used data collection tool research result study showed statistically significant difference favor experiment group aat mm score however significant difference found group intrinsic goal orientation test anxiety score motivation sub dimension finding obtained aat mm student opinion showed mobile technology application used school learning environment positively affect learning processcomputer_aided_instruction educational_institutions human_factors mobile_learning teaching73_middle_school_students individual_learning learning_materials learning_process mathematics_education mathematics_motivation_scale mobile_technology_applications out of school_learning_environments seamless_learning_environments secondary_school_7th_grade_mathematics_class_algebra_unit space_limitations student_opinions
321,"A unified framework for automated registration of point clouds, mesh surfaces and 3D models by using planar surfaces","Zhao, Y., Zhao, H., Radanovic, M., & Khoshelham, K. (2022). A unified framework for automated registration of point clouds, mesh surfaces and <scp>3D</scp> models by using planar surfaces. The Photogrammetric Record, 37(180), 366–384. Portico. https://doi.org/10.1111/phor.12428
",10.1111/phor.12428,"Registration of 3D spatial data and models is a fundamental task in applications such as mapping, positioning and virtual/augmented reality. Most of the existing 3D registration methods such as iterative closest point (ICP) and recent learning-based methods are dedicated to point cloud registration, and rely heavily on point-wise correspondences, which limits their ability to address registration problems across different data types. Since man-made objects and buildings usually contain many planar surfaces, it is possible to use the planes for accurate registration of different data and models. In this paper, a unified registration framework is proposed consisting of a plane extraction module, which can extract planes from various forms of spatial data such as point clouds or surface-based 3D models, and a registration module, which performs automatic registration based on the extracted planes. Tests show that the proposed method can handle small-overlap registration across all these data types with high success rates. The result of point cloud registration also indicates that the method achieves better accuracy as compared to ICP.&lt;i&gt;The Photogrammetric Record&lt;/i&gt;&#169; 2022 The Remote Sensing and Photogrammetry Society and John Wiley &amp; Sons Ltd.","B6135 Optical, image and video signal processing;C4130 Interpolation and function approximation (numerical analysis);C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C7330 Biology and medical computing",automated registration;automatic registration;existing 3D registration methods;extracted planes;iterative closest point;mesh surfaces;planar surfaces;plane extraction module;point cloud registration;point clouds;point-wise correspondences;recent learning-based methods;registration module;registration problems;small-overlap registration;spatial data;surface-based 3D models;unified registration framework;virtual,augmented reality;image registration;iterative methods;photogrammetry;remote sensing;solid modelling,2022,Journal article (JA),Photogramm. Rec. (USA),"(1) Yuan Zhao; (1) Hang Zhao; (1) Radanovic, M.; (1) Khoshelham, K.; ","(1) University of Melbourne, Department of Infrastructure Engineering, Carlton, VIC, Australia; ",Wiley,-1,"[""image registration"", ""iterative methods"", ""photogrammetry"", ""remote sensing"", ""solid modelling""]","[""image registration"", ""iterative methods"", ""photogrammetry"", ""remote sensing"", ""solid modelling""]",image registration;iterative methods;photogrammetry;remote sensing;solid modelling,computer vision;manufacturing;artificial intelligence;sensors,technology;industries,computer vision;manufacturing;artificial intelligence;sensors,technology;industries,image_registration iterative_methods photogrammetry remote_sensing solid_modelling automated_registration automatic_registration existing_3d_registration_methods extracted_planes iterative_closest_point mesh_surfaces planar_surfaces plane_extraction_module point_cloud_registration point_clouds point wise_correspondences recent_learning based_methods registration_module registration_problems small overlap_registration spatial_data surface based_3d_models unified_registration_framework virtual b6135_optical _image_and_video_signal_processing c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision manufacturing artificial_intelligence sensors,image_registration iterative_methods photogrammetry remote_sensing solid_modelling,automated_registration automatic_registration existing_3d_registration_methods extracted_planes iterative_closest_point mesh_surfaces planar_surfaces plane_extraction_module point_cloud_registration point_clouds point wise_correspondences recent_learning based_methods registration_module registration_problems small overlap_registration spatial_data surface based_3d_models unified_registration_framework virtual,registration 3d spatial data model fundamental task application mapping positioning virtual augmented reality existing 3d registration method iterative closest point icp recent learning based method dedicated point cloud registration rely heavily point wise correspondence limit ability address registration problem across different data type since man made object building usually contain many planar surface possible use plane accurate registration different data model paper unified registration framework proposed consisting plane extraction module extract plane various form spatial data point cloud surface based 3d model registration module performs automatic registration based extracted plane test show proposed method handle small overlap registration across data type high success rate result point cloud registration also indicates method achieves better accuracy compared icp lt gt photogrammetric record lt gt 169 2022 remote sensing photogrammetry society john wiley amp son ltd,image_registration iterative_methods photogrammetry remote_sensing solid_modelling automated_registration automatic_registration existing_3d_registration_methods extracted_planes iterative_closest_point mesh_surfaces planar_surfaces plane_extraction_module point_cloud_registration point_clouds point wise_correspondences recent_learning based_methods registration_module registration_problems small overlap_registration spatial_data surface based_3d_models unified_registration_framework virtual b6135_optical _image_and_video_signal_processing c4130_interpolation_and_function_approximation_ numerical_analysis c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision manufacturing artificial_intelligence sensors registration 3d spatial data model fundamental task application mapping positioning virtual augmented reality existing 3d registration method iterative closest point icp recent learning based method dedicated point cloud registration rely heavily point wise correspondence limit ability address registration problem across different data type since man made object building usually contain many planar surface possible use plane accurate registration different data model paper unified registration framework proposed consisting plane extraction module extract plane various form spatial data point cloud surface based 3d model registration module performs automatic registration based extracted plane test show proposed method handle small overlap registration across data type high success rate result point cloud registration also indicates method achieves better accuracy compared icp lt gt photogrammetric record lt gt 169 2022 remote sensing photogrammetry society john wiley amp son ltd,registration 3d spatial data model fundamental task application mapping positioning virtual augmented reality existing 3d registration method iterative closest point icp recent learning based method dedicated point cloud registration rely heavily point wise correspondence limit ability address registration problem across different data type since man made object building usually contain many planar surface possible use plane accurate registration different data model paper unified registration framework proposed consisting plane extraction module extract plane various form spatial data point cloud surface based 3d model registration module performs automatic registration based extracted plane test show proposed method handle small overlap registration across data type high success rate result point cloud registration also indicates method achieves better accuracy compared icp lt gt photogrammetric record lt gt 169 2022 remote sensing photogrammetry society john wiley amp son ltdimage_registration iterative_methods photogrammetry remote_sensing solid_modellingautomated_registration automatic_registration existing_3d_registration_methods extracted_planes iterative_closest_point mesh_surfaces planar_surfaces plane_extraction_module point_cloud_registration point_clouds point wise_correspondences recent_learning based_methods registration_module registration_problems small overlap_registration spatial_data surface based_3d_models unified_registration_framework virtual
322,Research on problems and countermeasures in the application of substation intelligent inspection system,"Zhao, M., Mao, Y., Hen, Q., & Zhou, Y. (2021). Research on problems and countermeasures in the application of substation intelligent inspection system. Journal of Physics: Conference Series, 1983(1), 012084. https://doi.org/10.1088/1742-6596/1983/1/012084
",10.1088/1742-6596/1983/1/012084,"Substation plays an important role in the power system as the pivot of the power grid. With the continuous expansion of the power grid, the intelligent inspection system based on robots is widely used in the substation industry. However, the existing inspection robot has some drawbacks, such as low battery capacity, weak obstacle performance, slow movement speed, and blind areas during the inspection. This paper proposed some measurements aimed at these drawbacks, such as optimizing the robot performance, adding the image acquisition PTZ (Pan, Tilt, and Zoom camera) in fixed point, using the AR (Augmented Reality) glasses assistance. These approaches improve the efficiency and quality of the existing intelligent inspection system in the substation.",B8375 Substations;B0170L Inspection and quality control;C3390C Mobile robots;C6130V Virtual reality;C7410B Power engineering computing;C7420 Control engineering computing,continuous expansion;existing inspection robot;existing intelligent inspection system;low battery capacity;power grid;power system;robot performance;slow movement speed;substation industry;substation intelligent inspection system;weak obstacle performance,augmented reality;cameras;inspection;mobile robots;power grids;substations,2021,Conference article (CA),"J. Phys., Conf. Ser. (UK)","(1) Zhao, M.; (1) Mao, Y.; (1) Hen, Q.; (1) Zhou, Y.; ","(1) State Grid Shanghai Electric Power Company Maintenance Company, 600 Wuning Road, China; ",IOP Publishing,-1,"[""cameras"", ""inspection"", ""mobile robots"", ""power grids"", ""substations""]","[""cameras"", ""inspection"", ""mobile robots"", ""power grids"", ""substations""]",cameras;inspection;mobile robots;power grids;substations,"inspection, safety and quality;robotics;input;power and energy",technology;use cases;industries,"inspection, safety and quality;robotics;input;power and energy",technology;use cases;industries,cameras inspection mobile_robots power_grids substations continuous_expansion existing_inspection_robot existing_intelligent_inspection_system low_battery_capacity power_grid power_system robot_performance slow_movement_speed substation_industry substation_intelligent_inspection_system weak_obstacle_performance b8375_substations b0170l_inspection_and_quality_control c3390c_mobile_robots c6130v_virtual_reality c7410b_power_engineering_computing c7420_control_engineering_computing inspection _safety_and_quality robotics input power_and_energy,cameras inspection mobile_robots power_grids substations,continuous_expansion existing_inspection_robot existing_intelligent_inspection_system low_battery_capacity power_grid power_system robot_performance slow_movement_speed substation_industry substation_intelligent_inspection_system weak_obstacle_performance,substation play important role power system pivot power grid continuous expansion power grid intelligent inspection system based robot widely used substation industry however existing inspection robot drawback low battery capacity weak obstacle performance slow movement speed blind area inspection paper proposed measurement aimed drawback optimizing robot performance adding image acquisition ptz pan tilt zoom camera fixed point using ar augmented reality glass assistance approach improve efficiency quality existing intelligent inspection system substation,cameras inspection mobile_robots power_grids substations continuous_expansion existing_inspection_robot existing_intelligent_inspection_system low_battery_capacity power_grid power_system robot_performance slow_movement_speed substation_industry substation_intelligent_inspection_system weak_obstacle_performance b8375_substations b0170l_inspection_and_quality_control c3390c_mobile_robots c6130v_virtual_reality c7410b_power_engineering_computing c7420_control_engineering_computing inspection _safety_and_quality robotics input power_and_energy substation play important role power system pivot power grid continuous expansion power grid intelligent inspection system based robot widely used substation industry however existing inspection robot drawback low battery capacity weak obstacle performance slow movement speed blind area inspection paper proposed measurement aimed drawback optimizing robot performance adding image acquisition ptz pan tilt zoom camera fixed point using ar augmented reality glass assistance approach improve efficiency quality existing intelligent inspection system substation,substation play important role power system pivot power grid continuous expansion power grid intelligent inspection system based robot widely used substation industry however existing inspection robot drawback low battery capacity weak obstacle performance slow movement speed blind area inspection paper proposed measurement aimed drawback optimizing robot performance adding image acquisition ptz pan tilt zoom camera fixed point using ar augmented reality glass assistance approach improve efficiency quality existing intelligent inspection system substationcameras inspection mobile_robots power_grids substationscontinuous_expansion existing_inspection_robot existing_intelligent_inspection_system low_battery_capacity power_grid power_system robot_performance slow_movement_speed substation_industry substation_intelligent_inspection_system weak_obstacle_performance
323,Feature-aggregated spatiotemporal spine surface estimation for wearable patch ultrasound volumetric imaging,"Jiang, B., Xu, K., Moghekar, A., Kazanzides, P., & Boctor, E. M. (2023). Feature-aggregated spatiotemporal spine surface estimation for wearable patch ultrasound volumetric imaging. Medical Imaging 2023: Ultrasonic Imaging and Tomography. https://doi.org/10.1117/12.2653114
",10.1117/12.2653114,"Clear identification of bone structures is crucial for ultrasound-guided lumbar interventions, but it can be challenging due to the complex shapes of the self-shadowing vertebra anatomy and the extensive background speckle noise from the surrounding soft tissue structures. Therefore, in this work, we will present our method for estimating the vertebra bone surfaces by using a spatiotemporal U-Net architecture learning from the B-Mode image and aggregated feature maps of hand-crafted filters. Additionally, we are integrating this solution with our patch-like wearable ultrasound system to capture the repeating anatomical patterns and image the bone surfaces from multiple insonification angles. 3D bone representations can then be created for interventional guidance. The methods are evaluated on spine phantom image data collected by our proposed ""Patch"" scanner, and our systematic ablation experiment shows that improved accuracy can be achieved with the proposed architecture. Equipped with this surface estimation network, our wearable ultrasound system can potentially provide intuitive and accurate interventional guidance for clinicians in an augmented reality setting. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.4 Ergonomics and Human Factors Engineering;723 Computer Software, Data Handling and Applications;746 Imaging Techniques;753.1 Ultrasonic Waves",Bone surface;Bone surface estimation;Deep learning;Interventional;Lumbar puncture;Surface estimation;Ultrasound system;Volume reconstruction;Volumetric Imaging;Wearable ultrasound,Augmented reality;Deep learning;Image enhancement;Image reconstruction;Medical imaging;Network architecture;Wearable technology,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Jiang, Baichuan; (1) Xu, Keshuai; (2) Moghekar, Ahbay; (1) Kazanzides, Peter; (1) Boctor, Emad; ","(1) Department of Computer Science, Johns Hopkins University, Baltimore, United States; (2) Department of Neurology, Johns Hopkins Medical Institute, Baltimore, United States; ",SPIE,-1,"[""deep learning"", ""image enhancement"", ""image reconstruction"", ""medical imaging"", ""network architecture"", ""wearable technology""]","[""deep learning"", ""image enhancement"", ""image reconstruction"", ""medical imaging"", ""network architecture"", ""wearable technology""]",deep learning;image enhancement;image reconstruction;medical imaging;network architecture;wearable technology,"construction;computer vision;medical;inspection, safety and quality;wearables;human-computer interaction;artificial intelligence;networks",displays;end users and user experience;industries;use cases;technology,"construction;computer vision;medical;inspection, safety and quality;wearables;human-computer interaction;artificial intelligence;networks",displays;end users and user experience;industries;use cases;technology,deep_learning image_enhancement image_reconstruction medical_imaging network_architecture wearable_technology bone_surface bone_surface_estimation deep_learning interventional lumbar_puncture surface_estimation ultrasound_system volume_reconstruction volumetric_imaging wearable_ultrasound 461 1_biomedical_engineering 461 4_ergonomics_and_human_factors_engineering 723_computer_software _data_handling_and_applications 746_imaging_techniques 753 1_ultrasonic_waves construction computer_vision medical inspection _safety_and_quality wearables human computer_interaction artificial_intelligence networks,deep_learning image_enhancement image_reconstruction medical_imaging network_architecture wearable_technology,bone_surface bone_surface_estimation deep_learning interventional lumbar_puncture surface_estimation ultrasound_system volume_reconstruction volumetric_imaging wearable_ultrasound,clear identification bone structure crucial ultrasound guided lumbar intervention challenging due complex shape self shadowing vertebra anatomy extensive background speckle noise surrounding soft tissue structure therefore work present method estimating vertebra bone surface using spatiotemporal u net architecture learning b mode image aggregated feature map hand crafted filter additionally integrating solution patch like wearable ultrasound system capture repeating anatomical pattern image bone surface multiple insonification angle 3d bone representation created interventional guidance method evaluated spine phantom image data collected proposed patch scanner systematic ablation experiment show improved accuracy achieved proposed architecture equipped surface estimation network wearable ultrasound system potentially provide intuitive accurate interventional guidance clinician augmented reality setting copy 2023 spie,deep_learning image_enhancement image_reconstruction medical_imaging network_architecture wearable_technology bone_surface bone_surface_estimation deep_learning interventional lumbar_puncture surface_estimation ultrasound_system volume_reconstruction volumetric_imaging wearable_ultrasound 461 1_biomedical_engineering 461 4_ergonomics_and_human_factors_engineering 723_computer_software _data_handling_and_applications 746_imaging_techniques 753 1_ultrasonic_waves construction computer_vision medical inspection _safety_and_quality wearables human computer_interaction artificial_intelligence networks clear identification bone structure crucial ultrasound guided lumbar intervention challenging due complex shape self shadowing vertebra anatomy extensive background speckle noise surrounding soft tissue structure therefore work present method estimating vertebra bone surface using spatiotemporal u net architecture learning b mode image aggregated feature map hand crafted filter additionally integrating solution patch like wearable ultrasound system capture repeating anatomical pattern image bone surface multiple insonification angle 3d bone representation created interventional guidance method evaluated spine phantom image data collected proposed patch scanner systematic ablation experiment show improved accuracy achieved proposed architecture equipped surface estimation network wearable ultrasound system potentially provide intuitive accurate interventional guidance clinician augmented reality setting copy 2023 spie,clear identification bone structure crucial ultrasound guided lumbar intervention challenging due complex shape self shadowing vertebra anatomy extensive background speckle noise surrounding soft tissue structure therefore work present method estimating vertebra bone surface using spatiotemporal u net architecture learning b mode image aggregated feature map hand crafted filter additionally integrating solution patch like wearable ultrasound system capture repeating anatomical pattern image bone surface multiple insonification angle 3d bone representation created interventional guidance method evaluated spine phantom image data collected proposed patch scanner systematic ablation experiment show improved accuracy achieved proposed architecture equipped surface estimation network wearable ultrasound system potentially provide intuitive accurate interventional guidance clinician augmented reality setting copy 2023 spiedeep_learning image_enhancement image_reconstruction medical_imaging network_architecture wearable_technologybone_surface bone_surface_estimation deep_learning interventional lumbar_puncture surface_estimation ultrasound_system volume_reconstruction volumetric_imaging wearable_ultrasound
324,Efficient piezoelectric gimbal-less MEMS-mirror with large design flexibility,"Wysocki, L., Ratzmann, L., Schütt, P., Albers, J., Wille, G., & Gu-Stoppel, S. (2023). Efficient piezoelectric gimbal-less MEMS-mirror with large design flexibility. MOEMS and Miniaturized Systems XXII. https://doi.org/10.1117/12.2647807
",10.1117/12.2647807,"Biaxial resonant MEMS-scanners are considered as promising core-device in state-of-the-art imaging and projection systems due to their compactness, the large field-of-view, high speed, and comparably low power consumption. However, the usage in three-dimensional LIDAR modules or projectors for industrial applications is often limited by non-optimal Lissajous-scanning patterns. To achieve dense and spatially uniform Lissajous-trajectories, a suitable frequency ratio of the two oscillation modes is essential. In previous works, the frequency ratio was either maximized or minimized, which often led either to mechanical fragility or undesirable coupling of the two normal modes. For solving the abovementioned problems, a piezoelectrically-driven biaxial MEMS-scanner exhibiting large design flexibility, enabling the individual tailoring of the two orthogonal rotational oscillation-modes and Lissajous-patterns with large fill factor, was developed. This design freedom and decoupling of two axes motions are achieved by a gimbal-less design with individual actuator systems for the two oscillatory axes. Driven by the CMOS-compatible piezoelectric Al(Sc)N, the Q-factor of the resonant mirror with large optical aperture of 5 mm is enhanced by hermetic wafer-level glass-encapsulation. A projection module, which combines the biaxial MEMS-scanner, an RGB-laser-beam combiner, and the electronics for both read-out and control, was developed in the frame of a funded research project (""MEMS-scanner-based laser projection system for maritime augmented reality""). The target of the project was the development of a smart window, in the sense of a MEMS-scanner-based laser projection system for maritime augmented reality, which offers the possibility to fade in safety-relevant information of navigation and ship sensors into the field-of-view of the bridge personnel on the ship&rsquo;s bridge. Such projector is promising also for further applications in industry, for instance in 3D cameras. &copy; 2023 SPIE.",401.1 Bridges;701.1 Electricity: Basic Concepts and Phenomena;704.2 Electric Equipment;716.2 Radar Systems and Equipment;741.3 Optical Devices and Systems;742.2 Photographic Equipment;744.7 Laser Components;744.8 Laser Beam Interactions;942.2 Electric Variables Measurements,2d resonant MEMS mirror;Design flexibility;Frequency ratios;Large designs;Lissajous;MEMS mirrors;MEMS scanner;Oscillation mode;Piezoelectric;Projection system for maritime augmented reality,Bridges;Cameras;Laser mirrors;MEMS;Optical radar;Piezoelectricity;Q factor measurement;Ships,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Wysocki, L.; (1) Ratzmann, L.; (1) Sch&uuml;tt, P.; (1) Albers, J.; (1) Wille, G.; (1) Gu-Stoppel, S.; ","(1) Fraunhofer Institute for Silicon Technology, Fraunhoferstrasse 1, Itzehoe; 25524, Germany; ",SPIE,-1,"[""bridges"", ""cameras"", ""laser mirrors"", ""mems"", ""optical radar"", ""piezoelectricity"", ""q factor measurement"", ""ships""]","[""bridges"", ""cameras"", ""laser mirrors"", ""mems"", ""optical radar"", ""piezoelectricity"", ""q factor measurement"", ""ships""]",bridges;cameras;laser mirrors;mems;optical radar;piezoelectricity;q factor measurement;ships,"other;input;transportation;optics;inspection, safety and quality;government;developers;geospatial;semiconductors",other;displays;industries;use cases;technology,"other;input;transportation;optics;inspection, safety and quality;government;developers;geospatial;semiconductors",other;displays;industries;use cases;technology,bridges cameras laser_mirrors mems optical_radar piezoelectricity q_factor_measurement ships 2d_resonant_mems_mirror design_flexibility frequency_ratios large_designs lissajous mems_mirrors mems_scanner oscillation_mode piezoelectric projection_system_for_maritime_augmented_reality 401 1_bridges 701 1_electricity _basic_concepts_and_phenomena 704 2_electric_equipment 716 2_radar_systems_and_equipment 741 3_optical_devices_and_systems 742 2_photographic_equipment 744 7_laser_components 744 8_laser_beam_interactions 942 2_electric_variables_measurements other input transportation optics inspection _safety_and_quality government developers geospatial semiconductors,bridges cameras laser_mirrors mems optical_radar piezoelectricity q_factor_measurement ships,2d_resonant_mems_mirror design_flexibility frequency_ratios large_designs lissajous mems_mirrors mems_scanner oscillation_mode piezoelectric projection_system_for_maritime_augmented_reality,biaxial resonant mem scanner considered promising core device state art imaging projection system due compactness large field view high speed comparably low power consumption however usage three dimensional lidar module projector industrial application often limited non optimal lissajous scanning pattern achieve dense spatially uniform lissajous trajectory suitable frequency ratio two oscillation mode essential previous work frequency ratio either maximized minimized often led either mechanical fragility undesirable coupling two normal mode solving abovementioned problem piezoelectrically driven biaxial mem scanner exhibiting large design flexibility enabling individual tailoring two orthogonal rotational oscillation mode lissajous pattern large fill factor developed design freedom decoupling two ax motion achieved gimbal le design individual actuator system two oscillatory ax driven cmos compatible piezoelectric al sc n q factor resonant mirror large optical aperture 5 mm enhanced hermetic wafer level glass encapsulation projection module combine biaxial mem scanner rgb laser beam combiner electronics read control developed frame funded research project mem scanner based laser projection system maritime augmented reality target project development smart window sense mem scanner based laser projection system maritime augmented reality offer possibility fade safety relevant information navigation ship sensor field view bridge personnel ship rsquo bridge projector promising also application industry instance 3d camera copy 2023 spie,bridges cameras laser_mirrors mems optical_radar piezoelectricity q_factor_measurement ships 2d_resonant_mems_mirror design_flexibility frequency_ratios large_designs lissajous mems_mirrors mems_scanner oscillation_mode piezoelectric projection_system_for_maritime_augmented_reality 401 1_bridges 701 1_electricity _basic_concepts_and_phenomena 704 2_electric_equipment 716 2_radar_systems_and_equipment 741 3_optical_devices_and_systems 742 2_photographic_equipment 744 7_laser_components 744 8_laser_beam_interactions 942 2_electric_variables_measurements other input transportation optics inspection _safety_and_quality government developers geospatial semiconductors biaxial resonant mem scanner considered promising core device state art imaging projection system due compactness large field view high speed comparably low power consumption however usage three dimensional lidar module projector industrial application often limited non optimal lissajous scanning pattern achieve dense spatially uniform lissajous trajectory suitable frequency ratio two oscillation mode essential previous work frequency ratio either maximized minimized often led either mechanical fragility undesirable coupling two normal mode solving abovementioned problem piezoelectrically driven biaxial mem scanner exhibiting large design flexibility enabling individual tailoring two orthogonal rotational oscillation mode lissajous pattern large fill factor developed design freedom decoupling two ax motion achieved gimbal le design individual actuator system two oscillatory ax driven cmos compatible piezoelectric al sc n q factor resonant mirror large optical aperture 5 mm enhanced hermetic wafer level glass encapsulation projection module combine biaxial mem scanner rgb laser beam combiner electronics read control developed frame funded research project mem scanner based laser projection system maritime augmented reality target project development smart window sense mem scanner based laser projection system maritime augmented reality offer possibility fade safety relevant information navigation ship sensor field view bridge personnel ship rsquo bridge projector promising also application industry instance 3d camera copy 2023 spie,biaxial resonant mem scanner considered promising core device state art imaging projection system due compactness large field view high speed comparably low power consumption however usage three dimensional lidar module projector industrial application often limited non optimal lissajous scanning pattern achieve dense spatially uniform lissajous trajectory suitable frequency ratio two oscillation mode essential previous work frequency ratio either maximized minimized often led either mechanical fragility undesirable coupling two normal mode solving abovementioned problem piezoelectrically driven biaxial mem scanner exhibiting large design flexibility enabling individual tailoring two orthogonal rotational oscillation mode lissajous pattern large fill factor developed design freedom decoupling two ax motion achieved gimbal le design individual actuator system two oscillatory ax driven cmos compatible piezoelectric al sc n q factor resonant mirror large optical aperture 5 mm enhanced hermetic wafer level glass encapsulation projection module combine biaxial mem scanner rgb laser beam combiner electronics read control developed frame funded research project mem scanner based laser projection system maritime augmented reality target project development smart window sense mem scanner based laser projection system maritime augmented reality offer possibility fade safety relevant information navigation ship sensor field view bridge personnel ship rsquo bridge projector promising also application industry instance 3d camera copy 2023 spiebridges cameras laser_mirrors mems optical_radar piezoelectricity q_factor_measurement ships2d_resonant_mems_mirror design_flexibility frequency_ratios large_designs lissajous mems_mirrors mems_scanner oscillation_mode piezoelectric projection_system_for_maritime_augmented_reality
325,Genie in the Model: Automatic Generation of Human-in-the-Loop Deep Neural Networks for Mobile Applications,"Wang, Y., Yu, Z., Liu, S., Zhou, Z., & Guo, B. (2022). Genie in the Model. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 7(1), 1–29. https://doi.org/10.1145/3580815
",10.1145/3580815,"Advances in deep neural networks (DNNs) have fostered a wide spectrum of intelligent mobile applications ranging from voice assistants on smartphones to augmented reality with smart-glasses. To deliver high-quality services, these DNNs should operate on resource-constrained mobile platforms and yield consistent performance in open environments. However, DNNs are notoriously resource-intensive, and often suffer from performance degradation in real-world deployments. Existing research strives to optimize the resource-performance trade-off of DNNs by compressing the model without notably compromising its inference accuracy. Accordingly, the accuracy of these compressed DNNs is bounded by the original ones, leading to more severe accuracy drop in challenging yet common scenarios such as low-resolution, small-size, and motion-blur. In this paper, we propose to push forward the frontiers of the DNN performance-resource trade-off by introducing human intelligence as a new design dimension. To this end, we explore human-in-the-loop DNNs (H-DNNs) and their automatic performance-resource optimization. We present H-Gen, an automatic H-DNN compression framework that incorporates human participation as a new hyperparameter for accurate and efficient DNN generation. It involves novel hyperparameter formulation, metric calculation, and search strategy in the context of automatic H-DNN generation. We also propose human participation mechanisms for three common DNN architectures to showcase the feasibility of H-Gen. Extensive experiments on twelve categories of challenging samples with three common DNN structures demonstrate the superiority of H-Gen in terms of the overall trade-off between performance (accuracy, latency), and resource (storage, energy, human labour).","C6264 Neural nets;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",accurate DNN generation;automatic generation;automatic H-DNN compression framework;automatic performance-resource optimization;challenging yet common scenarios;common DNN architectures;common DNN structures;compressed DNNs;DNN performance-resource trade-off;efficient DNN generation;H-DNN generation;high-quality services;human intelligence;human labour;human participation mechanisms;human-in-the-loop deep neural networks;human-in-the-loop DNNs;inference accuracy;intelligent mobile applications;performance degradation;resource-constrained mobile platforms;resource-performance trade-off;severe accuracy drop;trade-off between performance,augmented reality;deep learning (artificial intelligence);mobile computing;smart phones,2022,Journal article (JA),Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. (USA),"(1) Wang, Y.; (1) Yu, Z.; (1) Liu, S.; (2) Zhou, Z.; (1) Guo, B.; ","(1) Northwestern Polytechnical University, School of Computer Science, China; (2) City University of Hong Kong, School of Data Science, China; ",ACM,-1,"[""deep learning (artificial intelligence)"", ""mobile computing"", ""smartphones""]","[""deep learning (artificial intelligence)"", ""mobile computing"", ""smartphones""]",deep learning (artificial intelligence);mobile computing;smartphones,other;liberal arts;medical;telecommunication;artificial intelligence,technology;other;industries,other;liberal arts;medical;telecommunication;artificial intelligence,technology;other;industries,deep_learning_ artificial_intelligence mobile_computing smartphones accurate_dnn_generation automatic_generation automatic_h dnn_compression_framework automatic_performance resource_optimization challenging_yet_common_scenarios common_dnn_architectures common_dnn_structures compressed_dnns dnn_performance resource_trade off efficient_dnn_generation h dnn_generation high quality_services human_intelligence human_labour human_participation_mechanisms human in the loop_deep_neural_networks human in the loop_dnns inference_accuracy intelligent_mobile_applications performance_degradation resource constrained_mobile_platforms resource performance_trade off severe_accuracy_drop trade off_between_performance c6264_neural_nets c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing other liberal_arts medical telecommunication artificial_intelligence,deep_learning_ artificial_intelligence mobile_computing smartphones,accurate_dnn_generation automatic_generation automatic_h dnn_compression_framework automatic_performance resource_optimization challenging_yet_common_scenarios common_dnn_architectures common_dnn_structures compressed_dnns dnn_performance resource_trade off efficient_dnn_generation h dnn_generation high quality_services human_intelligence human_labour human_participation_mechanisms human in the loop_deep_neural_networks human in the loop_dnns inference_accuracy intelligent_mobile_applications performance_degradation resource constrained_mobile_platforms resource performance_trade off severe_accuracy_drop trade off_between_performance,advance deep neural network dnns fostered wide spectrum intelligent mobile application ranging voice assistant smartphones augmented reality smart glass deliver high quality service dnns operate resource constrained mobile platform yield consistent performance open environment however dnns notoriously resource intensive often suffer performance degradation real world deployment existing research strives optimize resource performance trade dnns compressing model without notably compromising inference accuracy accordingly accuracy compressed dnns bounded original one leading severe accuracy drop challenging yet common scenario low resolution small size motion blur paper propose push forward frontier dnn performance resource trade introducing human intelligence new design dimension end explore human loop dnns h dnns automatic performance resource optimization present h gen automatic h dnn compression framework incorporates human participation new hyperparameter accurate efficient dnn generation involves novel hyperparameter formulation metric calculation search strategy context automatic h dnn generation also propose human participation mechanism three common dnn architecture showcase feasibility h gen extensive experiment twelve category challenging sample three common dnn structure demonstrate superiority h gen term overall trade performance accuracy latency resource storage energy human labour,deep_learning_ artificial_intelligence mobile_computing smartphones accurate_dnn_generation automatic_generation automatic_h dnn_compression_framework automatic_performance resource_optimization challenging_yet_common_scenarios common_dnn_architectures common_dnn_structures compressed_dnns dnn_performance resource_trade off efficient_dnn_generation h dnn_generation high quality_services human_intelligence human_labour human_participation_mechanisms human in the loop_deep_neural_networks human in the loop_dnns inference_accuracy intelligent_mobile_applications performance_degradation resource constrained_mobile_platforms resource performance_trade off severe_accuracy_drop trade off_between_performance c6264_neural_nets c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing other liberal_arts medical telecommunication artificial_intelligence advance deep neural network dnns fostered wide spectrum intelligent mobile application ranging voice assistant smartphones augmented reality smart glass deliver high quality service dnns operate resource constrained mobile platform yield consistent performance open environment however dnns notoriously resource intensive often suffer performance degradation real world deployment existing research strives optimize resource performance trade dnns compressing model without notably compromising inference accuracy accordingly accuracy compressed dnns bounded original one leading severe accuracy drop challenging yet common scenario low resolution small size motion blur paper propose push forward frontier dnn performance resource trade introducing human intelligence new design dimension end explore human loop dnns h dnns automatic performance resource optimization present h gen automatic h dnn compression framework incorporates human participation new hyperparameter accurate efficient dnn generation involves novel hyperparameter formulation metric calculation search strategy context automatic h dnn generation also propose human participation mechanism three common dnn architecture showcase feasibility h gen extensive experiment twelve category challenging sample three common dnn structure demonstrate superiority h gen term overall trade performance accuracy latency resource storage energy human labour,advance deep neural network dnns fostered wide spectrum intelligent mobile application ranging voice assistant smartphones augmented reality smart glass deliver high quality service dnns operate resource constrained mobile platform yield consistent performance open environment however dnns notoriously resource intensive often suffer performance degradation real world deployment existing research strives optimize resource performance trade dnns compressing model without notably compromising inference accuracy accordingly accuracy compressed dnns bounded original one leading severe accuracy drop challenging yet common scenario low resolution small size motion blur paper propose push forward frontier dnn performance resource trade introducing human intelligence new design dimension end explore human loop dnns h dnns automatic performance resource optimization present h gen automatic h dnn compression framework incorporates human participation new hyperparameter accurate efficient dnn generation involves novel hyperparameter formulation metric calculation search strategy context automatic h dnn generation also propose human participation mechanism three common dnn architecture showcase feasibility h gen extensive experiment twelve category challenging sample three common dnn structure demonstrate superiority h gen term overall trade performance accuracy latency resource storage energy human labourdeep_learning_ artificial_intelligence mobile_computing smartphonesaccurate_dnn_generation automatic_generation automatic_h dnn_compression_framework automatic_performance resource_optimization challenging_yet_common_scenarios common_dnn_architectures common_dnn_structures compressed_dnns dnn_performance resource_trade off efficient_dnn_generation h dnn_generation high quality_services human_intelligence human_labour human_participation_mechanisms human in the loop_deep_neural_networks human in the loop_dnns inference_accuracy intelligent_mobile_applications performance_degradation resource constrained_mobile_platforms resource performance_trade off severe_accuracy_drop trade off_between_performance
326,Information loss challenges in surgical navigation systems: From information fusion to AI-based approaches,"Xu, L., Zhang, H., Wang, J., Li, A., Song, S., Ren, H., Qi, L., Gu, J. J., & Meng, M. Q.-H. (2023). Information loss challenges in surgical navigation systems: From information fusion to AI-based approaches. Information Fusion, 92, 13–36. https://doi.org/10.1016/j.inffus.2022.11.015
",10.1016/j.inffus.2022.11.015,"Surgical navigation technology provides minimally invasive surgery (MIS) with the relative pose relationships amongst medical images, surgical instruments, and lesions. On the other hand, traditional operation procedures depend heavily on direct surgical field exposure. Consequently, introducing surgical navigation can enable surgeons to operate more accurately and efficiently. A tracking system is a core enabling technology of a surgical navigation system. In this paper, after reviewing the tracking technologies, we compare and analyze their pros and cons, and find that information loss is a common challenge. The information loss problem is an inherent drawback in mono-modality surgical navigation systems. It is characterized by physical constraints, attenuation, breakdown of signal, and accuracy instability of the tracking algorithms. This review focuses on the information loss problem in tracking technologies for surgical navigation systems. Furthermore, we survey the existing solutions that aim at tackling the information loss problem, especially in the information fusion of surgical tracking technologies, and we also summarize their key improvements and limitations. Particular attention has been given to the modalities, approaches, objectives, and surgical application scenarios, which can improve the accuracy, precision, and stability of surgical navigation systems. Finally, future research trends directed at improving the information loss problem are discussed, i.e., tight integration of sensing technology, augmented reality for visualization in surgical tracking, stable high-speed 5G networks for telesurgery, strong intelligence and affordable service. All rights reserved Elsevier.","A8770E Patient diagnostic methods and instrumentation;A8770G Patient care and treatment;B6135 Optical, image and video signal processing;B6250F Mobile radio systems;B7520 Patient care and treatment;C3385 Biological and medical control systems;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7330 Biology and medical computing",direct surgical field exposure;information fusion;information loss challenges;information loss problem;mono-modality surgical navigation systems;surgical application scenarios;surgical instruments;surgical navigation system;surgical navigation technology;surgical tracking technologies;tracking system,5G mobile communication;artificial intelligence;augmented reality;medical image processing;medical robotics;surgery,2023,Journal article (JA),Inf. Fusion (Netherlands),"(1) Xu, L.; (1) Zhang, H.; (4) Wang, J.; (5) Li, A.; (4) Song, S.; (5) Ren, H.; (1) Qi, L.; (6) Gu, J.J.; (5) Meng, M.Q.-H.; ","(1) Northeastern University, College of Medicine and Biological Information Engineering, China; (2) Ministry of Education, Key Laboratory of Medical Image Computing, China; (3) Neusoft Research of Intelligent Healthcare Technology, Co. Ltd., China; (4) Harbin Institute of Technology, School of Mechanical Engineering and Automation, China; (5) Chinese University of Hong Kong, Department of Electronic Engineering, China; (6) Dalhousie University, Department of Electrical and Computer Engineering, Halifax, NS, Canada; ",Elsevier B.V.,-1,"[""5g mobile communication"", ""artificial intelligence"", ""medical image processing"", ""medical robotics"", ""surgery""]","[""5g mobile communication"", ""artificial intelligence"", ""medical image processing"", ""medical robotics"", ""surgery""]",5g mobile communication;artificial intelligence;medical image processing;medical robotics;surgery,computer vision;robotics;input;liberal arts;medical;telecommunication;data;artificial intelligence,technology;industries,computer vision;robotics;input;liberal arts;medical;telecommunication;data;artificial intelligence,technology;industries,5g_mobile_communication artificial_intelligence medical_image_processing medical_robotics surgery direct_surgical_field_exposure information_fusion information_loss_challenges information_loss_problem mono modality_surgical_navigation_systems surgical_application_scenarios surgical_instruments surgical_navigation_system surgical_navigation_technology surgical_tracking_technologies tracking_system a8770e_patient_diagnostic_methods_and_instrumentation a8770g_patient_care_and_treatment b6135_optical _image_and_video_signal_processing b6250f_mobile_radio_systems b7520_patient_care_and_treatment c3385_biological_and_medical_control_systems c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision robotics input liberal_arts medical telecommunication data artificial_intelligence,5g_mobile_communication artificial_intelligence medical_image_processing medical_robotics surgery,direct_surgical_field_exposure information_fusion information_loss_challenges information_loss_problem mono modality_surgical_navigation_systems surgical_application_scenarios surgical_instruments surgical_navigation_system surgical_navigation_technology surgical_tracking_technologies tracking_system,surgical navigation technology provides minimally invasive surgery mi relative pose relationship amongst medical image surgical instrument lesion hand traditional operation procedure depend heavily direct surgical field exposure consequently introducing surgical navigation enable surgeon operate accurately efficiently tracking system core enabling technology surgical navigation system paper reviewing tracking technology compare analyze pro con find information loss common challenge information loss problem inherent drawback mono modality surgical navigation system characterized physical constraint attenuation breakdown signal accuracy instability tracking algorithm review focus information loss problem tracking technology surgical navigation system furthermore survey existing solution aim tackling information loss problem especially information fusion surgical tracking technology also summarize key improvement limitation particular attention given modality approach objective surgical application scenario improve accuracy precision stability surgical navigation system finally future research trend directed improving information loss problem discussed e tight integration sensing technology augmented reality visualization surgical tracking stable high speed 5g network telesurgery strong intelligence affordable service right reserved elsevier,5g_mobile_communication artificial_intelligence medical_image_processing medical_robotics surgery direct_surgical_field_exposure information_fusion information_loss_challenges information_loss_problem mono modality_surgical_navigation_systems surgical_application_scenarios surgical_instruments surgical_navigation_system surgical_navigation_technology surgical_tracking_technologies tracking_system a8770e_patient_diagnostic_methods_and_instrumentation a8770g_patient_care_and_treatment b6135_optical _image_and_video_signal_processing b6250f_mobile_radio_systems b7520_patient_care_and_treatment c3385_biological_and_medical_control_systems c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7330_biology_and_medical_computing computer_vision robotics input liberal_arts medical telecommunication data artificial_intelligence surgical navigation technology provides minimally invasive surgery mi relative pose relationship amongst medical image surgical instrument lesion hand traditional operation procedure depend heavily direct surgical field exposure consequently introducing surgical navigation enable surgeon operate accurately efficiently tracking system core enabling technology surgical navigation system paper reviewing tracking technology compare analyze pro con find information loss common challenge information loss problem inherent drawback mono modality surgical navigation system characterized physical constraint attenuation breakdown signal accuracy instability tracking algorithm review focus information loss problem tracking technology surgical navigation system furthermore survey existing solution aim tackling information loss problem especially information fusion surgical tracking technology also summarize key improvement limitation particular attention given modality approach objective surgical application scenario improve accuracy precision stability surgical navigation system finally future research trend directed improving information loss problem discussed e tight integration sensing technology augmented reality visualization surgical tracking stable high speed 5g network telesurgery strong intelligence affordable service right reserved elsevier,surgical navigation technology provides minimally invasive surgery mi relative pose relationship amongst medical image surgical instrument lesion hand traditional operation procedure depend heavily direct surgical field exposure consequently introducing surgical navigation enable surgeon operate accurately efficiently tracking system core enabling technology surgical navigation system paper reviewing tracking technology compare analyze pro con find information loss common challenge information loss problem inherent drawback mono modality surgical navigation system characterized physical constraint attenuation breakdown signal accuracy instability tracking algorithm review focus information loss problem tracking technology surgical navigation system furthermore survey existing solution aim tackling information loss problem especially information fusion surgical tracking technology also summarize key improvement limitation particular attention given modality approach objective surgical application scenario improve accuracy precision stability surgical navigation system finally future research trend directed improving information loss problem discussed e tight integration sensing technology augmented reality visualization surgical tracking stable high speed 5g network telesurgery strong intelligence affordable service right reserved elsevier5g_mobile_communication artificial_intelligence medical_image_processing medical_robotics surgerydirect_surgical_field_exposure information_fusion information_loss_challenges information_loss_problem mono modality_surgical_navigation_systems surgical_application_scenarios surgical_instruments surgical_navigation_system surgical_navigation_technology surgical_tracking_technologies tracking_system
327,Demystifying Mobile Extended Reality in Web Browsers: How Far Can We Go?,"Bi, W., Ma, Y., Tian, D., Yang, Q., Zhang, M., & Jing, X. (2023). Demystifying Mobile Extended Reality in Web Browsers: How Far Can We Go? Proceedings of the ACM Web Conference 2023. https://doi.org/10.1145/3543507.3583329
",10.1145/3543507.3583329,"Mobile extended reality (XR) has developed rapidly in recent years. Compared with the app-based XR, XR in web browsers has the advantages of being lightweight and cross-platform, providing users with a pervasive experience. Therefore, many frameworks are emerging to support the development of XR in web browsers. However, little has been known about how well these frameworks perform and how complex XR apps modern web browsers can support on mobile devices. To fill the knowledge gap, in this paper, we conduct an empirical study of mobile XR in web browsers. We select seven most popular web-based XR frameworks and investigate their runtime performance, including 3D rendering, camera capturing, and real-world understanding. We find that current frameworks have the potential to further enhance their performance by increasing GPU utilization or improving computing parallelism. Besides, for 3D scenes with good rendering performance, developers can feel free to add camera capturing with little influence on performance to support augmented reality (AR) and mixed reality (MR) applications. Based on our findings, we draw several practical implications to provide better XR support in web browsers.","C6190V Mobile, ubiquitous and pervasive computing;C6130B Graphics techniques;C6130V Virtual reality;C7210N Information networks",app-based XR;complex XR apps modern web browsers;frameworks perform;mobile extended reality;mobile XR;seven most popular web-based XR frameworks;XR support,augmented reality;graphics processing units;Internet;mobile computing;online front-ends;rendering (computer graphics),2023,Conference article (CA),WWW '23: Proceedings of the ACM Web Conference 2023,"(1) Bi, W.; (2) Ma, Y.; (1) Tian, D.; (3) Yang, Q.; (1) Zhang, M.; (4) Jing, X.; ","(1) Peking University, School of Computer Science, China; (2) Peking University, Institute for Artificial Intelligence, China; (3) University of New South Wales, School of Computer Science and Engineering, Sydney, NSW, Australia; (4) Peking University, School of Software & Microelectronics, China; ",ACM,-1,"[""graphics processing units"", ""internet"", ""mobile computing"", ""online front ends"", ""rendering""]","[""graphics processing units"", ""internet"", ""mobile computing"", ""online front ends"", ""rendering""]",graphics processing units;internet;mobile computing;online front ends;rendering,graphics;telecommunication;data;human-computer interaction;semiconductors;networks,technology;industries;end users and user experience,graphics;telecommunication;data;human-computer interaction;semiconductors;networks,technology;industries;end users and user experience,graphics_processing_units internet mobile_computing online_front_ends rendering app based_xr complex_xr_apps_modern_web_browsers frameworks_perform mobile_extended_reality mobile_xr seven_most_popular_web based_xr_frameworks xr_support c6190v_mobile _ubiquitous_and_pervasive_computing c6130b_graphics_techniques c6130v_virtual_reality c7210n_information_networks graphics telecommunication data human computer_interaction semiconductors networks,graphics_processing_units internet mobile_computing online_front_ends rendering,app based_xr complex_xr_apps_modern_web_browsers frameworks_perform mobile_extended_reality mobile_xr seven_most_popular_web based_xr_frameworks xr_support,mobile extended reality xr developed rapidly recent year compared app based xr xr web browser advantage lightweight cross platform providing user pervasive experience therefore many framework emerging support development xr web browser however little known well framework perform complex xr apps modern web browser support mobile device fill knowledge gap paper conduct empirical study mobile xr web browser select seven popular web based xr framework investigate runtime performance including 3d rendering camera capturing real world understanding find current framework potential enhance performance increasing gpu utilization improving computing parallelism besides 3d scene good rendering performance developer feel free add camera capturing little influence performance support augmented reality ar mixed reality mr application based finding draw several practical implication provide better xr support web browser,graphics_processing_units internet mobile_computing online_front_ends rendering app based_xr complex_xr_apps_modern_web_browsers frameworks_perform mobile_extended_reality mobile_xr seven_most_popular_web based_xr_frameworks xr_support c6190v_mobile _ubiquitous_and_pervasive_computing c6130b_graphics_techniques c6130v_virtual_reality c7210n_information_networks graphics telecommunication data human computer_interaction semiconductors networks mobile extended reality xr developed rapidly recent year compared app based xr xr web browser advantage lightweight cross platform providing user pervasive experience therefore many framework emerging support development xr web browser however little known well framework perform complex xr apps modern web browser support mobile device fill knowledge gap paper conduct empirical study mobile xr web browser select seven popular web based xr framework investigate runtime performance including 3d rendering camera capturing real world understanding find current framework potential enhance performance increasing gpu utilization improving computing parallelism besides 3d scene good rendering performance developer feel free add camera capturing little influence performance support augmented reality ar mixed reality mr application based finding draw several practical implication provide better xr support web browser,mobile extended reality xr developed rapidly recent year compared app based xr xr web browser advantage lightweight cross platform providing user pervasive experience therefore many framework emerging support development xr web browser however little known well framework perform complex xr apps modern web browser support mobile device fill knowledge gap paper conduct empirical study mobile xr web browser select seven popular web based xr framework investigate runtime performance including 3d rendering camera capturing real world understanding find current framework potential enhance performance increasing gpu utilization improving computing parallelism besides 3d scene good rendering performance developer feel free add camera capturing little influence performance support augmented reality ar mixed reality mr application based finding draw several practical implication provide better xr support web browsergraphics_processing_units internet mobile_computing online_front_ends renderingapp based_xr complex_xr_apps_modern_web_browsers frameworks_perform mobile_extended_reality mobile_xr seven_most_popular_web based_xr_frameworks xr_support
328,Happiness through Metaverse: Health and Innovation Relationship,"Bhumika, Kaur, A., & Datta, P. (2023). Happiness through Metaverse: Health and Innovation Relationship. 2023 IEEE 12th International Conference on Communication Systems and Network Technologies (CSNT). https://doi.org/10.1109/csnt57126.2023.10134713
",10.1109/CSNT57126.2023.10134713,"Happiness is the state of emotion characterized by various aspects including satisfaction, day-to-day activities, and balance of emotions. Feeling of accomplishment and living the life you want are the common signs of happy people whereas Metaverse is the concept of the world that exists virtually, it helps in creating a virtual environment for users. Consequently, research related to the contribution of the Metaverse in the field of mental health is increasing. In this paper the relationship between innovation (Metaverse) and mental health (happiness) according to research work is analysed, the result of analysis is presented through several graphs. According to the reviews of papers, it has been observed that there is a great future and improvement in the field of psychology with the help of emerging technologies i.e. Metaverse, AR, and VR.",C6130V Virtual reality;C7810 Social and behavioural sciences computing,AR;day-to-day activities;happy people;mental health;Metaverse;virtual environment;VR,augmented reality;emotion recognition;innovation management;psychology,2023,Conference article (CA),2023 IEEE 12th International Conference on Communication Systems and Network Technologies (CSNT),"(1) Bhumika; (1) Kaur, A.; (1) Datta, P.; ","(1) Chitkara University Institute of Engineering & Technology Chitkara University Patiala, India; ",IEEE,-1,"[""emotion recognition"", ""innovation management"", ""psychology""]","[""emotion recognition"", ""innovation management"", ""psychology""]",emotion recognition;innovation management;psychology,medical;human factors;input;business performance metrics,technology;industries;business;end users and user experience,medical;human factors;input;business performance metrics,technology;industries;business;end users and user experience,emotion_recognition innovation_management psychology ar day to day_activities happy_people mental_health metaverse virtual_environment vr c6130v_virtual_reality c7810_social_and_behavioural_sciences_computing medical human_factors input business_performance_metrics,emotion_recognition innovation_management psychology,ar day to day_activities happy_people mental_health metaverse virtual_environment vr,happiness state emotion characterized various aspect including satisfaction day day activity balance emotion feeling accomplishment living life want common sign happy people whereas metaverse concept world exists virtually help creating virtual environment user consequently research related contribution metaverse field mental health increasing paper relationship innovation metaverse mental health happiness according research work analysed result analysis presented several graph according review paper observed great future improvement field psychology help emerging technology e metaverse ar vr,emotion_recognition innovation_management psychology ar day to day_activities happy_people mental_health metaverse virtual_environment vr c6130v_virtual_reality c7810_social_and_behavioural_sciences_computing medical human_factors input business_performance_metrics happiness state emotion characterized various aspect including satisfaction day day activity balance emotion feeling accomplishment living life want common sign happy people whereas metaverse concept world exists virtually help creating virtual environment user consequently research related contribution metaverse field mental health increasing paper relationship innovation metaverse mental health happiness according research work analysed result analysis presented several graph according review paper observed great future improvement field psychology help emerging technology e metaverse ar vr,happiness state emotion characterized various aspect including satisfaction day day activity balance emotion feeling accomplishment living life want common sign happy people whereas metaverse concept world exists virtually help creating virtual environment user consequently research related contribution metaverse field mental health increasing paper relationship innovation metaverse mental health happiness according research work analysed result analysis presented several graph according review paper observed great future improvement field psychology help emerging technology e metaverse ar vremotion_recognition innovation_management psychologyar day to day_activities happy_people mental_health metaverse virtual_environment vr
329,HybridMingler: Towards Mixed-Reality Support for Mingling at Hybrid Conferences,"Le, K.-D., Ly, D.-N., Nguyen, H.-L., Le, Q.-T., Fjeld, M., & Tran, M.-T. (2023). HybridMingler: Towards Mixed-Reality Support for Mingling at Hybrid Conferences. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585806
",10.1145/3544549.3585806,"Mingling, the activity of ad-hoc, private, opportunistic conversations ahead of, during, or after breaks, is an important socializing activity for attendees at scheduled events, such as in-person conferences. The Covid-19 pandemic had a dramatic impact on the way conferences are organized, so that most of them now take place in a hybrid mode where people can either attend on-site or remotely. While on-site attendees can resume in-person mingling, hybrid modes make it challenging for remote attendees to mingle with on-site peers. In addressing this problem, we propose a collaborative mixed-reality (MR) concept, including a prototype, called HybridMingler. This is a distributed MR system supporting ambient awareness and allowing both on-site and remote conference attendees to virtually mingle. HybridMingler aims to provide both on-site and remote attendees with a spatial sense of co-location in the very same venue location, thus ultimately improving perceived presence.",C6130V Virtual reality;C6130G Groupware;C6180 User interfaces;C6190Z Other distributed systems software,ad-hoc conversations;ambient awareness;collaborative mixed-reality concept;Covid-19 pandemic;distributed MR system;hybrid conferences;hybrid mode;HybridMingler;in-person conferences;in-person mingling;on-site attendees;on-site peers;opportunistic conversations;perceived presence;private conversations;remote conference attendees;scheduled events;socializing activity;virtual mingling,augmented reality;epidemics;groupware;human computer interaction,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Le, K.-D.; (1) Ly, D.-N.; (1) Nguyen, H.-L.; (1) Le, Q.-T.; (2) Fjeld, M.; (1) Tran, M.-T.; ","(1) University of Science, Viet Nam; (2) Chalmers University of Technology, Norway and t2i lab, Sweden; ",ACM,-1,"[""epidemics"", ""groupware"", ""human computer interaction""]","[""epidemics"", ""groupware"", ""human computer interaction""]",epidemics;groupware;human computer interaction,medical;human-computer interaction;collaboration,industries;use cases;end users and user experience,medical;human-computer interaction;collaboration,industries;use cases;end users and user experience,epidemics groupware human_computer_interaction ad hoc_conversations ambient_awareness collaborative_mixed reality_concept covid 19_pandemic distributed_mr_system hybrid_conferences hybrid_mode hybridmingler in person_conferences in person_mingling on site_attendees on site_peers opportunistic_conversations perceived_presence private_conversations remote_conference_attendees scheduled_events socializing_activity virtual_mingling c6130v_virtual_reality c6130g_groupware c6180_user_interfaces c6190z_other_distributed_systems_software medical human computer_interaction collaboration,epidemics groupware human_computer_interaction,ad hoc_conversations ambient_awareness collaborative_mixed reality_concept covid 19_pandemic distributed_mr_system hybrid_conferences hybrid_mode hybridmingler in person_conferences in person_mingling on site_attendees on site_peers opportunistic_conversations perceived_presence private_conversations remote_conference_attendees scheduled_events socializing_activity virtual_mingling,mingling activity ad hoc private opportunistic conversation ahead break important socializing activity attendee scheduled event person conference covid 19 pandemic dramatic impact way conference organized take place hybrid mode people either attend site remotely site attendee resume person mingling hybrid mode make challenging remote attendee mingle site peer addressing problem propose collaborative mixed reality mr concept including prototype called hybridmingler distributed mr system supporting ambient awareness allowing site remote conference attendee virtually mingle hybridmingler aim provide site remote attendee spatial sense co location venue location thus ultimately improving perceived presence,epidemics groupware human_computer_interaction ad hoc_conversations ambient_awareness collaborative_mixed reality_concept covid 19_pandemic distributed_mr_system hybrid_conferences hybrid_mode hybridmingler in person_conferences in person_mingling on site_attendees on site_peers opportunistic_conversations perceived_presence private_conversations remote_conference_attendees scheduled_events socializing_activity virtual_mingling c6130v_virtual_reality c6130g_groupware c6180_user_interfaces c6190z_other_distributed_systems_software medical human computer_interaction collaboration mingling activity ad hoc private opportunistic conversation ahead break important socializing activity attendee scheduled event person conference covid 19 pandemic dramatic impact way conference organized take place hybrid mode people either attend site remotely site attendee resume person mingling hybrid mode make challenging remote attendee mingle site peer addressing problem propose collaborative mixed reality mr concept including prototype called hybridmingler distributed mr system supporting ambient awareness allowing site remote conference attendee virtually mingle hybridmingler aim provide site remote attendee spatial sense co location venue location thus ultimately improving perceived presence,mingling activity ad hoc private opportunistic conversation ahead break important socializing activity attendee scheduled event person conference covid 19 pandemic dramatic impact way conference organized take place hybrid mode people either attend site remotely site attendee resume person mingling hybrid mode make challenging remote attendee mingle site peer addressing problem propose collaborative mixed reality mr concept including prototype called hybridmingler distributed mr system supporting ambient awareness allowing site remote conference attendee virtually mingle hybridmingler aim provide site remote attendee spatial sense co location venue location thus ultimately improving perceived presenceepidemics groupware human_computer_interactionad hoc_conversations ambient_awareness collaborative_mixed reality_concept covid 19_pandemic distributed_mr_system hybrid_conferences hybrid_mode hybridmingler in person_conferences in person_mingling on site_attendees on site_peers opportunistic_conversations perceived_presence private_conversations remote_conference_attendees scheduled_events socializing_activity virtual_mingling
330,Mixed Reality Ecosystem Architecture to Support Visuoconstructive Ability in Older Adults,"Chaparro, E. B. M., Muñoz-Arteaga, J., Zavala, Á. E. M., Reyes, H. C., & Condori, K. O. V. (2023). Mixed Reality Ecosystem Architecture to Support Visuoconstructive Ability in Older Adults. IEEE Revista Iberoamericana de Tecnologias Del Aprendizaje, 18(2), 182–189. https://doi.org/10.1109/rita.2023.3259986
",10.1109/RITA.2023.3259986,"Nowadays, Senile Dementia is one of the most recurrent ailments related to aging as brain functions begin to deteriorate, making the elderly more dependent on others to take care of them. Using ecosystems with mixed reality allows them to have an easier way to their activities, have some independence, improve their quality of life and do exercise routines by themselves with the help of the Internet for remote control monitoring. This work proposes an architectural model for a mixed reality ecosystem to support older adults' daily activities. The work advocates the design of the ecosystem components, which are used in two scenarios for the rehabilitation of the visuo-constructive ability of patients, making a more adequate and detailed combination and implementation of connectivity, software and peripherals.",C6130V Virtual reality;C7210N Information networks,architectural model;brain functions;Internet;mixed reality ecosystem architecture;older adults;recurrent ailments;Senile Dementia;visuoconstructive ability,augmented reality;brain;geriatrics;Internet,2023,Journal article (JA),IEEE Rev. Iberoam. Tecnol. Aprendiz. (USA),"(1) Chaparro, E.B.M.; (2) Munoz-Arteaga, J.; (1) Zavala, A.E.M.; (3) Reyes, H.C.; (4) Condori, K.O.V.; ","(1) Universidad Auto&#769;noma de Aguascalientes, Departamento de Estadi&#769;stica, Mexico; (2) Universidad Autonoma de Aguascalientes, Departamento de Sistemas de Informacio&#769;n, Mexico; (3) CIMAT, Mexico; (4) Universidad Cato&#769;lica de Santa Mari&#769;a, Departamento Vicerrectorado de Investigacio&#769;n, Peru; ",IEEE,-1,"[""brain"", ""geriatrics"", ""internet""]","[""brain"", ""geriatrics"", ""internet""]",brain;geriatrics;internet,medical;farming and natural science;networks,technology;industries,medical;farming and natural science;networks,technology;industries,brain geriatrics internet architectural_model brain_functions internet mixed_reality_ecosystem_architecture older_adults recurrent_ailments senile_dementia visuoconstructive_ability c6130v_virtual_reality c7210n_information_networks medical farming_and_natural_science networks,brain geriatrics internet,architectural_model brain_functions internet mixed_reality_ecosystem_architecture older_adults recurrent_ailments senile_dementia visuoconstructive_ability,nowadays senile dementia one recurrent ailment related aging brain function begin deteriorate making elderly dependent others take care using ecosystem mixed reality allows easier way activity independence improve quality life exercise routine help internet remote control monitoring work proposes architectural model mixed reality ecosystem support older adult daily activity work advocate design ecosystem component used two scenario rehabilitation visuo constructive ability patient making adequate detailed combination implementation connectivity software peripheral,brain geriatrics internet architectural_model brain_functions internet mixed_reality_ecosystem_architecture older_adults recurrent_ailments senile_dementia visuoconstructive_ability c6130v_virtual_reality c7210n_information_networks medical farming_and_natural_science networks nowadays senile dementia one recurrent ailment related aging brain function begin deteriorate making elderly dependent others take care using ecosystem mixed reality allows easier way activity independence improve quality life exercise routine help internet remote control monitoring work proposes architectural model mixed reality ecosystem support older adult daily activity work advocate design ecosystem component used two scenario rehabilitation visuo constructive ability patient making adequate detailed combination implementation connectivity software peripheral,nowadays senile dementia one recurrent ailment related aging brain function begin deteriorate making elderly dependent others take care using ecosystem mixed reality allows easier way activity independence improve quality life exercise routine help internet remote control monitoring work proposes architectural model mixed reality ecosystem support older adult daily activity work advocate design ecosystem component used two scenario rehabilitation visuo constructive ability patient making adequate detailed combination implementation connectivity software peripheralbrain geriatrics internetarchitectural_model brain_functions internet mixed_reality_ecosystem_architecture older_adults recurrent_ailments senile_dementia visuoconstructive_ability
331,The Aachen Lab Demo: From Fundamental Perception to Design Tools,"Borchers, J., Brocker, A., Hueber, S., Nowak, O., Schäfer, R., Wagner, A., Preuschoff, P. M., & Schirp, L. E. (2023). The Aachen Lab Demo: From Fundamental Perception to Design Tools. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583937
",10.1145/3544549.3583937,"This year, the Media Computing Group at RWTH Aachen University turns 20. We celebrate this anniversary with a Lab Interactivity Demo at CHI that showcases not past achievements, but the range of currently ongoing research at the lab. It features hands-on interactive demos ranging from fundamental research in perception and cognition with traditional devices, such as experiencing input latency and Dark Patterns, to new input and output techniques beyond the desktop, such as user-perspective rendering in handheld AR and interaction with time-based media through conducting, to physical interfaces and the tools and processes for their design and fabrication, such as textile icons and sliders, soft robotics, and 3D printing fabric-covered objects.",C6180 User interfaces;C6130B Graphics techniques;C6130V Virtual reality,Aachen Lab Demo;Dark Patterns;hands-on interactive demos;Lab Interactivity Demo;Media Computing Group;RWTH Aachen University;time-based media;user-perspective rendering,augmented reality;rendering (computer graphics);user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Borchers, J.; (1) Brocker, A.; (1) Hueber, S.; (1) Nowak, O.; (1) Scha&#776;fer, R.; (1) Wagner, A.; (1) Preuschoff, P.M.; (1) Schirp, L.E.; ","(1) RWTH Aachen University, Germany; ",ACM,-1,"[""rendering"", ""user interfaces""]","[""rendering"", ""user interfaces""]",rendering;user interfaces,graphics;human-computer interaction,technology;end users and user experience,graphics;human-computer interaction,technology;end users and user experience,rendering user_interfaces aachen_lab_demo dark_patterns hands on_interactive_demos lab_interactivity_demo media_computing_group rwth_aachen_university time based_media user perspective_rendering c6180_user_interfaces c6130b_graphics_techniques c6130v_virtual_reality graphics human computer_interaction,rendering user_interfaces,aachen_lab_demo dark_patterns hands on_interactive_demos lab_interactivity_demo media_computing_group rwth_aachen_university time based_media user perspective_rendering,year medium computing group rwth aachen university turn 20 celebrate anniversary lab interactivity demo chi showcase past achievement range currently ongoing research lab feature hand interactive demo ranging fundamental research perception cognition traditional device experiencing input latency dark pattern new input output technique beyond desktop user perspective rendering handheld ar interaction time based medium conducting physical interface tool process design fabrication textile icon slider soft robotics 3d printing fabric covered object,rendering user_interfaces aachen_lab_demo dark_patterns hands on_interactive_demos lab_interactivity_demo media_computing_group rwth_aachen_university time based_media user perspective_rendering c6180_user_interfaces c6130b_graphics_techniques c6130v_virtual_reality graphics human computer_interaction year medium computing group rwth aachen university turn 20 celebrate anniversary lab interactivity demo chi showcase past achievement range currently ongoing research lab feature hand interactive demo ranging fundamental research perception cognition traditional device experiencing input latency dark pattern new input output technique beyond desktop user perspective rendering handheld ar interaction time based medium conducting physical interface tool process design fabrication textile icon slider soft robotics 3d printing fabric covered object,year medium computing group rwth aachen university turn 20 celebrate anniversary lab interactivity demo chi showcase past achievement range currently ongoing research lab feature hand interactive demo ranging fundamental research perception cognition traditional device experiencing input latency dark pattern new input output technique beyond desktop user perspective rendering handheld ar interaction time based medium conducting physical interface tool process design fabrication textile icon slider soft robotics 3d printing fabric covered objectrendering user_interfacesaachen_lab_demo dark_patterns hands on_interactive_demos lab_interactivity_demo media_computing_group rwth_aachen_university time based_media user perspective_rendering
332,Method for large field of view and eye-box for holographic waveguide display based on LED illumination,"Zhang, T., & Kaneda, Y. (2023). Method for large field of view and eye-box of holographic waveguide display based on LED illumination. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2668436
",10.1117/12.2668436,"Holographic waveguide display takes the advantage of pupil expansion to increase the size of eye-box which can be widely employed into augmented reality (AR) systems. However, the angular selectivity of holographic optical elements (HOEs) used as in- and out-coupler for waveguide display is very limited when reading out by coherent light source like lasers. Here, we propose a method by utilizing broadband light source like LED with multilayer HOEs or multilayer waveguides, each pair of the in- and out-coupling HOEs or waveguides will be angularly separated to construct the specific angular region. Due to its decent spectrum selectivity of holographic couplers and multilayer structure, the field of view (FOV) of the display system can be significantly increased. Large eye-box is realized by employing pupil expansion for allowing the image to interact with out-couplers multiple times. &copy; 2023 SPIE.","714.2 Semiconductor Devices and Integrated Circuits;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;743 Holography",Angular regions;Angular selectivity;Augmented reality systems;Broadband Light Sources;Coherent light sources;Holographic waveguide display;Large field of views;LED illumination;Multilayer waveguides;Spectra's,Holographic displays;Holographic optical elements;Light emitting diodes;Multilayers;Three dimensional displays,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zhang, Tianyao; (1) Kaneda, Yushi; ","(1) University of Arizona, James C. Wyant College of Optical Sciences, 1630 E University Blvd, Tucson; AZ; 85721, United States; ",SPIE,-1,"[""holographic displays"", ""holographic optical elements"", ""light emitting diodes"", ""multilayers"", ""three-dimensional displays""]","[""holographic displays"", ""holographic optical elements"", ""light emitting diodes"", ""multilayers"", ""three-dimensional displays""]",holographic displays;holographic optical elements;light emitting diodes;multilayers;three-dimensional displays,display technology;optics;input;networks,technology;displays,display technology;optics;input;networks,technology;displays,holographic_displays holographic_optical_elements light_emitting_diodes multilayers three dimensional_displays angular_regions angular_selectivity augmented_reality_systems broadband_light_sources coherent_light_sources holographic_waveguide_display large_field_of_views led_illumination multilayer_waveguides spectra s 714 2_semiconductor_devices_and_integrated_circuits 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 743_holography display_technology optics input networks,holographic_displays holographic_optical_elements light_emitting_diodes multilayers three dimensional_displays,angular_regions angular_selectivity augmented_reality_systems broadband_light_sources coherent_light_sources holographic_waveguide_display large_field_of_views led_illumination multilayer_waveguides spectra s,holographic waveguide display take advantage pupil expansion increase size eye box widely employed augmented reality ar system however angular selectivity holographic optical element hoe used coupler waveguide display limited reading coherent light source like laser propose method utilizing broadband light source like led multilayer hoe multilayer waveguide pair coupling hoe waveguide angularly separated construct specific angular region due decent spectrum selectivity holographic coupler multilayer structure field view fov display system significantly increased large eye box realized employing pupil expansion allowing image interact coupler multiple time copy 2023 spie,holographic_displays holographic_optical_elements light_emitting_diodes multilayers three dimensional_displays angular_regions angular_selectivity augmented_reality_systems broadband_light_sources coherent_light_sources holographic_waveguide_display large_field_of_views led_illumination multilayer_waveguides spectra s 714 2_semiconductor_devices_and_integrated_circuits 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 743_holography display_technology optics input networks holographic waveguide display take advantage pupil expansion increase size eye box widely employed augmented reality ar system however angular selectivity holographic optical element hoe used coupler waveguide display limited reading coherent light source like laser propose method utilizing broadband light source like led multilayer hoe multilayer waveguide pair coupling hoe waveguide angularly separated construct specific angular region due decent spectrum selectivity holographic coupler multilayer structure field view fov display system significantly increased large eye box realized employing pupil expansion allowing image interact coupler multiple time copy 2023 spie,holographic waveguide display take advantage pupil expansion increase size eye box widely employed augmented reality ar system however angular selectivity holographic optical element hoe used coupler waveguide display limited reading coherent light source like laser propose method utilizing broadband light source like led multilayer hoe multilayer waveguide pair coupling hoe waveguide angularly separated construct specific angular region due decent spectrum selectivity holographic coupler multilayer structure field view fov display system significantly increased large eye box realized employing pupil expansion allowing image interact coupler multiple time copy 2023 spieholographic_displays holographic_optical_elements light_emitting_diodes multilayers three dimensional_displaysangular_regions angular_selectivity augmented_reality_systems broadband_light_sources coherent_light_sources holographic_waveguide_display large_field_of_views led_illumination multilayer_waveguides spectra s
333,How to Promote User Purchase in Metaverse? A Systematic Literature Review on Consumer Behavior Research and Virtual Commerce Application Design,"Shen, B., Tan, W., Guo, J., Zhao, L., & Qin, P. (2021). How to Promote User Purchase in Metaverse? A Systematic Literature Review on Consumer Behavior Research and Virtual Commerce Application Design. Applied Sciences, 11(23), 11087. https://doi.org/10.3390/app112311087
",10.3390/app112311087,"Virtual commerce applies immersive technology such as augmented reality and virtual reality into e-commerce to shift consumer perception from 2D product catalogs to 3D immersive virtual spaces. In virtual commerce, the alignment of application design paradigms and the factors influencing consumer behavior is paramount to promote purchase of products and services. The question of their relation needs to be answered, together with the possible improvement of application design. This paper used a systematic literature review approach to synthesize research on virtual commerce from both application design and consumer behavior research, considering the promotion of purchase in virtual commerce settings. Throughout the review, influential factors to purchase and preeminent design artifacts were identified. Then, the research gaps were discovered by mapping the design artifacts to the influential factors, which can inspire future research opportunities on the synergy of these two research directions. Moreover, the evolution of virtual commerce research along with multiple directions were discussed, including the suggestion of meta-commerce as a future trend.",C7170 Marketing computing;C6130V Virtual reality;C6180 User interfaces;C7210N Information networks,2D product catalogs;3D immersive virtual spaces;application design paradigms;consumer behavior research;consumer perception;design artifacts;e-commerce;future research opportunities;meta-commerce;systematic literature review approach;user purchase;virtual commerce application design;virtual commerce research;virtual commerce settings;virtual reality,augmented reality;consumer behaviour;electronic commerce;purchasing;user interfaces,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Shen, B.; (2) Tan, W.; (2) Guo, J.; (3) Zhao, L.; (2) Qin, P.; ","(1) Shanghai Jiao Tong University, School of Software, China; (2) University of Macau, Faculty of Science and Technology, China; (3) Shantou University, Department of Civil and Environmental Engineering, China; ",MDPI,-1,"[""consumer behaviour"", ""electronic commerce"", ""purchasing"", ""user interfaces""]","[""consumer behaviour"", ""electronic commerce"", ""purchasing"", ""user interfaces""]",consumer behaviour;electronic commerce;purchasing;user interfaces,sales and marketing;logistics;human-computer interaction,business;end users and user experience,sales and marketing;logistics;human-computer interaction,business;end users and user experience,consumer_behaviour electronic_commerce purchasing user_interfaces 2d_product_catalogs 3d_immersive_virtual_spaces application_design_paradigms consumer_behavior_research consumer_perception design_artifacts e commerce future_research_opportunities meta commerce systematic_literature_review_approach user_purchase virtual_commerce_application_design virtual_commerce_research virtual_commerce_settings virtual_reality c7170_marketing_computing c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks sales_and_marketing logistics human computer_interaction,consumer_behaviour electronic_commerce purchasing user_interfaces,2d_product_catalogs 3d_immersive_virtual_spaces application_design_paradigms consumer_behavior_research consumer_perception design_artifacts e commerce future_research_opportunities meta commerce systematic_literature_review_approach user_purchase virtual_commerce_application_design virtual_commerce_research virtual_commerce_settings virtual_reality,virtual commerce applies immersive technology augmented reality virtual reality e commerce shift consumer perception 2d product catalog 3d immersive virtual space virtual commerce alignment application design paradigm factor influencing consumer behavior paramount promote purchase product service question relation need answered together possible improvement application design paper used systematic literature review approach synthesize research virtual commerce application design consumer behavior research considering promotion purchase virtual commerce setting throughout review influential factor purchase preeminent design artifact identified research gap discovered mapping design artifact influential factor inspire future research opportunity synergy two research direction moreover evolution virtual commerce research along multiple direction discussed including suggestion meta commerce future trend,consumer_behaviour electronic_commerce purchasing user_interfaces 2d_product_catalogs 3d_immersive_virtual_spaces application_design_paradigms consumer_behavior_research consumer_perception design_artifacts e commerce future_research_opportunities meta commerce systematic_literature_review_approach user_purchase virtual_commerce_application_design virtual_commerce_research virtual_commerce_settings virtual_reality c7170_marketing_computing c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks sales_and_marketing logistics human computer_interaction virtual commerce applies immersive technology augmented reality virtual reality e commerce shift consumer perception 2d product catalog 3d immersive virtual space virtual commerce alignment application design paradigm factor influencing consumer behavior paramount promote purchase product service question relation need answered together possible improvement application design paper used systematic literature review approach synthesize research virtual commerce application design consumer behavior research considering promotion purchase virtual commerce setting throughout review influential factor purchase preeminent design artifact identified research gap discovered mapping design artifact influential factor inspire future research opportunity synergy two research direction moreover evolution virtual commerce research along multiple direction discussed including suggestion meta commerce future trend,virtual commerce applies immersive technology augmented reality virtual reality e commerce shift consumer perception 2d product catalog 3d immersive virtual space virtual commerce alignment application design paradigm factor influencing consumer behavior paramount promote purchase product service question relation need answered together possible improvement application design paper used systematic literature review approach synthesize research virtual commerce application design consumer behavior research considering promotion purchase virtual commerce setting throughout review influential factor purchase preeminent design artifact identified research gap discovered mapping design artifact influential factor inspire future research opportunity synergy two research direction moreover evolution virtual commerce research along multiple direction discussed including suggestion meta commerce future trendconsumer_behaviour electronic_commerce purchasing user_interfaces2d_product_catalogs 3d_immersive_virtual_spaces application_design_paradigms consumer_behavior_research consumer_perception design_artifacts e commerce future_research_opportunities meta commerce systematic_literature_review_approach user_purchase virtual_commerce_application_design virtual_commerce_research virtual_commerce_settings virtual_reality
334,Machine Learning and Computer Vision for the automation of processes in advanced logistics: the Integrated Logistic Platform (ILP) 4.0,"Capua, M. D., Ciaramella, A., & De Prisco, A. (2023). Machine Learning and Computer Vision for the automation of processes in advanced logistics: the Integrated Logistic Platform (ILP) 4.0. Procedia Computer Science, 217, 326–338. https://doi.org/10.1016/j.procs.2022.12.228
",10.1016/j.procs.2022.12.228,"The growing complexity of the logistics chain, the need to take on an ever longer and distributed logistic chain, which in some cases even reaches the final stages of the production of the same goods, highlights the problem of managing the post-production phases of products and goods, but also of the personnel who work on these activities, charged to the companies that deal with logistics. We present in this paper the Integrated Logistic Platform (ILP 4.0), a software architectural model, whose purpose is to lead warehouse logistics to new levels of efficiency, not reachable as the sum of the operational functions within a single logistic company, but reachable only through a unique and cross-functional system, which surpasses the usual fragmented vision and consequent approaches, in favor a strategic coordination of all activities. In this paper it is described the general architecture of the realized platform, with its research contributions and innovations, in particular related to some typical problems of warehouse environments, solved with the help of machine learning and computer vision approaches, but also with the integration of augmented reality (AR) and virtual reality (VR) devices. The aim of the integration of these technologies in the project is the definition of a ""smart"" warehouse model environment, capable of mitigate problems of warehouse logistics such as: automation of the inventory process (through an UAV), control of warehouse movements, and management of logical / physical security of the premises. Based on the experiences made on the project, and focusing the attention on the safety and security aspects in logistics, that the platform covers, we discuss further a possible federated learning approach in order to mitigate the lack of data in order to solve some security and safety problems in the logistic area. All rights reserved Elsevier.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6110B Software engineering techniques;C7480 Production engineering computing;E0410D Industrial applications of IT;E1010 Production management;E1820 Warehousing and storage,advanced logistics;computer vision;ILP 4.0;Integrated Logistic Platform 4;logistic area;logistic chain;logistics chain;machine learning;mitigate problems;operational functions;possible federated learning approach;post-production phases;realized platform;safety problems;security;smart warehouse model environment;software architectural model;typical problems;unique cross-functional system;usual fragmented vision;warehouse environments;warehouse logistics;warehouse movements,augmented reality;computer vision;learning (artificial intelligence);logistics;software architecture;virtual reality;warehousing,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Capua, M.D.; (2) Ciaramella, A.; (3) De Prisco, A.; ","(1) Unlimited Technology srl, isola G2, Italy; (2) Parthenope University of Naples, CVPR Lab, Italy; (3) Magsistem SpA, Italy; ",Elsevier B.V.,-1,"[""computer vision"", ""learning algorithms"", ""logistics"", ""software architecture"", ""warehousing""]","[""computer vision"", ""learning algorithms"", ""logistics"", ""software architecture"", ""warehousing""]",computer vision;learning algorithms;logistics;software architecture;warehousing,construction;computer vision;medical;logistics;developers;artificial intelligence,technology;business;industries,construction;computer vision;medical;logistics;developers;artificial intelligence,technology;business;industries,computer_vision learning_algorithms logistics software_architecture warehousing advanced_logistics computer_vision ilp_4 0 integrated_logistic_platform_4 logistic_area logistic_chain logistics_chain machine_learning mitigate_problems operational_functions possible_federated_learning_approach post production_phases realized_platform safety_problems security smart_warehouse_model_environment software_architectural_model typical_problems unique_cross functional_system usual_fragmented_vision warehouse_environments warehouse_logistics warehouse_movements c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6110b_software_engineering_techniques c7480_production_engineering_computing e0410d_industrial_applications_of_it e1010_production_management e1820_warehousing_and_storage construction computer_vision medical logistics developers artificial_intelligence,computer_vision learning_algorithms logistics software_architecture warehousing,advanced_logistics computer_vision ilp_4 0 integrated_logistic_platform_4 logistic_area logistic_chain logistics_chain machine_learning mitigate_problems operational_functions possible_federated_learning_approach post production_phases realized_platform safety_problems security smart_warehouse_model_environment software_architectural_model typical_problems unique_cross functional_system usual_fragmented_vision warehouse_environments warehouse_logistics warehouse_movements,growing complexity logistics chain need take ever longer distributed logistic chain case even reach final stage production good highlight problem managing post production phase product good also personnel work activity charged company deal logistics present paper integrated logistic platform ilp 4 0 software architectural model whose purpose lead warehouse logistics new level efficiency reachable sum operational function within single logistic company reachable unique cross functional system surpasses usual fragmented vision consequent approach favor strategic coordination activity paper described general architecture realized platform research contribution innovation particular related typical problem warehouse environment solved help machine learning computer vision approach also integration augmented reality ar virtual reality vr device aim integration technology project definition smart warehouse model environment capable mitigate problem warehouse logistics automation inventory process uav control warehouse movement management logical physical security premise based experience made project focusing attention safety security aspect logistics platform cover discus possible federated learning approach order mitigate lack data order solve security safety problem logistic area right reserved elsevier,computer_vision learning_algorithms logistics software_architecture warehousing advanced_logistics computer_vision ilp_4 0 integrated_logistic_platform_4 logistic_area logistic_chain logistics_chain machine_learning mitigate_problems operational_functions possible_federated_learning_approach post production_phases realized_platform safety_problems security smart_warehouse_model_environment software_architectural_model typical_problems unique_cross functional_system usual_fragmented_vision warehouse_environments warehouse_logistics warehouse_movements c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6110b_software_engineering_techniques c7480_production_engineering_computing e0410d_industrial_applications_of_it e1010_production_management e1820_warehousing_and_storage construction computer_vision medical logistics developers artificial_intelligence growing complexity logistics chain need take ever longer distributed logistic chain case even reach final stage production good highlight problem managing post production phase product good also personnel work activity charged company deal logistics present paper integrated logistic platform ilp 4 0 software architectural model whose purpose lead warehouse logistics new level efficiency reachable sum operational function within single logistic company reachable unique cross functional system surpasses usual fragmented vision consequent approach favor strategic coordination activity paper described general architecture realized platform research contribution innovation particular related typical problem warehouse environment solved help machine learning computer vision approach also integration augmented reality ar virtual reality vr device aim integration technology project definition smart warehouse model environment capable mitigate problem warehouse logistics automation inventory process uav control warehouse movement management logical physical security premise based experience made project focusing attention safety security aspect logistics platform cover discus possible federated learning approach order mitigate lack data order solve security safety problem logistic area right reserved elsevier,growing complexity logistics chain need take ever longer distributed logistic chain case even reach final stage production good highlight problem managing post production phase product good also personnel work activity charged company deal logistics present paper integrated logistic platform ilp 4 0 software architectural model whose purpose lead warehouse logistics new level efficiency reachable sum operational function within single logistic company reachable unique cross functional system surpasses usual fragmented vision consequent approach favor strategic coordination activity paper described general architecture realized platform research contribution innovation particular related typical problem warehouse environment solved help machine learning computer vision approach also integration augmented reality ar virtual reality vr device aim integration technology project definition smart warehouse model environment capable mitigate problem warehouse logistics automation inventory process uav control warehouse movement management logical physical security premise based experience made project focusing attention safety security aspect logistics platform cover discus possible federated learning approach order mitigate lack data order solve security safety problem logistic area right reserved elseviercomputer_vision learning_algorithms logistics software_architecture warehousingadvanced_logistics computer_vision ilp_4 0 integrated_logistic_platform_4 logistic_area logistic_chain logistics_chain machine_learning mitigate_problems operational_functions possible_federated_learning_approach post production_phases realized_platform safety_problems security smart_warehouse_model_environment software_architectural_model typical_problems unique_cross functional_system usual_fragmented_vision warehouse_environments warehouse_logistics warehouse_movements
335,Collaborative Edge Caching with Multiple Virtual Reality Service Providers Using Coalition Games,"Lin, C.-C., Chiang, Y., & Wei, H.-Y. (2023). Collaborative Edge Caching with Multiple Virtual Reality Service Providers Using Coalition Games. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118763
",10.1109/WCNC55385.2023.10118763,"Mobile edge computing (MEC) and 5G networks can provide ultra-low latency connections. Combining the two, caching services at the network edge can greatly reduce the delay of virtual reality (VR) and augmented reality (AR) services, enhancing the Quality of Service (QoS) for users. In this paper, we investigate an efficient collaborative service caching scheme between multiple service providers (SPs) with a game-theoretical approach. We model SPs as players who care about nothing but their profits and can form coalitions by sharing edge server resources as well as costs with other members. More than one coalition can be formed in an edge server. Our algorithm guarantees to reach a Nash equilibrium, where no one has the incentive to deviate. Simulation results show that through the proposed collaboration scheme, SPs can reach a higher profit compared to several baselines as well as previously proposed schemes.","B6250F Mobile radio systems;B0240E Game theory;C1140E Game theory;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",caching services;coalition games;collaboration scheme;collaborative edge caching;edge server resources;efficient collaborative service caching scheme;game-theoretical approach;multiple service providers;multiple virtual reality Service providers;network edge;SPs;ultra-low latency connections,5G mobile communication;augmented reality;edge computing;game theory;mobile computing;quality of service;virtual reality,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Lin, C.-C.; (1) Chiang, Y.; (1) Wei, H.-Y.; ","(1) National Taiwan University, Department of Electrical Engineering, Taiwan; ",IEEE,-1,"[""5g mobile communication"", ""edge computing"", ""game theory"", ""mobile computing"", ""quality of service""]","[""5g mobile communication"", ""edge computing"", ""game theory"", ""mobile computing"", ""quality of service""]",5g mobile communication;edge computing;game theory;mobile computing;quality of service,input;business performance metrics;telecommunication;human resources;networks,technology;business;industries,input;business performance metrics;telecommunication;human resources;networks,technology;business;industries,5g_mobile_communication edge_computing game_theory mobile_computing quality_of_service caching_services coalition_games collaboration_scheme collaborative_edge_caching edge_server_resources efficient_collaborative_service_caching_scheme game theoretical_approach multiple_service_providers multiple_virtual_reality_service_providers network_edge sps ultra low_latency_connections b6250f_mobile_radio_systems b0240e_game_theory c1140e_game_theory c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing input business_performance_metrics telecommunication human_resources networks,5g_mobile_communication edge_computing game_theory mobile_computing quality_of_service,caching_services coalition_games collaboration_scheme collaborative_edge_caching edge_server_resources efficient_collaborative_service_caching_scheme game theoretical_approach multiple_service_providers multiple_virtual_reality_service_providers network_edge sps ultra low_latency_connections,mobile edge computing mec 5g network provide ultra low latency connection combining two caching service network edge greatly reduce delay virtual reality vr augmented reality ar service enhancing quality service qos user paper investigate efficient collaborative service caching scheme multiple service provider sps game theoretical approach model sps player care nothing profit form coalition sharing edge server resource well cost member one coalition formed edge server algorithm guarantee reach nash equilibrium one incentive deviate simulation result show proposed collaboration scheme sps reach higher profit compared several baseline well previously proposed scheme,5g_mobile_communication edge_computing game_theory mobile_computing quality_of_service caching_services coalition_games collaboration_scheme collaborative_edge_caching edge_server_resources efficient_collaborative_service_caching_scheme game theoretical_approach multiple_service_providers multiple_virtual_reality_service_providers network_edge sps ultra low_latency_connections b6250f_mobile_radio_systems b0240e_game_theory c1140e_game_theory c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing input business_performance_metrics telecommunication human_resources networks mobile edge computing mec 5g network provide ultra low latency connection combining two caching service network edge greatly reduce delay virtual reality vr augmented reality ar service enhancing quality service qos user paper investigate efficient collaborative service caching scheme multiple service provider sps game theoretical approach model sps player care nothing profit form coalition sharing edge server resource well cost member one coalition formed edge server algorithm guarantee reach nash equilibrium one incentive deviate simulation result show proposed collaboration scheme sps reach higher profit compared several baseline well previously proposed scheme,mobile edge computing mec 5g network provide ultra low latency connection combining two caching service network edge greatly reduce delay virtual reality vr augmented reality ar service enhancing quality service qos user paper investigate efficient collaborative service caching scheme multiple service provider sps game theoretical approach model sps player care nothing profit form coalition sharing edge server resource well cost member one coalition formed edge server algorithm guarantee reach nash equilibrium one incentive deviate simulation result show proposed collaboration scheme sps reach higher profit compared several baseline well previously proposed scheme5g_mobile_communication edge_computing game_theory mobile_computing quality_of_servicecaching_services coalition_games collaboration_scheme collaborative_edge_caching edge_server_resources efficient_collaborative_service_caching_scheme game theoretical_approach multiple_service_providers multiple_virtual_reality_service_providers network_edge sps ultra low_latency_connections
336,Playful co-design: creating an AR-prototype with nurses in interlocking remote and on-site workshops,"Albrecht-Gansohr, C., Geisler, S., & Eimler, S. C. (2023). Playful Co-Design: Creating an AR-Prototype with Nurses in Interlocking Remote and On-Site Workshops. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3573869
",10.1145/3544549.3573869,"Deeply engaging nurses in a participatory co-design process, especially in times of COVID-19, is challenging. In this case study, we shed light on the process of developing a prototype for AR-glasses in nursing. We show the challenges we faced, the methods we used and how they contribute to the core principles of participatory design. A special focus is laid on small-scale interventions with high-impact, that helped us to truly engage users. We introduce empathetic ways to connect contrasting work environments, establish mutual understanding, make the abstract more graspable with playful tools like PLAYMOBIL&#174;, and support co-design development with online formats. Finally, we discuss the transferability to other projects.",C7330 Biology and medical computing;C6130V Virtual reality;C7140 Medical administration,AR-glasses;codesign development;contrasting work environments;core principles;COVID-19;deeply engaging nurses;empathetic ways;nursing;on-site workshops;participatory codesign process;participatory design;playful codesign;playful tools;small-scale interventions,augmented reality;diseases;epidemics;health care;medical computing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Albrecht-Gansohr, C.; (1) Geisler, S.; (1) Eimler, S.C.; ","(1) Ruhr West University of Applied Sciences, Institute of Positive Computing, Germany; ",ACM,-1,"[""diseases"", ""epidemics"", ""health care"", ""medical computing""]","[""diseases"", ""epidemics"", ""health care"", ""medical computing""]",diseases;epidemics;health care;medical computing,medical,industries,medical,industries,diseases epidemics health_care medical_computing ar glasses codesign_development contrasting_work_environments core_principles covid 19 deeply_engaging_nurses empathetic_ways nursing on site_workshops participatory_codesign_process participatory_design playful_codesign playful_tools small scale_interventions c7330_biology_and_medical_computing c6130v_virtual_reality c7140_medical_administration medical,diseases epidemics health_care medical_computing,ar glasses codesign_development contrasting_work_environments core_principles covid 19 deeply_engaging_nurses empathetic_ways nursing on site_workshops participatory_codesign_process participatory_design playful_codesign playful_tools small scale_interventions,deeply engaging nurse participatory co design process especially time covid 19 challenging case study shed light process developing prototype ar glass nursing show challenge faced method used contribute core principle participatory design special focus laid small scale intervention high impact helped u truly engage user introduce empathetic way connect contrasting work environment establish mutual understanding make abstract graspable playful tool like playmobil 174 support co design development online format finally discus transferability project,diseases epidemics health_care medical_computing ar glasses codesign_development contrasting_work_environments core_principles covid 19 deeply_engaging_nurses empathetic_ways nursing on site_workshops participatory_codesign_process participatory_design playful_codesign playful_tools small scale_interventions c7330_biology_and_medical_computing c6130v_virtual_reality c7140_medical_administration medical deeply engaging nurse participatory co design process especially time covid 19 challenging case study shed light process developing prototype ar glass nursing show challenge faced method used contribute core principle participatory design special focus laid small scale intervention high impact helped u truly engage user introduce empathetic way connect contrasting work environment establish mutual understanding make abstract graspable playful tool like playmobil 174 support co design development online format finally discus transferability project,deeply engaging nurse participatory co design process especially time covid 19 challenging case study shed light process developing prototype ar glass nursing show challenge faced method used contribute core principle participatory design special focus laid small scale intervention high impact helped u truly engage user introduce empathetic way connect contrasting work environment establish mutual understanding make abstract graspable playful tool like playmobil 174 support co design development online format finally discus transferability projectdiseases epidemics health_care medical_computingar glasses codesign_development contrasting_work_environments core_principles covid 19 deeply_engaging_nurses empathetic_ways nursing on site_workshops participatory_codesign_process participatory_design playful_codesign playful_tools small scale_interventions
337,Wish You Were Here: Mental and Physiological Effects of Remote Music Collaboration in Mixed Reality,"Schlagowski, R., Nazarenko, D., Can, Y., Gupta, K., Mertes, S., Billinghurst, M., & André, E. (2023). Wish You Were Here: Mental and Physiological Effects of Remote Music Collaboration in Mixed Reality. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581162
",10.1145/3544548.3581162,"With face-to-face music collaboration being severely limited during the recent pandemic, mixed reality technologies and their potential to provide musicians a feeling of ""being there"" with their musical partner can offer tremendous opportunities. In order to assess this potential, we conducted a laboratory study in which musicians made music together in real-time while simultaneously seeing their jamming partner's mixed reality point cloud via a head-mounted display and compared mental effects such as flow, affect, and co-presence to an audio-only baseline. In addition, we tracked the musicians' physiological signals and evaluated their features during times of self-reported flow. For users jamming in mixed reality, we observed a significant increase in co-presence. Regardless of the condition (mixed reality or audio-only), we observed an increase in positive affect after jamming remotely. Furthermore, we identified heart rate and HF/LF as promising features for classifying the flow state musicians experienced while making music together.",C7820 Humanities computing;C6130G Groupware;C6130V Virtual reality;C6180 User interfaces,audio-only baseline;face-to-face music collaboration;flow state musicians;head-mounted display;jamming partner;mental effects;mixed reality point cloud;mixed reality technologies;musical partner;musicians physiological signals;recent pandemic;remote music collaboration;self-reported flow,augmented reality;groupware;helmet mounted displays;jamming;music,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Schlagowski, R.; (1) Nazarenko, D.; (1) Can, Y.; (2) Gupta, K.; (1) Mertes, S.; (2) Billinghurst, M.; (1) Andre&#769;, E.; ","(1) University of Augsburg, Chair for Human-Centered Artificial Intelligence, Germany; (2) University of Auckland, Empathic Computing Lab., New Zealand; ",ACM,-1,"[""groupware"", ""helmet mounted displays"", ""jamming"", ""music""]","[""groupware"", ""helmet mounted displays"", ""jamming"", ""music""]",groupware;helmet mounted displays;jamming;music,other;collaboration;display technology;wearables;audio,technology;other;displays;use cases,other;collaboration;display technology;wearables;audio,technology;other;displays;use cases,groupware helmet_mounted_displays jamming music audio only_baseline face to face_music_collaboration flow_state_musicians head mounted_display jamming_partner mental_effects mixed_reality_point_cloud mixed_reality_technologies musical_partner musicians_physiological_signals recent_pandemic remote_music_collaboration self reported_flow c7820_humanities_computing c6130g_groupware c6130v_virtual_reality c6180_user_interfaces other collaboration display_technology wearables audio,groupware helmet_mounted_displays jamming music,audio only_baseline face to face_music_collaboration flow_state_musicians head mounted_display jamming_partner mental_effects mixed_reality_point_cloud mixed_reality_technologies musical_partner musicians_physiological_signals recent_pandemic remote_music_collaboration self reported_flow,face face music collaboration severely limited recent pandemic mixed reality technology potential provide musician feeling musical partner offer tremendous opportunity order ass potential conducted laboratory study musician made music together real time simultaneously seeing jamming partner mixed reality point cloud via head mounted display compared mental effect flow affect co presence audio baseline addition tracked musician physiological signal evaluated feature time self reported flow user jamming mixed reality observed significant increase co presence regardless condition mixed reality audio observed increase positive affect jamming remotely furthermore identified heart rate hf lf promising feature classifying flow state musician experienced making music together,groupware helmet_mounted_displays jamming music audio only_baseline face to face_music_collaboration flow_state_musicians head mounted_display jamming_partner mental_effects mixed_reality_point_cloud mixed_reality_technologies musical_partner musicians_physiological_signals recent_pandemic remote_music_collaboration self reported_flow c7820_humanities_computing c6130g_groupware c6130v_virtual_reality c6180_user_interfaces other collaboration display_technology wearables audio face face music collaboration severely limited recent pandemic mixed reality technology potential provide musician feeling musical partner offer tremendous opportunity order ass potential conducted laboratory study musician made music together real time simultaneously seeing jamming partner mixed reality point cloud via head mounted display compared mental effect flow affect co presence audio baseline addition tracked musician physiological signal evaluated feature time self reported flow user jamming mixed reality observed significant increase co presence regardless condition mixed reality audio observed increase positive affect jamming remotely furthermore identified heart rate hf lf promising feature classifying flow state musician experienced making music together,face face music collaboration severely limited recent pandemic mixed reality technology potential provide musician feeling musical partner offer tremendous opportunity order ass potential conducted laboratory study musician made music together real time simultaneously seeing jamming partner mixed reality point cloud via head mounted display compared mental effect flow affect co presence audio baseline addition tracked musician physiological signal evaluated feature time self reported flow user jamming mixed reality observed significant increase co presence regardless condition mixed reality audio observed increase positive affect jamming remotely furthermore identified heart rate hf lf promising feature classifying flow state musician experienced making music togethergroupware helmet_mounted_displays jamming musicaudio only_baseline face to face_music_collaboration flow_state_musicians head mounted_display jamming_partner mental_effects mixed_reality_point_cloud mixed_reality_technologies musical_partner musicians_physiological_signals recent_pandemic remote_music_collaboration self reported_flow
338,InExChange: Fostering Genuine Social Connection through Embodied Breath Sharing in Mixed Reality,"Morris, C., Liu, P., Riecke, B. E., & Maes, P. (2023). InExChange: Fostering Genuine Social Connection through Embodied Breath Sharing in Mixed Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583917
",10.1145/3544549.3583917,"InExChange is an interactive mixed reality experience centering around an inflatable vest which conveys a physical sense of shared breathing on the diaphragm between two or more participants. The experience is composed of three acts in which the participants' breaths are transformed into metaphorical projected representations: expansive waves, flowing light trails, and growing tree branches. The inflatable wearable devices physically enact in near real-time the inhale/exhale pattern of the other person's breath, varying in intensity level to create an attention interplay between the embodied sensation and the projection. Through this embodied sense of playful shared breathing, we aim to cultivate a genuine feeling of connection and contribute to the integration of somaesthetic design principles in mixed reality HCI.","A8745H Haemodynamics, pneumodynamics;C6130V Virtual reality;C6180 User interfaces",diaphragm;embodied breath sharing;embodied sensation;embodied sense;expansive waves;fostering genuine social connection;growing tree branches;InExChange;inflatable vest;inflatable wearable devices;interactive mixed reality experience centering;light trails;metaphorical projected representations;participants;person;physical sense;playful shared breathing,augmented reality;human computer interaction;pneumodynamics;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Morris, C.; (2) Liu, P.; (3) Riecke, B.E.; (1) Maes, P.; ","(1) Massachusetts Institute of Technology Media Lab, Cambridge, MA, United States; (2) Simon Fraser University, School of Interactive Art & Technology, Burnaby, BC, Canada; (3) Simon Fraser University, School of Interactive Arts + Technology (SIAT), Burnaby, BC, Canada; ",ACM,-1,"[""human computer interaction"", ""pneumodynamics""]","[""human computer interaction"", ""pneumodynamics""]",human computer interaction;pneumodynamics,medical;computer vision;human-computer interaction,technology;industries;end users and user experience,medical;computer vision;human-computer interaction,technology;industries;end users and user experience,human_computer_interaction pneumodynamics diaphragm embodied_breath_sharing embodied_sensation embodied_sense expansive_waves fostering_genuine_social_connection growing_tree_branches inexchange inflatable_vest inflatable_wearable_devices interactive_mixed_reality_experience_centering light_trails metaphorical_projected_representations participants person physical_sense playful_shared_breathing a8745h_haemodynamics _pneumodynamics c6130v_virtual_reality c6180_user_interfaces medical computer_vision human computer_interaction,human_computer_interaction pneumodynamics,diaphragm embodied_breath_sharing embodied_sensation embodied_sense expansive_waves fostering_genuine_social_connection growing_tree_branches inexchange inflatable_vest inflatable_wearable_devices interactive_mixed_reality_experience_centering light_trails metaphorical_projected_representations participants person physical_sense playful_shared_breathing,inexchange interactive mixed reality experience centering around inflatable vest conveys physical sense shared breathing diaphragm two participant experience composed three act participant breath transformed metaphorical projected representation expansive wave flowing light trail growing tree branch inflatable wearable device physically enact near real time inhale exhale pattern person breath varying intensity level create attention interplay embodied sensation projection embodied sense playful shared breathing aim cultivate genuine feeling connection contribute integration somaesthetic design principle mixed reality hci,human_computer_interaction pneumodynamics diaphragm embodied_breath_sharing embodied_sensation embodied_sense expansive_waves fostering_genuine_social_connection growing_tree_branches inexchange inflatable_vest inflatable_wearable_devices interactive_mixed_reality_experience_centering light_trails metaphorical_projected_representations participants person physical_sense playful_shared_breathing a8745h_haemodynamics _pneumodynamics c6130v_virtual_reality c6180_user_interfaces medical computer_vision human computer_interaction inexchange interactive mixed reality experience centering around inflatable vest conveys physical sense shared breathing diaphragm two participant experience composed three act participant breath transformed metaphorical projected representation expansive wave flowing light trail growing tree branch inflatable wearable device physically enact near real time inhale exhale pattern person breath varying intensity level create attention interplay embodied sensation projection embodied sense playful shared breathing aim cultivate genuine feeling connection contribute integration somaesthetic design principle mixed reality hci,inexchange interactive mixed reality experience centering around inflatable vest conveys physical sense shared breathing diaphragm two participant experience composed three act participant breath transformed metaphorical projected representation expansive wave flowing light trail growing tree branch inflatable wearable device physically enact near real time inhale exhale pattern person breath varying intensity level create attention interplay embodied sensation projection embodied sense playful shared breathing aim cultivate genuine feeling connection contribute integration somaesthetic design principle mixed reality hcihuman_computer_interaction pneumodynamicsdiaphragm embodied_breath_sharing embodied_sensation embodied_sense expansive_waves fostering_genuine_social_connection growing_tree_branches inexchange inflatable_vest inflatable_wearable_devices interactive_mixed_reality_experience_centering light_trails metaphorical_projected_representations participants person physical_sense playful_shared_breathing
339,Design and user experience analysis of AR intelligent virtual agents on smartphones,"Gan, Q., Liu, Z., Liu, T., Zhao, Y., & Chai, Y. (2023). Design and user experience analysis of AR intelligent virtual agents on smartphones. Cognitive Systems Research, 78, 33–47. https://doi.org/10.1016/j.cogsys.2022.11.007
",10.1016/j.cogsys.2022.11.007,"Intelligent Virtual Agents (IVAs) can provide users with a friendly experience and have a wide range of applications in the era of artificial intelligence. However, most of existing IVAs are designed for personal computers. Design and user studies of IVAs on smartphones are uncommon. Therefore, developing IVAs for smartphones is an interesting topic. Considering Augmented Reality (AR) technology can provide more potential application value for IVAs, we mainly investigate users' experiences of AR IVAs on smartphones in this paper. To make an IVA more suitable for a smartphone, a lightweight IVA's cognitive architecture is proposed. To find out the factors that affect users' interaction experiences, the effects of humanoid embodiment and emotional expressions of IVAs on users' perceptions and experiences are explored. A museum is used as a specific task scenario to measure users' experiences. Three forms of AR agents are evaluated in this scenario: a voice assistant without an entity, a humanoid IVA without emotional expressions, and a humanoid IVA with emotional expressions. The results show that compared with the voice assistant, a humanoid embodiment can significantly improve the user's experience, and compared with humanoid IVA without emotional expressions, a humanoid IVA with emotional expressions is more welcome. Moreover, we use the cloud model to describe the uncertainty of IVAs' actions (blinking and body orientation). The results show that the uncertainty of actions can increase the believability of IVAs. All rights reserved Elsevier.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C3390V Humanoid robots;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing",AR intelligent virtual agents;AR IVAs;emotional expressions;existing IVAs;friendly experience;humanoid embodiment;humanoid IVA;IVA more suitable;IVAs' actions;lightweight IVA's cognitive architecture;smartphone;user experience analysis;users,artificial intelligence;augmented reality;cognition;human computer interaction;humanoid robots;smart phones;virtual reality,2023,Journal article (JA),Cogn. Syst. Res. (Netherlands),"(1) Gan, Q.; (1) Liu, Z.; (2) Liu, T.; (1) Zhao, Y.; (1) Chai, Y.; ","(1) Ningbo University, Faculty of Information Science and Technology, China; (2) Ningbo University, College of Science and Technology, China; ",Elsevier B.V.,-1,"[""artificial intelligence"", ""cognition"", ""human computer interaction"", ""humanoid robots"", ""smartphones""]","[""artificial intelligence"", ""cognition"", ""human computer interaction"", ""humanoid robots"", ""smartphones""]",artificial intelligence;cognition;human computer interaction;humanoid robots;smartphones,robotics;liberal arts;human factors;telecommunication;human-computer interaction;artificial intelligence,technology;industries;end users and user experience,robotics;liberal arts;human factors;telecommunication;human-computer interaction;artificial intelligence,technology;industries;end users and user experience,artificial_intelligence cognition human_computer_interaction humanoid_robots smartphones ar_intelligent_virtual_agents ar_ivas emotional_expressions existing_ivas friendly_experience humanoid_embodiment humanoid_iva iva_more_suitable ivas _actions lightweight_iva s_cognitive_architecture smartphone user_experience_analysis users c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c3390v_humanoid_robots c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing robotics liberal_arts human_factors telecommunication human computer_interaction artificial_intelligence,artificial_intelligence cognition human_computer_interaction humanoid_robots smartphones,ar_intelligent_virtual_agents ar_ivas emotional_expressions existing_ivas friendly_experience humanoid_embodiment humanoid_iva iva_more_suitable ivas _actions lightweight_iva s_cognitive_architecture smartphone user_experience_analysis users,intelligent virtual agent iva provide user friendly experience wide range application era artificial intelligence however existing iva designed personal computer design user study iva smartphones uncommon therefore developing iva smartphones interesting topic considering augmented reality ar technology provide potential application value iva mainly investigate user experience ar iva smartphones paper make iva suitable smartphone lightweight iva cognitive architecture proposed find factor affect user interaction experience effect humanoid embodiment emotional expression iva user perception experience explored museum used specific task scenario measure user experience three form ar agent evaluated scenario voice assistant without entity humanoid iva without emotional expression humanoid iva emotional expression result show compared voice assistant humanoid embodiment significantly improve user experience compared humanoid iva without emotional expression humanoid iva emotional expression welcome moreover use cloud model describe uncertainty iva action blinking body orientation result show uncertainty action increase believability iva right reserved elsevier,artificial_intelligence cognition human_computer_interaction humanoid_robots smartphones ar_intelligent_virtual_agents ar_ivas emotional_expressions existing_ivas friendly_experience humanoid_embodiment humanoid_iva iva_more_suitable ivas _actions lightweight_iva s_cognitive_architecture smartphone user_experience_analysis users c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c3390v_humanoid_robots c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing robotics liberal_arts human_factors telecommunication human computer_interaction artificial_intelligence intelligent virtual agent iva provide user friendly experience wide range application era artificial intelligence however existing iva designed personal computer design user study iva smartphones uncommon therefore developing iva smartphones interesting topic considering augmented reality ar technology provide potential application value iva mainly investigate user experience ar iva smartphones paper make iva suitable smartphone lightweight iva cognitive architecture proposed find factor affect user interaction experience effect humanoid embodiment emotional expression iva user perception experience explored museum used specific task scenario measure user experience three form ar agent evaluated scenario voice assistant without entity humanoid iva without emotional expression humanoid iva emotional expression result show compared voice assistant humanoid embodiment significantly improve user experience compared humanoid iva without emotional expression humanoid iva emotional expression welcome moreover use cloud model describe uncertainty iva action blinking body orientation result show uncertainty action increase believability iva right reserved elsevier,intelligent virtual agent iva provide user friendly experience wide range application era artificial intelligence however existing iva designed personal computer design user study iva smartphones uncommon therefore developing iva smartphones interesting topic considering augmented reality ar technology provide potential application value iva mainly investigate user experience ar iva smartphones paper make iva suitable smartphone lightweight iva cognitive architecture proposed find factor affect user interaction experience effect humanoid embodiment emotional expression iva user perception experience explored museum used specific task scenario measure user experience three form ar agent evaluated scenario voice assistant without entity humanoid iva without emotional expression humanoid iva emotional expression result show compared voice assistant humanoid embodiment significantly improve user experience compared humanoid iva without emotional expression humanoid iva emotional expression welcome moreover use cloud model describe uncertainty iva action blinking body orientation result show uncertainty action increase believability iva right reserved elsevierartificial_intelligence cognition human_computer_interaction humanoid_robots smartphonesar_intelligent_virtual_agents ar_ivas emotional_expressions existing_ivas friendly_experience humanoid_embodiment humanoid_iva iva_more_suitable ivas _actions lightweight_iva s_cognitive_architecture smartphone user_experience_analysis users
340,A Method of Touchable 3d Model Reconstruction based on Mixed Reality -A Case Study of Medical Training Applications,"Liu, M., Guo, D., & Zhang, Z. (2023). A Method of Touchable 3d Model Reconstruction based on Mixed Reality –A Case Study of Medical Training Applications. Proceedings of the 2023 6th International Conference on Image and Graphics Processing. https://doi.org/10.1145/3582649.3582679
",10.1145/3582649.3582679,"The application of trauma and hemorrhage medical treatment training has generated higher and higher requirements for the authenticity of the medical model. With the increasing integration of mixed reality technology and the medical field, multi-view-based 3D reconstruction technology can generate trauma medical object models not limited to specific targets, with low cost and high precision. However, the current reconstruction methods have weak points such as the inability to build the object surface beyond the direct view of humans, the uneven distribution of reconstructed point clouds, many holes, and reconstructed triangles. And it is time-consuming and laborious to fill and modify manually and requires highly skilled modeling expertise. Therefore, the models generated by traditional 3D reconstruction methods cannot meet the needs of interaction and touch in mixed reality applications. In order to solve these problems, we propose a new model generation method based on multi-view and point cloud processing, which enables the model to reduce the computational cost under the premise of meeting the need for direct interaction and touch in mixed reality applications. Finally, based on the reconstruction method proposed in this paper, a new medical trauma hemorrhage control and rescue training system is designed and implemented, which proves the effectiveness of the method proposed in this paper.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C7330 Biology and medical computing",current reconstruction methods;hemorrhage medical treatment training;higher requirements;highly skilled modeling expertise;medical field;medical model;medical training applications;medical trauma hemorrhage control;mixed reality -a case study;mixed reality applications;mixed reality technology;model generation method;model reconstruction;multiview-based 3D reconstruction technology;object surface;point cloud processing;reconstructed point clouds;reconstruction method;rescue training system;specific targets;touchable 3;traditional 3D reconstruction methods;trauma medical object models;weak points,augmented reality;image reconstruction;solid modelling;virtual reality,2023,Conference article (CA),ICIGP '23: Proceedings of the 2023 6th International Conference on Image and Graphics Processing,"(1) Liu, M.; (1) Guo, D.; (2) Zhang, Z.; ","(1) Institute of Automation, School of Artificial Intelligence, China; (2) 7th Medical Center of PLA General Hospital, Department of Orthopedic, China; ",ACM,-1,"[""image reconstruction"", ""solid modelling""]","[""image reconstruction"", ""solid modelling""]",image reconstruction;solid modelling,construction;computer vision;manufacturing,technology;industries,construction;computer vision;manufacturing,technology;industries,image_reconstruction solid_modelling current_reconstruction_methods hemorrhage_medical_treatment_training higher_requirements highly_skilled_modeling_expertise medical_field medical_model medical_training_applications medical_trauma_hemorrhage_control mixed_reality_ a_case_study mixed_reality_applications mixed_reality_technology model_generation_method model_reconstruction multiview based_3d_reconstruction_technology object_surface point_cloud_processing reconstructed_point_clouds reconstruction_method rescue_training_system specific_targets touchable_3 traditional_3d_reconstruction_methods trauma_medical_object_models weak_points b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing construction computer_vision manufacturing,image_reconstruction solid_modelling,current_reconstruction_methods hemorrhage_medical_treatment_training higher_requirements highly_skilled_modeling_expertise medical_field medical_model medical_training_applications medical_trauma_hemorrhage_control mixed_reality_ a_case_study mixed_reality_applications mixed_reality_technology model_generation_method model_reconstruction multiview based_3d_reconstruction_technology object_surface point_cloud_processing reconstructed_point_clouds reconstruction_method rescue_training_system specific_targets touchable_3 traditional_3d_reconstruction_methods trauma_medical_object_models weak_points,application trauma hemorrhage medical treatment training generated higher higher requirement authenticity medical model increasing integration mixed reality technology medical field multi view based 3d reconstruction technology generate trauma medical object model limited specific target low cost high precision however current reconstruction method weak point inability build object surface beyond direct view human uneven distribution reconstructed point cloud many hole reconstructed triangle time consuming laborious fill modify manually requires highly skilled modeling expertise therefore model generated traditional 3d reconstruction method cannot meet need interaction touch mixed reality application order solve problem propose new model generation method based multi view point cloud processing enables model reduce computational cost premise meeting need direct interaction touch mixed reality application finally based reconstruction method proposed paper new medical trauma hemorrhage control rescue training system designed implemented prof effectiveness method proposed paper,image_reconstruction solid_modelling current_reconstruction_methods hemorrhage_medical_treatment_training higher_requirements highly_skilled_modeling_expertise medical_field medical_model medical_training_applications medical_trauma_hemorrhage_control mixed_reality_ a_case_study mixed_reality_applications mixed_reality_technology model_generation_method model_reconstruction multiview based_3d_reconstruction_technology object_surface point_cloud_processing reconstructed_point_clouds reconstruction_method rescue_training_system specific_targets touchable_3 traditional_3d_reconstruction_methods trauma_medical_object_models weak_points b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing construction computer_vision manufacturing application trauma hemorrhage medical treatment training generated higher higher requirement authenticity medical model increasing integration mixed reality technology medical field multi view based 3d reconstruction technology generate trauma medical object model limited specific target low cost high precision however current reconstruction method weak point inability build object surface beyond direct view human uneven distribution reconstructed point cloud many hole reconstructed triangle time consuming laborious fill modify manually requires highly skilled modeling expertise therefore model generated traditional 3d reconstruction method cannot meet need interaction touch mixed reality application order solve problem propose new model generation method based multi view point cloud processing enables model reduce computational cost premise meeting need direct interaction touch mixed reality application finally based reconstruction method proposed paper new medical trauma hemorrhage control rescue training system designed implemented prof effectiveness method proposed paper,application trauma hemorrhage medical treatment training generated higher higher requirement authenticity medical model increasing integration mixed reality technology medical field multi view based 3d reconstruction technology generate trauma medical object model limited specific target low cost high precision however current reconstruction method weak point inability build object surface beyond direct view human uneven distribution reconstructed point cloud many hole reconstructed triangle time consuming laborious fill modify manually requires highly skilled modeling expertise therefore model generated traditional 3d reconstruction method cannot meet need interaction touch mixed reality application order solve problem propose new model generation method based multi view point cloud processing enables model reduce computational cost premise meeting need direct interaction touch mixed reality application finally based reconstruction method proposed paper new medical trauma hemorrhage control rescue training system designed implemented prof effectiveness method proposed paperimage_reconstruction solid_modellingcurrent_reconstruction_methods hemorrhage_medical_treatment_training higher_requirements highly_skilled_modeling_expertise medical_field medical_model medical_training_applications medical_trauma_hemorrhage_control mixed_reality_ a_case_study mixed_reality_applications mixed_reality_technology model_generation_method model_reconstruction multiview based_3d_reconstruction_technology object_surface point_cloud_processing reconstructed_point_clouds reconstruction_method rescue_training_system specific_targets touchable_3 traditional_3d_reconstruction_methods trauma_medical_object_models weak_points
341,"A Faster, Lighter and&nbsp;Stronger Deep Learning-Based Approach for&nbsp;Place Recognition","Huang, R., Huang, Z., & Su, S. (2023). A Faster, Lighter and Stronger Deep Learning-Based Approach for Place Recognition. Communications in Computer and Information Science, 453–463. https://doi.org/10.1007/978-981-99-2385-4_34
",10.1007/978-981-99-2385-4_34,"Visual Place Recognition is a vital part of image localization and loop closure detection systems, and it has attracted widespread interest in multiple domains such as computer vision, robotics and AR/VR. In this work, we propose a faster, lighter and stronger approach that can generate models with fewer parameters and can spend less time in the inference stage. We designed RepVGG-lite as the backbone network in our architecture, it is more discriminative than other general networks in the Place Recognition task. RepVGG-lite has more speed advantages while achieving higher performance. We extract only one scale patch-level descriptors from global descriptors in the feature extraction stage. Then we design a trainable feature matcher to exploit both the space relationships and the visual appearance of the features, which is based on the attention mechanism. Extensive experiments on difficult datasets show that the proposed approach outperforming previous other advanced learning approaches, and achieving even higher inference speed. Our system has 14 times less params than Patch-NetVLAD, 6.8 times lower theoretical FLOPs, and run faster 21 and 33 times in feature extraction and feature matching. Moreover, the performance of our approach is 0.5% better than Patch-NetVLAD in Recall@1. We used subsets of Mapillary Street Level Sequences dataset to conduct experiments for all other challenging conditions. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","461.4 Ergonomics and Human Factors Engineering;723 Computer Software, Data Handling and Applications;723.5 Computer Applications;741.2 Vision;802.3 Chemical Operations",Computer vision for automation;Deep learning;Detection system;Features extraction;Image localization;Learning-based approach;Loop closure;Performance;Place recognition;Visual place recognition,Augmented reality;Computer vision;Deep learning;E-learning;Extraction,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Huang, Rui; (1) Huang, Ze; (1) Su, Songzhi; ","(1) School of Information, Xiamen University, Fujian, Xiamen; 361005, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""computer vision"", ""deep learning"", ""e-learning"", ""extraction""]","[""computer vision"", ""deep learning"", ""e-learning"", ""extraction""]",computer vision;deep learning;e-learning;extraction,computer vision;education;medical;chemical;artificial intelligence,technology;industries,computer vision;education;medical;chemical;artificial intelligence,technology;industries,computer_vision deep_learning e learning extraction computer_vision_for_automation deep_learning detection_system features_extraction image_localization learning based_approach loop_closure performance place_recognition visual_place_recognition 461 4_ergonomics_and_human_factors_engineering 723_computer_software _data_handling_and_applications 723 5_computer_applications 741 2_vision 802 3_chemical_operations computer_vision education medical chemical artificial_intelligence,computer_vision deep_learning e learning extraction,computer_vision_for_automation deep_learning detection_system features_extraction image_localization learning based_approach loop_closure performance place_recognition visual_place_recognition,visual place recognition vital part image localization loop closure detection system attracted widespread interest multiple domain computer vision robotics ar vr work propose faster lighter stronger approach generate model fewer parameter spend le time inference stage designed repvgg lite backbone network architecture discriminative general network place recognition task repvgg lite speed advantage achieving higher performance extract one scale patch level descriptor global descriptor feature extraction stage design trainable feature matcher exploit space relationship visual appearance feature based attention mechanism extensive experiment difficult datasets show proposed approach outperforming previous advanced learning approach achieving even higher inference speed system 14 time le params patch netvlad 6 8 time lower theoretical flop run faster 21 33 time feature extraction feature matching moreover performance approach 0 5 better patch netvlad recall 1 used subset mapillary street level sequence dataset conduct experiment challenging condition copy 2023 author exclusive license springer nature singapore pte ltd,computer_vision deep_learning e learning extraction computer_vision_for_automation deep_learning detection_system features_extraction image_localization learning based_approach loop_closure performance place_recognition visual_place_recognition 461 4_ergonomics_and_human_factors_engineering 723_computer_software _data_handling_and_applications 723 5_computer_applications 741 2_vision 802 3_chemical_operations computer_vision education medical chemical artificial_intelligence visual place recognition vital part image localization loop closure detection system attracted widespread interest multiple domain computer vision robotics ar vr work propose faster lighter stronger approach generate model fewer parameter spend le time inference stage designed repvgg lite backbone network architecture discriminative general network place recognition task repvgg lite speed advantage achieving higher performance extract one scale patch level descriptor global descriptor feature extraction stage design trainable feature matcher exploit space relationship visual appearance feature based attention mechanism extensive experiment difficult datasets show proposed approach outperforming previous advanced learning approach achieving even higher inference speed system 14 time le params patch netvlad 6 8 time lower theoretical flop run faster 21 33 time feature extraction feature matching moreover performance approach 0 5 better patch netvlad recall 1 used subset mapillary street level sequence dataset conduct experiment challenging condition copy 2023 author exclusive license springer nature singapore pte ltd,visual place recognition vital part image localization loop closure detection system attracted widespread interest multiple domain computer vision robotics ar vr work propose faster lighter stronger approach generate model fewer parameter spend le time inference stage designed repvgg lite backbone network architecture discriminative general network place recognition task repvgg lite speed advantage achieving higher performance extract one scale patch level descriptor global descriptor feature extraction stage design trainable feature matcher exploit space relationship visual appearance feature based attention mechanism extensive experiment difficult datasets show proposed approach outperforming previous advanced learning approach achieving even higher inference speed system 14 time le params patch netvlad 6 8 time lower theoretical flop run faster 21 33 time feature extraction feature matching moreover performance approach 0 5 better patch netvlad recall 1 used subset mapillary street level sequence dataset conduct experiment challenging condition copy 2023 author exclusive license springer nature singapore pte ltdcomputer_vision deep_learning e learning extractioncomputer_vision_for_automation deep_learning detection_system features_extraction image_localization learning based_approach loop_closure performance place_recognition visual_place_recognition
342,Design and Validation of a Virtual Chemical Laboratory&#8212;An Example of Natural Science in Elementary Education,"Tsai, C.-Y., Ho, Y.-C., & Nisar, H. (2021). Design and Validation of a Virtual Chemical Laboratory—An Example of Natural Science in Elementary Education. Applied Sciences, 11(21), 10070. https://doi.org/10.3390/app112110070
",10.3390/app112110070,"In the natural science curriculum, chemistry is a very important domain. However, when conducting chemistry experiments, safety issues need to be taken seriously, and excessive material waste may be caused during the experiment. Based on the 11-year-old student science curriculum, this paper proposed a virtual chemistry laboratory, which was designed by combining a virtual experiment application with physical teaching materials. The virtual experiment application was a virtual experiment laboratory environment created by using selected experimental equipment cards in combination with augmented reality (AR) technology. The physical teaching materials included all virtual equipment required for experiment units. Each piece of equipment had corresponding cards for learners to choose from and utilize in specific experimental operations. It was hoped that students were able to achieve the desired learning effectiveness of experimental teaching while reducing the waste of experimental materials through the virtual experimental environment. This study employed the quasi-experimental and questionnaire survey methods to evaluate both learning effectiveness and learning motivation. Eighty-one students and eight elementary school teachers were surveyed as research subjects. The experimental results revealed that significant differences in learning effectiveness existed between the experimental group and control group, indicating that the application of AR technology to teaching substantively helped enhance students' learning effectiveness and motivation. In addition, the results of the teacher questionnaire demonstrated that the virtual chemistry laboratory proposed in this study could effectively assist with classroom teaching.",C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces,11-year-old student science curriculum;conducting chemistry experiments;control group;desired learning effectiveness;elementary education;excessive material waste;experiment units;experimental equipment cards;experimental materials;experimental teaching;learning motivation;natural science curriculum;physical teaching materials;questionnaire survey methods;specific experimental operations;students;virtual chemical laboratory;virtual chemistry laboratory;virtual equipment;virtual experiment application;virtual experiment laboratory environment;virtual experimental environment,augmented reality;computer aided instruction;physics education;teaching;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Tsai, C.-Y.; (1) Ho, Y.-C.; (2) Nisar, H.; ","(1) Tamkang University, Department of Electrical and Computer Engineering, 151 Yingzhuan Road, Tamsui District, Taiwan; (2) Universiti Tunku Abdul Rahman, Department of Electronic Engineering, Bandar Barat, Kampar, Malaysia; ",MDPI,-1,"[""computer aided instruction"", ""physics education"", ""teaching""]","[""computer aided instruction"", ""physics education"", ""teaching""]",computer aided instruction;physics education;teaching,education;engineering;training,technology;use cases;industries,education;engineering;training,technology;use cases;industries,computer_aided_instruction physics_education teaching 11 year old_student_science_curriculum conducting_chemistry_experiments control_group desired_learning_effectiveness elementary_education excessive_material_waste experiment_units experimental_equipment_cards experimental_materials experimental_teaching learning_motivation natural_science_curriculum physical_teaching_materials questionnaire_survey_methods specific_experimental_operations students virtual_chemical_laboratory virtual_chemistry_laboratory virtual_equipment virtual_experiment_application virtual_experiment_laboratory_environment virtual_experimental_environment c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces education engineering training,computer_aided_instruction physics_education teaching,11 year old_student_science_curriculum conducting_chemistry_experiments control_group desired_learning_effectiveness elementary_education excessive_material_waste experiment_units experimental_equipment_cards experimental_materials experimental_teaching learning_motivation natural_science_curriculum physical_teaching_materials questionnaire_survey_methods specific_experimental_operations students virtual_chemical_laboratory virtual_chemistry_laboratory virtual_equipment virtual_experiment_application virtual_experiment_laboratory_environment virtual_experimental_environment,natural science curriculum chemistry important domain however conducting chemistry experiment safety issue need taken seriously excessive material waste may caused experiment based 11 year old student science curriculum paper proposed virtual chemistry laboratory designed combining virtual experiment application physical teaching material virtual experiment application virtual experiment laboratory environment created using selected experimental equipment card combination augmented reality ar technology physical teaching material included virtual equipment required experiment unit piece equipment corresponding card learner choose utilize specific experimental operation hoped student able achieve desired learning effectiveness experimental teaching reducing waste experimental material virtual experimental environment study employed quasi experimental questionnaire survey method evaluate learning effectiveness learning motivation eighty one student eight elementary school teacher surveyed research subject experimental result revealed significant difference learning effectiveness existed experimental group control group indicating application ar technology teaching substantively helped enhance student learning effectiveness motivation addition result teacher questionnaire demonstrated virtual chemistry laboratory proposed study could effectively assist classroom teaching,computer_aided_instruction physics_education teaching 11 year old_student_science_curriculum conducting_chemistry_experiments control_group desired_learning_effectiveness elementary_education excessive_material_waste experiment_units experimental_equipment_cards experimental_materials experimental_teaching learning_motivation natural_science_curriculum physical_teaching_materials questionnaire_survey_methods specific_experimental_operations students virtual_chemical_laboratory virtual_chemistry_laboratory virtual_equipment virtual_experiment_application virtual_experiment_laboratory_environment virtual_experimental_environment c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces education engineering training natural science curriculum chemistry important domain however conducting chemistry experiment safety issue need taken seriously excessive material waste may caused experiment based 11 year old student science curriculum paper proposed virtual chemistry laboratory designed combining virtual experiment application physical teaching material virtual experiment application virtual experiment laboratory environment created using selected experimental equipment card combination augmented reality ar technology physical teaching material included virtual equipment required experiment unit piece equipment corresponding card learner choose utilize specific experimental operation hoped student able achieve desired learning effectiveness experimental teaching reducing waste experimental material virtual experimental environment study employed quasi experimental questionnaire survey method evaluate learning effectiveness learning motivation eighty one student eight elementary school teacher surveyed research subject experimental result revealed significant difference learning effectiveness existed experimental group control group indicating application ar technology teaching substantively helped enhance student learning effectiveness motivation addition result teacher questionnaire demonstrated virtual chemistry laboratory proposed study could effectively assist classroom teaching,natural science curriculum chemistry important domain however conducting chemistry experiment safety issue need taken seriously excessive material waste may caused experiment based 11 year old student science curriculum paper proposed virtual chemistry laboratory designed combining virtual experiment application physical teaching material virtual experiment application virtual experiment laboratory environment created using selected experimental equipment card combination augmented reality ar technology physical teaching material included virtual equipment required experiment unit piece equipment corresponding card learner choose utilize specific experimental operation hoped student able achieve desired learning effectiveness experimental teaching reducing waste experimental material virtual experimental environment study employed quasi experimental questionnaire survey method evaluate learning effectiveness learning motivation eighty one student eight elementary school teacher surveyed research subject experimental result revealed significant difference learning effectiveness existed experimental group control group indicating application ar technology teaching substantively helped enhance student learning effectiveness motivation addition result teacher questionnaire demonstrated virtual chemistry laboratory proposed study could effectively assist classroom teachingcomputer_aided_instruction physics_education teaching11 year old_student_science_curriculum conducting_chemistry_experiments control_group desired_learning_effectiveness elementary_education excessive_material_waste experiment_units experimental_equipment_cards experimental_materials experimental_teaching learning_motivation natural_science_curriculum physical_teaching_materials questionnaire_survey_methods specific_experimental_operations students virtual_chemical_laboratory virtual_chemistry_laboratory virtual_equipment virtual_experiment_application virtual_experiment_laboratory_environment virtual_experimental_environment
343,Dielectric Metalens: Properties and Three-Dimensional Imaging Applications,"Kim, S.-J., Kim, C., Kim, Y., Jeong, J., Choi, S., Han, W., Kim, J., & Lee, B. (2021). Dielectric Metalens: Properties and Three-Dimensional Imaging Applications. Sensors, 21(13), 4584. https://doi.org/10.3390/s21134584
",10.3390/s21134584,"Recently, optical dielectric metasurfaces, ultrathin optical skins with densely arranged dielectric nanoantennas, have arisen as next-generation technologies with merits for miniaturization and functional improvement of conventional optical components. In particular, dielectric metalenses capable of optical focusing and imaging have attracted enormous attention from academic and industrial communities of optics. They can offer cutting-edge lensing functions owing to arbitrary wavefront encoding, polarization tunability, high efficiency, large diffraction angle, strong dispersion, and novel ultracompact integration methods. Based on the properties, dielectric metalenses have been applied to numerous three-dimensional imaging applications including wearable augmented or virtual reality displays with depth information, and optical sensing of three-dimensional position of object and various light properties. In this paper, we introduce the properties of optical dielectric metalenses, and review the working principles and recent advances in three-dimensional imaging applications based on them. The authors envision that the dielectric metalens and metasurface technologies could make breakthroughs for a wide range of compact optical systems for three-dimensional display and sensing.","A4280A Optical lenses and mirrors;A4215E Optical system design;A4270T Optical metamaterials;A4284 Nanophotonic devices and technology;B4110 Optical materials;B4146 Nanophotonic devices and technology;B4190 Other optical system components;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality",arbitrary wavefront encoding;compact optical systems;conventional optical components;cutting-edge lensing;densely arranged dielectric nanoantennas;dielectric metalens;functional improvement;light properties;metasurface technologies;next-generation technologies;optical dielectric metalenses;optical dielectric metasurfaces;optical focusing imaging;optical sensing;particular metalenses;three-dimensional display;three-dimensional imaging applications;ultrathin optical skins;virtual reality displays;wearable augmented reality displays,augmented reality;lenses;light polarisation;nanophotonics;optical arrays;optical design techniques;optical focusing;optical metamaterials;plasmonics;skin;three-dimensional displays;virtual reality,2021,Journal article (JA),Sensors (Switzerland),"(1) Kim, S.-J.; (2) Kim, C.; (2) Kim, Y.; (3) Jeong, J.; (1) Choi, S.; (1) Han, W.; (1) Kim, J.; (2) Lee, B.; ","(1) Myongji University, Department of Physics, Myongjiro 116, Namdong, Cheoin, Korea, Republic of; (2) Seoul National University, Inter-University Semiconductor Research Center, Gwanak-Gu Gwanakro 1, Korea, Republic of; (3) Korea Electronics Technology Institute, Hologram Research Center, 8 Floor, 11, World cup buk-ro 54-gil, Mapo, Korea, Republic of; ",MDPI,-1,"[""lenses"", ""light polarisation"", ""nanophotonics"", ""optical arrays"", ""optical design techniques"", ""optical focusing"", ""optical metamaterials"", ""plasmonics"", ""skin"", ""three-dimensional displays""]","[""lenses"", ""light polarisation"", ""nanophotonics"", ""optical arrays"", ""optical design techniques"", ""optical focusing"", ""optical metamaterials"", ""plasmonics"", ""skin"", ""three-dimensional displays""]",lenses;light polarisation;nanophotonics;optical arrays;optical design techniques;optical focusing;optical metamaterials;plasmonics;skin;three-dimensional displays,other;input;medical;optics;chemical;metals and mining;display technology;human factors;human-computer interaction,other;displays;end users and user experience;industries;technology,other;input;medical;optics;chemical;metals and mining;display technology;human factors;human-computer interaction,other;displays;end users and user experience;industries;technology,lenses light_polarisation nanophotonics optical_arrays optical_design_techniques optical_focusing optical_metamaterials plasmonics skin three dimensional_displays arbitrary_wavefront_encoding compact_optical_systems conventional_optical_components cutting edge_lensing densely_arranged_dielectric_nanoantennas dielectric_metalens functional_improvement light_properties metasurface_technologies next generation_technologies optical_dielectric_metalenses optical_dielectric_metasurfaces optical_focusing_imaging optical_sensing particular_metalenses three dimensional_display three dimensional_imaging_applications ultrathin_optical_skins virtual_reality_displays wearable_augmented_reality_displays a4280a_optical_lenses_and_mirrors a4215e_optical_system_design a4270t_optical_metamaterials a4284_nanophotonic_devices_and_technology b4110_optical_materials b4146_nanophotonic_devices_and_technology b4190_other_optical_system_components b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality other input medical optics chemical metals_and_mining display_technology human_factors human computer_interaction,lenses light_polarisation nanophotonics optical_arrays optical_design_techniques optical_focusing optical_metamaterials plasmonics skin three dimensional_displays,arbitrary_wavefront_encoding compact_optical_systems conventional_optical_components cutting edge_lensing densely_arranged_dielectric_nanoantennas dielectric_metalens functional_improvement light_properties metasurface_technologies next generation_technologies optical_dielectric_metalenses optical_dielectric_metasurfaces optical_focusing_imaging optical_sensing particular_metalenses three dimensional_display three dimensional_imaging_applications ultrathin_optical_skins virtual_reality_displays wearable_augmented_reality_displays,recently optical dielectric metasurfaces ultrathin optical skin densely arranged dielectric nanoantennas arisen next generation technology merit miniaturization functional improvement conventional optical component particular dielectric metalenses capable optical focusing imaging attracted enormous attention academic industrial community optic offer cutting edge lensing function owing arbitrary wavefront encoding polarization tunability high efficiency large diffraction angle strong dispersion novel ultracompact integration method based property dielectric metalenses applied numerous three dimensional imaging application including wearable augmented virtual reality display depth information optical sensing three dimensional position object various light property paper introduce property optical dielectric metalenses review working principle recent advance three dimensional imaging application based author envision dielectric metalens metasurface technology could make breakthrough wide range compact optical system three dimensional display sensing,lenses light_polarisation nanophotonics optical_arrays optical_design_techniques optical_focusing optical_metamaterials plasmonics skin three dimensional_displays arbitrary_wavefront_encoding compact_optical_systems conventional_optical_components cutting edge_lensing densely_arranged_dielectric_nanoantennas dielectric_metalens functional_improvement light_properties metasurface_technologies next generation_technologies optical_dielectric_metalenses optical_dielectric_metasurfaces optical_focusing_imaging optical_sensing particular_metalenses three dimensional_display three dimensional_imaging_applications ultrathin_optical_skins virtual_reality_displays wearable_augmented_reality_displays a4280a_optical_lenses_and_mirrors a4215e_optical_system_design a4270t_optical_metamaterials a4284_nanophotonic_devices_and_technology b4110_optical_materials b4146_nanophotonic_devices_and_technology b4190_other_optical_system_components b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality other input medical optics chemical metals_and_mining display_technology human_factors human computer_interaction recently optical dielectric metasurfaces ultrathin optical skin densely arranged dielectric nanoantennas arisen next generation technology merit miniaturization functional improvement conventional optical component particular dielectric metalenses capable optical focusing imaging attracted enormous attention academic industrial community optic offer cutting edge lensing function owing arbitrary wavefront encoding polarization tunability high efficiency large diffraction angle strong dispersion novel ultracompact integration method based property dielectric metalenses applied numerous three dimensional imaging application including wearable augmented virtual reality display depth information optical sensing three dimensional position object various light property paper introduce property optical dielectric metalenses review working principle recent advance three dimensional imaging application based author envision dielectric metalens metasurface technology could make breakthrough wide range compact optical system three dimensional display sensing,recently optical dielectric metasurfaces ultrathin optical skin densely arranged dielectric nanoantennas arisen next generation technology merit miniaturization functional improvement conventional optical component particular dielectric metalenses capable optical focusing imaging attracted enormous attention academic industrial community optic offer cutting edge lensing function owing arbitrary wavefront encoding polarization tunability high efficiency large diffraction angle strong dispersion novel ultracompact integration method based property dielectric metalenses applied numerous three dimensional imaging application including wearable augmented virtual reality display depth information optical sensing three dimensional position object various light property paper introduce property optical dielectric metalenses review working principle recent advance three dimensional imaging application based author envision dielectric metalens metasurface technology could make breakthrough wide range compact optical system three dimensional display sensinglenses light_polarisation nanophotonics optical_arrays optical_design_techniques optical_focusing optical_metamaterials plasmonics skin three dimensional_displaysarbitrary_wavefront_encoding compact_optical_systems conventional_optical_components cutting edge_lensing densely_arranged_dielectric_nanoantennas dielectric_metalens functional_improvement light_properties metasurface_technologies next generation_technologies optical_dielectric_metalenses optical_dielectric_metasurfaces optical_focusing_imaging optical_sensing particular_metalenses three dimensional_display three dimensional_imaging_applications ultrathin_optical_skins virtual_reality_displays wearable_augmented_reality_displays
344,Practical design for holographic head-mounted display system using holographic printing technology,"Hwang, L., Hong, K., Choi, J., & Lee, S. (2023). Practical design for holographic head-mounted display system using holographic printing technology. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2655308
",10.1117/12.2655308,"We propose a holographic printing technology for head-mounted display through practical design in hologram recording and reconstruction. Most head-mounted displays are designed based on waveguide type and analog holographic optical elements, resulting in disruption of the uniformity of the image because of the difference between the initial recording conditions and the source image. This problem can be solved using holographic printing technology to modulate different diffraction efficiencies for each holographic element. This study uses a digital holographic screen that can fabricate and reconstruct augmented reality images of 1.17"", 1.76"", and 2.35"" in a field of view of 28.07&deg;, 41.11&deg;, and 53.13&deg;, respectively, at a distance of 53.33 mm from the eye. Moreover, augmented images are realized with higher diffraction efficiency than conventional methods, simplifying the design and facilitating mass production of uniformed products using digital holographic printing technology. &copy; 2023 SPIE.","714.3 Waveguides;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;743 Holography;913.1 Production Engineering",Condition;Head mounted display systems;Head-mounted-displays;Hologram reconstruction;Hologram recording;Holographic elements;Holographic printing;Near-eye display;Printing technologies;Source images,Augmented reality;Diffraction efficiency;Helmet mounted displays;Holograms;Holographic displays;Holographic optical elements;Image recording;Product design,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Hwang, L.H.; (2) Hong, K.P.; (2) Choi, J.W.; (3) Lee, S.H.; ","(1) Department of Plasma-Bio-Display, Kwangwoon University, Korea, Republic of; (2) Department of Immersive Content Convergence, Kwangwoon University, Korea, Republic of; (3) Ingenium College, Kwangwoon University, Korea, Republic of; ",SPIE,-1,"[""diffraction efficiency"", ""helmet mounted displays"", ""holograms"", ""holographic displays"", ""holographic optical elements"", ""image recording"", ""product design""]","[""diffraction efficiency"", ""helmet mounted displays"", ""holograms"", ""holographic displays"", ""holographic optical elements"", ""image recording"", ""product design""]",diffraction efficiency;helmet mounted displays;holograms;holographic displays;holographic optical elements;image recording;product design,other;graphics;optics;display technology;wearables;human-computer interaction;manufacturing,other;displays;industries;end users and user experience;technology,other;graphics;optics;display technology;wearables;human-computer interaction;manufacturing,other;displays;industries;end users and user experience;technology,diffraction_efficiency helmet_mounted_displays holograms holographic_displays holographic_optical_elements image_recording product_design condition head_mounted_display_systems head mounted displays hologram_reconstruction hologram_recording holographic_elements holographic_printing near eye_display printing_technologies source_images 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 743_holography 913 1_production_engineering other graphics optics display_technology wearables human computer_interaction manufacturing,diffraction_efficiency helmet_mounted_displays holograms holographic_displays holographic_optical_elements image_recording product_design,condition head_mounted_display_systems head mounted displays hologram_reconstruction hologram_recording holographic_elements holographic_printing near eye_display printing_technologies source_images,propose holographic printing technology head mounted display practical design hologram recording reconstruction head mounted display designed based waveguide type analog holographic optical element resulting disruption uniformity image difference initial recording condition source image problem solved using holographic printing technology modulate different diffraction efficiency holographic element study us digital holographic screen fabricate reconstruct augmented reality image 1 17 1 76 2 35 field view 28 07 deg 41 11 deg 53 13 deg respectively distance 53 33 mm eye moreover augmented image realized higher diffraction efficiency conventional method simplifying design facilitating mass production uniformed product using digital holographic printing technology copy 2023 spie,diffraction_efficiency helmet_mounted_displays holograms holographic_displays holographic_optical_elements image_recording product_design condition head_mounted_display_systems head mounted displays hologram_reconstruction hologram_recording holographic_elements holographic_printing near eye_display printing_technologies source_images 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 743_holography 913 1_production_engineering other graphics optics display_technology wearables human computer_interaction manufacturing propose holographic printing technology head mounted display practical design hologram recording reconstruction head mounted display designed based waveguide type analog holographic optical element resulting disruption uniformity image difference initial recording condition source image problem solved using holographic printing technology modulate different diffraction efficiency holographic element study us digital holographic screen fabricate reconstruct augmented reality image 1 17 1 76 2 35 field view 28 07 deg 41 11 deg 53 13 deg respectively distance 53 33 mm eye moreover augmented image realized higher diffraction efficiency conventional method simplifying design facilitating mass production uniformed product using digital holographic printing technology copy 2023 spie,propose holographic printing technology head mounted display practical design hologram recording reconstruction head mounted display designed based waveguide type analog holographic optical element resulting disruption uniformity image difference initial recording condition source image problem solved using holographic printing technology modulate different diffraction efficiency holographic element study us digital holographic screen fabricate reconstruct augmented reality image 1 17 1 76 2 35 field view 28 07 deg 41 11 deg 53 13 deg respectively distance 53 33 mm eye moreover augmented image realized higher diffraction efficiency conventional method simplifying design facilitating mass production uniformed product using digital holographic printing technology copy 2023 spiediffraction_efficiency helmet_mounted_displays holograms holographic_displays holographic_optical_elements image_recording product_designcondition head_mounted_display_systems head mounted displays hologram_reconstruction hologram_recording holographic_elements holographic_printing near eye_display printing_technologies source_images
345,Research on Intelligent Patrol Inspection of Power Line based on Hybrid reality Technology,"Jin, H., Gang, Y., Deng, X., Zhao, J., & Li, D. (2022). Research on Intelligent Patrol Inspection of Power Line based on Hybrid reality Technology. 2022 4th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI). https://doi.org/10.1109/mlbdbi58171.2022.00045
",10.1109/MLBDBI58171.2022.00045,"In order to solve the problem of low image resolution and detection accuracy of power line inspection system in complex environment, an intelligent inspection system of power line based on MR technology is proposed. Based on Mixed Reality (MR) technology, the whole architecture of intelligent patrol system is designed, which includes operation interface, comprehensive analysis, guidance and supervision, etc., and the real-time image of the line is obtained by the combination of virtual and reality. Combined with the characteristics of human eyes, a power line detection method with linear edge is proposed to further improve the image processing ability of the system. The proposed method is tested based on the hybrid reality platform, and the experimental results show that the designed power line inspection system can accurately detect the obstacles in the line in a short time, and the detection error is small.","B6135 Optical, image and video signal processing;B0170L Inspection and quality control;B8130B Power cables;C5260B Computer vision and image processing techniques;C6130V Virtual reality",hybrid reality technology;image processing ability;intelligent patrol inspection;mixed reality technology;MR technology;power line detection method;power line inspection system;virtual reality,augmented reality;image resolution;inspection;power cables,2022,Conference article (CA),"2022 4th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","(1) Jin, H.; (1) Gang, Y.; (1) Deng, X.; (1) Zhao, J.; (2) Li, D.; ","(1) Liaoning Electric Power Energy Development Group Co., Ltd., China; (2) State Grid Liaoning Information and Communication Company, China; ",IEEE,-1,"[""image resolution"", ""inspection"", ""power cables""]","[""image resolution"", ""inspection"", ""power cables""]",image resolution;inspection;power cables,"other;graphics;inspection, safety and quality;networks",technology;other;use cases,"other;graphics;inspection, safety and quality;networks",technology;other;use cases,image_resolution inspection power_cables hybrid_reality_technology image_processing_ability intelligent_patrol_inspection mixed_reality_technology mr_technology power_line_detection_method power_line_inspection_system virtual_reality b6135_optical _image_and_video_signal_processing b0170l_inspection_and_quality_control b8130b_power_cables c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality other graphics inspection _safety_and_quality networks,image_resolution inspection power_cables,hybrid_reality_technology image_processing_ability intelligent_patrol_inspection mixed_reality_technology mr_technology power_line_detection_method power_line_inspection_system virtual_reality,order solve problem low image resolution detection accuracy power line inspection system complex environment intelligent inspection system power line based mr technology proposed based mixed reality mr technology whole architecture intelligent patrol system designed includes operation interface comprehensive analysis guidance supervision etc real time image line obtained combination virtual reality combined characteristic human eye power line detection method linear edge proposed improve image processing ability system proposed method tested based hybrid reality platform experimental result show designed power line inspection system accurately detect obstacle line short time detection error small,image_resolution inspection power_cables hybrid_reality_technology image_processing_ability intelligent_patrol_inspection mixed_reality_technology mr_technology power_line_detection_method power_line_inspection_system virtual_reality b6135_optical _image_and_video_signal_processing b0170l_inspection_and_quality_control b8130b_power_cables c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality other graphics inspection _safety_and_quality networks order solve problem low image resolution detection accuracy power line inspection system complex environment intelligent inspection system power line based mr technology proposed based mixed reality mr technology whole architecture intelligent patrol system designed includes operation interface comprehensive analysis guidance supervision etc real time image line obtained combination virtual reality combined characteristic human eye power line detection method linear edge proposed improve image processing ability system proposed method tested based hybrid reality platform experimental result show designed power line inspection system accurately detect obstacle line short time detection error small,order solve problem low image resolution detection accuracy power line inspection system complex environment intelligent inspection system power line based mr technology proposed based mixed reality mr technology whole architecture intelligent patrol system designed includes operation interface comprehensive analysis guidance supervision etc real time image line obtained combination virtual reality combined characteristic human eye power line detection method linear edge proposed improve image processing ability system proposed method tested based hybrid reality platform experimental result show designed power line inspection system accurately detect obstacle line short time detection error smallimage_resolution inspection power_cableshybrid_reality_technology image_processing_ability intelligent_patrol_inspection mixed_reality_technology mr_technology power_line_detection_method power_line_inspection_system virtual_reality
346,Combinatorial Auction-enabled Dependency-Aware Offloading Strategy in Mobile Edge Computing,"Kang, H., Li, M., Fan, S., & Cai, W. (2023). Combinatorial Auction-enabled Dependency-Aware Offloading Strategy in Mobile Edge Computing. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118890
",10.1109/WCNC55385.2023.10118890,"Mobile Edge Computing (MEC) enables computation offloading from resource-constrained mobile devices to edge servers in close vicinity, effectively promoting the user experience on emerging interactive multimedia applications such as virtual/augmented reality, mobile gaming, and mobile video editing. However, most contemporary MEC offloading research disregards the interdependencies between partitioned subtasks of application. Also, few studies focused on application topologies have neglected to design effective incentives to encourage edge servers to provide offloading services. In this paper, we propose a dependency-aware offloading algorithm based on a multi-round truthful combinatorial reverse auction (MTCRA) to address the social welfare maximization problem in the paradigm of MEC. Building on the topology of directed acyclic graphs (DAGs) modeled from applications, we discuss the complementarity and substitutability of subtasks in the context of combinatorial auction. Theoretical analysis shows that the presented auction mechanism achieves computing efficiency while maintaining desirable economic features like truthfulness, individual rationality, and budget balance. Simulation results demonstrate that the proposed algorithm achieves high social welfare regarding reduced execution time and good economic benefits for MEC servers.","B6250F Mobile radio systems;C1160 Combinatorial mathematics;C1180 Optimisation techniques;C6130V Virtual reality;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing;C7410F Communications computing",application topologies;combinatorial auction-enabled dependency-aware offloading strategy;computation offloading;contemporary MEC;dependency-aware offloading algorithm;edge servers;interactive multimedia applications;MEC servers;mobile Edge Computing;Mobile Edge Computing;mobile gaming;mobile video editing;multiround truthful combinatorial reverse auction;offloading services;presented auction mechanism;resource-constrained mobile devices,augmented reality;cloud computing;directed graphs;edge computing;electronic commerce;mobile computing;optimisation;resource allocation;telecommunication computing,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Kang, H.; (1) Li, M.; (1) Fan, S.; (1) Cai, W.; ","(1) Chinese University of Hong Kong, School of Science and Engineering, China; ",IEEE,-1,"[""cloud computing"", ""directed graphs"", ""edge computing"", ""electronic commerce"", ""mobile computing"", ""optimization"", ""resource allocation"", ""telecommunication computing""]","[""cloud computing"", ""directed graphs"", ""edge computing"", ""electronic commerce"", ""mobile computing"", ""optimization"", ""resource allocation"", ""telecommunication computing""]",cloud computing;directed graphs;edge computing;electronic commerce;mobile computing;optimization;resource allocation;telecommunication computing,input;sales and marketing;business performance metrics;telecommunication;developers;geospatial;business planning and management;networks,technology;business;industries,input;sales and marketing;business performance metrics;telecommunication;developers;geospatial;business planning and management;networks,technology;business;industries,cloud_computing directed_graphs edge_computing electronic_commerce mobile_computing optimization resource_allocation telecommunication_computing application_topologies combinatorial_auction enabled_dependency aware_offloading_strategy computation_offloading contemporary_mec dependency aware_offloading_algorithm edge_servers interactive_multimedia_applications mec_servers mobile_edge_computing mobile_edge_computing mobile_gaming mobile_video_editing multiround_truthful_combinatorial_reverse_auction offloading_services presented_auction_mechanism resource constrained_mobile_devices b6250f_mobile_radio_systems c1160_combinatorial_mathematics c1180_optimisation_techniques c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7410f_communications_computing input sales_and_marketing business_performance_metrics telecommunication developers geospatial business_planning_and_management networks,cloud_computing directed_graphs edge_computing electronic_commerce mobile_computing optimization resource_allocation telecommunication_computing,application_topologies combinatorial_auction enabled_dependency aware_offloading_strategy computation_offloading contemporary_mec dependency aware_offloading_algorithm edge_servers interactive_multimedia_applications mec_servers mobile_edge_computing mobile_edge_computing mobile_gaming mobile_video_editing multiround_truthful_combinatorial_reverse_auction offloading_services presented_auction_mechanism resource constrained_mobile_devices,mobile edge computing mec enables computation offloading resource constrained mobile device edge server close vicinity effectively promoting user experience emerging interactive multimedia application virtual augmented reality mobile gaming mobile video editing however contemporary mec offloading research disregard interdependency partitioned subtasks application also study focused application topology neglected design effective incentive encourage edge server provide offloading service paper propose dependency aware offloading algorithm based multi round truthful combinatorial reverse auction mtcra address social welfare maximization problem paradigm mec building topology directed acyclic graph dag modeled application discus complementarity substitutability subtasks context combinatorial auction theoretical analysis show presented auction mechanism achieves computing efficiency maintaining desirable economic feature like truthfulness individual rationality budget balance simulation result demonstrate proposed algorithm achieves high social welfare regarding reduced execution time good economic benefit mec server,cloud_computing directed_graphs edge_computing electronic_commerce mobile_computing optimization resource_allocation telecommunication_computing application_topologies combinatorial_auction enabled_dependency aware_offloading_strategy computation_offloading contemporary_mec dependency aware_offloading_algorithm edge_servers interactive_multimedia_applications mec_servers mobile_edge_computing mobile_edge_computing mobile_gaming mobile_video_editing multiround_truthful_combinatorial_reverse_auction offloading_services presented_auction_mechanism resource constrained_mobile_devices b6250f_mobile_radio_systems c1160_combinatorial_mathematics c1180_optimisation_techniques c6130v_virtual_reality c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing c7410f_communications_computing input sales_and_marketing business_performance_metrics telecommunication developers geospatial business_planning_and_management networks mobile edge computing mec enables computation offloading resource constrained mobile device edge server close vicinity effectively promoting user experience emerging interactive multimedia application virtual augmented reality mobile gaming mobile video editing however contemporary mec offloading research disregard interdependency partitioned subtasks application also study focused application topology neglected design effective incentive encourage edge server provide offloading service paper propose dependency aware offloading algorithm based multi round truthful combinatorial reverse auction mtcra address social welfare maximization problem paradigm mec building topology directed acyclic graph dag modeled application discus complementarity substitutability subtasks context combinatorial auction theoretical analysis show presented auction mechanism achieves computing efficiency maintaining desirable economic feature like truthfulness individual rationality budget balance simulation result demonstrate proposed algorithm achieves high social welfare regarding reduced execution time good economic benefit mec server,mobile edge computing mec enables computation offloading resource constrained mobile device edge server close vicinity effectively promoting user experience emerging interactive multimedia application virtual augmented reality mobile gaming mobile video editing however contemporary mec offloading research disregard interdependency partitioned subtasks application also study focused application topology neglected design effective incentive encourage edge server provide offloading service paper propose dependency aware offloading algorithm based multi round truthful combinatorial reverse auction mtcra address social welfare maximization problem paradigm mec building topology directed acyclic graph dag modeled application discus complementarity substitutability subtasks context combinatorial auction theoretical analysis show presented auction mechanism achieves computing efficiency maintaining desirable economic feature like truthfulness individual rationality budget balance simulation result demonstrate proposed algorithm achieves high social welfare regarding reduced execution time good economic benefit mec servercloud_computing directed_graphs edge_computing electronic_commerce mobile_computing optimization resource_allocation telecommunication_computingapplication_topologies combinatorial_auction enabled_dependency aware_offloading_strategy computation_offloading contemporary_mec dependency aware_offloading_algorithm edge_servers interactive_multimedia_applications mec_servers mobile_edge_computing mobile_edge_computing mobile_gaming mobile_video_editing multiround_truthful_combinatorial_reverse_auction offloading_services presented_auction_mechanism resource constrained_mobile_devices
347,"A fire reconnaissance robot based on SLAM position, thermal imaging technologies, and AR display","Li, Feng, Niu, Shi, Wu, & Song. (2019). A Fire Reconnaissance Robot Based on SLAM Position, Thermal Imaging Technologies, and AR Display. Sensors, 19(22), 5036. https://doi.org/10.3390/s19225036
",10.3390/s19225036,"Due to hot toxic smoke and unknown risks under fire conditions, detection and relevant reconnaissance are significant in avoiding casualties. A fire reconnaissance robot was therefore developed to assist in the problem by offering important fire information to fire fighters. The robot consists of three main systems, a display operating system, video surveillance, and mapping and positioning navigation. Augmented reality (AR) goggle technology with a display operating system was also developed to free fire fighters' hands, which enables them to focus on rescuing processes and not system operation. Considering smoke disturbance, a thermal imaging video surveillance system was included to extract information from the complicated fire conditions. Meanwhile, a simultaneous localization and mapping (SLAM) technology was adopted to build the map, together with the help of a mapping and positioning navigation system. This can provide a real-time map under the rapidly changing fire conditions to guide the fire fighters to the fire sources or the trapped occupants. Based on our experiments, it was found that all the tested system components work quite well under the fire conditions, while the video surveillance system produces clear images under dense smoke and a high-temperature environment; SLAM shows a high accuracy with an average error of less than 3.43%; the positioning accuracy error is 0.31 m; and the maximum error for the navigation system is 3.48%. The developed fire reconnaissance robot can provide a practically important platform to improve fire rescue efficiency to reduce the fire casualties of fire fighters.","B6135 Optical, image and video signal processing;B7230G Image sensors;C3120C Spatial variables control;C3390C Mobile robots;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130V Virtual reality;C7135 Emergency management",AR display;augmented reality Goggle technology;complicated fire conditions;display operating system;fire casualties;fire information;fire reconnaissance robot;fire rescue efficiency;fire sources;free fire fighters;hot toxic smoke;positioning accuracy error;positioning navigation system;real-time map;simultaneous localization and mapping technology;SLAM position;tested system components;thermal imaging video surveillance system,augmented reality;emergency management;emergency services;fires;infrared imaging;navigation;position control;rescue robots;robot vision;SLAM (robots);smoke;video surveillance,2019,Journal article (JA),Sensors (Switzerland),(1) Sen Li; (1) Chunyong Feng; (1) Yunchen Niu; (2) Shi; (1) Zeqi Wu; (1) Huaitao Song; ,"(1) Zhengzhou University of Light Industry, School of Building Environment Engineering, 5 Dongfeng Road, Henan, China; (2) RMIT University, Civil and Infrastructure Engineering Discipline, Melbourne, VIC 3000, Australia; ",MDPI,-1,"[""emergency management"", ""emergency services"", ""fires"", ""infrared imaging"", ""navigation"", ""position control"", ""rescue robots"", ""robot vision"", ""slam robotics"", ""smoke"", ""video surveillance""]","[""emergency management"", ""emergency services"", ""fires"", ""infrared imaging"", ""navigation"", ""position control"", ""rescue robots"", ""robot vision"", ""slam robotics"", ""smoke"", ""video surveillance""]",emergency management;emergency services;fires;infrared imaging;navigation;position control;rescue robots;robot vision;slam robotics;smoke;video surveillance,computer vision;security;robotics;input;sensors;human-computer interaction;navigation;emergency response,technology;end users and user experience;use cases;industries,computer vision;security;robotics;input;sensors;human-computer interaction;navigation;emergency response,technology;end users and user experience;use cases;industries,emergency_management emergency_services fires infrared_imaging navigation position_control rescue_robots robot_vision slam_robotics smoke video_surveillance ar_display augmented_reality_goggle_technology complicated_fire_conditions display_operating_system fire_casualties fire_information fire_reconnaissance_robot fire_rescue_efficiency fire_sources free_fire_fighters hot_toxic_smoke positioning_accuracy_error positioning_navigation_system real time_map simultaneous_localization_and_mapping_technology slam_position tested_system_components thermal_imaging_video_surveillance_system b6135_optical _image_and_video_signal_processing b7230g_image_sensors c3120c_spatial_variables_control c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130v_virtual_reality c7135_emergency_management computer_vision security robotics input sensors human computer_interaction navigation emergency_response,emergency_management emergency_services fires infrared_imaging navigation position_control rescue_robots robot_vision slam_robotics smoke video_surveillance,ar_display augmented_reality_goggle_technology complicated_fire_conditions display_operating_system fire_casualties fire_information fire_reconnaissance_robot fire_rescue_efficiency fire_sources free_fire_fighters hot_toxic_smoke positioning_accuracy_error positioning_navigation_system real time_map simultaneous_localization_and_mapping_technology slam_position tested_system_components thermal_imaging_video_surveillance_system,due hot toxic smoke unknown risk fire condition detection relevant reconnaissance significant avoiding casualty fire reconnaissance robot therefore developed assist problem offering important fire information fire fighter robot consists three main system display operating system video surveillance mapping positioning navigation augmented reality ar goggle technology display operating system also developed free fire fighter hand enables focus rescuing process system operation considering smoke disturbance thermal imaging video surveillance system included extract information complicated fire condition meanwhile simultaneous localization mapping slam technology adopted build map together help mapping positioning navigation system provide real time map rapidly changing fire condition guide fire fighter fire source trapped occupant based experiment found tested system component work quite well fire condition video surveillance system produce clear image dense smoke high temperature environment slam show high accuracy average error le 3 43 positioning accuracy error 0 31 maximum error navigation system 3 48 developed fire reconnaissance robot provide practically important platform improve fire rescue efficiency reduce fire casualty fire fighter,emergency_management emergency_services fires infrared_imaging navigation position_control rescue_robots robot_vision slam_robotics smoke video_surveillance ar_display augmented_reality_goggle_technology complicated_fire_conditions display_operating_system fire_casualties fire_information fire_reconnaissance_robot fire_rescue_efficiency fire_sources free_fire_fighters hot_toxic_smoke positioning_accuracy_error positioning_navigation_system real time_map simultaneous_localization_and_mapping_technology slam_position tested_system_components thermal_imaging_video_surveillance_system b6135_optical _image_and_video_signal_processing b7230g_image_sensors c3120c_spatial_variables_control c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130v_virtual_reality c7135_emergency_management computer_vision security robotics input sensors human computer_interaction navigation emergency_response due hot toxic smoke unknown risk fire condition detection relevant reconnaissance significant avoiding casualty fire reconnaissance robot therefore developed assist problem offering important fire information fire fighter robot consists three main system display operating system video surveillance mapping positioning navigation augmented reality ar goggle technology display operating system also developed free fire fighter hand enables focus rescuing process system operation considering smoke disturbance thermal imaging video surveillance system included extract information complicated fire condition meanwhile simultaneous localization mapping slam technology adopted build map together help mapping positioning navigation system provide real time map rapidly changing fire condition guide fire fighter fire source trapped occupant based experiment found tested system component work quite well fire condition video surveillance system produce clear image dense smoke high temperature environment slam show high accuracy average error le 3 43 positioning accuracy error 0 31 maximum error navigation system 3 48 developed fire reconnaissance robot provide practically important platform improve fire rescue efficiency reduce fire casualty fire fighter,due hot toxic smoke unknown risk fire condition detection relevant reconnaissance significant avoiding casualty fire reconnaissance robot therefore developed assist problem offering important fire information fire fighter robot consists three main system display operating system video surveillance mapping positioning navigation augmented reality ar goggle technology display operating system also developed free fire fighter hand enables focus rescuing process system operation considering smoke disturbance thermal imaging video surveillance system included extract information complicated fire condition meanwhile simultaneous localization mapping slam technology adopted build map together help mapping positioning navigation system provide real time map rapidly changing fire condition guide fire fighter fire source trapped occupant based experiment found tested system component work quite well fire condition video surveillance system produce clear image dense smoke high temperature environment slam show high accuracy average error le 3 43 positioning accuracy error 0 31 maximum error navigation system 3 48 developed fire reconnaissance robot provide practically important platform improve fire rescue efficiency reduce fire casualty fire fighteremergency_management emergency_services fires infrared_imaging navigation position_control rescue_robots robot_vision slam_robotics smoke video_surveillancear_display augmented_reality_goggle_technology complicated_fire_conditions display_operating_system fire_casualties fire_information fire_reconnaissance_robot fire_rescue_efficiency fire_sources free_fire_fighters hot_toxic_smoke positioning_accuracy_error positioning_navigation_system real time_map simultaneous_localization_and_mapping_technology slam_position tested_system_components thermal_imaging_video_surveillance_system
348,Text Me if You Can: Investigating Text Input Methods for Cyclists,"Matviienko, A., Durand-Pierre, J.-B., Cvancar, J., & Mühlhäuser, M. (2023). Text Me if You Can: Investigating Text Input Methods for Cyclists. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585734
",10.1145/3544549.3585734,"Cycling is emerging as a relevant alternative to cars. However, the more people commute by bicycle, the higher the number of cyclists who use their smartphones on the go and endanger road safety. To better understand input while cycling, in this paper, we present the design and evaluation of three text input methods for cyclists: (1) touch input using smartphones, (2) midair input using a Microsoft Hololens 2, and (3) a set of ten physical buttons placed on both sides of the handlebar. We conducted a controlled indoor experiment (N = 12) on a bicycle simulator to evaluate these input methods. We found that text input via touch input was faster and less mentally demanding than input with midair gestures and physical buttons. However, the midair gestures were the least error-prone, and the physical buttons facilitated keeping both hands on the handlebars and were more intuitive and less distracting.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing;C7445 Traffic engineering computing",bicycle simulator;controlled indoor experiment;cycling;investigating text input methods;Microsoft Hololens 2;midair gestures;people commute;physical buttons;relevant alternative;road safety;smartphones,augmented reality;bicycles;gesture recognition;road safety;smart phones,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Matviienko, A.; (2) Durand-Pierre, J.-B.; (2) Cvancar, J.; (3) Mu&#776;hlha&#776;user, M.; ","(1) Kungliga Tekniska Hogskolan, Sweden; (2) Technical University of Darmstadt, Germany; (3) Technical University of Darmstadt, Telecooperation Lab, Germany; ",ACM,-1,"[""bicycles"", ""gesture recognition"", ""road safety"", ""smartphones""]","[""bicycles"", ""gesture recognition"", ""road safety"", ""smartphones""]",bicycles;gesture recognition;road safety;smartphones,"liberal arts;input;transportation;inspection, safety and quality;human factors;telecommunication",technology;industries;use cases;end users and user experience,"liberal arts;input;transportation;inspection, safety and quality;human factors;telecommunication",technology;industries;use cases;end users and user experience,bicycles gesture_recognition road_safety smartphones bicycle_simulator controlled_indoor_experiment cycling investigating_text_input_methods microsoft_hololens_2 midair_gestures people_commute physical_buttons relevant_alternative road_safety smartphones c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7445_traffic_engineering_computing liberal_arts input transportation inspection _safety_and_quality human_factors telecommunication,bicycles gesture_recognition road_safety smartphones,bicycle_simulator controlled_indoor_experiment cycling investigating_text_input_methods microsoft_hololens_2 midair_gestures people_commute physical_buttons relevant_alternative road_safety smartphones,cycling emerging relevant alternative car however people commute bicycle higher number cyclist use smartphones go endanger road safety better understand input cycling paper present design evaluation three text input method cyclist 1 touch input using smartphones 2 midair input using microsoft hololens 2 3 set ten physical button placed side handlebar conducted controlled indoor experiment n 12 bicycle simulator evaluate input method found text input via touch input faster le mentally demanding input midair gesture physical button however midair gesture least error prone physical button facilitated keeping hand handlebar intuitive le distracting,bicycles gesture_recognition road_safety smartphones bicycle_simulator controlled_indoor_experiment cycling investigating_text_input_methods microsoft_hololens_2 midair_gestures people_commute physical_buttons relevant_alternative road_safety smartphones c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7445_traffic_engineering_computing liberal_arts input transportation inspection _safety_and_quality human_factors telecommunication cycling emerging relevant alternative car however people commute bicycle higher number cyclist use smartphones go endanger road safety better understand input cycling paper present design evaluation three text input method cyclist 1 touch input using smartphones 2 midair input using microsoft hololens 2 3 set ten physical button placed side handlebar conducted controlled indoor experiment n 12 bicycle simulator evaluate input method found text input via touch input faster le mentally demanding input midair gesture physical button however midair gesture least error prone physical button facilitated keeping hand handlebar intuitive le distracting,cycling emerging relevant alternative car however people commute bicycle higher number cyclist use smartphones go endanger road safety better understand input cycling paper present design evaluation three text input method cyclist 1 touch input using smartphones 2 midair input using microsoft hololens 2 3 set ten physical button placed side handlebar conducted controlled indoor experiment n 12 bicycle simulator evaluate input method found text input via touch input faster le mentally demanding input midair gesture physical button however midair gesture least error prone physical button facilitated keeping hand handlebar intuitive le distractingbicycles gesture_recognition road_safety smartphonesbicycle_simulator controlled_indoor_experiment cycling investigating_text_input_methods microsoft_hololens_2 midair_gestures people_commute physical_buttons relevant_alternative road_safety smartphones
349,VR and AR Restoration of Urban Heritage: A Virtual Platform Mediating Disagreement from Spatial Conflicts in Korea,"Youn, H.-C., & Ryoo, S.-L. (2021). VR and AR Restoration of Urban Heritage: A Virtual Platform Mediating Disagreement from Spatial Conflicts in Korea. Buildings, 11(11), 561. https://doi.org/10.3390/buildings11110561
",10.3390/buildings11110561,"This study sought to uncover (1) the disagreement of spatial conflict between urban heritage and surrounding urban structure using two case studies from Korea&#8212;the main gate of the royal palace (Gwanghwamun) and the urban park containing celebrity graves (Hyoch'ang Park)&#8212;and (2) whether digital heritage restoration may mediate spatial conflict. A historical literature review and field surveys were conducted, with three main findings. First, the place identity of Gwanghwamun and Hyoch'ang Park, rooted in the Joso&#774;n Dynasty, was seriously damaged during the Japanese colonial period. Although there were national attempts to recover the place identities of these sites during the modern period, limitations existed. Second, the restoration of Gwanghwamun's Wo&#774;ltae (podium) and the relocation of U&#774;iyo&#774;lsa (the shrine of Hyoch'ang Park), which involved spatial transformation based on heritage, emerged in conflict with their surrounding urban structures&#8212;we identify a spatial conflict between local residents and stakeholders' memories and the histories of these sites. Third, Donu&#774;imun (the west gate of the city wall of the Joso&#774;n Dynasty) digital restoration is a case mediating the conflict by restoring a sense of place in a virtual space and activating the cultural memory of the public by showcasing properties.",C7820 Humanities computing;C6130V Virtual reality,celebrity graves;digital heritage restoration;Donu&#774;imun digital restoration;field surveys;Gwanghwamun's Wo&#774;ltae;historical literature review;Hyoch'ang Park;Japanese colonial period;Joso&#774;n Dynasty;Korea;royal palace;spatial conflict;spatial transformation;surrounding urban structure;urban heritage;virtual platform mediating disagreement;U&#774;iyo&#774;lsa,augmented reality;cultural aspects;history,2021,Journal article (JA),Buildings (Switzerland),(1) Hyun-Chul Youn; (1) Seong-Lyong Ryoo; ,"(1) Korea University, Department of Architecture, Korea, Republic of; ",MDPI,-1,"[""cultural aspects"", ""history""]","[""cultural aspects"", ""history""]",cultural aspects;history,policy;liberal arts,business;industries,policy;liberal arts,business;industries,cultural_aspects history celebrity_graves digital_heritage_restoration donu 774 imun_digital_restoration field_surveys gwanghwamun s_wo 774 ltae historical_literature_review hyoch ang_park japanese_colonial_period joso 774 n_dynasty korea royal_palace spatial_conflict spatial_transformation surrounding_urban_structure urban_heritage virtual_platform_mediating_disagreement u 774 iyo 774 lsa c7820_humanities_computing c6130v_virtual_reality policy liberal_arts,cultural_aspects history,celebrity_graves digital_heritage_restoration donu 774 imun_digital_restoration field_surveys gwanghwamun s_wo 774 ltae historical_literature_review hyoch ang_park japanese_colonial_period joso 774 n_dynasty korea royal_palace spatial_conflict spatial_transformation surrounding_urban_structure urban_heritage virtual_platform_mediating_disagreement u 774 iyo 774 lsa,study sought uncover 1 disagreement spatial conflict urban heritage surrounding urban structure using two case study korea 8212 main gate royal palace gwanghwamun urban park containing celebrity graf hyoch ang park 8212 2 whether digital heritage restoration may mediate spatial conflict historical literature review field survey conducted three main finding first place identity gwanghwamun hyoch ang park rooted joso 774 n dynasty seriously damaged japanese colonial period although national attempt recover place identity site modern period limitation existed second restoration gwanghwamun wo 774 ltae podium relocation u 774 iyo 774 lsa shrine hyoch ang park involved spatial transformation based heritage emerged conflict surrounding urban structure 8212 identify spatial conflict local resident stakeholder memory history site third donu 774 imun west gate city wall joso 774 n dynasty digital restoration case mediating conflict restoring sense place virtual space activating cultural memory public showcasing property,cultural_aspects history celebrity_graves digital_heritage_restoration donu 774 imun_digital_restoration field_surveys gwanghwamun s_wo 774 ltae historical_literature_review hyoch ang_park japanese_colonial_period joso 774 n_dynasty korea royal_palace spatial_conflict spatial_transformation surrounding_urban_structure urban_heritage virtual_platform_mediating_disagreement u 774 iyo 774 lsa c7820_humanities_computing c6130v_virtual_reality policy liberal_arts study sought uncover 1 disagreement spatial conflict urban heritage surrounding urban structure using two case study korea 8212 main gate royal palace gwanghwamun urban park containing celebrity graf hyoch ang park 8212 2 whether digital heritage restoration may mediate spatial conflict historical literature review field survey conducted three main finding first place identity gwanghwamun hyoch ang park rooted joso 774 n dynasty seriously damaged japanese colonial period although national attempt recover place identity site modern period limitation existed second restoration gwanghwamun wo 774 ltae podium relocation u 774 iyo 774 lsa shrine hyoch ang park involved spatial transformation based heritage emerged conflict surrounding urban structure 8212 identify spatial conflict local resident stakeholder memory history site third donu 774 imun west gate city wall joso 774 n dynasty digital restoration case mediating conflict restoring sense place virtual space activating cultural memory public showcasing property,study sought uncover 1 disagreement spatial conflict urban heritage surrounding urban structure using two case study korea 8212 main gate royal palace gwanghwamun urban park containing celebrity graf hyoch ang park 8212 2 whether digital heritage restoration may mediate spatial conflict historical literature review field survey conducted three main finding first place identity gwanghwamun hyoch ang park rooted joso 774 n dynasty seriously damaged japanese colonial period although national attempt recover place identity site modern period limitation existed second restoration gwanghwamun wo 774 ltae podium relocation u 774 iyo 774 lsa shrine hyoch ang park involved spatial transformation based heritage emerged conflict surrounding urban structure 8212 identify spatial conflict local resident stakeholder memory history site third donu 774 imun west gate city wall joso 774 n dynasty digital restoration case mediating conflict restoring sense place virtual space activating cultural memory public showcasing propertycultural_aspects historycelebrity_graves digital_heritage_restoration donu 774 imun_digital_restoration field_surveys gwanghwamun s_wo 774 ltae historical_literature_review hyoch ang_park japanese_colonial_period joso 774 n_dynasty korea royal_palace spatial_conflict spatial_transformation surrounding_urban_structure urban_heritage virtual_platform_mediating_disagreement u 774 iyo 774 lsa
350,Rate-Distortion Modeling for Bit Rate Constrained Point Cloud Compression,"Gao, P., Luo, S., & Paul, M. (2023). Rate-Distortion Modeling for Bit Rate Constrained Point Cloud Compression. IEEE Transactions on Circuits and Systems for Video Technology, 33(5), 2424–2438. https://doi.org/10.1109/tcsvt.2022.3223898
",10.1109/TCSVT.2022.3223898,"As being one of the main representation formats of 3D real world and well-suited for virtual reality and augmented reality applications, point clouds have gained a lot of popularity. In order to reduce the huge amount of data, a considerable amount of research on point cloud compression has been done. However, given a target bit rate, how to properly choose the color and geometry quantization parameters for compressing point clouds is still an open issue. In this paper, we propose a rate-distortion model based quantization parameter selection scheme for bit rate constrained point cloud compression. Firstly, to overcome the measurement uncertainty in evaluating the distortion of the point clouds, we propose a unified model to combine the geometry distortion and color distortion. In this model, we take into account the correlation between geometry and color variables of point clouds and derive a dimensionless quantity to represent the overall quality degradation. Then, we derive the relationships of overall distortion and bit rate with the quantization parameters. Finally, we formulate the bit rate constrained point cloud compression as a constrained minimization problem using the derived polynomial models and deduce the solution via an iterative numerical method. Experimental results show that the proposed algorithm can achieve optimal decoded point cloud quality at various target bit rates, and substantially outperform the video-rate-distortion model based point cloud compression scheme.",B6135C Image and video coding;B0260 Optimisation techniques;C5260D Video signal processing;C6130V Virtual reality,bit rate constrained point cloud compression;color distortion;geometry distortion;geometry quantization parameters;optimal decoded point cloud quality;point clouds;rate-distortion modeling;target bit rate;video-rate-distortion model based point cloud compression scheme,augmented reality;data compression;iterative methods;minimisation;polynomials;quantisation (signal);rate distortion theory;video coding;virtual reality,2023,Journal article (JA),IEEE Trans. Circuits Syst. Video Technol. (USA),"(1) Gao, P.; (2) Luo, S.; (3) Paul, M.; ","(1) Nanjing University of Aeronautics and Astronautics, College of Computer Science and Technology, China; (2) South China Normal University, School of Software, China; (3) Charles Sturt University, School of Computing and Mathematics, Bathurst, NSW 2795, Australia; ",IEEE,-1,"[""data compression"", ""iterative methods"", ""minimisation"", ""polynomials"", ""quantisation (signal)"", ""rate distortion theory"", ""video coding""]","[""data compression"", ""iterative methods"", ""minimisation"", ""polynomials"", ""quantisation (signal)"", ""rate distortion theory"", ""video coding""]",data compression;iterative methods;minimisation;polynomials;quantisation (signal);rate distortion theory;video coding,other;data;device energy management;artificial intelligence;video,technology;other;displays,other;data;device energy management;artificial intelligence;video,technology;other;displays,data_compression iterative_methods minimisation polynomials quantisation_ signal rate_distortion_theory video_coding bit_rate_constrained_point_cloud_compression color_distortion geometry_distortion geometry_quantization_parameters optimal_decoded_point_cloud_quality point_clouds rate distortion_modeling target_bit_rate video rate distortion_model_based_point_cloud_compression_scheme b6135c_image_and_video_coding b0260_optimisation_techniques c5260d_video_signal_processing c6130v_virtual_reality other data device_energy_management artificial_intelligence video,data_compression iterative_methods minimisation polynomials quantisation_ signal rate_distortion_theory video_coding,bit_rate_constrained_point_cloud_compression color_distortion geometry_distortion geometry_quantization_parameters optimal_decoded_point_cloud_quality point_clouds rate distortion_modeling target_bit_rate video rate distortion_model_based_point_cloud_compression_scheme,one main representation format 3d real world well suited virtual reality augmented reality application point cloud gained lot popularity order reduce huge amount data considerable amount research point cloud compression done however given target bit rate properly choose color geometry quantization parameter compressing point cloud still open issue paper propose rate distortion model based quantization parameter selection scheme bit rate constrained point cloud compression firstly overcome measurement uncertainty evaluating distortion point cloud propose unified model combine geometry distortion color distortion model take account correlation geometry color variable point cloud derive dimensionless quantity represent overall quality degradation derive relationship overall distortion bit rate quantization parameter finally formulate bit rate constrained point cloud compression constrained minimization problem using derived polynomial model deduce solution via iterative numerical method experimental result show proposed algorithm achieve optimal decoded point cloud quality various target bit rate substantially outperform video rate distortion model based point cloud compression scheme,data_compression iterative_methods minimisation polynomials quantisation_ signal rate_distortion_theory video_coding bit_rate_constrained_point_cloud_compression color_distortion geometry_distortion geometry_quantization_parameters optimal_decoded_point_cloud_quality point_clouds rate distortion_modeling target_bit_rate video rate distortion_model_based_point_cloud_compression_scheme b6135c_image_and_video_coding b0260_optimisation_techniques c5260d_video_signal_processing c6130v_virtual_reality other data device_energy_management artificial_intelligence video one main representation format 3d real world well suited virtual reality augmented reality application point cloud gained lot popularity order reduce huge amount data considerable amount research point cloud compression done however given target bit rate properly choose color geometry quantization parameter compressing point cloud still open issue paper propose rate distortion model based quantization parameter selection scheme bit rate constrained point cloud compression firstly overcome measurement uncertainty evaluating distortion point cloud propose unified model combine geometry distortion color distortion model take account correlation geometry color variable point cloud derive dimensionless quantity represent overall quality degradation derive relationship overall distortion bit rate quantization parameter finally formulate bit rate constrained point cloud compression constrained minimization problem using derived polynomial model deduce solution via iterative numerical method experimental result show proposed algorithm achieve optimal decoded point cloud quality various target bit rate substantially outperform video rate distortion model based point cloud compression scheme,one main representation format 3d real world well suited virtual reality augmented reality application point cloud gained lot popularity order reduce huge amount data considerable amount research point cloud compression done however given target bit rate properly choose color geometry quantization parameter compressing point cloud still open issue paper propose rate distortion model based quantization parameter selection scheme bit rate constrained point cloud compression firstly overcome measurement uncertainty evaluating distortion point cloud propose unified model combine geometry distortion color distortion model take account correlation geometry color variable point cloud derive dimensionless quantity represent overall quality degradation derive relationship overall distortion bit rate quantization parameter finally formulate bit rate constrained point cloud compression constrained minimization problem using derived polynomial model deduce solution via iterative numerical method experimental result show proposed algorithm achieve optimal decoded point cloud quality various target bit rate substantially outperform video rate distortion model based point cloud compression schemedata_compression iterative_methods minimisation polynomials quantisation_ signal rate_distortion_theory video_codingbit_rate_constrained_point_cloud_compression color_distortion geometry_distortion geometry_quantization_parameters optimal_decoded_point_cloud_quality point_clouds rate distortion_modeling target_bit_rate video rate distortion_model_based_point_cloud_compression_scheme
351,Interactive AR Applications for Nonspeaking Autistic People? - A Usability Study,"Nazari, A., Shahidi, A., Kaufman, K. M., Bondi, J. E., Alabood, L., Jaswal, V. K., Krishnamurthy, D., & Wang, M. (2023). Interactive AR Applications for Nonspeaking Autistic People? - A Usability Study. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580721
",10.1145/3544548.3580721,"About one-third of autistic people are nonspeaking, and most are never provided access to an effective alternative to speech. Thoughtfully designed AR applications could provide members of this population with structured learning opportunities, including training on skills that underlie alternative forms of communication. A fundamental step toward creating such opportunities, however, is to investigate nonspeaking autistic people's ability to tolerate a head-mounted AR device and to interact with virtual objects. We present the first study to examine the usability of an interactive AR-based application by this population. We recruited 17 nonspeaking autistic subjects to play a HoloLens 2 game we developed that involved holographic animations and buttons. Almost all subjects tolerated the device long enough to begin the game, and most completed increasingly challenging tasks that involved pressing holographic buttons. Based on the results, we discuss best practice design and process recommendations. Our findings contradict prevailing assumptions about nonspeaking autistic people and thus open up exciting possibilities for AR-based solutions for this understudied and underserved population.",C7850 Computer assistance for persons with handicaps;C6130B Graphics techniques;C6130V Virtual reality;C7830D Computer games,head-mounted AR device;holographic animations;HoloLens 2 game;interactive AR applications;nonspeaking autistic people;structured learning opportunities;usability study,augmented reality;computer animation;computer games;handicapped aids;holographic displays,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Nazari, A.; (1) Shahidi, A.; (2) Kaufman, K.M.; (2) Bondi, J.E.; (1) Alabood, L.; (2) Jaswal, V.K.; (3) Krishnamurthy, D.; (3) Wang, M.; ","(1) University of Calgary, Electrical and Software Engineering, Calgary, AB, Canada; (2) University of Virginia, Charlottesville, VA, United States; (3) University of Calgary, Calgary, AB, Canada; ",ACM,-1,"[""computer animation"", ""computer games"", ""handicapped aids"", ""holographic displays""]","[""computer animation"", ""computer games"", ""handicapped aids"", ""holographic displays""]",computer animation;computer games;handicapped aids;holographic displays,medical;display technology;graphics;liberal arts,technology;displays;industries,medical;display technology;graphics;liberal arts,technology;displays;industries,computer_animation computer_games handicapped_aids holographic_displays head mounted_ar_device holographic_animations hololens_2_game interactive_ar_applications nonspeaking_autistic_people structured_learning_opportunities usability_study c7850_computer_assistance_for_persons_with_handicaps c6130b_graphics_techniques c6130v_virtual_reality c7830d_computer_games medical display_technology graphics liberal_arts,computer_animation computer_games handicapped_aids holographic_displays,head mounted_ar_device holographic_animations hololens_2_game interactive_ar_applications nonspeaking_autistic_people structured_learning_opportunities usability_study,one third autistic people nonspeaking never provided access effective alternative speech thoughtfully designed ar application could provide member population structured learning opportunity including training skill underlie alternative form communication fundamental step toward creating opportunity however investigate nonspeaking autistic people ability tolerate head mounted ar device interact virtual object present first study examine usability interactive ar based application population recruited 17 nonspeaking autistic subject play hololens 2 game developed involved holographic animation button almost subject tolerated device long enough begin game completed increasingly challenging task involved pressing holographic button based result discus best practice design process recommendation finding contradict prevailing assumption nonspeaking autistic people thus open exciting possibility ar based solution understudied underserved population,computer_animation computer_games handicapped_aids holographic_displays head mounted_ar_device holographic_animations hololens_2_game interactive_ar_applications nonspeaking_autistic_people structured_learning_opportunities usability_study c7850_computer_assistance_for_persons_with_handicaps c6130b_graphics_techniques c6130v_virtual_reality c7830d_computer_games medical display_technology graphics liberal_arts one third autistic people nonspeaking never provided access effective alternative speech thoughtfully designed ar application could provide member population structured learning opportunity including training skill underlie alternative form communication fundamental step toward creating opportunity however investigate nonspeaking autistic people ability tolerate head mounted ar device interact virtual object present first study examine usability interactive ar based application population recruited 17 nonspeaking autistic subject play hololens 2 game developed involved holographic animation button almost subject tolerated device long enough begin game completed increasingly challenging task involved pressing holographic button based result discus best practice design process recommendation finding contradict prevailing assumption nonspeaking autistic people thus open exciting possibility ar based solution understudied underserved population,one third autistic people nonspeaking never provided access effective alternative speech thoughtfully designed ar application could provide member population structured learning opportunity including training skill underlie alternative form communication fundamental step toward creating opportunity however investigate nonspeaking autistic people ability tolerate head mounted ar device interact virtual object present first study examine usability interactive ar based application population recruited 17 nonspeaking autistic subject play hololens 2 game developed involved holographic animation button almost subject tolerated device long enough begin game completed increasingly challenging task involved pressing holographic button based result discus best practice design process recommendation finding contradict prevailing assumption nonspeaking autistic people thus open exciting possibility ar based solution understudied underserved populationcomputer_animation computer_games handicapped_aids holographic_displayshead mounted_ar_device holographic_animations hololens_2_game interactive_ar_applications nonspeaking_autistic_people structured_learning_opportunities usability_study
352,The Necessity of Emotion Recognition from Speech Signals for Natural and Effective Human-Robot Interaction in Society 5.0,"Sönmez, Y. Ü., & Varol, A. (2022). The Necessity of Emotion Recognition from Speech Signals for Natural and Effective Human-Robot Interaction in Society 5.0. 2022 10th International Symposium on Digital Forensics and Security (ISDFS). https://doi.org/10.1109/isdfs55398.2022.9800837
",10.1109/ISDFS55398.2022.9800837,"The history of humanity has reached Industry 4.0 that aims to the integration of information technologies and especially artificial intelligence with all life-sustaining mechanisms in the 21st century, and consecutively, the transformation of Society 5.0 has begun. Society 5.0 means a smart society in which humans share life with physical robots and software robots as well as smart devices based on augmented reality. Industry 4.0 contains main structures such as the internet of things, big data analytics, digital transformation, cyber-physical systems, artificial intelligence, and business processes optimization. It is impossible to consider the machines to be without emotions and emotional intelligence within the transformation of smart tools and artificial intelligence, in addition, while it is planned to give most of the commands with voice and speaking, it became more important to develop algorithms that can detect emotions. In the smart society, new and rapid methods are needed for speech recognition, emotion recognition, and speech emotion recognition areas to maximize human-computer (HCI) or human-robot interaction (HRI) and collaboration. In this study, speech recognition and speech emotion recognition studies in robot technology are investigated and developments are revealed.",B6130E Speech recognition and synthesis;C5260B Computer vision and image processing techniques;C5260S Speech processing techniques;C6130 Data handling techniques;C6130V Virtual reality;C6180 User interfaces;C7210N Information networks,artificial intelligence;cyber-physical systems;digital transformation;effective human-robot interaction;emotional intelligence;humans share life;information technologies;life-sustaining mechanisms;physical robots;robot technology;smart devices;smart society;smart tools;Society 5;software robots;speech emotion recognition areas;speech emotion recognition studies;speech recognition;speech signals,artificial intelligence;augmented reality;Big Data;emotion recognition;human computer interaction;human-robot interaction;speech recognition,2022,Conference article (CA),2022 10th International Symposium on Digital Forensics and Security (ISDFS),"(1) Sonmez, Y.U.; (2) Varol, A.; ","(1) Software Engineering F&#305;rat University, Faculty of Technology, Turkey; (2) Maltepe University, College of Engineering and Natural Sciences Computer Engineering, Turkey; ",IEEE,-1,"[""artificial intelligence"", ""big data"", ""emotion recognition"", ""human computer interaction"", ""human-robot interaction"", ""speech recognition""]","[""artificial intelligence"", ""big data"", ""emotion recognition"", ""human computer interaction"", ""human-robot interaction"", ""speech recognition""]",artificial intelligence;big data;emotion recognition;human computer interaction;human-robot interaction;speech recognition,robotics;input;liberal arts;human factors;data;human-computer interaction;artificial intelligence,technology;industries;end users and user experience,robotics;input;liberal arts;human factors;data;human-computer interaction;artificial intelligence,technology;industries;end users and user experience,artificial_intelligence big_data emotion_recognition human_computer_interaction human robot_interaction speech_recognition artificial_intelligence cyber physical_systems digital_transformation effective_human robot_interaction emotional_intelligence humans_share_life information_technologies life sustaining_mechanisms physical_robots robot_technology smart_devices smart_society smart_tools society_5 software_robots speech_emotion_recognition_areas speech_emotion_recognition_studies speech_recognition speech_signals b6130e_speech_recognition_and_synthesis c5260b_computer_vision_and_image_processing_techniques c5260s_speech_processing_techniques c6130_data_handling_techniques c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks robotics input liberal_arts human_factors data human computer_interaction artificial_intelligence,artificial_intelligence big_data emotion_recognition human_computer_interaction human robot_interaction speech_recognition,artificial_intelligence cyber physical_systems digital_transformation effective_human robot_interaction emotional_intelligence humans_share_life information_technologies life sustaining_mechanisms physical_robots robot_technology smart_devices smart_society smart_tools society_5 software_robots speech_emotion_recognition_areas speech_emotion_recognition_studies speech_recognition speech_signals,history humanity reached industry 4 0 aim integration information technology especially artificial intelligence life sustaining mechanism 21st century consecutively transformation society 5 0 begun society 5 0 mean smart society human share life physical robot software robot well smart device based augmented reality industry 4 0 contains main structure internet thing big data analytics digital transformation cyber physical system artificial intelligence business process optimization impossible consider machine without emotion emotional intelligence within transformation smart tool artificial intelligence addition planned give command voice speaking became important develop algorithm detect emotion smart society new rapid method needed speech recognition emotion recognition speech emotion recognition area maximize human computer hci human robot interaction hri collaboration study speech recognition speech emotion recognition study robot technology investigated development revealed,artificial_intelligence big_data emotion_recognition human_computer_interaction human robot_interaction speech_recognition artificial_intelligence cyber physical_systems digital_transformation effective_human robot_interaction emotional_intelligence humans_share_life information_technologies life sustaining_mechanisms physical_robots robot_technology smart_devices smart_society smart_tools society_5 software_robots speech_emotion_recognition_areas speech_emotion_recognition_studies speech_recognition speech_signals b6130e_speech_recognition_and_synthesis c5260b_computer_vision_and_image_processing_techniques c5260s_speech_processing_techniques c6130_data_handling_techniques c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks robotics input liberal_arts human_factors data human computer_interaction artificial_intelligence history humanity reached industry 4 0 aim integration information technology especially artificial intelligence life sustaining mechanism 21st century consecutively transformation society 5 0 begun society 5 0 mean smart society human share life physical robot software robot well smart device based augmented reality industry 4 0 contains main structure internet thing big data analytics digital transformation cyber physical system artificial intelligence business process optimization impossible consider machine without emotion emotional intelligence within transformation smart tool artificial intelligence addition planned give command voice speaking became important develop algorithm detect emotion smart society new rapid method needed speech recognition emotion recognition speech emotion recognition area maximize human computer hci human robot interaction hri collaboration study speech recognition speech emotion recognition study robot technology investigated development revealed,history humanity reached industry 4 0 aim integration information technology especially artificial intelligence life sustaining mechanism 21st century consecutively transformation society 5 0 begun society 5 0 mean smart society human share life physical robot software robot well smart device based augmented reality industry 4 0 contains main structure internet thing big data analytics digital transformation cyber physical system artificial intelligence business process optimization impossible consider machine without emotion emotional intelligence within transformation smart tool artificial intelligence addition planned give command voice speaking became important develop algorithm detect emotion smart society new rapid method needed speech recognition emotion recognition speech emotion recognition area maximize human computer hci human robot interaction hri collaboration study speech recognition speech emotion recognition study robot technology investigated development revealedartificial_intelligence big_data emotion_recognition human_computer_interaction human robot_interaction speech_recognitionartificial_intelligence cyber physical_systems digital_transformation effective_human robot_interaction emotional_intelligence humans_share_life information_technologies life sustaining_mechanisms physical_robots robot_technology smart_devices smart_society smart_tools society_5 software_robots speech_emotion_recognition_areas speech_emotion_recognition_studies speech_recognition speech_signals
353,Beyond Text-to-Image: Multimodal Prompts to Explore Generative AI,"Liu, V. (2023). Beyond Text-to-Image: Multimodal Prompts to Explore Generative AI. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3577043
",10.1145/3544549.3577043,"Text-to-image AI systems have proven to have extraordinary generative capacities that have facilitated widespread adoption. However, these systems are primarily text-based, which is a fundamental inversion of what many artists are traditionally used to: having full control over the composition of their work. Prior work has shown that there is great utility in using text prompts and that AI augmented workflows can increase momentum on creative tasks for end users. However, multimodal interactions beyond text need to be further defined, so end users can have rich points of interaction that allow them to truly co-pilot AI-generated content creation. To this end, the goal of my research is to equip creators with workflows that 1) translate abstract design goals into prompts of visual language, 2) structure exploration of design outcomes, and 3) integrate creator contributions into generations.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130D Document processing and analysis techniques;C6130V Virtual reality;C6140D High level languages;C6210 Knowledge based systems",AI augmented workflow;copilot AI-generated content creation;end users;explore generative AI;extraordinary generative capacities;fundamental inversion;multimodal interactions;multimodal prompts;primarily text-based;text prompts;text-to-image AI systems;visual language,artificial intelligence;augmented reality;image processing;text analysis;visual languages,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Liu, V.; ","(1) Columbia University, New York, NY, United States; ",ACM,-1,"[""artificial intelligence"", ""image processing"", ""text analysis"", ""visual languages""]","[""artificial intelligence"", ""image processing"", ""text analysis"", ""visual languages""]",artificial intelligence;image processing;text analysis;visual languages,computer vision;input;liberal arts;developers;data;artificial intelligence,technology;industries,computer vision;input;liberal arts;developers;data;artificial intelligence,technology;industries,artificial_intelligence image_processing text_analysis visual_languages ai_augmented_workflow copilot_ai generated_content_creation end_users explore_generative_ai extraordinary_generative_capacities fundamental_inversion multimodal_interactions multimodal_prompts primarily_text based text_prompts text to image_ai_systems visual_language b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6140d_high_level_languages c6210_knowledge_based_systems computer_vision input liberal_arts developers data artificial_intelligence,artificial_intelligence image_processing text_analysis visual_languages,ai_augmented_workflow copilot_ai generated_content_creation end_users explore_generative_ai extraordinary_generative_capacities fundamental_inversion multimodal_interactions multimodal_prompts primarily_text based text_prompts text to image_ai_systems visual_language,text image ai system proven extraordinary generative capacity facilitated widespread adoption however system primarily text based fundamental inversion many artist traditionally used full control composition work prior work shown great utility using text prompt ai augmented workflow increase momentum creative task end user however multimodal interaction beyond text need defined end user rich point interaction allow truly co pilot ai generated content creation end goal research equip creator workflow 1 translate abstract design goal prompt visual language 2 structure exploration design outcome 3 integrate creator contribution generation,artificial_intelligence image_processing text_analysis visual_languages ai_augmented_workflow copilot_ai generated_content_creation end_users explore_generative_ai extraordinary_generative_capacities fundamental_inversion multimodal_interactions multimodal_prompts primarily_text based text_prompts text to image_ai_systems visual_language b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c6140d_high_level_languages c6210_knowledge_based_systems computer_vision input liberal_arts developers data artificial_intelligence text image ai system proven extraordinary generative capacity facilitated widespread adoption however system primarily text based fundamental inversion many artist traditionally used full control composition work prior work shown great utility using text prompt ai augmented workflow increase momentum creative task end user however multimodal interaction beyond text need defined end user rich point interaction allow truly co pilot ai generated content creation end goal research equip creator workflow 1 translate abstract design goal prompt visual language 2 structure exploration design outcome 3 integrate creator contribution generation,text image ai system proven extraordinary generative capacity facilitated widespread adoption however system primarily text based fundamental inversion many artist traditionally used full control composition work prior work shown great utility using text prompt ai augmented workflow increase momentum creative task end user however multimodal interaction beyond text need defined end user rich point interaction allow truly co pilot ai generated content creation end goal research equip creator workflow 1 translate abstract design goal prompt visual language 2 structure exploration design outcome 3 integrate creator contribution generationartificial_intelligence image_processing text_analysis visual_languagesai_augmented_workflow copilot_ai generated_content_creation end_users explore_generative_ai extraordinary_generative_capacities fundamental_inversion multimodal_interactions multimodal_prompts primarily_text based text_prompts text to image_ai_systems visual_language
354,Metaverse is the Next Normal and Digital Future: A Systematic Review,"Khalid, F. (2023). Metaverse is the Next Normal and Digital Future: A Systematic Review. 2023 IEEE International Conference on Emerging Trends in Engineering, Sciences and Technology (ICES&amp;T). https://doi.org/10.1109/icest56843.2023.10138832
",10.1109/ICEST56843.2023.10138832,"The Digital Future of the World is on the verge of being revolutionized. The Technology, wisdom, and internet thinking of Metaverse will extend the impacts on all aspects of life including education, economy, politics, life, and culture. This study is an overview of the metaverse applications in the near future. The outcomes of this review are aimed to understand the usage and importance of metaverse in various fields by using augmented and virtual realities. Finally, we propose the application of Metaverse in education, economy, politics, and entertainment because of its huge future implications.",C6130V Virtual reality,augmented reality;digital future;economy;education;entertainment;Internet thinking;metaverse applications;politics;systematic review;virtual reality,educational computing;entertainment;politics;virtual reality,2023,Conference article (CA),"2023 IEEE International Conference on Emerging Trends in Engineering, Sciences and Technology (ICES&amp;T)","(1) Khalid, F.; ","(1) National University of Modern Languages, Media & Comm Department, Pakistan; ",IEEE,-1,"[""educational computing"", ""entertainment"", ""politics""]","[""educational computing"", ""entertainment"", ""politics""]",educational computing;entertainment;politics,education;policy;liberal arts,business;industries,education;policy;liberal arts,business;industries,educational_computing entertainment politics augmented_reality digital_future economy education entertainment internet_thinking metaverse_applications politics systematic_review virtual_reality c6130v_virtual_reality education policy liberal_arts,educational_computing entertainment politics,augmented_reality digital_future economy education entertainment internet_thinking metaverse_applications politics systematic_review virtual_reality,digital future world verge revolutionized technology wisdom internet thinking metaverse extend impact aspect life including education economy politics life culture study overview metaverse application near future outcome review aimed understand usage importance metaverse various field using augmented virtual reality finally propose application metaverse education economy politics entertainment huge future implication,educational_computing entertainment politics augmented_reality digital_future economy education entertainment internet_thinking metaverse_applications politics systematic_review virtual_reality c6130v_virtual_reality education policy liberal_arts digital future world verge revolutionized technology wisdom internet thinking metaverse extend impact aspect life including education economy politics life culture study overview metaverse application near future outcome review aimed understand usage importance metaverse various field using augmented virtual reality finally propose application metaverse education economy politics entertainment huge future implication,digital future world verge revolutionized technology wisdom internet thinking metaverse extend impact aspect life including education economy politics life culture study overview metaverse application near future outcome review aimed understand usage importance metaverse various field using augmented virtual reality finally propose application metaverse education economy politics entertainment huge future implicationeducational_computing entertainment politicsaugmented_reality digital_future economy education entertainment internet_thinking metaverse_applications politics systematic_review virtual_reality
355,Metaverse and fintech: pathway for innovation and development,"Kaur, N., Saha, S., Agarwal, V., & Gulati, S. (2023). Metaverse and Fintech: Pathway for Innovation and Development. 2023 3rd International Conference on Innovative Practices in Technology and Management (ICIPTM). https://doi.org/10.1109/iciptm57143.2023.10117956
",10.1109/ICIPTM57143.2023.10117956,"The development of the metaverse may have a substantial effect on the financial sector, opening new avenues for firms and investors to interact with digital assets and engage in virtual trade. It's important to note that there are a variety of financial applications for metaverse technology, including virtual banking, trading platforms, and even insurance services. Users may require access to virtual money in a metaverse so they can purchase virtual goods and services. Metaverse banks could provide financial services such as virtual currency exchange, virtual wallet services, and virtual lending. They could also offer traditional banking services, such as loans and savings accounts, but in a virtual context. These services could be used by individuals, businesses, and organizations operating within the metaverse. In stock markets, companies that could benefit from the metaverse's growth include those involved in virtual reality and augmented reality, as well as those that provide the infrastructure required to support the metaverse. TAM (Technology Acceptance Model) is applied for understanding how users perceive and adopt metaverse technology.",C7120 Financial computing;C6130S Data security;C6130V Virtual reality,financial applications;financial sector;financial services;insurance services;metaverse banks;metaverse technology;traditional banking services;virtual banking;virtual context;virtual currency exchange;virtual goods;virtual lending;virtual money;virtual reality;virtual trade;virtual wallet services,augmented reality;bank data processing;banking;cryptocurrencies;financial data processing;financial management;purchasing;stock markets;technology acceptance model;virtual reality,2023,Conference article (CA),2023 3rd International Conference on Innovative Practices in Technology and Management (ICIPTM),"(1) Kaur, N.; (2) Saha, S.; (1) Agarwal, V.; (1) Gulati, S.; ","(1) Amity University, Amity International Business School, India; (2) Delhi Metropolitan Education, India; ",IEEE,-1,"[""bank data processing"", ""banking"", ""cryptocurrencies"", ""financial data processing"", ""financial management"", ""purchasing"", ""stock markets"", ""technology acceptance model""]","[""bank data processing"", ""banking"", ""cryptocurrencies"", ""financial data processing"", ""financial management"", ""purchasing"", ""stock markets"", ""technology acceptance model""]",bank data processing;banking;cryptocurrencies;financial data processing;financial management;purchasing;stock markets;technology acceptance model,other;sales and marketing;human factors;logistics;data;human-computer interaction;business planning and management,technology;other;business;end users and user experience,other;sales and marketing;human factors;logistics;data;human-computer interaction;business planning and management,technology;other;business;end users and user experience,bank_data_processing banking cryptocurrencies financial_data_processing financial_management purchasing stock_markets technology_acceptance_model financial_applications financial_sector financial_services insurance_services metaverse_banks metaverse_technology traditional_banking_services virtual_banking virtual_context virtual_currency_exchange virtual_goods virtual_lending virtual_money virtual_reality virtual_trade virtual_wallet_services c7120_financial_computing c6130s_data_security c6130v_virtual_reality other sales_and_marketing human_factors logistics data human computer_interaction business_planning_and_management,bank_data_processing banking cryptocurrencies financial_data_processing financial_management purchasing stock_markets technology_acceptance_model,financial_applications financial_sector financial_services insurance_services metaverse_banks metaverse_technology traditional_banking_services virtual_banking virtual_context virtual_currency_exchange virtual_goods virtual_lending virtual_money virtual_reality virtual_trade virtual_wallet_services,development metaverse may substantial effect financial sector opening new avenue firm investor interact digital asset engage virtual trade important note variety financial application metaverse technology including virtual banking trading platform even insurance service user may require access virtual money metaverse purchase virtual good service metaverse bank could provide financial service virtual currency exchange virtual wallet service virtual lending could also offer traditional banking service loan saving account virtual context service could used individual business organization operating within metaverse stock market company could benefit metaverse growth include involved virtual reality augmented reality well provide infrastructure required support metaverse tam technology acceptance model applied understanding user perceive adopt metaverse technology,bank_data_processing banking cryptocurrencies financial_data_processing financial_management purchasing stock_markets technology_acceptance_model financial_applications financial_sector financial_services insurance_services metaverse_banks metaverse_technology traditional_banking_services virtual_banking virtual_context virtual_currency_exchange virtual_goods virtual_lending virtual_money virtual_reality virtual_trade virtual_wallet_services c7120_financial_computing c6130s_data_security c6130v_virtual_reality other sales_and_marketing human_factors logistics data human computer_interaction business_planning_and_management development metaverse may substantial effect financial sector opening new avenue firm investor interact digital asset engage virtual trade important note variety financial application metaverse technology including virtual banking trading platform even insurance service user may require access virtual money metaverse purchase virtual good service metaverse bank could provide financial service virtual currency exchange virtual wallet service virtual lending could also offer traditional banking service loan saving account virtual context service could used individual business organization operating within metaverse stock market company could benefit metaverse growth include involved virtual reality augmented reality well provide infrastructure required support metaverse tam technology acceptance model applied understanding user perceive adopt metaverse technology,development metaverse may substantial effect financial sector opening new avenue firm investor interact digital asset engage virtual trade important note variety financial application metaverse technology including virtual banking trading platform even insurance service user may require access virtual money metaverse purchase virtual good service metaverse bank could provide financial service virtual currency exchange virtual wallet service virtual lending could also offer traditional banking service loan saving account virtual context service could used individual business organization operating within metaverse stock market company could benefit metaverse growth include involved virtual reality augmented reality well provide infrastructure required support metaverse tam technology acceptance model applied understanding user perceive adopt metaverse technologybank_data_processing banking cryptocurrencies financial_data_processing financial_management purchasing stock_markets technology_acceptance_modelfinancial_applications financial_sector financial_services insurance_services metaverse_banks metaverse_technology traditional_banking_services virtual_banking virtual_context virtual_currency_exchange virtual_goods virtual_lending virtual_money virtual_reality virtual_trade virtual_wallet_services
356,Hybrid Simulation and Planning Platform for Cryosurgery with Microsoft HoloLens,"Condino, S., Cutolo, F., Cattari, N., Colangeli, S., Parchi, P. D., Piazza, R., Ruinato, A. D., Capanna, R., & Ferrari, V. (2021). Hybrid Simulation and Planning Platform for Cryosurgery with Microsoft HoloLens. Sensors, 21(13), 4450. https://doi.org/10.3390/s21134450
",10.3390/s21134450,"Cryosurgery is a technique of growing popularity involving tissue ablation under controlled freezing. Technological advancement of devices along with surgical technique improvements have turned cryosurgery from an experimental to an established option for treating several diseases. However, cryosurgery is still limited by inaccurate planning based primarily on 2D visualization of the patient's preoperative images. Several works have been aimed at modelling cryoablation through heat transfer simulations; however, most software applications do not meet some key requirements for clinical routine use, such as high computational speed and user-friendliness. This work aims to develop an intuitive platform for anatomical understanding and pre-operative planning by integrating the information content of radiological images and cryoprobe specifications either in a 3D virtual environment (desktop application) or in a hybrid simulator, which exploits the potential of the 3D printing and augmented reality functionalities of Microsoft HoloLens. The proposed platform was preliminarily validated for the retrospective planning/simulation of two surgical cases. Results suggest that the platform is easy and quick to learn and could be used in clinical practice to improve anatomical understanding, to make surgical planning easier than the traditional method, and to strengthen the memorization of surgical planning.","A8770G Patient care and treatment;A8770E Patient diagnostic methods and instrumentation;B6135 Optical, image and video signal processing;B7520 Patient care and treatment;C5260B Computer vision and image processing techniques;C6130B Graphics techniques;C6130V Virtual reality;C7330 Biology and medical computing",3D virtual environment;anatomical understanding;controlled freezing;cryoprobe specifications;cryosurgery;established option;heat transfer simulations;high computational speed;hybrid simulator;inaccurate planning;intuitive platform;Microsoft HoloLens;patient;popularity involving tissue ablation;pre-operative planning;radiological images;software applications;surgical planning;surgical technique improvements,augmented reality;biological tissues;biothermics;diseases;freezing;medical image processing;surgery;virtual reality,2021,Journal article (JA),Sensors (Switzerland),"(1) Condino, S.; (1) Cutolo, F.; (2) Cattari, N.; (3) Colangeli, S.; (3) Parchi, P.D.; (2) Piazza, R.; (2) Ruinato, A.D.; (3) Capanna, R.; (1) Ferrari, V.; ","(1) University of Pisa, Information Engineering Department, Italy; (2) University of Pisa, Department of Translational Research and New Technologies in Medicine and Surgery, Italy; (3) University of Pisa, Department of Translational Research and of New Surgical and Medical Technologies, Italy; ",MDPI,-1,"[""biological tissues"", ""biothermics"", ""diseases"", ""freezing"", ""medical image processing"", ""surgery""]","[""biological tissues"", ""biothermics"", ""diseases"", ""freezing"", ""medical image processing"", ""surgery""]",biological tissues;biothermics;diseases;freezing;medical image processing;surgery,medical;computer vision;other;data,technology;other;industries,medical;computer vision;other;data,technology;other;industries,biological_tissues biothermics diseases freezing medical_image_processing surgery 3d_virtual_environment anatomical_understanding controlled_freezing cryoprobe_specifications cryosurgery established_option heat_transfer_simulations high_computational_speed hybrid_simulator inaccurate_planning intuitive_platform microsoft_hololens patient popularity_involving_tissue_ablation pre operative_planning radiological_images software_applications surgical_planning surgical_technique_improvements a8770g_patient_care_and_treatment a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b7520_patient_care_and_treatment c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing medical computer_vision other data,biological_tissues biothermics diseases freezing medical_image_processing surgery,3d_virtual_environment anatomical_understanding controlled_freezing cryoprobe_specifications cryosurgery established_option heat_transfer_simulations high_computational_speed hybrid_simulator inaccurate_planning intuitive_platform microsoft_hololens patient popularity_involving_tissue_ablation pre operative_planning radiological_images software_applications surgical_planning surgical_technique_improvements,cryosurgery technique growing popularity involving tissue ablation controlled freezing technological advancement device along surgical technique improvement turned cryosurgery experimental established option treating several disease however cryosurgery still limited inaccurate planning based primarily 2d visualization patient preoperative image several work aimed modelling cryoablation heat transfer simulation however software application meet key requirement clinical routine use high computational speed user friendliness work aim develop intuitive platform anatomical understanding pre operative planning integrating information content radiological image cryoprobe specification either 3d virtual environment desktop application hybrid simulator exploit potential 3d printing augmented reality functionality microsoft hololens proposed platform preliminarily validated retrospective planning simulation two surgical case result suggest platform easy quick learn could used clinical practice improve anatomical understanding make surgical planning easier traditional method strengthen memorization surgical planning,biological_tissues biothermics diseases freezing medical_image_processing surgery 3d_virtual_environment anatomical_understanding controlled_freezing cryoprobe_specifications cryosurgery established_option heat_transfer_simulations high_computational_speed hybrid_simulator inaccurate_planning intuitive_platform microsoft_hololens patient popularity_involving_tissue_ablation pre operative_planning radiological_images software_applications surgical_planning surgical_technique_improvements a8770g_patient_care_and_treatment a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b7520_patient_care_and_treatment c5260b_computer_vision_and_image_processing_techniques c6130b_graphics_techniques c6130v_virtual_reality c7330_biology_and_medical_computing medical computer_vision other data cryosurgery technique growing popularity involving tissue ablation controlled freezing technological advancement device along surgical technique improvement turned cryosurgery experimental established option treating several disease however cryosurgery still limited inaccurate planning based primarily 2d visualization patient preoperative image several work aimed modelling cryoablation heat transfer simulation however software application meet key requirement clinical routine use high computational speed user friendliness work aim develop intuitive platform anatomical understanding pre operative planning integrating information content radiological image cryoprobe specification either 3d virtual environment desktop application hybrid simulator exploit potential 3d printing augmented reality functionality microsoft hololens proposed platform preliminarily validated retrospective planning simulation two surgical case result suggest platform easy quick learn could used clinical practice improve anatomical understanding make surgical planning easier traditional method strengthen memorization surgical planning,cryosurgery technique growing popularity involving tissue ablation controlled freezing technological advancement device along surgical technique improvement turned cryosurgery experimental established option treating several disease however cryosurgery still limited inaccurate planning based primarily 2d visualization patient preoperative image several work aimed modelling cryoablation heat transfer simulation however software application meet key requirement clinical routine use high computational speed user friendliness work aim develop intuitive platform anatomical understanding pre operative planning integrating information content radiological image cryoprobe specification either 3d virtual environment desktop application hybrid simulator exploit potential 3d printing augmented reality functionality microsoft hololens proposed platform preliminarily validated retrospective planning simulation two surgical case result suggest platform easy quick learn could used clinical practice improve anatomical understanding make surgical planning easier traditional method strengthen memorization surgical planningbiological_tissues biothermics diseases freezing medical_image_processing surgery3d_virtual_environment anatomical_understanding controlled_freezing cryoprobe_specifications cryosurgery established_option heat_transfer_simulations high_computational_speed hybrid_simulator inaccurate_planning intuitive_platform microsoft_hololens patient popularity_involving_tissue_ablation pre operative_planning radiological_images software_applications surgical_planning surgical_technique_improvements
357,A Novel Mixed Reality Solution Based on Learning Environment for Sutures in Minor Surgery,"Rojo, A., Raya, L., & Sanchez, A. (2021). A Novel Mixed Reality Solution Based on Learning Environment for Sutures in Minor Surgery. Applied Sciences, 11(5), 2335. https://doi.org/10.3390/app11052335
",10.3390/app11052335,"Minor Surgery Sutures is a fundamental skill for healthcare professionals. However, in the educational field, the practice of suturing is sometimes limited and reduced, with more theoretical than practical study. In order to facilitate learning, our goal is to develop an immersive and interactive educational tool that complements theoretical study, called Suture MR. This application could enhance suture procedural skills in the fields of nursing and medicine. Applying Mixed Reality techniques, we generate a 3D model of an arm with a full-scale wound. Realistically, the user will simulate the suture movements as part of the learning process. The application has surgical clamps and a needle holder that are virtually visualized in the user's hands, allowing gestures and movements faithful to the real ones. In this article, we want to demonstrate the usability of our environment and the feasibility of using Mixed Reality learning experiences in clinical practical training as a complement to theoretical training. The results of the study reveal a greater perception of learning and the willingness of students to use this methodology.",C7810C Computer-aided instruction;C6130V Virtual reality,clinical practical training;healthcare professionals;interactive educational tool;learning environment;medicine;minor surgery sutures;mixed reality learning;mixed reality solution;nursing;surgical clamps;suture movements;Suture MR;suture procedural skills;theoretical training,augmented reality;computer aided instruction;surgery,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Rojo, A.; (1) Raya, L.; (2) Sanchez, A.; ","(1) Centro Universitario de Tecnologi&#769;a y Arte Digital, Spain; (2) Universidad Rey Juan Carlos, Department of Computer Science & Statistics, Spain; (3) Research Center for Computational Simulation, Spain; ",MDPI,-1,"[""computer aided instruction"", ""surgery""]","[""computer aided instruction"", ""surgery""]",computer aided instruction;surgery,medical;training,use cases;industries,medical;training,use cases;industries,computer_aided_instruction surgery clinical_practical_training healthcare_professionals interactive_educational_tool learning_environment medicine minor_surgery_sutures mixed_reality_learning mixed_reality_solution nursing surgical_clamps suture_movements suture_mr suture_procedural_skills theoretical_training c7810c_computer aided_instruction c6130v_virtual_reality medical training,computer_aided_instruction surgery,clinical_practical_training healthcare_professionals interactive_educational_tool learning_environment medicine minor_surgery_sutures mixed_reality_learning mixed_reality_solution nursing surgical_clamps suture_movements suture_mr suture_procedural_skills theoretical_training,minor surgery suture fundamental skill healthcare professional however educational field practice suturing sometimes limited reduced theoretical practical study order facilitate learning goal develop immersive interactive educational tool complement theoretical study called suture mr application could enhance suture procedural skill field nursing medicine applying mixed reality technique generate 3d model arm full scale wound realistically user simulate suture movement part learning process application surgical clamp needle holder virtually visualized user hand allowing gesture movement faithful real one article want demonstrate usability environment feasibility using mixed reality learning experience clinical practical training complement theoretical training result study reveal greater perception learning willingness student use methodology,computer_aided_instruction surgery clinical_practical_training healthcare_professionals interactive_educational_tool learning_environment medicine minor_surgery_sutures mixed_reality_learning mixed_reality_solution nursing surgical_clamps suture_movements suture_mr suture_procedural_skills theoretical_training c7810c_computer aided_instruction c6130v_virtual_reality medical training minor surgery suture fundamental skill healthcare professional however educational field practice suturing sometimes limited reduced theoretical practical study order facilitate learning goal develop immersive interactive educational tool complement theoretical study called suture mr application could enhance suture procedural skill field nursing medicine applying mixed reality technique generate 3d model arm full scale wound realistically user simulate suture movement part learning process application surgical clamp needle holder virtually visualized user hand allowing gesture movement faithful real one article want demonstrate usability environment feasibility using mixed reality learning experience clinical practical training complement theoretical training result study reveal greater perception learning willingness student use methodology,minor surgery suture fundamental skill healthcare professional however educational field practice suturing sometimes limited reduced theoretical practical study order facilitate learning goal develop immersive interactive educational tool complement theoretical study called suture mr application could enhance suture procedural skill field nursing medicine applying mixed reality technique generate 3d model arm full scale wound realistically user simulate suture movement part learning process application surgical clamp needle holder virtually visualized user hand allowing gesture movement faithful real one article want demonstrate usability environment feasibility using mixed reality learning experience clinical practical training complement theoretical training result study reveal greater perception learning willingness student use methodologycomputer_aided_instruction surgeryclinical_practical_training healthcare_professionals interactive_educational_tool learning_environment medicine minor_surgery_sutures mixed_reality_learning mixed_reality_solution nursing surgical_clamps suture_movements suture_mr suture_procedural_skills theoretical_training
358,Spherical Convolution Empowered Viewport Prediction in 360 Video Multicast with Limited FoV Feedback,"Li, J., Han, L., Zhang, C., Li, Q., & Liu, Z. (2023). Spherical Convolution Empowered Viewport Prediction in 360 Video Multicast with Limited FoV Feedback. ACM Transactions on Multimedia Computing, Communications, and Applications, 19(1), 1–23. https://doi.org/10.1145/3511603
",10.1145/3511603,"Field of view (FoV) prediction is critical in 360-degree video multicast, which is a key component of the emerging virtual reality and augmented reality applications. Most of the current prediction methods combining saliency detection and FoV information neither take into account that the distortion of projected 360-degree videos can invalidate the weight sharing of traditional convolutional networks nor do they adequately consider the difficulty of obtaining complete multi-user FoV information, which degrades the prediction performance. This article proposes a spherical convolution-empowered FoV prediction method, which is a multi-source prediction framework combining salient features extracted from 360-degree video with limited FoV feedback information. A spherical convolutional neural network is used instead of a traditional two-dimensional convolutional neural network to eliminate the problem of weight sharing failure caused by video projection distortion. Specifically, salient spatial-temporal features are extracted through a spherical convolution-based saliency detection model, after which the limited feedback FoV information is represented as a time-series model based on a spherical convolution-empowered gated recurrent unit network. Finally, the extracted salient video features are combined to predict future user FoVs. The experimental results show that the performance of the proposed method is better than other prediction methods.","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C5260D Video signal processing;C6130V Virtual reality;C6264 Neural nets",360 video multicast;360-degree video multicast;complete multiuser FoV information;current prediction methods;emerging virtual reality;extracted salient video features;FoV feedback information;future user FoVs;limited FoV feedback;multisource prediction framework;prediction performance;projected 360-degree videos;reality applications;recurrent unit network;salient features;spherical convolution-based saliency detection model;spherical convolution-empowered FoV prediction method;spherical convolutional neural network;traditional convolutional networks;two-dimensional convolutional neural network;video projection distortion;view prediction;viewport prediction;weight sharing failure,augmented reality;convolutional neural nets;feature extraction;object detection;recurrent neural nets;time series;video signal processing;virtual reality,2023,Journal article (JA),ACM Trans. Multimed. Comput. Commun. Appl. (USA),"(1) Li, J.; (1) Han, L.; (1) Zhang, C.; (1) Li, Q.; (2) Liu, Z.; ","(1) Hefei University of Technology, China; (2) University of Electro-Communications, Japan; ",ACM,-1,"[""convolutional neural nets"", ""feature extraction"", ""object detection"", ""recurrent neural nets"", ""time series"", ""video signal processing""]","[""convolutional neural nets"", ""feature extraction"", ""object detection"", ""recurrent neural nets"", ""time series"", ""video signal processing""]",convolutional neural nets;feature extraction;object detection;recurrent neural nets;time series;video signal processing,computer vision;semiconductors;chemical;sensors;data;artificial intelligence;networks,technology;industries,computer vision;semiconductors;chemical;sensors;data;artificial intelligence;networks,technology;industries,convolutional_neural_nets feature_extraction object_detection recurrent_neural_nets time_series video_signal_processing 360_video_multicast 360 degree_video_multicast complete_multiuser_fov_information current_prediction_methods emerging_virtual_reality extracted_salient_video_features fov_feedback_information future_user_fovs limited_fov_feedback multisource_prediction_framework prediction_performance projected_360 degree_videos reality_applications recurrent_unit_network salient_features spherical_convolution based_saliency_detection_model spherical_convolution empowered_fov_prediction_method spherical_convolutional_neural_network traditional_convolutional_networks two dimensional_convolutional_neural_network video_projection_distortion view_prediction viewport_prediction weight_sharing_failure b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130v_virtual_reality c6264_neural_nets computer_vision semiconductors chemical sensors data artificial_intelligence networks,convolutional_neural_nets feature_extraction object_detection recurrent_neural_nets time_series video_signal_processing,360_video_multicast 360 degree_video_multicast complete_multiuser_fov_information current_prediction_methods emerging_virtual_reality extracted_salient_video_features fov_feedback_information future_user_fovs limited_fov_feedback multisource_prediction_framework prediction_performance projected_360 degree_videos reality_applications recurrent_unit_network salient_features spherical_convolution based_saliency_detection_model spherical_convolution empowered_fov_prediction_method spherical_convolutional_neural_network traditional_convolutional_networks two dimensional_convolutional_neural_network video_projection_distortion view_prediction viewport_prediction weight_sharing_failure,field view fov prediction critical 360 degree video multicast key component emerging virtual reality augmented reality application current prediction method combining saliency detection fov information neither take account distortion projected 360 degree video invalidate weight sharing traditional convolutional network adequately consider difficulty obtaining complete multi user fov information degrades prediction performance article proposes spherical convolution empowered fov prediction method multi source prediction framework combining salient feature extracted 360 degree video limited fov feedback information spherical convolutional neural network used instead traditional two dimensional convolutional neural network eliminate problem weight sharing failure caused video projection distortion specifically salient spatial temporal feature extracted spherical convolution based saliency detection model limited feedback fov information represented time series model based spherical convolution empowered gated recurrent unit network finally extracted salient video feature combined predict future user fovs experimental result show performance proposed method better prediction method,convolutional_neural_nets feature_extraction object_detection recurrent_neural_nets time_series video_signal_processing 360_video_multicast 360 degree_video_multicast complete_multiuser_fov_information current_prediction_methods emerging_virtual_reality extracted_salient_video_features fov_feedback_information future_user_fovs limited_fov_feedback multisource_prediction_framework prediction_performance projected_360 degree_videos reality_applications recurrent_unit_network salient_features spherical_convolution based_saliency_detection_model spherical_convolution empowered_fov_prediction_method spherical_convolutional_neural_network traditional_convolutional_networks two dimensional_convolutional_neural_network video_projection_distortion view_prediction viewport_prediction weight_sharing_failure b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5260d_video_signal_processing c6130v_virtual_reality c6264_neural_nets computer_vision semiconductors chemical sensors data artificial_intelligence networks field view fov prediction critical 360 degree video multicast key component emerging virtual reality augmented reality application current prediction method combining saliency detection fov information neither take account distortion projected 360 degree video invalidate weight sharing traditional convolutional network adequately consider difficulty obtaining complete multi user fov information degrades prediction performance article proposes spherical convolution empowered fov prediction method multi source prediction framework combining salient feature extracted 360 degree video limited fov feedback information spherical convolutional neural network used instead traditional two dimensional convolutional neural network eliminate problem weight sharing failure caused video projection distortion specifically salient spatial temporal feature extracted spherical convolution based saliency detection model limited feedback fov information represented time series model based spherical convolution empowered gated recurrent unit network finally extracted salient video feature combined predict future user fovs experimental result show performance proposed method better prediction method,field view fov prediction critical 360 degree video multicast key component emerging virtual reality augmented reality application current prediction method combining saliency detection fov information neither take account distortion projected 360 degree video invalidate weight sharing traditional convolutional network adequately consider difficulty obtaining complete multi user fov information degrades prediction performance article proposes spherical convolution empowered fov prediction method multi source prediction framework combining salient feature extracted 360 degree video limited fov feedback information spherical convolutional neural network used instead traditional two dimensional convolutional neural network eliminate problem weight sharing failure caused video projection distortion specifically salient spatial temporal feature extracted spherical convolution based saliency detection model limited feedback fov information represented time series model based spherical convolution empowered gated recurrent unit network finally extracted salient video feature combined predict future user fovs experimental result show performance proposed method better prediction methodconvolutional_neural_nets feature_extraction object_detection recurrent_neural_nets time_series video_signal_processing360_video_multicast 360 degree_video_multicast complete_multiuser_fov_information current_prediction_methods emerging_virtual_reality extracted_salient_video_features fov_feedback_information future_user_fovs limited_fov_feedback multisource_prediction_framework prediction_performance projected_360 degree_videos reality_applications recurrent_unit_network salient_features spherical_convolution based_saliency_detection_model spherical_convolution empowered_fov_prediction_method spherical_convolutional_neural_network traditional_convolutional_networks two dimensional_convolutional_neural_network video_projection_distortion view_prediction viewport_prediction weight_sharing_failure
359,How is Technology Accepted? Fundamental Works in User Technology Acceptance from Diffusion of Innovations to UTAUT-2,"Lampo, A. (2022). How is Technology Accepted? Fundamental Works in User Technology Acceptance from Diffusion of Innovations to UTAUT-2. Proceedings of the 8th International Conference on Industrial and Business Engineering. https://doi.org/10.1145/3568834.3568903
",10.1145/3568834.3568903,"The decision to accept and use technology innovations has long been a source of debate across disciplines due to the complexity involved in predicting behavior. Recognizing that the subject is vast and fragmented, this paper examines the mainstream technology works to assist researchers to understand, conceptualize and select the most appropriate theoretical framework for their study. Starting with the pioneering effort on Diffusion of Innovations (DOI/IDT), the analysis considers the Theory of Reasoned Action (TRA), the Theory of Planned Behavior (TPB), the Technology Acceptance Model (TAM/TAM-2/TAM-3), the Value-based Acceptance Model (VAM), and the Unified Theory of Acceptance and Use of Technology (UTAUT/UTAUT-2) among the most important. A review of the key literature is vital to assessing and identifying research trends, as well as contributing to the discussion of emerging technologies such as Artificial Intelligence (AI), Augmented Reality (AR), Blockchain, Cloud Computing, Internet of Things (IoT), Mobile Apps, etc. Suggestions for future research paths are also provided.","C0240 Ergonomic aspects of computing;C0230 Economic, social and political aspects of computing;C5620D Internet of Things;C6130S Data security;C6130V Virtual reality;C6160B Distributed databases;C6190J Internet software;C6190V Mobile, ubiquitous and pervasive computing",appropriate theoretical framework;fundamental works;future research paths;mainstream technology;pioneering effort;Planned Behavior;predicting behavior;Reasoned Action;Technology Acceptance Model;Technology accepted;technology innovations;Unified Theory;user Technology Acceptance;Value-based Acceptance Model,artificial intelligence;augmented reality;blockchains;cloud computing;data analysis;human factors;Internet of Things;mobile computing;technology acceptance model,2022,Conference article (CA),ICIBE '22: Proceedings of the 8th International Conference on Industrial and Business Engineering,"(1) Lampo, A.; ","(1) University of Saint Joseph, China; ",ACM,-1,"[""artificial intelligence"", ""blockchains"", ""cloud computing"", ""data analysis"", ""human factors"", ""internet of things"", ""mobile computing"", ""technology acceptance model""]","[""artificial intelligence"", ""blockchains"", ""cloud computing"", ""data analysis"", ""human factors"", ""internet of things"", ""mobile computing"", ""technology acceptance model""]",artificial intelligence;blockchains;cloud computing;data analysis;human factors;internet of things;mobile computing;technology acceptance model,other;security;liberal arts;human factors;internet of things;telecommunication;data;human-computer interaction;artificial intelligence;networks,technology;other;industries;end users and user experience,other;security;liberal arts;human factors;internet of things;telecommunication;data;human-computer interaction;artificial intelligence;networks,technology;other;industries;end users and user experience,artificial_intelligence blockchains cloud_computing data_analysis human_factors internet_of_things mobile_computing technology_acceptance_model appropriate_theoretical_framework fundamental_works future_research_paths mainstream_technology pioneering_effort planned_behavior predicting_behavior reasoned_action technology_acceptance_model technology_accepted technology_innovations unified_theory user_technology_acceptance value based_acceptance_model c0240_ergonomic_aspects_of_computing c0230_economic _social_and_political_aspects_of_computing c5620d_internet_of_things c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing other security liberal_arts human_factors internet_of_things telecommunication data human computer_interaction artificial_intelligence networks,artificial_intelligence blockchains cloud_computing data_analysis human_factors internet_of_things mobile_computing technology_acceptance_model,appropriate_theoretical_framework fundamental_works future_research_paths mainstream_technology pioneering_effort planned_behavior predicting_behavior reasoned_action technology_acceptance_model technology_accepted technology_innovations unified_theory user_technology_acceptance value based_acceptance_model,decision accept use technology innovation long source debate across discipline due complexity involved predicting behavior recognizing subject vast fragmented paper examines mainstream technology work assist researcher understand conceptualize select appropriate theoretical framework study starting pioneering effort diffusion innovation doi idt analysis considers theory reasoned action tra theory planned behavior tpb technology acceptance model tam tam 2 tam 3 value based acceptance model vam unified theory acceptance use technology utaut utaut 2 among important review key literature vital assessing identifying research trend well contributing discussion emerging technology artificial intelligence ai augmented reality ar blockchain cloud computing internet thing iot mobile apps etc suggestion future research path also provided,artificial_intelligence blockchains cloud_computing data_analysis human_factors internet_of_things mobile_computing technology_acceptance_model appropriate_theoretical_framework fundamental_works future_research_paths mainstream_technology pioneering_effort planned_behavior predicting_behavior reasoned_action technology_acceptance_model technology_accepted technology_innovations unified_theory user_technology_acceptance value based_acceptance_model c0240_ergonomic_aspects_of_computing c0230_economic _social_and_political_aspects_of_computing c5620d_internet_of_things c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c6190j_internet_software c6190v_mobile _ubiquitous_and_pervasive_computing other security liberal_arts human_factors internet_of_things telecommunication data human computer_interaction artificial_intelligence networks decision accept use technology innovation long source debate across discipline due complexity involved predicting behavior recognizing subject vast fragmented paper examines mainstream technology work assist researcher understand conceptualize select appropriate theoretical framework study starting pioneering effort diffusion innovation doi idt analysis considers theory reasoned action tra theory planned behavior tpb technology acceptance model tam tam 2 tam 3 value based acceptance model vam unified theory acceptance use technology utaut utaut 2 among important review key literature vital assessing identifying research trend well contributing discussion emerging technology artificial intelligence ai augmented reality ar blockchain cloud computing internet thing iot mobile apps etc suggestion future research path also provided,decision accept use technology innovation long source debate across discipline due complexity involved predicting behavior recognizing subject vast fragmented paper examines mainstream technology work assist researcher understand conceptualize select appropriate theoretical framework study starting pioneering effort diffusion innovation doi idt analysis considers theory reasoned action tra theory planned behavior tpb technology acceptance model tam tam 2 tam 3 value based acceptance model vam unified theory acceptance use technology utaut utaut 2 among important review key literature vital assessing identifying research trend well contributing discussion emerging technology artificial intelligence ai augmented reality ar blockchain cloud computing internet thing iot mobile apps etc suggestion future research path also providedartificial_intelligence blockchains cloud_computing data_analysis human_factors internet_of_things mobile_computing technology_acceptance_modelappropriate_theoretical_framework fundamental_works future_research_paths mainstream_technology pioneering_effort planned_behavior predicting_behavior reasoned_action technology_acceptance_model technology_accepted technology_innovations unified_theory user_technology_acceptance value based_acceptance_model
360,Mixed Reality or Simply Mobile? A Case Study on Enabling Less Skilled Workers to Perform Routine Maintenance Tasks,"Wagner, M., Leubner, C., & Strunk, J. (2023). Mixed Reality or Simply Mobile? A Case Study on Enabling Less Skilled Workers to Perform Routine Maintenance Tasks. Procedia Computer Science, 217, 728–736. https://doi.org/10.1016/j.procs.2022.12.269
",10.1016/j.procs.2022.12.269,"The availability of skilled workers has become a severe issue for production companies in developed countries like Germany in recent years. Specialists for maintenance tasks are in strong demand and their workforce should be steered towards the most challenging tasks in maintenance. In this case study we analyze, whether less skilled or not specifically instructed workers can perform routine maintenance tasks without being directly supported by experts. In our setup ten participants try to handle a maintenance routine checklist in three different ways: paper-based printouts, on a mobile tablet, and with a Microsoft HoloLens 2 Mixed Reality (MR) device. The results show that workers fail to complete the task with a mere paper-based approach, but are able to succeed both with the mobile tablet and MR application. Quantitative time measurements and qualitative analyses indicate that the mobile tablet app was easier to learn, did not impair the worker as much as the HoloLens and worked more stable. However, the HoloLens solution showed advantages as hands-free and spatial guiding device, which could be important aspects when better MR hardware will be available and MR interaction principles become common knowledge. All rights reserved Elsevier.","C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6190V Mobile, ubiquitous and pervasive computing;C7480 Production engineering computing;E0410D Industrial applications of IT",maintenance routine checklist;mere paper-based approach;Microsoft HoloLens 2 Mixed Reality device;mobile tablet app;not specifically instructed workers;paper-based printouts;perform routine maintenance tasks;skilled instructed workers;skilled workers,augmented reality;maintenance engineering;mobile computing;personnel;production engineering computing,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Wagner, M.; (1) Leubner, C.; (2) Strunk, J.; ","(1) South Westphalia University of Applied Sciences, Department for Technical Business Administration, Germany; (2) Fern Universita&#776;t in Hagen, Faculty of Business Administration and Economics, Germany; ",Elsevier B.V.,-1,"[""maintenance engineering"", ""mobile computing"", ""personnel"", ""production engineering computing""]","[""maintenance engineering"", ""mobile computing"", ""personnel"", ""production engineering computing""]",maintenance engineering;mobile computing;personnel;production engineering computing,manufacturing;engineering;telecommunication;human resources,technology;business;industries,manufacturing;engineering;telecommunication;human resources,technology;business;industries,maintenance_engineering mobile_computing personnel production_engineering_computing maintenance_routine_checklist mere_paper based_approach microsoft_hololens_2_mixed_reality_device mobile_tablet_app not_specifically_instructed_workers paper based_printouts perform_routine_maintenance_tasks skilled_instructed_workers skilled_workers c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6190v_mobile _ubiquitous_and_pervasive_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it manufacturing engineering telecommunication human_resources,maintenance_engineering mobile_computing personnel production_engineering_computing,maintenance_routine_checklist mere_paper based_approach microsoft_hololens_2_mixed_reality_device mobile_tablet_app not_specifically_instructed_workers paper based_printouts perform_routine_maintenance_tasks skilled_instructed_workers skilled_workers,availability skilled worker become severe issue production company developed country like germany recent year specialist maintenance task strong demand workforce steered towards challenging task maintenance case study analyze whether le skilled specifically instructed worker perform routine maintenance task without directly supported expert setup ten participant try handle maintenance routine checklist three different way paper based printout mobile tablet microsoft hololens 2 mixed reality mr device result show worker fail complete task mere paper based approach able succeed mobile tablet mr application quantitative time measurement qualitative analysis indicate mobile tablet app easier learn impair worker much hololens worked stable however hololens solution showed advantage hand free spatial guiding device could important aspect better mr hardware available mr interaction principle become common knowledge right reserved elsevier,maintenance_engineering mobile_computing personnel production_engineering_computing maintenance_routine_checklist mere_paper based_approach microsoft_hololens_2_mixed_reality_device mobile_tablet_app not_specifically_instructed_workers paper based_printouts perform_routine_maintenance_tasks skilled_instructed_workers skilled_workers c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6190v_mobile _ubiquitous_and_pervasive_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it manufacturing engineering telecommunication human_resources availability skilled worker become severe issue production company developed country like germany recent year specialist maintenance task strong demand workforce steered towards challenging task maintenance case study analyze whether le skilled specifically instructed worker perform routine maintenance task without directly supported expert setup ten participant try handle maintenance routine checklist three different way paper based printout mobile tablet microsoft hololens 2 mixed reality mr device result show worker fail complete task mere paper based approach able succeed mobile tablet mr application quantitative time measurement qualitative analysis indicate mobile tablet app easier learn impair worker much hololens worked stable however hololens solution showed advantage hand free spatial guiding device could important aspect better mr hardware available mr interaction principle become common knowledge right reserved elsevier,availability skilled worker become severe issue production company developed country like germany recent year specialist maintenance task strong demand workforce steered towards challenging task maintenance case study analyze whether le skilled specifically instructed worker perform routine maintenance task without directly supported expert setup ten participant try handle maintenance routine checklist three different way paper based printout mobile tablet microsoft hololens 2 mixed reality mr device result show worker fail complete task mere paper based approach able succeed mobile tablet mr application quantitative time measurement qualitative analysis indicate mobile tablet app easier learn impair worker much hololens worked stable however hololens solution showed advantage hand free spatial guiding device could important aspect better mr hardware available mr interaction principle become common knowledge right reserved elseviermaintenance_engineering mobile_computing personnel production_engineering_computingmaintenance_routine_checklist mere_paper based_approach microsoft_hololens_2_mixed_reality_device mobile_tablet_app not_specifically_instructed_workers paper based_printouts perform_routine_maintenance_tasks skilled_instructed_workers skilled_workers
361,Robotic Technology as the Basis of Implementation of Industry 4.0 in Production Processes in China,"Karabegović, I., Husak, E., Karabegović, E., & Mahmić, M. (2023). Robotic Technology as the Basis of Implementation of Industry 4.0 in Production Processes in China. Lecture Notes in Networks and Systems, 3–18. https://doi.org/10.1007/978-3-031-31066-9_1
",10.1007/978-3-031-31066-9_1,"The implementation of Industry 4.0 has been intensively present in the surrounding countries in the last five to six years. However, its concept is not widespread enough in production processes in the world. Its implementation will improve many aspects of human life in all segments of society. The business paradigm and production models will change at all levels of production processes, including the supply chain. Major changes have taken place in the recent years, such as the transformation of production systems, consumption, delivery, logistics, etc., all due to the implementation of the latest technological discoveries such as: robotics, automation, 3D printing, Internet of Things (IoT), smart sensors, Big Data, Cloud Computing, Radio Frequency Identification (RFID), Virtual and Augmented Reality (AR), Artificial Intelligence (AI), Cyber-Physical Systems (CPS), etc. The implementation strategy of Industry 4.0 consists of adapting industrial production to complete smart automation, which means introducing methods of self-automation, self-configuration, self-diagnosis and elimination of problems, knowledge, and intelligent decision-making. By implementing the &lsquo;&rsquo;Made in China 2025&rsquo;&rsquo; strategy, China has become the first country in the world in terms of robot implementation and vehicle production. The paper provides an analysis of Industry 4.0 patent applications and the trend of robot implementation in the last ten years with the aim of presenting the implementation of Industry 4.0. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","716.3 Radio Systems and Equipment;722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;731.1 Control Systems;731.6 Robot Applications;745.1.1 Printing Equipment;911.3 Inventory Control;912 Industrial Engineering and Management;912.2 Management;913 Production Planning and Control; Manufacturing;913.4 Manufacturing",China;Delivery logistics;Human lives;Production models;Production process;Production system;Robot implementation;Robotic automation;Robotic technologies;Technological discoveries,3D printing;Augmented reality;Decision making;Embedded systems;Intelligent robots;Internet of things;Metadata;Radio frequency identification (RFID);Supply chains,2023,Conference article (CA),Lect. Notes Networks Syst.,"(1) Karabegovi&#263;, Isak; (2) Husak, Ermin; (2) Karabegovi&#263;, Edina; (2) Mahmi&#263;, Mehmed; ","(1) Academy of Sciences and Arts of Bosnia and Herzegovina, Bistrik 7, Sarajevo; 71000, Bosnia and Herzegovina; (2) Technical Faculty Biha&#263;, Univesity of Biha&#263;, Ul.Irfana Ljubijanki&#263;a Bb, Biha&#263;; 77000, Bosnia and Herzegovina; ",Springer Science and Business Media Deutschland GmbH,-1,"[""3d printing"", ""decision making"", ""embedded systems"", ""intelligent robots"", ""internet of things"", ""metadata"", ""radio frequency identification"", ""supply chains""]","[""3d printing"", ""decision making"", ""embedded systems"", ""intelligent robots"", ""internet of things"", ""metadata"", ""radio frequency identification"", ""supply chains""]",3d printing;decision making;embedded systems;intelligent robots;internet of things;metadata;radio frequency identification;supply chains,education;semiconductors;robotics;other;input;human factors;internet of things;telecommunication;developers;data;manufacturing;business planning and management;networks,other;business;end users and user experience;industries;technology,education;semiconductors;robotics;other;input;human factors;internet of things;telecommunication;developers;data;manufacturing;business planning and management;networks,other;business;end users and user experience;industries;technology,3d_printing decision_making embedded_systems intelligent_robots internet_of_things metadata radio_frequency_identification supply_chains china delivery_logistics human_lives production_models production_process production_system robot_implementation robotic_automation robotic_technologies technological_discoveries 716 3_radio_systems_and_equipment 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 731 1_control_systems 731 6_robot_applications 745 1 1_printing_equipment 911 3_inventory_control 912_industrial_engineering_and_management 912 2_management 913_production_planning_and_control _manufacturing 913 4_manufacturing education semiconductors robotics other input human_factors internet_of_things telecommunication developers data manufacturing business_planning_and_management networks,3d_printing decision_making embedded_systems intelligent_robots internet_of_things metadata radio_frequency_identification supply_chains,china delivery_logistics human_lives production_models production_process production_system robot_implementation robotic_automation robotic_technologies technological_discoveries,implementation industry 4 0 intensively present surrounding country last five six year however concept widespread enough production process world implementation improve many aspect human life segment society business paradigm production model change level production process including supply chain major change taken place recent year transformation production system consumption delivery logistics etc due implementation latest technological discovery robotics automation 3d printing internet thing iot smart sensor big data cloud computing radio frequency identification rfid virtual augmented reality ar artificial intelligence ai cyber physical system cps etc implementation strategy industry 4 0 consists adapting industrial production complete smart automation mean introducing method self automation self configuration self diagnosis elimination problem knowledge intelligent decision making implementing lsquo rsquo made china 2025 rsquo rsquo strategy china become first country world term robot implementation vehicle production paper provides analysis industry 4 0 patent application trend robot implementation last ten year aim presenting implementation industry 4 0 copy 2023 author exclusive license springer nature switzerland ag,3d_printing decision_making embedded_systems intelligent_robots internet_of_things metadata radio_frequency_identification supply_chains china delivery_logistics human_lives production_models production_process production_system robot_implementation robotic_automation robotic_technologies technological_discoveries 716 3_radio_systems_and_equipment 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 731 1_control_systems 731 6_robot_applications 745 1 1_printing_equipment 911 3_inventory_control 912_industrial_engineering_and_management 912 2_management 913_production_planning_and_control _manufacturing 913 4_manufacturing education semiconductors robotics other input human_factors internet_of_things telecommunication developers data manufacturing business_planning_and_management networks implementation industry 4 0 intensively present surrounding country last five six year however concept widespread enough production process world implementation improve many aspect human life segment society business paradigm production model change level production process including supply chain major change taken place recent year transformation production system consumption delivery logistics etc due implementation latest technological discovery robotics automation 3d printing internet thing iot smart sensor big data cloud computing radio frequency identification rfid virtual augmented reality ar artificial intelligence ai cyber physical system cps etc implementation strategy industry 4 0 consists adapting industrial production complete smart automation mean introducing method self automation self configuration self diagnosis elimination problem knowledge intelligent decision making implementing lsquo rsquo made china 2025 rsquo rsquo strategy china become first country world term robot implementation vehicle production paper provides analysis industry 4 0 patent application trend robot implementation last ten year aim presenting implementation industry 4 0 copy 2023 author exclusive license springer nature switzerland ag,implementation industry 4 0 intensively present surrounding country last five six year however concept widespread enough production process world implementation improve many aspect human life segment society business paradigm production model change level production process including supply chain major change taken place recent year transformation production system consumption delivery logistics etc due implementation latest technological discovery robotics automation 3d printing internet thing iot smart sensor big data cloud computing radio frequency identification rfid virtual augmented reality ar artificial intelligence ai cyber physical system cps etc implementation strategy industry 4 0 consists adapting industrial production complete smart automation mean introducing method self automation self configuration self diagnosis elimination problem knowledge intelligent decision making implementing lsquo rsquo made china 2025 rsquo rsquo strategy china become first country world term robot implementation vehicle production paper provides analysis industry 4 0 patent application trend robot implementation last ten year aim presenting implementation industry 4 0 copy 2023 author exclusive license springer nature switzerland ag3d_printing decision_making embedded_systems intelligent_robots internet_of_things metadata radio_frequency_identification supply_chainschina delivery_logistics human_lives production_models production_process production_system robot_implementation robotic_automation robotic_technologies technological_discoveries
362,Predictive digital twin for offshore wind farms,"Haghshenas, A., Hasan, A., Osen, O., & Mikalsen, E. T. (2023). Predictive digital twin for offshore wind farms. Energy Informatics, 6(1). https://doi.org/10.1186/s42162-023-00257-4
",10.1186/s42162-023-00257-4,"As wind turbines continue to grow in size, they are increasingly being deployed offshore. This causes operation and maintenance of wind turbines becoming more challenging. Digitalization is a key enabling technology to manage wind farms in hostile environments and potentially increasing safety and reducing operational and maintenance costs. Digital infrastructure based on Industry 4.0 concept, such as digital twin, enables data collection, visualization, and analysis of wind power analytic at either individual turbine or wind farm level. In this paper, the concept of predictive digital twin for wind farm applications is introduced and demonstrated. To this end, a digital twin platform based on Unity3D for visualization and OPC Unified Architecture (OPC-UA) for data communication is developed. The platform is completed with the Prophet prediction algorithm to detect potential failure of wind turbine components in the near future and presented in augmented reality to enhance user experience. The presentation is intuitive and easy to use. The limitations of the platform include a lack of support for specific features like electronic signature, enhanced failover, and historical data sources. Simulation results based on the Hywind Tampen floating wind farm configuration show our proposed platform has promising potentials for offshore wind farm applications.",B8245 Wind power plants;C6130V Virtual reality;C7410B Power engineering computing;C7480 Production engineering computing;E0410D Industrial applications of IT,data collection;digital infrastructure;digital twin platform;digitalization;hostile environments;individual turbine;maintenance costs;offshore wind farm applications;offshore wind farms;OPC Unified Architecture;potentially increasing safety;Prophet prediction algorithm;wind farm configuration;wind power;wind turbine components;wind turbines,augmented reality;cyber-physical systems;digital twins;offshore installations;power engineering computing;production engineering computing;wind power plants;wind turbines,2023,Journal article (JA),Energy Inform. (Germany),"(1) Haghshenas, A.; (2) Hasan, A.; (2) Osen, O.; (1) Mikalsen, E.T.; ","(1) Offshore Simulator Centre AS, Norway; (2) Norwegian University of Science and Technology, Department of ICT and Natural Sciences, Norway; ",Springer,-1,"[""cyber-physical systems"", ""digital twins"", ""offshore installations"", ""power engineering computing"", ""production engineering computing"", ""wind power plants"", ""wind turbines""]","[""cyber-physical systems"", ""digital twins"", ""offshore installations"", ""power engineering computing"", ""production engineering computing"", ""wind power plants"", ""wind turbines""]",cyber-physical systems;digital twins;offshore installations;power engineering computing;production engineering computing;wind power plants;wind turbines,education;farming and natural science;robotics;other;power and energy;engineering;smart cities;manufacturing;integration,other;business;industries;use cases;technology,education;farming and natural science;robotics;other;power and energy;engineering;smart cities;manufacturing;integration,other;business;industries;use cases;technology,cyber physical_systems digital_twins offshore_installations power_engineering_computing production_engineering_computing wind_power_plants wind_turbines data_collection digital_infrastructure digital_twin_platform digitalization hostile_environments individual_turbine maintenance_costs offshore_wind_farm_applications offshore_wind_farms opc_unified_architecture potentially_increasing_safety prophet_prediction_algorithm wind_farm_configuration wind_power wind_turbine_components wind_turbines b8245_wind_power_plants c6130v_virtual_reality c7410b_power_engineering_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it education farming_and_natural_science robotics other power_and_energy engineering smart_cities manufacturing integration,cyber physical_systems digital_twins offshore_installations power_engineering_computing production_engineering_computing wind_power_plants wind_turbines,data_collection digital_infrastructure digital_twin_platform digitalization hostile_environments individual_turbine maintenance_costs offshore_wind_farm_applications offshore_wind_farms opc_unified_architecture potentially_increasing_safety prophet_prediction_algorithm wind_farm_configuration wind_power wind_turbine_components wind_turbines,wind turbine continue grow size increasingly deployed offshore cause operation maintenance wind turbine becoming challenging digitalization key enabling technology manage wind farm hostile environment potentially increasing safety reducing operational maintenance cost digital infrastructure based industry 4 0 concept digital twin enables data collection visualization analysis wind power analytic either individual turbine wind farm level paper concept predictive digital twin wind farm application introduced demonstrated end digital twin platform based unity3d visualization opc unified architecture opc ua data communication developed platform completed prophet prediction algorithm detect potential failure wind turbine component near future presented augmented reality enhance user experience presentation intuitive easy use limitation platform include lack support specific feature like electronic signature enhanced failover historical data source simulation result based hywind tampen floating wind farm configuration show proposed platform promising potential offshore wind farm application,cyber physical_systems digital_twins offshore_installations power_engineering_computing production_engineering_computing wind_power_plants wind_turbines data_collection digital_infrastructure digital_twin_platform digitalization hostile_environments individual_turbine maintenance_costs offshore_wind_farm_applications offshore_wind_farms opc_unified_architecture potentially_increasing_safety prophet_prediction_algorithm wind_farm_configuration wind_power wind_turbine_components wind_turbines b8245_wind_power_plants c6130v_virtual_reality c7410b_power_engineering_computing c7480_production_engineering_computing e0410d_industrial_applications_of_it education farming_and_natural_science robotics other power_and_energy engineering smart_cities manufacturing integration wind turbine continue grow size increasingly deployed offshore cause operation maintenance wind turbine becoming challenging digitalization key enabling technology manage wind farm hostile environment potentially increasing safety reducing operational maintenance cost digital infrastructure based industry 4 0 concept digital twin enables data collection visualization analysis wind power analytic either individual turbine wind farm level paper concept predictive digital twin wind farm application introduced demonstrated end digital twin platform based unity3d visualization opc unified architecture opc ua data communication developed platform completed prophet prediction algorithm detect potential failure wind turbine component near future presented augmented reality enhance user experience presentation intuitive easy use limitation platform include lack support specific feature like electronic signature enhanced failover historical data source simulation result based hywind tampen floating wind farm configuration show proposed platform promising potential offshore wind farm application,wind turbine continue grow size increasingly deployed offshore cause operation maintenance wind turbine becoming challenging digitalization key enabling technology manage wind farm hostile environment potentially increasing safety reducing operational maintenance cost digital infrastructure based industry 4 0 concept digital twin enables data collection visualization analysis wind power analytic either individual turbine wind farm level paper concept predictive digital twin wind farm application introduced demonstrated end digital twin platform based unity3d visualization opc unified architecture opc ua data communication developed platform completed prophet prediction algorithm detect potential failure wind turbine component near future presented augmented reality enhance user experience presentation intuitive easy use limitation platform include lack support specific feature like electronic signature enhanced failover historical data source simulation result based hywind tampen floating wind farm configuration show proposed platform promising potential offshore wind farm applicationcyber physical_systems digital_twins offshore_installations power_engineering_computing production_engineering_computing wind_power_plants wind_turbinesdata_collection digital_infrastructure digital_twin_platform digitalization hostile_environments individual_turbine maintenance_costs offshore_wind_farm_applications offshore_wind_farms opc_unified_architecture potentially_increasing_safety prophet_prediction_algorithm wind_farm_configuration wind_power wind_turbine_components wind_turbines
363,Demystifying and Analysing Metaverse Towards Education 4.0,"Raj, A., Sharma, V., Rani, S., Singh, T., Shanu, A. K., & Alkhayyat, A. (2023). Demystifying and Analysing Metaverse Towards Education 4.0. 2023 3rd International Conference on Innovative Practices in Technology and Management (ICIPTM). https://doi.org/10.1109/iciptm57143.2023.10118054
",10.1109/ICIPTM57143.2023.10118054,"The word Metaverse has influenced many sectors such as healthcare, education, retail and manufacturing and few more industries are there which will be impacted by 2026 as per the research conducted by Gartner. The word ""Metaverse"" especially in education sector came into existence after the COVID-19 epidemic when the humanity were forced to think about the new methodology of educating and teaching. This ecosphere is the combination of technologies which enables multimodal interactions with artificial environment, electronic library and people such as Virtual Reality (VR) and Augmented Reality (AR). It is believed that metaverse will improve collaboration, training process will be enhanced and most importantly it will create a happier workplace. This is only the reason that many corporate giants like Nvidia, facebook, apple, epic Games and companies has shifted towards this pedagogical ecosystem. This technology has the potential which enables absolute incorporating user conversation in actual-time and compelling interactivity with digital artifact. In this paper, we are addressing metaverse in education along with a detailed framework of metaverse in education. It includes a comparative study of conventional education, online education and metaverse education based on parameters like place of learning, resources used, teaching methodology, learning experience, learning target and learning assessment. Competency based education, energize student and positive attitude towards learning. The various challenges of the metaverse in educational sector are also debated. This paper will help the researcher's fraternity to get a deeper insight along with a clear perception of this ecosystem in education.",C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces;C7210N Information networks,AR;artificial environment;augmented reality;competency based education;COVID-19 epidemic;Education 4.0;education sector;educational sector;electronic library;Metaverse;metaverse education;multimodal interactions;online education;teaching;virtual reality;VR,computer aided instruction;diseases;epidemics;social networking (online);teaching;virtual reality,2023,Conference article (CA),2023 3rd International Conference on Innovative Practices in Technology and Management (ICIPTM),"(1) Raj, A.; (2) Sharma, V.; (2) Rani, S.; (3) Singh, T.; (1) Shanu, A.K.; (4) Alkhayyat, A.; ","(1) Galgotias University, School of Computing Science and Engineering, India; (2) Amity University, Amity Institute of Information Technology, India; (3) University of California, Department of Mechanical Engineering, United States; (4) Islamic University, College of technical engineering, Iraq; ",IEEE,-1,"[""computer aided instruction"", ""diseases"", ""epidemics"", ""social networking"", ""teaching""]","[""computer aided instruction"", ""diseases"", ""epidemics"", ""social networking"", ""teaching""]",computer aided instruction;diseases;epidemics;social networking;teaching,medical;education;training;collaboration,use cases;industries,medical;education;training;collaboration,use cases;industries,computer_aided_instruction diseases epidemics social_networking teaching ar artificial_environment augmented_reality competency_based_education covid 19_epidemic education_4 0 education_sector educational_sector electronic_library metaverse metaverse_education multimodal_interactions online_education teaching virtual_reality vr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks medical education training collaboration,computer_aided_instruction diseases epidemics social_networking teaching,ar artificial_environment augmented_reality competency_based_education covid 19_epidemic education_4 0 education_sector educational_sector electronic_library metaverse metaverse_education multimodal_interactions online_education teaching virtual_reality vr,word metaverse influenced many sector healthcare education retail manufacturing industry impacted 2026 per research conducted gartner word metaverse especially education sector came existence covid 19 epidemic humanity forced think new methodology educating teaching ecosphere combination technology enables multimodal interaction artificial environment electronic library people virtual reality vr augmented reality ar believed metaverse improve collaboration training process enhanced importantly create happier workplace reason many corporate giant like nvidia facebook apple epic game company shifted towards pedagogical ecosystem technology potential enables absolute incorporating user conversation actual time compelling interactivity digital artifact paper addressing metaverse education along detailed framework metaverse education includes comparative study conventional education online education metaverse education based parameter like place learning resource used teaching methodology learning experience learning target learning assessment competency based education energize student positive attitude towards learning various challenge metaverse educational sector also debated paper help researcher fraternity get deeper insight along clear perception ecosystem education,computer_aided_instruction diseases epidemics social_networking teaching ar artificial_environment augmented_reality competency_based_education covid 19_epidemic education_4 0 education_sector educational_sector electronic_library metaverse metaverse_education multimodal_interactions online_education teaching virtual_reality vr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7210n_information_networks medical education training collaboration word metaverse influenced many sector healthcare education retail manufacturing industry impacted 2026 per research conducted gartner word metaverse especially education sector came existence covid 19 epidemic humanity forced think new methodology educating teaching ecosphere combination technology enables multimodal interaction artificial environment electronic library people virtual reality vr augmented reality ar believed metaverse improve collaboration training process enhanced importantly create happier workplace reason many corporate giant like nvidia facebook apple epic game company shifted towards pedagogical ecosystem technology potential enables absolute incorporating user conversation actual time compelling interactivity digital artifact paper addressing metaverse education along detailed framework metaverse education includes comparative study conventional education online education metaverse education based parameter like place learning resource used teaching methodology learning experience learning target learning assessment competency based education energize student positive attitude towards learning various challenge metaverse educational sector also debated paper help researcher fraternity get deeper insight along clear perception ecosystem education,word metaverse influenced many sector healthcare education retail manufacturing industry impacted 2026 per research conducted gartner word metaverse especially education sector came existence covid 19 epidemic humanity forced think new methodology educating teaching ecosphere combination technology enables multimodal interaction artificial environment electronic library people virtual reality vr augmented reality ar believed metaverse improve collaboration training process enhanced importantly create happier workplace reason many corporate giant like nvidia facebook apple epic game company shifted towards pedagogical ecosystem technology potential enables absolute incorporating user conversation actual time compelling interactivity digital artifact paper addressing metaverse education along detailed framework metaverse education includes comparative study conventional education online education metaverse education based parameter like place learning resource used teaching methodology learning experience learning target learning assessment competency based education energize student positive attitude towards learning various challenge metaverse educational sector also debated paper help researcher fraternity get deeper insight along clear perception ecosystem educationcomputer_aided_instruction diseases epidemics social_networking teachingar artificial_environment augmented_reality competency_based_education covid 19_epidemic education_4 0 education_sector educational_sector electronic_library metaverse metaverse_education multimodal_interactions online_education teaching virtual_reality vr
364,WebJump: AR-facilitated Distributed Display of Web Pages,"Zeng, X., Wang, X., Gou, Z., Chen, Y., & Zhang, T. (2023). WebJump: AR-facilitated Distributed Display of Web Pages. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585669
",10.1145/3544549.3585669,"Head-mounted displays (HMD) like AR glasses support powerful 3D displays and intuitive input modalities. However, there is a lack of collaboration between the HMD and other displays like PC monitors. In this paper, we propose WebJump, a software tool that analyzes HTML web pages and enables UI elements 'jump' from the PC monitor to the HMD. This way, contents like high-resolution images and long texts can take full advantage of the high-quality monitor display. Auxiliary contents like sidebars and menus, on the other hand, are offloaded to the HMD for easier access albeit with a lower display quality. We describe our software tool and explain in detail its implementation. We develop two applications to demonstrate WebJump's feasibility and potential.",C7210N Information networks;C5540D Computer displays;C6130V Virtual reality,AR-facilitated distributed display;head-mounted displays;high-quality monitor display;HMD;intuitive input modalities;PC monitor;software tool;UI elements;Web pages;WebJump,augmented reality;helmet mounted displays;Internet;three-dimensional displays;user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Zeng, X.; (2) Wang, X.; (3) Gou, Z.; (1) Chen, Y.; (1) Zhang, T.; ","(1) Institute of Computing Technology, China; (2) Peking University, Yuanpei College, China; (3) Tsinghua University, Pervasive Human Computer Interaction Laboratory, China; ",ACM,-1,"[""helmet mounted displays"", ""internet"", ""three-dimensional displays"", ""user interfaces""]","[""helmet mounted displays"", ""internet"", ""three-dimensional displays"", ""user interfaces""]",helmet mounted displays;internet;three-dimensional displays;user interfaces,display technology;wearables;human-computer interaction;networks,technology;displays;end users and user experience,display technology;wearables;human-computer interaction;networks,technology;displays;end users and user experience,helmet_mounted_displays internet three dimensional_displays user_interfaces ar facilitated_distributed_display head mounted_displays high quality_monitor_display hmd intuitive_input_modalities pc_monitor software_tool ui_elements web_pages webjump c7210n_information_networks c5540d_computer_displays c6130v_virtual_reality display_technology wearables human computer_interaction networks,helmet_mounted_displays internet three dimensional_displays user_interfaces,ar facilitated_distributed_display head mounted_displays high quality_monitor_display hmd intuitive_input_modalities pc_monitor software_tool ui_elements web_pages webjump,head mounted display hmd like ar glass support powerful 3d display intuitive input modality however lack collaboration hmd display like pc monitor paper propose webjump software tool analyzes html web page enables ui element jump pc monitor hmd way content like high resolution image long text take full advantage high quality monitor display auxiliary content like sidebar menu hand offloaded hmd easier access albeit lower display quality describe software tool explain detail implementation develop two application demonstrate webjump feasibility potential,helmet_mounted_displays internet three dimensional_displays user_interfaces ar facilitated_distributed_display head mounted_displays high quality_monitor_display hmd intuitive_input_modalities pc_monitor software_tool ui_elements web_pages webjump c7210n_information_networks c5540d_computer_displays c6130v_virtual_reality display_technology wearables human computer_interaction networks head mounted display hmd like ar glass support powerful 3d display intuitive input modality however lack collaboration hmd display like pc monitor paper propose webjump software tool analyzes html web page enables ui element jump pc monitor hmd way content like high resolution image long text take full advantage high quality monitor display auxiliary content like sidebar menu hand offloaded hmd easier access albeit lower display quality describe software tool explain detail implementation develop two application demonstrate webjump feasibility potential,head mounted display hmd like ar glass support powerful 3d display intuitive input modality however lack collaboration hmd display like pc monitor paper propose webjump software tool analyzes html web page enables ui element jump pc monitor hmd way content like high resolution image long text take full advantage high quality monitor display auxiliary content like sidebar menu hand offloaded hmd easier access albeit lower display quality describe software tool explain detail implementation develop two application demonstrate webjump feasibility potentialhelmet_mounted_displays internet three dimensional_displays user_interfacesar facilitated_distributed_display head mounted_displays high quality_monitor_display hmd intuitive_input_modalities pc_monitor software_tool ui_elements web_pages webjump
365,Spatiality and Semantics - Towards Understanding Content Placement in Mixed Reality,"Ellenberg, M. O., Satkowski, M., Luo, W., & Dachselt, R. (2023). Spatiality and Semantics - Towards Understanding Content Placement in Mixed Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585853
",10.1145/3544549.3585853,"Mixed Reality (MR) popularizes numerous situated applications where virtual content is spatially integrated into our physical environment. However, we only know little about what properties of an environment influence the way how people place digital content and perceive the resulting layout. We thus conducted a preliminary study (N = 8) examining how physical surfaces affect organizing virtual content like documents or charts, focusing on user perception and experience. We found, among others, that the situated layout of virtual content in its environment can be characterized by the level of spatial as well as semantic coupling. Consequently, we propose a two-dimensional design space to establish the vocabularies and detail their parameters for content organization. With our work, we aim to facilitate communication between designers or researchers, inform general MR interface design, and provide a first step towards future MR workspaces empowered by blending digital content and its real-world context.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C6180 User interfaces,content organization;content placement;digital content;mixed reality;MR interface design;MR workspaces;physical environment;physical surfaces;semantic coupling;situated layout;two-dimensional design space;user experience;user perception;virtual content,augmented reality;human computer interaction;human factors;user experience;user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Ellenberg, M.O.; (2) Satkowski, M.; (3) Luo, W.; (1) Dachselt, R.; ","(1) Technische Universitat Dresden, Germany and Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany; (2) Technische Universitat Dresden, Germany and Centre for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI), Germany; (3) Interactive Media Lab Dresden, Germany; ",ACM,-1,"[""human computer interaction"", ""human factors"", ""user experience"", ""user interfaces""]","[""human computer interaction"", ""human factors"", ""user experience"", ""user interfaces""]",human computer interaction;human factors;user experience;user interfaces,human factors;human-computer interaction,end users and user experience,human factors;human-computer interaction,end users and user experience,human_computer_interaction human_factors user_experience user_interfaces content_organization content_placement digital_content mixed_reality mr_interface_design mr_workspaces physical_environment physical_surfaces semantic_coupling situated_layout two dimensional_design_space user_experience user_perception virtual_content c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces human_factors human computer_interaction,human_computer_interaction human_factors user_experience user_interfaces,content_organization content_placement digital_content mixed_reality mr_interface_design mr_workspaces physical_environment physical_surfaces semantic_coupling situated_layout two dimensional_design_space user_experience user_perception virtual_content,mixed reality mr popularizes numerous situated application virtual content spatially integrated physical environment however know little property environment influence way people place digital content perceive resulting layout thus conducted preliminary study n 8 examining physical surface affect organizing virtual content like document chart focusing user perception experience found among others situated layout virtual content environment characterized level spatial well semantic coupling consequently propose two dimensional design space establish vocabulary detail parameter content organization work aim facilitate communication designer researcher inform general mr interface design provide first step towards future mr workspace empowered blending digital content real world context,human_computer_interaction human_factors user_experience user_interfaces content_organization content_placement digital_content mixed_reality mr_interface_design mr_workspaces physical_environment physical_surfaces semantic_coupling situated_layout two dimensional_design_space user_experience user_perception virtual_content c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c6180_user_interfaces human_factors human computer_interaction mixed reality mr popularizes numerous situated application virtual content spatially integrated physical environment however know little property environment influence way people place digital content perceive resulting layout thus conducted preliminary study n 8 examining physical surface affect organizing virtual content like document chart focusing user perception experience found among others situated layout virtual content environment characterized level spatial well semantic coupling consequently propose two dimensional design space establish vocabulary detail parameter content organization work aim facilitate communication designer researcher inform general mr interface design provide first step towards future mr workspace empowered blending digital content real world context,mixed reality mr popularizes numerous situated application virtual content spatially integrated physical environment however know little property environment influence way people place digital content perceive resulting layout thus conducted preliminary study n 8 examining physical surface affect organizing virtual content like document chart focusing user perception experience found among others situated layout virtual content environment characterized level spatial well semantic coupling consequently propose two dimensional design space establish vocabulary detail parameter content organization work aim facilitate communication designer researcher inform general mr interface design provide first step towards future mr workspace empowered blending digital content real world contexthuman_computer_interaction human_factors user_experience user_interfacescontent_organization content_placement digital_content mixed_reality mr_interface_design mr_workspaces physical_environment physical_surfaces semantic_coupling situated_layout two dimensional_design_space user_experience user_perception virtual_content
366,ChameleonControl: Teleoperating Real Human Surrogates through Mixed Reality Gestural Guidance for Remote Hands-on Classrooms,"Faridan, M., Kumari, B., & Suzuki, R. (2023). ChameleonControl: Teleoperating Real Human Surrogates through Mixed Reality Gestural Guidance for Remote Hands-on Classrooms. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3581381
",10.1145/3544548.3581381,"We present ChameleonControl, a real-human teleoperation system for scalable remote instruction in hands-on classrooms. In contrast to existing video or AR/VR-based remote hands-on education, ChameleonControl uses a real human as a surrogate of a remote instructor. Building on existing human-based telepresence approaches, we contribute a novel method to teleoperate a human surrogate through synchronized mixed reality hand gestural navigation and verbal communication. By overlaying the remote instructor's virtual hands in the local user's MR view, the remote instructor can guide and control the local user as if they were physically present. This allows the local user/surrogate to synchronize their hand movements and gestures with the remote instructor, effectively teleoperating a real human. We deploy and evaluate our system in classrooms of physiotherapy training, as well as other application domains such as mechanical assembly, sign language and cooking lessons. The study results confirm that our approach can increase engagement and the sense of co-presence, showing potential for the future of remote hands-on classrooms.",C6130V Virtual reality;C3390T Telerobotics;C5260B Computer vision and image processing techniques;C6180 User interfaces,ChameleonControl;existing video;hand movements;human surrogate;local user;mixed reality gestural guidance;real-human teleoperation system;remote hands-on;remote instructor;scalable remote instruction;synchronized mixed reality hand gestural navigation;teleoperating,augmented reality;gesture recognition;human computer interaction;telecontrol;telerobotics;virtual reality,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Faridan, M.; (2) Kumari, B.; (2) Suzuki, R.; ","(1) University of Calgary, Canada and MaKami College, Calgary, AB, Canada; (2) University of Calgary, Calgary, AB, Canada; ",ACM,-1,"[""gesture recognition"", ""human computer interaction"", ""telecontrol"", ""telerobotics""]","[""gesture recognition"", ""human computer interaction"", ""telecontrol"", ""telerobotics""]",gesture recognition;human computer interaction;telecontrol;telerobotics,human factors;input;robotics;human-computer interaction,technology;end users and user experience,human factors;input;robotics;human-computer interaction,technology;end users and user experience,gesture_recognition human_computer_interaction telecontrol telerobotics chameleoncontrol existing_video hand_movements human_surrogate local_user mixed_reality_gestural_guidance real human_teleoperation_system remote_hands on remote_instructor scalable_remote_instruction synchronized_mixed_reality_hand_gestural_navigation teleoperating c6130v_virtual_reality c3390t_telerobotics c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces human_factors input robotics human computer_interaction,gesture_recognition human_computer_interaction telecontrol telerobotics,chameleoncontrol existing_video hand_movements human_surrogate local_user mixed_reality_gestural_guidance real human_teleoperation_system remote_hands on remote_instructor scalable_remote_instruction synchronized_mixed_reality_hand_gestural_navigation teleoperating,present chameleoncontrol real human teleoperation system scalable remote instruction hand classroom contrast existing video ar vr based remote hand education chameleoncontrol us real human surrogate remote instructor building existing human based telepresence approach contribute novel method teleoperate human surrogate synchronized mixed reality hand gestural navigation verbal communication overlaying remote instructor virtual hand local user mr view remote instructor guide control local user physically present allows local user surrogate synchronize hand movement gesture remote instructor effectively teleoperating real human deploy evaluate system classroom physiotherapy training well application domain mechanical assembly sign language cooking lesson study result confirm approach increase engagement sense co presence showing potential future remote hand classroom,gesture_recognition human_computer_interaction telecontrol telerobotics chameleoncontrol existing_video hand_movements human_surrogate local_user mixed_reality_gestural_guidance real human_teleoperation_system remote_hands on remote_instructor scalable_remote_instruction synchronized_mixed_reality_hand_gestural_navigation teleoperating c6130v_virtual_reality c3390t_telerobotics c5260b_computer_vision_and_image_processing_techniques c6180_user_interfaces human_factors input robotics human computer_interaction present chameleoncontrol real human teleoperation system scalable remote instruction hand classroom contrast existing video ar vr based remote hand education chameleoncontrol us real human surrogate remote instructor building existing human based telepresence approach contribute novel method teleoperate human surrogate synchronized mixed reality hand gestural navigation verbal communication overlaying remote instructor virtual hand local user mr view remote instructor guide control local user physically present allows local user surrogate synchronize hand movement gesture remote instructor effectively teleoperating real human deploy evaluate system classroom physiotherapy training well application domain mechanical assembly sign language cooking lesson study result confirm approach increase engagement sense co presence showing potential future remote hand classroom,present chameleoncontrol real human teleoperation system scalable remote instruction hand classroom contrast existing video ar vr based remote hand education chameleoncontrol us real human surrogate remote instructor building existing human based telepresence approach contribute novel method teleoperate human surrogate synchronized mixed reality hand gestural navigation verbal communication overlaying remote instructor virtual hand local user mr view remote instructor guide control local user physically present allows local user surrogate synchronize hand movement gesture remote instructor effectively teleoperating real human deploy evaluate system classroom physiotherapy training well application domain mechanical assembly sign language cooking lesson study result confirm approach increase engagement sense co presence showing potential future remote hand classroomgesture_recognition human_computer_interaction telecontrol teleroboticschameleoncontrol existing_video hand_movements human_surrogate local_user mixed_reality_gestural_guidance real human_teleoperation_system remote_hands on remote_instructor scalable_remote_instruction synchronized_mixed_reality_hand_gestural_navigation teleoperating
367,Can Cross-Reality Help Nonspeaking Autistic People Transition to AR Typing?,"Alabood, L., Dow, T., Kaufman, K. M., Jaswal, V. K., & Krishnamurthy, D. (2023). Can Cross-Reality Help Nonspeaking Autistic People Transition to AR Typing? Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585859
",10.1145/3544549.3585859,"About of autistic people are nonspeakers; they cannot use speech to communicate effectively. Pointing to letters on a letterboard held by a Communication and Regulation Partner (CRP) is one alternative method of expressive communication that some members of this population use. In the training of this method, a CRP delivers engaging and customized lessons. Additionally, the CRP provides regulatory, sensory, and attentional support and also works to strengthen the subject's pointing skills. The goal of this training is to equip individuals with the required skills to be able to type independently. Recent studies have proposed using AR to provide opportunities for nonspeakers to practice the motor skills involved in typing. To use such systems, however, there needs to be a transition phase where a CRP teaches their subject how to interact with a virtual letterboard. In this paper, we explore the feasibility of using cross-reality, in which a CRP and nonspeaker can interact with the same virtual objects simultaneously, as a possible means of fostering this transition. We report a study involving 5 nonspeaking autistic subjects with diverse motor skills interacting using a virtual HoloLens 2 letterboard system we developed called HoloBoard. All subjects succeeded in pointing to letters correctly or spelling on the virtual board. We report process and design recommendations based on feedback obtained from subjects and their CRPs.",C6130V Virtual reality;C6180 User interfaces;C7810C Computer-aided instruction,"5 nonspeaking autistic subjects;attentional support;autistic people transition;cross-reality help;CRP;diverse motor skills;expressive communication;nonspeaker;pointing skills;regulatory support;required skills;sensory, support;transition phase;typing;virtual HoloLens 2 letterboard system;virtual letterboard",augmented reality;computer aided instruction;handicapped aids;medical disorders;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Alabood, L.; (1) Dow, T.; (2) Kaufman, K.M.; (2) Jaswal, V.K.; (1) Krishnamurthy, D.; ","(1) University of Calgary, Electrical and Software Engineering, Calgary, AB, Canada; (2) University of Virginia, Charlottesville, VA, United States; ",ACM,-1,"[""computer aided instruction"", ""handicapped aids"", ""medical disorders""]","[""computer aided instruction"", ""handicapped aids"", ""medical disorders""]",computer aided instruction;handicapped aids;medical disorders,medical;training,use cases;industries,medical;training,use cases;industries,computer_aided_instruction handicapped_aids medical_disorders 5_nonspeaking_autistic_subjects attentional_support autistic_people_transition cross reality_help crp diverse_motor_skills expressive_communication nonspeaker pointing_skills regulatory_support required_skills sensory _support transition_phase typing virtual_hololens_2_letterboard_system virtual_letterboard c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction medical training,computer_aided_instruction handicapped_aids medical_disorders,5_nonspeaking_autistic_subjects attentional_support autistic_people_transition cross reality_help crp diverse_motor_skills expressive_communication nonspeaker pointing_skills regulatory_support required_skills sensory _support transition_phase typing virtual_hololens_2_letterboard_system virtual_letterboard,autistic people nonspeakers cannot use speech communicate effectively pointing letter letterboard held communication regulation partner crp one alternative method expressive communication member population use training method crp delivers engaging customized lesson additionally crp provides regulatory sensory attentional support also work strengthen subject pointing skill goal training equip individual required skill able type independently recent study proposed using ar provide opportunity nonspeakers practice motor skill involved typing use system however need transition phase crp teach subject interact virtual letterboard paper explore feasibility using cross reality crp nonspeaker interact virtual object simultaneously possible mean fostering transition report study involving 5 nonspeaking autistic subject diverse motor skill interacting using virtual hololens 2 letterboard system developed called holoboard subject succeeded pointing letter correctly spelling virtual board report process design recommendation based feedback obtained subject crp,computer_aided_instruction handicapped_aids medical_disorders 5_nonspeaking_autistic_subjects attentional_support autistic_people_transition cross reality_help crp diverse_motor_skills expressive_communication nonspeaker pointing_skills regulatory_support required_skills sensory _support transition_phase typing virtual_hololens_2_letterboard_system virtual_letterboard c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction medical training autistic people nonspeakers cannot use speech communicate effectively pointing letter letterboard held communication regulation partner crp one alternative method expressive communication member population use training method crp delivers engaging customized lesson additionally crp provides regulatory sensory attentional support also work strengthen subject pointing skill goal training equip individual required skill able type independently recent study proposed using ar provide opportunity nonspeakers practice motor skill involved typing use system however need transition phase crp teach subject interact virtual letterboard paper explore feasibility using cross reality crp nonspeaker interact virtual object simultaneously possible mean fostering transition report study involving 5 nonspeaking autistic subject diverse motor skill interacting using virtual hololens 2 letterboard system developed called holoboard subject succeeded pointing letter correctly spelling virtual board report process design recommendation based feedback obtained subject crp,autistic people nonspeakers cannot use speech communicate effectively pointing letter letterboard held communication regulation partner crp one alternative method expressive communication member population use training method crp delivers engaging customized lesson additionally crp provides regulatory sensory attentional support also work strengthen subject pointing skill goal training equip individual required skill able type independently recent study proposed using ar provide opportunity nonspeakers practice motor skill involved typing use system however need transition phase crp teach subject interact virtual letterboard paper explore feasibility using cross reality crp nonspeaker interact virtual object simultaneously possible mean fostering transition report study involving 5 nonspeaking autistic subject diverse motor skill interacting using virtual hololens 2 letterboard system developed called holoboard subject succeeded pointing letter correctly spelling virtual board report process design recommendation based feedback obtained subject crpcomputer_aided_instruction handicapped_aids medical_disorders5_nonspeaking_autistic_subjects attentional_support autistic_people_transition cross reality_help crp diverse_motor_skills expressive_communication nonspeaker pointing_skills regulatory_support required_skills sensory _support transition_phase typing virtual_hololens_2_letterboard_system virtual_letterboard
368,Application of analytical hierarchy process model in selecting an appropriate digital marketing communication technology: A case study of a textile company,"Mukhsinov, B. T., & Ergashxodjayeva, S. D. (2022). Application of analytical hierarchy process model in selecting an appropriate digital marketing communication technology: A case study of a textile company. Proceedings of the 6th International Conference on Future Networks &amp; Distributed Systems. https://doi.org/10.1145/3584202.3584241
",10.1145/3584202.3584241,"Differently from traditional marketing communication, digital marketing communication is characterized to facilitate efficiently communication between businesses and consumers through different digital technologies such as social media platforms, artificial intelligence, virtual reality, and augmented reality. However, the successful selection of an appropriate digital marketing communication technology has become crucial for the businesses that aims to promote their products efficiently. In the case of a textile company in Uzbekistan, our work aims to show how to select an appropriate digital marketing communication tool compatible with company marketing strategy and target market by using analytical hierarchy process model, so as to support the marketing communication-based decision making of businesses. In this regard, selection criteria are identified through extensive review of relevant literature and stakeholder interview (including questionnaire) and then importance of each criterion is measured based on the analytical hierarchy process model to develop hierarchy of those criteria. The ranking of five alternative marketing communication technologies is identified based on the success scores derived from consumer-based survey and selection criteria weights. The results show that social media platforms such as telegram are more preferable to be implemented in digital marketing communication activities of the company. Through the analytical hierarchy process model, we uncovered important recommendations for businesses in retail industry about enhancing their marketing communication strategies.",C7210N Information networks;C6130V Virtual reality;C7170 Marketing computing,alternative marketing communication technologies;analytical hierarchy process model;appropriate digital marketing communication technology;appropriate digital marketing communication tool;company marketing strategy;different digital technologies;digital marketing communication activities;efficiently communication;marketing communication strategies;marketing communication-based decision making;selection criteria;social media platforms;target market;traditional marketing communication,analytic hierarchy process;artificial intelligence;augmented reality;decision making;marketing data processing;social networking (online);virtual reality,2022,Conference article (CA),ICFNDS '22: Proceedings of the 6th International Conference on Future Networks &amp; Distributed Systems,"(1) Mukhsinov, B.T.; (2) Ergashxodjayeva, S.D.; ","(1) Bukhara Engineering Technological Institute, Macroeconomics Department of Economics Faculty, Uzbekistan; (2) Tashkent State University of Economics, Macroeconomics Department of Economics Faculty, Uzbekistan; ",ACM,-1,"[""analytic hierarchy process"", ""artificial intelligence"", ""decision making"", ""marketing data processing"", ""social networking""]","[""analytic hierarchy process"", ""artificial intelligence"", ""decision making"", ""marketing data processing"", ""social networking""]",analytic hierarchy process;artificial intelligence;decision making;marketing data processing;social networking,liberal arts;sales and marketing;collaboration;human factors;data;artificial intelligence,business;industries;end users and user experience;use cases;technology,liberal arts;sales and marketing;collaboration;human factors;data;artificial intelligence,business;industries;end users and user experience;use cases;technology,analytic_hierarchy_process artificial_intelligence decision_making marketing_data_processing social_networking alternative_marketing_communication_technologies analytical_hierarchy_process_model appropriate_digital_marketing_communication_technology appropriate_digital_marketing_communication_tool company_marketing_strategy different_digital_technologies digital_marketing_communication_activities efficiently_communication marketing_communication_strategies marketing_communication based_decision_making selection_criteria social_media_platforms target_market traditional_marketing_communication c7210n_information_networks c6130v_virtual_reality c7170_marketing_computing liberal_arts sales_and_marketing collaboration human_factors data artificial_intelligence,analytic_hierarchy_process artificial_intelligence decision_making marketing_data_processing social_networking,alternative_marketing_communication_technologies analytical_hierarchy_process_model appropriate_digital_marketing_communication_technology appropriate_digital_marketing_communication_tool company_marketing_strategy different_digital_technologies digital_marketing_communication_activities efficiently_communication marketing_communication_strategies marketing_communication based_decision_making selection_criteria social_media_platforms target_market traditional_marketing_communication,differently traditional marketing communication digital marketing communication characterized facilitate efficiently communication business consumer different digital technology social medium platform artificial intelligence virtual reality augmented reality however successful selection appropriate digital marketing communication technology become crucial business aim promote product efficiently case textile company uzbekistan work aim show select appropriate digital marketing communication tool compatible company marketing strategy target market using analytical hierarchy process model support marketing communication based decision making business regard selection criterion identified extensive review relevant literature stakeholder interview including questionnaire importance criterion measured based analytical hierarchy process model develop hierarchy criterion ranking five alternative marketing communication technology identified based success score derived consumer based survey selection criterion weight result show social medium platform telegram preferable implemented digital marketing communication activity company analytical hierarchy process model uncovered important recommendation business retail industry enhancing marketing communication strategy,analytic_hierarchy_process artificial_intelligence decision_making marketing_data_processing social_networking alternative_marketing_communication_technologies analytical_hierarchy_process_model appropriate_digital_marketing_communication_technology appropriate_digital_marketing_communication_tool company_marketing_strategy different_digital_technologies digital_marketing_communication_activities efficiently_communication marketing_communication_strategies marketing_communication based_decision_making selection_criteria social_media_platforms target_market traditional_marketing_communication c7210n_information_networks c6130v_virtual_reality c7170_marketing_computing liberal_arts sales_and_marketing collaboration human_factors data artificial_intelligence differently traditional marketing communication digital marketing communication characterized facilitate efficiently communication business consumer different digital technology social medium platform artificial intelligence virtual reality augmented reality however successful selection appropriate digital marketing communication technology become crucial business aim promote product efficiently case textile company uzbekistan work aim show select appropriate digital marketing communication tool compatible company marketing strategy target market using analytical hierarchy process model support marketing communication based decision making business regard selection criterion identified extensive review relevant literature stakeholder interview including questionnaire importance criterion measured based analytical hierarchy process model develop hierarchy criterion ranking five alternative marketing communication technology identified based success score derived consumer based survey selection criterion weight result show social medium platform telegram preferable implemented digital marketing communication activity company analytical hierarchy process model uncovered important recommendation business retail industry enhancing marketing communication strategy,differently traditional marketing communication digital marketing communication characterized facilitate efficiently communication business consumer different digital technology social medium platform artificial intelligence virtual reality augmented reality however successful selection appropriate digital marketing communication technology become crucial business aim promote product efficiently case textile company uzbekistan work aim show select appropriate digital marketing communication tool compatible company marketing strategy target market using analytical hierarchy process model support marketing communication based decision making business regard selection criterion identified extensive review relevant literature stakeholder interview including questionnaire importance criterion measured based analytical hierarchy process model develop hierarchy criterion ranking five alternative marketing communication technology identified based success score derived consumer based survey selection criterion weight result show social medium platform telegram preferable implemented digital marketing communication activity company analytical hierarchy process model uncovered important recommendation business retail industry enhancing marketing communication strategyanalytic_hierarchy_process artificial_intelligence decision_making marketing_data_processing social_networkingalternative_marketing_communication_technologies analytical_hierarchy_process_model appropriate_digital_marketing_communication_technology appropriate_digital_marketing_communication_tool company_marketing_strategy different_digital_technologies digital_marketing_communication_activities efficiently_communication marketing_communication_strategies marketing_communication based_decision_making selection_criteria social_media_platforms target_market traditional_marketing_communication
369,From motivational experience to creative writing: A motivational AR-based learning approach to promoting Chinese writing performance and positive writing behaviours,"Li, M., Chen, Y.-T., Huang, C.-Q., Hwang, G.-J., & Cukurova, M. (2023). From motivational experience to creative writing: A motivational AR-based learning approach to promoting Chinese writing performance and positive writing behaviours. Computers &amp; Education, 202, 104844. https://doi.org/10.1016/j.compedu.2023.104844
",10.1016/j.compedu.2023.104844,"The ability to write is one of the key literacies required by students in relation to 21st century skills and is an emphasis of early education. Although the ability to write is a vital foundation for further education, due to the lack of authentic experience and limited instructional methods, cultivating writing ability in the early stage of education is still a significant challenge for students in elementary schools. Therefore, the majority of students are not able to actively engage in the process of learning to write. To address these problems, this study proposes a motivational AR-based (MAR) learning approach to support students in learning to write, which not only provides an authentic learning environment, but also aims to motivate students' active writing. Its effects were verified through a quasi-experiment. A total of 47 elementary school students from China were invited to participate, and were assigned to either an experimental group (EG) which was exposed to the MAR approach or the control group (CG) which was exposed to the motivational learning approach in a conventional environment (MC). The results showed that the proposed MAR learning approach improved the students' writing performance in terms of feature descriptiveness and thinking innovation. It can be found that, compared with the CG, the achievement gaps between the low- and high-engagement students were much larger in the EG. In addition, the sequential pattern analysis results showed that students who learned with the MAR learning approach concentrated more on the process of observation than those who learned with the MC learning approach, and they tended to exhibit less distracted behaviours. To sum up, the proposed MAR learning approach was effective in terms of facilitating elementary school students&rsquo; writing education. The main contribution of our study is that it provides evidence for the effectiveness of the proposed MAR learning approach and opens up opportunities for future studies which aim to further explore its impacts in different designs of writing learning activities. &copy; 2023 Elsevier Ltd","723 Computer Software, Data Handling and Applications;723.5 Computer Applications;901.2 Education",Augmented and virtual realities;Elementary education;Elementary schools;Experimental groups;Exposed to;Improving classroom teaching;Learning approach;School students;Teaching/learning strategy;Writing performance,Augmented reality;Computer aided instruction;E-learning;Learning systems;Virtual reality,2023,Journal article (JA),Comput Educ,"(1) Li, Ming; (1) Chen, Yu-Ting; (1) Huang, Chang-Qin; (2) Hwang, Gwo-Jen; (4) Cukurova, Mutlu; ","(1) Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, China; (2) Graduate Institute of Digital Learning and Education, National Taiwan University of Science and Technology, Taiwan; (3) Yuan Ze University, Taiwan; (4) UCL Institute of Education, University College London, United Kingdom; ",Elsevier Ltd,-1,"[""computer aided instruction"", ""e-learning"", ""learning systems""]","[""computer aided instruction"", ""e-learning"", ""learning systems""]",computer aided instruction;e-learning;learning systems,medical;education;training,use cases;industries,medical;education;training,use cases;industries,computer_aided_instruction e learning learning_systems augmented_and_virtual_realities elementary_education elementary_schools experimental_groups exposed_to improving_classroom_teaching learning_approach school_students teaching learning_strategy writing_performance 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education medical education training,computer_aided_instruction e learning learning_systems,augmented_and_virtual_realities elementary_education elementary_schools experimental_groups exposed_to improving_classroom_teaching learning_approach school_students teaching learning_strategy writing_performance,ability write one key literacy required student relation 21st century skill emphasis early education although ability write vital foundation education due lack authentic experience limited instructional method cultivating writing ability early stage education still significant challenge student elementary school therefore majority student able actively engage process learning write address problem study proposes motivational ar based mar learning approach support student learning write provides authentic learning environment also aim motivate student active writing effect verified quasi experiment total 47 elementary school student china invited participate assigned either experimental group eg exposed mar approach control group cg exposed motivational learning approach conventional environment mc result showed proposed mar learning approach improved student writing performance term feature descriptiveness thinking innovation found compared cg achievement gap low high engagement student much larger eg addition sequential pattern analysis result showed student learned mar learning approach concentrated process observation learned mc learning approach tended exhibit le distracted behaviour sum proposed mar learning approach effective term facilitating elementary school student rsquo writing education main contribution study provides evidence effectiveness proposed mar learning approach open opportunity future study aim explore impact different design writing learning activity copy 2023 elsevier ltd,computer_aided_instruction e learning learning_systems augmented_and_virtual_realities elementary_education elementary_schools experimental_groups exposed_to improving_classroom_teaching learning_approach school_students teaching learning_strategy writing_performance 723_computer_software _data_handling_and_applications 723 5_computer_applications 901 2_education medical education training ability write one key literacy required student relation 21st century skill emphasis early education although ability write vital foundation education due lack authentic experience limited instructional method cultivating writing ability early stage education still significant challenge student elementary school therefore majority student able actively engage process learning write address problem study proposes motivational ar based mar learning approach support student learning write provides authentic learning environment also aim motivate student active writing effect verified quasi experiment total 47 elementary school student china invited participate assigned either experimental group eg exposed mar approach control group cg exposed motivational learning approach conventional environment mc result showed proposed mar learning approach improved student writing performance term feature descriptiveness thinking innovation found compared cg achievement gap low high engagement student much larger eg addition sequential pattern analysis result showed student learned mar learning approach concentrated process observation learned mc learning approach tended exhibit le distracted behaviour sum proposed mar learning approach effective term facilitating elementary school student rsquo writing education main contribution study provides evidence effectiveness proposed mar learning approach open opportunity future study aim explore impact different design writing learning activity copy 2023 elsevier ltd,ability write one key literacy required student relation 21st century skill emphasis early education although ability write vital foundation education due lack authentic experience limited instructional method cultivating writing ability early stage education still significant challenge student elementary school therefore majority student able actively engage process learning write address problem study proposes motivational ar based mar learning approach support student learning write provides authentic learning environment also aim motivate student active writing effect verified quasi experiment total 47 elementary school student china invited participate assigned either experimental group eg exposed mar approach control group cg exposed motivational learning approach conventional environment mc result showed proposed mar learning approach improved student writing performance term feature descriptiveness thinking innovation found compared cg achievement gap low high engagement student much larger eg addition sequential pattern analysis result showed student learned mar learning approach concentrated process observation learned mc learning approach tended exhibit le distracted behaviour sum proposed mar learning approach effective term facilitating elementary school student rsquo writing education main contribution study provides evidence effectiveness proposed mar learning approach open opportunity future study aim explore impact different design writing learning activity copy 2023 elsevier ltdcomputer_aided_instruction e learning learning_systemsaugmented_and_virtual_realities elementary_education elementary_schools experimental_groups exposed_to improving_classroom_teaching learning_approach school_students teaching learning_strategy writing_performance
370,Data-driven and AR assisted intelligent collaborative assembly system for large-scale complex products,"Liu, X., Zheng, L., Shuai, J., Zhang, R., & Li, Y. (2020). Data-driven and AR assisted intelligent collaborative assembly system for large-scale complex products. Procedia CIRP, 93, 1049–1054. https://doi.org/10.1016/j.procir.2020.04.041
",10.1016/j.procir.2020.04.041,"With the continuous improvement of function diversity, quality and reliability, the complexity and scale of significant products such as aerospace equipment are increasing. This trend poses severe challenges to the assembly process. The large scale of products requires the fixed-position assembly with multiple roles of workers in parallel, and it increases the difficulty of multi-person assembly. The high complexity of products makes the assembly process tedious. It is time-consuming and laborious for workers to understand the 2D documents, and it easily leads to mis-operation. The assembly process of complex products can produce huge amounts of data, which have the potential for improving efficiency and quality but remain underutilized. The high reliability of products puts forward high requirements for real-time detection of the assembly process. With the development of information technology, data driven approach and Augmented Reality (AR) provide an efficient way to change the above situation. Therefore, this paper proposes an intelligent collaboration assembly system (ICAS) combining real-time data driven method with AR technology. In the ICAS, real-time data driven method is used to realize the human-to-human and human-to-machine collaboration under the fixed-position assembly, and AR is introduced to the system to assist the assembly of large-scale complex products. The intelligent detection method in the ICAS combines 3D reconstruction with sensors measurement data, and the detection result is displayed in an intuitive way by AR. The proposed system is verified in the assembly process of a large-scale space deployable mechanism, and it paves the way for the further development of intelligent assembly in the future. [All rights reserved Elsevier].","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7480 Production engineering computing;E0410D Industrial applications of IT;E1520C Assembling",assembly process;intelligent assembly;intelligent collaboration assembly system;intelligent collaborative assembly system;multiperson assembly;significant products,assembling;augmented reality;image reconstruction;production engineering computing,2020,Journal article (JA),Procedia CIRP (Netherlands),(1) Xinyu Liu; (1) Lianyu Zheng; (1) Jiazhou Shuai; (1) Renjie Zhang; (2) Yun Li; ,"(1) Beihang University, School of Mechanical Engineering and Automation, 37 xueyuan road, China; (2) China Academy of Space Technology, Beijing Spacecrafts, 102 dengzhuang south road, haidian district, China; ",Elsevier B.V.,-1,"[""assembling"", ""image reconstruction"", ""production engineering computing""]","[""assembling"", ""image reconstruction"", ""production engineering computing""]",assembling;image reconstruction;production engineering computing,construction;computer vision;manufacturing;engineering,technology;industries,construction;computer vision;manufacturing;engineering,technology;industries,assembling image_reconstruction production_engineering_computing assembly_process intelligent_assembly intelligent_collaboration_assembly_system intelligent_collaborative_assembly_system multiperson_assembly significant_products b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it e1520c_assembling construction computer_vision manufacturing engineering,assembling image_reconstruction production_engineering_computing,assembly_process intelligent_assembly intelligent_collaboration_assembly_system intelligent_collaborative_assembly_system multiperson_assembly significant_products,continuous improvement function diversity quality reliability complexity scale significant product aerospace equipment increasing trend pose severe challenge assembly process large scale product requires fixed position assembly multiple role worker parallel increase difficulty multi person assembly high complexity product make assembly process tedious time consuming laborious worker understand 2d document easily lead mi operation assembly process complex product produce huge amount data potential improving efficiency quality remain underutilized high reliability product put forward high requirement real time detection assembly process development information technology data driven approach augmented reality ar provide efficient way change situation therefore paper proposes intelligent collaboration assembly system icas combining real time data driven method ar technology icas real time data driven method used realize human human human machine collaboration fixed position assembly ar introduced system assist assembly large scale complex product intelligent detection method icas combine 3d reconstruction sensor measurement data detection result displayed intuitive way ar proposed system verified assembly process large scale space deployable mechanism pave way development intelligent assembly future right reserved elsevier,assembling image_reconstruction production_engineering_computing assembly_process intelligent_assembly intelligent_collaboration_assembly_system intelligent_collaborative_assembly_system multiperson_assembly significant_products b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7480_production_engineering_computing e0410d_industrial_applications_of_it e1520c_assembling construction computer_vision manufacturing engineering continuous improvement function diversity quality reliability complexity scale significant product aerospace equipment increasing trend pose severe challenge assembly process large scale product requires fixed position assembly multiple role worker parallel increase difficulty multi person assembly high complexity product make assembly process tedious time consuming laborious worker understand 2d document easily lead mi operation assembly process complex product produce huge amount data potential improving efficiency quality remain underutilized high reliability product put forward high requirement real time detection assembly process development information technology data driven approach augmented reality ar provide efficient way change situation therefore paper proposes intelligent collaboration assembly system icas combining real time data driven method ar technology icas real time data driven method used realize human human human machine collaboration fixed position assembly ar introduced system assist assembly large scale complex product intelligent detection method icas combine 3d reconstruction sensor measurement data detection result displayed intuitive way ar proposed system verified assembly process large scale space deployable mechanism pave way development intelligent assembly future right reserved elsevier,continuous improvement function diversity quality reliability complexity scale significant product aerospace equipment increasing trend pose severe challenge assembly process large scale product requires fixed position assembly multiple role worker parallel increase difficulty multi person assembly high complexity product make assembly process tedious time consuming laborious worker understand 2d document easily lead mi operation assembly process complex product produce huge amount data potential improving efficiency quality remain underutilized high reliability product put forward high requirement real time detection assembly process development information technology data driven approach augmented reality ar provide efficient way change situation therefore paper proposes intelligent collaboration assembly system icas combining real time data driven method ar technology icas real time data driven method used realize human human human machine collaboration fixed position assembly ar introduced system assist assembly large scale complex product intelligent detection method icas combine 3d reconstruction sensor measurement data detection result displayed intuitive way ar proposed system verified assembly process large scale space deployable mechanism pave way development intelligent assembly future right reserved elsevierassembling image_reconstruction production_engineering_computingassembly_process intelligent_assembly intelligent_collaboration_assembly_system intelligent_collaborative_assembly_system multiperson_assembly significant_products
371,Mixed Reality Based Teleoperation of Surgical Robotics,"Chen, A. C., Hadi, M., Kazanzides, P., & Azimi, E. (2023). Mixed Reality Based Teleoperation of Surgical Robotics. 2023 International Symposium on Medical Robotics (ISMR). https://doi.org/10.1109/ismr57123.2023.10130178
",10.1109/ISMR57123.2023.10130178,"Many surgical robotic systems are controlled by mechanical based devices that require the operator to remain at a fixed location away from the robot. This restriction in mobility and physical barrier between the surgeon and the robot may reduce procedural efficiency. Thus, we propose an alternative teleoperation approach and mixed reality based system that uses the surgeon's tracked hand poses to control the robot through the use of an untethered head mounted display. We conducted a controlled user study to assess the efficacy of our system. Our experimental results indicate that, for the ring-wire task we tested, there is not a considerable difference in the performance of users compared to existing mechanical based teleoperation devices.",C3385 Biological and medical control systems;C3390T Telerobotics;C5540D Computer displays;C6130V Virtual reality;C6180 User interfaces;C7420 Control engineering computing,mechanical based teleoperation devices;mixed reality based teleoperation system;physical barrier;surgeon;surgical robotic systems;untethered head mounted display,augmented reality;control engineering computing;helmet mounted displays;surgery;surgical robots;telerobotics,2023,Conference article (CA),2023 International Symposium on Medical Robotics (ISMR),"(1) Chen, A.C.; (1) Hadi, M.; (2) Kazanzides, P.; (2) Azimi, E.; ","(1) Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD 21218, United States; (2) Johns Hopkins University, Computer Science Department, Baltimore, MD 21218, United States; ",IEEE,-1,"[""control engineering computing"", ""helmet mounted displays"", ""surgery"", ""surgical robots"", ""telerobotics""]","[""control engineering computing"", ""helmet mounted displays"", ""surgery"", ""surgical robots"", ""telerobotics""]",control engineering computing;helmet mounted displays;surgery;surgical robots;telerobotics,other;robotics;medical;display technology;wearables;engineering,technology;other;displays;industries,other;robotics;medical;display technology;wearables;engineering,technology;other;displays;industries,control_engineering_computing helmet_mounted_displays surgery surgical_robots telerobotics mechanical_based_teleoperation_devices mixed_reality_based_teleoperation_system physical_barrier surgeon surgical_robotic_systems untethered_head_mounted_display c3385_biological_and_medical_control_systems c3390t_telerobotics c5540d_computer_displays c6130v_virtual_reality c6180_user_interfaces c7420_control_engineering_computing other robotics medical display_technology wearables engineering,control_engineering_computing helmet_mounted_displays surgery surgical_robots telerobotics,mechanical_based_teleoperation_devices mixed_reality_based_teleoperation_system physical_barrier surgeon surgical_robotic_systems untethered_head_mounted_display,many surgical robotic system controlled mechanical based device require operator remain fixed location away robot restriction mobility physical barrier surgeon robot may reduce procedural efficiency thus propose alternative teleoperation approach mixed reality based system us surgeon tracked hand pose control robot use untethered head mounted display conducted controlled user study ass efficacy system experimental result indicate ring wire task tested considerable difference performance user compared existing mechanical based teleoperation device,control_engineering_computing helmet_mounted_displays surgery surgical_robots telerobotics mechanical_based_teleoperation_devices mixed_reality_based_teleoperation_system physical_barrier surgeon surgical_robotic_systems untethered_head_mounted_display c3385_biological_and_medical_control_systems c3390t_telerobotics c5540d_computer_displays c6130v_virtual_reality c6180_user_interfaces c7420_control_engineering_computing other robotics medical display_technology wearables engineering many surgical robotic system controlled mechanical based device require operator remain fixed location away robot restriction mobility physical barrier surgeon robot may reduce procedural efficiency thus propose alternative teleoperation approach mixed reality based system us surgeon tracked hand pose control robot use untethered head mounted display conducted controlled user study ass efficacy system experimental result indicate ring wire task tested considerable difference performance user compared existing mechanical based teleoperation device,many surgical robotic system controlled mechanical based device require operator remain fixed location away robot restriction mobility physical barrier surgeon robot may reduce procedural efficiency thus propose alternative teleoperation approach mixed reality based system us surgeon tracked hand pose control robot use untethered head mounted display conducted controlled user study ass efficacy system experimental result indicate ring wire task tested considerable difference performance user compared existing mechanical based teleoperation devicecontrol_engineering_computing helmet_mounted_displays surgery surgical_robots teleroboticsmechanical_based_teleoperation_devices mixed_reality_based_teleoperation_system physical_barrier surgeon surgical_robotic_systems untethered_head_mounted_display
372,The Role of Artificial Intelligence in the Education Process of Political Science Field,"Khalifa, M. (2022). The Role of Artificial Intelligence in the Education Process of Political Science Field. 2022 ASU International Conference in Emerging Technologies for Sustainability and Intelligent Systems (ICETSIS). https://doi.org/10.1109/icetsis55481.2022.9888844
",10.1109/ICETSIS55481.2022.9888844,"Over the last two decades, the field of artificial intelligence in education has undergone significant changes. So, Recent years have witnessed very remarkable developments in the technical and technological fields. Political Science can help people understand themselves and their relationships with the governors and government. This valuable field helps people make better decisions and improve their lives. It is also helping address some of the world's most pressing problems, such as global poverty and national security. So, there is no doubt that political science as a branch of social sciences differs from practical fields such as Physics, Mathematics, and Biological Sciences, and therefore the use of artificial intelligence applications in the field will be different in some applications due to the characteristics of the field. The research problem revolved around the following question what is the role of artificial intelligence in improving the educational process in the political science field? The paper aims to highlight the AI Applications used in Educational Process, the difference between Virtual Reality and Augmented Reality in learning and teaching, as well as the applications of VR in teaching political science. The paper concluded that AI applications in political science allow students to experience the world around them in a completely different way, and it can be done anytime and anywhere. And students can learn how to express themselves fully and confidently. It is the technology that has the potential to transform the way students learn.",C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces;C6210 Knowledge based systems,AI applications;artificial intelligence applications;augmented reality;biological sciences;educational process;mathematics;physics;political science field;practical fields;social sciences;teaching;technical fields;technological fields;virtual reality;VR,artificial intelligence;computer aided instruction;politics;teaching;virtual reality,2022,Conference article (CA),2022 ASU International Conference in Emerging Technologies for Sustainability and Intelligent Systems (ICETSIS),"(1) Khalifa, M.; ","(1) Applied Science University (ASU) Kingdom of Bahrain & Suez Canal University, Egypt; ",IEEE,-1,"[""artificial intelligence"", ""computer aided instruction"", ""politics"", ""teaching""]","[""artificial intelligence"", ""computer aided instruction"", ""politics"", ""teaching""]",artificial intelligence;computer aided instruction;politics;teaching,education;liberal arts;training;policy;artificial intelligence,technology;business;use cases;industries,education;liberal arts;training;policy;artificial intelligence,technology;business;use cases;industries,artificial_intelligence computer_aided_instruction politics teaching ai_applications artificial_intelligence_applications augmented_reality biological_sciences educational_process mathematics physics political_science_field practical_fields social_sciences teaching technical_fields technological_fields virtual_reality vr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c6210_knowledge_based_systems education liberal_arts training policy artificial_intelligence,artificial_intelligence computer_aided_instruction politics teaching,ai_applications artificial_intelligence_applications augmented_reality biological_sciences educational_process mathematics physics political_science_field practical_fields social_sciences teaching technical_fields technological_fields virtual_reality vr,last two decade field artificial intelligence education undergone significant change recent year witnessed remarkable development technical technological field political science help people understand relationship governor government valuable field help people make better decision improve life also helping address world pressing problem global poverty national security doubt political science branch social science differs practical field physic mathematics biological science therefore use artificial intelligence application field different application due characteristic field research problem revolved around following question role artificial intelligence improving educational process political science field paper aim highlight ai application used educational process difference virtual reality augmented reality learning teaching well application vr teaching political science paper concluded ai application political science allow student experience world around completely different way done anytime anywhere student learn express fully confidently technology potential transform way student learn,artificial_intelligence computer_aided_instruction politics teaching ai_applications artificial_intelligence_applications augmented_reality biological_sciences educational_process mathematics physics political_science_field practical_fields social_sciences teaching technical_fields technological_fields virtual_reality vr c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c6210_knowledge_based_systems education liberal_arts training policy artificial_intelligence last two decade field artificial intelligence education undergone significant change recent year witnessed remarkable development technical technological field political science help people understand relationship governor government valuable field help people make better decision improve life also helping address world pressing problem global poverty national security doubt political science branch social science differs practical field physic mathematics biological science therefore use artificial intelligence application field different application due characteristic field research problem revolved around following question role artificial intelligence improving educational process political science field paper aim highlight ai application used educational process difference virtual reality augmented reality learning teaching well application vr teaching political science paper concluded ai application political science allow student experience world around completely different way done anytime anywhere student learn express fully confidently technology potential transform way student learn,last two decade field artificial intelligence education undergone significant change recent year witnessed remarkable development technical technological field political science help people understand relationship governor government valuable field help people make better decision improve life also helping address world pressing problem global poverty national security doubt political science branch social science differs practical field physic mathematics biological science therefore use artificial intelligence application field different application due characteristic field research problem revolved around following question role artificial intelligence improving educational process political science field paper aim highlight ai application used educational process difference virtual reality augmented reality learning teaching well application vr teaching political science paper concluded ai application political science allow student experience world around completely different way done anytime anywhere student learn express fully confidently technology potential transform way student learnartificial_intelligence computer_aided_instruction politics teachingai_applications artificial_intelligence_applications augmented_reality biological_sciences educational_process mathematics physics political_science_field practical_fields social_sciences teaching technical_fields technological_fields virtual_reality vr
373,Digital technology implementation and impact of artificial intelligence based on bipolar complex fuzzy Schweizer&ndash;Sklar power aggregation operators,"Mahmood, T., & Rehman, U. ur. (2023). Digital technology implementation and impact of artificial intelligence based on bipolar complex fuzzy Schweizer–Sklar power aggregation operators. Applied Soft Computing, 143, 110375. https://doi.org/10.1016/j.asoc.2023.110375
",10.1016/j.asoc.2023.110375,"Digital technology refers to any technology that uses digital signals or electronic data to process, store, and transmit information. Some examples of digital technologies include social media platforms, cloud computing, artificial intelligence, virtual and augmented reality, and blockchain technology. Digital technology has the potential to play a significant role in achieving sustainable development goals by providing solutions for a wide range of environmental, social, and economic challenges. In this manuscript, we investigate digital technology implementation under sustainable development and would find which area of sustainable development is most in need of digital technology. Further, we investigate the operational laws based on Schweizer&ndash;Sklar t-norm and t-conorm and originate aggregation operators based on these deduced operational laws under the environment of bipolar complex fuzzy set that is bipolar complex fuzzy Schweizer&ndash;Sklar power averaging, bipolar complex fuzzy Schweizer&ndash;Sklar power weighted averaging, bipolar complex fuzzy Schweizer&ndash;Sklar power geometric and bipolar complex fuzzy Schweizer&ndash;Sklar power weighted geometric operators and then we deduce techniques of decision-making utilizing these originated operators. Afterward, we tackle a numerical example related to the digital technology implementation under sustainable development by considering artificial data and finding the area of sustainable development which is most in need of digital technology. Moreover, we reveal the impact of one of the digital technologies that are artificial intelligence in the field of healthcare and study a numerical example by considering hypothetical data by employing the originated technique of decision-making. At the last, we do a comparison of the deduced operators with numerous current operators to reveal the superiority and benefits of the deduced operators. &copy; 2023 Elsevier B.V.","454 Environmental Engineering;454.2 Environmental Impact and Protection;461.7 Health Care;721.1 Computer Theory, Includes Formal Logic, Automata Theory, Switching Theory, Programming Theory;723 Computer Software, Data Handling and Applications;723.4 Artificial Intelligence;912.2 Management;921.6 Numerical Methods",Aggregation operator;Bipolar complex fuzzy set;Complex fuzzy sets;Decisions makings;Digital technologies;Healthcare;Operational laws;Power;Schweizer&ndash;sklar operation;Technology implementation,Artificial intelligence;Augmented reality;Decision making;Environmental regulations;Environmental technology;Fuzzy logic;Fuzzy sets;Health care;Mathematical operators;Sustainable development,2023,Journal article (JA),Appl. Soft Comput.,"(1) Mahmood, Tahir; (1) Rehman, Ubaid ur; ","(1) Department of Mathematics and Statistics, International Islamic University, Islamabad, Pakistan; ",Elsevier Ltd,-1,"[""artificial intelligence"", ""decision making"", ""environmental regulations"", ""environmental technology"", ""fuzzy logic"", ""fuzzy sets"", ""health care"", ""mathematical operators"", ""sustainable development""]","[""artificial intelligence"", ""decision making"", ""environmental regulations"", ""environmental technology"", ""fuzzy logic"", ""fuzzy sets"", ""health care"", ""mathematical operators"", ""sustainable development""]",artificial intelligence;decision making;environmental regulations;environmental technology;fuzzy logic;fuzzy sets;health care;mathematical operators;sustainable development,farming and natural science;other;liberal arts;medical;human factors;policy;human-computer interaction;artificial intelligence,other;business;end users and user experience;industries;technology,farming and natural science;other;liberal arts;medical;human factors;policy;human-computer interaction;artificial intelligence,other;business;end users and user experience;industries;technology,artificial_intelligence decision_making environmental_regulations environmental_technology fuzzy_logic fuzzy_sets health_care mathematical_operators sustainable_development aggregation_operator bipolar_complex_fuzzy_set complex_fuzzy_sets decisions_makings digital_technologies healthcare operational_laws power schweizer ndash sklar_operation technology_implementation 454_environmental_engineering 454 2_environmental_impact_and_protection 461 7_health_care 721 1_computer_theory _includes_formal_logic _automata_theory _switching_theory _programming_theory 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 912 2_management 921 6_numerical_methods farming_and_natural_science other liberal_arts medical human_factors policy human computer_interaction artificial_intelligence,artificial_intelligence decision_making environmental_regulations environmental_technology fuzzy_logic fuzzy_sets health_care mathematical_operators sustainable_development,aggregation_operator bipolar_complex_fuzzy_set complex_fuzzy_sets decisions_makings digital_technologies healthcare operational_laws power schweizer ndash sklar_operation technology_implementation,digital technology refers technology us digital signal electronic data process store transmit information example digital technology include social medium platform cloud computing artificial intelligence virtual augmented reality blockchain technology digital technology potential play significant role achieving sustainable development goal providing solution wide range environmental social economic challenge manuscript investigate digital technology implementation sustainable development would find area sustainable development need digital technology investigate operational law based schweizer ndash sklar norm conorm originate aggregation operator based deduced operational law environment bipolar complex fuzzy set bipolar complex fuzzy schweizer ndash sklar power averaging bipolar complex fuzzy schweizer ndash sklar power weighted averaging bipolar complex fuzzy schweizer ndash sklar power geometric bipolar complex fuzzy schweizer ndash sklar power weighted geometric operator deduce technique decision making utilizing originated operator afterward tackle numerical example related digital technology implementation sustainable development considering artificial data finding area sustainable development need digital technology moreover reveal impact one digital technology artificial intelligence field healthcare study numerical example considering hypothetical data employing originated technique decision making last comparison deduced operator numerous current operator reveal superiority benefit deduced operator copy 2023 elsevier b v,artificial_intelligence decision_making environmental_regulations environmental_technology fuzzy_logic fuzzy_sets health_care mathematical_operators sustainable_development aggregation_operator bipolar_complex_fuzzy_set complex_fuzzy_sets decisions_makings digital_technologies healthcare operational_laws power schweizer ndash sklar_operation technology_implementation 454_environmental_engineering 454 2_environmental_impact_and_protection 461 7_health_care 721 1_computer_theory _includes_formal_logic _automata_theory _switching_theory _programming_theory 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 912 2_management 921 6_numerical_methods farming_and_natural_science other liberal_arts medical human_factors policy human computer_interaction artificial_intelligence digital technology refers technology us digital signal electronic data process store transmit information example digital technology include social medium platform cloud computing artificial intelligence virtual augmented reality blockchain technology digital technology potential play significant role achieving sustainable development goal providing solution wide range environmental social economic challenge manuscript investigate digital technology implementation sustainable development would find area sustainable development need digital technology investigate operational law based schweizer ndash sklar norm conorm originate aggregation operator based deduced operational law environment bipolar complex fuzzy set bipolar complex fuzzy schweizer ndash sklar power averaging bipolar complex fuzzy schweizer ndash sklar power weighted averaging bipolar complex fuzzy schweizer ndash sklar power geometric bipolar complex fuzzy schweizer ndash sklar power weighted geometric operator deduce technique decision making utilizing originated operator afterward tackle numerical example related digital technology implementation sustainable development considering artificial data finding area sustainable development need digital technology moreover reveal impact one digital technology artificial intelligence field healthcare study numerical example considering hypothetical data employing originated technique decision making last comparison deduced operator numerous current operator reveal superiority benefit deduced operator copy 2023 elsevier b v,digital technology refers technology us digital signal electronic data process store transmit information example digital technology include social medium platform cloud computing artificial intelligence virtual augmented reality blockchain technology digital technology potential play significant role achieving sustainable development goal providing solution wide range environmental social economic challenge manuscript investigate digital technology implementation sustainable development would find area sustainable development need digital technology investigate operational law based schweizer ndash sklar norm conorm originate aggregation operator based deduced operational law environment bipolar complex fuzzy set bipolar complex fuzzy schweizer ndash sklar power averaging bipolar complex fuzzy schweizer ndash sklar power weighted averaging bipolar complex fuzzy schweizer ndash sklar power geometric bipolar complex fuzzy schweizer ndash sklar power weighted geometric operator deduce technique decision making utilizing originated operator afterward tackle numerical example related digital technology implementation sustainable development considering artificial data finding area sustainable development need digital technology moreover reveal impact one digital technology artificial intelligence field healthcare study numerical example considering hypothetical data employing originated technique decision making last comparison deduced operator numerous current operator reveal superiority benefit deduced operator copy 2023 elsevier b vartificial_intelligence decision_making environmental_regulations environmental_technology fuzzy_logic fuzzy_sets health_care mathematical_operators sustainable_developmentaggregation_operator bipolar_complex_fuzzy_set complex_fuzzy_sets decisions_makings digital_technologies healthcare operational_laws power schweizer ndash sklar_operation technology_implementation
374,A Digital Twin Mixed-reality System for Testing Future Advanced Air Mobility Concepts: A Prototype,"Zhao, J., Conrad, C., Delezenne, Q., Xu, Y., & Tsourdos, A. (2023). A Digital Twin Mixed-reality System for Testing Future Advanced Air Mobility Concepts: A Prototype. 2023 Integrated Communication, Navigation and Surveillance Conference (ICNS). https://doi.org/10.1109/icns58246.2023.10124310
",10.1109/ICNS58246.2023.10124310,"The UK Future Flight Vision and Roadmap defines how aviation in the UK is envisioned to develop by 2030. As part of the Future Flight demonstration segment, project HADO (High-intensity Autonomous Drone Operations) will develop, test, and deploy fully automated Unmanned Aircraft System (UAS) operations at London Heathrow airport. The resource-demanding nature of real-world tests, however, suggests that developing and improving the reliability and efficiency of virtual environment-based testing methods is indispensable for the evolution of such operations. Nonetheless, developing a high-fidelity and real-time virtual environment that enables the safe, scalable, and sustainable development, verification, and validation of UAS operations remains a daunting task. Notably, the need to integrate physical and virtual elements with a high degree of correlation presents a significant challenge. Consequently, as part of the synthetic test environment work package within the HADO project, this paper proposes a Digital Twin (DT) system to enable mixed-reality tests in the context of autonomous UAS operations. This connects a physical world to its digital counterpart made up of five distinct layers and several digital elements to support enhanced mixed-reality functionality. The paper highlights how the static layers of the synthetic test environment are built, and presents a DT prototype that supports mixed-reality test capabilities. In particular, the ability to inject virtual obstacles into physical test environments is demonstrated, highlighting how the sharp boundaries between virtual environments and reality can be blurred for safe, flexible, efficient, and effective testing of UAS operations.",B7620 Aerospace testing and simulation;C3360L Aerospace control;C3390C Mobile robots;C6130V Virtual reality;C7460 Aerospace engineering computing,autonomous UAS operations;digital twin mixed-reality system;future advanced air mobility concept testing;HADO project;high-intensity autonomous drone operations;London Heathrow airport;roadmap;safe development;scalable development;sustainable development;UK future flight vision;unmanned aircraft system operations;virtual environment-based testing;virtual reality,aerospace computing;aerospace testing;airports;augmented reality;autonomous aerial vehicles;digital twins,2023,Conference article (CA),"2023 Integrated Communication, Navigation and Surveillance Conference (ICNS)","(1) Zhao, J.; (1) Conrad, C.; (1) Delezenne, Q.; (1) Xu, Y.; (1) Tsourdos, A.; ","(1) Cranfield University, School of Aerospace, Transport and Manufacturing, United Kingdom; ",IEEE,-1,"[""aerospace computing"", ""aerospace testing"", ""airports"", ""autonomous aerial vehicles"", ""digital twins""]","[""aerospace computing"", ""aerospace testing"", ""airports"", ""autonomous aerial vehicles"", ""digital twins""]",aerospace computing;aerospace testing;airports;autonomous aerial vehicles;digital twins,"other;aviation and aerospace;automotive;inspection, safety and quality;smart cities",other;use cases;industries,"other;aviation and aerospace;automotive;inspection, safety and quality;smart cities",other;use cases;industries,aerospace_computing aerospace_testing airports autonomous_aerial_vehicles digital_twins autonomous_uas_operations digital_twin_mixed reality_system future_advanced_air_mobility_concept_testing hado_project high intensity_autonomous_drone_operations london_heathrow_airport roadmap safe_development scalable_development sustainable_development uk_future_flight_vision unmanned_aircraft_system_operations virtual_environment based_testing virtual_reality b7620_aerospace_testing_and_simulation c3360l_aerospace_control c3390c_mobile_robots c6130v_virtual_reality c7460_aerospace_engineering_computing other aviation_and_aerospace automotive inspection _safety_and_quality smart_cities,aerospace_computing aerospace_testing airports autonomous_aerial_vehicles digital_twins,autonomous_uas_operations digital_twin_mixed reality_system future_advanced_air_mobility_concept_testing hado_project high intensity_autonomous_drone_operations london_heathrow_airport roadmap safe_development scalable_development sustainable_development uk_future_flight_vision unmanned_aircraft_system_operations virtual_environment based_testing virtual_reality,uk future flight vision roadmap defines aviation uk envisioned develop 2030 part future flight demonstration segment project hado high intensity autonomous drone operation develop test deploy fully automated unmanned aircraft system uas operation london heathrow airport resource demanding nature real world test however suggests developing improving reliability efficiency virtual environment based testing method indispensable evolution operation nonetheless developing high fidelity real time virtual environment enables safe scalable sustainable development verification validation uas operation remains daunting task notably need integrate physical virtual element high degree correlation present significant challenge consequently part synthetic test environment work package within hado project paper proposes digital twin dt system enable mixed reality test context autonomous uas operation connects physical world digital counterpart made five distinct layer several digital element support enhanced mixed reality functionality paper highlight static layer synthetic test environment built present dt prototype support mixed reality test capability particular ability inject virtual obstacle physical test environment demonstrated highlighting sharp boundary virtual environment reality blurred safe flexible efficient effective testing uas operation,aerospace_computing aerospace_testing airports autonomous_aerial_vehicles digital_twins autonomous_uas_operations digital_twin_mixed reality_system future_advanced_air_mobility_concept_testing hado_project high intensity_autonomous_drone_operations london_heathrow_airport roadmap safe_development scalable_development sustainable_development uk_future_flight_vision unmanned_aircraft_system_operations virtual_environment based_testing virtual_reality b7620_aerospace_testing_and_simulation c3360l_aerospace_control c3390c_mobile_robots c6130v_virtual_reality c7460_aerospace_engineering_computing other aviation_and_aerospace automotive inspection _safety_and_quality smart_cities uk future flight vision roadmap defines aviation uk envisioned develop 2030 part future flight demonstration segment project hado high intensity autonomous drone operation develop test deploy fully automated unmanned aircraft system uas operation london heathrow airport resource demanding nature real world test however suggests developing improving reliability efficiency virtual environment based testing method indispensable evolution operation nonetheless developing high fidelity real time virtual environment enables safe scalable sustainable development verification validation uas operation remains daunting task notably need integrate physical virtual element high degree correlation present significant challenge consequently part synthetic test environment work package within hado project paper proposes digital twin dt system enable mixed reality test context autonomous uas operation connects physical world digital counterpart made five distinct layer several digital element support enhanced mixed reality functionality paper highlight static layer synthetic test environment built present dt prototype support mixed reality test capability particular ability inject virtual obstacle physical test environment demonstrated highlighting sharp boundary virtual environment reality blurred safe flexible efficient effective testing uas operation,uk future flight vision roadmap defines aviation uk envisioned develop 2030 part future flight demonstration segment project hado high intensity autonomous drone operation develop test deploy fully automated unmanned aircraft system uas operation london heathrow airport resource demanding nature real world test however suggests developing improving reliability efficiency virtual environment based testing method indispensable evolution operation nonetheless developing high fidelity real time virtual environment enables safe scalable sustainable development verification validation uas operation remains daunting task notably need integrate physical virtual element high degree correlation present significant challenge consequently part synthetic test environment work package within hado project paper proposes digital twin dt system enable mixed reality test context autonomous uas operation connects physical world digital counterpart made five distinct layer several digital element support enhanced mixed reality functionality paper highlight static layer synthetic test environment built present dt prototype support mixed reality test capability particular ability inject virtual obstacle physical test environment demonstrated highlighting sharp boundary virtual environment reality blurred safe flexible efficient effective testing uas operationaerospace_computing aerospace_testing airports autonomous_aerial_vehicles digital_twinsautonomous_uas_operations digital_twin_mixed reality_system future_advanced_air_mobility_concept_testing hado_project high intensity_autonomous_drone_operations london_heathrow_airport roadmap safe_development scalable_development sustainable_development uk_future_flight_vision unmanned_aircraft_system_operations virtual_environment based_testing virtual_reality
375,Following the Master's Hands: Capturing Piano Performances for Mixed Reality Piano Learning Applications,"Labrou, K., Zaman, C. H., Turkyasar, A., & Davis, R. (2023). Following the Master’s Hands: Capturing Piano Performances for Mixed Reality Piano Learning Applications. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585838
",10.1145/3544549.3585838,"Piano learning applications in Mixed Reality (MR) are a promising substitute for physical instruction when a piano teacher is absent. Existing piano learning applications that use visual indicators to highlight the notes to be played on the keyboard or employ video projections of a pianist provide minimal guidance on how the learner should execute hand movements to develop their technique in performance and prevent injuries. To address this gap, we developed an immersive first-person piano learning experience that uses a library of targeted visualizations of the teacher's hands and 3D traces of hand movements in MR. Seeing the piano teacher's hands while hearing the music is central to developing the novice's musical intuition. We introduced an end-to-end workflow to accurately capture the pianist's technical gestures and align them with the musical score. We recorded pianists playing technical exercises and music pieces. We developed a multimodal performance dataset (MPD) comprising virtual hand models, keyboard (MIDI) recordings and the corresponding music scores, and different visualizations of hand traces capturing movement. Finally, we developed Pianoverse, an MR application to assist piano learning, and performed exploratory user testing with novice piano players to understand the impact of multimodal representations of movement on skill learning. Our initial observations suggest that apprehending the movement traces of a recorded performance over a physical keyboard increases the learner's ability to position their body and hands correctly and to replicate hand gestures while playing from written music. Further research will focus on automating performance data collection and a comprehensive evaluation of the use of leading movement traces in piano learning.",C7820 Humanities computing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C7810C Computer-aided instruction,automating performance data collection;capturing piano performances;corresponding music scores;different visualizations;end-to-end workflow;existing piano learning applications;first-person piano learning experience;hand gestures;hand movements;hand traces;keyboard recordings;leading movement;master;Mixed Reality piano learning applications;MR application;multimodal performance dataset;music pieces;musical score;novice piano players;physical keyboard;pianist;piano teacher;recorded performance;skill learning;targeted visualizations;virtual hand models;visual indicators;written music,augmented reality;computer aided instruction;gesture recognition;injuries;keyboards;music;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Labrou, K.; (2) Zaman, C.H.; (3) Turkyasar, A.; (4) Davis, R.; ","(1) Massachusetts Institute of Technology, Cambridge, MA, United States; (2) Massachusetts Institute of Technology, Virtual Experience Design Lab, Cambridge, MA, United States; (3) Mediate Labs, United States; (4) Northwestern University Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Evanston, IL, United States; ",ACM,-1,"[""computer aided instruction"", ""gesture recognition"", ""injuries"", ""keyboards"", ""music""]","[""computer aided instruction"", ""gesture recognition"", ""injuries"", ""keyboards"", ""music""]",computer aided instruction;gesture recognition;injuries;keyboards;music,input;medical;training;human factors;audio,technology;industries;use cases;end users and user experience,input;medical;training;human factors;audio,technology;industries;use cases;end users and user experience,computer_aided_instruction gesture_recognition injuries keyboards music automating_performance_data_collection capturing_piano_performances corresponding_music_scores different_visualizations end to end_workflow existing_piano_learning_applications first person_piano_learning_experience hand_gestures hand_movements hand_traces keyboard_recordings leading_movement master mixed_reality_piano_learning_applications mr_application multimodal_performance_dataset music_pieces musical_score novice_piano_players physical_keyboard pianist piano_teacher recorded_performance skill_learning targeted_visualizations virtual_hand_models visual_indicators written_music c7820_humanities_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction input medical training human_factors audio,computer_aided_instruction gesture_recognition injuries keyboards music,automating_performance_data_collection capturing_piano_performances corresponding_music_scores different_visualizations end to end_workflow existing_piano_learning_applications first person_piano_learning_experience hand_gestures hand_movements hand_traces keyboard_recordings leading_movement master mixed_reality_piano_learning_applications mr_application multimodal_performance_dataset music_pieces musical_score novice_piano_players physical_keyboard pianist piano_teacher recorded_performance skill_learning targeted_visualizations virtual_hand_models visual_indicators written_music,piano learning application mixed reality mr promising substitute physical instruction piano teacher absent existing piano learning application use visual indicator highlight note played keyboard employ video projection pianist provide minimal guidance learner execute hand movement develop technique performance prevent injury address gap developed immersive first person piano learning experience us library targeted visualization teacher hand 3d trace hand movement mr seeing piano teacher hand hearing music central developing novice musical intuition introduced end end workflow accurately capture pianist technical gesture align musical score recorded pianist playing technical exercise music piece developed multimodal performance dataset mpd comprising virtual hand model keyboard midi recording corresponding music score different visualization hand trace capturing movement finally developed pianoverse mr application assist piano learning performed exploratory user testing novice piano player understand impact multimodal representation movement skill learning initial observation suggest apprehending movement trace recorded performance physical keyboard increase learner ability position body hand correctly replicate hand gesture playing written music research focus automating performance data collection comprehensive evaluation use leading movement trace piano learning,computer_aided_instruction gesture_recognition injuries keyboards music automating_performance_data_collection capturing_piano_performances corresponding_music_scores different_visualizations end to end_workflow existing_piano_learning_applications first person_piano_learning_experience hand_gestures hand_movements hand_traces keyboard_recordings leading_movement master mixed_reality_piano_learning_applications mr_application multimodal_performance_dataset music_pieces musical_score novice_piano_players physical_keyboard pianist piano_teacher recorded_performance skill_learning targeted_visualizations virtual_hand_models visual_indicators written_music c7820_humanities_computing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction input medical training human_factors audio piano learning application mixed reality mr promising substitute physical instruction piano teacher absent existing piano learning application use visual indicator highlight note played keyboard employ video projection pianist provide minimal guidance learner execute hand movement develop technique performance prevent injury address gap developed immersive first person piano learning experience us library targeted visualization teacher hand 3d trace hand movement mr seeing piano teacher hand hearing music central developing novice musical intuition introduced end end workflow accurately capture pianist technical gesture align musical score recorded pianist playing technical exercise music piece developed multimodal performance dataset mpd comprising virtual hand model keyboard midi recording corresponding music score different visualization hand trace capturing movement finally developed pianoverse mr application assist piano learning performed exploratory user testing novice piano player understand impact multimodal representation movement skill learning initial observation suggest apprehending movement trace recorded performance physical keyboard increase learner ability position body hand correctly replicate hand gesture playing written music research focus automating performance data collection comprehensive evaluation use leading movement trace piano learning,piano learning application mixed reality mr promising substitute physical instruction piano teacher absent existing piano learning application use visual indicator highlight note played keyboard employ video projection pianist provide minimal guidance learner execute hand movement develop technique performance prevent injury address gap developed immersive first person piano learning experience us library targeted visualization teacher hand 3d trace hand movement mr seeing piano teacher hand hearing music central developing novice musical intuition introduced end end workflow accurately capture pianist technical gesture align musical score recorded pianist playing technical exercise music piece developed multimodal performance dataset mpd comprising virtual hand model keyboard midi recording corresponding music score different visualization hand trace capturing movement finally developed pianoverse mr application assist piano learning performed exploratory user testing novice piano player understand impact multimodal representation movement skill learning initial observation suggest apprehending movement trace recorded performance physical keyboard increase learner ability position body hand correctly replicate hand gesture playing written music research focus automating performance data collection comprehensive evaluation use leading movement trace piano learningcomputer_aided_instruction gesture_recognition injuries keyboards musicautomating_performance_data_collection capturing_piano_performances corresponding_music_scores different_visualizations end to end_workflow existing_piano_learning_applications first person_piano_learning_experience hand_gestures hand_movements hand_traces keyboard_recordings leading_movement master mixed_reality_piano_learning_applications mr_application multimodal_performance_dataset music_pieces musical_score novice_piano_players physical_keyboard pianist piano_teacher recorded_performance skill_learning targeted_visualizations virtual_hand_models visual_indicators written_music
376,Applications of Smart Glasses in Applied Sciences: A Systematic Review,"Kim, D., & Choi, Y. (2021). Applications of Smart Glasses in Applied Sciences: A Systematic Review. Applied Sciences, 11(11), 4956. https://doi.org/10.3390/app11114956
",10.3390/app11114956,"The aim of this study is to review academic papers on the applications of smart glasses. Among 82 surveyed papers, 57 were selected through filtering. The papers were published from January 2014 to October 2020. Four research questions were set up using the systematic review method, and conclusions were drawn focusing on the research trends by year and application fields; product and operating system; sensors depending on the application purpose; and data visualization, processing, and transfer methods. It was found that the most popular commercial smart glass products are Android-based Google products. In addition, smart glasses are most often used in the healthcare field, particularly for clinical and surgical assistance or for assisting mentally or physically disabled persons. For visual data transfer, 90% of the studies conducted used a camera sensor. Smart glasses have mainly been used to visualize data based on augmented reality, in contrast with the use of mixed reality. The results of this review indicate that research related to smart glasses is steadily increasing, and technological research into the development of smart glasses is being actively conducted.","C7330 Biology and medical computing;C6130B Graphics techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction",82 surveyed papers;popular commercial smart glass products;review academic papers;smart glasses;systematic review method,augmented reality;computer aided instruction;data visualisation;handicapped aids;health care;Internet;medical computing;mobile computing;surgery,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Kim, D.; (1) Choi, Y.; ","(1) Pukyong National University, Department of Energy Resources Engineering, Korea, Republic of; ",MDPI,-1,"[""computer aided instruction"", ""data visualization"", ""handicapped aids"", ""health care"", ""internet"", ""medical computing"", ""mobile computing"", ""surgery""]","[""computer aided instruction"", ""data visualization"", ""handicapped aids"", ""health care"", ""internet"", ""medical computing"", ""mobile computing"", ""surgery""]",computer aided instruction;data visualization;handicapped aids;health care;internet;medical computing;mobile computing;surgery,medical;training;telecommunication;data;networks,technology;use cases;industries,medical;training;telecommunication;data;networks,technology;use cases;industries,computer_aided_instruction data_visualization handicapped_aids health_care internet medical_computing mobile_computing surgery 82_surveyed_papers popular_commercial_smart_glass_products review_academic_papers smart_glasses systematic_review_method c7330_biology_and_medical_computing c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction medical training telecommunication data networks,computer_aided_instruction data_visualization handicapped_aids health_care internet medical_computing mobile_computing surgery,82_surveyed_papers popular_commercial_smart_glass_products review_academic_papers smart_glasses systematic_review_method,aim study review academic paper application smart glass among 82 surveyed paper 57 selected filtering paper published january 2014 october 2020 four research question set using systematic review method conclusion drawn focusing research trend year application field product operating system sensor depending application purpose data visualization processing transfer method found popular commercial smart glass product android based google product addition smart glass often used healthcare field particularly clinical surgical assistance assisting mentally physically disabled person visual data transfer 90 study conducted used camera sensor smart glass mainly used visualize data based augmented reality contrast use mixed reality result review indicate research related smart glass steadily increasing technological research development smart glass actively conducted,computer_aided_instruction data_visualization handicapped_aids health_care internet medical_computing mobile_computing surgery 82_surveyed_papers popular_commercial_smart_glass_products review_academic_papers smart_glasses systematic_review_method c7330_biology_and_medical_computing c6130b_graphics_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction medical training telecommunication data networks aim study review academic paper application smart glass among 82 surveyed paper 57 selected filtering paper published january 2014 october 2020 four research question set using systematic review method conclusion drawn focusing research trend year application field product operating system sensor depending application purpose data visualization processing transfer method found popular commercial smart glass product android based google product addition smart glass often used healthcare field particularly clinical surgical assistance assisting mentally physically disabled person visual data transfer 90 study conducted used camera sensor smart glass mainly used visualize data based augmented reality contrast use mixed reality result review indicate research related smart glass steadily increasing technological research development smart glass actively conducted,aim study review academic paper application smart glass among 82 surveyed paper 57 selected filtering paper published january 2014 october 2020 four research question set using systematic review method conclusion drawn focusing research trend year application field product operating system sensor depending application purpose data visualization processing transfer method found popular commercial smart glass product android based google product addition smart glass often used healthcare field particularly clinical surgical assistance assisting mentally physically disabled person visual data transfer 90 study conducted used camera sensor smart glass mainly used visualize data based augmented reality contrast use mixed reality result review indicate research related smart glass steadily increasing technological research development smart glass actively conductedcomputer_aided_instruction data_visualization handicapped_aids health_care internet medical_computing mobile_computing surgery82_surveyed_papers popular_commercial_smart_glass_products review_academic_papers smart_glasses systematic_review_method
377,Identity Threats in the Metaverse and Future Research Opportunities,"Awadallah, A. M., Damiani, E., Zemerly, J., & Yeun, C. Y. (2023). Identity Threats in the Metaverse and Future Research Opportunities. 2023 International Conference on Business Analytics for Technology and Security (ICBATS). https://doi.org/10.1109/icbats57792.2023.10111122
",10.1109/ICBATS57792.2023.10111122,"The metaverse is the next-generation internet, which can be described as three-dimensional virtual environments that reflect different aspects of the physical world. Users can engage in various experiences while representing themselves as customizable digital avatars. Virtual Reality (VR), Augmented Reality (AR), Digital Twin, Artificial Intelligence (AI), and Blockchain are key technologies that power immersion, interoperability, automation, and 3D elements of the metaverse. Recently, the metaverse has gained significant attention from the tech industry, especially with Facebook rebranding to Meta and announcing its vision for the future metaverse. The metaverse has many applications, including gaming, entertainment, shopping, education, healthcare, and work. Despite the revolutionary potential of the metaverse, several cybersecurity and privacy issues are inevitable and need to be addressed. Specifically, this paper focuses on highlighting identity-related risks for metaverse users. First, an overview of the metaverse elements, technologies, and characteristics is presented, along with a proposed definition of what a user's digital identity represents in the metaverse. Accordingly, potential identity risks and cybersecurity threats are discussed. Finally, AI and biometric authentication techniques are presented as possible solutions and future research opportunities.",C6130S Data security;C6130V Virtual reality;C6160B Distributed databases;C7210N Information networks,future metaverse;future research opportunities;metaverse elements;metaverse users;user,artificial intelligence;augmented reality;avatars;biometrics (access control);blockchains;data privacy;digital twins;Internet;open systems;security of data;social networking (online);virtual reality,2023,Conference article (CA),2023 International Conference on Business Analytics for Technology and Security (ICBATS),"(1) Awadallah, A.M.; (1) Damiani, E.; (1) Zemerly, J.; (1) Yeun, C.Y.; ","(1) Khalifa University, United Arab Emirates; ",IEEE,-1,"[""artificial intelligence"", ""avatars"", ""biometrics"", ""blockchains"", ""data privacy"", ""digital twins"", ""internet"", ""open systems"", ""security of data"", ""social networking""]","[""artificial intelligence"", ""avatars"", ""biometrics"", ""blockchains"", ""data privacy"", ""digital twins"", ""internet"", ""open systems"", ""security of data"", ""social networking""]",artificial intelligence;avatars;biometrics;blockchains;data privacy;digital twins;internet;open systems;security of data;social networking,education;security;other;liberal arts;collaboration;presence;policy;smart cities;developers;human-computer interaction;artificial intelligence;networks,other;business;end users and user experience;industries;use cases;technology,education;security;other;liberal arts;collaboration;presence;policy;smart cities;developers;human-computer interaction;artificial intelligence;networks,other;business;end users and user experience;industries;use cases;technology,artificial_intelligence avatars biometrics blockchains data_privacy digital_twins internet open_systems security_of_data social_networking future_metaverse future_research_opportunities metaverse_elements metaverse_users user c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c7210n_information_networks education security other liberal_arts collaboration presence policy smart_cities developers human computer_interaction artificial_intelligence networks,artificial_intelligence avatars biometrics blockchains data_privacy digital_twins internet open_systems security_of_data social_networking,future_metaverse future_research_opportunities metaverse_elements metaverse_users user,metaverse next generation internet described three dimensional virtual environment reflect different aspect physical world user engage various experience representing customizable digital avatar virtual reality vr augmented reality ar digital twin artificial intelligence ai blockchain key technology power immersion interoperability automation 3d element metaverse recently metaverse gained significant attention tech industry especially facebook rebranding meta announcing vision future metaverse metaverse many application including gaming entertainment shopping education healthcare work despite revolutionary potential metaverse several cybersecurity privacy issue inevitable need addressed specifically paper focus highlighting identity related risk metaverse user first overview metaverse element technology characteristic presented along proposed definition user digital identity represents metaverse accordingly potential identity risk cybersecurity threat discussed finally ai biometric authentication technique presented possible solution future research opportunity,artificial_intelligence avatars biometrics blockchains data_privacy digital_twins internet open_systems security_of_data social_networking future_metaverse future_research_opportunities metaverse_elements metaverse_users user c6130s_data_security c6130v_virtual_reality c6160b_distributed_databases c7210n_information_networks education security other liberal_arts collaboration presence policy smart_cities developers human computer_interaction artificial_intelligence networks metaverse next generation internet described three dimensional virtual environment reflect different aspect physical world user engage various experience representing customizable digital avatar virtual reality vr augmented reality ar digital twin artificial intelligence ai blockchain key technology power immersion interoperability automation 3d element metaverse recently metaverse gained significant attention tech industry especially facebook rebranding meta announcing vision future metaverse metaverse many application including gaming entertainment shopping education healthcare work despite revolutionary potential metaverse several cybersecurity privacy issue inevitable need addressed specifically paper focus highlighting identity related risk metaverse user first overview metaverse element technology characteristic presented along proposed definition user digital identity represents metaverse accordingly potential identity risk cybersecurity threat discussed finally ai biometric authentication technique presented possible solution future research opportunity,metaverse next generation internet described three dimensional virtual environment reflect different aspect physical world user engage various experience representing customizable digital avatar virtual reality vr augmented reality ar digital twin artificial intelligence ai blockchain key technology power immersion interoperability automation 3d element metaverse recently metaverse gained significant attention tech industry especially facebook rebranding meta announcing vision future metaverse metaverse many application including gaming entertainment shopping education healthcare work despite revolutionary potential metaverse several cybersecurity privacy issue inevitable need addressed specifically paper focus highlighting identity related risk metaverse user first overview metaverse element technology characteristic presented along proposed definition user digital identity represents metaverse accordingly potential identity risk cybersecurity threat discussed finally ai biometric authentication technique presented possible solution future research opportunityartificial_intelligence avatars biometrics blockchains data_privacy digital_twins internet open_systems security_of_data social_networkingfuture_metaverse future_research_opportunities metaverse_elements metaverse_users user
378,Analysis of enablers for the digitalization of supply chain using an interpretive structural modelling approach,"Agrawal, P., & Narain, R. (2021). Analysis of enablers for the digitalization of supply chain using an interpretive structural modelling approach. International Journal of Productivity and Performance Management, 72(2), 410–439. https://doi.org/10.1108/ijppm-09-2020-0481
",10.1108/IJPPM-09-2020-0481,"&lt;b&gt;Purpose &lt;/b&gt;Over the years, technology development has rationalized supply chain processes. The demand economy is disrupting every sector causing the supply chain to be more innovative than ever before. The digitalization of the supply chain fulfils this demand. Several technologies such as blockchain, big data analytics, 3D printing, Internet of things (IoT), artificial intelligence (AI), augmented reality (AR), etc. have been innovated in recent years, which expedite the digitalization of the supply chain. The paper aims to analyse the applicability of these technological enablers in the digital transformation of the supply chain and to present an interpretive structural modelling (ISM) model, which presents a sequence in which enablers can be implemented in a sequential manner. &lt;b&gt;Design/methodology/approach &lt;/b&gt;This paper employed the ISM approach to propose a various levelled model for the enablers of the digital supply chain. The enablers are also classified graphically based on their driving and dependence powers using matrix multiplication cross-impact applied to classification (MICMAC) analysis. &lt;b&gt;Findings &lt;/b&gt;The study indicates that the enablers ""big data analytics"", ""IoT"", ""blockchain"" and ""AI"" are the most powerful enablers for the digitalization of the supply chain and actualizing these enablers should be a topmost concern for organizations, which want to exploit new opportunities created by these technologies. &lt;b&gt;Practical implications &lt;/b&gt;This study presents a systematic approach to adopt new technologies for performing various supply chain activities and assists the policymakers better organize their assets and execution endeavours towards digitalization of the supply chain. &lt;b&gt;Originality/value &lt;/b&gt;This is one of the initial research studies, which has analysed the enablers for the digitalization supply chain using the ISM approach.",C6130S Data security;C5620D Internet of Things;C6130J Big Data;C6130V Virtual reality;C6160B Distributed databases;E0410D Industrial applications of IT;E1010 Production management,assists;digital supply chain;digitalization supply chain;interpretive structural modelling model;supply chain activities;supply chain processes,artificial intelligence;augmented reality;Big Data;blockchains;data analysis;Internet of Things;matrix multiplication;organisational aspects;supply chain management;supply chains,2023,Journal article (JA),Int. J. Product. Perform. Manag. (UK),"(1) Agrawal, P.; (1) Narain, R.; ","(1) Motilal Nehru National Institute of Technology, Mechanical Engineering Department, India; ",Emerald,-1,"[""artificial intelligence"", ""big data"", ""blockchains"", ""data analysis"", ""internet of things"", ""matrix multiplication"", ""organisational aspects"", ""supply chain management"", ""supply chains""]","[""artificial intelligence"", ""big data"", ""blockchains"", ""data analysis"", ""internet of things"", ""matrix multiplication"", ""organisational aspects"", ""supply chain management"", ""supply chains""]",artificial intelligence;big data;blockchains;data analysis;internet of things;matrix multiplication;organisational aspects;supply chain management;supply chains,other;security;liberal arts;internet of things;logistics;data;artificial intelligence;business planning and management;networks,technology;other;business;industries,other;security;liberal arts;internet of things;logistics;data;artificial intelligence;business planning and management;networks,technology;other;business;industries,artificial_intelligence big_data blockchains data_analysis internet_of_things matrix_multiplication organisational_aspects supply_chain_management supply_chains assists digital_supply_chain digitalization_supply_chain interpretive_structural_modelling_model supply_chain_activities supply_chain_processes c6130s_data_security c5620d_internet_of_things c6130j_big_data c6130v_virtual_reality c6160b_distributed_databases e0410d_industrial_applications_of_it e1010_production_management other security liberal_arts internet_of_things logistics data artificial_intelligence business_planning_and_management networks,artificial_intelligence big_data blockchains data_analysis internet_of_things matrix_multiplication organisational_aspects supply_chain_management supply_chains,assists digital_supply_chain digitalization_supply_chain interpretive_structural_modelling_model supply_chain_activities supply_chain_processes,lt b gt purpose lt b gt year technology development rationalized supply chain process demand economy disrupting every sector causing supply chain innovative ever digitalization supply chain fulfils demand several technology blockchain big data analytics 3d printing internet thing iot artificial intelligence ai augmented reality ar etc innovated recent year expedite digitalization supply chain paper aim analyse applicability technological enablers digital transformation supply chain present interpretive structural modelling ism model present sequence enablers implemented sequential manner lt b gt design methodology approach lt b gt paper employed ism approach propose various levelled model enablers digital supply chain enablers also classified graphically based driving dependence power using matrix multiplication cross impact applied classification micmac analysis lt b gt finding lt b gt study indicates enablers big data analytics iot blockchain ai powerful enablers digitalization supply chain actualizing enablers topmost concern organization want exploit new opportunity created technology lt b gt practical implication lt b gt study present systematic approach adopt new technology performing various supply chain activity assist policymakers better organize asset execution endeavour towards digitalization supply chain lt b gt originality value lt b gt one initial research study analysed enablers digitalization supply chain using ism approach,artificial_intelligence big_data blockchains data_analysis internet_of_things matrix_multiplication organisational_aspects supply_chain_management supply_chains assists digital_supply_chain digitalization_supply_chain interpretive_structural_modelling_model supply_chain_activities supply_chain_processes c6130s_data_security c5620d_internet_of_things c6130j_big_data c6130v_virtual_reality c6160b_distributed_databases e0410d_industrial_applications_of_it e1010_production_management other security liberal_arts internet_of_things logistics data artificial_intelligence business_planning_and_management networks lt b gt purpose lt b gt year technology development rationalized supply chain process demand economy disrupting every sector causing supply chain innovative ever digitalization supply chain fulfils demand several technology blockchain big data analytics 3d printing internet thing iot artificial intelligence ai augmented reality ar etc innovated recent year expedite digitalization supply chain paper aim analyse applicability technological enablers digital transformation supply chain present interpretive structural modelling ism model present sequence enablers implemented sequential manner lt b gt design methodology approach lt b gt paper employed ism approach propose various levelled model enablers digital supply chain enablers also classified graphically based driving dependence power using matrix multiplication cross impact applied classification micmac analysis lt b gt finding lt b gt study indicates enablers big data analytics iot blockchain ai powerful enablers digitalization supply chain actualizing enablers topmost concern organization want exploit new opportunity created technology lt b gt practical implication lt b gt study present systematic approach adopt new technology performing various supply chain activity assist policymakers better organize asset execution endeavour towards digitalization supply chain lt b gt originality value lt b gt one initial research study analysed enablers digitalization supply chain using ism approach,lt b gt purpose lt b gt year technology development rationalized supply chain process demand economy disrupting every sector causing supply chain innovative ever digitalization supply chain fulfils demand several technology blockchain big data analytics 3d printing internet thing iot artificial intelligence ai augmented reality ar etc innovated recent year expedite digitalization supply chain paper aim analyse applicability technological enablers digital transformation supply chain present interpretive structural modelling ism model present sequence enablers implemented sequential manner lt b gt design methodology approach lt b gt paper employed ism approach propose various levelled model enablers digital supply chain enablers also classified graphically based driving dependence power using matrix multiplication cross impact applied classification micmac analysis lt b gt finding lt b gt study indicates enablers big data analytics iot blockchain ai powerful enablers digitalization supply chain actualizing enablers topmost concern organization want exploit new opportunity created technology lt b gt practical implication lt b gt study present systematic approach adopt new technology performing various supply chain activity assist policymakers better organize asset execution endeavour towards digitalization supply chain lt b gt originality value lt b gt one initial research study analysed enablers digitalization supply chain using ism approachartificial_intelligence big_data blockchains data_analysis internet_of_things matrix_multiplication organisational_aspects supply_chain_management supply_chainsassists digital_supply_chain digitalization_supply_chain interpretive_structural_modelling_model supply_chain_activities supply_chain_processes
379,Guided Depth Completion with Instance Segmentation Fusion in Autonomous Driving Applications,"El-Yabroudi, M. Z., Abdel-Qader, I., Bazuin, B. J., Abudayyeh, O., & Chabaan, R. C. (2022). Guided Depth Completion with Instance Segmentation Fusion in Autonomous Driving Applications. Sensors, 22(24), 9578. https://doi.org/10.3390/s22249578
",10.3390/s22249578,"Pixel-level depth information is crucial to many applications, such as autonomous driving, robotics navigation, 3D scene reconstruction, and augmented reality. However, depth information, which is usually acquired by sensors such as LiDAR, is sparse. Depth completion is a process that predicts missing pixels' depth information from a set of sparse depth measurements. Most of the ongoing research applies deep neural networks on the entire sparse depth map and camera scene without utilizing any information about the available objects, which results in more complex and resource-demanding networks. In this work, we propose to use image instance segmentation to detect objects of interest with pixel-level locations, along with sparse depth data, to support depth completion. The framework utilizes a two-branch encoder-decoder deep neural network. It fuses information about scene available objects, such as objects' type and pixel-level location, LiDAR, and RGB camera, to predict dense accurate depth maps. Experimental results on the KITTI dataset showed faster training and improved prediction accuracy. The proposed method reaches a convergence state faster and surpasses the baseline model in all evaluation metrics.","B6135 Optical, image and video signal processing;B6320C Optical radar;C3390C Mobile robots;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets",3D scene reconstruction;autonomous driving applications;camera scene;complex resource-demanding networks;deep neural networks;dense accurate depth maps;depth completion;entire sparse depth map;image instance segmentation;instance segmentation fusion;pixel-level depth information;pixel-level location;pixels;scene available objects;sparse depth data;sparse depth measurements;two-branch encoder-decoder deep neural network,augmented reality;cameras;deep learning (artificial intelligence);feature extraction;image colour analysis;image reconstruction;image segmentation;mobile robots;object detection;optical radar,2022,Journal article (JA),Sensors (Switzerland),"(1) El-yabroudi, M.Z.; (1) Abdel-qader, I.; (1) Bazuin, B.J.; (2) Abudayyeh, O.; (3) Chabaan, R.C.; ","(1) Western Michigan University, Electrical and Computer Engineering Department, Kalamazoo, MI 49008, United States; (2) Western Michigan University, Civil and Construction Engineering Department, Kalamazoo, MI 49008, United States; (3) Hyundai America Technical Center, Inc., Superior Charter Township, MI 48198, United States; ",MDPI,-1,"[""cameras"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image colour analysis"", ""image reconstruction"", ""image segmentation"", ""mobile robots"", ""object detection"", ""optical radar""]","[""cameras"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image colour analysis"", ""image reconstruction"", ""image segmentation"", ""mobile robots"", ""object detection"", ""optical radar""]",cameras;deep learning (artificial intelligence);feature extraction;image colour analysis;image reconstruction;image segmentation;mobile robots;object detection;optical radar,construction;computer vision;other;graphics;robotics;input;liberal arts;medical;optics;chemical;developers;geospatial;artificial intelligence,technology;other;displays;industries,construction;computer vision;other;graphics;robotics;input;liberal arts;medical;optics;chemical;developers;geospatial;artificial intelligence,technology;other;displays;industries,cameras deep_learning_ artificial_intelligence feature_extraction image_colour_analysis image_reconstruction image_segmentation mobile_robots object_detection optical_radar 3d_scene_reconstruction autonomous_driving_applications camera_scene complex_resource demanding_networks deep_neural_networks dense_accurate_depth_maps depth_completion entire_sparse_depth_map image_instance_segmentation instance_segmentation_fusion pixel level_depth_information pixel level_location pixels scene_available_objects sparse_depth_data sparse_depth_measurements two branch_encoder decoder_deep_neural_network b6135_optical _image_and_video_signal_processing b6320c_optical_radar c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets construction computer_vision other graphics robotics input liberal_arts medical optics chemical developers geospatial artificial_intelligence,cameras deep_learning_ artificial_intelligence feature_extraction image_colour_analysis image_reconstruction image_segmentation mobile_robots object_detection optical_radar,3d_scene_reconstruction autonomous_driving_applications camera_scene complex_resource demanding_networks deep_neural_networks dense_accurate_depth_maps depth_completion entire_sparse_depth_map image_instance_segmentation instance_segmentation_fusion pixel level_depth_information pixel level_location pixels scene_available_objects sparse_depth_data sparse_depth_measurements two branch_encoder decoder_deep_neural_network,pixel level depth information crucial many application autonomous driving robotics navigation 3d scene reconstruction augmented reality however depth information usually acquired sensor lidar sparse depth completion process predicts missing pixel depth information set sparse depth measurement ongoing research applies deep neural network entire sparse depth map camera scene without utilizing information available object result complex resource demanding network work propose use image instance segmentation detect object interest pixel level location along sparse depth data support depth completion framework utilizes two branch encoder decoder deep neural network fuse information scene available object object type pixel level location lidar rgb camera predict dense accurate depth map experimental result kitti dataset showed faster training improved prediction accuracy proposed method reach convergence state faster surpasses baseline model evaluation metric,cameras deep_learning_ artificial_intelligence feature_extraction image_colour_analysis image_reconstruction image_segmentation mobile_robots object_detection optical_radar 3d_scene_reconstruction autonomous_driving_applications camera_scene complex_resource demanding_networks deep_neural_networks dense_accurate_depth_maps depth_completion entire_sparse_depth_map image_instance_segmentation instance_segmentation_fusion pixel level_depth_information pixel level_location pixels scene_available_objects sparse_depth_data sparse_depth_measurements two branch_encoder decoder_deep_neural_network b6135_optical _image_and_video_signal_processing b6320c_optical_radar c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets construction computer_vision other graphics robotics input liberal_arts medical optics chemical developers geospatial artificial_intelligence pixel level depth information crucial many application autonomous driving robotics navigation 3d scene reconstruction augmented reality however depth information usually acquired sensor lidar sparse depth completion process predicts missing pixel depth information set sparse depth measurement ongoing research applies deep neural network entire sparse depth map camera scene without utilizing information available object result complex resource demanding network work propose use image instance segmentation detect object interest pixel level location along sparse depth data support depth completion framework utilizes two branch encoder decoder deep neural network fuse information scene available object object type pixel level location lidar rgb camera predict dense accurate depth map experimental result kitti dataset showed faster training improved prediction accuracy proposed method reach convergence state faster surpasses baseline model evaluation metric,pixel level depth information crucial many application autonomous driving robotics navigation 3d scene reconstruction augmented reality however depth information usually acquired sensor lidar sparse depth completion process predicts missing pixel depth information set sparse depth measurement ongoing research applies deep neural network entire sparse depth map camera scene without utilizing information available object result complex resource demanding network work propose use image instance segmentation detect object interest pixel level location along sparse depth data support depth completion framework utilizes two branch encoder decoder deep neural network fuse information scene available object object type pixel level location lidar rgb camera predict dense accurate depth map experimental result kitti dataset showed faster training improved prediction accuracy proposed method reach convergence state faster surpasses baseline model evaluation metriccameras deep_learning_ artificial_intelligence feature_extraction image_colour_analysis image_reconstruction image_segmentation mobile_robots object_detection optical_radar3d_scene_reconstruction autonomous_driving_applications camera_scene complex_resource demanding_networks deep_neural_networks dense_accurate_depth_maps depth_completion entire_sparse_depth_map image_instance_segmentation instance_segmentation_fusion pixel level_depth_information pixel level_location pixels scene_available_objects sparse_depth_data sparse_depth_measurements two branch_encoder decoder_deep_neural_network
380,School foodservice directors' national training practices,"Reynolds, J., Jeong, H., & Nam, C. S. (2022). School foodservice directors’ national training practices. Journal of Food Safety, 42(6). Portico. https://doi.org/10.1111/jfs.13010
",10.1111/jfs.13010,"In the United States, over 29 million students daily are consuming meals at school. This number continues to increase as more diverse meal options are presented and increased demand for meal assistance. Very young students (under the age of 5) are considered a high-risk population for foodborne illness. Though numerous interventions have been implemented previously, several predominant food safety violations continue to persist. To better understand and improve targeted food safety trainings and interventions this study aimed to conduct a needs assessment of school foodservice directors' training programs and topics. A total of 1,250 electronic surveys were sent nationally to K-12 school foodservice directors. Of that, 264 useable responses were analyzed. Descriptive statistics were used to summarize demographics, as well as identified training methods and topics. Structural modeling was used to identify relatedness ratings between training methods. Approximately 67% of directors reported currently make less than 40% of the menu items from scratch. On-the-job training (94%) was the most frequent training method, while augmented reality and virtual reality were the least with 1.9% and 1.5%, respectively. Structural modeling identified two central nodes, on-the-job (six pairings) and lecture-style (four pairings). All other modalities had one to three relationship pairings. For the majority (73%), the average length of training is less than 2 hr. The top two training topics school foodservice directors reported providing were: food safety (95.5% very likely/likely) and food production (94.3% very likely/likely). Study results provide insights into current training methods and topics provided by school foodservice directors at the time of the survey. &#169; 2022 Wiley Periodicals LLC.",C6130V Virtual reality;E0240H Health and safety aspects;E1780 Products and commodities;E3602 Food industry,1 surveys;250 electronic surveys;264 useable responses;29 million students;consuming meals;current training methods;diverse meal options;food production;foodborne illness;frequent training method;high-risk population;identified training methods;interventions this study;K-12 school foodservice directors;meal assistance;numerous interventions;predominant food safety violations;structural modeling;targeted food safety trainings;time 2.0 hour;training topics school foodservice directors;United States;young students,augmented reality;educational institutions;food processing industry;food products;food safety;on-the-job training;personnel;virtual reality,2022,Journal article (JA),J. Food Saf. (USA),"(1) Reynolds, J.; (2) Jeong, H.; (3) Nam, C.S.; ","(1) DePaul University, School of Hospitality Leadership, Chicago, IL, United States; (2) Arizona State University, Ira A. Fulton Schools of Engineering, Mesa, AZ, United States; (3) North Carolina State University, Raleigh, NC, United States; ",Wiley,-1,"[""educational institutions"", ""food processing industry"", ""food products"", ""food safety"", ""on-the-job training"", ""personnel""]","[""educational institutions"", ""food processing industry"", ""food products"", ""food safety"", ""on-the-job training"", ""personnel""]",educational institutions;food processing industry;food products;food safety;on-the-job training;personnel,"education;farming and natural science;inspection, safety and quality;training;data;human resources",technology;business;use cases;industries,"education;farming and natural science;inspection, safety and quality;training;data;human resources",technology;business;use cases;industries,educational_institutions food_processing_industry food_products food_safety on the job_training personnel 1_surveys 250_electronic_surveys 264_useable_responses 29_million_students consuming_meals current_training_methods diverse_meal_options food_production foodborne_illness frequent_training_method high risk_population identified_training_methods interventions_this_study k 12_school_foodservice_directors meal_assistance numerous_interventions predominant_food_safety_violations structural_modeling targeted_food_safety_trainings time_2 0_hour training_topics_school_foodservice_directors united_states young_students c6130v_virtual_reality e0240h_health_and_safety_aspects e1780_products_and_commodities e3602_food_industry education farming_and_natural_science inspection _safety_and_quality training data human_resources,educational_institutions food_processing_industry food_products food_safety on the job_training personnel,1_surveys 250_electronic_surveys 264_useable_responses 29_million_students consuming_meals current_training_methods diverse_meal_options food_production foodborne_illness frequent_training_method high risk_population identified_training_methods interventions_this_study k 12_school_foodservice_directors meal_assistance numerous_interventions predominant_food_safety_violations structural_modeling targeted_food_safety_trainings time_2 0_hour training_topics_school_foodservice_directors united_states young_students,united state 29 million student daily consuming meal school number continues increase diverse meal option presented increased demand meal assistance young student age 5 considered high risk population foodborne illness though numerous intervention implemented previously several predominant food safety violation continue persist better understand improve targeted food safety training intervention study aimed conduct need assessment school foodservice director training program topic total 1 250 electronic survey sent nationally k 12 school foodservice director 264 useable response analyzed descriptive statistic used summarize demographic well identified training method topic structural modeling used identify relatedness rating training method approximately 67 director reported currently make le 40 menu item scratch job training 94 frequent training method augmented reality virtual reality least 1 9 1 5 respectively structural modeling identified two central node job six pairing lecture style four pairing modality one three relationship pairing majority 73 average length training le 2 hr top two training topic school foodservice director reported providing food safety 95 5 likely likely food production 94 3 likely likely study result provide insight current training method topic provided school foodservice director time survey 169 2022 wiley periodical llc,educational_institutions food_processing_industry food_products food_safety on the job_training personnel 1_surveys 250_electronic_surveys 264_useable_responses 29_million_students consuming_meals current_training_methods diverse_meal_options food_production foodborne_illness frequent_training_method high risk_population identified_training_methods interventions_this_study k 12_school_foodservice_directors meal_assistance numerous_interventions predominant_food_safety_violations structural_modeling targeted_food_safety_trainings time_2 0_hour training_topics_school_foodservice_directors united_states young_students c6130v_virtual_reality e0240h_health_and_safety_aspects e1780_products_and_commodities e3602_food_industry education farming_and_natural_science inspection _safety_and_quality training data human_resources united state 29 million student daily consuming meal school number continues increase diverse meal option presented increased demand meal assistance young student age 5 considered high risk population foodborne illness though numerous intervention implemented previously several predominant food safety violation continue persist better understand improve targeted food safety training intervention study aimed conduct need assessment school foodservice director training program topic total 1 250 electronic survey sent nationally k 12 school foodservice director 264 useable response analyzed descriptive statistic used summarize demographic well identified training method topic structural modeling used identify relatedness rating training method approximately 67 director reported currently make le 40 menu item scratch job training 94 frequent training method augmented reality virtual reality least 1 9 1 5 respectively structural modeling identified two central node job six pairing lecture style four pairing modality one three relationship pairing majority 73 average length training le 2 hr top two training topic school foodservice director reported providing food safety 95 5 likely likely food production 94 3 likely likely study result provide insight current training method topic provided school foodservice director time survey 169 2022 wiley periodical llc,united state 29 million student daily consuming meal school number continues increase diverse meal option presented increased demand meal assistance young student age 5 considered high risk population foodborne illness though numerous intervention implemented previously several predominant food safety violation continue persist better understand improve targeted food safety training intervention study aimed conduct need assessment school foodservice director training program topic total 1 250 electronic survey sent nationally k 12 school foodservice director 264 useable response analyzed descriptive statistic used summarize demographic well identified training method topic structural modeling used identify relatedness rating training method approximately 67 director reported currently make le 40 menu item scratch job training 94 frequent training method augmented reality virtual reality least 1 9 1 5 respectively structural modeling identified two central node job six pairing lecture style four pairing modality one three relationship pairing majority 73 average length training le 2 hr top two training topic school foodservice director reported providing food safety 95 5 likely likely food production 94 3 likely likely study result provide insight current training method topic provided school foodservice director time survey 169 2022 wiley periodical llceducational_institutions food_processing_industry food_products food_safety on the job_training personnel1_surveys 250_electronic_surveys 264_useable_responses 29_million_students consuming_meals current_training_methods diverse_meal_options food_production foodborne_illness frequent_training_method high risk_population identified_training_methods interventions_this_study k 12_school_foodservice_directors meal_assistance numerous_interventions predominant_food_safety_violations structural_modeling targeted_food_safety_trainings time_2 0_hour training_topics_school_foodservice_directors united_states young_students
381,Deep Learning for Visual SLAM: The State-of-the-Art and Future Trends,"Favorskaya, M. N. (2023). Deep Learning for Visual SLAM: The State-of-the-Art and Future Trends. Electronics, 12(9), 2006. https://doi.org/10.3390/electronics12092006
",10.3390/electronics12092006,"Visual Simultaneous Localization and Mapping (VSLAM) has been a hot topic of research since the 1990s, first based on traditional computer vision and recognition techniques and later on deep learning models. Although the implementation of VSLAM methods is far from perfect and complete, recent research in deep learning has yielded promising results for applications such as autonomous driving and navigation, service robots, virtual and augmented reality, and pose estimation. The pipeline of traditional VSLAM methods based on classical image processing algorithms consists of six main steps, including initialization (data acquisition), feature extraction, feature matching, pose estimation, map construction, and loop closure. Since 2017, deep learning has changed this approach from individual steps to implementation as a whole. Currently, three ways are developing with varying degrees of integration of deep learning into traditional VSLAM systems: (1) adding auxiliary modules based on deep learning, (2) replacing the original modules of traditional VSLAM with deep learning modules, and (3) replacing the traditional VSLAM system with end-to-end deep neural networks. The first way is the most elaborate and includes multiple algorithms. The other two are in the early stages of development due to complex requirements and criteria. The available datasets with multi-modal data are also of interest. The discussed challenges, advantages, and disadvantages underlie future VSLAM trends, guiding subsequent directions of research.","B6135 Optical, image and video signal processing;B6135E Image recognition;C3390C Mobile robots;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets",complete research;deep learning models;deep learning modules;end-to-end deep neural networks;feature extraction;future VSLAM trends;perfect research;recognition techniques;service robots;traditional computer vision;traditional VSLAM methods;traditional VSLAM system;Visual Simultaneous Localization,augmented reality;computer vision;data acquisition;deep learning (artificial intelligence);feature extraction;image processing;mobile robots;pose estimation;robot vision;service robots;SLAM (robots),2023,Journal article (JA),Electronics (Switzerland),"(1) Favorskaya, M.N.; ","(1) State University, Department of Informatics and Computer Engineering, Russia; ",MDPI,-1,"[""computer vision"", ""data acquisition"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image processing"", ""mobile robots"", ""pose estimation"", ""robot vision"", ""service robots"", ""slam robotics""]","[""computer vision"", ""data acquisition"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image processing"", ""mobile robots"", ""pose estimation"", ""robot vision"", ""service robots"", ""slam robotics""]",computer vision;data acquisition;deep learning (artificial intelligence);feature extraction;image processing;mobile robots;pose estimation;robot vision;service robots;slam robotics,computer vision;other;graphics;robotics;input;liberal arts;medical;chemical;data;artificial intelligence,technology;other;industries,computer vision;other;graphics;robotics;input;liberal arts;medical;chemical;data;artificial intelligence,technology;other;industries,computer_vision data_acquisition deep_learning_ artificial_intelligence feature_extraction image_processing mobile_robots pose_estimation robot_vision service_robots slam_robotics complete_research deep_learning_models deep_learning_modules end to end_deep_neural_networks feature_extraction future_vslam_trends perfect_research recognition_techniques service_robots traditional_computer_vision traditional_vslam_methods traditional_vslam_system visual_simultaneous_localization b6135_optical _image_and_video_signal_processing b6135e_image_recognition c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics robotics input liberal_arts medical chemical data artificial_intelligence,computer_vision data_acquisition deep_learning_ artificial_intelligence feature_extraction image_processing mobile_robots pose_estimation robot_vision service_robots slam_robotics,complete_research deep_learning_models deep_learning_modules end to end_deep_neural_networks feature_extraction future_vslam_trends perfect_research recognition_techniques service_robots traditional_computer_vision traditional_vslam_methods traditional_vslam_system visual_simultaneous_localization,visual simultaneous localization mapping vslam hot topic research since 1990s first based traditional computer vision recognition technique later deep learning model although implementation vslam method far perfect complete recent research deep learning yielded promising result application autonomous driving navigation service robot virtual augmented reality pose estimation pipeline traditional vslam method based classical image processing algorithm consists six main step including initialization data acquisition feature extraction feature matching pose estimation map construction loop closure since 2017 deep learning changed approach individual step implementation whole currently three way developing varying degree integration deep learning traditional vslam system 1 adding auxiliary module based deep learning 2 replacing original module traditional vslam deep learning module 3 replacing traditional vslam system end end deep neural network first way elaborate includes multiple algorithm two early stage development due complex requirement criterion available datasets multi modal data also interest discussed challenge advantage disadvantage underlie future vslam trend guiding subsequent direction research,computer_vision data_acquisition deep_learning_ artificial_intelligence feature_extraction image_processing mobile_robots pose_estimation robot_vision service_robots slam_robotics complete_research deep_learning_models deep_learning_modules end to end_deep_neural_networks feature_extraction future_vslam_trends perfect_research recognition_techniques service_robots traditional_computer_vision traditional_vslam_methods traditional_vslam_system visual_simultaneous_localization b6135_optical _image_and_video_signal_processing b6135e_image_recognition c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics robotics input liberal_arts medical chemical data artificial_intelligence visual simultaneous localization mapping vslam hot topic research since 1990s first based traditional computer vision recognition technique later deep learning model although implementation vslam method far perfect complete recent research deep learning yielded promising result application autonomous driving navigation service robot virtual augmented reality pose estimation pipeline traditional vslam method based classical image processing algorithm consists six main step including initialization data acquisition feature extraction feature matching pose estimation map construction loop closure since 2017 deep learning changed approach individual step implementation whole currently three way developing varying degree integration deep learning traditional vslam system 1 adding auxiliary module based deep learning 2 replacing original module traditional vslam deep learning module 3 replacing traditional vslam system end end deep neural network first way elaborate includes multiple algorithm two early stage development due complex requirement criterion available datasets multi modal data also interest discussed challenge advantage disadvantage underlie future vslam trend guiding subsequent direction research,visual simultaneous localization mapping vslam hot topic research since 1990s first based traditional computer vision recognition technique later deep learning model although implementation vslam method far perfect complete recent research deep learning yielded promising result application autonomous driving navigation service robot virtual augmented reality pose estimation pipeline traditional vslam method based classical image processing algorithm consists six main step including initialization data acquisition feature extraction feature matching pose estimation map construction loop closure since 2017 deep learning changed approach individual step implementation whole currently three way developing varying degree integration deep learning traditional vslam system 1 adding auxiliary module based deep learning 2 replacing original module traditional vslam deep learning module 3 replacing traditional vslam system end end deep neural network first way elaborate includes multiple algorithm two early stage development due complex requirement criterion available datasets multi modal data also interest discussed challenge advantage disadvantage underlie future vslam trend guiding subsequent direction researchcomputer_vision data_acquisition deep_learning_ artificial_intelligence feature_extraction image_processing mobile_robots pose_estimation robot_vision service_robots slam_roboticscomplete_research deep_learning_models deep_learning_modules end to end_deep_neural_networks feature_extraction future_vslam_trends perfect_research recognition_techniques service_robots traditional_computer_vision traditional_vslam_methods traditional_vslam_system visual_simultaneous_localization
382,Pareto Optimal Layouts for Adaptive Mixed Reality,"Johns, C. A., Evangelista Belo, J. M., Klokmose, C. N., & Pfeuffer, K. (2023). Pareto Optimal Layouts for Adaptive Mixed Reality. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585732
",10.1145/3544549.3585732,"Adaptive mixed reality applications adjust their user interfaces based on the context in which they are used to provide a smooth experience for different users and environments. This involves carefully positioning UI elements, which can be challenging due to the many possible placements and need to balance competing goals. Current approaches employ global criterion optimization methods like weighted sums, which can be difficult to use, inflexible, and might not find preferred solutions. This can prevent the adaptations from meeting end-user expectations. We suggest using online multi-objective optimization methods which generate a set of Pareto optimal adaptation proposals, giving users more control and adding flexibility to the computational decision-making. We explore the feasibility of our approach by generating adaptations for a basic synthetic example and discuss relevant dimensions for a formal evaluation with end-users, including the choice of algorithm, decomposition technique, and objectives.",C6130V Virtual reality;C0240 Ergonomic aspects of computing;C1180 Optimisation techniques;C6180 User interfaces,adaptive mixed reality;computational decision-making;decomposition technique;end-user expectations;online multiobjective optimization methods;Pareto optimal adaptation proposals;Pareto optimal layouts;UI elements;user experience;user interfaces,augmented reality;decision making;human computer interaction;Pareto optimisation;user experience;user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Johns, C.A.; (1) Evangelista Belo, J.M.; (1) Klokmose, C.N.; (1) Pfeuffer, K.; ","(1) Aarhus University, Department of Computer Science, Denmark; ",ACM,-1,"[""decision making"", ""human computer interaction"", ""pareto optimisation"", ""user experience"", ""user interfaces""]","[""decision making"", ""human computer interaction"", ""pareto optimisation"", ""user experience"", ""user interfaces""]",decision making;human computer interaction;pareto optimisation;user experience;user interfaces,human factors;other;human-computer interaction;business performance metrics,other;business;end users and user experience,human factors;other;human-computer interaction;business performance metrics,other;business;end users and user experience,decision_making human_computer_interaction pareto_optimisation user_experience user_interfaces adaptive_mixed_reality computational_decision making decomposition_technique end user_expectations online_multiobjective_optimization_methods pareto_optimal_adaptation_proposals pareto_optimal_layouts ui_elements user_experience user_interfaces c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c1180_optimisation_techniques c6180_user_interfaces human_factors other human computer_interaction business_performance_metrics,decision_making human_computer_interaction pareto_optimisation user_experience user_interfaces,adaptive_mixed_reality computational_decision making decomposition_technique end user_expectations online_multiobjective_optimization_methods pareto_optimal_adaptation_proposals pareto_optimal_layouts ui_elements user_experience user_interfaces,adaptive mixed reality application adjust user interface based context used provide smooth experience different user environment involves carefully positioning ui element challenging due many possible placement need balance competing goal current approach employ global criterion optimization method like weighted sum difficult use inflexible might find preferred solution prevent adaptation meeting end user expectation suggest using online multi objective optimization method generate set pareto optimal adaptation proposal giving user control adding flexibility computational decision making explore feasibility approach generating adaptation basic synthetic example discus relevant dimension formal evaluation end user including choice algorithm decomposition technique objective,decision_making human_computer_interaction pareto_optimisation user_experience user_interfaces adaptive_mixed_reality computational_decision making decomposition_technique end user_expectations online_multiobjective_optimization_methods pareto_optimal_adaptation_proposals pareto_optimal_layouts ui_elements user_experience user_interfaces c6130v_virtual_reality c0240_ergonomic_aspects_of_computing c1180_optimisation_techniques c6180_user_interfaces human_factors other human computer_interaction business_performance_metrics adaptive mixed reality application adjust user interface based context used provide smooth experience different user environment involves carefully positioning ui element challenging due many possible placement need balance competing goal current approach employ global criterion optimization method like weighted sum difficult use inflexible might find preferred solution prevent adaptation meeting end user expectation suggest using online multi objective optimization method generate set pareto optimal adaptation proposal giving user control adding flexibility computational decision making explore feasibility approach generating adaptation basic synthetic example discus relevant dimension formal evaluation end user including choice algorithm decomposition technique objective,adaptive mixed reality application adjust user interface based context used provide smooth experience different user environment involves carefully positioning ui element challenging due many possible placement need balance competing goal current approach employ global criterion optimization method like weighted sum difficult use inflexible might find preferred solution prevent adaptation meeting end user expectation suggest using online multi objective optimization method generate set pareto optimal adaptation proposal giving user control adding flexibility computational decision making explore feasibility approach generating adaptation basic synthetic example discus relevant dimension formal evaluation end user including choice algorithm decomposition technique objectivedecision_making human_computer_interaction pareto_optimisation user_experience user_interfacesadaptive_mixed_reality computational_decision making decomposition_technique end user_expectations online_multiobjective_optimization_methods pareto_optimal_adaptation_proposals pareto_optimal_layouts ui_elements user_experience user_interfaces
383,"Effects of Wearable Hybrid AR/VR Learning Material on High School Students' Situational Interest, Engagement, and Learning Performance: the Case of a Physics Laboratory Learning Environment","Sun, J. C.-Y., Ye, S.-L., Yu, S.-J., & Chiu, T. K. F. (2022). Effects of Wearable Hybrid AR/VR Learning Material on High School Students’ Situational Interest, Engagement, and Learning Performance: the Case of a Physics Laboratory Learning Environment. Journal of Science Education and Technology, 32(1), 1–12. https://doi.org/10.1007/s10956-022-10001-4
",10.1007/s10956-022-10001-4,"This study investigates the effect of incorporating different learning materials (paper textbooks, wearable AR material, and wearable hybrid AR/VR material) in a physics laboratory education on the situational interest, engagement, and learning performance of high school students. The study utilized a quasi-experimental research design. The participants were 105 students, who were assigned to three groups: the traditional learning group, wearable AR group, and wearable hybrid AR/VR group. The instruments included a situational interest scale, an engagement scale, a learning performance test, and an open-ended questionnaire. The results showed that the situational interest and learning performance of the wearable hybrid AR/VR group were significantly higher, compared with that of the traditional learning group. The engagement of the wearable hybrid AR/VR group was significantly higher, compared with that of the other two groups. The wearable hybrid AR/VR material increased situational interest, engagement, and learning performance in the physical laboratory course. This study suggests that instructors can use wearable hybrid AR/VR to enhance situational interest, engagement, and learning performance among learners in science laboratory learning environments.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C5430 Microcomputers;C6130V Virtual reality;C6180 User interfaces,different learning materials;high school students;learning performance test;paper textbooks;physical laboratory course;physics laboratory education;physics laboratory learning environment;quasi-experimental research design;science laboratory learning environments;situational interest scale;wearable AR group;wearable AR material;wearable hybrid AR learning material;wearable hybrid VR learning material,augmented reality;computer aided instruction;educational courses;further education;human factors;wearable computers,2023,Journal article (JA),J. Sci. Educ. Technol. (Germany),"(1) Sun, J.C.-Y.; (1) Ye, S.-L.; (1) Yu, S.-J.; (2) Chiu, T.K.F.; ","(1) National Yang Ming Chiao Tung University, Institute of Education, Taiwan; (2) Chinese University of Hong Kong, Department of Curriculum and Instruction Faculty of Education, China; ",Springer,-1,"[""computer aided instruction"", ""educational courses"", ""further education"", ""human factors"", ""wearable computers""]","[""computer aided instruction"", ""educational courses"", ""further education"", ""human factors"", ""wearable computers""]",computer aided instruction;educational courses;further education;human factors;wearable computers,"education;medical;inspection, safety and quality;training;human factors;wearables;developers",displays;end users and user experience;industries;use cases;technology,"education;medical;inspection, safety and quality;training;human factors;wearables;developers",displays;end users and user experience;industries;use cases;technology,computer_aided_instruction educational_courses further_education human_factors wearable_computers different_learning_materials high_school_students learning_performance_test paper_textbooks physical_laboratory_course physics_laboratory_education physics_laboratory_learning_environment quasi experimental_research_design science_laboratory_learning_environments situational_interest_scale wearable_ar_group wearable_ar_material wearable_hybrid_ar_learning_material wearable_hybrid_vr_learning_material c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5430_microcomputers c6130v_virtual_reality c6180_user_interfaces education medical inspection _safety_and_quality training human_factors wearables developers,computer_aided_instruction educational_courses further_education human_factors wearable_computers,different_learning_materials high_school_students learning_performance_test paper_textbooks physical_laboratory_course physics_laboratory_education physics_laboratory_learning_environment quasi experimental_research_design science_laboratory_learning_environments situational_interest_scale wearable_ar_group wearable_ar_material wearable_hybrid_ar_learning_material wearable_hybrid_vr_learning_material,study investigates effect incorporating different learning material paper textbook wearable ar material wearable hybrid ar vr material physic laboratory education situational interest engagement learning performance high school student study utilized quasi experimental research design participant 105 student assigned three group traditional learning group wearable ar group wearable hybrid ar vr group instrument included situational interest scale engagement scale learning performance test open ended questionnaire result showed situational interest learning performance wearable hybrid ar vr group significantly higher compared traditional learning group engagement wearable hybrid ar vr group significantly higher compared two group wearable hybrid ar vr material increased situational interest engagement learning performance physical laboratory course study suggests instructor use wearable hybrid ar vr enhance situational interest engagement learning performance among learner science laboratory learning environment,computer_aided_instruction educational_courses further_education human_factors wearable_computers different_learning_materials high_school_students learning_performance_test paper_textbooks physical_laboratory_course physics_laboratory_education physics_laboratory_learning_environment quasi experimental_research_design science_laboratory_learning_environments situational_interest_scale wearable_ar_group wearable_ar_material wearable_hybrid_ar_learning_material wearable_hybrid_vr_learning_material c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c5430_microcomputers c6130v_virtual_reality c6180_user_interfaces education medical inspection _safety_and_quality training human_factors wearables developers study investigates effect incorporating different learning material paper textbook wearable ar material wearable hybrid ar vr material physic laboratory education situational interest engagement learning performance high school student study utilized quasi experimental research design participant 105 student assigned three group traditional learning group wearable ar group wearable hybrid ar vr group instrument included situational interest scale engagement scale learning performance test open ended questionnaire result showed situational interest learning performance wearable hybrid ar vr group significantly higher compared traditional learning group engagement wearable hybrid ar vr group significantly higher compared two group wearable hybrid ar vr material increased situational interest engagement learning performance physical laboratory course study suggests instructor use wearable hybrid ar vr enhance situational interest engagement learning performance among learner science laboratory learning environment,study investigates effect incorporating different learning material paper textbook wearable ar material wearable hybrid ar vr material physic laboratory education situational interest engagement learning performance high school student study utilized quasi experimental research design participant 105 student assigned three group traditional learning group wearable ar group wearable hybrid ar vr group instrument included situational interest scale engagement scale learning performance test open ended questionnaire result showed situational interest learning performance wearable hybrid ar vr group significantly higher compared traditional learning group engagement wearable hybrid ar vr group significantly higher compared two group wearable hybrid ar vr material increased situational interest engagement learning performance physical laboratory course study suggests instructor use wearable hybrid ar vr enhance situational interest engagement learning performance among learner science laboratory learning environmentcomputer_aided_instruction educational_courses further_education human_factors wearable_computersdifferent_learning_materials high_school_students learning_performance_test paper_textbooks physical_laboratory_course physics_laboratory_education physics_laboratory_learning_environment quasi experimental_research_design science_laboratory_learning_environments situational_interest_scale wearable_ar_group wearable_ar_material wearable_hybrid_ar_learning_material wearable_hybrid_vr_learning_material
384,Immersive AR Merged with MI-BCI Hand Function Rehabilitation Training System for Stroke Patients,"Qin, Y., Yang, B., & Li, D. (2022). Immersive AR Merged with MI-BCI Hand Function Rehabilitation Training System for Stroke Patients. Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition. https://doi.org/10.1145/3581807.3581851
",10.1145/3581807.3581851,"Strokes can cause neurological damage to the patient, which leads to hand dysfunction. Traditional methods of hand function rehabilitation, such as electrical stimulation and therapist-dependent movement therapy, are ineffective due to the brain's lack of direct involvement in the motor nervous system. To improve the rehabilitation efficacy, we design a rehabilitation system based on motor imagery brain-computer interface (MI-BCI) and augmented reality (AR) for hand function rehabilitation of stroke patients. It includes two-class motor imagery tasks: left-hand fist and right-hand fist based on AR. Motor imagery electroencephalogram (MI-EEG) is acquired from 10 subjects and decoded by using an algorithm module encapsulated in the master system. It reaches an average accuracy of 76.4% and is eventually fed back to patients through rehabilitation peripherals. In addition, the master system provides an interactive interface with features to design treatment tasks, manage patient information and monitor patient status. The system realizes an immersive rehabilitation experience that promotes the reconstruction of the central nervous system and provides a new approach for stroke patients to recover.",A8730C Electrical activity in neurophysiological processes;A8730 Biophysics of neurophysiological processes;A8770F Electrodiagnostics and other electrical measurement techniques;A8770G Patient care and treatment;B6140 Signal processing and detection;B7510D Bioelectric signals;B7520 Patient care and treatment;C3385 Biological and medical control systems;C5260 Digital signal processing;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing,central nervous system;immersive rehabilitation experience;left-hand fist;master system;MI-BCI hand function rehabilitation training system;motor imagery brain-computer interface;motor imagery electroencephalogram;motor nervous system;patient information;patient status;rehabilitation efficacy;rehabilitation peripherals;rehabilitation system;right-hand fist;stroke patients;therapist-dependent movement therapy;two-class motor imagery tasks,augmented reality;brain;brain-computer interfaces;electroencephalography;feature extraction;medical computing;medical signal processing;neurophysiology;patient monitoring;patient rehabilitation;patient treatment;signal classification,2022,Conference article (CA),ICCPR '22: Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition,"(1) Qin, Y.; (1) Yang, B.; (1) Li, D.; ","(1) Shanghai University, School of Mechatronic Engineering and Automation, China; ",ACM,-1,"[""brain"", ""brain-computer interfaces"", ""electroencephalography"", ""feature extraction"", ""medical computing"", ""medical signal processing"", ""neurophysiology"", ""patient monitoring"", ""patient rehabilitation"", ""patient treatment"", ""signal classification""]","[""brain"", ""brain-computer interfaces"", ""electroencephalography"", ""feature extraction"", ""medical computing"", ""medical signal processing"", ""neurophysiology"", ""patient monitoring"", ""patient rehabilitation"", ""patient treatment"", ""signal classification""]",brain;brain-computer interfaces;electroencephalography;feature extraction;medical computing;medical signal processing;neurophysiology;patient monitoring;patient rehabilitation;patient treatment;signal classification,"computer vision;farming and natural science;medical;chemical;sensors;inspection, safety and quality;human factors;data",technology;end users and user experience;use cases;industries,"computer vision;farming and natural science;medical;chemical;sensors;inspection, safety and quality;human factors;data",technology;end users and user experience;use cases;industries,brain brain computer_interfaces electroencephalography feature_extraction medical_computing medical_signal_processing neurophysiology patient_monitoring patient_rehabilitation patient_treatment signal_classification central_nervous_system immersive_rehabilitation_experience left hand_fist master_system mi bci_hand_function_rehabilitation_training_system motor_imagery_brain computer_interface motor_imagery_electroencephalogram motor_nervous_system patient_information patient_status rehabilitation_efficacy rehabilitation_peripherals rehabilitation_system right hand_fist stroke_patients therapist dependent_movement_therapy two class_motor_imagery_tasks a8730c_electrical_activity_in_neurophysiological_processes a8730_biophysics_of_neurophysiological_processes a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8770g_patient_care_and_treatment b6140_signal_processing_and_detection b7510d_bioelectric_signals b7520_patient_care_and_treatment c3385_biological_and_medical_control_systems c5260_digital_signal_processing c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing computer_vision farming_and_natural_science medical chemical sensors inspection _safety_and_quality human_factors data,brain brain computer_interfaces electroencephalography feature_extraction medical_computing medical_signal_processing neurophysiology patient_monitoring patient_rehabilitation patient_treatment signal_classification,central_nervous_system immersive_rehabilitation_experience left hand_fist master_system mi bci_hand_function_rehabilitation_training_system motor_imagery_brain computer_interface motor_imagery_electroencephalogram motor_nervous_system patient_information patient_status rehabilitation_efficacy rehabilitation_peripherals rehabilitation_system right hand_fist stroke_patients therapist dependent_movement_therapy two class_motor_imagery_tasks,stroke cause neurological damage patient lead hand dysfunction traditional method hand function rehabilitation electrical stimulation therapist dependent movement therapy ineffective due brain lack direct involvement motor nervous system improve rehabilitation efficacy design rehabilitation system based motor imagery brain computer interface mi bci augmented reality ar hand function rehabilitation stroke patient includes two class motor imagery task left hand fist right hand fist based ar motor imagery electroencephalogram mi eeg acquired 10 subject decoded using algorithm module encapsulated master system reach average accuracy 76 4 eventually fed back patient rehabilitation peripheral addition master system provides interactive interface feature design treatment task manage patient information monitor patient status system realizes immersive rehabilitation experience promotes reconstruction central nervous system provides new approach stroke patient recover,brain brain computer_interfaces electroencephalography feature_extraction medical_computing medical_signal_processing neurophysiology patient_monitoring patient_rehabilitation patient_treatment signal_classification central_nervous_system immersive_rehabilitation_experience left hand_fist master_system mi bci_hand_function_rehabilitation_training_system motor_imagery_brain computer_interface motor_imagery_electroencephalogram motor_nervous_system patient_information patient_status rehabilitation_efficacy rehabilitation_peripherals rehabilitation_system right hand_fist stroke_patients therapist dependent_movement_therapy two class_motor_imagery_tasks a8730c_electrical_activity_in_neurophysiological_processes a8730_biophysics_of_neurophysiological_processes a8770f_electrodiagnostics_and_other_electrical_measurement_techniques a8770g_patient_care_and_treatment b6140_signal_processing_and_detection b7510d_bioelectric_signals b7520_patient_care_and_treatment c3385_biological_and_medical_control_systems c5260_digital_signal_processing c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing computer_vision farming_and_natural_science medical chemical sensors inspection _safety_and_quality human_factors data stroke cause neurological damage patient lead hand dysfunction traditional method hand function rehabilitation electrical stimulation therapist dependent movement therapy ineffective due brain lack direct involvement motor nervous system improve rehabilitation efficacy design rehabilitation system based motor imagery brain computer interface mi bci augmented reality ar hand function rehabilitation stroke patient includes two class motor imagery task left hand fist right hand fist based ar motor imagery electroencephalogram mi eeg acquired 10 subject decoded using algorithm module encapsulated master system reach average accuracy 76 4 eventually fed back patient rehabilitation peripheral addition master system provides interactive interface feature design treatment task manage patient information monitor patient status system realizes immersive rehabilitation experience promotes reconstruction central nervous system provides new approach stroke patient recover,stroke cause neurological damage patient lead hand dysfunction traditional method hand function rehabilitation electrical stimulation therapist dependent movement therapy ineffective due brain lack direct involvement motor nervous system improve rehabilitation efficacy design rehabilitation system based motor imagery brain computer interface mi bci augmented reality ar hand function rehabilitation stroke patient includes two class motor imagery task left hand fist right hand fist based ar motor imagery electroencephalogram mi eeg acquired 10 subject decoded using algorithm module encapsulated master system reach average accuracy 76 4 eventually fed back patient rehabilitation peripheral addition master system provides interactive interface feature design treatment task manage patient information monitor patient status system realizes immersive rehabilitation experience promotes reconstruction central nervous system provides new approach stroke patient recoverbrain brain computer_interfaces electroencephalography feature_extraction medical_computing medical_signal_processing neurophysiology patient_monitoring patient_rehabilitation patient_treatment signal_classificationcentral_nervous_system immersive_rehabilitation_experience left hand_fist master_system mi bci_hand_function_rehabilitation_training_system motor_imagery_brain computer_interface motor_imagery_electroencephalogram motor_nervous_system patient_information patient_status rehabilitation_efficacy rehabilitation_peripherals rehabilitation_system right hand_fist stroke_patients therapist dependent_movement_therapy two class_motor_imagery_tasks
385,Indoor Place Prediction on Smart Phones,"Sen, P., Jiang, X., Wu, Q., Talasila, M., Hsu, W.-L., & Borcea, C. (2022). Indoor Place Prediction on Smart Phones. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3568062
",10.1145/3560905.3568062,"High-accuracy and low-latency indoor place prediction for mobile users is crucial to enable applications for assisted living, emergency services, smart homes, and augmented reality. Previous studies on indoor place prediction use complex infrastructure with multiple visual/wireless anchors or multiple wireless access points. These localization techniques are difficult to deploy, may negatively impact user privacy through location tracking, and their data collection is not suitable for personalized place prediction. To solve these challenges, this paper proposes GoPlaces, a novel app that fuses inertial sensor data with WiFi-RTT estimated distances to predict the future indoor places visited by a user. GoPlaces does not require any infrastructure, except for one cheap off-the-shelf WiFi access point that supports ranging with RTT. In addition, it enables personalized place naming and prediction through its on-the-phone data collection and protects users' location privacy because user's data never leaves the phone. GoPlaces uses an attention-based bidirectional long short-term memory model to detect user's current trajectory, which is then used together with historical information stored in a prediction tree to infer user's future places. We implemented GoPlaces in Android and evaluated it in several indoor spaces. The experimental results demonstrate prediction accuracy as high as 92%, low latency, and low resource consumption on the phones.","B6250F Mobile radio systems;B6210L Computer communications;C6130S Data security;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing",fuses inertial sensor data;future indoor places;future places;GoPlaces;indoor place prediction;indoor spaces;mobile users;multiple wireless access points;on-the-phone data collection;personalized place prediction;place naming;prediction accuracy;prediction tree;smart homes;smart phones;user privacy,augmented reality;data privacy;emergency services;indoor navigation;indoor radio;mobile computing;mobile handsets;recurrent neural nets;smart phones;wireless LAN,2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Sen, P.; (1) Jiang, X.; (2) Wu, Q.; (2) Talasila, M.; (2) Hsu, W.-L.; (1) Borcea, C.; ","(1) New Jersey Institute of Technology, Newark, NJ, United States; (2) AT&T Research Lab; ",ACM,-1,"[""data privacy"", ""emergency services"", ""indoor navigation"", ""indoor radio"", ""mobile computing"", ""mobile handsets"", ""recurrent neural nets"", ""smartphones"", ""wireless lan""]","[""data privacy"", ""emergency services"", ""indoor navigation"", ""indoor radio"", ""mobile computing"", ""mobile handsets"", ""recurrent neural nets"", ""smartphones"", ""wireless lan""]",data privacy;emergency services;indoor navigation;indoor radio;mobile computing;mobile handsets;recurrent neural nets;smartphones;wireless lan,input;liberal arts;policy;telecommunication;navigation;emergency response;artificial intelligence;networks,technology;business;use cases;industries,input;liberal arts;policy;telecommunication;navigation;emergency response;artificial intelligence;networks,technology;business;use cases;industries,data_privacy emergency_services indoor_navigation indoor_radio mobile_computing mobile_handsets recurrent_neural_nets smartphones wireless_lan fuses_inertial_sensor_data future_indoor_places future_places goplaces indoor_place_prediction indoor_spaces mobile_users multiple_wireless_access_points on the phone_data_collection personalized_place_prediction place_naming prediction_accuracy prediction_tree smart_homes smart_phones user_privacy b6250f_mobile_radio_systems b6210l_computer_communications c6130s_data_security c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing input liberal_arts policy telecommunication navigation emergency_response artificial_intelligence networks,data_privacy emergency_services indoor_navigation indoor_radio mobile_computing mobile_handsets recurrent_neural_nets smartphones wireless_lan,fuses_inertial_sensor_data future_indoor_places future_places goplaces indoor_place_prediction indoor_spaces mobile_users multiple_wireless_access_points on the phone_data_collection personalized_place_prediction place_naming prediction_accuracy prediction_tree smart_homes smart_phones user_privacy,high accuracy low latency indoor place prediction mobile user crucial enable application assisted living emergency service smart home augmented reality previous study indoor place prediction use complex infrastructure multiple visual wireless anchor multiple wireless access point localization technique difficult deploy may negatively impact user privacy location tracking data collection suitable personalized place prediction solve challenge paper proposes goplaces novel app fuse inertial sensor data wifi rtt estimated distance predict future indoor place visited user goplaces require infrastructure except one cheap shelf wifi access point support ranging rtt addition enables personalized place naming prediction phone data collection protects user location privacy user data never leaf phone goplaces us attention based bidirectional long short term memory model detect user current trajectory used together historical information stored prediction tree infer user future place implemented goplaces android evaluated several indoor space experimental result demonstrate prediction accuracy high 92 low latency low resource consumption phone,data_privacy emergency_services indoor_navigation indoor_radio mobile_computing mobile_handsets recurrent_neural_nets smartphones wireless_lan fuses_inertial_sensor_data future_indoor_places future_places goplaces indoor_place_prediction indoor_spaces mobile_users multiple_wireless_access_points on the phone_data_collection personalized_place_prediction place_naming prediction_accuracy prediction_tree smart_homes smart_phones user_privacy b6250f_mobile_radio_systems b6210l_computer_communications c6130s_data_security c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing input liberal_arts policy telecommunication navigation emergency_response artificial_intelligence networks high accuracy low latency indoor place prediction mobile user crucial enable application assisted living emergency service smart home augmented reality previous study indoor place prediction use complex infrastructure multiple visual wireless anchor multiple wireless access point localization technique difficult deploy may negatively impact user privacy location tracking data collection suitable personalized place prediction solve challenge paper proposes goplaces novel app fuse inertial sensor data wifi rtt estimated distance predict future indoor place visited user goplaces require infrastructure except one cheap shelf wifi access point support ranging rtt addition enables personalized place naming prediction phone data collection protects user location privacy user data never leaf phone goplaces us attention based bidirectional long short term memory model detect user current trajectory used together historical information stored prediction tree infer user future place implemented goplaces android evaluated several indoor space experimental result demonstrate prediction accuracy high 92 low latency low resource consumption phone,high accuracy low latency indoor place prediction mobile user crucial enable application assisted living emergency service smart home augmented reality previous study indoor place prediction use complex infrastructure multiple visual wireless anchor multiple wireless access point localization technique difficult deploy may negatively impact user privacy location tracking data collection suitable personalized place prediction solve challenge paper proposes goplaces novel app fuse inertial sensor data wifi rtt estimated distance predict future indoor place visited user goplaces require infrastructure except one cheap shelf wifi access point support ranging rtt addition enables personalized place naming prediction phone data collection protects user location privacy user data never leaf phone goplaces us attention based bidirectional long short term memory model detect user current trajectory used together historical information stored prediction tree infer user future place implemented goplaces android evaluated several indoor space experimental result demonstrate prediction accuracy high 92 low latency low resource consumption phonedata_privacy emergency_services indoor_navigation indoor_radio mobile_computing mobile_handsets recurrent_neural_nets smartphones wireless_lanfuses_inertial_sensor_data future_indoor_places future_places goplaces indoor_place_prediction indoor_spaces mobile_users multiple_wireless_access_points on the phone_data_collection personalized_place_prediction place_naming prediction_accuracy prediction_tree smart_homes smart_phones user_privacy
386,"Creation of auditory augmented rea lity using a position-dynamic binaural synthesis system&#8212;technical components, psychoacoustic needs, and perceptual evaluation","Werner, S., Klein, F., Neidhardt, A., Sloma, U., Schneiderwind, C., & Brandenburg, K. (2021). Creation of Auditory Augmented Reality Using a Position-Dynamic Binaural Synthesis System—Technical Components, Psychoacoustic Needs, and Perceptual Evaluation. Applied Sciences, 11(3), 1150. https://doi.org/10.3390/app11031150
",10.3390/app11031150,"For a spatial audio reproduction in the context of augmented reality, a position-dynamic binaural synthesis system can be used to synthesize the ear signals for a moving listener. The goal is the fusion of the auditory perception of the virtual audio objects with the real listening environment. Such a system has several components, each of which help to enable a plausible auditory simulation. For each possible position of the listener in the room, a set of binaural room impulse responses (BRIRs) congruent with the expected auditory environment is required to avoid room divergence effects. Adequate and efficient approaches are methods to synthesize new BRIRs using very few measurements of the listening room. The required spatial resolution of the BRIR positions can be estimated by spatial auditory perception thresholds. Retrieving and processing the tracking data of the listener's head-pose and position as well as convolving BRIRs with an audio signal needs to be done in real-time. This contribution presents work done by the authors including several technical components of such a system in detail. It shows how the single components are affected by psychoacoustics. Furthermore, the paper also discusses the perceptive effect by means of listening tests demonstrating the appropriateness of the approaches.",A4360 Acoustic signal processing;A8734 Audition;B6130 Speech and audio signal processing;B6140 Signal processing and detection;C5260 Digital signal processing;C6130V Virtual reality,auditory augmented rea lity;binaural room impulse responses;BRIR positions;BRIRs;expected auditory environment;listening environment;listening room;moving listener;plausible auditory simulation;position-dynamic binaural synthesis system&#8212;technical components;possible position;required spatial resolution;room divergence effects;spatial audio reproduction;spatial auditory perception thresholds;virtual audio objects,acoustic signal processing;architectural acoustics;audio signal processing;augmented reality;hearing;signal synthesis;transient response;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Werner, S.; (1) Klein, F.; (1) Neidhardt, A.; (1) Sloma, U.; (1) Schneiderwind, C.; (1) Brandenburg, K.; ","(1) Technische Universita&#776;t Ilmenau, Electronic Media Technology Group, Germany; (2) Brandenburg Labs GmbH, Germany; ",MDPI,-1,"[""acoustic signal processing"", ""architectural acoustics"", ""audio signal processing"", ""hearing"", ""signal synthesis"", ""transient response""]","[""acoustic signal processing"", ""architectural acoustics"", ""audio signal processing"", ""hearing"", ""signal synthesis"", ""transient response""]",acoustic signal processing;architectural acoustics;audio signal processing;hearing;signal synthesis;transient response,construction;other;medical;sensors;human factors;data;audio,technology;other;end users and user experience;industries,construction;other;medical;sensors;human factors;data;audio,technology;other;end users and user experience;industries,acoustic_signal_processing architectural_acoustics audio_signal_processing hearing signal_synthesis transient_response auditory_augmented_rea_lity binaural_room_impulse_responses brir_positions brirs expected_auditory_environment listening_environment listening_room moving_listener plausible_auditory_simulation position dynamic_binaural_synthesis_system 8212 technical_components possible_position required_spatial_resolution room_divergence_effects spatial_audio_reproduction spatial_auditory_perception_thresholds virtual_audio_objects a4360_acoustic_signal_processing a8734_audition b6130_speech_and_audio_signal_processing b6140_signal_processing_and_detection c5260_digital_signal_processing c6130v_virtual_reality construction other medical sensors human_factors data audio,acoustic_signal_processing architectural_acoustics audio_signal_processing hearing signal_synthesis transient_response,auditory_augmented_rea_lity binaural_room_impulse_responses brir_positions brirs expected_auditory_environment listening_environment listening_room moving_listener plausible_auditory_simulation position dynamic_binaural_synthesis_system 8212 technical_components possible_position required_spatial_resolution room_divergence_effects spatial_audio_reproduction spatial_auditory_perception_thresholds virtual_audio_objects,spatial audio reproduction context augmented reality position dynamic binaural synthesis system used synthesize ear signal moving listener goal fusion auditory perception virtual audio object real listening environment system several component help enable plausible auditory simulation possible position listener room set binaural room impulse response brirs congruent expected auditory environment required avoid room divergence effect adequate efficient approach method synthesize new brirs using measurement listening room required spatial resolution brir position estimated spatial auditory perception threshold retrieving processing tracking data listener head pose position well convolving brirs audio signal need done real time contribution present work done author including several technical component system detail show single component affected psychoacoustics furthermore paper also discus perceptive effect mean listening test demonstrating appropriateness approach,acoustic_signal_processing architectural_acoustics audio_signal_processing hearing signal_synthesis transient_response auditory_augmented_rea_lity binaural_room_impulse_responses brir_positions brirs expected_auditory_environment listening_environment listening_room moving_listener plausible_auditory_simulation position dynamic_binaural_synthesis_system 8212 technical_components possible_position required_spatial_resolution room_divergence_effects spatial_audio_reproduction spatial_auditory_perception_thresholds virtual_audio_objects a4360_acoustic_signal_processing a8734_audition b6130_speech_and_audio_signal_processing b6140_signal_processing_and_detection c5260_digital_signal_processing c6130v_virtual_reality construction other medical sensors human_factors data audio spatial audio reproduction context augmented reality position dynamic binaural synthesis system used synthesize ear signal moving listener goal fusion auditory perception virtual audio object real listening environment system several component help enable plausible auditory simulation possible position listener room set binaural room impulse response brirs congruent expected auditory environment required avoid room divergence effect adequate efficient approach method synthesize new brirs using measurement listening room required spatial resolution brir position estimated spatial auditory perception threshold retrieving processing tracking data listener head pose position well convolving brirs audio signal need done real time contribution present work done author including several technical component system detail show single component affected psychoacoustics furthermore paper also discus perceptive effect mean listening test demonstrating appropriateness approach,spatial audio reproduction context augmented reality position dynamic binaural synthesis system used synthesize ear signal moving listener goal fusion auditory perception virtual audio object real listening environment system several component help enable plausible auditory simulation possible position listener room set binaural room impulse response brirs congruent expected auditory environment required avoid room divergence effect adequate efficient approach method synthesize new brirs using measurement listening room required spatial resolution brir position estimated spatial auditory perception threshold retrieving processing tracking data listener head pose position well convolving brirs audio signal need done real time contribution present work done author including several technical component system detail show single component affected psychoacoustics furthermore paper also discus perceptive effect mean listening test demonstrating appropriateness approachacoustic_signal_processing architectural_acoustics audio_signal_processing hearing signal_synthesis transient_responseauditory_augmented_rea_lity binaural_room_impulse_responses brir_positions brirs expected_auditory_environment listening_environment listening_room moving_listener plausible_auditory_simulation position dynamic_binaural_synthesis_system 8212 technical_components possible_position required_spatial_resolution room_divergence_effects spatial_audio_reproduction spatial_auditory_perception_thresholds virtual_audio_objects
387,Posture Guided Human Action Recognition for Fitness Applications,"S R, V., Akula, J., Prasad, B. H. P., & Rosh, G. (2022). Posture Guided Human Action Recognition for Fitness Applications. Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing. https://doi.org/10.1145/3571600.3571612
",10.1145/3571600.3571612,"Human action recognition has attracted a lot of attention in the recent past due to newer applications in computer vision such as fitness tracking, augmented reality and virtual reality. Most of the existing deep learning based methods first deploy a deep neural network to estimate the human pose from a sequence of images followed by a second network to classify the human actions using all the estimated human poses. However, the pose estimation used in these methods typically fail to generalize for non-upright actions such as push-ups, plank, etc since the keypoints are closer to each other than observed in upright postures such as jump, dead-lift, etc. Hence, the accuracy of these methods gets impacted for non-upright actions, typically seen in fitness applications. In this paper, we propose a novel multi-stage deep learning based method for action recognition to predict upright as well as non-upright actions with high accuracy. We use a Light Weight Boundary Refinement Module (LWBRM) during pose estimation to distinguish closer keypoints more effectively. Further, we also introduce an intermediate frame-by-frame posture classification stage after pose estimation. We observed that this intermediate stage enables us to improve the human action recognition accuracy by while improving computational efficiency by ~ 2 &#215; compared to state-of-the-art methods. Our method can process at 104 frames per second on an android smartphone, and hence can readily be deployed for consumer oriented fitness applications.","B6135E Image recognition;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C6264 Neural nets",consumer oriented fitness applications;deep neural network;estimated human poses;existing deep learning;fitness tracking;human action recognition accuracy;human actions;intermediate frame-by-frame posture classification stage;newer applications;nonupright actions;novel multistage deep learning based method;posture guided human action recognition;upright postures,augmented reality;computer vision;deep learning (artificial intelligence);feature extraction;image classification;image motion analysis;pose estimation;smart phones;virtual reality,2022,Conference article (CA),"ICVGIP '22: Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing","(1) S R, V.; (1) Akula, J.; (2) Prasad, B.H.P.; (1) Rosh, G.; ","(1) Samsung Research Institute Bangalore, India; (2) Samsung Research, India; ",ACM,-1,"[""computer vision"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image classification"", ""image motion analysis"", ""pose estimation"", ""smartphones""]","[""computer vision"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""image classification"", ""image motion analysis"", ""pose estimation"", ""smartphones""]",computer vision;deep learning (artificial intelligence);feature extraction;image classification;image motion analysis;pose estimation;smartphones,computer vision;other;graphics;input;liberal arts;medical;chemical;telecommunication;artificial intelligence,technology;other;industries,computer vision;other;graphics;input;liberal arts;medical;chemical;telecommunication;artificial intelligence,technology;other;industries,computer_vision deep_learning_ artificial_intelligence feature_extraction image_classification image_motion_analysis pose_estimation smartphones consumer_oriented_fitness_applications deep_neural_network estimated_human_poses existing_deep_learning fitness_tracking human_action_recognition_accuracy human_actions intermediate_frame by frame_posture_classification_stage newer_applications nonupright_actions novel_multistage_deep_learning_based_method posture_guided_human_action_recognition upright_postures b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision other graphics input liberal_arts medical chemical telecommunication artificial_intelligence,computer_vision deep_learning_ artificial_intelligence feature_extraction image_classification image_motion_analysis pose_estimation smartphones,consumer_oriented_fitness_applications deep_neural_network estimated_human_poses existing_deep_learning fitness_tracking human_action_recognition_accuracy human_actions intermediate_frame by frame_posture_classification_stage newer_applications nonupright_actions novel_multistage_deep_learning_based_method posture_guided_human_action_recognition upright_postures,human action recognition attracted lot attention recent past due newer application computer vision fitness tracking augmented reality virtual reality existing deep learning based method first deploy deep neural network estimate human pose sequence image followed second network classify human action using estimated human pose however pose estimation used method typically fail generalize non upright action push ups plank etc since keypoints closer observed upright posture jump dead lift etc hence accuracy method get impacted non upright action typically seen fitness application paper propose novel multi stage deep learning based method action recognition predict upright well non upright action high accuracy use light weight boundary refinement module lwbrm pose estimation distinguish closer keypoints effectively also introduce intermediate frame frame posture classification stage pose estimation observed intermediate stage enables u improve human action recognition accuracy improving computational efficiency 2 215 compared state art method method process 104 frame per second android smartphone hence readily deployed consumer oriented fitness application,computer_vision deep_learning_ artificial_intelligence feature_extraction image_classification image_motion_analysis pose_estimation smartphones consumer_oriented_fitness_applications deep_neural_network estimated_human_poses existing_deep_learning fitness_tracking human_action_recognition_accuracy human_actions intermediate_frame by frame_posture_classification_stage newer_applications nonupright_actions novel_multistage_deep_learning_based_method posture_guided_human_action_recognition upright_postures b6135e_image_recognition b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision other graphics input liberal_arts medical chemical telecommunication artificial_intelligence human action recognition attracted lot attention recent past due newer application computer vision fitness tracking augmented reality virtual reality existing deep learning based method first deploy deep neural network estimate human pose sequence image followed second network classify human action using estimated human pose however pose estimation used method typically fail generalize non upright action push ups plank etc since keypoints closer observed upright posture jump dead lift etc hence accuracy method get impacted non upright action typically seen fitness application paper propose novel multi stage deep learning based method action recognition predict upright well non upright action high accuracy use light weight boundary refinement module lwbrm pose estimation distinguish closer keypoints effectively also introduce intermediate frame frame posture classification stage pose estimation observed intermediate stage enables u improve human action recognition accuracy improving computational efficiency 2 215 compared state art method method process 104 frame per second android smartphone hence readily deployed consumer oriented fitness application,human action recognition attracted lot attention recent past due newer application computer vision fitness tracking augmented reality virtual reality existing deep learning based method first deploy deep neural network estimate human pose sequence image followed second network classify human action using estimated human pose however pose estimation used method typically fail generalize non upright action push ups plank etc since keypoints closer observed upright posture jump dead lift etc hence accuracy method get impacted non upright action typically seen fitness application paper propose novel multi stage deep learning based method action recognition predict upright well non upright action high accuracy use light weight boundary refinement module lwbrm pose estimation distinguish closer keypoints effectively also introduce intermediate frame frame posture classification stage pose estimation observed intermediate stage enables u improve human action recognition accuracy improving computational efficiency 2 215 compared state art method method process 104 frame per second android smartphone hence readily deployed consumer oriented fitness applicationcomputer_vision deep_learning_ artificial_intelligence feature_extraction image_classification image_motion_analysis pose_estimation smartphonesconsumer_oriented_fitness_applications deep_neural_network estimated_human_poses existing_deep_learning fitness_tracking human_action_recognition_accuracy human_actions intermediate_frame by frame_posture_classification_stage newer_applications nonupright_actions novel_multistage_deep_learning_based_method posture_guided_human_action_recognition upright_postures
388,Implementing Virtuality in Production - a Design Science Approach,"Brunner, M., Jodlbauer, H., Bachmann, N., & Tripathi, S. (2023). Implementing Virtuality in Production - a Design Science Approach. Procedia Computer Science, 217, 988–997. https://doi.org/10.1016/j.procs.2022.12.297
",10.1016/j.procs.2022.12.297,"The trend toward smart production is omnipresent in research over recent years and there are different approaches how to making a production smart. One of these approaches is to enrich reality with virtual aspects. Alongside the efforts to make production smarter by implementing augmented and virtual reality devices arise the challenges like motion sickness, usability, the weight of devices, or simply the complexity of the implementation process. A forced implementation of smart applications could lead to the frustration of the applicants and ruin the fruitful ground for improvement. The right position for the implementation of virtuality measures as well as the right dose of implementation is essential for success. This paper aims to connect an existing comprehensive approach with the implementation process of virtuality in production and show that such a scientific-based approach supports such a task. Design science research offers an existing, well-elaborated framework for complex tasks and bears the potential to support a virtuality implementation process. This led to the research question: Does design science as an existing research framework support the virtuality implementation process in production? Design science defines the environment of application as characterized by people (in different roles and capabilities) an organization (with different processes and structures) and technologies (like infrastructure and communication). This environment could be seen as the production environment. Further, we do have a broad knowledge base due to the profound work of the academic community in the field of augmented and virtual reality and a huge methodological toolbox. The existing environment and knowledge base are the basements to create an artifact, evaluate, and reshaping it. With this paper, we suggest a design science research-based procedure to support the implementation of virtuality in production. Design science research comes out from information science and is more and more applied in other research fields. As a result of our work, we saw that following a structured approach like the design science approach has the potential to support companies to successfully implement virtuality measures in production.",C6130V Virtual reality;C6180 User interfaces;C7480 Production engineering computing;E0410D Industrial applications of IT,augmented reality;design science approach;design science research-based procedure;scientific-based approach;smart applications;virtual reality devices;virtuality implementation process,production engineering computing;virtual reality,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Brunner, M.; (1) Jodlbauer, H.; (1) Bachmann, N.; (1) Tripathi, S.; ","(1) University of Applied Sciences Upper Austria, Wehrgrabengasse 1-3, Austria; ",Elsevier B.V.,-1,"[""production engineering computing""]","[""production engineering computing""]",production engineering computing,manufacturing;engineering,technology;industries,manufacturing;engineering,technology;industries,production_engineering_computing augmented_reality design_science_approach design_science_research based_procedure scientific based_approach smart_applications virtual_reality_devices virtuality_implementation_process c6130v_virtual_reality c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it manufacturing engineering,production_engineering_computing,augmented_reality design_science_approach design_science_research based_procedure scientific based_approach smart_applications virtual_reality_devices virtuality_implementation_process,trend toward smart production omnipresent research recent year different approach making production smart one approach enrich reality virtual aspect alongside effort make production smarter implementing augmented virtual reality device arise challenge like motion sickness usability weight device simply complexity implementation process forced implementation smart application could lead frustration applicant ruin fruitful ground improvement right position implementation virtuality measure well right dose implementation essential success paper aim connect existing comprehensive approach implementation process virtuality production show scientific based approach support task design science research offer existing well elaborated framework complex task bear potential support virtuality implementation process led research question design science existing research framework support virtuality implementation process production design science defines environment application characterized people different role capability organization different process structure technology like infrastructure communication environment could seen production environment broad knowledge base due profound work academic community field augmented virtual reality huge methodological toolbox existing environment knowledge base basement create artifact evaluate reshaping paper suggest design science research based procedure support implementation virtuality production design science research come information science applied research field result work saw following structured approach like design science approach potential support company successfully implement virtuality measure production,production_engineering_computing augmented_reality design_science_approach design_science_research based_procedure scientific based_approach smart_applications virtual_reality_devices virtuality_implementation_process c6130v_virtual_reality c6180_user_interfaces c7480_production_engineering_computing e0410d_industrial_applications_of_it manufacturing engineering trend toward smart production omnipresent research recent year different approach making production smart one approach enrich reality virtual aspect alongside effort make production smarter implementing augmented virtual reality device arise challenge like motion sickness usability weight device simply complexity implementation process forced implementation smart application could lead frustration applicant ruin fruitful ground improvement right position implementation virtuality measure well right dose implementation essential success paper aim connect existing comprehensive approach implementation process virtuality production show scientific based approach support task design science research offer existing well elaborated framework complex task bear potential support virtuality implementation process led research question design science existing research framework support virtuality implementation process production design science defines environment application characterized people different role capability organization different process structure technology like infrastructure communication environment could seen production environment broad knowledge base due profound work academic community field augmented virtual reality huge methodological toolbox existing environment knowledge base basement create artifact evaluate reshaping paper suggest design science research based procedure support implementation virtuality production design science research come information science applied research field result work saw following structured approach like design science approach potential support company successfully implement virtuality measure production,trend toward smart production omnipresent research recent year different approach making production smart one approach enrich reality virtual aspect alongside effort make production smarter implementing augmented virtual reality device arise challenge like motion sickness usability weight device simply complexity implementation process forced implementation smart application could lead frustration applicant ruin fruitful ground improvement right position implementation virtuality measure well right dose implementation essential success paper aim connect existing comprehensive approach implementation process virtuality production show scientific based approach support task design science research offer existing well elaborated framework complex task bear potential support virtuality implementation process led research question design science existing research framework support virtuality implementation process production design science defines environment application characterized people different role capability organization different process structure technology like infrastructure communication environment could seen production environment broad knowledge base due profound work academic community field augmented virtual reality huge methodological toolbox existing environment knowledge base basement create artifact evaluate reshaping paper suggest design science research based procedure support implementation virtuality production design science research come information science applied research field result work saw following structured approach like design science approach potential support company successfully implement virtuality measure productionproduction_engineering_computingaugmented_reality design_science_approach design_science_research based_procedure scientific based_approach smart_applications virtual_reality_devices virtuality_implementation_process
389,BIM-Based Digital Twin and XR Devices to Improve Maintenance Procedures in Smart Buildings: A Literature Review,"Coupry, C., Noblecourt, S., Richard, P., Baudry, D., & Bigaud, D. (2021). BIM-Based Digital Twin and XR Devices to Improve Maintenance Procedures in Smart Buildings: A Literature Review. Applied Sciences, 11(15), 6810. https://doi.org/10.3390/app11156810
",10.3390/app11156810,"In recent years, the use of digital twins (DT) to improve maintenance procedures has increased in various industrial sectors (e.g., manufacturing, energy industry, aerospace) but is more limited in the construction industry. However, the operation and maintenance (O&amp;M) phase of a building's life cycle is the most expensive. Smart buildings already use BIM (Building Information Modeling) for facility management, but they lack the predictive capabilities of DT. On the other hand, the use of extended reality (XR) technologies to improve maintenance operations has been a major topic of academic research in recent years, both through data display and remote collaboration. In this context, this paper focuses on reviewing projects using a combination of these technologies to improve maintenance operations in smart buildings. This review uses a combination of at least three of the terms ""Digital Twin"", ""Maintenance"", ""BIM"" and ""Extended Reality"". Results show how a BIM can be used to create a DT and how this DT use combined with XR technologies can improve maintenance operations in a smart building. This paper also highlights the challenges for the correct implementation of a BIM-based DT combined with XR devices. An example of use is also proposed using a diagram of the possible interactions between the user, the DT and the application framework during maintenance operations.",C7440 Civil and mechanical engineering computing;C6130V Virtual reality;E1020 Maintenance and reliability;E3030 Construction industry,BIM-based digital twin;BIM-based DT;building information modeling;construction industry;extended reality;O and M;operation and maintenance phase;smart building;XR technologies,augmented reality;building information modelling;construction industry;maintenance engineering,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Coupry, C.; (2) Noblecourt, S.; (1) Richard, P.; (3) Baudry, D.; (1) Bigaud, D.; ","(1) Univ. Angers, LARIS, France; (2) CESI, LINEACT, 44 Avenue Fre&#769;de&#769;ric Auguste Bartholdi, France; (3) CESI, LINEACT, 80 rue Edmund Halley, France; ",MDPI,-1,"[""building information modelling"", ""construction industry"", ""maintenance engineering""]","[""building information modelling"", ""construction industry"", ""maintenance engineering""]",building information modelling;construction industry;maintenance engineering,construction;manufacturing,industries,construction;manufacturing,industries,building_information_modelling construction_industry maintenance_engineering bim based_digital_twin bim based_dt building_information_modeling construction_industry extended_reality o_and_m operation_and_maintenance_phase smart_building xr_technologies c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e1020_maintenance_and_reliability e3030_construction_industry construction manufacturing,building_information_modelling construction_industry maintenance_engineering,bim based_digital_twin bim based_dt building_information_modeling construction_industry extended_reality o_and_m operation_and_maintenance_phase smart_building xr_technologies,recent year use digital twin dt improve maintenance procedure increased various industrial sector e g manufacturing energy industry aerospace limited construction industry however operation maintenance amp phase building life cycle expensive smart building already use bim building information modeling facility management lack predictive capability dt hand use extended reality xr technology improve maintenance operation major topic academic research recent year data display remote collaboration context paper focus reviewing project using combination technology improve maintenance operation smart building review us combination least three term digital twin maintenance bim extended reality result show bim used create dt dt use combined xr technology improve maintenance operation smart building paper also highlight challenge correct implementation bim based dt combined xr device example use also proposed using diagram possible interaction user dt application framework maintenance operation,building_information_modelling construction_industry maintenance_engineering bim based_digital_twin bim based_dt building_information_modeling construction_industry extended_reality o_and_m operation_and_maintenance_phase smart_building xr_technologies c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality e1020_maintenance_and_reliability e3030_construction_industry construction manufacturing recent year use digital twin dt improve maintenance procedure increased various industrial sector e g manufacturing energy industry aerospace limited construction industry however operation maintenance amp phase building life cycle expensive smart building already use bim building information modeling facility management lack predictive capability dt hand use extended reality xr technology improve maintenance operation major topic academic research recent year data display remote collaboration context paper focus reviewing project using combination technology improve maintenance operation smart building review us combination least three term digital twin maintenance bim extended reality result show bim used create dt dt use combined xr technology improve maintenance operation smart building paper also highlight challenge correct implementation bim based dt combined xr device example use also proposed using diagram possible interaction user dt application framework maintenance operation,recent year use digital twin dt improve maintenance procedure increased various industrial sector e g manufacturing energy industry aerospace limited construction industry however operation maintenance amp phase building life cycle expensive smart building already use bim building information modeling facility management lack predictive capability dt hand use extended reality xr technology improve maintenance operation major topic academic research recent year data display remote collaboration context paper focus reviewing project using combination technology improve maintenance operation smart building review us combination least three term digital twin maintenance bim extended reality result show bim used create dt dt use combined xr technology improve maintenance operation smart building paper also highlight challenge correct implementation bim based dt combined xr device example use also proposed using diagram possible interaction user dt application framework maintenance operationbuilding_information_modelling construction_industry maintenance_engineeringbim based_digital_twin bim based_dt building_information_modeling construction_industry extended_reality o_and_m operation_and_maintenance_phase smart_building xr_technologies
390,Health Research and Education during and after the COVID-19 Pandemic: An Australian Clinician and Researcher Perspective,"Cordato, D. J., Fatima Shad, K., Soubra, W., & Beran, R. G. (2023). Health Research and Education during and after the COVID-19 Pandemic: An Australian Clinician and Researcher Perspective. Diagnostics, 13(2), 289. https://doi.org/10.3390/diagnostics13020289
",10.3390/diagnostics13020289,"&lt;b&gt;Introduction: &lt;/b&gt;The COVID-19 pandemic had an unprecedented global effect on teaching and education. This review discusses research, education and diagnostics from the perspectives of four academic clinicians and researchers across different facilities in Australia. &lt;b&gt;Materials and methods: &lt;/b&gt;The study adopted a literature review and an Australian researcher's perspective on the impact of the COVID-19 pandemic on health education, research and diagnostics. &lt;b&gt;Results: &lt;/b&gt;At the start of the pandemic, medical facilities had to adhere urgently to major work restrictions, including social distancing, mask-wearing rules and/or the closure of facilities to protect staff, students and patients from the risk of COVID-19 infection. Telemedicine and telehealth services were rapidly implemented and adapted to meet the needs of medical education, the teaching of students, trainee doctors, nursing and allied health staff and became a widely accepted norm. The impact on clinical research and education saw the closure of clinical trials and the implementation of new methods in the conducting of trials, including electronic consents, remote patient assessments and the ability to commence fully virtual clinical trials. Academic teaching adapted augmented reality and competency-based teaching to become important new modes of education delivery. Diagnostic services also required new policies and procedures to ensure the safety of personnel. &lt;b&gt;Conclusions: &lt;/b&gt;As a by-product of the COVID-19 pandemic, traditional, face-to-face learning and clinical research were converted into online formats. An hybrid environment of traditional methods and novel technological tools has emerged in readiness for future pandemics that allows for virtual learning with concurrent recognition of the need to provide for interpersonal interactions.","B7550 Biomedical communication;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7140 Medical administration;C7210N Information networks;C7330 Biology and medical computing;C7810C Computer-aided instruction",Australian researcher;clinical research;COVID-19 infection;COVID-19 pandemic;education delivery;health education;medical education;medical facilities;pandemic facilities;researcher perspective;teaching,augmented reality;biomedical education;computer aided instruction;computer based training;diseases;epidemics;health care;medical computing;medical information systems;patient care;teaching;telemedicine,2023,Journal article (JA),Diagnostics (Switzerland),"(1) Cordato, D.J.; (2) Fatima Shad, K.; (2) Soubra, W.; (1) Beran, R.G.; ","(1) Liverpool Hospital, Department of Neurophysiology, Locked Bag 7103, NSW 1871, Liverpool, NSW 7103, Australia; (2) Ingham Institute for Applied Medical Research, Campbell St Liverpool, Sydney, NSW 2170, Australia; (3) Sydney Clinic, NSW 2170, Sydney, NSW NSW 2170, Australia; (4) University of Technology Sydney, School of Life Sciences, NSW 2007, Sydney, NSW NSW 2007, Australia; (5) Australian Catholic University, Faculty of Health Sciences, 40 Edward St, NSW 2060, Brisbane, QLD 40 E, Australia; (6) University of Hyderabad Pakistan, School of Medical Sciences, Pakistan; (7) Lakemba, NSW 2195, Sydney, NSW NSW 2195, Australia; (8) Griffith University, School of Medicine, QLD 4222, Brisbane, QLD QLD 4222, Australia; (9) Western Sydney University, School of Medicine, NSW 2170, Richmond, NSW NSW 2170, Australia; (10) Sechenov Moscow First State University, Faculty of Sociology, Russia; ",MDPI,-1,"[""biomedical education"", ""computer aided instruction"", ""computer based training"", ""diseases"", ""epidemics"", ""health care"", ""medical computing"", ""medical information systems"", ""patient care"", ""teaching"", ""telemedicine""]","[""biomedical education"", ""computer aided instruction"", ""computer based training"", ""diseases"", ""epidemics"", ""health care"", ""medical computing"", ""medical information systems"", ""patient care"", ""teaching"", ""telemedicine""]",biomedical education;computer aided instruction;computer based training;diseases;epidemics;health care;medical computing;medical information systems;patient care;teaching;telemedicine,education;farming and natural science;medical;training;developers,technology;use cases;industries,education;farming and natural science;medical;training;developers,technology;use cases;industries,biomedical_education computer_aided_instruction computer_based_training diseases epidemics health_care medical_computing medical_information_systems patient_care teaching telemedicine australian_researcher clinical_research covid 19_infection covid 19_pandemic education_delivery health_education medical_education medical_facilities pandemic_facilities researcher_perspective teaching b7550_biomedical_communication c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7140_medical_administration c7210n_information_networks c7330_biology_and_medical_computing c7810c_computer aided_instruction education farming_and_natural_science medical training developers,biomedical_education computer_aided_instruction computer_based_training diseases epidemics health_care medical_computing medical_information_systems patient_care teaching telemedicine,australian_researcher clinical_research covid 19_infection covid 19_pandemic education_delivery health_education medical_education medical_facilities pandemic_facilities researcher_perspective teaching,lt b gt introduction lt b gt covid 19 pandemic unprecedented global effect teaching education review discus research education diagnostics perspective four academic clinician researcher across different facility australia lt b gt material method lt b gt study adopted literature review australian researcher perspective impact covid 19 pandemic health education research diagnostics lt b gt result lt b gt start pandemic medical facility adhere urgently major work restriction including social distancing mask wearing rule closure facility protect staff student patient risk covid 19 infection telemedicine telehealth service rapidly implemented adapted meet need medical education teaching student trainee doctor nursing allied health staff became widely accepted norm impact clinical research education saw closure clinical trial implementation new method conducting trial including electronic consent remote patient assessment ability commence fully virtual clinical trial academic teaching adapted augmented reality competency based teaching become important new mode education delivery diagnostic service also required new policy procedure ensure safety personnel lt b gt conclusion lt b gt product covid 19 pandemic traditional face face learning clinical research converted online format hybrid environment traditional method novel technological tool emerged readiness future pandemic allows virtual learning concurrent recognition need provide interpersonal interaction,biomedical_education computer_aided_instruction computer_based_training diseases epidemics health_care medical_computing medical_information_systems patient_care teaching telemedicine australian_researcher clinical_research covid 19_infection covid 19_pandemic education_delivery health_education medical_education medical_facilities pandemic_facilities researcher_perspective teaching b7550_biomedical_communication c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7140_medical_administration c7210n_information_networks c7330_biology_and_medical_computing c7810c_computer aided_instruction education farming_and_natural_science medical training developers lt b gt introduction lt b gt covid 19 pandemic unprecedented global effect teaching education review discus research education diagnostics perspective four academic clinician researcher across different facility australia lt b gt material method lt b gt study adopted literature review australian researcher perspective impact covid 19 pandemic health education research diagnostics lt b gt result lt b gt start pandemic medical facility adhere urgently major work restriction including social distancing mask wearing rule closure facility protect staff student patient risk covid 19 infection telemedicine telehealth service rapidly implemented adapted meet need medical education teaching student trainee doctor nursing allied health staff became widely accepted norm impact clinical research education saw closure clinical trial implementation new method conducting trial including electronic consent remote patient assessment ability commence fully virtual clinical trial academic teaching adapted augmented reality competency based teaching become important new mode education delivery diagnostic service also required new policy procedure ensure safety personnel lt b gt conclusion lt b gt product covid 19 pandemic traditional face face learning clinical research converted online format hybrid environment traditional method novel technological tool emerged readiness future pandemic allows virtual learning concurrent recognition need provide interpersonal interaction,lt b gt introduction lt b gt covid 19 pandemic unprecedented global effect teaching education review discus research education diagnostics perspective four academic clinician researcher across different facility australia lt b gt material method lt b gt study adopted literature review australian researcher perspective impact covid 19 pandemic health education research diagnostics lt b gt result lt b gt start pandemic medical facility adhere urgently major work restriction including social distancing mask wearing rule closure facility protect staff student patient risk covid 19 infection telemedicine telehealth service rapidly implemented adapted meet need medical education teaching student trainee doctor nursing allied health staff became widely accepted norm impact clinical research education saw closure clinical trial implementation new method conducting trial including electronic consent remote patient assessment ability commence fully virtual clinical trial academic teaching adapted augmented reality competency based teaching become important new mode education delivery diagnostic service also required new policy procedure ensure safety personnel lt b gt conclusion lt b gt product covid 19 pandemic traditional face face learning clinical research converted online format hybrid environment traditional method novel technological tool emerged readiness future pandemic allows virtual learning concurrent recognition need provide interpersonal interactionbiomedical_education computer_aided_instruction computer_based_training diseases epidemics health_care medical_computing medical_information_systems patient_care teaching telemedicineaustralian_researcher clinical_research covid 19_infection covid 19_pandemic education_delivery health_education medical_education medical_facilities pandemic_facilities researcher_perspective teaching
391,"You Can Handle, You Can Teach It: Systematic Review on the Use of Extended Reality and Artificial Intelligence Technologies for Online Higher Education","Rangel-de Lázaro, G., & Duart, J. M. (2023). You Can Handle, You Can Teach It: Systematic Review on the Use of Extended Reality and Artificial Intelligence Technologies for Online Higher Education. Sustainability, 15(4), 3507. https://doi.org/10.3390/su15043507
",10.3390/su15043507,"Over the past year, defined by the COVID-19 pandemic, we have witnessed a boom in applying key emerging technologies in education. In such challenging situations, technology and education expanded their work together to strengthen and interactively impact the learning process in the online higher education context. From a pedagogical perspective, extended reality (XR) and artificial intelligence (AI) were accessible toolboxes to amplify an active and learner-centered teaching method. Whether and how such activities will continue in a post-COVID-19 situation remains unclear. In this systematic literature review, we document the application of XR and AI in online higher education settings and build up an accurate depiction of their influence after the COVID-19 pandemic outbreak. A significant contribution of the thorough analysis conducted was the corroboration of the growing interest of these fast-emerging technologies and their impact on learner agency and outcomes, making online education more accessible, effective, engaging, collaborative, self-paced, and adapted to the diverse academic trajectories. The momentum brought about by the pandemic has served as an impulse for educators and universities to expand the use of these technologies progressively, meet new challenges, and shape the future of online higher education.",C7810C Computer-aided instruction;C6130V Virtual reality;C6210 Knowledge based systems,active learner-centered teaching method;AI;artificial intelligence technologies;COVID-19 pandemic outbreak;extended reality;online higher education settings;post-COVID-19 situation;systematic literature review;universities;XR,artificial intelligence;augmented reality;computer aided instruction;diseases;educational institutions;epidemics;further education;teaching,2023,Journal article (JA),Sustainability (Switzerland),"(1) Rangel-De La&#769;zaro, G.; (1) Duart, J.M.; ","(1) Universitat Oberta de Catalunya, Faculty of Psychology and Educational Sciences, Spain; ",MDPI,-1,"[""artificial intelligence"", ""computer aided instruction"", ""diseases"", ""educational institutions"", ""epidemics"", ""further education"", ""teaching""]","[""artificial intelligence"", ""computer aided instruction"", ""diseases"", ""educational institutions"", ""epidemics"", ""further education"", ""teaching""]",artificial intelligence;computer aided instruction;diseases;educational institutions;epidemics;further education;teaching,education;liberal arts;medical;training;artificial intelligence,technology;use cases;industries,education;liberal arts;medical;training;artificial intelligence,technology;use cases;industries,artificial_intelligence computer_aided_instruction diseases educational_institutions epidemics further_education teaching active_learner centered_teaching_method ai artificial_intelligence_technologies covid 19_pandemic_outbreak extended_reality online_higher_education_settings post covid 19_situation systematic_literature_review universities xr c7810c_computer aided_instruction c6130v_virtual_reality c6210_knowledge_based_systems education liberal_arts medical training artificial_intelligence,artificial_intelligence computer_aided_instruction diseases educational_institutions epidemics further_education teaching,active_learner centered_teaching_method ai artificial_intelligence_technologies covid 19_pandemic_outbreak extended_reality online_higher_education_settings post covid 19_situation systematic_literature_review universities xr,past year defined covid 19 pandemic witnessed boom applying key emerging technology education challenging situation technology education expanded work together strengthen interactively impact learning process online higher education context pedagogical perspective extended reality xr artificial intelligence ai accessible toolbox amplify active learner centered teaching method whether activity continue post covid 19 situation remains unclear systematic literature review document application xr ai online higher education setting build accurate depiction influence covid 19 pandemic outbreak significant contribution thorough analysis conducted corroboration growing interest fast emerging technology impact learner agency outcome making online education accessible effective engaging collaborative self paced adapted diverse academic trajectory momentum brought pandemic served impulse educator university expand use technology progressively meet new challenge shape future online higher education,artificial_intelligence computer_aided_instruction diseases educational_institutions epidemics further_education teaching active_learner centered_teaching_method ai artificial_intelligence_technologies covid 19_pandemic_outbreak extended_reality online_higher_education_settings post covid 19_situation systematic_literature_review universities xr c7810c_computer aided_instruction c6130v_virtual_reality c6210_knowledge_based_systems education liberal_arts medical training artificial_intelligence past year defined covid 19 pandemic witnessed boom applying key emerging technology education challenging situation technology education expanded work together strengthen interactively impact learning process online higher education context pedagogical perspective extended reality xr artificial intelligence ai accessible toolbox amplify active learner centered teaching method whether activity continue post covid 19 situation remains unclear systematic literature review document application xr ai online higher education setting build accurate depiction influence covid 19 pandemic outbreak significant contribution thorough analysis conducted corroboration growing interest fast emerging technology impact learner agency outcome making online education accessible effective engaging collaborative self paced adapted diverse academic trajectory momentum brought pandemic served impulse educator university expand use technology progressively meet new challenge shape future online higher education,past year defined covid 19 pandemic witnessed boom applying key emerging technology education challenging situation technology education expanded work together strengthen interactively impact learning process online higher education context pedagogical perspective extended reality xr artificial intelligence ai accessible toolbox amplify active learner centered teaching method whether activity continue post covid 19 situation remains unclear systematic literature review document application xr ai online higher education setting build accurate depiction influence covid 19 pandemic outbreak significant contribution thorough analysis conducted corroboration growing interest fast emerging technology impact learner agency outcome making online education accessible effective engaging collaborative self paced adapted diverse academic trajectory momentum brought pandemic served impulse educator university expand use technology progressively meet new challenge shape future online higher educationartificial_intelligence computer_aided_instruction diseases educational_institutions epidemics further_education teachingactive_learner centered_teaching_method ai artificial_intelligence_technologies covid 19_pandemic_outbreak extended_reality online_higher_education_settings post covid 19_situation systematic_literature_review universities xr
392,MonuAR: M.A.R Application for Visualising 3D Monuments,"Sorna, S. D., Bhuvaneswaran, B., Manoj, A. R., & Pooja, S. (2023). MonuAR:M.A.R Application for Visualising 3D Monuments. 2023 International Conference on Networking and Communications (ICNWC). https://doi.org/10.1109/icnwc57852.2023.10127425
",10.1109/ICNWC57852.2023.10127425,"The Art and Heritage has been an integral part of our Indian Culture. These art forms and heritage are left unnoticed just because they are very much away. Therefore these sites can be brought back to life in any environment. The heritage properties of art and craft of India can be brought to life from anywhere by using an AR application on the phone. There are times when people visit the monuments and they are in need of a third party to show them the main attractions of the monument. Instead of relying on a third party, this can be done using this app where an AR marker appears on important tourist spots. The software that are used are Unity, Blender, Python and Visual Studio for C#. The software development kit used are Vuforia AR SDK and Mapbox SDK.The software that are used are Unity, Blender, Python and Visual Studio for C#. The software development kit used are Vuforia AR SDK and Mapbox SDK","C6130B Graphics techniques;C6110B Software engineering techniques;C6130V Virtual reality;C6190V Mobile, ubiquitous and pervasive computing;C7185 Administration of other service industries;C7820 Humanities computing",AR application;art forms;Blender;heritage properties;important tourist spots;Indian Culture;m.a.r application;main attractions;MonuAR;monument;Python;software development kit;Visual Studio;visualising 3d,art;augmented reality;data visualisation;mobile computing;Python;software engineering;solid modelling;travel industry,2023,Conference article (CA),2023 International Conference on Networking and Communications (ICNWC),"(1) Sorna, S.D.; (1) Bhuvaneswaran, B.; (1) Manoj, A.R.; (1) Pooja, S.; ","(1) Rajalakshmi Engineering College, Department of Computer Science of Engineering, India; ",IEEE,-1,"[""art"", ""data visualization"", ""mobile computing"", ""python"", ""software engineering"", ""solid modelling"", ""travel industry""]","[""art"", ""data visualization"", ""mobile computing"", ""python"", ""software engineering"", ""solid modelling"", ""travel industry""]",art;data visualization;mobile computing;python;software engineering;solid modelling;travel industry,other;liberal arts;transportation;telecommunication;developers;data;manufacturing,technology;other;industries,other;liberal arts;transportation;telecommunication;developers;data;manufacturing,technology;other;industries,art data_visualization mobile_computing python software_engineering solid_modelling travel_industry ar_application art_forms blender heritage_properties important_tourist_spots indian_culture m a r_application main_attractions monuar monument python software_development_kit visual_studio visualising_3d c6130b_graphics_techniques c6110b_software_engineering_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7185_administration_of_other_service_industries c7820_humanities_computing other liberal_arts transportation telecommunication developers data manufacturing,art data_visualization mobile_computing python software_engineering solid_modelling travel_industry,ar_application art_forms blender heritage_properties important_tourist_spots indian_culture m a r_application main_attractions monuar monument python software_development_kit visual_studio visualising_3d,art heritage integral part indian culture art form heritage left unnoticed much away therefore site brought back life environment heritage property art craft india brought life anywhere using ar application phone time people visit monument need third party show main attraction monument instead relying third party done using app ar marker appears important tourist spot software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdk software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdk,art data_visualization mobile_computing python software_engineering solid_modelling travel_industry ar_application art_forms blender heritage_properties important_tourist_spots indian_culture m a r_application main_attractions monuar monument python software_development_kit visual_studio visualising_3d c6130b_graphics_techniques c6110b_software_engineering_techniques c6130v_virtual_reality c6190v_mobile _ubiquitous_and_pervasive_computing c7185_administration_of_other_service_industries c7820_humanities_computing other liberal_arts transportation telecommunication developers data manufacturing art heritage integral part indian culture art form heritage left unnoticed much away therefore site brought back life environment heritage property art craft india brought life anywhere using ar application phone time people visit monument need third party show main attraction monument instead relying third party done using app ar marker appears important tourist spot software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdk software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdk,art heritage integral part indian culture art form heritage left unnoticed much away therefore site brought back life environment heritage property art craft india brought life anywhere using ar application phone time people visit monument need third party show main attraction monument instead relying third party done using app ar marker appears important tourist spot software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdk software used unity blender python visual studio c software development kit used vuforia ar sdk mapbox sdkart data_visualization mobile_computing python software_engineering solid_modelling travel_industryar_application art_forms blender heritage_properties important_tourist_spots indian_culture m a r_application main_attractions monuar monument python software_development_kit visual_studio visualising_3d
393,Enlarged mid-air image display based on slim DOE waveguide,"Danilova, S., Malyshev, I., Shtykov, S., Muravyev, N., Aspidov, A., Keum, C., Bae, J., & Lee, S. (2023). Enlarged mid-air image display based on slim DOE waveguide. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2648892
",10.1117/12.2648892,"Currently, mid-air display (MAD) technology is of a great interest to practitioners. Potential application in consumer products with large aperture ""floating"" image displays, like TV, monitor, ATM, vending machine, home appliance, etc., and contactless user interface for remote control increase their attractiveness. In order to obtain enlarged mid-air image size at maintaining large horizontal field of view (FoV) and high light display efficiency, the following challenges are to be solved: developing high fill-factor diffractive optical elements (DOE) architecture with optimal size of out-coupling aperture, and designing custom-made projection optics with specified exit pupil matched to in-coupling DOE. As a possible solution to abovementioned problems, the authors propose a MAD based on commercially available projector source, custom-made projection optics and designed corner DOE waveguide architecture with focusing Fresnel lens. The mid-air image is formed at the back focal plane of the Fresnel lens, between the viewer and the display. For mid-air image with 5-inch diagonal and 32&deg; horizontal FoV, we take waveguide out-coupling aperture of 245 x 145 mm2 and Fresnel lens with back focal length of 220 mm, and obtain image brightness ~1000 cd/m2 due to custom projection optics. Basic contactless user interaction was also implemented. &copy; 2023 SPIE.","714.3 Waveguides;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;731.1 Control Systems;741.3 Optical Devices and Systems",Contact less;Floating image;Fresnel lens;HOE/diffractive optical element;Holographic user interface;Horizontal fields;Image display;Mid-air display;Mixed reality;Projection optics,Augmented reality;Consumer products;Domestic appliances;Mixed reality;Optical instrument lenses;Remote control;Waveguides,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Danilova, Svetlana; (1) Malyshev, Ilya; (1) Shtykov, Stanislav; (1) Muravyev, Nikolay; (1) Aspidov, Aleksandr; (2) Keum, Changmin; (2) Bae, Jungkweon; (2) Lee, Sunil; ","(1) Samsung R&D Institute Russia, 12 Dvintsev str., Moscow; 127018, Russia; (2) Samsung Seoul R&D Campus, 56 Seongchon-gil, Seocho-gu, Seoul; 06765, Korea, Republic of; ",SPIE,-1,"[""consumer products"", ""domestic appliances"", ""optical instrument lenses"", ""remote control"", ""waveguides""]","[""consumer products"", ""domestic appliances"", ""optical instrument lenses"", ""remote control"", ""waveguides""]",consumer products;domestic appliances;optical instrument lenses;remote control;waveguides,consumer products;input;optics;collaboration;display technology,technology;displays;use cases;industries,consumer products;input;optics;collaboration;display technology,technology;displays;use cases;industries,consumer_products domestic_appliances optical_instrument_lenses remote_control waveguides contact_less floating_image fresnel_lens hoe diffractive_optical_element holographic_user_interface horizontal_fields image_display mid air_display mixed_reality projection_optics 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 731 1_control_systems 741 3_optical_devices_and_systems consumer_products input optics collaboration display_technology,consumer_products domestic_appliances optical_instrument_lenses remote_control waveguides,contact_less floating_image fresnel_lens hoe diffractive_optical_element holographic_user_interface horizontal_fields image_display mid air_display mixed_reality projection_optics,currently mid air display mad technology great interest practitioner potential application consumer product large aperture floating image display like tv monitor atm vending machine home appliance etc contactless user interface remote control increase attractiveness order obtain enlarged mid air image size maintaining large horizontal field view fov high light display efficiency following challenge solved developing high fill factor diffractive optical element doe architecture optimal size coupling aperture designing custom made projection optic specified exit pupil matched coupling doe possible solution abovementioned problem author propose mad based commercially available projector source custom made projection optic designed corner doe waveguide architecture focusing fresnel lens mid air image formed back focal plane fresnel lens viewer display mid air image 5 inch diagonal 32 deg horizontal fov take waveguide coupling aperture 245 x 145 mm2 fresnel lens back focal length 220 mm obtain image brightness 1000 cd m2 due custom projection optic basic contactless user interaction also implemented copy 2023 spie,consumer_products domestic_appliances optical_instrument_lenses remote_control waveguides contact_less floating_image fresnel_lens hoe diffractive_optical_element holographic_user_interface horizontal_fields image_display mid air_display mixed_reality projection_optics 714 3_waveguides 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 731 1_control_systems 741 3_optical_devices_and_systems consumer_products input optics collaboration display_technology currently mid air display mad technology great interest practitioner potential application consumer product large aperture floating image display like tv monitor atm vending machine home appliance etc contactless user interface remote control increase attractiveness order obtain enlarged mid air image size maintaining large horizontal field view fov high light display efficiency following challenge solved developing high fill factor diffractive optical element doe architecture optimal size coupling aperture designing custom made projection optic specified exit pupil matched coupling doe possible solution abovementioned problem author propose mad based commercially available projector source custom made projection optic designed corner doe waveguide architecture focusing fresnel lens mid air image formed back focal plane fresnel lens viewer display mid air image 5 inch diagonal 32 deg horizontal fov take waveguide coupling aperture 245 x 145 mm2 fresnel lens back focal length 220 mm obtain image brightness 1000 cd m2 due custom projection optic basic contactless user interaction also implemented copy 2023 spie,currently mid air display mad technology great interest practitioner potential application consumer product large aperture floating image display like tv monitor atm vending machine home appliance etc contactless user interface remote control increase attractiveness order obtain enlarged mid air image size maintaining large horizontal field view fov high light display efficiency following challenge solved developing high fill factor diffractive optical element doe architecture optimal size coupling aperture designing custom made projection optic specified exit pupil matched coupling doe possible solution abovementioned problem author propose mad based commercially available projector source custom made projection optic designed corner doe waveguide architecture focusing fresnel lens mid air image formed back focal plane fresnel lens viewer display mid air image 5 inch diagonal 32 deg horizontal fov take waveguide coupling aperture 245 x 145 mm2 fresnel lens back focal length 220 mm obtain image brightness 1000 cd m2 due custom projection optic basic contactless user interaction also implemented copy 2023 spieconsumer_products domestic_appliances optical_instrument_lenses remote_control waveguidescontact_less floating_image fresnel_lens hoe diffractive_optical_element holographic_user_interface horizontal_fields image_display mid air_display mixed_reality projection_optics
394,AEDLE: Designing Drama Therapy Interface for Improving Pragmatic Language Skills of Children with Autism Spectrum Disorder Using AR,"Park, J., Bae, G., Park, J., Park, S. K., Kim, Y. S., & Lee, S. (2023). AEDLE: Designing Drama Therapy Interface for Improving Pragmatic Language Skills of Children with Autism Spectrum Disorder Using AR. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585809
",10.1145/3544549.3585809,"This research proposes AEDLE, a new interface combining AR with drama therapy - an approved method of improving pragmatic language skills - to offer effective, universal, and accessible language therapy for children with Autism Spectrum Disorder (ASD). People with ASD commonly have a disability in pragmatic language and experience difficulty speaking. However, although therapy in childhood is necessary to prevent long-term social isolation due to such constraints, the limited number of therapists forbids doing so. Technology-based therapy can be a solution, but studies on utilizing digital therapy to improve pragmatic language are still insufficient. We conducted a preliminary user study with an ASD child and a therapist to investigate how the child with ASD reacts to drama therapy using AEDLE. We observed that our ASD child actively participated in AEDLE-mediated drama therapy, used our insights to recommend design suggestions for AR-based drama therapy, and explored various ways to utilize AEDLE.",C7330 Biology and medical computing;C6130V Virtual reality;C6180 User interfaces;C7820N Natural language processing;C7850 Computer assistance for persons with handicaps,accessible language therapy;AEDLE-mediated drama therapy;AR-based drama therapy;ASD child;children with autism spectrum disorder;digital therapy;drama therapy interface;effective language therapy;improving pragmatic language skills;long-term social isolation;technology-based therapy;universal language therapy,augmented reality;handicapped aids;human computer interaction;medical disorders;natural language processing;patient treatment,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Park, J.; (2) Bae, G.; (2) Park, J.; (2) Park, S.K.; (2) Kim, Y.S.; (2) Lee, S.; ","(1) Korea Advanced Institute of Science and Technology, School of Transdisciplinary Studies, Korea, Republic of; (2) Korea Advanced Institute of Science and Technology, Korea, Republic of; ",ACM,-1,"[""handicapped aids"", ""human computer interaction"", ""medical disorders"", ""natural language processing"", ""patient treatment""]","[""handicapped aids"", ""human computer interaction"", ""medical disorders"", ""natural language processing"", ""patient treatment""]",handicapped aids;human computer interaction;medical disorders;natural language processing;patient treatment,medical;artificial intelligence;data;human-computer interaction,technology;industries;end users and user experience,medical;artificial intelligence;data;human-computer interaction,technology;industries;end users and user experience,handicapped_aids human_computer_interaction medical_disorders natural_language_processing patient_treatment accessible_language_therapy aedle mediated_drama_therapy ar based_drama_therapy asd_child children_with_autism_spectrum_disorder digital_therapy drama_therapy_interface effective_language_therapy improving_pragmatic_language_skills long term_social_isolation technology based_therapy universal_language_therapy c7330_biology_and_medical_computing c6130v_virtual_reality c6180_user_interfaces c7820n_natural_language_processing c7850_computer_assistance_for_persons_with_handicaps medical artificial_intelligence data human computer_interaction,handicapped_aids human_computer_interaction medical_disorders natural_language_processing patient_treatment,accessible_language_therapy aedle mediated_drama_therapy ar based_drama_therapy asd_child children_with_autism_spectrum_disorder digital_therapy drama_therapy_interface effective_language_therapy improving_pragmatic_language_skills long term_social_isolation technology based_therapy universal_language_therapy,research proposes aedle new interface combining ar drama therapy approved method improving pragmatic language skill offer effective universal accessible language therapy child autism spectrum disorder asd people asd commonly disability pragmatic language experience difficulty speaking however although therapy childhood necessary prevent long term social isolation due constraint limited number therapist forbids technology based therapy solution study utilizing digital therapy improve pragmatic language still insufficient conducted preliminary user study asd child therapist investigate child asd reacts drama therapy using aedle observed asd child actively participated aedle mediated drama therapy used insight recommend design suggestion ar based drama therapy explored various way utilize aedle,handicapped_aids human_computer_interaction medical_disorders natural_language_processing patient_treatment accessible_language_therapy aedle mediated_drama_therapy ar based_drama_therapy asd_child children_with_autism_spectrum_disorder digital_therapy drama_therapy_interface effective_language_therapy improving_pragmatic_language_skills long term_social_isolation technology based_therapy universal_language_therapy c7330_biology_and_medical_computing c6130v_virtual_reality c6180_user_interfaces c7820n_natural_language_processing c7850_computer_assistance_for_persons_with_handicaps medical artificial_intelligence data human computer_interaction research proposes aedle new interface combining ar drama therapy approved method improving pragmatic language skill offer effective universal accessible language therapy child autism spectrum disorder asd people asd commonly disability pragmatic language experience difficulty speaking however although therapy childhood necessary prevent long term social isolation due constraint limited number therapist forbids technology based therapy solution study utilizing digital therapy improve pragmatic language still insufficient conducted preliminary user study asd child therapist investigate child asd reacts drama therapy using aedle observed asd child actively participated aedle mediated drama therapy used insight recommend design suggestion ar based drama therapy explored various way utilize aedle,research proposes aedle new interface combining ar drama therapy approved method improving pragmatic language skill offer effective universal accessible language therapy child autism spectrum disorder asd people asd commonly disability pragmatic language experience difficulty speaking however although therapy childhood necessary prevent long term social isolation due constraint limited number therapist forbids technology based therapy solution study utilizing digital therapy improve pragmatic language still insufficient conducted preliminary user study asd child therapist investigate child asd reacts drama therapy using aedle observed asd child actively participated aedle mediated drama therapy used insight recommend design suggestion ar based drama therapy explored various way utilize aedlehandicapped_aids human_computer_interaction medical_disorders natural_language_processing patient_treatmentaccessible_language_therapy aedle mediated_drama_therapy ar based_drama_therapy asd_child children_with_autism_spectrum_disorder digital_therapy drama_therapy_interface effective_language_therapy improving_pragmatic_language_skills long term_social_isolation technology based_therapy universal_language_therapy
395,Development of a distributed MR-IoT method for operations and maintenance of underground pipeline network,"Li, W., Ye, Z., Wang, Y., Yang, H., Yang, S., Gong, Z., & Wang, L. (2023). Development of a distributed MR-IoT method for operations and maintenance of underground pipeline network. Tunnelling and Underground Space Technology, 133, 104935. https://doi.org/10.1016/j.tust.2022.104935
",10.1016/j.tust.2022.104935,"The underground pipeline network (UPN) is an essential infrastructure and plays an irreplaceable role in national defense and urban activities. The complexity of structural environment and management makes its operation and maintenance difficult. To solve this problem, a distributed mixed reality (MR) and internet of things (IoT) system is developed through game thinking. Firstly, digital models are created based on design drawings and real-world environments, and then an MR system for the UPN is built by the game engine and the OpenXR platform. Secondly, an IoT cloud platform is built to connect with the MR system based on the API sets and cloud services; the data communication between sensors and MR devices is linked with the Socket method, and the data filtering model is constructed by the Kalman algorithm to realize the information exchange between the field workers and the backend managers. Finally, the National Center for Materials Service Safety at the University of Science and Technology Beijing (NCMS_USTB) is used as the experimental site to test this system, and its underground sewage and rainwater pipeline network are used to simulate the key problems in the operation and maintenance. The effect of the application shows that there is potential technical complementarity between the MR and IoT, and the distributed MR-IoT approach can be used as a new technical reference for the operation and maintenance of the UPN. All rights reserved Elsevier.",B6210L Computer communications;C5620D Internet of Things;C6130V Virtual reality;C7440 Civil and mechanical engineering computing;E0410H Mechanical engineering applications of IT;E2110 Mechanical structures,cloud services;data communication;data filtering model;distributed MR-IoT method;game engine;game thinking;Internet of Things system;IoT cloud platform;MR system;MR-IoT approach;National Center for Materials Service Safety;national defense;OpenXR platform;rainwater pipeline network;Socket method;underground pipeline network;underground sewage;UPN;urban activities,application program interfaces;augmented reality;cloud computing;Internet of Things;pipelines;structural engineering computing,2023,Journal article (JA),Tunn. Undergr. Space Technol. Inc. Trenchless Technol. Res. (Netherlands),"(1) Li, W.; (1) Ye, Z.; (1) Wang, Y.; (1) Yang, H.; (1) Yang, S.; (1) Gong, Z.; (2) Wang, L.; ","(1) University of Science and Technology Beijing, National Center for Materials Service Safety, China; (2) University of Georgia, School of Environmental, Civil, Agricultural and Mechanical Engineering, Athens, GA 30602, United States; ",Elsevier B.V.,-1,"[""application program interfaces"", ""cloud computing"", ""internet of things"", ""pipelines"", ""structural engineering computing""]","[""application program interfaces"", ""cloud computing"", ""internet of things"", ""pipelines"", ""structural engineering computing""]",application program interfaces;cloud computing;internet of things;pipelines;structural engineering computing,internet of things;engineering;developers;oil and gas;networks,technology;industries,internet of things;engineering;developers;oil and gas;networks,technology;industries,application_program_interfaces cloud_computing internet_of_things pipelines structural_engineering_computing cloud_services data_communication data_filtering_model distributed_mr iot_method game_engine game_thinking internet_of_things_system iot_cloud_platform mr_system mr iot_approach national_center_for_materials_service_safety national_defense openxr_platform rainwater_pipeline_network socket_method underground_pipeline_network underground_sewage upn urban_activities b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c7440_civil_and_mechanical_engineering_computing e0410h_mechanical_engineering_applications_of_it e2110_mechanical_structures internet_of_things engineering developers oil_and_gas networks,application_program_interfaces cloud_computing internet_of_things pipelines structural_engineering_computing,cloud_services data_communication data_filtering_model distributed_mr iot_method game_engine game_thinking internet_of_things_system iot_cloud_platform mr_system mr iot_approach national_center_for_materials_service_safety national_defense openxr_platform rainwater_pipeline_network socket_method underground_pipeline_network underground_sewage upn urban_activities,underground pipeline network upn essential infrastructure play irreplaceable role national defense urban activity complexity structural environment management make operation maintenance difficult solve problem distributed mixed reality mr internet thing iot system developed game thinking firstly digital model created based design drawing real world environment mr system upn built game engine openxr platform secondly iot cloud platform built connect mr system based api set cloud service data communication sensor mr device linked socket method data filtering model constructed kalman algorithm realize information exchange field worker backend manager finally national center material service safety university science technology beijing ncms ustb used experimental site test system underground sewage rainwater pipeline network used simulate key problem operation maintenance effect application show potential technical complementarity mr iot distributed mr iot approach used new technical reference operation maintenance upn right reserved elsevier,application_program_interfaces cloud_computing internet_of_things pipelines structural_engineering_computing cloud_services data_communication data_filtering_model distributed_mr iot_method game_engine game_thinking internet_of_things_system iot_cloud_platform mr_system mr iot_approach national_center_for_materials_service_safety national_defense openxr_platform rainwater_pipeline_network socket_method underground_pipeline_network underground_sewage upn urban_activities b6210l_computer_communications c5620d_internet_of_things c6130v_virtual_reality c7440_civil_and_mechanical_engineering_computing e0410h_mechanical_engineering_applications_of_it e2110_mechanical_structures internet_of_things engineering developers oil_and_gas networks underground pipeline network upn essential infrastructure play irreplaceable role national defense urban activity complexity structural environment management make operation maintenance difficult solve problem distributed mixed reality mr internet thing iot system developed game thinking firstly digital model created based design drawing real world environment mr system upn built game engine openxr platform secondly iot cloud platform built connect mr system based api set cloud service data communication sensor mr device linked socket method data filtering model constructed kalman algorithm realize information exchange field worker backend manager finally national center material service safety university science technology beijing ncms ustb used experimental site test system underground sewage rainwater pipeline network used simulate key problem operation maintenance effect application show potential technical complementarity mr iot distributed mr iot approach used new technical reference operation maintenance upn right reserved elsevier,underground pipeline network upn essential infrastructure play irreplaceable role national defense urban activity complexity structural environment management make operation maintenance difficult solve problem distributed mixed reality mr internet thing iot system developed game thinking firstly digital model created based design drawing real world environment mr system upn built game engine openxr platform secondly iot cloud platform built connect mr system based api set cloud service data communication sensor mr device linked socket method data filtering model constructed kalman algorithm realize information exchange field worker backend manager finally national center material service safety university science technology beijing ncms ustb used experimental site test system underground sewage rainwater pipeline network used simulate key problem operation maintenance effect application show potential technical complementarity mr iot distributed mr iot approach used new technical reference operation maintenance upn right reserved elsevierapplication_program_interfaces cloud_computing internet_of_things pipelines structural_engineering_computingcloud_services data_communication data_filtering_model distributed_mr iot_method game_engine game_thinking internet_of_things_system iot_cloud_platform mr_system mr iot_approach national_center_for_materials_service_safety national_defense openxr_platform rainwater_pipeline_network socket_method underground_pipeline_network underground_sewage upn urban_activities
396,HoloSet - A Dataset for Visual-Inertial Pose Estimation in Extended Reality: Dataset,"Chandio, Y., Bashir, N., & Anwar, F. M. (2022). HoloSet - A Dataset for Visual-Inertial Pose Estimation in Extended Reality. Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems. https://doi.org/10.1145/3560905.3567763
",10.1145/3560905.3567763,"There is a lack of datasets for visual-inertial odometry applications in Extended Reality (XR). To the best of our knowledge, there is no dataset available that is captured from an XR headset with a human as a carrier. To bridge this gap, we present a novel pose estimation dataset --- called HoloSet --- collected using Microsoft Hololens 2, which is a state-of-the-art head mounted device for XR. Potential applications for HoloSet include visual-inertial odometry, simultaneous localization and mapping (SLAM), and additional applications in XR that leverage visual-inertial data.HoloSet captures both macro and micro movements. For macro movements, the dataset consists of more than 66,000 samples of visual, inertial, and depth camera data in a variety of environments (indoor, outdoor) and scene setups (trails, suburbs, downtown) under multiple user action scenarios (walk, jog). For micro movements, the dataset consists of more than 12,000 samples of additional articulated hand depth camera images while a user plays games that exercise fine motor skills and hand-eye coordination. We present basic visualizations and high-level statistics of the data and outline the potential research use cases for HoloSet.","B6135E Image recognition;B6135 Optical, image and video signal processing;B7230G Image sensors;C3390C Mobile robots;C5260B Computer vision and image processing techniques;C6130V Virtual reality","additional applications;additional articulated hand depth camera images;basic visualizations;estimation dataset;Extended Reality;inertial, depth camera data;leverage visual-inertial data.HoloSet;micromovements;visual depth camera data;visual-inertial odometry applications;visual-inertial pose estimation;XR headset",augmented reality;cameras;distance measurement;mobile robots;pose estimation;robot vision;SLAM (robots),2022,Conference article (CA),SenSys '22: Proceedings of the Twentieth ACM Conference on Embedded Networked Sensor Systems,"(1) Chandio, Y.; (1) Bashir, N.; (1) Anwar, F.M.; ","(1) University of Massachusetts Lowell, Lowell, MA, United States; ",ACM,-1,"[""cameras"", ""distance measurement"", ""mobile robots"", ""pose estimation"", ""robot vision"", ""slam robotics""]","[""cameras"", ""distance measurement"", ""mobile robots"", ""pose estimation"", ""robot vision"", ""slam robotics""]",cameras;distance measurement;mobile robots;pose estimation;robot vision;slam robotics,"computer vision;graphics;robotics;input;inspection, safety and quality;navigation",technology;use cases,"computer vision;graphics;robotics;input;inspection, safety and quality;navigation",technology;use cases,cameras distance_measurement mobile_robots pose_estimation robot_vision slam_robotics additional_applications additional_articulated_hand_depth_camera_images basic_visualizations estimation_dataset extended_reality inertial _depth_camera_data leverage_visual inertial_data holoset micromovements visual_depth_camera_data visual inertial_odometry_applications visual inertial_pose_estimation xr_headset b6135e_image_recognition b6135_optical _image_and_video_signal_processing b7230g_image_sensors c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision graphics robotics input inspection _safety_and_quality navigation,cameras distance_measurement mobile_robots pose_estimation robot_vision slam_robotics,additional_applications additional_articulated_hand_depth_camera_images basic_visualizations estimation_dataset extended_reality inertial _depth_camera_data leverage_visual inertial_data holoset micromovements visual_depth_camera_data visual inertial_odometry_applications visual inertial_pose_estimation xr_headset,lack datasets visual inertial odometry application extended reality xr best knowledge dataset available captured xr headset human carrier bridge gap present novel pose estimation dataset called holoset collected using microsoft hololens 2 state art head mounted device xr potential application holoset include visual inertial odometry simultaneous localization mapping slam additional application xr leverage visual inertial data holoset capture macro micro movement macro movement dataset consists 66 000 sample visual inertial depth camera data variety environment indoor outdoor scene setup trail suburb downtown multiple user action scenario walk jog micro movement dataset consists 12 000 sample additional articulated hand depth camera image user play game exercise fine motor skill hand eye coordination present basic visualization high level statistic data outline potential research use case holoset,cameras distance_measurement mobile_robots pose_estimation robot_vision slam_robotics additional_applications additional_articulated_hand_depth_camera_images basic_visualizations estimation_dataset extended_reality inertial _depth_camera_data leverage_visual inertial_data holoset micromovements visual_depth_camera_data visual inertial_odometry_applications visual inertial_pose_estimation xr_headset b6135e_image_recognition b6135_optical _image_and_video_signal_processing b7230g_image_sensors c3390c_mobile_robots c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality computer_vision graphics robotics input inspection _safety_and_quality navigation lack datasets visual inertial odometry application extended reality xr best knowledge dataset available captured xr headset human carrier bridge gap present novel pose estimation dataset called holoset collected using microsoft hololens 2 state art head mounted device xr potential application holoset include visual inertial odometry simultaneous localization mapping slam additional application xr leverage visual inertial data holoset capture macro micro movement macro movement dataset consists 66 000 sample visual inertial depth camera data variety environment indoor outdoor scene setup trail suburb downtown multiple user action scenario walk jog micro movement dataset consists 12 000 sample additional articulated hand depth camera image user play game exercise fine motor skill hand eye coordination present basic visualization high level statistic data outline potential research use case holoset,lack datasets visual inertial odometry application extended reality xr best knowledge dataset available captured xr headset human carrier bridge gap present novel pose estimation dataset called holoset collected using microsoft hololens 2 state art head mounted device xr potential application holoset include visual inertial odometry simultaneous localization mapping slam additional application xr leverage visual inertial data holoset capture macro micro movement macro movement dataset consists 66 000 sample visual inertial depth camera data variety environment indoor outdoor scene setup trail suburb downtown multiple user action scenario walk jog micro movement dataset consists 12 000 sample additional articulated hand depth camera image user play game exercise fine motor skill hand eye coordination present basic visualization high level statistic data outline potential research use case holosetcameras distance_measurement mobile_robots pose_estimation robot_vision slam_roboticsadditional_applications additional_articulated_hand_depth_camera_images basic_visualizations estimation_dataset extended_reality inertial _depth_camera_data leverage_visual inertial_data holoset micromovements visual_depth_camera_data visual inertial_odometry_applications visual inertial_pose_estimation xr_headset
397,A Mixed Reality application to support the design of custom prostheses,"Gattullo, M., Piccininni, A., Evangelista, A., Guglielmi, P., Boccaccio, A., Cusanno, A., Uva, A. E., & Palumbo, G. (2023). A Mixed Reality application to support the design of custom prostheses. Procedia Computer Science, 217, 1018–1027. https://doi.org/10.1016/j.procs.2022.12.300
",10.1016/j.procs.2022.12.300,"The definition of an innovative category of implantable devices, characterized not only by a fully customization but also by improved osteoconductive and functionalized bioactive surfaces, needs to be supported by a systematic approach. In the present work, a new human-machine interface based on the Mixed Reality (MR) is proposed and focused on the implantation of a fully customized prosthesis. By means of an informal and exploratory focus group (i.e., without using a structured questionnaire), the limitations belonging to the current procedure were highlighted and a first list of user needs was subsequently defined. The MR interface was then considered to be the most suitable solution to match the gathered requirements. However, the doctors proposed also to develop a desktop interface for a finer and easier manipulation of 3D models. The proposed MR application offers several advantages from the possibility to display 3D anatomical structures and 3D models of custom prostheses in an immersive environment to the optimized communication and data exchange among the players (medical staff, doctors and engineers). A mock-up of the MR applications is presented in this work to show the results of the design stage, before the deployment of the application. All rights reserved Elsevier.",A8770J Prosthetics and other practical applications;B7520E Prosthetics and orthotics;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C7330 Biology and medical computing,3D anatomical structures;current procedure;custom prostheses;design stage;desktop interface;doctors;exploratory focus group;fully customization;fully customized prosthesis;functionalized bioactive surfaces;gathered requirements;human-machine interface;implantable devices;implantation;improved osteoconductive surfaces;informal focus group;innovative category;Mixed Reality application;MR application;MR interface;structured questionnaire;systematic approach,augmented reality;bone;human computer interaction;medical computing;prosthetics;solid modelling;user interfaces;virtual reality,2023,Journal article (JA),Procedia Comput. Sci. (Netherlands),"(1) Gattullo, M.; (1) Piccininni, A.; (1) Evangelista, A.; (1) Guglielmi, P.; (1) Boccaccio, A.; (1) Cusanno, A.; (1) Uva, A.E.; (1) Palumbo, G.; ","(1) Politecnico di Bari, Department of Mechanics, Mathematics, and Management, via Orabona 4, Italy; ",Elsevier B.V.,-1,"[""bone"", ""human computer interaction"", ""medical computing"", ""prosthetics"", ""solid modelling"", ""user interfaces""]","[""bone"", ""human computer interaction"", ""medical computing"", ""prosthetics"", ""solid modelling"", ""user interfaces""]",bone;human computer interaction;medical computing;prosthetics;solid modelling;user interfaces,medical;manufacturing;human-computer interaction,industries;end users and user experience,medical;manufacturing;human-computer interaction,industries;end users and user experience,bone human_computer_interaction medical_computing prosthetics solid_modelling user_interfaces 3d_anatomical_structures current_procedure custom_prostheses design_stage desktop_interface doctors exploratory_focus_group fully_customization fully_customized_prosthesis functionalized_bioactive_surfaces gathered_requirements human machine_interface implantable_devices implantation improved_osteoconductive_surfaces informal_focus_group innovative_category mixed_reality_application mr_application mr_interface structured_questionnaire systematic_approach a8770j_prosthetics_and_other_practical_applications b7520e_prosthetics_and_orthotics c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing medical manufacturing human computer_interaction,bone human_computer_interaction medical_computing prosthetics solid_modelling user_interfaces,3d_anatomical_structures current_procedure custom_prostheses design_stage desktop_interface doctors exploratory_focus_group fully_customization fully_customized_prosthesis functionalized_bioactive_surfaces gathered_requirements human machine_interface implantable_devices implantation improved_osteoconductive_surfaces informal_focus_group innovative_category mixed_reality_application mr_application mr_interface structured_questionnaire systematic_approach,definition innovative category implantable device characterized fully customization also improved osteoconductive functionalized bioactive surface need supported systematic approach present work new human machine interface based mixed reality mr proposed focused implantation fully customized prosthesis mean informal exploratory focus group e without using structured questionnaire limitation belonging current procedure highlighted first list user need subsequently defined mr interface considered suitable solution match gathered requirement however doctor proposed also develop desktop interface finer easier manipulation 3d model proposed mr application offer several advantage possibility display 3d anatomical structure 3d model custom prosthesis immersive environment optimized communication data exchange among player medical staff doctor engineer mock mr application presented work show result design stage deployment application right reserved elsevier,bone human_computer_interaction medical_computing prosthetics solid_modelling user_interfaces 3d_anatomical_structures current_procedure custom_prostheses design_stage desktop_interface doctors exploratory_focus_group fully_customization fully_customized_prosthesis functionalized_bioactive_surfaces gathered_requirements human machine_interface implantable_devices implantation improved_osteoconductive_surfaces informal_focus_group innovative_category mixed_reality_application mr_application mr_interface structured_questionnaire systematic_approach a8770j_prosthetics_and_other_practical_applications b7520e_prosthetics_and_orthotics c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c7330_biology_and_medical_computing medical manufacturing human computer_interaction definition innovative category implantable device characterized fully customization also improved osteoconductive functionalized bioactive surface need supported systematic approach present work new human machine interface based mixed reality mr proposed focused implantation fully customized prosthesis mean informal exploratory focus group e without using structured questionnaire limitation belonging current procedure highlighted first list user need subsequently defined mr interface considered suitable solution match gathered requirement however doctor proposed also develop desktop interface finer easier manipulation 3d model proposed mr application offer several advantage possibility display 3d anatomical structure 3d model custom prosthesis immersive environment optimized communication data exchange among player medical staff doctor engineer mock mr application presented work show result design stage deployment application right reserved elsevier,definition innovative category implantable device characterized fully customization also improved osteoconductive functionalized bioactive surface need supported systematic approach present work new human machine interface based mixed reality mr proposed focused implantation fully customized prosthesis mean informal exploratory focus group e without using structured questionnaire limitation belonging current procedure highlighted first list user need subsequently defined mr interface considered suitable solution match gathered requirement however doctor proposed also develop desktop interface finer easier manipulation 3d model proposed mr application offer several advantage possibility display 3d anatomical structure 3d model custom prosthesis immersive environment optimized communication data exchange among player medical staff doctor engineer mock mr application presented work show result design stage deployment application right reserved elsevierbone human_computer_interaction medical_computing prosthetics solid_modelling user_interfaces3d_anatomical_structures current_procedure custom_prostheses design_stage desktop_interface doctors exploratory_focus_group fully_customization fully_customized_prosthesis functionalized_bioactive_surfaces gathered_requirements human machine_interface implantable_devices implantation improved_osteoconductive_surfaces informal_focus_group innovative_category mixed_reality_application mr_application mr_interface structured_questionnaire systematic_approach
398,BirdViewAR: Surroundings-aware Remote Drone Piloting Using an Augmented Third-person Perspective,"Inoue, M., Takashima, K., Fujita, K., & Kitamura, Y. (2023). BirdViewAR: Surroundings-aware Remote Drone Piloting Using an Augmented Third-person Perspective. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580681
",10.1145/3544548.3580681,"We propose BirdViewAR, a surroundings-aware remote drone-operation system that provides significant spatial awareness to pilots through an augmented third-person view (TPV) from an autopiloted secondary follower drone. The follower drone responds to the main drone's motions and directions using our optimization-based autopilot, allowing the pilots to clearly observe the main drone and its imminent destination without extra input. To improve their understanding of the spatial relationships between the main drone and its surroundings, the TPV is visually augmented with AR-overlay graphics, where the main drone's spatial statuses are highlighted: its heading, altitude, ground position, camera field-of-view (FOV), and proximity areas. We discuss BirdViewAR's design and implement its proof-of-concept prototype using programmable drones. Finally, we conduct a preliminary outdoor user study and find that BirdViewAR effectively increased spatial awareness and piloting performance.",C3360L Aerospace control;C3390C Mobile robots;C3390T Telerobotics;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C7420 Control engineering computing,augmented third-person perspective;augmented third-person view;autopiloted secondary follower drone;BirdViewAR;follower drone responds;main drone;piloting performance;programmable drones;significant spatial awareness;surroundings-aware remote drone piloting;surroundings-aware remote drone-operation system,augmented reality;autonomous aerial vehicles;cameras;control engineering computing;mobile robots;remotely operated vehicles;robot vision,2023,Conference article (CA),CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Inoue, M.; (1) Takashima, K.; (1) Fujita, K.; (1) Kitamura, Y.; ","(1) Tohoku University, Japan; ",ACM,-1,"[""autonomous aerial vehicles"", ""cameras"", ""control engineering computing"", ""mobile robots"", ""remotely operated vehicles"", ""robot vision""]","[""autonomous aerial vehicles"", ""cameras"", ""control engineering computing"", ""mobile robots"", ""remotely operated vehicles"", ""robot vision""]",autonomous aerial vehicles;cameras;control engineering computing;mobile robots;remotely operated vehicles;robot vision,computer vision;aviation and aerospace;robotics;input;automotive;engineering,technology;industries,computer vision;aviation and aerospace;robotics;input;automotive;engineering,technology;industries,autonomous_aerial_vehicles cameras control_engineering_computing mobile_robots remotely_operated_vehicles robot_vision augmented_third person_perspective augmented_third person_view autopiloted_secondary_follower_drone birdviewar follower_drone_responds main_drone piloting_performance programmable_drones significant_spatial_awareness surroundings aware_remote_drone_piloting surroundings aware_remote_drone operation_system c3360l_aerospace_control c3390c_mobile_robots c3390t_telerobotics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7420_control_engineering_computing computer_vision aviation_and_aerospace robotics input automotive engineering,autonomous_aerial_vehicles cameras control_engineering_computing mobile_robots remotely_operated_vehicles robot_vision,augmented_third person_perspective augmented_third person_view autopiloted_secondary_follower_drone birdviewar follower_drone_responds main_drone piloting_performance programmable_drones significant_spatial_awareness surroundings aware_remote_drone_piloting surroundings aware_remote_drone operation_system,propose birdviewar surroundings aware remote drone operation system provides significant spatial awareness pilot augmented third person view tpv autopiloted secondary follower drone follower drone responds main drone motion direction using optimization based autopilot allowing pilot clearly observe main drone imminent destination without extra input improve understanding spatial relationship main drone surroundings tpv visually augmented ar overlay graphic main drone spatial status highlighted heading altitude ground position camera field view fov proximity area discus birdviewar design implement proof concept prototype using programmable drone finally conduct preliminary outdoor user study find birdviewar effectively increased spatial awareness piloting performance,autonomous_aerial_vehicles cameras control_engineering_computing mobile_robots remotely_operated_vehicles robot_vision augmented_third person_perspective augmented_third person_view autopiloted_secondary_follower_drone birdviewar follower_drone_responds main_drone piloting_performance programmable_drones significant_spatial_awareness surroundings aware_remote_drone_piloting surroundings aware_remote_drone operation_system c3360l_aerospace_control c3390c_mobile_robots c3390t_telerobotics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c7420_control_engineering_computing computer_vision aviation_and_aerospace robotics input automotive engineering propose birdviewar surroundings aware remote drone operation system provides significant spatial awareness pilot augmented third person view tpv autopiloted secondary follower drone follower drone responds main drone motion direction using optimization based autopilot allowing pilot clearly observe main drone imminent destination without extra input improve understanding spatial relationship main drone surroundings tpv visually augmented ar overlay graphic main drone spatial status highlighted heading altitude ground position camera field view fov proximity area discus birdviewar design implement proof concept prototype using programmable drone finally conduct preliminary outdoor user study find birdviewar effectively increased spatial awareness piloting performance,propose birdviewar surroundings aware remote drone operation system provides significant spatial awareness pilot augmented third person view tpv autopiloted secondary follower drone follower drone responds main drone motion direction using optimization based autopilot allowing pilot clearly observe main drone imminent destination without extra input improve understanding spatial relationship main drone surroundings tpv visually augmented ar overlay graphic main drone spatial status highlighted heading altitude ground position camera field view fov proximity area discus birdviewar design implement proof concept prototype using programmable drone finally conduct preliminary outdoor user study find birdviewar effectively increased spatial awareness piloting performanceautonomous_aerial_vehicles cameras control_engineering_computing mobile_robots remotely_operated_vehicles robot_visionaugmented_third person_perspective augmented_third person_view autopiloted_secondary_follower_drone birdviewar follower_drone_responds main_drone piloting_performance programmable_drones significant_spatial_awareness surroundings aware_remote_drone_piloting surroundings aware_remote_drone operation_system
399,Aerial Manipulation using a Human-Embodied Drone Interface,"Kim, D., & Oh, P. Y. (2022). Aerial Manipulation using a Human-Embodied Drone Interface. 2022 IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO). https://doi.org/10.1109/arso54254.2022.9802972
",10.1109/ARSO54254.2022.9802972,"This paper presents a human-embodied drone interface for aerial manipulation. With the immersive frame-work constructed by Unity and Virtual and Augment Reality (VR/AR), the system allows the operator to leverage their intelligence to evaluate the tasks and collaboratively perform the desired tasks beyond the operator's line-of-sight with a mobile manipulating drone. Flight trials demonstrate the results from three horizontal tasks including drilling, peg-in-hole, and key manipulation to illustrate the efficacy of this system. This paper concludes that the successful human-embodied drone interface can contribute to society by the following: a quality dataset for autonomous dexterous aerial manipulation; hardware-free training system; opportunities for various people who live outside of normal life boundaries.",C3390M Manipulators;C3120C Spatial variables control;C3390C Mobile robots;C6130V Virtual reality;C7420 Control engineering computing,autonomous dexterous aerial manipulation;horizontal tasks including drilling;human-embodied drone interface;key manipulation;mobile manipulating drone,augmented reality;control engineering computing;dexterous manipulators;manipulators;mobile robots;path planning;virtual reality,2022,Conference article (CA),2022 IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO),"(1) Dongbin Kim; (1) Oh, P.Y.; ","(1) University of Nevada, Mechanical Engineering Department, United States; ",IEEE,-1,"[""control engineering computing"", ""dexterous manipulators"", ""manipulators"", ""mobile robots"", ""path planning""]","[""control engineering computing"", ""dexterous manipulators"", ""manipulators"", ""mobile robots"", ""path planning""]",control engineering computing;dexterous manipulators;manipulators;mobile robots;path planning,robotics;industrial equipment;engineering;manufacturing;business planning and management,technology;business;industries,robotics;industrial equipment;engineering;manufacturing;business planning and management,technology;business;industries,control_engineering_computing dexterous_manipulators manipulators mobile_robots path_planning autonomous_dexterous_aerial_manipulation horizontal_tasks_including_drilling human embodied_drone_interface key_manipulation mobile_manipulating_drone c3390m_manipulators c3120c_spatial_variables_control c3390c_mobile_robots c6130v_virtual_reality c7420_control_engineering_computing robotics industrial_equipment engineering manufacturing business_planning_and_management,control_engineering_computing dexterous_manipulators manipulators mobile_robots path_planning,autonomous_dexterous_aerial_manipulation horizontal_tasks_including_drilling human embodied_drone_interface key_manipulation mobile_manipulating_drone,paper present human embodied drone interface aerial manipulation immersive frame work constructed unity virtual augment reality vr ar system allows operator leverage intelligence evaluate task collaboratively perform desired task beyond operator line sight mobile manipulating drone flight trial demonstrate result three horizontal task including drilling peg hole key manipulation illustrate efficacy system paper concludes successful human embodied drone interface contribute society following quality dataset autonomous dexterous aerial manipulation hardware free training system opportunity various people live outside normal life boundary,control_engineering_computing dexterous_manipulators manipulators mobile_robots path_planning autonomous_dexterous_aerial_manipulation horizontal_tasks_including_drilling human embodied_drone_interface key_manipulation mobile_manipulating_drone c3390m_manipulators c3120c_spatial_variables_control c3390c_mobile_robots c6130v_virtual_reality c7420_control_engineering_computing robotics industrial_equipment engineering manufacturing business_planning_and_management paper present human embodied drone interface aerial manipulation immersive frame work constructed unity virtual augment reality vr ar system allows operator leverage intelligence evaluate task collaboratively perform desired task beyond operator line sight mobile manipulating drone flight trial demonstrate result three horizontal task including drilling peg hole key manipulation illustrate efficacy system paper concludes successful human embodied drone interface contribute society following quality dataset autonomous dexterous aerial manipulation hardware free training system opportunity various people live outside normal life boundary,paper present human embodied drone interface aerial manipulation immersive frame work constructed unity virtual augment reality vr ar system allows operator leverage intelligence evaluate task collaboratively perform desired task beyond operator line sight mobile manipulating drone flight trial demonstrate result three horizontal task including drilling peg hole key manipulation illustrate efficacy system paper concludes successful human embodied drone interface contribute society following quality dataset autonomous dexterous aerial manipulation hardware free training system opportunity various people live outside normal life boundarycontrol_engineering_computing dexterous_manipulators manipulators mobile_robots path_planningautonomous_dexterous_aerial_manipulation horizontal_tasks_including_drilling human embodied_drone_interface key_manipulation mobile_manipulating_drone
400,Spelland: Situated Language Learning with a Mixed-Reality Spelling Game through Everyday Objects,"Hsu, C., Chen, Y., Liu, Y.-J., Chang, Y.-C., & Lee, M.-J. (2023). Spelland: Situated Language Learning with a Mixed-Reality Spelling Game through Everyday Objects. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3583830
",10.1145/3544549.3583830,"This work explores the use of mixed-reality (MR) technology to enable situated language learning using everyday objects in the environment around the learners. The learning method is based on Presentation, Practice, and Production (PPP), which cultivates the habit of independent learning through repetition, practice, and demonstration. In our game design, the learners first interact with real-world objects via MR, and the objects' spelling and their pronunciation will appear (Presentation), the learners repeat the pronunciation (Practice) to collect the letters of this objects, and finally the learner use the collected letters to spell out the target words (Production), which then transform into interactive 3D objects. We designed the learning experience and content tools using gestural UI, voice input, and object-to-word engine. Children in the preliminary user study found the game to be immersive, helpful in learning the spelling of the everyday objects and the target words, and additionally showed increased interests in learning about other nearby objects after playing the game.",C7810C Computer-aided instruction;C6130V Virtual reality;C6180 User interfaces;C7820N Natural language processing;C7830D Computer games,content tools;game design;gestural UI;independent learning;interactive 3D objects;learning experience;mixed-reality technology;mixed-reality spelling game;MR technology;object-to-word engine;PPP;presentation practice and production;pronunciation;real-world objects;situated language learning;Spelland;target words;voice input,augmented reality;computer aided instruction;educational courses;human computer interaction;linguistics;serious games (computing);user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Hsu, C.; (2) Chen, Y.; (1) Liu, Y.-J.; (3) Chang, Y.-C.; (2) Lee, M.-J.; ","(1) National Taiwan University of Science and Technology, Department of Design, Taiwan; (2) National Taiwan University, Taiwan; (3) National Taiwan University, Human Computer Interaction Lab, Taiwan; ",ACM,-1,"[""computer aided instruction"", ""educational courses"", ""human computer interaction"", ""linguistics"", ""serious games"", ""user interfaces""]","[""computer aided instruction"", ""educational courses"", ""human computer interaction"", ""linguistics"", ""serious games"", ""user interfaces""]",computer aided instruction;educational courses;human computer interaction;linguistics;serious games;user interfaces,education;simulation;input;training;human-computer interaction,technology;end users and user experience;use cases;industries,education;simulation;input;training;human-computer interaction,technology;end users and user experience;use cases;industries,computer_aided_instruction educational_courses human_computer_interaction linguistics serious_games user_interfaces content_tools game_design gestural_ui independent_learning interactive_3d_objects learning_experience mixed reality_technology mixed reality_spelling_game mr_technology object to word_engine ppp presentation_practice_and_production pronunciation real world_objects situated_language_learning spelland target_words voice_input c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7820n_natural_language_processing c7830d_computer_games education simulation input training human computer_interaction,computer_aided_instruction educational_courses human_computer_interaction linguistics serious_games user_interfaces,content_tools game_design gestural_ui independent_learning interactive_3d_objects learning_experience mixed reality_technology mixed reality_spelling_game mr_technology object to word_engine ppp presentation_practice_and_production pronunciation real world_objects situated_language_learning spelland target_words voice_input,work explores use mixed reality mr technology enable situated language learning using everyday object environment around learner learning method based presentation practice production ppp cultivates habit independent learning repetition practice demonstration game design learner first interact real world object via mr object spelling pronunciation appear presentation learner repeat pronunciation practice collect letter object finally learner use collected letter spell target word production transform interactive 3d object designed learning experience content tool using gestural ui voice input object word engine child preliminary user study found game immersive helpful learning spelling everyday object target word additionally showed increased interest learning nearby object playing game,computer_aided_instruction educational_courses human_computer_interaction linguistics serious_games user_interfaces content_tools game_design gestural_ui independent_learning interactive_3d_objects learning_experience mixed reality_technology mixed reality_spelling_game mr_technology object to word_engine ppp presentation_practice_and_production pronunciation real world_objects situated_language_learning spelland target_words voice_input c7810c_computer aided_instruction c6130v_virtual_reality c6180_user_interfaces c7820n_natural_language_processing c7830d_computer_games education simulation input training human computer_interaction work explores use mixed reality mr technology enable situated language learning using everyday object environment around learner learning method based presentation practice production ppp cultivates habit independent learning repetition practice demonstration game design learner first interact real world object via mr object spelling pronunciation appear presentation learner repeat pronunciation practice collect letter object finally learner use collected letter spell target word production transform interactive 3d object designed learning experience content tool using gestural ui voice input object word engine child preliminary user study found game immersive helpful learning spelling everyday object target word additionally showed increased interest learning nearby object playing game,work explores use mixed reality mr technology enable situated language learning using everyday object environment around learner learning method based presentation practice production ppp cultivates habit independent learning repetition practice demonstration game design learner first interact real world object via mr object spelling pronunciation appear presentation learner repeat pronunciation practice collect letter object finally learner use collected letter spell target word production transform interactive 3d object designed learning experience content tool using gestural ui voice input object word engine child preliminary user study found game immersive helpful learning spelling everyday object target word additionally showed increased interest learning nearby object playing gamecomputer_aided_instruction educational_courses human_computer_interaction linguistics serious_games user_interfacescontent_tools game_design gestural_ui independent_learning interactive_3d_objects learning_experience mixed reality_technology mixed reality_spelling_game mr_technology object to word_engine ppp presentation_practice_and_production pronunciation real world_objects situated_language_learning spelland target_words voice_input
401,Interoperability between Real and Virtual Environments Connected by a GAN for the Path-Planning Problem,"Maldonado-Romo, J., & Aldape-Pérez, M. (2021). Interoperability between Real and Virtual Environments Connected by a GAN for the Path-Planning Problem. Applied Sciences, 11(21), 10445. https://doi.org/10.3390/app112110445
",10.3390/app112110445,"Path planning is a fundamental issue in robotic systems because it requires coordination between the environment and an agent. The path-planning generator is composed of two modules: perception and planning. The first module scans the environment to determine the location, detect obstacles, estimate objects in motion, and build the planner module's restrictions. On the other hand, the second module controls the flight of the system. This process is computationally expensive and requires adequate performance to avoid accidents. For this reason, we propose a novel solution to improve conventional robotic systems' functions, such as systems having a small-capacity battery, a restricted size, and a limited number of sensors, using fewer elements. A navigation dataset was generated through a virtual simulator and a generative adversarial network to connect the virtual and real environments under an end-to-end approach. Furthermore, three path generators were analyzed using deep-learning solutions: a deep convolutional neural network, hierarchical clustering, and an auto-encoder. Since the path generators share a characteristic vector, transfer learning approaches complex problems by using solutions with fewer features, minimizing the costs and optimizing the resources of conventional system architectures, thus improving the limitations with respect to the implementation in embedded devices. Finally, a visualizer applying augmented reality was used to display the path generated by the proposed system.",C5260B Computer vision and image processing techniques;C1180 Optimisation techniques;C3120C Spatial variables control;C3390C Mobile robots;C6130B Graphics techniques;C6130V Virtual reality,adequate performance;complex problems;conventional robotic systems;conventional system architectures;deep convolutional neural network;deep-learning solutions;end-to-end approach;generative adversarial network;path generators;path planning;path-planning generator;path-planning problem;planner module;real environments;restricted size;virtual environments;virtual simulator,augmented reality;collision avoidance;data visualisation;intelligent robots;learning (artificial intelligence);mobile robots;motion control;neural nets;path planning,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Maldonado-romo, J.; (1) Aldape-pe&#769;rez, M.; ","(1) CIDETEC, Postgraduate Department, Mexico; ",MDPI,-1,"[""collision avoidance"", ""data visualization"", ""intelligent robots"", ""learning algorithms"", ""mobile robots"", ""motion control"", ""neural networks"", ""path planning""]","[""collision avoidance"", ""data visualization"", ""intelligent robots"", ""learning algorithms"", ""mobile robots"", ""motion control"", ""neural networks"", ""path planning""]",collision avoidance;data visualization;intelligent robots;learning algorithms;mobile robots;motion control;neural networks;path planning,artificial intelligence;robotics;medical;automotive;data;manufacturing;business planning and management,technology;business;industries,artificial intelligence;robotics;medical;automotive;data;manufacturing;business planning and management,technology;business;industries,collision_avoidance data_visualization intelligent_robots learning_algorithms mobile_robots motion_control neural_networks path_planning adequate_performance complex_problems conventional_robotic_systems conventional_system_architectures deep_convolutional_neural_network deep learning_solutions end to end_approach generative_adversarial_network path_generators path_planning path planning_generator path planning_problem planner_module real_environments restricted_size virtual_environments virtual_simulator c5260b_computer_vision_and_image_processing_techniques c1180_optimisation_techniques c3120c_spatial_variables_control c3390c_mobile_robots c6130b_graphics_techniques c6130v_virtual_reality artificial_intelligence robotics medical automotive data manufacturing business_planning_and_management,collision_avoidance data_visualization intelligent_robots learning_algorithms mobile_robots motion_control neural_networks path_planning,adequate_performance complex_problems conventional_robotic_systems conventional_system_architectures deep_convolutional_neural_network deep learning_solutions end to end_approach generative_adversarial_network path_generators path_planning path planning_generator path planning_problem planner_module real_environments restricted_size virtual_environments virtual_simulator,path planning fundamental issue robotic system requires coordination environment agent path planning generator composed two module perception planning first module scan environment determine location detect obstacle estimate object motion build planner module restriction hand second module control flight system process computationally expensive requires adequate performance avoid accident reason propose novel solution improve conventional robotic system function system small capacity battery restricted size limited number sensor using fewer element navigation dataset generated virtual simulator generative adversarial network connect virtual real environment end end approach furthermore three path generator analyzed using deep learning solution deep convolutional neural network hierarchical clustering auto encoder since path generator share characteristic vector transfer learning approach complex problem using solution fewer feature minimizing cost optimizing resource conventional system architecture thus improving limitation respect implementation embedded device finally visualizer applying augmented reality used display path generated proposed system,collision_avoidance data_visualization intelligent_robots learning_algorithms mobile_robots motion_control neural_networks path_planning adequate_performance complex_problems conventional_robotic_systems conventional_system_architectures deep_convolutional_neural_network deep learning_solutions end to end_approach generative_adversarial_network path_generators path_planning path planning_generator path planning_problem planner_module real_environments restricted_size virtual_environments virtual_simulator c5260b_computer_vision_and_image_processing_techniques c1180_optimisation_techniques c3120c_spatial_variables_control c3390c_mobile_robots c6130b_graphics_techniques c6130v_virtual_reality artificial_intelligence robotics medical automotive data manufacturing business_planning_and_management path planning fundamental issue robotic system requires coordination environment agent path planning generator composed two module perception planning first module scan environment determine location detect obstacle estimate object motion build planner module restriction hand second module control flight system process computationally expensive requires adequate performance avoid accident reason propose novel solution improve conventional robotic system function system small capacity battery restricted size limited number sensor using fewer element navigation dataset generated virtual simulator generative adversarial network connect virtual real environment end end approach furthermore three path generator analyzed using deep learning solution deep convolutional neural network hierarchical clustering auto encoder since path generator share characteristic vector transfer learning approach complex problem using solution fewer feature minimizing cost optimizing resource conventional system architecture thus improving limitation respect implementation embedded device finally visualizer applying augmented reality used display path generated proposed system,path planning fundamental issue robotic system requires coordination environment agent path planning generator composed two module perception planning first module scan environment determine location detect obstacle estimate object motion build planner module restriction hand second module control flight system process computationally expensive requires adequate performance avoid accident reason propose novel solution improve conventional robotic system function system small capacity battery restricted size limited number sensor using fewer element navigation dataset generated virtual simulator generative adversarial network connect virtual real environment end end approach furthermore three path generator analyzed using deep learning solution deep convolutional neural network hierarchical clustering auto encoder since path generator share characteristic vector transfer learning approach complex problem using solution fewer feature minimizing cost optimizing resource conventional system architecture thus improving limitation respect implementation embedded device finally visualizer applying augmented reality used display path generated proposed systemcollision_avoidance data_visualization intelligent_robots learning_algorithms mobile_robots motion_control neural_networks path_planningadequate_performance complex_problems conventional_robotic_systems conventional_system_architectures deep_convolutional_neural_network deep learning_solutions end to end_approach generative_adversarial_network path_generators path_planning path planning_generator path planning_problem planner_module real_environments restricted_size virtual_environments virtual_simulator
402,Cross-Modal Sentiment Sensing with Visual-Augmented Representation and Diverse Decision Fusion,"Zhang, S., Li, B., & Yin, C. (2021). Cross-Modal Sentiment Sensing with Visual-Augmented Representation and Diverse Decision Fusion. Sensors, 22(1), 74. https://doi.org/10.3390/s22010074
",10.3390/s22010074,"The rising use of online media has changed the social customs of the public. Users have become accustomed to sharing daily experiences and publishing personal opinions on social networks. Social data carrying emotion and attitude has provided significant decision support for numerous tasks in sentiment analysis. Conventional methods for sentiment classification only concern textual modality and are vulnerable to the multimodal scenario, while common multimodal approaches only focus on the interactive relationship among modalities without considering unique intra-modal information. A hybrid fusion network is proposed in this paper to capture both inter-modal and intra-modal features. Firstly, in the stage of representation fusion, a multi-head visual attention is proposed to extract accurate semantic and sentimental information from textual contents, with the guidance of visual features. Then, multiple base classifiers are trained to learn independent and diverse discriminative information from different modal representations in the stage of decision fusion. The final decision is determined based on fusing the decision supports from base classifiers via a decision fusion method. To improve the generalization of our hybrid fusion network, a similarity loss is employed to inject decision diversity into the whole model. Empiric results on five multimodal datasets have demonstrated that the proposed model achieves higher accuracy and better generalization capacity for multimodal sentiment analysis.",B6135E Image recognition;C5260B Computer vision and image processing techniques;C6130D Document processing and analysis techniques;C6130V Virtual reality;C7210N Information networks;C7820N Natural language processing,accurate semantic information;cross-modal sentiment sensing;decision diversity;decision fusion method;diverse discriminative information;hybrid fusion network;independent information;inter-modal;interactive relationship;intra-modal features;multihead visual attention;multimodal scenario;multimodal sentiment analysis;multiple base classifiers;online media;sentiment classification;sentimental information;social customs;social data carrying emotion;social networks;textual contents;unique intra-modal information;visual features;visual-augmented representation,augmented reality;emotion recognition;feature extraction;sentiment analysis;social networking (online),2021,Journal article (JA),Sensors (Switzerland),(1) Sun Zhang; (1) Bo Li; (1) Chunyong Yin; ,"(1) Nanjing University of Information Science and Technology, School of Computer and Software, China; ",MDPI,-1,"[""emotion recognition"", ""feature extraction"", ""sentiment analysis"", ""social networking""]","[""emotion recognition"", ""feature extraction"", ""sentiment analysis"", ""social networking""]",emotion recognition;feature extraction;sentiment analysis;social networking,computer vision;input;chemical;collaboration;human factors,technology;end users and user experience;use cases;industries,computer vision;input;chemical;collaboration;human factors,technology;end users and user experience;use cases;industries,emotion_recognition feature_extraction sentiment_analysis social_networking accurate_semantic_information cross modal_sentiment_sensing decision_diversity decision_fusion_method diverse_discriminative_information hybrid_fusion_network independent_information inter modal interactive_relationship intra modal_features multihead_visual_attention multimodal_scenario multimodal_sentiment_analysis multiple_base_classifiers online_media sentiment_classification sentimental_information social_customs social_data_carrying_emotion social_networks textual_contents unique_intra modal_information visual_features visual augmented_representation b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c7210n_information_networks c7820n_natural_language_processing computer_vision input chemical collaboration human_factors,emotion_recognition feature_extraction sentiment_analysis social_networking,accurate_semantic_information cross modal_sentiment_sensing decision_diversity decision_fusion_method diverse_discriminative_information hybrid_fusion_network independent_information inter modal interactive_relationship intra modal_features multihead_visual_attention multimodal_scenario multimodal_sentiment_analysis multiple_base_classifiers online_media sentiment_classification sentimental_information social_customs social_data_carrying_emotion social_networks textual_contents unique_intra modal_information visual_features visual augmented_representation,rising use online medium changed social custom public user become accustomed sharing daily experience publishing personal opinion social network social data carrying emotion attitude provided significant decision support numerous task sentiment analysis conventional method sentiment classification concern textual modality vulnerable multimodal scenario common multimodal approach focus interactive relationship among modality without considering unique intra modal information hybrid fusion network proposed paper capture inter modal intra modal feature firstly stage representation fusion multi head visual attention proposed extract accurate semantic sentimental information textual content guidance visual feature multiple base classifier trained learn independent diverse discriminative information different modal representation stage decision fusion final decision determined based fusing decision support base classifier via decision fusion method improve generalization hybrid fusion network similarity loss employed inject decision diversity whole model empiric result five multimodal datasets demonstrated proposed model achieves higher accuracy better generalization capacity multimodal sentiment analysis,emotion_recognition feature_extraction sentiment_analysis social_networking accurate_semantic_information cross modal_sentiment_sensing decision_diversity decision_fusion_method diverse_discriminative_information hybrid_fusion_network independent_information inter modal interactive_relationship intra modal_features multihead_visual_attention multimodal_scenario multimodal_sentiment_analysis multiple_base_classifiers online_media sentiment_classification sentimental_information social_customs social_data_carrying_emotion social_networks textual_contents unique_intra modal_information visual_features visual augmented_representation b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c6130d_document_processing_and_analysis_techniques c6130v_virtual_reality c7210n_information_networks c7820n_natural_language_processing computer_vision input chemical collaboration human_factors rising use online medium changed social custom public user become accustomed sharing daily experience publishing personal opinion social network social data carrying emotion attitude provided significant decision support numerous task sentiment analysis conventional method sentiment classification concern textual modality vulnerable multimodal scenario common multimodal approach focus interactive relationship among modality without considering unique intra modal information hybrid fusion network proposed paper capture inter modal intra modal feature firstly stage representation fusion multi head visual attention proposed extract accurate semantic sentimental information textual content guidance visual feature multiple base classifier trained learn independent diverse discriminative information different modal representation stage decision fusion final decision determined based fusing decision support base classifier via decision fusion method improve generalization hybrid fusion network similarity loss employed inject decision diversity whole model empiric result five multimodal datasets demonstrated proposed model achieves higher accuracy better generalization capacity multimodal sentiment analysis,rising use online medium changed social custom public user become accustomed sharing daily experience publishing personal opinion social network social data carrying emotion attitude provided significant decision support numerous task sentiment analysis conventional method sentiment classification concern textual modality vulnerable multimodal scenario common multimodal approach focus interactive relationship among modality without considering unique intra modal information hybrid fusion network proposed paper capture inter modal intra modal feature firstly stage representation fusion multi head visual attention proposed extract accurate semantic sentimental information textual content guidance visual feature multiple base classifier trained learn independent diverse discriminative information different modal representation stage decision fusion final decision determined based fusing decision support base classifier via decision fusion method improve generalization hybrid fusion network similarity loss employed inject decision diversity whole model empiric result five multimodal datasets demonstrated proposed model achieves higher accuracy better generalization capacity multimodal sentiment analysisemotion_recognition feature_extraction sentiment_analysis social_networkingaccurate_semantic_information cross modal_sentiment_sensing decision_diversity decision_fusion_method diverse_discriminative_information hybrid_fusion_network independent_information inter modal interactive_relationship intra modal_features multihead_visual_attention multimodal_scenario multimodal_sentiment_analysis multiple_base_classifiers online_media sentiment_classification sentimental_information social_customs social_data_carrying_emotion social_networks textual_contents unique_intra modal_information visual_features visual augmented_representation
403,VanityX: An Agile 3D Rendering Platform Supporting Mixed Reality,"Zoraja, I., Bonkovic, M., Papic, V., & Sunderam, V. (2023). VanityX: An Agile 3D Rendering Platform Supporting Mixed Reality. Applied Sciences, 13(9), 5468. https://doi.org/10.3390/app13095468
",10.3390/app13095468,"VanityX is a prototype, low-level, real-time 3D rendering and computing platform. Unlike most XR solutions, which integrate several commercial and/or open-source products, such as game engines, XR libraries, runtime, and services, VanityX is a platform ready to adapt to any business domain including anthropology and medicine. The design, architecture, and implementation are presented, which are based on CPU and GPU asymmetric multiprocessing with explicit synchronization and collaboration of parallel tasks and a predictable transfer of pipeline resources between processors. The VanityX API is based on DirectX 12 and native programming languages C++20 and HLSL 6, which, in conjunction with explicit parallel processing, the asynchronous loading and explicit managing of graphic resources, and effective algorithms, results in great performance and resource utilization close to metal. Surface-based rendering, direct volume rendering (DVR), and mixed reality (MR) on the HoloLens 2 immersive headset are currently supported. Our MR applications are directly compiled and deployed to HoloLens 2 allowing for better programming experiences and software engineering practices such as testing, debugging, and profiling. The VanityX server provides various computational and rendering services to its clients running on HoloLens 2. The use and test cases are in many business domains including anthropology and medicine. Our future research challenges will primarily, via the MetaverseMed project, focus on opening new opportunities for implementing innovative MR-based scenarios in medical procedures, especially in education, diagnostics, and surgical operations.",C6130B Graphics techniques;C6110B Software engineering techniques;C6130V Virtual reality;C6150E General utility programs;C6180 User interfaces,agile 3D rendering platform supporting mixed reality;business domain including anthropology;business domains including anthropology;computational rendering services;computing platform;direct volume rendering;explicit managing;explicit parallel processing;explicit synchronization;game engines;graphic resources;HoloLens 2 immersive headset;innovative MR-based scenarios;medicine;native programming languages C;open-source products;parallel tasks;pipeline resources;predictable transfer;resource utilization close;software engineering practices;surface-based rendering;VanityX API;VanityX server;XR libraries;XR solutions,application program interfaces;augmented reality;multiprocessing systems;parallel processing;rendering (computer graphics);software engineering;virtual reality,2023,Journal article (JA),Appl. Sci. (Switzerland),"(1) Zoraja, I.; (2) Bonkovic, M.; (2) Papic, V.; (3) Sunderam, V.; ","(1) Zoraja Consulting, Spinc&#780;ic&#769;eva 2E, Croatia; (2) University of Split, Faculty of Electrical Engineering, Mechanical Engineering and Naval Architecture, Ru&#273;era Bos&#780;kovic&#769;a 32, Croatia; (3) Emory University, Department of Mathematics and Computer Science, 400 Dowman Dr., Atlanta, GA 30322, United States; ",MDPI,-1,"[""application program interfaces"", ""multiprocessing systems"", ""parallel processing"", ""rendering"", ""software engineering""]","[""application program interfaces"", ""multiprocessing systems"", ""parallel processing"", ""rendering"", ""software engineering""]",application program interfaces;multiprocessing systems;parallel processing;rendering;software engineering,education;graphics;developers;data;semiconductors,technology;industries,education;graphics;developers;data;semiconductors,technology;industries,application_program_interfaces multiprocessing_systems parallel_processing rendering software_engineering agile_3d_rendering_platform_supporting_mixed_reality business_domain_including_anthropology business_domains_including_anthropology computational_rendering_services computing_platform direct_volume_rendering explicit_managing explicit_parallel_processing explicit_synchronization game_engines graphic_resources hololens_2_immersive_headset innovative_mr based_scenarios medicine native_programming_languages_c open source_products parallel_tasks pipeline_resources predictable_transfer resource_utilization_close software_engineering_practices surface based_rendering vanityx_api vanityx_server xr_libraries xr_solutions c6130b_graphics_techniques c6110b_software_engineering_techniques c6130v_virtual_reality c6150e_general_utility_programs c6180_user_interfaces education graphics developers data semiconductors,application_program_interfaces multiprocessing_systems parallel_processing rendering software_engineering,agile_3d_rendering_platform_supporting_mixed_reality business_domain_including_anthropology business_domains_including_anthropology computational_rendering_services computing_platform direct_volume_rendering explicit_managing explicit_parallel_processing explicit_synchronization game_engines graphic_resources hololens_2_immersive_headset innovative_mr based_scenarios medicine native_programming_languages_c open source_products parallel_tasks pipeline_resources predictable_transfer resource_utilization_close software_engineering_practices surface based_rendering vanityx_api vanityx_server xr_libraries xr_solutions,vanityx prototype low level real time 3d rendering computing platform unlike xr solution integrate several commercial open source product game engine xr library runtime service vanityx platform ready adapt business domain including anthropology medicine design architecture implementation presented based cpu gpu asymmetric multiprocessing explicit synchronization collaboration parallel task predictable transfer pipeline resource processor vanityx api based directx 12 native programming language c 20 hlsl 6 conjunction explicit parallel processing asynchronous loading explicit managing graphic resource effective algorithm result great performance resource utilization close metal surface based rendering direct volume rendering dvr mixed reality mr hololens 2 immersive headset currently supported mr application directly compiled deployed hololens 2 allowing better programming experience software engineering practice testing debugging profiling vanityx server provides various computational rendering service client running hololens 2 use test case many business domain including anthropology medicine future research challenge primarily via metaversemed project focus opening new opportunity implementing innovative mr based scenario medical procedure especially education diagnostics surgical operation,application_program_interfaces multiprocessing_systems parallel_processing rendering software_engineering agile_3d_rendering_platform_supporting_mixed_reality business_domain_including_anthropology business_domains_including_anthropology computational_rendering_services computing_platform direct_volume_rendering explicit_managing explicit_parallel_processing explicit_synchronization game_engines graphic_resources hololens_2_immersive_headset innovative_mr based_scenarios medicine native_programming_languages_c open source_products parallel_tasks pipeline_resources predictable_transfer resource_utilization_close software_engineering_practices surface based_rendering vanityx_api vanityx_server xr_libraries xr_solutions c6130b_graphics_techniques c6110b_software_engineering_techniques c6130v_virtual_reality c6150e_general_utility_programs c6180_user_interfaces education graphics developers data semiconductors vanityx prototype low level real time 3d rendering computing platform unlike xr solution integrate several commercial open source product game engine xr library runtime service vanityx platform ready adapt business domain including anthropology medicine design architecture implementation presented based cpu gpu asymmetric multiprocessing explicit synchronization collaboration parallel task predictable transfer pipeline resource processor vanityx api based directx 12 native programming language c 20 hlsl 6 conjunction explicit parallel processing asynchronous loading explicit managing graphic resource effective algorithm result great performance resource utilization close metal surface based rendering direct volume rendering dvr mixed reality mr hololens 2 immersive headset currently supported mr application directly compiled deployed hololens 2 allowing better programming experience software engineering practice testing debugging profiling vanityx server provides various computational rendering service client running hololens 2 use test case many business domain including anthropology medicine future research challenge primarily via metaversemed project focus opening new opportunity implementing innovative mr based scenario medical procedure especially education diagnostics surgical operation,vanityx prototype low level real time 3d rendering computing platform unlike xr solution integrate several commercial open source product game engine xr library runtime service vanityx platform ready adapt business domain including anthropology medicine design architecture implementation presented based cpu gpu asymmetric multiprocessing explicit synchronization collaboration parallel task predictable transfer pipeline resource processor vanityx api based directx 12 native programming language c 20 hlsl 6 conjunction explicit parallel processing asynchronous loading explicit managing graphic resource effective algorithm result great performance resource utilization close metal surface based rendering direct volume rendering dvr mixed reality mr hololens 2 immersive headset currently supported mr application directly compiled deployed hololens 2 allowing better programming experience software engineering practice testing debugging profiling vanityx server provides various computational rendering service client running hololens 2 use test case many business domain including anthropology medicine future research challenge primarily via metaversemed project focus opening new opportunity implementing innovative mr based scenario medical procedure especially education diagnostics surgical operationapplication_program_interfaces multiprocessing_systems parallel_processing rendering software_engineeringagile_3d_rendering_platform_supporting_mixed_reality business_domain_including_anthropology business_domains_including_anthropology computational_rendering_services computing_platform direct_volume_rendering explicit_managing explicit_parallel_processing explicit_synchronization game_engines graphic_resources hololens_2_immersive_headset innovative_mr based_scenarios medicine native_programming_languages_c open source_products parallel_tasks pipeline_resources predictable_transfer resource_utilization_close software_engineering_practices surface based_rendering vanityx_api vanityx_server xr_libraries xr_solutions
404,A Novel MAC Scheduling Approach for Mobility based 5G Millimeter Wave Networks,"Hassan, T., & Mowla, M. (2022). A Novel MAC Scheduling Approach for Mobility based 5G Millimeter Wave Networks. 2022 4th International Conference on Electrical, Computer &amp; Telecommunication Engineering (ICECTE). https://doi.org/10.1109/icecte57896.2022.10114524
",10.1109/ICECTE57896.2022.10114524,"Recent days have seen an increase in network traffic caused by bandwidth-hungry apps like augmented reality (AR), virtual reality (VR), and vehicle-to-everything (V2X), which 4G standards and technologies are unable to handle. The millimeter-wave (mmWave) can be seen as a gift for 5G systems meeting extremely high traffic demands by guaranteeing high throughput and low latency. More performance metrics such as SINR, throughput, and RTT inspection are required while increasing the number of UEs in different challenging regions. In UMa situations, MAC scheduling, as well as admission control, are also confusing TCP performance issues. This article uses ns3 to demonstrate a mobility based novel Proportional-Fair (PF) MAC scheduler for 5G networks integrated with mmWave. In this paper, we investigated resource allocation and access to the nearest data center in a practical mobility model based on 5G heterogeneous networks (HetNets). The result spreads higher-yielding in simultaneously growing quantities in the future complex structure of 5G networks.",B6250F Mobile radio systems;B6150M Protocols;B6210C Network management;C3370H Control applications in radio and radar;C5640 Protocols,4G standards;5G heterogeneous networks;5G millimeter wave networks;admission control;augmented reality;bandwidth-hungry apps;high traffic demands;nearest data center;network traffic;performance metrics;practical mobility model;proportional-fair MAC scheduler;resource allocation;RTT inspection;TCP performance;UMa situations;vehicle-to-everything;virtual reality,4G mobile communication;5G mobile communication;millimetre wave communication;mobility management (mobile radio);resource allocation;telecommunication congestion control;telecommunication scheduling;telecommunication traffic;transport protocols,2022,Conference article (CA),"2022 4th International Conference on Electrical, Computer &amp; Telecommunication Engineering (ICECTE)","(1) Hassan, T.; (1) Mowla, M.; ","(1) Rajshahi University of Engineering and Technology, Bangladesh; ",IEEE,-1,"[""4g mobile communication"", ""5g mobile communication"", ""millimetre wave communication"", ""mobility management"", ""resource allocation"", ""telecommunication congestion control"", ""telecommunication scheduling"", ""telecommunication traffic"", ""transport protocols""]","[""4g mobile communication"", ""5g mobile communication"", ""millimetre wave communication"", ""mobility management"", ""resource allocation"", ""telecommunication congestion control"", ""telecommunication scheduling"", ""telecommunication traffic"", ""transport protocols""]",4g mobile communication;5g mobile communication;millimetre wave communication;mobility management;resource allocation;telecommunication congestion control;telecommunication scheduling;telecommunication traffic;transport protocols,input;cultural heritage;telecommunication;developers;standards;geospatial;business planning and management;networks,technology;standards;business;industries,input;cultural heritage;telecommunication;developers;standards;geospatial;business planning and management;networks,technology;standards;business;industries,4g_mobile_communication 5g_mobile_communication millimetre_wave_communication mobility_management resource_allocation telecommunication_congestion_control telecommunication_scheduling telecommunication_traffic transport_protocols 4g_standards 5g_heterogeneous_networks 5g_millimeter_wave_networks admission_control augmented_reality bandwidth hungry_apps high_traffic_demands nearest_data_center network_traffic performance_metrics practical_mobility_model proportional fair_mac_scheduler resource_allocation rtt_inspection tcp_performance uma_situations vehicle to everything virtual_reality b6250f_mobile_radio_systems b6150m_protocols b6210c_network_management c3370h_control_applications_in_radio_and_radar c5640_protocols input cultural_heritage telecommunication developers standards geospatial business_planning_and_management networks,4g_mobile_communication 5g_mobile_communication millimetre_wave_communication mobility_management resource_allocation telecommunication_congestion_control telecommunication_scheduling telecommunication_traffic transport_protocols,4g_standards 5g_heterogeneous_networks 5g_millimeter_wave_networks admission_control augmented_reality bandwidth hungry_apps high_traffic_demands nearest_data_center network_traffic performance_metrics practical_mobility_model proportional fair_mac_scheduler resource_allocation rtt_inspection tcp_performance uma_situations vehicle to everything virtual_reality,recent day seen increase network traffic caused bandwidth hungry apps like augmented reality ar virtual reality vr vehicle everything v2x 4g standard technology unable handle millimeter wave mmwave seen gift 5g system meeting extremely high traffic demand guaranteeing high throughput low latency performance metric sinr throughput rtt inspection required increasing number ues different challenging region uma situation mac scheduling well admission control also confusing tcp performance issue article us ns3 demonstrate mobility based novel proportional fair pf mac scheduler 5g network integrated mmwave paper investigated resource allocation access nearest data center practical mobility model based 5g heterogeneous network hetnets result spread higher yielding simultaneously growing quantity future complex structure 5g network,4g_mobile_communication 5g_mobile_communication millimetre_wave_communication mobility_management resource_allocation telecommunication_congestion_control telecommunication_scheduling telecommunication_traffic transport_protocols 4g_standards 5g_heterogeneous_networks 5g_millimeter_wave_networks admission_control augmented_reality bandwidth hungry_apps high_traffic_demands nearest_data_center network_traffic performance_metrics practical_mobility_model proportional fair_mac_scheduler resource_allocation rtt_inspection tcp_performance uma_situations vehicle to everything virtual_reality b6250f_mobile_radio_systems b6150m_protocols b6210c_network_management c3370h_control_applications_in_radio_and_radar c5640_protocols input cultural_heritage telecommunication developers standards geospatial business_planning_and_management networks recent day seen increase network traffic caused bandwidth hungry apps like augmented reality ar virtual reality vr vehicle everything v2x 4g standard technology unable handle millimeter wave mmwave seen gift 5g system meeting extremely high traffic demand guaranteeing high throughput low latency performance metric sinr throughput rtt inspection required increasing number ues different challenging region uma situation mac scheduling well admission control also confusing tcp performance issue article us ns3 demonstrate mobility based novel proportional fair pf mac scheduler 5g network integrated mmwave paper investigated resource allocation access nearest data center practical mobility model based 5g heterogeneous network hetnets result spread higher yielding simultaneously growing quantity future complex structure 5g network,recent day seen increase network traffic caused bandwidth hungry apps like augmented reality ar virtual reality vr vehicle everything v2x 4g standard technology unable handle millimeter wave mmwave seen gift 5g system meeting extremely high traffic demand guaranteeing high throughput low latency performance metric sinr throughput rtt inspection required increasing number ues different challenging region uma situation mac scheduling well admission control also confusing tcp performance issue article us ns3 demonstrate mobility based novel proportional fair pf mac scheduler 5g network integrated mmwave paper investigated resource allocation access nearest data center practical mobility model based 5g heterogeneous network hetnets result spread higher yielding simultaneously growing quantity future complex structure 5g network4g_mobile_communication 5g_mobile_communication millimetre_wave_communication mobility_management resource_allocation telecommunication_congestion_control telecommunication_scheduling telecommunication_traffic transport_protocols4g_standards 5g_heterogeneous_networks 5g_millimeter_wave_networks admission_control augmented_reality bandwidth hungry_apps high_traffic_demands nearest_data_center network_traffic performance_metrics practical_mobility_model proportional fair_mac_scheduler resource_allocation rtt_inspection tcp_performance uma_situations vehicle to everything virtual_reality
405,Evaluating the design of an art student framework supporting xr exhibitions: evaluating an art student framework,"Koukopoulos, D., Dafiotis, P., Sylaiou, S., Koukoulis, K., & Fidas, C. (2022). Evaluating the Design of an Art Student Framework Supporting XR Exhibitions. Proceedings of the 26th Pan-Hellenic Conference on Informatics. https://doi.org/10.1145/3575879.3576003
",10.1145/3575879.3576003,"A successful system design may lead to a successfully implemented system. This paper demonstrates the followed evaluation procedure for the creation of a system dedicated to art schools. Specifically, we focus on meeting the needs of art teachers, art students, and visitors who are the stakeholders of such a system. Art teachers need to be able to initiate art exhibitions for their students and assess them, art students to create virtual exhibitions, and art exhibition visitors to have immersive and interactive experiences. This evaluation is a part of an EU-funded research project, namely CREAMS which aims to design, develop end evaluate a framework and open-source tools based on virtual, augmented, and mixed reality for the creation of virtual exhibitions for art students. Here, we present the followed user-centered design methodology that we followed to reach the first system design. The methodology begins with the literature review and continues with the filtering of review findings by experts, the creation of the corresponding mockups, the evaluation of the mockups by the end users, the specification of quantitative and qualitative metrics on employing XR technologies in Higher Education Institutions and concludes with the identification of a set of specifications that drives the development of a specific conceptual system design.",C7810C Computer-aided instruction;C0240 Ergonomic aspects of computing;C6130V Virtual reality;C6180 User interfaces;C7820 Humanities computing,art exhibition visitors;art exhibitions;art schools;art student framework;art students;art teachers;followed evaluation procedure;followed user-centered design methodology;specific conceptual system design;successful system design;successfully implemented system;virtual exhibitions;xr exhibitions,art;augmented reality;computer aided instruction;educational institutions;further education;user centred design;virtual reality,2022,Conference article (CA),PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics,"(1) Koukopoulos, D.; (2) Dafiotis, P.; (3) Sylaiou, S.; (1) Koukoulis, K.; (1) Fidas, C.; ","(1) University of Patras, Greece; (2) Aristotle University of Thessaloniki, Greece; (3) International Hellenic University, Greece; ",ACM,-1,"[""art"", ""computer aided instruction"", ""educational institutions"", ""further education"", ""user centered design""]","[""art"", ""computer aided instruction"", ""educational institutions"", ""further education"", ""user centered design""]",art;computer aided instruction;educational institutions;further education;user centered design,education;liberal arts;training;developers;human-computer interaction,technology;end users and user experience;use cases;industries,education;liberal arts;training;developers;human-computer interaction,technology;end users and user experience;use cases;industries,art computer_aided_instruction educational_institutions further_education user_centered_design art_exhibition_visitors art_exhibitions art_schools art_student_framework art_students art_teachers followed_evaluation_procedure followed_user centered_design_methodology specific_conceptual_system_design successful_system_design successfully_implemented_system virtual_exhibitions xr_exhibitions c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces c7820_humanities_computing education liberal_arts training developers human computer_interaction,art computer_aided_instruction educational_institutions further_education user_centered_design,art_exhibition_visitors art_exhibitions art_schools art_student_framework art_students art_teachers followed_evaluation_procedure followed_user centered_design_methodology specific_conceptual_system_design successful_system_design successfully_implemented_system virtual_exhibitions xr_exhibitions,successful system design may lead successfully implemented system paper demonstrates followed evaluation procedure creation system dedicated art school specifically focus meeting need art teacher art student visitor stakeholder system art teacher need able initiate art exhibition student ass art student create virtual exhibition art exhibition visitor immersive interactive experience evaluation part eu funded research project namely cream aim design develop end evaluate framework open source tool based virtual augmented mixed reality creation virtual exhibition art student present followed user centered design methodology followed reach first system design methodology begin literature review continues filtering review finding expert creation corresponding mockups evaluation mockups end user specification quantitative qualitative metric employing xr technology higher education institution concludes identification set specification drive development specific conceptual system design,art computer_aided_instruction educational_institutions further_education user_centered_design art_exhibition_visitors art_exhibitions art_schools art_student_framework art_students art_teachers followed_evaluation_procedure followed_user centered_design_methodology specific_conceptual_system_design successful_system_design successfully_implemented_system virtual_exhibitions xr_exhibitions c7810c_computer aided_instruction c0240_ergonomic_aspects_of_computing c6130v_virtual_reality c6180_user_interfaces c7820_humanities_computing education liberal_arts training developers human computer_interaction successful system design may lead successfully implemented system paper demonstrates followed evaluation procedure creation system dedicated art school specifically focus meeting need art teacher art student visitor stakeholder system art teacher need able initiate art exhibition student ass art student create virtual exhibition art exhibition visitor immersive interactive experience evaluation part eu funded research project namely cream aim design develop end evaluate framework open source tool based virtual augmented mixed reality creation virtual exhibition art student present followed user centered design methodology followed reach first system design methodology begin literature review continues filtering review finding expert creation corresponding mockups evaluation mockups end user specification quantitative qualitative metric employing xr technology higher education institution concludes identification set specification drive development specific conceptual system design,successful system design may lead successfully implemented system paper demonstrates followed evaluation procedure creation system dedicated art school specifically focus meeting need art teacher art student visitor stakeholder system art teacher need able initiate art exhibition student ass art student create virtual exhibition art exhibition visitor immersive interactive experience evaluation part eu funded research project namely cream aim design develop end evaluate framework open source tool based virtual augmented mixed reality creation virtual exhibition art student present followed user centered design methodology followed reach first system design methodology begin literature review continues filtering review finding expert creation corresponding mockups evaluation mockups end user specification quantitative qualitative metric employing xr technology higher education institution concludes identification set specification drive development specific conceptual system designart computer_aided_instruction educational_institutions further_education user_centered_designart_exhibition_visitors art_exhibitions art_schools art_student_framework art_students art_teachers followed_evaluation_procedure followed_user centered_design_methodology specific_conceptual_system_design successful_system_design successfully_implemented_system virtual_exhibitions xr_exhibitions
406,System and Package-Level EMI Shielding Effectiveness Analysis for AR/VR Devices,"Zhang, H., Sarmast, S., Basu, S., & Codd, P. (2022). System and Package-Level EMI Shielding Effectiveness Analysis for AR/VR Devices. 2022 IEEE International Symposium on Electromagnetic Compatibility &amp; Signal/Power Integrity (EMCSI). https://doi.org/10.1109/emcsi39492.2022.10050244
",10.1109/EMCSI39492.2022.10050244,Conformal metal sputtering on package mold compound provides an alternative to meet package and system electromagnetic interference (EMI) and RF interference (RFI) requirements without sacrificing product form factors. However available coating thickness and material options on the outsourced semiconductor assembly and test (OSTA) market is limited and inadequate. An EM-circuit co-simulation method was developed for conformal shielding effectiveness (SE) analysis for augmented and virtual reality (AR/VR) applications. SE results of various coating thickness and materials are presented to show the custom needs for thicker Cu coating and high permeability coating materials.,B5230 Electromagnetic compatibility and interference;B1130B Computer-aided circuit analysis and design;B2560 Semiconductor devices;C6130V Virtual reality;C7410D Electronic engineering computing,AR-VR devices;coating thickness;conformal metal sputtering;conformal SE analysis;conformal shielding effectiveness analysis;EM-circuit co-simulation method;high permeability coating materials;OSTA;outsourced semiconductor assembly and test;package mold compound;package-level EMI shielding effectiveness analysis;system EMI shielding effectiveness analysis,augmented reality;circuit analysis computing;copper;electromagnetic interference;electromagnetic shielding;outsourcing;semiconductor devices;sputtered coatings,2022,Conference article (CA),2022 IEEE International Symposium on Electromagnetic Compatibility &amp; Signal/Power Integrity (EMCSI),"(1) Zhang, H.; (1) Sarmast, S.; (1) Basu, S.; (1) Codd, P.; ","(1) Reality Labs, United States; ",IEEE,-1,"[""circuit analysis computing"", ""copper"", ""electromagnetic interference"", ""electromagnetic shielding"", ""outsourcing"", ""semiconductor devices"", ""sputtered coatings""]","[""circuit analysis computing"", ""copper"", ""electromagnetic interference"", ""electromagnetic shielding"", ""outsourcing"", ""semiconductor devices"", ""sputtered coatings""]",circuit analysis computing;copper;electromagnetic interference;electromagnetic shielding;outsourcing;semiconductor devices;sputtered coatings,other;education;engineering;human resources,technology;other;business;industries,other;education;engineering;human resources,technology;other;business;industries,circuit_analysis_computing copper electromagnetic_interference electromagnetic_shielding outsourcing semiconductor_devices sputtered_coatings ar vr_devices coating_thickness conformal_metal_sputtering conformal_se_analysis conformal_shielding_effectiveness_analysis em circuit_co simulation_method high_permeability_coating_materials osta outsourced_semiconductor_assembly_and_test package_mold_compound package level_emi_shielding_effectiveness_analysis system_emi_shielding_effectiveness_analysis b5230_electromagnetic_compatibility_and_interference b1130b_computer aided_circuit_analysis_and_design b2560_semiconductor_devices c6130v_virtual_reality c7410d_electronic_engineering_computing other education engineering human_resources,circuit_analysis_computing copper electromagnetic_interference electromagnetic_shielding outsourcing semiconductor_devices sputtered_coatings,ar vr_devices coating_thickness conformal_metal_sputtering conformal_se_analysis conformal_shielding_effectiveness_analysis em circuit_co simulation_method high_permeability_coating_materials osta outsourced_semiconductor_assembly_and_test package_mold_compound package level_emi_shielding_effectiveness_analysis system_emi_shielding_effectiveness_analysis,conformal metal sputtering package mold compound provides alternative meet package system electromagnetic interference emi rf interference rfi requirement without sacrificing product form factor however available coating thickness material option outsourced semiconductor assembly test osta market limited inadequate em circuit co simulation method developed conformal shielding effectiveness se analysis augmented virtual reality ar vr application se result various coating thickness material presented show custom need thicker cu coating high permeability coating material,circuit_analysis_computing copper electromagnetic_interference electromagnetic_shielding outsourcing semiconductor_devices sputtered_coatings ar vr_devices coating_thickness conformal_metal_sputtering conformal_se_analysis conformal_shielding_effectiveness_analysis em circuit_co simulation_method high_permeability_coating_materials osta outsourced_semiconductor_assembly_and_test package_mold_compound package level_emi_shielding_effectiveness_analysis system_emi_shielding_effectiveness_analysis b5230_electromagnetic_compatibility_and_interference b1130b_computer aided_circuit_analysis_and_design b2560_semiconductor_devices c6130v_virtual_reality c7410d_electronic_engineering_computing other education engineering human_resources conformal metal sputtering package mold compound provides alternative meet package system electromagnetic interference emi rf interference rfi requirement without sacrificing product form factor however available coating thickness material option outsourced semiconductor assembly test osta market limited inadequate em circuit co simulation method developed conformal shielding effectiveness se analysis augmented virtual reality ar vr application se result various coating thickness material presented show custom need thicker cu coating high permeability coating material,conformal metal sputtering package mold compound provides alternative meet package system electromagnetic interference emi rf interference rfi requirement without sacrificing product form factor however available coating thickness material option outsourced semiconductor assembly test osta market limited inadequate em circuit co simulation method developed conformal shielding effectiveness se analysis augmented virtual reality ar vr application se result various coating thickness material presented show custom need thicker cu coating high permeability coating materialcircuit_analysis_computing copper electromagnetic_interference electromagnetic_shielding outsourcing semiconductor_devices sputtered_coatingsar vr_devices coating_thickness conformal_metal_sputtering conformal_se_analysis conformal_shielding_effectiveness_analysis em circuit_co simulation_method high_permeability_coating_materials osta outsourced_semiconductor_assembly_and_test package_mold_compound package level_emi_shielding_effectiveness_analysis system_emi_shielding_effectiveness_analysis
407,Interactive Parametric Design and Robotic Fabrication within Mixed Reality Environment,"Buyruk, Y., & Çağdaş, G. (2022). Interactive Parametric Design and Robotic Fabrication within Mixed Reality Environment. Applied Sciences, 12(24), 12797. https://doi.org/10.3390/app122412797
",10.3390/app122412797,"In this study, a method, in which parametric design and robotic fabrication are combined into one unified framework, and integrated within a mixed reality environment, where designers can interact with design and fabrication alternatives, and manage this process in collaboration with other designers, is proposed. To achieve this goal, the digital twin of both design and robotic fabrication steps was created within a mixed-reality environment. The proposed method was tested on a design product, which was defined with the shape-grammar method using parametric-modeling tools. In this framework, designers can interact with both design and robotic-fabrication parameters, and subsequent steps are generated instantly. Robotic fabrication can continue uninterrupted with human-robot collaboration. This study contributes to improving design and fabrication possibilities such as mass-customization, and shortens the process from design to production. The user experience and augmented spatial feedback provided by mixed reality are richer than the interaction with the computer screen. Since the whole process from parametric design to robotic fabrication can be controlled by parameters with hand gestures, the perception of reality is richer. The digital twin of parametric design and robotic fabrication is superimposed as holographic content by adding it on top of real-world images. Designers can interact with both design and fabrication processes both physically and virtually and can collaborate with other designers.",C6130V Virtual reality;C5260B Computer vision and image processing techniques;C6180R Human-robot interaction;C7480 Production engineering computing;E0410D Industrial applications of IT,design product;fabrication alternatives;fabrication possibilities;fabrication processes;human-robot collaboration;interactive parametric design;mixed reality environment;mixed-reality environment;robotic fabrication steps;robotic-fabrication parameters,augmented reality;digital twins;gesture recognition;grammars;human-robot interaction;production engineering computing;virtual reality,2022,Journal article (JA),Appl. Sci. (Switzerland),"(1) Buyruk, Y.; (1) C&#807;ag&#774;das&#807;, G.; ","(1) Istanbul Technical University, Graduate School, Turkey; ",MDPI,-1,"[""digital twins"", ""gesture recognition"", ""grammars"", ""human-robot interaction"", ""production engineering computing""]","[""digital twins"", ""gesture recognition"", ""grammars"", ""human-robot interaction"", ""production engineering computing""]",digital twins;gesture recognition;grammars;human-robot interaction;production engineering computing,other;aviation and aerospace;robotics;input;human factors;engineering;smart cities;standards;manufacturing,other;end users and user experience;industries;use cases;standards;technology,other;aviation and aerospace;robotics;input;human factors;engineering;smart cities;standards;manufacturing,other;end users and user experience;industries;use cases;standards;technology,digital_twins gesture_recognition grammars human robot_interaction production_engineering_computing design_product fabrication_alternatives fabrication_possibilities fabrication_processes human robot_collaboration interactive_parametric_design mixed_reality_environment mixed reality_environment robotic_fabrication_steps robotic fabrication_parameters c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180r_human robot_interaction c7480_production_engineering_computing e0410d_industrial_applications_of_it other aviation_and_aerospace robotics input human_factors engineering smart_cities standards manufacturing,digital_twins gesture_recognition grammars human robot_interaction production_engineering_computing,design_product fabrication_alternatives fabrication_possibilities fabrication_processes human robot_collaboration interactive_parametric_design mixed_reality_environment mixed reality_environment robotic_fabrication_steps robotic fabrication_parameters,study method parametric design robotic fabrication combined one unified framework integrated within mixed reality environment designer interact design fabrication alternative manage process collaboration designer proposed achieve goal digital twin design robotic fabrication step created within mixed reality environment proposed method tested design product defined shape grammar method using parametric modeling tool framework designer interact design robotic fabrication parameter subsequent step generated instantly robotic fabrication continue uninterrupted human robot collaboration study contributes improving design fabrication possibility mass customization shortens process design production user experience augmented spatial feedback provided mixed reality richer interaction computer screen since whole process parametric design robotic fabrication controlled parameter hand gesture perception reality richer digital twin parametric design robotic fabrication superimposed holographic content adding top real world image designer interact design fabrication process physically virtually collaborate designer,digital_twins gesture_recognition grammars human robot_interaction production_engineering_computing design_product fabrication_alternatives fabrication_possibilities fabrication_processes human robot_collaboration interactive_parametric_design mixed_reality_environment mixed reality_environment robotic_fabrication_steps robotic fabrication_parameters c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c6180r_human robot_interaction c7480_production_engineering_computing e0410d_industrial_applications_of_it other aviation_and_aerospace robotics input human_factors engineering smart_cities standards manufacturing study method parametric design robotic fabrication combined one unified framework integrated within mixed reality environment designer interact design fabrication alternative manage process collaboration designer proposed achieve goal digital twin design robotic fabrication step created within mixed reality environment proposed method tested design product defined shape grammar method using parametric modeling tool framework designer interact design robotic fabrication parameter subsequent step generated instantly robotic fabrication continue uninterrupted human robot collaboration study contributes improving design fabrication possibility mass customization shortens process design production user experience augmented spatial feedback provided mixed reality richer interaction computer screen since whole process parametric design robotic fabrication controlled parameter hand gesture perception reality richer digital twin parametric design robotic fabrication superimposed holographic content adding top real world image designer interact design fabrication process physically virtually collaborate designer,study method parametric design robotic fabrication combined one unified framework integrated within mixed reality environment designer interact design fabrication alternative manage process collaboration designer proposed achieve goal digital twin design robotic fabrication step created within mixed reality environment proposed method tested design product defined shape grammar method using parametric modeling tool framework designer interact design robotic fabrication parameter subsequent step generated instantly robotic fabrication continue uninterrupted human robot collaboration study contributes improving design fabrication possibility mass customization shortens process design production user experience augmented spatial feedback provided mixed reality richer interaction computer screen since whole process parametric design robotic fabrication controlled parameter hand gesture perception reality richer digital twin parametric design robotic fabrication superimposed holographic content adding top real world image designer interact design fabrication process physically virtually collaborate designerdigital_twins gesture_recognition grammars human robot_interaction production_engineering_computingdesign_product fabrication_alternatives fabrication_possibilities fabrication_processes human robot_collaboration interactive_parametric_design mixed_reality_environment mixed reality_environment robotic_fabrication_steps robotic fabrication_parameters
408,Interactive application for training orthopedic residents to perform knee arthroscopy procedure,"Nunez De Villavicencio Castineyra, J. A., Rodriguez Chaparro, S., Bautista Rojas, L., & Bautista Rozo, L. (2022). Interactive application for training orthopedic residents to perform knee arthroscopy procedure. 9th Mexican International Conference on Human-Computer Interaction. https://doi.org/10.1145/3565494.3565528
",10.1145/3565494.3565528,"A knee arthroscopy exploration is a minimally invasive surgical procedure; but training residents to perform it is complex and expensive. In addition, years of training are required to perform the procedure correctly and safely. An interactive Mixed Reality application was developed with the purpose of providing an alternative for the procedures training, which seeks to create a practice environment for training surgeons while promoting safe learning. Hololens 2 was used to project holograms of the procedure scenario, and a set of optitrack tracking cameras were placed to track the instruments and simulate the operation. In the design process, a CTA (cognitive task analysis) was carried out, which functions as a fundamental guide to establishing a step-by-step procedure and finding the most significant difficulties when executing it. In the interaction with the application, the user must complete several tasks and simulate an arthroscopic knee exploration procedure within a virtual scenario. Tests were conducted with medical students, general practitioners, and orthopedic experts to test the application's performance as an educational tool. The results showed that the application is a valuable tool to improve the learning of this type of procedure,providing a suitable practice environment for skill improvement.",C6130V Virtual reality;C7330 Biology and medical computing;C7810C Computer-aided instruction,"arthroscopic knee exploration procedure;cognitive task analysis;CTA;design process;hololens 2;interactive application;interactive Mixed Reality application;knee arthroscopy exploration;knee arthroscopy procedure;minimally invasive surgical procedure;optitrack tracking cameras;orthopedic experts;procedure scenario;procedure,providing;procedures training;safe learning;step-by-step procedure;suitable practice environment;training orthopedic residents;training residents;training surgeons;virtual scenario",augmented reality;biomedical education;cognition;computer based training;medical computing;orthopaedics;surgery;task analysis;virtual reality,2022,Conference article (CA),MexIHC '22: 9th Mexican International Conference on Human-Computer Interaction,"(1) Nunez de villavicencio castineyra, J.A.; (1) Rodriguez chaparro, S.; (1) Bautista rojas, L.; (1) Bautista rozo, L.; ","(1) Universidad Industrial de Santander, Colombia; ",ACM,-1,"[""biomedical education"", ""cognition"", ""computer based training"", ""medical computing"", ""orthopedics"", ""surgery"", ""task analysis""]","[""biomedical education"", ""cognition"", ""computer based training"", ""medical computing"", ""orthopedics"", ""surgery"", ""task analysis""]",biomedical education;cognition;computer based training;medical computing;orthopedics;surgery;task analysis,education;farming and natural science;medical;training;human factors,end users and user experience;use cases;industries,education;farming and natural science;medical;training;human factors,end users and user experience;use cases;industries,biomedical_education cognition computer_based_training medical_computing orthopedics surgery task_analysis arthroscopic_knee_exploration_procedure cognitive_task_analysis cta design_process hololens_2 interactive_application interactive_mixed_reality_application knee_arthroscopy_exploration knee_arthroscopy_procedure minimally_invasive_surgical_procedure optitrack_tracking_cameras orthopedic_experts procedure_scenario procedure providing procedures_training safe_learning step by step_procedure suitable_practice_environment training_orthopedic_residents training_residents training_surgeons virtual_scenario c6130v_virtual_reality c7330_biology_and_medical_computing c7810c_computer aided_instruction education farming_and_natural_science medical training human_factors,biomedical_education cognition computer_based_training medical_computing orthopedics surgery task_analysis,arthroscopic_knee_exploration_procedure cognitive_task_analysis cta design_process hololens_2 interactive_application interactive_mixed_reality_application knee_arthroscopy_exploration knee_arthroscopy_procedure minimally_invasive_surgical_procedure optitrack_tracking_cameras orthopedic_experts procedure_scenario procedure providing procedures_training safe_learning step by step_procedure suitable_practice_environment training_orthopedic_residents training_residents training_surgeons virtual_scenario,knee arthroscopy exploration minimally invasive surgical procedure training resident perform complex expensive addition year training required perform procedure correctly safely interactive mixed reality application developed purpose providing alternative procedure training seek create practice environment training surgeon promoting safe learning hololens 2 used project hologram procedure scenario set optitrack tracking camera placed track instrument simulate operation design process cta cognitive task analysis carried function fundamental guide establishing step step procedure finding significant difficulty executing interaction application user must complete several task simulate arthroscopic knee exploration procedure within virtual scenario test conducted medical student general practitioner orthopedic expert test application performance educational tool result showed application valuable tool improve learning type procedure providing suitable practice environment skill improvement,biomedical_education cognition computer_based_training medical_computing orthopedics surgery task_analysis arthroscopic_knee_exploration_procedure cognitive_task_analysis cta design_process hololens_2 interactive_application interactive_mixed_reality_application knee_arthroscopy_exploration knee_arthroscopy_procedure minimally_invasive_surgical_procedure optitrack_tracking_cameras orthopedic_experts procedure_scenario procedure providing procedures_training safe_learning step by step_procedure suitable_practice_environment training_orthopedic_residents training_residents training_surgeons virtual_scenario c6130v_virtual_reality c7330_biology_and_medical_computing c7810c_computer aided_instruction education farming_and_natural_science medical training human_factors knee arthroscopy exploration minimally invasive surgical procedure training resident perform complex expensive addition year training required perform procedure correctly safely interactive mixed reality application developed purpose providing alternative procedure training seek create practice environment training surgeon promoting safe learning hololens 2 used project hologram procedure scenario set optitrack tracking camera placed track instrument simulate operation design process cta cognitive task analysis carried function fundamental guide establishing step step procedure finding significant difficulty executing interaction application user must complete several task simulate arthroscopic knee exploration procedure within virtual scenario test conducted medical student general practitioner orthopedic expert test application performance educational tool result showed application valuable tool improve learning type procedure providing suitable practice environment skill improvement,knee arthroscopy exploration minimally invasive surgical procedure training resident perform complex expensive addition year training required perform procedure correctly safely interactive mixed reality application developed purpose providing alternative procedure training seek create practice environment training surgeon promoting safe learning hololens 2 used project hologram procedure scenario set optitrack tracking camera placed track instrument simulate operation design process cta cognitive task analysis carried function fundamental guide establishing step step procedure finding significant difficulty executing interaction application user must complete several task simulate arthroscopic knee exploration procedure within virtual scenario test conducted medical student general practitioner orthopedic expert test application performance educational tool result showed application valuable tool improve learning type procedure providing suitable practice environment skill improvementbiomedical_education cognition computer_based_training medical_computing orthopedics surgery task_analysisarthroscopic_knee_exploration_procedure cognitive_task_analysis cta design_process hololens_2 interactive_application interactive_mixed_reality_application knee_arthroscopy_exploration knee_arthroscopy_procedure minimally_invasive_surgical_procedure optitrack_tracking_cameras orthopedic_experts procedure_scenario procedure providing procedures_training safe_learning step by step_procedure suitable_practice_environment training_orthopedic_residents training_residents training_surgeons virtual_scenario
409,Reach Prediction using Finger Motion Dynamics,"Valkov, D., Kockwelp, P., Daiber, F., & Krüger, A. (2023). Reach Prediction using Finger Motion Dynamics. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585773
",10.1145/3544549.3585773,"The ability to predict the object the user intends to grasp or to recognize the one she is already holding offers essential contextual information and may help to leverage the effects of point-to-point latency in interactive environments. This paper investigates the feasibility and accuracy of recognizing un-instrumented objects based on hand kinematics during reach-to-grasp and transport actions. In a data collection study, we recorded the hand motions of 16 participants while reaching out to grasp and then moving real and synthetic objects. Our results demonstrate that even a simple LSTM network can predict the time point at which the user grasps an object with 23 ms precision and the current distance to it with a precision better than 1 cm. The target's size can be determined in advance with an accuracy better than 97%. Our results have implications for designing adaptive and fine-grained interactive user interfaces in ubiquitous and mixed-reality environments.","C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing;C6264 Neural nets",adaptive interactive user interfaces;contextual information;data collection;fine-grained interactive user interfaces;finger motion dynamics;hand kinematics;hand motions;interactive environments;LSTM network;mixed-reality environments;point-to-point latency;reach prediction;reach-to-grasp actions;time point;transport actions;ubiquitous environments;un-instrumented object recognition,augmented reality;data acquisition;human computer interaction;interactive systems;object recognition;recurrent neural nets;ubiquitous computing;user interfaces,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Valkov, D.; (2) Kockwelp, P.; (3) Daiber, F.; (3) Kru&#776;ger, A.; ","(1) Saarland University, Germany; (2) University of Mu&#776;nster, Computer Science Department, Germany; (3) Deutsches Forschungszentrum fur Kunstliche Intelligenz GmbH, Germany; ",ACM,-1,"[""data acquisition"", ""human computer interaction"", ""interactive systems"", ""object recognition"", ""recurrent neural nets"", ""ubiquitous computing"", ""user interfaces""]","[""data acquisition"", ""human computer interaction"", ""interactive systems"", ""object recognition"", ""recurrent neural nets"", ""ubiquitous computing"", ""user interfaces""]",data acquisition;human computer interaction;interactive systems;object recognition;recurrent neural nets;ubiquitous computing;user interfaces,computer vision;education;input;human factors;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,computer vision;education;input;human factors;human-computer interaction;artificial intelligence,technology;end users and user experience;industries,data_acquisition human_computer_interaction interactive_systems object_recognition recurrent_neural_nets ubiquitous_computing user_interfaces adaptive_interactive_user_interfaces contextual_information data_collection fine grained_interactive_user_interfaces finger_motion_dynamics hand_kinematics hand_motions interactive_environments lstm_network mixed reality_environments point to point_latency reach_prediction reach to grasp_actions time_point transport_actions ubiquitous_environments un instrumented_object_recognition c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision education input human_factors human computer_interaction artificial_intelligence,data_acquisition human_computer_interaction interactive_systems object_recognition recurrent_neural_nets ubiquitous_computing user_interfaces,adaptive_interactive_user_interfaces contextual_information data_collection fine grained_interactive_user_interfaces finger_motion_dynamics hand_kinematics hand_motions interactive_environments lstm_network mixed reality_environments point to point_latency reach_prediction reach to grasp_actions time_point transport_actions ubiquitous_environments un instrumented_object_recognition,ability predict object user intends grasp recognize one already holding offer essential contextual information may help leverage effect point point latency interactive environment paper investigates feasibility accuracy recognizing un instrumented object based hand kinematics reach grasp transport action data collection study recorded hand motion 16 participant reaching grasp moving real synthetic object result demonstrate even simple lstm network predict time point user grasp object 23 m precision current distance precision better 1 cm target size determined advance accuracy better 97 result implication designing adaptive fine grained interactive user interface ubiquitous mixed reality environment,data_acquisition human_computer_interaction interactive_systems object_recognition recurrent_neural_nets ubiquitous_computing user_interfaces adaptive_interactive_user_interfaces contextual_information data_collection fine grained_interactive_user_interfaces finger_motion_dynamics hand_kinematics hand_motions interactive_environments lstm_network mixed reality_environments point to point_latency reach_prediction reach to grasp_actions time_point transport_actions ubiquitous_environments un instrumented_object_recognition c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c6264_neural_nets computer_vision education input human_factors human computer_interaction artificial_intelligence ability predict object user intends grasp recognize one already holding offer essential contextual information may help leverage effect point point latency interactive environment paper investigates feasibility accuracy recognizing un instrumented object based hand kinematics reach grasp transport action data collection study recorded hand motion 16 participant reaching grasp moving real synthetic object result demonstrate even simple lstm network predict time point user grasp object 23 m precision current distance precision better 1 cm target size determined advance accuracy better 97 result implication designing adaptive fine grained interactive user interface ubiquitous mixed reality environment,ability predict object user intends grasp recognize one already holding offer essential contextual information may help leverage effect point point latency interactive environment paper investigates feasibility accuracy recognizing un instrumented object based hand kinematics reach grasp transport action data collection study recorded hand motion 16 participant reaching grasp moving real synthetic object result demonstrate even simple lstm network predict time point user grasp object 23 m precision current distance precision better 1 cm target size determined advance accuracy better 97 result implication designing adaptive fine grained interactive user interface ubiquitous mixed reality environmentdata_acquisition human_computer_interaction interactive_systems object_recognition recurrent_neural_nets ubiquitous_computing user_interfacesadaptive_interactive_user_interfaces contextual_information data_collection fine grained_interactive_user_interfaces finger_motion_dynamics hand_kinematics hand_motions interactive_environments lstm_network mixed reality_environments point to point_latency reach_prediction reach to grasp_actions time_point transport_actions ubiquitous_environments un instrumented_object_recognition
410,BlocklyXR: An Interactive Extended Reality Toolkit for Digital Storytelling,"Jung, K., Nguyen, V. T., & Lee, J. (2021). BlocklyXR: An Interactive Extended Reality Toolkit for Digital Storytelling. Applied Sciences, 11(3), 1073. https://doi.org/10.3390/app11031073
",10.3390/app11031073,"Traditional in-app virtual reality (VR)/augmented reality (AR) applications pose a challenge of reaching users due to their dependency on operating systems (Android, iOS). Besides, it is difficult for general users to create their own VR/AR applications and foster their creative ideas without advanced programming skills. This paper addresses these issues by proposing an interactive extended reality toolkit, named BlocklyXR. The objective of this research is to provide general users with a visual programming environment to build an extended reality application for digital storytelling. The contextual design was generated from real-world map data retrieved from Mapbox GL. ThreeJS was used for setting up, rendering 3D environments, and controlling animations. A block-based programming approach was adapted to let users design their own story. The capability of BlocklyXR was illustrated with a use case where users were able to replicate the existing PalmitoAR utilizing the block-based authoring toolkit with fewer efforts in programming. The technology acceptance model was used to evaluate the adoption and use of the interactive extended reality toolkit. The findings showed that visual design and task technology fit had significantly positive effects on user motivation factors (perceived ease of use and perceived usefulness). In turn, perceived usefulness had statistically significant and positive effects on intention to use, while there was no significant impact of perceived ease of use on intention to use. Study implications and future research directions are discussed.","C6130V Virtual reality;C6130B Graphics techniques;C6190V Mobile, ubiquitous and pervasive computing;C7810C Computer-aided instruction;C7830D Computer games",advanced programming skills;block-based programming approach;BlocklyXR;digital storytelling;extended reality application;general users;interactive extended reality toolkit;user motivation factors;visual programming environment,augmented reality;computer aided instruction;computer games;cultural aspects;data visualisation;human factors;mobile computing;rendering (computer graphics);virtual reality;visual programming,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Jung, K.; (2) Nguyen, V.T.; (1) Lee, J.; ","(1) Texas Tech University, Department of Educational Psychology and Leadership, Lubbock, TX 79409, United States; (2) University of Information and Communication Technology, Department of Information Technology, Viet Nam; ",MDPI,-1,"[""computer aided instruction"", ""computer games"", ""cultural aspects"", ""data visualization"", ""human factors"", ""mobile computing"", ""rendering"", ""visual programming""]","[""computer aided instruction"", ""computer games"", ""cultural aspects"", ""data visualization"", ""human factors"", ""mobile computing"", ""rendering"", ""visual programming""]",computer aided instruction;computer games;cultural aspects;data visualization;human factors;mobile computing;rendering;visual programming,graphics;liberal arts;training;human factors;policy;telecommunication;developers;data,business;industries;end users and user experience;use cases;technology,graphics;liberal arts;training;human factors;policy;telecommunication;developers;data,business;industries;end users and user experience;use cases;technology,computer_aided_instruction computer_games cultural_aspects data_visualization human_factors mobile_computing rendering visual_programming advanced_programming_skills block based_programming_approach blocklyxr digital_storytelling extended_reality_application general_users interactive_extended_reality_toolkit user_motivation_factors visual_programming_environment c6130v_virtual_reality c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7830d_computer_games graphics liberal_arts training human_factors policy telecommunication developers data,computer_aided_instruction computer_games cultural_aspects data_visualization human_factors mobile_computing rendering visual_programming,advanced_programming_skills block based_programming_approach blocklyxr digital_storytelling extended_reality_application general_users interactive_extended_reality_toolkit user_motivation_factors visual_programming_environment,traditional app virtual reality vr augmented reality ar application pose challenge reaching user due dependency operating system android io besides difficult general user create vr ar application foster creative idea without advanced programming skill paper address issue proposing interactive extended reality toolkit named blocklyxr objective research provide general user visual programming environment build extended reality application digital storytelling contextual design generated real world map data retrieved mapbox gl threejs used setting rendering 3d environment controlling animation block based programming approach adapted let user design story capability blocklyxr illustrated use case user able replicate existing palmitoar utilizing block based authoring toolkit fewer effort programming technology acceptance model used evaluate adoption use interactive extended reality toolkit finding showed visual design task technology fit significantly positive effect user motivation factor perceived ease use perceived usefulness turn perceived usefulness statistically significant positive effect intention use significant impact perceived ease use intention use study implication future research direction discussed,computer_aided_instruction computer_games cultural_aspects data_visualization human_factors mobile_computing rendering visual_programming advanced_programming_skills block based_programming_approach blocklyxr digital_storytelling extended_reality_application general_users interactive_extended_reality_toolkit user_motivation_factors visual_programming_environment c6130v_virtual_reality c6130b_graphics_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7810c_computer aided_instruction c7830d_computer_games graphics liberal_arts training human_factors policy telecommunication developers data traditional app virtual reality vr augmented reality ar application pose challenge reaching user due dependency operating system android io besides difficult general user create vr ar application foster creative idea without advanced programming skill paper address issue proposing interactive extended reality toolkit named blocklyxr objective research provide general user visual programming environment build extended reality application digital storytelling contextual design generated real world map data retrieved mapbox gl threejs used setting rendering 3d environment controlling animation block based programming approach adapted let user design story capability blocklyxr illustrated use case user able replicate existing palmitoar utilizing block based authoring toolkit fewer effort programming technology acceptance model used evaluate adoption use interactive extended reality toolkit finding showed visual design task technology fit significantly positive effect user motivation factor perceived ease use perceived usefulness turn perceived usefulness statistically significant positive effect intention use significant impact perceived ease use intention use study implication future research direction discussed,traditional app virtual reality vr augmented reality ar application pose challenge reaching user due dependency operating system android io besides difficult general user create vr ar application foster creative idea without advanced programming skill paper address issue proposing interactive extended reality toolkit named blocklyxr objective research provide general user visual programming environment build extended reality application digital storytelling contextual design generated real world map data retrieved mapbox gl threejs used setting rendering 3d environment controlling animation block based programming approach adapted let user design story capability blocklyxr illustrated use case user able replicate existing palmitoar utilizing block based authoring toolkit fewer effort programming technology acceptance model used evaluate adoption use interactive extended reality toolkit finding showed visual design task technology fit significantly positive effect user motivation factor perceived ease use perceived usefulness turn perceived usefulness statistically significant positive effect intention use significant impact perceived ease use intention use study implication future research direction discussedcomputer_aided_instruction computer_games cultural_aspects data_visualization human_factors mobile_computing rendering visual_programmingadvanced_programming_skills block based_programming_approach blocklyxr digital_storytelling extended_reality_application general_users interactive_extended_reality_toolkit user_motivation_factors visual_programming_environment
411,Industrial Metaverse: Supporting remote maintenance with avatars and digital twins in collaborative XR environments,"Oppermann, L., Buchholz, F., & Uzun, Y. (2023). Industrial Metaverse. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585835
",10.1145/3544549.3585835,"We present a 5G mixed reality toolbox that supports hands-free remote assistance in industrial settings. It provides mixed reality and virtual reality views for on-site and office workers linked via a shared digital space. Working on actual machines in a real production line, our system uses the actual CAD-data of those machines to provide for a realistic prototyping-environment. We focus on data-scarcity with cloud-services to protect intellectual property, while embracing the possibilities offered by new technology, such as remote rendering over wireless networks. The presented prototype exhibits several key characteristics of an industrial metaverse application.",C6130V Virtual reality;C6130B Graphics techniques;C7480 Production engineering computing;E0410D Industrial applications of IT,actual CAD-data;actual machines;avatars;collaborative XR environments;data-scarcity;digital twins;hands-free remote assistance;industrial metaverse application;industrial settings;mixed reality;office workers;on-site;production line;prototype exhibits several key characteristics;realistic prototyping-environment;remote maintenance;remote rendering;shared digital space;virtual reality views,augmented reality;avatars;CAD;cloud computing;digital twins;industrial property;production engineering computing;rendering (computer graphics);virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Oppermann, L.; (1) Buchholz, F.; (1) Uzun, Y.; ","(1) Fraunhofer Institute for Applied Information Technology, Germany; ",ACM,-1,"[""avatars"", ""cad"", ""cloud computing"", ""digital twins"", ""industrial property"", ""production engineering computing"", ""rendering""]","[""avatars"", ""cad"", ""cloud computing"", ""digital twins"", ""industrial property"", ""production engineering computing"", ""rendering""]",avatars;cad;cloud computing;digital twins;industrial property;production engineering computing;rendering,other;graphics;presence;engineering;smart cities;human-computer interaction;manufacturing;networks,other;industries;end users and user experience;use cases;technology,other;graphics;presence;engineering;smart cities;human-computer interaction;manufacturing;networks,other;industries;end users and user experience;use cases;technology,avatars cad cloud_computing digital_twins industrial_property production_engineering_computing rendering actual_cad data actual_machines avatars collaborative_xr_environments data scarcity digital_twins hands free_remote_assistance industrial_metaverse_application industrial_settings mixed_reality office_workers on site production_line prototype_exhibits_several_key_characteristics realistic_prototyping environment remote_maintenance remote_rendering shared_digital_space virtual_reality_views c6130v_virtual_reality c6130b_graphics_techniques c7480_production_engineering_computing e0410d_industrial_applications_of_it other graphics presence engineering smart_cities human computer_interaction manufacturing networks,avatars cad cloud_computing digital_twins industrial_property production_engineering_computing rendering,actual_cad data actual_machines avatars collaborative_xr_environments data scarcity digital_twins hands free_remote_assistance industrial_metaverse_application industrial_settings mixed_reality office_workers on site production_line prototype_exhibits_several_key_characteristics realistic_prototyping environment remote_maintenance remote_rendering shared_digital_space virtual_reality_views,present 5g mixed reality toolbox support hand free remote assistance industrial setting provides mixed reality virtual reality view site office worker linked via shared digital space working actual machine real production line system us actual cad data machine provide realistic prototyping environment focus data scarcity cloud service protect intellectual property embracing possibility offered new technology remote rendering wireless network presented prototype exhibit several key characteristic industrial metaverse application,avatars cad cloud_computing digital_twins industrial_property production_engineering_computing rendering actual_cad data actual_machines avatars collaborative_xr_environments data scarcity digital_twins hands free_remote_assistance industrial_metaverse_application industrial_settings mixed_reality office_workers on site production_line prototype_exhibits_several_key_characteristics realistic_prototyping environment remote_maintenance remote_rendering shared_digital_space virtual_reality_views c6130v_virtual_reality c6130b_graphics_techniques c7480_production_engineering_computing e0410d_industrial_applications_of_it other graphics presence engineering smart_cities human computer_interaction manufacturing networks present 5g mixed reality toolbox support hand free remote assistance industrial setting provides mixed reality virtual reality view site office worker linked via shared digital space working actual machine real production line system us actual cad data machine provide realistic prototyping environment focus data scarcity cloud service protect intellectual property embracing possibility offered new technology remote rendering wireless network presented prototype exhibit several key characteristic industrial metaverse application,present 5g mixed reality toolbox support hand free remote assistance industrial setting provides mixed reality virtual reality view site office worker linked via shared digital space working actual machine real production line system us actual cad data machine provide realistic prototyping environment focus data scarcity cloud service protect intellectual property embracing possibility offered new technology remote rendering wireless network presented prototype exhibit several key characteristic industrial metaverse applicationavatars cad cloud_computing digital_twins industrial_property production_engineering_computing renderingactual_cad data actual_machines avatars collaborative_xr_environments data scarcity digital_twins hands free_remote_assistance industrial_metaverse_application industrial_settings mixed_reality office_workers on site production_line prototype_exhibits_several_key_characteristics realistic_prototyping environment remote_maintenance remote_rendering shared_digital_space virtual_reality_views
412,Development of a mixed reality method for underground pipelines in digital mechanics experiments,"Li, W., Wang, Y., Yang, H., Ye, Z., Li, P., Aron Liu, Y., & Wang, L. (2023). Development of a mixed reality method for underground pipelines in digital mechanics experiments. Tunnelling and Underground Space Technology, 132, 104833. https://doi.org/10.1016/j.tust.2022.104833
",10.1016/j.tust.2022.104833,"The underground pipeline network (UPN) is an essential underground structure and infrastructure. Its full-cycle digital twin system is an important part of the smart city. However, traditional information transmission between humans and computers lacks understanding and interaction in the digital twin experiments. From the perspective of perception, a space interaction system based on mixed reality (MR) technology is used to solve the problem of interaction for traditional mechanical experiments. Firstly, during the design phase, Building Information Modeling (BIM) is used to integrate models and information storage, including physical geometry data and material information. Secondly, the analytical algorithm is constructed for sensors by data filtering and material mechanics theory; based on sensors communication, C#/C++, and Socket to develop human-computer interactive methods through Game Engines and Mixed Reality Toolkits (MRTK). Finally, based on comparing the mechanical parameters, the testing of digital pipeline experiments by spatial anchors. Twenty-four experimenters are selected to test this method. The advantages and prospects of spatial interaction with MR are summarized through qualitative and quantitative analysis. This study realizes the data perception of the UPN and maps it to the real environment, which can provide a technical reference for engineering digital experiments. All rights reserved Elsevier.",C7440 Civil and mechanical engineering computing;C6130V Virtual reality;C7485 Smart cities;E0410D Industrial applications of IT;E0410H Mechanical engineering applications of IT;E1400 Design;E2110B Building structures;E3030 Construction industry,analytical algorithm;building information modeling;data filtering;data perception;design phase;digital mechanics experiments;digital pipeline experiments;digital twin experiments;engineering digital experiments;human-computer interactive methods;information storage;material information;material mechanics theory;mechanical parameters;mixed reality method;physical geometry data;sensors communication;smart city;space interaction system;spatial interaction;traditional mechanical experiments;underground pipeline network;underground pipelines;underground structure;UPN,augmented reality;building information modelling;construction industry;design engineering;digital twins;interactive systems;pipelines;production engineering computing;smart cities,2023,Journal article (JA),Tunn. Undergr. Space Technol. Inc. Trenchless Technol. Res. (Netherlands),"(1) Li, W.; (1) Wang, Y.; (1) Yang, H.; (1) Ye, Z.; (1) Li, P.; (2) Aron liu, Y.; (3) Wang, L.; ","(1) University of Science and Technology Beijing, National Center for Materials Service Safety, China; (2) University of Chinese Academy of Sciences, Institute of Applied Mathematics, China; (3) University of Georgia, School of Environmental, Civil, Agricultural and Mechanical Engineering, Athens, GA 30602, United States; ",Elsevier B.V.,-1,"[""building information modelling"", ""construction industry"", ""design engineering"", ""digital twins"", ""interactive systems"", ""pipelines"", ""production engineering computing"", ""smart cities""]","[""building information modelling"", ""construction industry"", ""design engineering"", ""digital twins"", ""interactive systems"", ""pipelines"", ""production engineering computing"", ""smart cities""]",building information modelling;construction industry;design engineering;digital twins;interactive systems;pipelines;production engineering computing;smart cities,construction;education;other;input;liberal arts;engineering;smart cities;human-computer interaction;manufacturing;oil and gas,other;end users and user experience;industries;use cases;technology,construction;education;other;input;liberal arts;engineering;smart cities;human-computer interaction;manufacturing;oil and gas,other;end users and user experience;industries;use cases;technology,building_information_modelling construction_industry design_engineering digital_twins interactive_systems pipelines production_engineering_computing smart_cities analytical_algorithm building_information_modeling data_filtering data_perception design_phase digital_mechanics_experiments digital_pipeline_experiments digital_twin_experiments engineering_digital_experiments human computer_interactive_methods information_storage material_information material_mechanics_theory mechanical_parameters mixed_reality_method physical_geometry_data sensors_communication smart_city space_interaction_system spatial_interaction traditional_mechanical_experiments underground_pipeline_network underground_pipelines underground_structure upn c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality c7485_smart_cities e0410d_industrial_applications_of_it e0410h_mechanical_engineering_applications_of_it e1400_design e2110b_building_structures e3030_construction_industry construction education other input liberal_arts engineering smart_cities human computer_interaction manufacturing oil_and_gas,building_information_modelling construction_industry design_engineering digital_twins interactive_systems pipelines production_engineering_computing smart_cities,analytical_algorithm building_information_modeling data_filtering data_perception design_phase digital_mechanics_experiments digital_pipeline_experiments digital_twin_experiments engineering_digital_experiments human computer_interactive_methods information_storage material_information material_mechanics_theory mechanical_parameters mixed_reality_method physical_geometry_data sensors_communication smart_city space_interaction_system spatial_interaction traditional_mechanical_experiments underground_pipeline_network underground_pipelines underground_structure upn,underground pipeline network upn essential underground structure infrastructure full cycle digital twin system important part smart city however traditional information transmission human computer lack understanding interaction digital twin experiment perspective perception space interaction system based mixed reality mr technology used solve problem interaction traditional mechanical experiment firstly design phase building information modeling bim used integrate model information storage including physical geometry data material information secondly analytical algorithm constructed sensor data filtering material mechanic theory based sensor communication c c socket develop human computer interactive method game engine mixed reality toolkits mrtk finally based comparing mechanical parameter testing digital pipeline experiment spatial anchor twenty four experimenter selected test method advantage prospect spatial interaction mr summarized qualitative quantitative analysis study realizes data perception upn map real environment provide technical reference engineering digital experiment right reserved elsevier,building_information_modelling construction_industry design_engineering digital_twins interactive_systems pipelines production_engineering_computing smart_cities analytical_algorithm building_information_modeling data_filtering data_perception design_phase digital_mechanics_experiments digital_pipeline_experiments digital_twin_experiments engineering_digital_experiments human computer_interactive_methods information_storage material_information material_mechanics_theory mechanical_parameters mixed_reality_method physical_geometry_data sensors_communication smart_city space_interaction_system spatial_interaction traditional_mechanical_experiments underground_pipeline_network underground_pipelines underground_structure upn c7440_civil_and_mechanical_engineering_computing c6130v_virtual_reality c7485_smart_cities e0410d_industrial_applications_of_it e0410h_mechanical_engineering_applications_of_it e1400_design e2110b_building_structures e3030_construction_industry construction education other input liberal_arts engineering smart_cities human computer_interaction manufacturing oil_and_gas underground pipeline network upn essential underground structure infrastructure full cycle digital twin system important part smart city however traditional information transmission human computer lack understanding interaction digital twin experiment perspective perception space interaction system based mixed reality mr technology used solve problem interaction traditional mechanical experiment firstly design phase building information modeling bim used integrate model information storage including physical geometry data material information secondly analytical algorithm constructed sensor data filtering material mechanic theory based sensor communication c c socket develop human computer interactive method game engine mixed reality toolkits mrtk finally based comparing mechanical parameter testing digital pipeline experiment spatial anchor twenty four experimenter selected test method advantage prospect spatial interaction mr summarized qualitative quantitative analysis study realizes data perception upn map real environment provide technical reference engineering digital experiment right reserved elsevier,underground pipeline network upn essential underground structure infrastructure full cycle digital twin system important part smart city however traditional information transmission human computer lack understanding interaction digital twin experiment perspective perception space interaction system based mixed reality mr technology used solve problem interaction traditional mechanical experiment firstly design phase building information modeling bim used integrate model information storage including physical geometry data material information secondly analytical algorithm constructed sensor data filtering material mechanic theory based sensor communication c c socket develop human computer interactive method game engine mixed reality toolkits mrtk finally based comparing mechanical parameter testing digital pipeline experiment spatial anchor twenty four experimenter selected test method advantage prospect spatial interaction mr summarized qualitative quantitative analysis study realizes data perception upn map real environment provide technical reference engineering digital experiment right reserved elsevierbuilding_information_modelling construction_industry design_engineering digital_twins interactive_systems pipelines production_engineering_computing smart_citiesanalytical_algorithm building_information_modeling data_filtering data_perception design_phase digital_mechanics_experiments digital_pipeline_experiments digital_twin_experiments engineering_digital_experiments human computer_interactive_methods information_storage material_information material_mechanics_theory mechanical_parameters mixed_reality_method physical_geometry_data sensors_communication smart_city space_interaction_system spatial_interaction traditional_mechanical_experiments underground_pipeline_network underground_pipelines underground_structure upn
413,Partially-Coherent Neural Holography with Fast Spatial Light Modulators,"Choi, S., Gopakumar, M., Peng, Y., Kim, J., O’Toole, M., & Wetzstein, G. (2023). Partially coherent neural holography with fast spatial light modulators. Emerging Digital Micromirror Device Based Systems and Applications XV. https://doi.org/10.1117/12.2655404
",10.1117/12.2655404,"Holographic near-eye displays are a promising technology to provide realistic and visually comfortable imagery with improved user experience, but their coherent light sources limit the image quality and restrict the types of patterns that can be generated. A partially-coherent mode, supported by emerging fast spatial light modulators (SLMs), has potential to overcome these limitations. However, these SLMs often have a limited phase control precision, which current computer-generated holography (CGH) techniques are not equipped to handle. In this work, we present a flexible CGH framework for fast, highly-quantized SLMs. This framework is capable of incorporating a wide range of content, including 2D and 2.5D RGBD images, 3D focal stacks, and 4D light fields, and we demonstrate its effectiveness through state-of-the-art simulation and experimental results. &copy; 2023 SPIE.","722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;723.4 Artificial Intelligence;723.5 Computer Applications;741.1 Light/Optics;743 Holography;743.1 Holographic Techniques",Coherent light sources;Coherent modes;Computational display;Computer-generated holography;Control precision;Machine-learning;Partially coherent;Phase-Control;Spatial light modulators;Users' experiences,Augmented reality;Computer generated holography;E-learning;Image enhancement;Light modulation;Light modulators;Light sources;Machine learning;Virtual reality,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Choi, Suyeon; (1) Gopakumar, Manu; (2) Peng, Yifan; (3) Kim, Jonghyun; (4) O&rsquo;Toole, Matthew; (1) Wetzstein, Gordon; ","(1) Electrical Engineering Department, Stanford University, 350 Jane Stanford Way, Stanford; CA, United States; (2) Department of Electrical and Electronic Engineering, The University of Hong Kong, Pokfulam, Hong Kong; (3) NVIDIA Research, 2788 San Tomas Expressway, Santa Clara; CA, United States; (4) Robotics Institute, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh; PA, United States; ",SPIE,-1,"[""computer-generated holography"", ""e-learning"", ""image enhancement"", ""light modulation"", ""light modulators"", ""light sources"", ""machine learning""]","[""computer-generated holography"", ""e-learning"", ""image enhancement"", ""light modulation"", ""light modulators"", ""light sources"", ""machine learning""]",computer-generated holography;e-learning;image enhancement;light modulation;light modulators;light sources;machine learning,computer vision;education;graphics;input;medical;display technology;artificial intelligence,technology;displays;industries,computer vision;education;graphics;input;medical;display technology;artificial intelligence,technology;displays;industries,computer generated_holography e learning image_enhancement light_modulation light_modulators light_sources machine_learning coherent_light_sources coherent_modes computational_display computer generated_holography control_precision machine learning partially_coherent phase control spatial_light_modulators users _experiences 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 5_computer_applications 741 1_light optics 743_holography 743 1_holographic_techniques computer_vision education graphics input medical display_technology artificial_intelligence,computer generated_holography e learning image_enhancement light_modulation light_modulators light_sources machine_learning,coherent_light_sources coherent_modes computational_display computer generated_holography control_precision machine learning partially_coherent phase control spatial_light_modulators users _experiences,holographic near eye display promising technology provide realistic visually comfortable imagery improved user experience coherent light source limit image quality restrict type pattern generated partially coherent mode supported emerging fast spatial light modulators slms potential overcome limitation however slms often limited phase control precision current computer generated holography cgh technique equipped handle work present flexible cgh framework fast highly quantized slms framework capable incorporating wide range content including 2d 2 5d rgbd image 3d focal stack 4d light field demonstrate effectiveness state art simulation experimental result copy 2023 spie,computer generated_holography e learning image_enhancement light_modulation light_modulators light_sources machine_learning coherent_light_sources coherent_modes computational_display computer generated_holography control_precision machine learning partially_coherent phase control spatial_light_modulators users _experiences 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 5_computer_applications 741 1_light optics 743_holography 743 1_holographic_techniques computer_vision education graphics input medical display_technology artificial_intelligence holographic near eye display promising technology provide realistic visually comfortable imagery improved user experience coherent light source limit image quality restrict type pattern generated partially coherent mode supported emerging fast spatial light modulators slms potential overcome limitation however slms often limited phase control precision current computer generated holography cgh technique equipped handle work present flexible cgh framework fast highly quantized slms framework capable incorporating wide range content including 2d 2 5d rgbd image 3d focal stack 4d light field demonstrate effectiveness state art simulation experimental result copy 2023 spie,holographic near eye display promising technology provide realistic visually comfortable imagery improved user experience coherent light source limit image quality restrict type pattern generated partially coherent mode supported emerging fast spatial light modulators slms potential overcome limitation however slms often limited phase control precision current computer generated holography cgh technique equipped handle work present flexible cgh framework fast highly quantized slms framework capable incorporating wide range content including 2d 2 5d rgbd image 3d focal stack 4d light field demonstrate effectiveness state art simulation experimental result copy 2023 spiecomputer generated_holography e learning image_enhancement light_modulation light_modulators light_sources machine_learningcoherent_light_sources coherent_modes computational_display computer generated_holography control_precision machine learning partially_coherent phase control spatial_light_modulators users _experiences
414,VR Education Support System&#8212;A Case Study of Digital Circuits Design,"Paszkiewicz, A., Salach, M., Strzałka, D., Budzik, G., Nikodem, A., Wójcik, H., & Witek, M. (2021). VR Education Support System—A Case Study of Digital Circuits Design. Energies, 15(1), 277. https://doi.org/10.3390/en15010277
",10.3390/en15010277,"Areas of experience allow for the acquisition and consolidation of both existing knowledge and skills. These are significant factors in the training of staff members for companies in the Industry 4.0 area. One of the currently available modern tools used in the teaching process is virtual reality (VR) technology. This technology, due to its high level of immersion and involvement of the different senses, and the need to focus on the performed activities, allows one to develop skills in solving various tasks and problems. The extended VR environment enables the creation of diverse teaching scenarios adapted to the needs of industry. This paper presents the possibility of building training scenarios in the field of digital techniques. The software solution, developed and presented by the authors, uses elements of computer game mechanics and is designed to familiarize students with the idea of digital circuits, their construction, logical implementation and application. This paper also presents a comparison of the features of different forms of education used in teaching digital techniques, as well as a comparison of these forms, from the point of view of the student and his/her perceptions.",C6130V Virtual reality;C5540D Computer displays;C6180 User interfaces;C7810C Computer-aided instruction;C7830D Computer games,computer game mechanics;currently available modern tools;different senses;digital circuits design;digital techniques;diverse teaching scenarios;logical implementation;performed activities;software solution;staff members;teaching process;training scenarios;virtual reality;VR education support system;VR environment,augmented reality;computer aided instruction;computer displays;computer games;teaching;user interfaces;virtual reality,2021,Journal article (JA),Energies (Switzerland),"(1) Paszkiewicz, A.; (1) Salach, M.; (1) Strza&#322;ka, D.; (2) Budzik, G.; (3) Nikodem, A.; (3) Wo&#769;jcik, H.; (3) Witek, M.; ","(1) Rzeszow University of Technology, Department of Complex Systems, Poland; (2) Rzeszow University of Technology, Faculty of Mechanical Engineering and Aeronautics, Poland; (3) Rzeszow University of Technology, Faculty of Electrical and Computer Engineering, Poland; ",MDPI,-1,"[""computer aided instruction"", ""computer displays"", ""computer games"", ""teaching"", ""user interfaces""]","[""computer aided instruction"", ""computer displays"", ""computer games"", ""teaching"", ""user interfaces""]",computer aided instruction;computer displays;computer games;teaching;user interfaces,education;liberal arts;training;display technology;human-computer interaction,end users and user experience;displays;use cases;industries,education;liberal arts;training;display technology;human-computer interaction,end users and user experience;displays;use cases;industries,computer_aided_instruction computer_displays computer_games teaching user_interfaces computer_game_mechanics currently_available_modern_tools different_senses digital_circuits_design digital_techniques diverse_teaching_scenarios logical_implementation performed_activities software_solution staff_members teaching_process training_scenarios virtual_reality vr_education_support_system vr_environment c6130v_virtual_reality c5540d_computer_displays c6180_user_interfaces c7810c_computer aided_instruction c7830d_computer_games education liberal_arts training display_technology human computer_interaction,computer_aided_instruction computer_displays computer_games teaching user_interfaces,computer_game_mechanics currently_available_modern_tools different_senses digital_circuits_design digital_techniques diverse_teaching_scenarios logical_implementation performed_activities software_solution staff_members teaching_process training_scenarios virtual_reality vr_education_support_system vr_environment,area experience allow acquisition consolidation existing knowledge skill significant factor training staff member company industry 4 0 area one currently available modern tool used teaching process virtual reality vr technology technology due high level immersion involvement different sens need focus performed activity allows one develop skill solving various task problem extended vr environment enables creation diverse teaching scenario adapted need industry paper present possibility building training scenario field digital technique software solution developed presented author us element computer game mechanic designed familiarize student idea digital circuit construction logical implementation application paper also present comparison feature different form education used teaching digital technique well comparison form point view student perception,computer_aided_instruction computer_displays computer_games teaching user_interfaces computer_game_mechanics currently_available_modern_tools different_senses digital_circuits_design digital_techniques diverse_teaching_scenarios logical_implementation performed_activities software_solution staff_members teaching_process training_scenarios virtual_reality vr_education_support_system vr_environment c6130v_virtual_reality c5540d_computer_displays c6180_user_interfaces c7810c_computer aided_instruction c7830d_computer_games education liberal_arts training display_technology human computer_interaction area experience allow acquisition consolidation existing knowledge skill significant factor training staff member company industry 4 0 area one currently available modern tool used teaching process virtual reality vr technology technology due high level immersion involvement different sens need focus performed activity allows one develop skill solving various task problem extended vr environment enables creation diverse teaching scenario adapted need industry paper present possibility building training scenario field digital technique software solution developed presented author us element computer game mechanic designed familiarize student idea digital circuit construction logical implementation application paper also present comparison feature different form education used teaching digital technique well comparison form point view student perception,area experience allow acquisition consolidation existing knowledge skill significant factor training staff member company industry 4 0 area one currently available modern tool used teaching process virtual reality vr technology technology due high level immersion involvement different sens need focus performed activity allows one develop skill solving various task problem extended vr environment enables creation diverse teaching scenario adapted need industry paper present possibility building training scenario field digital technique software solution developed presented author us element computer game mechanic designed familiarize student idea digital circuit construction logical implementation application paper also present comparison feature different form education used teaching digital technique well comparison form point view student perceptioncomputer_aided_instruction computer_displays computer_games teaching user_interfacescomputer_game_mechanics currently_available_modern_tools different_senses digital_circuits_design digital_techniques diverse_teaching_scenarios logical_implementation performed_activities software_solution staff_members teaching_process training_scenarios virtual_reality vr_education_support_system vr_environment
415,CAFI-AR: Contact-aware Freehand Interaction with AR Objects,"Tang, X., Li, R., & Fu, C.-W. (2022). CAFI-AR. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 6(4), 1–23. https://doi.org/10.1145/3569499
",10.1145/3569499,"Freehand interaction enhances user experience, allowing one to use bare hands to manipulate virtual objects in AR. Yet, it remains challenging to accurately and efficiently detect contacts between real hand and virtual object, due to the imprecise captured/estimated hand geometry. This paper presents CAFI-AR, a new approach for Contact-Aware Freehand Interaction with virtual AR objects, enabling us to automatically detect hand-object contacts in real-time with low latency. Specifically, we formulate a compact deep architecture to efficiently learn to predict hand action and contact moment from sequences of captured RGB images relative to the 3D virtual object. To train the architecture for detecting contacts on AR objects, we build a new dataset with 4,008 frame sequences, each with annotated hand-object interaction information. Further, we integrate CAFI-AR into our prototyping AR system and develop various interactive scenarios, demonstrating fine-grained contact-aware interactions on a rich variety of virtual AR objects, which cannot be achieved by existing AR interaction approaches. Lastly, we also evaluate CAFI-AR, quantitatively and qualitatively, through two user studies to demonstrate its effectiveness in terms of accurately detecting the hand-object contacts and promoting fluid freehand interactions","B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6180 User interfaces;C6264 Neural nets",AR interaction approaches;CAFI-AR;contact moment;contact-aware freehand interaction;fine-grained contact-aware interactions;hand action;hand geometry;hand-object contacts;interactive scenarios;RGB image capture;user experience;virtual AR objects,augmented reality;deep learning (artificial intelligence);gesture recognition;human computer interaction;image capture;image colour analysis;user experience,2022,Journal article (JA),Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. (USA),"(1) Tang, X.; (2) Li, R.; (3) Fu, C.-W.; ","(1) Chinese University of Hong Kong, China; (2) Hunan University, China; (3) Chinese University of Hong Kong, China and Institute of Medical Intelligence and XR, China; ",ACM,-1,"[""deep learning (artificial intelligence)"", ""gesture recognition"", ""human computer interaction"", ""image capture"", ""image colour analysis"", ""user experience""]","[""deep learning (artificial intelligence)"", ""gesture recognition"", ""human computer interaction"", ""image capture"", ""image colour analysis"", ""user experience""]",deep learning (artificial intelligence);gesture recognition;human computer interaction;image capture;image colour analysis;user experience,computer vision;other;graphics;input;liberal arts;medical;human factors;human-computer interaction;artificial intelligence,technology;other;industries;end users and user experience,computer vision;other;graphics;input;liberal arts;medical;human factors;human-computer interaction;artificial intelligence,technology;other;industries;end users and user experience,deep_learning_ artificial_intelligence gesture_recognition human_computer_interaction image_capture image_colour_analysis user_experience ar_interaction_approaches cafi ar contact_moment contact aware_freehand_interaction fine grained_contact aware_interactions hand_action hand_geometry hand object_contacts interactive_scenarios rgb_image_capture user_experience virtual_ar_objects b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6264_neural_nets computer_vision other graphics input liberal_arts medical human_factors human computer_interaction artificial_intelligence,deep_learning_ artificial_intelligence gesture_recognition human_computer_interaction image_capture image_colour_analysis user_experience,ar_interaction_approaches cafi ar contact_moment contact aware_freehand_interaction fine grained_contact aware_interactions hand_action hand_geometry hand object_contacts interactive_scenarios rgb_image_capture user_experience virtual_ar_objects,freehand interaction enhances user experience allowing one use bare hand manipulate virtual object ar yet remains challenging accurately efficiently detect contact real hand virtual object due imprecise captured estimated hand geometry paper present cafi ar new approach contact aware freehand interaction virtual ar object enabling u automatically detect hand object contact real time low latency specifically formulate compact deep architecture efficiently learn predict hand action contact moment sequence captured rgb image relative 3d virtual object train architecture detecting contact ar object build new dataset 4 008 frame sequence annotated hand object interaction information integrate cafi ar prototyping ar system develop various interactive scenario demonstrating fine grained contact aware interaction rich variety virtual ar object cannot achieved existing ar interaction approach lastly also evaluate cafi ar quantitatively qualitatively two user study demonstrate effectiveness term accurately detecting hand object contact promoting fluid freehand interaction,deep_learning_ artificial_intelligence gesture_recognition human_computer_interaction image_capture image_colour_analysis user_experience ar_interaction_approaches cafi ar contact_moment contact aware_freehand_interaction fine grained_contact aware_interactions hand_action hand_geometry hand object_contacts interactive_scenarios rgb_image_capture user_experience virtual_ar_objects b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6180_user_interfaces c6264_neural_nets computer_vision other graphics input liberal_arts medical human_factors human computer_interaction artificial_intelligence freehand interaction enhances user experience allowing one use bare hand manipulate virtual object ar yet remains challenging accurately efficiently detect contact real hand virtual object due imprecise captured estimated hand geometry paper present cafi ar new approach contact aware freehand interaction virtual ar object enabling u automatically detect hand object contact real time low latency specifically formulate compact deep architecture efficiently learn predict hand action contact moment sequence captured rgb image relative 3d virtual object train architecture detecting contact ar object build new dataset 4 008 frame sequence annotated hand object interaction information integrate cafi ar prototyping ar system develop various interactive scenario demonstrating fine grained contact aware interaction rich variety virtual ar object cannot achieved existing ar interaction approach lastly also evaluate cafi ar quantitatively qualitatively two user study demonstrate effectiveness term accurately detecting hand object contact promoting fluid freehand interaction,freehand interaction enhances user experience allowing one use bare hand manipulate virtual object ar yet remains challenging accurately efficiently detect contact real hand virtual object due imprecise captured estimated hand geometry paper present cafi ar new approach contact aware freehand interaction virtual ar object enabling u automatically detect hand object contact real time low latency specifically formulate compact deep architecture efficiently learn predict hand action contact moment sequence captured rgb image relative 3d virtual object train architecture detecting contact ar object build new dataset 4 008 frame sequence annotated hand object interaction information integrate cafi ar prototyping ar system develop various interactive scenario demonstrating fine grained contact aware interaction rich variety virtual ar object cannot achieved existing ar interaction approach lastly also evaluate cafi ar quantitatively qualitatively two user study demonstrate effectiveness term accurately detecting hand object contact promoting fluid freehand interactiondeep_learning_ artificial_intelligence gesture_recognition human_computer_interaction image_capture image_colour_analysis user_experiencear_interaction_approaches cafi ar contact_moment contact aware_freehand_interaction fine grained_contact aware_interactions hand_action hand_geometry hand object_contacts interactive_scenarios rgb_image_capture user_experience virtual_ar_objects
416,ATARI: a graph convolutional neural network approach for performance prediction in next-generation WLANs,"Soto, P., Camelo, M., Mets, K., Wilhelmi, F., Góez, D., Fletscher, L. A., Gaviria, N., Hellinckx, P., Botero, J. F., & Latré, S. (2021). ATARI: A Graph Convolutional Neural Network Approach for Performance Prediction in Next-Generation WLANs. Sensors, 21(13), 4321. https://doi.org/10.3390/s21134321
",10.3390/s21134321,"IEEE 802.11 (Wi-Fi) is one of the technologies that provides high performance with a high density of connected devices to support emerging demanding services, such as virtual and augmented reality. However, in highly dense deployments, Wi-Fi performance is severely affected by interference. This problem is even worse in new standards, such as 802.11n/ac, where new features such as Channel Bonding (CB) are introduced to increase network capacity but at the cost of using wider spectrum channels. Finding the best channel assignment in dense deployments under dynamic environments with CB is challenging, given its combinatorial nature. Therefore, the use of analytical or system models to predict Wi-Fi performance after potential changes (e.g., dynamic channel selection with CB, and the deployment of new devices) are not suitable, due to either low accuracy or high computational cost. This paper presents a novel, data-driven approach to speed up this process, using a Graph Neural Network (GNN) model that exploits the information carried in the deployment's topology and the intricate wireless interactions to predict Wi-Fi performance with high accuracy. The evaluation results show that preserving the graph structure in the learning process obtains a 64% increase versus a naive approach, and around 55% compared to other Machine Learning (ML) approaches when using all training features.","B6250 Radio links and equipment;B0250 Combinatorial mathematics;B6150P Communication network design, planning and routing;B6210L Computer communications;C1160 Combinatorial mathematics;C5620L Local area networks;C5670 Computer network performance;C6264 Neural nets",augmented reality;channel assignment;Channel Bonding;computational cost;deployment topology;dynamic channel selection;GNN model;graph convolutional neural network approach;Graph Neural Network model;IEEE 8802.11n/ac;network capacity;next-generation WLAN;performance prediction;virtual reality;Wi-Fi performance;wider spectrum channels,channel allocation;computer network performance evaluation;graph theory;learning (artificial intelligence);neural nets;telecommunication network topology;wireless LAN,2021,Journal article (JA),Sensors (Switzerland),"(1) Soto, P.; (1) Camelo, M.; (1) Mets, K.; (3) Wilhelmi, F.; (2) Go&#769;ez, D.; (2) Fletscher, L.A.; (2) Gaviria, N.; (1) Hellinckx, P.; (2) Botero, J.F.; (1) Latre&#769;, S.; ","(1) University of Antwerp&#8212;imec, Department of Computer Science, Belgium; (2) Universidad de Antioquia, Department of Telecommunications Engineering, Colombia; (3) Centre Tecnolo&#768;gic de Telecomunicacions de Catalunya, Spain; ",MDPI,-1,"[""channel allocation"", ""computer network performance evaluation"", ""graph theory"", ""learning algorithms"", ""neural networks"", ""telecommunication network topology"", ""wireless lan""]","[""channel allocation"", ""computer network performance evaluation"", ""graph theory"", ""learning algorithms"", ""neural networks"", ""telecommunication network topology"", ""wireless lan""]",channel allocation;computer network performance evaluation;graph theory;learning algorithms;neural networks;telecommunication network topology;wireless lan,other;input;medical;business performance metrics;telecommunication;geospatial;artificial intelligence;networks,technology;other;business;industries,other;input;medical;business performance metrics;telecommunication;geospatial;artificial intelligence;networks,technology;other;business;industries,channel_allocation computer_network_performance_evaluation graph_theory learning_algorithms neural_networks telecommunication_network_topology wireless_lan augmented_reality channel_assignment channel_bonding computational_cost deployment_topology dynamic_channel_selection gnn_model graph_convolutional_neural_network_approach graph_neural_network_model ieee_8802 11n ac network_capacity next generation_wlan performance_prediction virtual_reality wi fi_performance wider_spectrum_channels b6250_radio_links_and_equipment b0250_combinatorial_mathematics b6150p_communication_network_design _planning_and_routing b6210l_computer_communications c1160_combinatorial_mathematics c5620l_local_area_networks c5670_computer_network_performance c6264_neural_nets other input medical business_performance_metrics telecommunication geospatial artificial_intelligence networks,channel_allocation computer_network_performance_evaluation graph_theory learning_algorithms neural_networks telecommunication_network_topology wireless_lan,augmented_reality channel_assignment channel_bonding computational_cost deployment_topology dynamic_channel_selection gnn_model graph_convolutional_neural_network_approach graph_neural_network_model ieee_8802 11n ac network_capacity next generation_wlan performance_prediction virtual_reality wi fi_performance wider_spectrum_channels,ieee 802 11 wi fi one technology provides high performance high density connected device support emerging demanding service virtual augmented reality however highly dense deployment wi fi performance severely affected interference problem even worse new standard 802 11n ac new feature channel bonding cb introduced increase network capacity cost using wider spectrum channel finding best channel assignment dense deployment dynamic environment cb challenging given combinatorial nature therefore use analytical system model predict wi fi performance potential change e g dynamic channel selection cb deployment new device suitable due either low accuracy high computational cost paper present novel data driven approach speed process using graph neural network gnn model exploit information carried deployment topology intricate wireless interaction predict wi fi performance high accuracy evaluation result show preserving graph structure learning process obtains 64 increase versus naive approach around 55 compared machine learning ml approach using training feature,channel_allocation computer_network_performance_evaluation graph_theory learning_algorithms neural_networks telecommunication_network_topology wireless_lan augmented_reality channel_assignment channel_bonding computational_cost deployment_topology dynamic_channel_selection gnn_model graph_convolutional_neural_network_approach graph_neural_network_model ieee_8802 11n ac network_capacity next generation_wlan performance_prediction virtual_reality wi fi_performance wider_spectrum_channels b6250_radio_links_and_equipment b0250_combinatorial_mathematics b6150p_communication_network_design _planning_and_routing b6210l_computer_communications c1160_combinatorial_mathematics c5620l_local_area_networks c5670_computer_network_performance c6264_neural_nets other input medical business_performance_metrics telecommunication geospatial artificial_intelligence networks ieee 802 11 wi fi one technology provides high performance high density connected device support emerging demanding service virtual augmented reality however highly dense deployment wi fi performance severely affected interference problem even worse new standard 802 11n ac new feature channel bonding cb introduced increase network capacity cost using wider spectrum channel finding best channel assignment dense deployment dynamic environment cb challenging given combinatorial nature therefore use analytical system model predict wi fi performance potential change e g dynamic channel selection cb deployment new device suitable due either low accuracy high computational cost paper present novel data driven approach speed process using graph neural network gnn model exploit information carried deployment topology intricate wireless interaction predict wi fi performance high accuracy evaluation result show preserving graph structure learning process obtains 64 increase versus naive approach around 55 compared machine learning ml approach using training feature,ieee 802 11 wi fi one technology provides high performance high density connected device support emerging demanding service virtual augmented reality however highly dense deployment wi fi performance severely affected interference problem even worse new standard 802 11n ac new feature channel bonding cb introduced increase network capacity cost using wider spectrum channel finding best channel assignment dense deployment dynamic environment cb challenging given combinatorial nature therefore use analytical system model predict wi fi performance potential change e g dynamic channel selection cb deployment new device suitable due either low accuracy high computational cost paper present novel data driven approach speed process using graph neural network gnn model exploit information carried deployment topology intricate wireless interaction predict wi fi performance high accuracy evaluation result show preserving graph structure learning process obtains 64 increase versus naive approach around 55 compared machine learning ml approach using training featurechannel_allocation computer_network_performance_evaluation graph_theory learning_algorithms neural_networks telecommunication_network_topology wireless_lanaugmented_reality channel_assignment channel_bonding computational_cost deployment_topology dynamic_channel_selection gnn_model graph_convolutional_neural_network_approach graph_neural_network_model ieee_8802 11n ac network_capacity next generation_wlan performance_prediction virtual_reality wi fi_performance wider_spectrum_channels
417,Implementation of the XR rehabilitation simulation system for the utilization of rehabilitation with robotic prosthetic leg,"Shim, W., Kim, H., Lim, G., Lee, S., Kim, H., Hwang, J., Lee, E., Cho, J., Jeong, H., Pak, C., Suh, H., Hong, J., & Kwon, S. (2022). Implementation of the XR Rehabilitation Simulation System for the Utilization of Rehabilitation with Robotic Prosthetic Leg. Applied Sciences, 12(24), 12659. https://doi.org/10.3390/app122412659
",10.3390/app122412659,"With the recent development of a digital rehabilitation system, research on the rehabilitation of amputees is accelerating. However, research on rehabilitation systems for patients with amputation of the lower extremities is insufficient. For the rehabilitation of amputees, it is important to maintain muscle mass through the improvement of muscle movement memory, continuous rehabilitation learning, and motivation to improve efficiency. The rehabilitation system in a virtual environment is convenient in that there is no restriction on time and space because rehabilitation training of amputees is possible without removing/attaching general prosthetic legs and robot prosthetic legs. In this paper, we propose an XR rehabilitation system for patients with lower extremity amputation to improve the motivational aspect of rehabilitation training. The proposed method is a system that allows patients and clinical experts to perform rehabilitation in the same environment using two XR equipment called HoloLens 2. The content was provided in the form of a game in which the number of movements of amputees was allocated as scores to enhance rehabilitation convenience and motivation aspects. The virtual 3D model prosthetic leg used in-game content worked through the acquisition and processing of the patient's actual muscle EMG (ElectroMyoGraphy) signal. In order to improve reactivity, there was a time limit for completing the operation. The classified action should be completed by the amputee within the time limit, although the number of times set as the target. To complete the operation, the amputee must force the amputation area to exceed an arbitrarily set threshold. The evaluation results were evaluated through an independent sample&lt;i&gt;t&lt;/i&gt;-test. we contribute to the development of digital rehabilitation simulation systems. XR rehabilitation training techniques, operated with EMG signals obtained from actual amputation sites, contribute to the promotion of rehabilitation content in patients with amputation of the lower extremities. It is expected that this paper will improve the convenience and rehabilitation of rehabilitation training in the future.",A8770J Prosthetics and other practical applications;A8730C Electrical activity in neurophysiological processes;A8745D Physics of body movements;A8770F Electrodiagnostics and other electrical measurement techniques;B7510D Bioelectric signals;B7520 Patient care and treatment;B7520E Prosthetics and orthotics;C3385 Biological and medical control systems;C3385C Prosthetic and orthotic control systems;C3390 Robotics;C5260 Digital signal processing;C6130V Virtual reality;C7330 Biology and medical computing;C7830D Computer games,amputee;continuous rehabilitation learning;digital rehabilitation simulation systems;digital rehabilitation system;lower extremities;patient;rehabilitation content;rehabilitation convenience;robot prosthetic legs;robotic prosthetic leg;virtual 3D model prosthetic leg;XR rehabilitation simulation system;XR rehabilitation system;XR rehabilitation training techniques,augmented reality;biomechanics;computer games;electromyography;human factors;medical robotics;medical signal processing;muscle;patient rehabilitation;prosthetics;virtual reality,2022,Journal article (JA),Appl. Sci. (Switzerland),"(1) Shim, W.; (2) Kim, H.; (2) Lim, G.; (3) Lee, S.; (4) Kim, H.; (4) Hwang, J.; (4) Lee, E.; (4) Cho, J.; (4) Jeong, H.; (4) Pak, C.; (4) Suh, H.; (4) Hong, J.; (1) Kwon, S.; ","(1) Kwangwoon University, Graduate School of Smart Convergence, Korea, Republic of; (2) Kwangwoon University, Department of Plasma Bio Display, Korea, Republic of; (3) Kwangwoon University, Department of Ingenium College Liberal Arts, Korea, Republic of; (4) Seoul Asan Medical Center, Department of Plastic Surgery, Korea, Republic of; ",MDPI,-1,"[""biomechanics"", ""computer games"", ""electromyography"", ""human factors"", ""medical robotics"", ""medical signal processing"", ""muscle"", ""patient rehabilitation"", ""prosthetics""]","[""biomechanics"", ""computer games"", ""electromyography"", ""human factors"", ""medical robotics"", ""medical signal processing"", ""muscle"", ""patient rehabilitation"", ""prosthetics""]",biomechanics;computer games;electromyography;human factors;medical robotics;medical signal processing;muscle;patient rehabilitation;prosthetics,robotics;liberal arts;medical;sensors;human factors;data,technology;industries;end users and user experience,robotics;liberal arts;medical;sensors;human factors;data,technology;industries;end users and user experience,biomechanics computer_games electromyography human_factors medical_robotics medical_signal_processing muscle patient_rehabilitation prosthetics amputee continuous_rehabilitation_learning digital_rehabilitation_simulation_systems digital_rehabilitation_system lower_extremities patient rehabilitation_content rehabilitation_convenience robot_prosthetic_legs robotic_prosthetic_leg virtual_3d_model_prosthetic_leg xr_rehabilitation_simulation_system xr_rehabilitation_system xr_rehabilitation_training_techniques a8770j_prosthetics_and_other_practical_applications a8730c_electrical_activity_in_neurophysiological_processes a8745d_physics_of_body_movements a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b7510d_bioelectric_signals b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c3385c_prosthetic_and_orthotic_control_systems c3390_robotics c5260_digital_signal_processing c6130v_virtual_reality c7330_biology_and_medical_computing c7830d_computer_games robotics liberal_arts medical sensors human_factors data,biomechanics computer_games electromyography human_factors medical_robotics medical_signal_processing muscle patient_rehabilitation prosthetics,amputee continuous_rehabilitation_learning digital_rehabilitation_simulation_systems digital_rehabilitation_system lower_extremities patient rehabilitation_content rehabilitation_convenience robot_prosthetic_legs robotic_prosthetic_leg virtual_3d_model_prosthetic_leg xr_rehabilitation_simulation_system xr_rehabilitation_system xr_rehabilitation_training_techniques,recent development digital rehabilitation system research rehabilitation amputee accelerating however research rehabilitation system patient amputation lower extremity insufficient rehabilitation amputee important maintain muscle mass improvement muscle movement memory continuous rehabilitation learning motivation improve efficiency rehabilitation system virtual environment convenient restriction time space rehabilitation training amputee possible without removing attaching general prosthetic leg robot prosthetic leg paper propose xr rehabilitation system patient lower extremity amputation improve motivational aspect rehabilitation training proposed method system allows patient clinical expert perform rehabilitation environment using two xr equipment called hololens 2 content provided form game number movement amputee allocated score enhance rehabilitation convenience motivation aspect virtual 3d model prosthetic leg used game content worked acquisition processing patient actual muscle emg electromyography signal order improve reactivity time limit completing operation classified action completed amputee within time limit although number time set target complete operation amputee must force amputation area exceed arbitrarily set threshold evaluation result evaluated independent sample lt gt lt gt test contribute development digital rehabilitation simulation system xr rehabilitation training technique operated emg signal obtained actual amputation site contribute promotion rehabilitation content patient amputation lower extremity expected paper improve convenience rehabilitation rehabilitation training future,biomechanics computer_games electromyography human_factors medical_robotics medical_signal_processing muscle patient_rehabilitation prosthetics amputee continuous_rehabilitation_learning digital_rehabilitation_simulation_systems digital_rehabilitation_system lower_extremities patient rehabilitation_content rehabilitation_convenience robot_prosthetic_legs robotic_prosthetic_leg virtual_3d_model_prosthetic_leg xr_rehabilitation_simulation_system xr_rehabilitation_system xr_rehabilitation_training_techniques a8770j_prosthetics_and_other_practical_applications a8730c_electrical_activity_in_neurophysiological_processes a8745d_physics_of_body_movements a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b7510d_bioelectric_signals b7520_patient_care_and_treatment b7520e_prosthetics_and_orthotics c3385_biological_and_medical_control_systems c3385c_prosthetic_and_orthotic_control_systems c3390_robotics c5260_digital_signal_processing c6130v_virtual_reality c7330_biology_and_medical_computing c7830d_computer_games robotics liberal_arts medical sensors human_factors data recent development digital rehabilitation system research rehabilitation amputee accelerating however research rehabilitation system patient amputation lower extremity insufficient rehabilitation amputee important maintain muscle mass improvement muscle movement memory continuous rehabilitation learning motivation improve efficiency rehabilitation system virtual environment convenient restriction time space rehabilitation training amputee possible without removing attaching general prosthetic leg robot prosthetic leg paper propose xr rehabilitation system patient lower extremity amputation improve motivational aspect rehabilitation training proposed method system allows patient clinical expert perform rehabilitation environment using two xr equipment called hololens 2 content provided form game number movement amputee allocated score enhance rehabilitation convenience motivation aspect virtual 3d model prosthetic leg used game content worked acquisition processing patient actual muscle emg electromyography signal order improve reactivity time limit completing operation classified action completed amputee within time limit although number time set target complete operation amputee must force amputation area exceed arbitrarily set threshold evaluation result evaluated independent sample lt gt lt gt test contribute development digital rehabilitation simulation system xr rehabilitation training technique operated emg signal obtained actual amputation site contribute promotion rehabilitation content patient amputation lower extremity expected paper improve convenience rehabilitation rehabilitation training future,recent development digital rehabilitation system research rehabilitation amputee accelerating however research rehabilitation system patient amputation lower extremity insufficient rehabilitation amputee important maintain muscle mass improvement muscle movement memory continuous rehabilitation learning motivation improve efficiency rehabilitation system virtual environment convenient restriction time space rehabilitation training amputee possible without removing attaching general prosthetic leg robot prosthetic leg paper propose xr rehabilitation system patient lower extremity amputation improve motivational aspect rehabilitation training proposed method system allows patient clinical expert perform rehabilitation environment using two xr equipment called hololens 2 content provided form game number movement amputee allocated score enhance rehabilitation convenience motivation aspect virtual 3d model prosthetic leg used game content worked acquisition processing patient actual muscle emg electromyography signal order improve reactivity time limit completing operation classified action completed amputee within time limit although number time set target complete operation amputee must force amputation area exceed arbitrarily set threshold evaluation result evaluated independent sample lt gt lt gt test contribute development digital rehabilitation simulation system xr rehabilitation training technique operated emg signal obtained actual amputation site contribute promotion rehabilitation content patient amputation lower extremity expected paper improve convenience rehabilitation rehabilitation training futurebiomechanics computer_games electromyography human_factors medical_robotics medical_signal_processing muscle patient_rehabilitation prostheticsamputee continuous_rehabilitation_learning digital_rehabilitation_simulation_systems digital_rehabilitation_system lower_extremities patient rehabilitation_content rehabilitation_convenience robot_prosthetic_legs robotic_prosthetic_leg virtual_3d_model_prosthetic_leg xr_rehabilitation_simulation_system xr_rehabilitation_system xr_rehabilitation_training_techniques
418,Using Mixed Reality (MR) to Improve On-Site Design Experience in Community Planning,"Dan, Y., Shen, Z., Zhu, Y., & Huang, L. (2021). Using Mixed Reality (MR) to Improve On-Site Design Experience in Community Planning. Applied Sciences, 11(7), 3071. https://doi.org/10.3390/app11073071
",10.3390/app11073071,"In recent years, designing in existing environments has been consistently emphasized in community planning. However, practicing such on-site design is not easy for designers, because the current technical conditions do not allow virtual design objects into real environments for 3D visualization and interaction. Thus, designers' intuitive design perceptions, accurate design judgments, and convenient design decisions are hardly supported. This paper explores the possibilities of using mixed reality (MR) technology to improve designers' on-site design experiences in community planning. For this, we introduced an MR design support system (MR-DSS) for the interactive on-site 3D visualization of virtual design objects. With the MR-DSS, we performed a design experiment with sixteen participants in a typical on-site design scene of community planning. The results showed that the MR technology could provide designers with intuitive design perceptions, accurate design judgments, and convenient design decisions, thus effectively improving their on-site design experiences.",C7130 Public administration;C6130B Graphics techniques;C6130V Virtual reality;E1400 Design,3D visualization;community planning;interactive on-site 3D visualization;mixed reality technology;MR design support system;MR technology;MR-DSS;on-site design experience;on-site design experiences;on-site design scene;virtual design objects,augmented reality;data visualisation;design;solid modelling;town and country planning;virtual reality,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Dan, Y.; (1) Shen, Z.; (3) Zhu, Y.; (4) Huang, L.; ","(1) Kanazawa University, Division of Environmental Design, Japan; (2) Fujian Science & Technology Innovation Laboratory, China; (3) Chongqing College of Electronic Engineering, School of Smart Health, China; (4) Chongqing University, School of Architecture and Urban planning, China; ",MDPI,-1,"[""data visualization"", ""design"", ""solid modelling"", ""town and country planning""]","[""data visualization"", ""design"", ""solid modelling"", ""town and country planning""]",data visualization;design;solid modelling;town and country planning,smart cities;data;human-computer interaction;manufacturing;business planning and management,business;industries;end users and user experience;use cases;technology,smart cities;data;human-computer interaction;manufacturing;business planning and management,business;industries;end users and user experience;use cases;technology,data_visualization design solid_modelling town_and_country_planning 3d_visualization community_planning interactive_on site_3d_visualization mixed_reality_technology mr_design_support_system mr_technology mr dss on site_design_experience on site_design_experiences on site_design_scene virtual_design_objects c7130_public_administration c6130b_graphics_techniques c6130v_virtual_reality e1400_design smart_cities data human computer_interaction manufacturing business_planning_and_management,data_visualization design solid_modelling town_and_country_planning,3d_visualization community_planning interactive_on site_3d_visualization mixed_reality_technology mr_design_support_system mr_technology mr dss on site_design_experience on site_design_experiences on site_design_scene virtual_design_objects,recent year designing existing environment consistently emphasized community planning however practicing site design easy designer current technical condition allow virtual design object real environment 3d visualization interaction thus designer intuitive design perception accurate design judgment convenient design decision hardly supported paper explores possibility using mixed reality mr technology improve designer site design experience community planning introduced mr design support system mr ds interactive site 3d visualization virtual design object mr ds performed design experiment sixteen participant typical site design scene community planning result showed mr technology could provide designer intuitive design perception accurate design judgment convenient design decision thus effectively improving site design experience,data_visualization design solid_modelling town_and_country_planning 3d_visualization community_planning interactive_on site_3d_visualization mixed_reality_technology mr_design_support_system mr_technology mr dss on site_design_experience on site_design_experiences on site_design_scene virtual_design_objects c7130_public_administration c6130b_graphics_techniques c6130v_virtual_reality e1400_design smart_cities data human computer_interaction manufacturing business_planning_and_management recent year designing existing environment consistently emphasized community planning however practicing site design easy designer current technical condition allow virtual design object real environment 3d visualization interaction thus designer intuitive design perception accurate design judgment convenient design decision hardly supported paper explores possibility using mixed reality mr technology improve designer site design experience community planning introduced mr design support system mr ds interactive site 3d visualization virtual design object mr ds performed design experiment sixteen participant typical site design scene community planning result showed mr technology could provide designer intuitive design perception accurate design judgment convenient design decision thus effectively improving site design experience,recent year designing existing environment consistently emphasized community planning however practicing site design easy designer current technical condition allow virtual design object real environment 3d visualization interaction thus designer intuitive design perception accurate design judgment convenient design decision hardly supported paper explores possibility using mixed reality mr technology improve designer site design experience community planning introduced mr design support system mr ds interactive site 3d visualization virtual design object mr ds performed design experiment sixteen participant typical site design scene community planning result showed mr technology could provide designer intuitive design perception accurate design judgment convenient design decision thus effectively improving site design experiencedata_visualization design solid_modelling town_and_country_planning3d_visualization community_planning interactive_on site_3d_visualization mixed_reality_technology mr_design_support_system mr_technology mr dss on site_design_experience on site_design_experiences on site_design_scene virtual_design_objects
419,Exploring the Use of Smartphones as Input Devices for the Mixed Reality Environment,"Pan, Z., Pan, Z., Luo, T., & Zhang, M. (2022). Exploring the Use of Smartphones as Input Devices for the Mixed Reality Environment. Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry. https://doi.org/10.1145/3574131.3574451
",10.1145/3574131.3574451,"Nowadays, researches on mixed reality (MR) have made a lot of exploration in the aspects of user experience, hardware devices, interaction technologies, application systems, etc. However, more research is still needed to explore how to improve the experience in the shared MR Environment and design appropriate collaborative interaction models. The traditional VR handle can realize tool simulation and 3D interaction, while smartphones can realize 2D interactions such as fast 2D gestures, text input and handwriting. Using the mobile phone as the handle of the MR headset can realize the complementary advantages of the two. In this study, we design a cross-device collaborative system sharing a hybrid reality environment. In the MR Environment, the smartphone will realize the functions of the controller for remote selection and manipulation of objects, and its advantages in 2D interaction can be well applied to some special tasks. We design the user interface with three levels of immersion: high, medium and low. High immersion: We provide a hybrid user interface combining a HoloLens2 and a smartphone. Medium immersion: We provide a 3D user interface represented by HoloLens2. Low immersion: We provide a multi-touch user interface represented by tablet. User studies show that the hybrid user interfaces can bring users satisfactory immersion and interactive experience, but it also needs to design accurate and efficient input methods according to the interactive tasks.","C6130V Virtual reality;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C6130B Graphics techniques;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing;C7480 Production engineering computing;C7810C Computer-aided instruction;E0410D Industrial applications of IT",accurate input methods;application systems;appropriate collaborative interaction models;complementary advantages;cross-device collaborative system;efficient input methods;fast 2D gestures;handwriting;hardware devices;high immersion;HoloLens2;hybrid reality environment;hybrid user interface;input devices;interaction technologies;interactive experience;interactive tasks;low immersion;medium immersion;mixed reality Environment;mobile phone;multitouch user interface;remote selection;shared MR Environment;smartphone;text input;tool simulation;traditional VR handle;user experience;users satisfactory immersion,augmented reality;computer based training;gesture recognition;human computer interaction;mobile computing;production engineering computing;smart phones;user interfaces;virtual reality,2022,Conference article (CA),VRCAI'22: Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry,"(1) Pan, Z.; (2) Pan, Z.; (3) Luo, T.; (4) Zhang, M.; ","(1) Nanjing University of Information Science and Technology, China; (2) Hangzhou Normal University, China; (3) University of Chinese Academy of Sciences, China; (4) Zhejiang University, China; ",ACM,-1,"[""computer based training"", ""gesture recognition"", ""human computer interaction"", ""mobile computing"", ""production engineering computing"", ""smartphones"", ""user interfaces""]","[""computer based training"", ""gesture recognition"", ""human computer interaction"", ""mobile computing"", ""production engineering computing"", ""smartphones"", ""user interfaces""]",computer based training;gesture recognition;human computer interaction;mobile computing;production engineering computing;smartphones;user interfaces,farming and natural science;input;liberal arts;training;human factors;telecommunication;engineering;human-computer interaction;manufacturing,technology;end users and user experience;use cases;industries,farming and natural science;input;liberal arts;training;human factors;telecommunication;engineering;human-computer interaction;manufacturing,technology;end users and user experience;use cases;industries,computer_based_training gesture_recognition human_computer_interaction mobile_computing production_engineering_computing smartphones user_interfaces accurate_input_methods application_systems appropriate_collaborative_interaction_models complementary_advantages cross device_collaborative_system efficient_input_methods fast_2d_gestures handwriting hardware_devices high_immersion hololens2 hybrid_reality_environment hybrid_user_interface input_devices interaction_technologies interactive_experience interactive_tasks low_immersion medium_immersion mixed_reality_environment mobile_phone multitouch_user_interface remote_selection shared_mr_environment smartphone text_input tool_simulation traditional_vr_handle user_experience users_satisfactory_immersion c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7480_production_engineering_computing c7810c_computer aided_instruction e0410d_industrial_applications_of_it farming_and_natural_science input liberal_arts training human_factors telecommunication engineering human computer_interaction manufacturing,computer_based_training gesture_recognition human_computer_interaction mobile_computing production_engineering_computing smartphones user_interfaces,accurate_input_methods application_systems appropriate_collaborative_interaction_models complementary_advantages cross device_collaborative_system efficient_input_methods fast_2d_gestures handwriting hardware_devices high_immersion hololens2 hybrid_reality_environment hybrid_user_interface input_devices interaction_technologies interactive_experience interactive_tasks low_immersion medium_immersion mixed_reality_environment mobile_phone multitouch_user_interface remote_selection shared_mr_environment smartphone text_input tool_simulation traditional_vr_handle user_experience users_satisfactory_immersion,nowadays research mixed reality mr made lot exploration aspect user experience hardware device interaction technology application system etc however research still needed explore improve experience shared mr environment design appropriate collaborative interaction model traditional vr handle realize tool simulation 3d interaction smartphones realize 2d interaction fast 2d gesture text input handwriting using mobile phone handle mr headset realize complementary advantage two study design cross device collaborative system sharing hybrid reality environment mr environment smartphone realize function controller remote selection manipulation object advantage 2d interaction well applied special task design user interface three level immersion high medium low high immersion provide hybrid user interface combining hololens2 smartphone medium immersion provide 3d user interface represented hololens2 low immersion provide multi touch user interface represented tablet user study show hybrid user interface bring user satisfactory immersion interactive experience also need design accurate efficient input method according interactive task,computer_based_training gesture_recognition human_computer_interaction mobile_computing production_engineering_computing smartphones user_interfaces accurate_input_methods application_systems appropriate_collaborative_interaction_models complementary_advantages cross device_collaborative_system efficient_input_methods fast_2d_gestures handwriting hardware_devices high_immersion hololens2 hybrid_reality_environment hybrid_user_interface input_devices interaction_technologies interactive_experience interactive_tasks low_immersion medium_immersion mixed_reality_environment mobile_phone multitouch_user_interface remote_selection shared_mr_environment smartphone text_input tool_simulation traditional_vr_handle user_experience users_satisfactory_immersion c6130v_virtual_reality c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7480_production_engineering_computing c7810c_computer aided_instruction e0410d_industrial_applications_of_it farming_and_natural_science input liberal_arts training human_factors telecommunication engineering human computer_interaction manufacturing nowadays research mixed reality mr made lot exploration aspect user experience hardware device interaction technology application system etc however research still needed explore improve experience shared mr environment design appropriate collaborative interaction model traditional vr handle realize tool simulation 3d interaction smartphones realize 2d interaction fast 2d gesture text input handwriting using mobile phone handle mr headset realize complementary advantage two study design cross device collaborative system sharing hybrid reality environment mr environment smartphone realize function controller remote selection manipulation object advantage 2d interaction well applied special task design user interface three level immersion high medium low high immersion provide hybrid user interface combining hololens2 smartphone medium immersion provide 3d user interface represented hololens2 low immersion provide multi touch user interface represented tablet user study show hybrid user interface bring user satisfactory immersion interactive experience also need design accurate efficient input method according interactive task,nowadays research mixed reality mr made lot exploration aspect user experience hardware device interaction technology application system etc however research still needed explore improve experience shared mr environment design appropriate collaborative interaction model traditional vr handle realize tool simulation 3d interaction smartphones realize 2d interaction fast 2d gesture text input handwriting using mobile phone handle mr headset realize complementary advantage two study design cross device collaborative system sharing hybrid reality environment mr environment smartphone realize function controller remote selection manipulation object advantage 2d interaction well applied special task design user interface three level immersion high medium low high immersion provide hybrid user interface combining hololens2 smartphone medium immersion provide 3d user interface represented hololens2 low immersion provide multi touch user interface represented tablet user study show hybrid user interface bring user satisfactory immersion interactive experience also need design accurate efficient input method according interactive taskcomputer_based_training gesture_recognition human_computer_interaction mobile_computing production_engineering_computing smartphones user_interfacesaccurate_input_methods application_systems appropriate_collaborative_interaction_models complementary_advantages cross device_collaborative_system efficient_input_methods fast_2d_gestures handwriting hardware_devices high_immersion hololens2 hybrid_reality_environment hybrid_user_interface input_devices interaction_technologies interactive_experience interactive_tasks low_immersion medium_immersion mixed_reality_environment mobile_phone multitouch_user_interface remote_selection shared_mr_environment smartphone text_input tool_simulation traditional_vr_handle user_experience users_satisfactory_immersion
420,Mixed Reality-Enhanced Intuitive Teleoperation with Hybrid Virtual Fixtures for Intelligent Robotic Welding,"Su, Y.-P., Chen, X.-Q., Zhou, T., Pretty, C., & Chase, G. (2021). Mixed Reality-Enhanced Intuitive Teleoperation with Hybrid Virtual Fixtures for Intelligent Robotic Welding. Applied Sciences, 11(23), 11280. https://doi.org/10.3390/app112311280
",10.3390/app112311280,"This paper presents an integrated scheme based on a mixed reality (MR) and haptic feedback approach for intuitive and immersive teleoperation of robotic welding systems. By incorporating MR technology, the user is fully immersed in a virtual operating space augmented by real-time visual feedback from the robot working space. The proposed robotic tele-welding system features imitative motion mapping from the user's hand movements to the welding robot motions, and it enables the spatial velocity-based control of the robot tool center point (TCP). The proposed mixed reality virtual fixture (MRVF) integration approach implements hybrid haptic constraints to guide the operator's hand movements following the conical guidance to effectively align the welding torch for welding and constrain the welding operation within a collision-free area. Onsite welding and tele-welding experiments identify the operational differences between professional and unskilled welders and demonstrate the effectiveness of the proposed MRVF tele-welding framework for novice welders. The MRVF-integrated visual/haptic tele-welding scheme reduced the torch alignment times by 56% and 60% compared to the MRnoVF and baseline cases, with minimized cognitive workload and optimal usability. The MRVF scheme effectively stabilized welders' hand movements and eliminated undesirable collisions while generating smooth welds.",C3390T Telerobotics;C3120C Spatial variables control;C5540B Interactive-input devices;C6130V Virtual reality;C6180 User interfaces;C7420 Control engineering computing;E1520E Joining processes and welding;E1550A Robotics,haptic feedback approach;hybrid haptic constraints;hybrid virtual fixtures;immersive teleoperation;integrated scheme;intelligent robotic welding;mixed reality virtual fixture integration approach;mixed reality-enhanced intuitive teleoperation;motion mapping;MRVF tele-welding framework;real-time visual feedback;robot tool center point;robot working space;robotic tele-welding system features;spatial velocity-based control;TCP;user hand movements;virtual operating space;welding robot motions;welding torch,augmented reality;collision avoidance;control engineering computing;force feedback;haptic interfaces;intelligent robots;motion control;robotic welding;telerobotics,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Su, Y.-P.; (2) Chen, X.-Q.; (1) Zhou, T.; (1) Pretty, C.; (1) Chase, G.; ","(1) University of Canterbury, Mechanical Engineering Department, New Zealand; (2) Swinburne University of Technology, Manufacturing Futures Research Institute, Australia; ",MDPI,-1,"[""collision avoidance"", ""control engineering computing"", ""force feedback"", ""haptic interfaces"", ""intelligent robots"", ""motion control"", ""robotic welding"", ""telerobotics""]","[""collision avoidance"", ""control engineering computing"", ""force feedback"", ""haptic interfaces"", ""intelligent robots"", ""motion control"", ""robotic welding"", ""telerobotics""]",collision avoidance;control engineering computing;force feedback;haptic interfaces;intelligent robots;motion control;robotic welding;telerobotics,other;robotics;input;automotive;engineering;human-computer interaction;manufacturing,technology;other;end users and user experience;industries,other;robotics;input;automotive;engineering;human-computer interaction;manufacturing,technology;other;end users and user experience;industries,collision_avoidance control_engineering_computing force_feedback haptic_interfaces intelligent_robots motion_control robotic_welding telerobotics haptic_feedback_approach hybrid_haptic_constraints hybrid_virtual_fixtures immersive_teleoperation integrated_scheme intelligent_robotic_welding mixed_reality_virtual_fixture_integration_approach mixed_reality enhanced_intuitive_teleoperation motion_mapping mrvf_tele welding_framework real time_visual_feedback robot_tool_center_point robot_working_space robotic_tele welding_system_features spatial_velocity based_control tcp user_hand_movements virtual_operating_space welding_robot_motions welding_torch c3390t_telerobotics c3120c_spatial_variables_control c5540b_interactive input_devices c6130v_virtual_reality c6180_user_interfaces c7420_control_engineering_computing e1520e_joining_processes_and_welding e1550a_robotics other robotics input automotive engineering human computer_interaction manufacturing,collision_avoidance control_engineering_computing force_feedback haptic_interfaces intelligent_robots motion_control robotic_welding telerobotics,haptic_feedback_approach hybrid_haptic_constraints hybrid_virtual_fixtures immersive_teleoperation integrated_scheme intelligent_robotic_welding mixed_reality_virtual_fixture_integration_approach mixed_reality enhanced_intuitive_teleoperation motion_mapping mrvf_tele welding_framework real time_visual_feedback robot_tool_center_point robot_working_space robotic_tele welding_system_features spatial_velocity based_control tcp user_hand_movements virtual_operating_space welding_robot_motions welding_torch,paper present integrated scheme based mixed reality mr haptic feedback approach intuitive immersive teleoperation robotic welding system incorporating mr technology user fully immersed virtual operating space augmented real time visual feedback robot working space proposed robotic tele welding system feature imitative motion mapping user hand movement welding robot motion enables spatial velocity based control robot tool center point tcp proposed mixed reality virtual fixture mrvf integration approach implement hybrid haptic constraint guide operator hand movement following conical guidance effectively align welding torch welding constrain welding operation within collision free area onsite welding tele welding experiment identify operational difference professional unskilled welder demonstrate effectiveness proposed mrvf tele welding framework novice welder mrvf integrated visual haptic tele welding scheme reduced torch alignment time 56 60 compared mrnovf baseline case minimized cognitive workload optimal usability mrvf scheme effectively stabilized welder hand movement eliminated undesirable collision generating smooth weld,collision_avoidance control_engineering_computing force_feedback haptic_interfaces intelligent_robots motion_control robotic_welding telerobotics haptic_feedback_approach hybrid_haptic_constraints hybrid_virtual_fixtures immersive_teleoperation integrated_scheme intelligent_robotic_welding mixed_reality_virtual_fixture_integration_approach mixed_reality enhanced_intuitive_teleoperation motion_mapping mrvf_tele welding_framework real time_visual_feedback robot_tool_center_point robot_working_space robotic_tele welding_system_features spatial_velocity based_control tcp user_hand_movements virtual_operating_space welding_robot_motions welding_torch c3390t_telerobotics c3120c_spatial_variables_control c5540b_interactive input_devices c6130v_virtual_reality c6180_user_interfaces c7420_control_engineering_computing e1520e_joining_processes_and_welding e1550a_robotics other robotics input automotive engineering human computer_interaction manufacturing paper present integrated scheme based mixed reality mr haptic feedback approach intuitive immersive teleoperation robotic welding system incorporating mr technology user fully immersed virtual operating space augmented real time visual feedback robot working space proposed robotic tele welding system feature imitative motion mapping user hand movement welding robot motion enables spatial velocity based control robot tool center point tcp proposed mixed reality virtual fixture mrvf integration approach implement hybrid haptic constraint guide operator hand movement following conical guidance effectively align welding torch welding constrain welding operation within collision free area onsite welding tele welding experiment identify operational difference professional unskilled welder demonstrate effectiveness proposed mrvf tele welding framework novice welder mrvf integrated visual haptic tele welding scheme reduced torch alignment time 56 60 compared mrnovf baseline case minimized cognitive workload optimal usability mrvf scheme effectively stabilized welder hand movement eliminated undesirable collision generating smooth weld,paper present integrated scheme based mixed reality mr haptic feedback approach intuitive immersive teleoperation robotic welding system incorporating mr technology user fully immersed virtual operating space augmented real time visual feedback robot working space proposed robotic tele welding system feature imitative motion mapping user hand movement welding robot motion enables spatial velocity based control robot tool center point tcp proposed mixed reality virtual fixture mrvf integration approach implement hybrid haptic constraint guide operator hand movement following conical guidance effectively align welding torch welding constrain welding operation within collision free area onsite welding tele welding experiment identify operational difference professional unskilled welder demonstrate effectiveness proposed mrvf tele welding framework novice welder mrvf integrated visual haptic tele welding scheme reduced torch alignment time 56 60 compared mrnovf baseline case minimized cognitive workload optimal usability mrvf scheme effectively stabilized welder hand movement eliminated undesirable collision generating smooth weldcollision_avoidance control_engineering_computing force_feedback haptic_interfaces intelligent_robots motion_control robotic_welding teleroboticshaptic_feedback_approach hybrid_haptic_constraints hybrid_virtual_fixtures immersive_teleoperation integrated_scheme intelligent_robotic_welding mixed_reality_virtual_fixture_integration_approach mixed_reality enhanced_intuitive_teleoperation motion_mapping mrvf_tele welding_framework real time_visual_feedback robot_tool_center_point robot_working_space robotic_tele welding_system_features spatial_velocity based_control tcp user_hand_movements virtual_operating_space welding_robot_motions welding_torch
421,Review: Development and Technical Design of Tangible User Interfaces in Wide-Field Areas of Application,"Krestanova, A., Cerny, M., & Augustynek, M. (2021). Review: Development and Technical Design of Tangible User Interfaces in Wide-Field Areas of Application. Sensors, 21(13), 4258. https://doi.org/10.3390/s21134258
",10.3390/s21134258,"A tangible user interface or TUI connects physical objects and digital interfaces. It is more interactive and interesting for users than a classic graphic user interface. This article presents a descriptive overview of TUI's real-world applications sorted into ten main application areas&#8212;teaching of traditional subjects, medicine and psychology, programming, database development, music and arts, modeling of 3D objects, modeling in architecture, literature and storytelling, adjustable TUI solutions, and commercial TUI smart toys. The paper focuses on TUI's technical solutions and a description of technical constructions that influences the applicability of TUIs in the real world. Based on the review, the technical concept was divided into two main approaches: the sensory technical concept and technology based on a computer vision algorithm. The sensory technical concept is processed to use wireless technology, sensors, and feedback possibilities in TUI applications. The image processing approach is processed to a marker and markerless approach for object recognition, the use of cameras, and the use of computer vision platforms for TUI applications.","B6135 Optical, image and video signal processing;B6135E Image recognition;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C6180G Graphical user interfaces",adjustable TUI solutions;classic graphic user interface;commercial TUI smart toys;database development;descriptive overview;digital interfaces;main application areas&#8212;teaching;physical objects;sensory technical concept;tangible user interface;technical constructions;technical design;TUI applications;TUI's real-world applications;TUI's technical solutions;wide-field areas,augmented reality;computer vision;graphical user interfaces;haptic interfaces;human computer interaction;image processing;object recognition;teaching;user interfaces,2021,Journal article (JA),Sensors (Switzerland),"(1) Krestanova, A.; (1) Cerny, M.; (1) Augustynek, M.; ","(1) VSB-Technical university of Ostrava, Faculty of Electrical Engineering and Computer Science, 17. Listopadu 15, Czech Republic; ",MDPI,-1,"[""computer vision"", ""graphical user interfaces"", ""haptic interfaces"", ""human computer interaction"", ""image processing"", ""object recognition"", ""teaching"", ""user interfaces""]","[""computer vision"", ""graphical user interfaces"", ""haptic interfaces"", ""human computer interaction"", ""image processing"", ""object recognition"", ""teaching"", ""user interfaces""]",computer vision;graphical user interfaces;haptic interfaces;human computer interaction;image processing;object recognition;teaching;user interfaces,computer vision;education;graphics;input;human factors;data;human-computer interaction,technology;end users and user experience;industries,computer vision;education;graphics;input;human factors;data;human-computer interaction,technology;end users and user experience;industries,computer_vision graphical_user_interfaces haptic_interfaces human_computer_interaction image_processing object_recognition teaching user_interfaces adjustable_tui_solutions classic_graphic_user_interface commercial_tui_smart_toys database_development descriptive_overview digital_interfaces main_application_areas 8212 teaching physical_objects sensory_technical_concept tangible_user_interface technical_constructions technical_design tui_applications tui s_real world_applications tui s_technical_solutions wide field_areas b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c6180g_graphical_user_interfaces computer_vision education graphics input human_factors data human computer_interaction,computer_vision graphical_user_interfaces haptic_interfaces human_computer_interaction image_processing object_recognition teaching user_interfaces,adjustable_tui_solutions classic_graphic_user_interface commercial_tui_smart_toys database_development descriptive_overview digital_interfaces main_application_areas 8212 teaching physical_objects sensory_technical_concept tangible_user_interface technical_constructions technical_design tui_applications tui s_real world_applications tui s_technical_solutions wide field_areas,tangible user interface tui connects physical object digital interface interactive interesting user classic graphic user interface article present descriptive overview tui real world application sorted ten main application area 8212 teaching traditional subject medicine psychology programming database development music art modeling 3d object modeling architecture literature storytelling adjustable tui solution commercial tui smart toy paper focus tui technical solution description technical construction influence applicability tuis real world based review technical concept divided two main approach sensory technical concept technology based computer vision algorithm sensory technical concept processed use wireless technology sensor feedback possibility tui application image processing approach processed marker markerless approach object recognition use camera use computer vision platform tui application,computer_vision graphical_user_interfaces haptic_interfaces human_computer_interaction image_processing object_recognition teaching user_interfaces adjustable_tui_solutions classic_graphic_user_interface commercial_tui_smart_toys database_development descriptive_overview digital_interfaces main_application_areas 8212 teaching physical_objects sensory_technical_concept tangible_user_interface technical_constructions technical_design tui_applications tui s_real world_applications tui s_technical_solutions wide field_areas b6135_optical _image_and_video_signal_processing b6135e_image_recognition c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c6180g_graphical_user_interfaces computer_vision education graphics input human_factors data human computer_interaction tangible user interface tui connects physical object digital interface interactive interesting user classic graphic user interface article present descriptive overview tui real world application sorted ten main application area 8212 teaching traditional subject medicine psychology programming database development music art modeling 3d object modeling architecture literature storytelling adjustable tui solution commercial tui smart toy paper focus tui technical solution description technical construction influence applicability tuis real world based review technical concept divided two main approach sensory technical concept technology based computer vision algorithm sensory technical concept processed use wireless technology sensor feedback possibility tui application image processing approach processed marker markerless approach object recognition use camera use computer vision platform tui application,tangible user interface tui connects physical object digital interface interactive interesting user classic graphic user interface article present descriptive overview tui real world application sorted ten main application area 8212 teaching traditional subject medicine psychology programming database development music art modeling 3d object modeling architecture literature storytelling adjustable tui solution commercial tui smart toy paper focus tui technical solution description technical construction influence applicability tuis real world based review technical concept divided two main approach sensory technical concept technology based computer vision algorithm sensory technical concept processed use wireless technology sensor feedback possibility tui application image processing approach processed marker markerless approach object recognition use camera use computer vision platform tui applicationcomputer_vision graphical_user_interfaces haptic_interfaces human_computer_interaction image_processing object_recognition teaching user_interfacesadjustable_tui_solutions classic_graphic_user_interface commercial_tui_smart_toys database_development descriptive_overview digital_interfaces main_application_areas 8212 teaching physical_objects sensory_technical_concept tangible_user_interface technical_constructions technical_design tui_applications tui s_real world_applications tui s_technical_solutions wide field_areas
422,Compact optical system displaying mid-air images movable in depth by rotating light source and mirror,"Osato, Y., & Koizumi, N. (2020). Compact optical system displaying mid-air images movable in depth by rotating light source and mirror. Computers &amp; Graphics, 91, 290–300. https://doi.org/10.1016/j.cag.2020.08.006
",10.1016/j.cag.2020.08.006,"Mid-air imaging technology enables computer graphics (CG) images to move around in the real world. However, the big form-factor of large-format mid-air displays makes them bulky and limits their applicability. To reduce the size of such displays, we propose an optical design that realizes mid-air image movement by rotating the reflecting surface and the light source with motors and thus moving the virtual image of the light source. We made a prototype based on the calculation of the mirror and display angles and the distance between them and evaluated the luminance, sharpness, and position of the mid-air image of this prototype. We confirmed that the size of the prototype was smaller than that produced by the previous method, which will allow a smaller form-factor for creating mid-air images for different applications. [All rights reserved Elsevier].","A4215E Optical system design;B6135 Optical, image and video signal processing;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces",compact optical system;computer graphics images;display angles;light source;mirror;virtual image,augmented reality;computer graphics;human computer interaction;interactive devices;light sources;mirrors;optical design techniques;reflectivity;screens (display),2020,Journal article (JA),Comput. Graph. (Netherlands),"(1) Osato, Y.; (None) Koizumi, N.; ","(1) University of Electro-Communications, 1-5-1 Chofugaoka, Japan; ",Elsevier B.V.,-1,"[""computer graphics"", ""human computer interaction"", ""interactive devices"", ""light sources"", ""mirrors"", ""optical design techniques"", ""reflectivity"", ""display screens""]","[""computer graphics"", ""human computer interaction"", ""interactive devices"", ""light sources"", ""mirrors"", ""optical design techniques"", ""reflectivity"", ""display screens""]",computer graphics;human computer interaction;interactive devices;light sources;mirrors;optical design techniques;reflectivity;display screens,graphics;input;optics;chemical;display technology;human-computer interaction,technology;end users and user experience;displays;industries,graphics;input;optics;chemical;display technology;human-computer interaction,technology;end users and user experience;displays;industries,computer_graphics human_computer_interaction interactive_devices light_sources mirrors optical_design_techniques reflectivity display_screens compact_optical_system computer_graphics_images display_angles light_source mirror virtual_image a4215e_optical_system_design b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces graphics input optics chemical display_technology human computer_interaction,computer_graphics human_computer_interaction interactive_devices light_sources mirrors optical_design_techniques reflectivity display_screens,compact_optical_system computer_graphics_images display_angles light_source mirror virtual_image,mid air imaging technology enables computer graphic cg image move around real world however big form factor large format mid air display make bulky limit applicability reduce size display propose optical design realizes mid air image movement rotating reflecting surface light source motor thus moving virtual image light source made prototype based calculation mirror display angle distance evaluated luminance sharpness position mid air image prototype confirmed size prototype smaller produced previous method allow smaller form factor creating mid air image different application right reserved elsevier,computer_graphics human_computer_interaction interactive_devices light_sources mirrors optical_design_techniques reflectivity display_screens compact_optical_system computer_graphics_images display_angles light_source mirror virtual_image a4215e_optical_system_design b6135_optical _image_and_video_signal_processing c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces graphics input optics chemical display_technology human computer_interaction mid air imaging technology enables computer graphic cg image move around real world however big form factor large format mid air display make bulky limit applicability reduce size display propose optical design realizes mid air image movement rotating reflecting surface light source motor thus moving virtual image light source made prototype based calculation mirror display angle distance evaluated luminance sharpness position mid air image prototype confirmed size prototype smaller produced previous method allow smaller form factor creating mid air image different application right reserved elsevier,mid air imaging technology enables computer graphic cg image move around real world however big form factor large format mid air display make bulky limit applicability reduce size display propose optical design realizes mid air image movement rotating reflecting surface light source motor thus moving virtual image light source made prototype based calculation mirror display angle distance evaluated luminance sharpness position mid air image prototype confirmed size prototype smaller produced previous method allow smaller form factor creating mid air image different application right reserved elseviercomputer_graphics human_computer_interaction interactive_devices light_sources mirrors optical_design_techniques reflectivity display_screenscompact_optical_system computer_graphics_images display_angles light_source mirror virtual_image
423,Large-Scale Dynamic Spectrum Access with IEEE 1900.5.2 Spectrum Consumption Models,"Netalkar, P., Zahabee, A., Caicedo Bastidas, C. E., Kadota, I., Stojadinovic, D., Zussman, G., Seskar, I., & Raychaudhuri, D. (2023). Large-Scale Dynamic Spectrum Access with IEEE 1900.5.2 Spectrum Consumption Models. 2023 IEEE Wireless Communications and Networking Conference (WCNC). https://doi.org/10.1109/wcnc55385.2023.10118670
",10.1109/WCNC55385.2023.10118670,"Next generation wireless services and applications, including Augmented Reality, Internet-of-Things, and Smart-Cities, will increasingly rely on Dynamic Spectrum Access (DSA) methods that can manage spectrum resources rapidly and efficiently. Advances in regulatory policies, standardization, networking, and wireless technology are enabling DSA methods on a more granular basis in terms of time, frequency, and geographical location which are key for the operation of 5G and beyond-5G networks. In this context, this paper proposes a novel DSA algorithm that leverages IEEE 1900.5.2 Spectrum Consumption Models (SCMs) which offer a mechanism for RF devices to: (i) ""announce"" or ""declare"" their intention to use the spectrum and their needs in terms of interference protection; and (ii) determine compatibility (i.e., non-interference) with existing devices. In this paper, we develop an SCM-based DSA algorithm for spectrum deconfliction in large-scale wireless network environments and evaluate this algorithm in terms of computation time, efficiency of spectrum allocation, and number of device reconfigurations due to interference using a custom simulation platform. The results demonstrate the benefits of using SCMs and their capabilities to perform fine grained spectrum assignments in dynamic and dense communication environments.","B6250F Mobile radio systems;B6210L Computer communications;B6410 Legislation, frequency allocation and spectrum pollution;C7410F Communications computing",Augmented Reality;beyond-5G networks;custom simulation platform;dense communication environments;device reconfigurations;DSA methods;dynamic communication environments;Dynamic Spectrum Access methods;fine grained spectrum assignments;geographical location;IEEE 1900.5.2 Spectrum Consumption Models;interference protection;Internet-of-Things;large-scale Dynamic Spectrum Access;large-scale wireless network environments;next generation wireless services;regulatory policies;RF devices;SCM-based DSA algorithm;Smart-Cities;spectrum allocation;spectrum deconfliction;spectrum resource management;wireless technology,5G mobile communication;IEEE standards;next generation networks;radio networks;radio spectrum management;resource allocation;telecommunication computing,2023,Conference article (CA),2023 IEEE Wireless Communications and Networking Conference (WCNC),"(1) Netalkar, P.; (2) Zahabee, A.; (3) Caicedo Bastidas, C.E.; (2) Kadota, I.; (1) Stojadinovic, D.; (2) Zussman, G.; (1) Seskar, I.; (1) Raychaudhuri, D.; ","(1) Rutgers University, WINLAB, North Brunswick, NJ, United States; (2) Columbia University, United States; (3) Syracuse University, United States; ",IEEE,-1,"[""5g mobile communication"", ""ieee standards"", ""next generation networks"", ""radio networks"", ""radio spectrum management"", ""resource allocation"", ""telecommunication computing""]","[""5g mobile communication"", ""ieee standards"", ""next generation networks"", ""radio networks"", ""radio spectrum management"", ""resource allocation"", ""telecommunication computing""]",5g mobile communication;ieee standards;next generation networks;radio networks;radio spectrum management;resource allocation;telecommunication computing,other;input;telecommunication;standards;geospatial;business planning and management;networks,other;business;industries;standards;technology,other;input;telecommunication;standards;geospatial;business planning and management;networks,other;business;industries;standards;technology,5g_mobile_communication ieee_standards next_generation_networks radio_networks radio_spectrum_management resource_allocation telecommunication_computing augmented_reality beyond 5g_networks custom_simulation_platform dense_communication_environments device_reconfigurations dsa_methods dynamic_communication_environments dynamic_spectrum_access_methods fine_grained_spectrum_assignments geographical_location ieee_1900 5 2_spectrum_consumption_models interference_protection internet of things large scale_dynamic_spectrum_access large scale_wireless_network_environments next_generation_wireless_services regulatory_policies rf_devices scm based_dsa_algorithm smart cities spectrum_allocation spectrum_deconfliction spectrum_resource_management wireless_technology b6250f_mobile_radio_systems b6210l_computer_communications b6410_legislation _frequency_allocation_and_spectrum_pollution c7410f_communications_computing other input telecommunication standards geospatial business_planning_and_management networks,5g_mobile_communication ieee_standards next_generation_networks radio_networks radio_spectrum_management resource_allocation telecommunication_computing,augmented_reality beyond 5g_networks custom_simulation_platform dense_communication_environments device_reconfigurations dsa_methods dynamic_communication_environments dynamic_spectrum_access_methods fine_grained_spectrum_assignments geographical_location ieee_1900 5 2_spectrum_consumption_models interference_protection internet of things large scale_dynamic_spectrum_access large scale_wireless_network_environments next_generation_wireless_services regulatory_policies rf_devices scm based_dsa_algorithm smart cities spectrum_allocation spectrum_deconfliction spectrum_resource_management wireless_technology,next generation wireless service application including augmented reality internet thing smart city increasingly rely dynamic spectrum access dsa method manage spectrum resource rapidly efficiently advance regulatory policy standardization networking wireless technology enabling dsa method granular basis term time frequency geographical location key operation 5g beyond 5g network context paper proposes novel dsa algorithm leverage ieee 1900 5 2 spectrum consumption model scms offer mechanism rf device announce declare intention use spectrum need term interference protection ii determine compatibility e non interference existing device paper develop scm based dsa algorithm spectrum deconfliction large scale wireless network environment evaluate algorithm term computation time efficiency spectrum allocation number device reconfigurations due interference using custom simulation platform result demonstrate benefit using scms capability perform fine grained spectrum assignment dynamic dense communication environment,5g_mobile_communication ieee_standards next_generation_networks radio_networks radio_spectrum_management resource_allocation telecommunication_computing augmented_reality beyond 5g_networks custom_simulation_platform dense_communication_environments device_reconfigurations dsa_methods dynamic_communication_environments dynamic_spectrum_access_methods fine_grained_spectrum_assignments geographical_location ieee_1900 5 2_spectrum_consumption_models interference_protection internet of things large scale_dynamic_spectrum_access large scale_wireless_network_environments next_generation_wireless_services regulatory_policies rf_devices scm based_dsa_algorithm smart cities spectrum_allocation spectrum_deconfliction spectrum_resource_management wireless_technology b6250f_mobile_radio_systems b6210l_computer_communications b6410_legislation _frequency_allocation_and_spectrum_pollution c7410f_communications_computing other input telecommunication standards geospatial business_planning_and_management networks next generation wireless service application including augmented reality internet thing smart city increasingly rely dynamic spectrum access dsa method manage spectrum resource rapidly efficiently advance regulatory policy standardization networking wireless technology enabling dsa method granular basis term time frequency geographical location key operation 5g beyond 5g network context paper proposes novel dsa algorithm leverage ieee 1900 5 2 spectrum consumption model scms offer mechanism rf device announce declare intention use spectrum need term interference protection ii determine compatibility e non interference existing device paper develop scm based dsa algorithm spectrum deconfliction large scale wireless network environment evaluate algorithm term computation time efficiency spectrum allocation number device reconfigurations due interference using custom simulation platform result demonstrate benefit using scms capability perform fine grained spectrum assignment dynamic dense communication environment,next generation wireless service application including augmented reality internet thing smart city increasingly rely dynamic spectrum access dsa method manage spectrum resource rapidly efficiently advance regulatory policy standardization networking wireless technology enabling dsa method granular basis term time frequency geographical location key operation 5g beyond 5g network context paper proposes novel dsa algorithm leverage ieee 1900 5 2 spectrum consumption model scms offer mechanism rf device announce declare intention use spectrum need term interference protection ii determine compatibility e non interference existing device paper develop scm based dsa algorithm spectrum deconfliction large scale wireless network environment evaluate algorithm term computation time efficiency spectrum allocation number device reconfigurations due interference using custom simulation platform result demonstrate benefit using scms capability perform fine grained spectrum assignment dynamic dense communication environment5g_mobile_communication ieee_standards next_generation_networks radio_networks radio_spectrum_management resource_allocation telecommunication_computingaugmented_reality beyond 5g_networks custom_simulation_platform dense_communication_environments device_reconfigurations dsa_methods dynamic_communication_environments dynamic_spectrum_access_methods fine_grained_spectrum_assignments geographical_location ieee_1900 5 2_spectrum_consumption_models interference_protection internet of things large scale_dynamic_spectrum_access large scale_wireless_network_environments next_generation_wireless_services regulatory_policies rf_devices scm based_dsa_algorithm smart cities spectrum_allocation spectrum_deconfliction spectrum_resource_management wireless_technology
424,HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies,"Chulpongsatorn, N., Willett, W., & Suzuki, R. (2023). HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585738
",10.1145/3544549.3585738,"We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts.","B4350 Holography;C5260B Computer vision and image processing techniques;C5540B Interactive-input devices;C5540D Computer displays;C6130B Graphics techniques;C6130V Virtual reality;C6180 User interfaces;C6190V Mobile, ubiquitous and pervasive computing;C7330 Biology and medical computing",6 interaction techniques;combined physicality;current MR visualizations;data physicalizations;dynamic modification;dynamic visualizations;head-mounted displays;high-resolution 2D graphics;HMDs;HoloTouch;imprecise input;interactive modification;low visual resolution;low-resolution holographic 3D charts;mixed reality visualizations;mobile devices;mobile touchscreens;MR data interactions;natural physical manipulation;physical charts;physical proxies;physical visualizations;precise touch input;rich input;smartphone proxies;smartphones;support precise manipulation;tablets;unreliable tracking,augmented reality;data visualisation;haptic interfaces;helmet mounted displays;human computer interaction;image resolution;medical computing;mobile computing;smart phones;touch sensitive screens;virtual reality,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Chulpongsatorn, N.; (2) Willett, W.; (2) Suzuki, R.; ","(1) University of Calgary, Computer Science, Calgary, AB, Canada; (2) University of Calgary, Calgary, AB, Canada; ",ACM,-1,"[""data visualization"", ""haptic interfaces"", ""helmet mounted displays"", ""human computer interaction"", ""image resolution"", ""medical computing"", ""mobile computing"", ""smartphones"", ""touch screens""]","[""data visualization"", ""haptic interfaces"", ""helmet mounted displays"", ""human computer interaction"", ""image resolution"", ""medical computing"", ""mobile computing"", ""smartphones"", ""touch screens""]",data visualization;haptic interfaces;helmet mounted displays;human computer interaction;image resolution;medical computing;mobile computing;smartphones;touch screens,graphics;input;liberal arts;medical;display technology;telecommunication;wearables;data;human-computer interaction,technology;industries;displays;end users and user experience,graphics;input;liberal arts;medical;display technology;telecommunication;wearables;data;human-computer interaction,technology;industries;displays;end users and user experience,data_visualization haptic_interfaces helmet_mounted_displays human_computer_interaction image_resolution medical_computing mobile_computing smartphones touch_screens 6_interaction_techniques combined_physicality current_mr_visualizations data_physicalizations dynamic_modification dynamic_visualizations head mounted_displays high resolution_2d_graphics hmds holotouch imprecise_input interactive_modification low_visual_resolution low resolution_holographic_3d_charts mixed_reality_visualizations mobile_devices mobile_touchscreens mr_data_interactions natural_physical_manipulation physical_charts physical_proxies physical_visualizations precise_touch_input rich_input smartphone_proxies smartphones support_precise_manipulation tablets unreliable_tracking b4350_holography c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing graphics input liberal_arts medical display_technology telecommunication wearables data human computer_interaction,data_visualization haptic_interfaces helmet_mounted_displays human_computer_interaction image_resolution medical_computing mobile_computing smartphones touch_screens,6_interaction_techniques combined_physicality current_mr_visualizations data_physicalizations dynamic_modification dynamic_visualizations head mounted_displays high resolution_2d_graphics hmds holotouch imprecise_input interactive_modification low_visual_resolution low resolution_holographic_3d_charts mixed_reality_visualizations mobile_devices mobile_touchscreens mr_data_interactions natural_physical_manipulation physical_charts physical_proxies physical_visualizations precise_touch_input rich_input smartphone_proxies smartphones support_precise_manipulation tablets unreliable_tracking,contribute interaction technique augmenting mixed reality mr visualization smartphone proxy combining head mounted display hmds mobile touchscreen augment low resolution holographic 3d chart precise touch input haptics feedback high resolution 2d graphic physical manipulation approach aim complement mr physical visualization current mr visualization suffer unreliable tracking low visual resolution imprecise input data physicalizations hand although allowing natural physical manipulation limited dynamic interactive modification demonstrate mobile device smartphones tablet serve physical proxy mr data interaction creating dynamic visualization support precise manipulation rich input output describe 6 interaction technique leverage combined physicality sensing output capability hmds smartphones demonstrate interaction via prototype system based evaluation outline opportunity combining advantage mr physical chart,data_visualization haptic_interfaces helmet_mounted_displays human_computer_interaction image_resolution medical_computing mobile_computing smartphones touch_screens 6_interaction_techniques combined_physicality current_mr_visualizations data_physicalizations dynamic_modification dynamic_visualizations head mounted_displays high resolution_2d_graphics hmds holotouch imprecise_input interactive_modification low_visual_resolution low resolution_holographic_3d_charts mixed_reality_visualizations mobile_devices mobile_touchscreens mr_data_interactions natural_physical_manipulation physical_charts physical_proxies physical_visualizations precise_touch_input rich_input smartphone_proxies smartphones support_precise_manipulation tablets unreliable_tracking b4350_holography c5260b_computer_vision_and_image_processing_techniques c5540b_interactive input_devices c5540d_computer_displays c6130b_graphics_techniques c6130v_virtual_reality c6180_user_interfaces c6190v_mobile _ubiquitous_and_pervasive_computing c7330_biology_and_medical_computing graphics input liberal_arts medical display_technology telecommunication wearables data human computer_interaction contribute interaction technique augmenting mixed reality mr visualization smartphone proxy combining head mounted display hmds mobile touchscreen augment low resolution holographic 3d chart precise touch input haptics feedback high resolution 2d graphic physical manipulation approach aim complement mr physical visualization current mr visualization suffer unreliable tracking low visual resolution imprecise input data physicalizations hand although allowing natural physical manipulation limited dynamic interactive modification demonstrate mobile device smartphones tablet serve physical proxy mr data interaction creating dynamic visualization support precise manipulation rich input output describe 6 interaction technique leverage combined physicality sensing output capability hmds smartphones demonstrate interaction via prototype system based evaluation outline opportunity combining advantage mr physical chart,contribute interaction technique augmenting mixed reality mr visualization smartphone proxy combining head mounted display hmds mobile touchscreen augment low resolution holographic 3d chart precise touch input haptics feedback high resolution 2d graphic physical manipulation approach aim complement mr physical visualization current mr visualization suffer unreliable tracking low visual resolution imprecise input data physicalizations hand although allowing natural physical manipulation limited dynamic interactive modification demonstrate mobile device smartphones tablet serve physical proxy mr data interaction creating dynamic visualization support precise manipulation rich input output describe 6 interaction technique leverage combined physicality sensing output capability hmds smartphones demonstrate interaction via prototype system based evaluation outline opportunity combining advantage mr physical chartdata_visualization haptic_interfaces helmet_mounted_displays human_computer_interaction image_resolution medical_computing mobile_computing smartphones touch_screens6_interaction_techniques combined_physicality current_mr_visualizations data_physicalizations dynamic_modification dynamic_visualizations head mounted_displays high resolution_2d_graphics hmds holotouch imprecise_input interactive_modification low_visual_resolution low resolution_holographic_3d_charts mixed_reality_visualizations mobile_devices mobile_touchscreens mr_data_interactions natural_physical_manipulation physical_charts physical_proxies physical_visualizations precise_touch_input rich_input smartphone_proxies smartphones support_precise_manipulation tablets unreliable_tracking
425,dVPose: Automated Data Collection and Dataset for 6D Pose Estimation of Robotic Surgical Instruments,"Greene, N., Luo, W., & Kazanzides, P. (2023). dVPose: Automated Data Collection and Dataset for 6D Pose Estimation of Robotic Surgical Instruments. 2023 International Symposium on Medical Robotics (ISMR). https://doi.org/10.1109/ismr57123.2023.10130238
",10.1109/ISMR57123.2023.10130238,"We present dVPose, a realistic multi-modality dataset intended for use in the development and evaluation of real-time single-shot deep-learning based 6D pose estimation algorithms on a head mounted display (HMD). In addition to the dataset, our contribution includes an automated (robotic) data collection platform that integrates an accurate optical tracking system to provide the ground-truth poses. We collected a comprehensive set of data for vision-based 6D pose estimation, including images and poses of the extra-corporeal portions of the instruments and endoscope of a da Vinci surgical robot. The images are collected using the multi-camera rig of the Microsoft HoloLens 2 HMD, mounted on a UR10 robot, and the corresponding poses are collected by optically tracking both the instruments/endoscope and HMD. The intended application is to enable markerless localization of the HMD with respect to the da Vinci robot, considering that the instruments and endoscope are among the few robotic components that are not covered by sterile drapes. Our dataset features synchronized images from the RGB, depth, and grayscale cameras of the HoloLens 2 device. It is unique in that it provides medically focused images, provides images from a HoloLens 2 device where object tracking is a fundamental task, and provides data from multiple visible-light cameras in addition to depth. Furthermore, the automated data collection platform can be easily adapted to collect images and ground-truth poses of other objects.","A8770E Patient diagnostic methods and instrumentation;B6135 Optical, image and video signal processing;B6135E Image recognition;B7230G Image sensors;C3385 Biological and medical control systems;C3390 Robotics;C5260B Computer vision and image processing techniques;C6130V Virtual reality;C6264 Neural nets",accurate optical tracking system;automated data collection platform;collect images;corresponding poses;da Vinci robot;da Vinci surgical robot;dVPose;extra-corporeal portions;ground-truth poses;HoloLens 2 device;Microsoft HoloLens 2 HMD;multicamera rig;realistic multimodality dataset;robotic components;robotic surgical instruments;single-shot deep-learning based 6D pose estimation algorithms;UR10 robot;vision-based 6D pose estimation,augmented reality;cameras;computer vision;deep learning (artificial intelligence);endoscopes;helmet mounted displays;image colour analysis;image sensors;medical robotics;object tracking;optical tracking;pose estimation;robot vision;surgery,2023,Conference article (CA),2023 International Symposium on Medical Robotics (ISMR),"(1) Greene, N.; (1) Luo, W.; (1) Kazanzides, P.; ","(1) Johns Hopkins University, Department of Computer Science, Baltimore, MD 21218, United States; ",IEEE,-1,"[""cameras"", ""computer vision"", ""deep learning (artificial intelligence)"", ""endoscopes"", ""helmet mounted displays"", ""image colour analysis"", ""image sensors"", ""medical robotics"", ""object tracking"", ""optical tracking"", ""pose estimation"", ""robot vision"", ""surgery""]","[""cameras"", ""computer vision"", ""deep learning (artificial intelligence)"", ""endoscopes"", ""helmet mounted displays"", ""image colour analysis"", ""image sensors"", ""medical robotics"", ""object tracking"", ""optical tracking"", ""pose estimation"", ""robot vision"", ""surgery""]",cameras;computer vision;deep learning (artificial intelligence);endoscopes;helmet mounted displays;image colour analysis;image sensors;medical robotics;object tracking;optical tracking;pose estimation;robot vision;surgery,computer vision;other;graphics;robotics;input;liberal arts;medical;sensors;display technology;wearables;artificial intelligence,technology;other;displays;industries,computer vision;other;graphics;robotics;input;liberal arts;medical;sensors;display technology;wearables;artificial intelligence,technology;other;displays;industries,cameras computer_vision deep_learning_ artificial_intelligence endoscopes helmet_mounted_displays image_colour_analysis image_sensors medical_robotics object_tracking optical_tracking pose_estimation robot_vision surgery accurate_optical_tracking_system automated_data_collection_platform collect_images corresponding_poses da_vinci_robot da_vinci_surgical_robot dvpose extra corporeal_portions ground truth_poses hololens_2_device microsoft_hololens_2_hmd multicamera_rig realistic_multimodality_dataset robotic_components robotic_surgical_instruments single shot_deep learning_based_6d_pose_estimation_algorithms ur10_robot vision based_6d_pose_estimation a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b6135e_image_recognition b7230g_image_sensors c3385_biological_and_medical_control_systems c3390_robotics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics robotics input liberal_arts medical sensors display_technology wearables artificial_intelligence,cameras computer_vision deep_learning_ artificial_intelligence endoscopes helmet_mounted_displays image_colour_analysis image_sensors medical_robotics object_tracking optical_tracking pose_estimation robot_vision surgery,accurate_optical_tracking_system automated_data_collection_platform collect_images corresponding_poses da_vinci_robot da_vinci_surgical_robot dvpose extra corporeal_portions ground truth_poses hololens_2_device microsoft_hololens_2_hmd multicamera_rig realistic_multimodality_dataset robotic_components robotic_surgical_instruments single shot_deep learning_based_6d_pose_estimation_algorithms ur10_robot vision based_6d_pose_estimation,present dvpose realistic multi modality dataset intended use development evaluation real time single shot deep learning based 6d pose estimation algorithm head mounted display hmd addition dataset contribution includes automated robotic data collection platform integrates accurate optical tracking system provide ground truth pose collected comprehensive set data vision based 6d pose estimation including image pose extra corporeal portion instrument endoscope da vinci surgical robot image collected using multi camera rig microsoft hololens 2 hmd mounted ur10 robot corresponding pose collected optically tracking instrument endoscope hmd intended application enable markerless localization hmd respect da vinci robot considering instrument endoscope among robotic component covered sterile drape dataset feature synchronized image rgb depth grayscale camera hololens 2 device unique provides medically focused image provides image hololens 2 device object tracking fundamental task provides data multiple visible light camera addition depth furthermore automated data collection platform easily adapted collect image ground truth pose object,cameras computer_vision deep_learning_ artificial_intelligence endoscopes helmet_mounted_displays image_colour_analysis image_sensors medical_robotics object_tracking optical_tracking pose_estimation robot_vision surgery accurate_optical_tracking_system automated_data_collection_platform collect_images corresponding_poses da_vinci_robot da_vinci_surgical_robot dvpose extra corporeal_portions ground truth_poses hololens_2_device microsoft_hololens_2_hmd multicamera_rig realistic_multimodality_dataset robotic_components robotic_surgical_instruments single shot_deep learning_based_6d_pose_estimation_algorithms ur10_robot vision based_6d_pose_estimation a8770e_patient_diagnostic_methods_and_instrumentation b6135_optical _image_and_video_signal_processing b6135e_image_recognition b7230g_image_sensors c3385_biological_and_medical_control_systems c3390_robotics c5260b_computer_vision_and_image_processing_techniques c6130v_virtual_reality c6264_neural_nets computer_vision other graphics robotics input liberal_arts medical sensors display_technology wearables artificial_intelligence present dvpose realistic multi modality dataset intended use development evaluation real time single shot deep learning based 6d pose estimation algorithm head mounted display hmd addition dataset contribution includes automated robotic data collection platform integrates accurate optical tracking system provide ground truth pose collected comprehensive set data vision based 6d pose estimation including image pose extra corporeal portion instrument endoscope da vinci surgical robot image collected using multi camera rig microsoft hololens 2 hmd mounted ur10 robot corresponding pose collected optically tracking instrument endoscope hmd intended application enable markerless localization hmd respect da vinci robot considering instrument endoscope among robotic component covered sterile drape dataset feature synchronized image rgb depth grayscale camera hololens 2 device unique provides medically focused image provides image hololens 2 device object tracking fundamental task provides data multiple visible light camera addition depth furthermore automated data collection platform easily adapted collect image ground truth pose object,present dvpose realistic multi modality dataset intended use development evaluation real time single shot deep learning based 6d pose estimation algorithm head mounted display hmd addition dataset contribution includes automated robotic data collection platform integrates accurate optical tracking system provide ground truth pose collected comprehensive set data vision based 6d pose estimation including image pose extra corporeal portion instrument endoscope da vinci surgical robot image collected using multi camera rig microsoft hololens 2 hmd mounted ur10 robot corresponding pose collected optically tracking instrument endoscope hmd intended application enable markerless localization hmd respect da vinci robot considering instrument endoscope among robotic component covered sterile drape dataset feature synchronized image rgb depth grayscale camera hololens 2 device unique provides medically focused image provides image hololens 2 device object tracking fundamental task provides data multiple visible light camera addition depth furthermore automated data collection platform easily adapted collect image ground truth pose objectcameras computer_vision deep_learning_ artificial_intelligence endoscopes helmet_mounted_displays image_colour_analysis image_sensors medical_robotics object_tracking optical_tracking pose_estimation robot_vision surgeryaccurate_optical_tracking_system automated_data_collection_platform collect_images corresponding_poses da_vinci_robot da_vinci_surgical_robot dvpose extra corporeal_portions ground truth_poses hololens_2_device microsoft_hololens_2_hmd multicamera_rig realistic_multimodality_dataset robotic_components robotic_surgical_instruments single shot_deep learning_based_6d_pose_estimation_algorithms ur10_robot vision based_6d_pose_estimation
426,ML-Aided Dynamic Clustering and Classification of UEs as VBs in D2D Communication Networks,"Ioannou, I., Nagaradjane, P., Khalifeh, A., Christophorou, C., Vassiliou, V., Sashank, G. V. S., Jain, C., & Pitsillides, A. (2023). ML-Aided Dynamic Clustering and Classification of UEs as VBs in D2D Communication Networks. 2023 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET). https://doi.org/10.1109/wispnet57748.2023.10134336
",10.1109/WiSPNET57748.2023.10134336,"With the next generation of mobile devices and streaming services such as Virtual Reality, Augmented Reality, and Meta being available worldwide, the network's data rate, latency, and connectivity must be improved. Even though 5G provides the user with the required Quality of Service (QoS) in terms of data rate and reduced delays by transmitting signals in the higher frequencies (called New Radio (NR)), it faces a lot of attenuation, leading to a short communication range. However, to meet goals set by utilising 6G requirements, many technological advancements and components must be incorporated into the network. The dense disposition of small cells will help reduce the network traffic in hotspot areas and increase the coverage and spectral efficiency. Nonetheless, the current deployment of 5G Base Stations (BSs) and small cells is static and cannot move around even though they are deployed in hot spot areas, leading to high operational costs. Furthermore, more than these static deployments of base stations can be required in an unpredictable scenario of extreme crowd movement. To overcome these issues, Device to Device (D2D) Communication with the dynamic deployment of Virtual Base stations (VBSs) can be called upon, which can be achieved by using User Equipment (UE) such as phones or laptops to mimic the functions of a Base Station (BS). Therefore, in this paper, a User Equipment based Virtual Base Station (UE-VBS) is studied, which will act as a secondary base station and, in turn, help alleviate the traffic load in the network. Specifically, as one UE cannot relieve the entire network traffic load, the network area is split into different clusters by using an unsupervised Machine Learning (ML) clustering technique(i.e., K-Means with Mean Shift Clustering), and a single UE is selected to act as a VBS for that cluster with the utilisation of supervised ML classification techniques (i.e., Decision Trees, Logistic Regression, Linear Discriminant Analysis And Quadratic Discriminant Analysis, Linear Support Vector). In our work, we utilise the K-means along with mean shift clustering techniques to cluster simulated network areas accurately. Also, we use and compare different classification machine learning techniques to predict/classify whether user equipment can be employed as a VBS and become UE-VBs. Our simulation study reveals that the Decision Tree algorithm achieves the highest accuracy in categorising the eligible UEs as UE-VBs.",B6250F Mobile radio systems;B0240V Regression analysis;B0250 Combinatorial mathematics;C1140V Regression analysis;C1160 Combinatorial mathematics;C6130 Data handling techniques;C6262 Unsupervised learning;C7410F Communications computing,6G requirements;augmented reality;cluster simulated network areas;D2D communication networks;data rate;decision tree algorithm;device communication;device to device communication;dynamic deployment;hotspot areas;K-means;linear discriminant analysis;linear support vector;mean shift clustering;ML-aided dynamic clustering;mobile devices;network traffic load;QoS;quadratic discriminant analysis;quality of service;secondary base station;short communication range;static deployments;streaming services;supervised ML classification techniques;technological advancements;UE-VBS;unsupervised machine learning clustering;user equipment;virtual base station;virtual reality,5G mobile communication;6G mobile communication;cellular radio;decision trees;logistic regression;pattern classification;pattern clustering;quality of service;telecommunication computing;telecommunication traffic;unsupervised learning,2023,Conference article (CA),2023 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET),"(1) Ioannou, I.; (3) Nagaradjane, P.; (4) Khalifeh, A.; (1) Christophorou, C.; (1) Vassiliou, V.; (3) Sashank, G.V.S.; (3) Jain, C.; (1) Pitsillides, A.; ","(1) University of Cyprus, Department of Computer Science, Cyprus; (2) CYENS - Centre of Excellence, Cyprus; (3) Sri Sivasubramaniya Nadar College of Engineering, Department of ECE, India; (4) German Jordanian University, Department of Electrical Engineering and Information Technology; (5) University of Johannesburg, Department of Electrical & Electronic Engineering; ",IEEE,-1,"[""5g mobile communication"", ""6g mobile communication"", ""cellular radio"", ""decision trees"", ""logistic regression"", ""pattern classification"", ""pattern clustering"", ""quality of service"", ""telecommunication computing"", ""telecommunication traffic"", ""unsupervised learning""]","[""5g mobile communication"", ""6g mobile communication"", ""cellular radio"", ""decision trees"", ""logistic regression"", ""pattern classification"", ""pattern clustering"", ""quality of service"", ""telecommunication computing"", ""telecommunication traffic"", ""unsupervised learning""]",5g mobile communication;6g mobile communication;cellular radio;decision trees;logistic regression;pattern classification;pattern clustering;quality of service;telecommunication computing;telecommunication traffic;unsupervised learning,computer vision;other;input;medical;business performance metrics;telecommunication;artificial intelligence,technology;other;business;industries,computer vision;other;input;medical;business performance metrics;telecommunication;artificial intelligence,technology;other;business;industries,5g_mobile_communication 6g_mobile_communication cellular_radio decision_trees logistic_regression pattern_classification pattern_clustering quality_of_service telecommunication_computing telecommunication_traffic unsupervised_learning 6g_requirements augmented_reality cluster_simulated_network_areas d2d_communication_networks data_rate decision_tree_algorithm device_communication device_to_device_communication dynamic_deployment hotspot_areas k means linear_discriminant_analysis linear_support_vector mean_shift_clustering ml aided_dynamic_clustering mobile_devices network_traffic_load qos quadratic_discriminant_analysis quality_of_service secondary_base_station short_communication_range static_deployments streaming_services supervised_ml_classification_techniques technological_advancements ue vbs unsupervised_machine_learning_clustering user_equipment virtual_base_station virtual_reality b6250f_mobile_radio_systems b0240v_regression_analysis b0250_combinatorial_mathematics c1140v_regression_analysis c1160_combinatorial_mathematics c6130_data_handling_techniques c6262_unsupervised_learning c7410f_communications_computing computer_vision other input medical business_performance_metrics telecommunication artificial_intelligence,5g_mobile_communication 6g_mobile_communication cellular_radio decision_trees logistic_regression pattern_classification pattern_clustering quality_of_service telecommunication_computing telecommunication_traffic unsupervised_learning,6g_requirements augmented_reality cluster_simulated_network_areas d2d_communication_networks data_rate decision_tree_algorithm device_communication device_to_device_communication dynamic_deployment hotspot_areas k means linear_discriminant_analysis linear_support_vector mean_shift_clustering ml aided_dynamic_clustering mobile_devices network_traffic_load qos quadratic_discriminant_analysis quality_of_service secondary_base_station short_communication_range static_deployments streaming_services supervised_ml_classification_techniques technological_advancements ue vbs unsupervised_machine_learning_clustering user_equipment virtual_base_station virtual_reality,next generation mobile device streaming service virtual reality augmented reality meta available worldwide network data rate latency connectivity must improved even though 5g provides user required quality service qos term data rate reduced delay transmitting signal higher frequency called new radio nr face lot attenuation leading short communication range however meet goal set utilising 6g requirement many technological advancement component must incorporated network dense disposition small cell help reduce network traffic hotspot area increase coverage spectral efficiency nonetheless current deployment 5g base station bs small cell static cannot move around even though deployed hot spot area leading high operational cost furthermore static deployment base station required unpredictable scenario extreme crowd movement overcome issue device device d2d communication dynamic deployment virtual base station vbss called upon achieved using user equipment ue phone laptop mimic function base station b therefore paper user equipment based virtual base station ue vbs studied act secondary base station turn help alleviate traffic load network specifically one ue cannot relieve entire network traffic load network area split different cluster using unsupervised machine learning ml clustering technique e k mean mean shift clustering single ue selected act vbs cluster utilisation supervised ml classification technique e decision tree logistic regression linear discriminant analysis quadratic discriminant analysis linear support vector work utilise k mean along mean shift clustering technique cluster simulated network area accurately also use compare different classification machine learning technique predict classify whether user equipment employed vbs become ue vbs simulation study reveals decision tree algorithm achieves highest accuracy categorising eligible ues ue vbs,5g_mobile_communication 6g_mobile_communication cellular_radio decision_trees logistic_regression pattern_classification pattern_clustering quality_of_service telecommunication_computing telecommunication_traffic unsupervised_learning 6g_requirements augmented_reality cluster_simulated_network_areas d2d_communication_networks data_rate decision_tree_algorithm device_communication device_to_device_communication dynamic_deployment hotspot_areas k means linear_discriminant_analysis linear_support_vector mean_shift_clustering ml aided_dynamic_clustering mobile_devices network_traffic_load qos quadratic_discriminant_analysis quality_of_service secondary_base_station short_communication_range static_deployments streaming_services supervised_ml_classification_techniques technological_advancements ue vbs unsupervised_machine_learning_clustering user_equipment virtual_base_station virtual_reality b6250f_mobile_radio_systems b0240v_regression_analysis b0250_combinatorial_mathematics c1140v_regression_analysis c1160_combinatorial_mathematics c6130_data_handling_techniques c6262_unsupervised_learning c7410f_communications_computing computer_vision other input medical business_performance_metrics telecommunication artificial_intelligence next generation mobile device streaming service virtual reality augmented reality meta available worldwide network data rate latency connectivity must improved even though 5g provides user required quality service qos term data rate reduced delay transmitting signal higher frequency called new radio nr face lot attenuation leading short communication range however meet goal set utilising 6g requirement many technological advancement component must incorporated network dense disposition small cell help reduce network traffic hotspot area increase coverage spectral efficiency nonetheless current deployment 5g base station bs small cell static cannot move around even though deployed hot spot area leading high operational cost furthermore static deployment base station required unpredictable scenario extreme crowd movement overcome issue device device d2d communication dynamic deployment virtual base station vbss called upon achieved using user equipment ue phone laptop mimic function base station b therefore paper user equipment based virtual base station ue vbs studied act secondary base station turn help alleviate traffic load network specifically one ue cannot relieve entire network traffic load network area split different cluster using unsupervised machine learning ml clustering technique e k mean mean shift clustering single ue selected act vbs cluster utilisation supervised ml classification technique e decision tree logistic regression linear discriminant analysis quadratic discriminant analysis linear support vector work utilise k mean along mean shift clustering technique cluster simulated network area accurately also use compare different classification machine learning technique predict classify whether user equipment employed vbs become ue vbs simulation study reveals decision tree algorithm achieves highest accuracy categorising eligible ues ue vbs,next generation mobile device streaming service virtual reality augmented reality meta available worldwide network data rate latency connectivity must improved even though 5g provides user required quality service qos term data rate reduced delay transmitting signal higher frequency called new radio nr face lot attenuation leading short communication range however meet goal set utilising 6g requirement many technological advancement component must incorporated network dense disposition small cell help reduce network traffic hotspot area increase coverage spectral efficiency nonetheless current deployment 5g base station bs small cell static cannot move around even though deployed hot spot area leading high operational cost furthermore static deployment base station required unpredictable scenario extreme crowd movement overcome issue device device d2d communication dynamic deployment virtual base station vbss called upon achieved using user equipment ue phone laptop mimic function base station b therefore paper user equipment based virtual base station ue vbs studied act secondary base station turn help alleviate traffic load network specifically one ue cannot relieve entire network traffic load network area split different cluster using unsupervised machine learning ml clustering technique e k mean mean shift clustering single ue selected act vbs cluster utilisation supervised ml classification technique e decision tree logistic regression linear discriminant analysis quadratic discriminant analysis linear support vector work utilise k mean along mean shift clustering technique cluster simulated network area accurately also use compare different classification machine learning technique predict classify whether user equipment employed vbs become ue vbs simulation study reveals decision tree algorithm achieves highest accuracy categorising eligible ues ue vbs5g_mobile_communication 6g_mobile_communication cellular_radio decision_trees logistic_regression pattern_classification pattern_clustering quality_of_service telecommunication_computing telecommunication_traffic unsupervised_learning6g_requirements augmented_reality cluster_simulated_network_areas d2d_communication_networks data_rate decision_tree_algorithm device_communication device_to_device_communication dynamic_deployment hotspot_areas k means linear_discriminant_analysis linear_support_vector mean_shift_clustering ml aided_dynamic_clustering mobile_devices network_traffic_load qos quadratic_discriminant_analysis quality_of_service secondary_base_station short_communication_range static_deployments streaming_services supervised_ml_classification_techniques technological_advancements ue vbs unsupervised_machine_learning_clustering user_equipment virtual_base_station virtual_reality
427,Invited Paper: Intelligent Agent Support for Achieving Low Latency in Cloud-Native NextG Mobile Core Networks,"Choudhury, S., Das, S., Paul, S., Seskar, I., & Raychaudhuri, D. (2023). Invited Paper: Intelligent Agent Support for Achieving Low Latency in Cloud-Native NextG Mobile Core Networks. Proceedings of the 24th International Conference on Distributed Computing and Networking. https://doi.org/10.1145/3571306.3571386
",10.1145/3571306.3571386,"Next-generation mobile core networks are being designed to support a variety of latency sensitive applications based on emerging virtual, augmented or mixed reality technologies. A cloud-native approach for 5G core has been proposed to meet the diverse service requirements of NextG while reducing both CAPEX and OPEX. In this context, microservice architecture for network function virtualization is generally considered to be suitable for meeting NextG service requirements. Despite many advantages, the cloud-native core raises new challenges in the design of NextG systems for latency critical applications. An approach to achieving diverse QoS requirements is proposed in this paper. Specifically, the design is based on an orchestrator called the MEC-Intelligent Agent (MEC-IA) which enables dynamic compute resource distribution and network slice assignment in the core for improved QoS. The MEC-IA framework realizes resource management by intelligently assigning UEs to the access and mobility management function (AMF) while also performing slice provisioning. Simulation results are presented for the proposed MEC-IA framework showing the median control plane delay reduced by a factor of 1.67 &#215;. Further, robustness of the system improves significantly, reflecting a better overall user experience since the percentage connection dropped at 3 &#215; traffic volume reduces by 1.5 &#215; and slices assignment increases by 1.4 &#215; across all slices, even when the traffic arrival is skewed.",B6250F Mobile radio systems;B6210C Network management;B6210L Computer communications;C5620 Computer networks and techniques;C6130V Virtual reality;C6190J Internet software,augmented reality technologies;cloud-native approach;cloud-native core;cloud-native NextG mobile core networks;diverse QoS requirements;diverse service requirements;dynamic compute resource distribution;emerging virtual reality technologies;Intelligent Agent support;latency critical applications;latency sensitive applications;MEC-IA framework;MEC-Intelligent Agent;mixed reality technologies;network function virtualization;network slice assignment;next-generation mobile core networks;NextG service requirements;NextG systems,5G mobile communication;cloud computing;mobility management (mobile radio);quality of service;resource allocation;telecommunication traffic;virtualisation,2023,Conference article (CA),ICDCN2023: Proceedings of the 24th International Conference on Distributed Computing and Networking,"(1) Choudhury, S.; (2) Das, S.; (3) Paul, S.; (1) Seskar, I.; (1) Raychaudhuri, D.; ","(1) Rutgers University-Newark, Newark, NJ, United States; (2) Rice University, Houston, TX, United States; (3) Accenture Labs, United States; ",ACM,-1,"[""5g mobile communication"", ""cloud computing"", ""mobility management"", ""quality of service"", ""resource allocation"", ""telecommunication traffic"", ""virtualization""]","[""5g mobile communication"", ""cloud computing"", ""mobility management"", ""quality of service"", ""resource allocation"", ""telecommunication traffic"", ""virtualization""]",5g mobile communication;cloud computing;mobility management;quality of service;resource allocation;telecommunication traffic;virtualization,simulation;input;business performance metrics;telecommunication;geospatial;business planning and management;networks,technology;business;use cases;industries,simulation;input;business performance metrics;telecommunication;geospatial;business planning and management;networks,technology;business;use cases;industries,5g_mobile_communication cloud_computing mobility_management quality_of_service resource_allocation telecommunication_traffic virtualization augmented_reality_technologies cloud native_approach cloud native_core cloud native_nextg_mobile_core_networks diverse_qos_requirements diverse_service_requirements dynamic_compute_resource_distribution emerging_virtual_reality_technologies intelligent_agent_support latency_critical_applications latency_sensitive_applications mec ia_framework mec intelligent_agent mixed_reality_technologies network_function_virtualization network_slice_assignment next generation_mobile_core_networks nextg_service_requirements nextg_systems b6250f_mobile_radio_systems b6210c_network_management b6210l_computer_communications c5620_computer_networks_and_techniques c6130v_virtual_reality c6190j_internet_software simulation input business_performance_metrics telecommunication geospatial business_planning_and_management networks,5g_mobile_communication cloud_computing mobility_management quality_of_service resource_allocation telecommunication_traffic virtualization,augmented_reality_technologies cloud native_approach cloud native_core cloud native_nextg_mobile_core_networks diverse_qos_requirements diverse_service_requirements dynamic_compute_resource_distribution emerging_virtual_reality_technologies intelligent_agent_support latency_critical_applications latency_sensitive_applications mec ia_framework mec intelligent_agent mixed_reality_technologies network_function_virtualization network_slice_assignment next generation_mobile_core_networks nextg_service_requirements nextg_systems,next generation mobile core network designed support variety latency sensitive application based emerging virtual augmented mixed reality technology cloud native approach 5g core proposed meet diverse service requirement nextg reducing capex opex context microservice architecture network function virtualization generally considered suitable meeting nextg service requirement despite many advantage cloud native core raise new challenge design nextg system latency critical application approach achieving diverse qos requirement proposed paper specifically design based orchestrator called mec intelligent agent mec ia enables dynamic compute resource distribution network slice assignment core improved qos mec ia framework realizes resource management intelligently assigning ues access mobility management function amf also performing slice provisioning simulation result presented proposed mec ia framework showing median control plane delay reduced factor 1 67 215 robustness system improves significantly reflecting better overall user experience since percentage connection dropped 3 215 traffic volume reduces 1 5 215 slice assignment increase 1 4 215 across slice even traffic arrival skewed,5g_mobile_communication cloud_computing mobility_management quality_of_service resource_allocation telecommunication_traffic virtualization augmented_reality_technologies cloud native_approach cloud native_core cloud native_nextg_mobile_core_networks diverse_qos_requirements diverse_service_requirements dynamic_compute_resource_distribution emerging_virtual_reality_technologies intelligent_agent_support latency_critical_applications latency_sensitive_applications mec ia_framework mec intelligent_agent mixed_reality_technologies network_function_virtualization network_slice_assignment next generation_mobile_core_networks nextg_service_requirements nextg_systems b6250f_mobile_radio_systems b6210c_network_management b6210l_computer_communications c5620_computer_networks_and_techniques c6130v_virtual_reality c6190j_internet_software simulation input business_performance_metrics telecommunication geospatial business_planning_and_management networks next generation mobile core network designed support variety latency sensitive application based emerging virtual augmented mixed reality technology cloud native approach 5g core proposed meet diverse service requirement nextg reducing capex opex context microservice architecture network function virtualization generally considered suitable meeting nextg service requirement despite many advantage cloud native core raise new challenge design nextg system latency critical application approach achieving diverse qos requirement proposed paper specifically design based orchestrator called mec intelligent agent mec ia enables dynamic compute resource distribution network slice assignment core improved qos mec ia framework realizes resource management intelligently assigning ues access mobility management function amf also performing slice provisioning simulation result presented proposed mec ia framework showing median control plane delay reduced factor 1 67 215 robustness system improves significantly reflecting better overall user experience since percentage connection dropped 3 215 traffic volume reduces 1 5 215 slice assignment increase 1 4 215 across slice even traffic arrival skewed,next generation mobile core network designed support variety latency sensitive application based emerging virtual augmented mixed reality technology cloud native approach 5g core proposed meet diverse service requirement nextg reducing capex opex context microservice architecture network function virtualization generally considered suitable meeting nextg service requirement despite many advantage cloud native core raise new challenge design nextg system latency critical application approach achieving diverse qos requirement proposed paper specifically design based orchestrator called mec intelligent agent mec ia enables dynamic compute resource distribution network slice assignment core improved qos mec ia framework realizes resource management intelligently assigning ues access mobility management function amf also performing slice provisioning simulation result presented proposed mec ia framework showing median control plane delay reduced factor 1 67 215 robustness system improves significantly reflecting better overall user experience since percentage connection dropped 3 215 traffic volume reduces 1 5 215 slice assignment increase 1 4 215 across slice even traffic arrival skewed5g_mobile_communication cloud_computing mobility_management quality_of_service resource_allocation telecommunication_traffic virtualizationaugmented_reality_technologies cloud native_approach cloud native_core cloud native_nextg_mobile_core_networks diverse_qos_requirements diverse_service_requirements dynamic_compute_resource_distribution emerging_virtual_reality_technologies intelligent_agent_support latency_critical_applications latency_sensitive_applications mec ia_framework mec intelligent_agent mixed_reality_technologies network_function_virtualization network_slice_assignment next generation_mobile_core_networks nextg_service_requirements nextg_systems
428,Beam Management Technique For 5G Wireless Communication: A Deep Learning Approach,"Pawar, S., & Venkatesan, M. (2022). Beam Management Technique For 5G Wireless Communication: A Deep Learning Approach. 2022 IEEE Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI). https://doi.org/10.1109/iatmsi56455.2022.10119247
",10.1109/IATMSI56455.2022.10119247,"The expectation from next-generation 5G technology is to satisfy data-hungry applications such as vehicular applications and augmented and virtual reality. 5G along with millimeter-wave technology is a prominent technology that can satisfy user demands and needs as it provides a high data rate. The accomplishment of a high data rate is possible using a large number of antennas. However, the increased number of antennas results in increased path loss. Apart from increased path loss, beam misalignment is another challenge that can be overcome by robust beam forming techniques. Beam management involves providing a comprehensive solution to various challenges associated with the beam. This paper provides an overview of beam management procedures using deep learning to reduce beam alignment problems. Beam management includes various steps such as channel state estimation, beam training, beam selection, beam alignment, and beamforming. Based on the analysis, the paper also provides a comprehensive framework for improved beam management. Finally, the paper also discusses the open issues in this field of work.",A8620X Telecommunication systems (energy utilisation);B6140 Signal processing and detection;B6250F Mobile radio systems;C6130V Virtual reality;C6264 Neural nets;C7410F Communications computing,5G wireless communication;antennas results;augmented reality;beam alignment problems;beam management procedures;beam management technique;beam misalignment;beam selection;beam training;data-hungry applications;deep learning approach;high data rate;improved beam management;increased path loss;millimeter-wave technology;next-generation 5G technology;prominent technology;robust beam forming techniques;vehicular applications;virtual reality,5G mobile communication;array signal processing;deep learning (artificial intelligence);millimetre wave communication;virtual reality,2022,Conference article (CA),2022 IEEE Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI),"(1) Pawar, S.; (1) Venkatesan, M.; ","(1) Research Scholar, E&TC Department, India; ",IEEE,-1,"[""5g mobile communication"", ""array signal processing"", ""deep learning (artificial intelligence)"", ""millimetre wave communication""]","[""5g mobile communication"", ""array signal processing"", ""deep learning (artificial intelligence)"", ""millimetre wave communication""]",5g mobile communication;array signal processing;deep learning (artificial intelligence);millimetre wave communication,semiconductors;other;input;liberal arts;medical;sensors;telecommunication;data;artificial intelligence,technology;other;industries,semiconductors;other;input;liberal arts;medical;sensors;telecommunication;data;artificial intelligence,technology;other;industries,5g_mobile_communication array_signal_processing deep_learning_ artificial_intelligence millimetre_wave_communication 5g_wireless_communication antennas_results augmented_reality beam_alignment_problems beam_management_procedures beam_management_technique beam_misalignment beam_selection beam_training data hungry_applications deep_learning_approach high_data_rate improved_beam_management increased_path_loss millimeter wave_technology next generation_5g_technology prominent_technology robust_beam_forming_techniques vehicular_applications virtual_reality a8620x_telecommunication_systems_ energy_utilisation b6140_signal_processing_and_detection b6250f_mobile_radio_systems c6130v_virtual_reality c6264_neural_nets c7410f_communications_computing semiconductors other input liberal_arts medical sensors telecommunication data artificial_intelligence,5g_mobile_communication array_signal_processing deep_learning_ artificial_intelligence millimetre_wave_communication,5g_wireless_communication antennas_results augmented_reality beam_alignment_problems beam_management_procedures beam_management_technique beam_misalignment beam_selection beam_training data hungry_applications deep_learning_approach high_data_rate improved_beam_management increased_path_loss millimeter wave_technology next generation_5g_technology prominent_technology robust_beam_forming_techniques vehicular_applications virtual_reality,expectation next generation 5g technology satisfy data hungry application vehicular application augmented virtual reality 5g along millimeter wave technology prominent technology satisfy user demand need provides high data rate accomplishment high data rate possible using large number antenna however increased number antenna result increased path loss apart increased path loss beam misalignment another challenge overcome robust beam forming technique beam management involves providing comprehensive solution various challenge associated beam paper provides overview beam management procedure using deep learning reduce beam alignment problem beam management includes various step channel state estimation beam training beam selection beam alignment beamforming based analysis paper also provides comprehensive framework improved beam management finally paper also discus open issue field work,5g_mobile_communication array_signal_processing deep_learning_ artificial_intelligence millimetre_wave_communication 5g_wireless_communication antennas_results augmented_reality beam_alignment_problems beam_management_procedures beam_management_technique beam_misalignment beam_selection beam_training data hungry_applications deep_learning_approach high_data_rate improved_beam_management increased_path_loss millimeter wave_technology next generation_5g_technology prominent_technology robust_beam_forming_techniques vehicular_applications virtual_reality a8620x_telecommunication_systems_ energy_utilisation b6140_signal_processing_and_detection b6250f_mobile_radio_systems c6130v_virtual_reality c6264_neural_nets c7410f_communications_computing semiconductors other input liberal_arts medical sensors telecommunication data artificial_intelligence expectation next generation 5g technology satisfy data hungry application vehicular application augmented virtual reality 5g along millimeter wave technology prominent technology satisfy user demand need provides high data rate accomplishment high data rate possible using large number antenna however increased number antenna result increased path loss apart increased path loss beam misalignment another challenge overcome robust beam forming technique beam management involves providing comprehensive solution various challenge associated beam paper provides overview beam management procedure using deep learning reduce beam alignment problem beam management includes various step channel state estimation beam training beam selection beam alignment beamforming based analysis paper also provides comprehensive framework improved beam management finally paper also discus open issue field work,expectation next generation 5g technology satisfy data hungry application vehicular application augmented virtual reality 5g along millimeter wave technology prominent technology satisfy user demand need provides high data rate accomplishment high data rate possible using large number antenna however increased number antenna result increased path loss apart increased path loss beam misalignment another challenge overcome robust beam forming technique beam management involves providing comprehensive solution various challenge associated beam paper provides overview beam management procedure using deep learning reduce beam alignment problem beam management includes various step channel state estimation beam training beam selection beam alignment beamforming based analysis paper also provides comprehensive framework improved beam management finally paper also discus open issue field work5g_mobile_communication array_signal_processing deep_learning_ artificial_intelligence millimetre_wave_communication5g_wireless_communication antennas_results augmented_reality beam_alignment_problems beam_management_procedures beam_management_technique beam_misalignment beam_selection beam_training data hungry_applications deep_learning_approach high_data_rate improved_beam_management increased_path_loss millimeter wave_technology next generation_5g_technology prominent_technology robust_beam_forming_techniques vehicular_applications virtual_reality
429,Towards a Mixed Virtual Reality Environment Implementation to Enable Industrial Robot Programming Competencies within a Cyber-Physical Factory,"Vázquez-Hurtado, C., Altamirano-Avila, E., Roman-Flores, A., & Vargas-Martinez, A. (2023). Towards a Mixed Virtual Reality Environment Implementation to Enable Industrial Robot Programming Competencies within a Cyber-Physical Factory. 2023 IEEE Global Engineering Education Conference (EDUCON). https://doi.org/10.1109/educon54358.2023.10125175
",10.1109/EDUCON54358.2023.10125175,"This work aims to present a roadmap towards the Cyber-Physical implementation at Tecnologico de Monterrey. This document describes the approach to conceptualize, design, and implement a mixed virtual environment that fulfills the Paradigm of Industry 4.0. This implementation has the following benefits: 1) The Cyber-Learning-Factory that emulates a real, controlled, Industry 4.0 workplace, 2) It allows the students to design a solution to manufacture and assembly a product from a realistic product specification 3) It allows the students to play similar roles to those found in industry positions. This concept was validated on a project to build a product that integrates autonomous, industrial and collaborative robots, Product and Process Digital Twins, flexible CNC machinery and Additive Manufacturing, Simulation stations and CAD/CAM/CAE applications, Horizontal and Vertical Integration (MES and ERP), Augmented-Virtual and Mixed Reality aids and all the IT infrastructure and applications supporting IoT, Cyber Security, Cloud Computing and Big Data &amp; Analytics.",C7480 Production engineering computing;C5620D Internet of Things;C6110 Systems analysis and programming;C6130G Groupware;C6130J Big Data;C6130S Data security;C6130V Virtual reality;C6190J Internet software;C7420 Control engineering computing;C7810C Computer-aided instruction;E0410D Industrial applications of IT;E1510 Manufacturing systems;E1550A Robotics,Additive Manufacturing;assembly;autonomous robots;collaborative robots;controlled Industry 4;Cyber Security;Cyber-Learning-Factory;Cyber-Physical Factory;Cyber-Physical implementation;enable industrial robot programming competencies;industrial robots;industry positions;mixed virtual environment;Mixed Virtual Reality environment implementation;realistic product specification 3;Tecnologico de Monterrey,augmented reality;Big Data;CAD/CAM;cloud computing;computer aided engineering;computer aided instruction;computerised numerical control;cyber-physical systems;digital twins;groupware;industrial robots;Internet of Things;production engineering computing;production facilities;robot programming;virtual reality,2023,Conference article (CA),2023 IEEE Global Engineering Education Conference (EDUCON),"(1) Vazquez-Hurtado, C.; (1) Altamirano-Avila, E.; (1) Roman-Flores, A.; (1) Vargas-Martinez, A.; ","(1) Tecnolo&#769;gico de Monterrey, Mexico; ",IEEE,-1,"[""big data"", ""cad/cam"", ""cloud computing"", ""computer aided engineering"", ""computer aided instruction"", ""computerised numerical control"", ""cyber-physical systems"", ""digital twins"", ""groupware"", ""industrial robots"", ""internet of things"", ""production engineering computing"", ""production facilities"", ""robot programming""]","[""big data"", ""cad/cam"", ""cloud computing"", ""computer aided engineering"", ""computer aided instruction"", ""computerised numerical control"", ""cyber-physical systems"", ""digital twins"", ""groupware"", ""industrial robots"", ""internet of things"", ""production engineering computing"", ""production facilities"", ""robot programming""]",big data;cad/cam;cloud computing;computer aided engineering;computer aided instruction;computerised numerical control;cyber-physical systems;digital twins;groupware;industrial robots;internet of things;production engineering computing;production facilities;robot programming,education;other;graphics;robotics;simulation;training;collaboration;internet of things;engineering;developers;data;smart cities;manufacturing;networks,technology;other;use cases;industries,education;other;graphics;robotics;simulation;training;collaboration;internet of things;engineering;developers;data;smart cities;manufacturing;networks,technology;other;use cases;industries,big_data cad cam cloud_computing computer_aided_engineering computer_aided_instruction computerised_numerical_control cyber physical_systems digital_twins groupware industrial_robots internet_of_things production_engineering_computing production_facilities robot_programming additive_manufacturing assembly autonomous_robots collaborative_robots controlled_industry_4 cyber_security cyber learning factory cyber physical_factory cyber physical_implementation enable_industrial_robot_programming_competencies industrial_robots industry_positions mixed_virtual_environment mixed_virtual_reality_environment_implementation realistic_product_specification_3 tecnologico_de_monterrey c7480_production_engineering_computing c5620d_internet_of_things c6110_systems_analysis_and_programming c6130g_groupware c6130j_big_data c6130s_data_security c6130v_virtual_reality c6190j_internet_software c7420_control_engineering_computing c7810c_computer aided_instruction e0410d_industrial_applications_of_it e1510_manufacturing_systems e1550a_robotics education other graphics robotics simulation training collaboration internet_of_things engineering developers data smart_cities manufacturing networks,big_data cad cam cloud_computing computer_aided_engineering computer_aided_instruction computerised_numerical_control cyber physical_systems digital_twins groupware industrial_robots internet_of_things production_engineering_computing production_facilities robot_programming,additive_manufacturing assembly autonomous_robots collaborative_robots controlled_industry_4 cyber_security cyber learning factory cyber physical_factory cyber physical_implementation enable_industrial_robot_programming_competencies industrial_robots industry_positions mixed_virtual_environment mixed_virtual_reality_environment_implementation realistic_product_specification_3 tecnologico_de_monterrey,work aim present roadmap towards cyber physical implementation tecnologico de monterrey document describes approach conceptualize design implement mixed virtual environment fulfills paradigm industry 4 0 implementation following benefit 1 cyber learning factory emulates real controlled industry 4 0 workplace 2 allows student design solution manufacture assembly product realistic product specification 3 allows student play similar role found industry position concept validated project build product integrates autonomous industrial collaborative robot product process digital twin flexible cnc machinery additive manufacturing simulation station cad cam cae application horizontal vertical integration me erp augmented virtual mixed reality aid infrastructure application supporting iot cyber security cloud computing big data amp analytics,big_data cad cam cloud_computing computer_aided_engineering computer_aided_instruction computerised_numerical_control cyber physical_systems digital_twins groupware industrial_robots internet_of_things production_engineering_computing production_facilities robot_programming additive_manufacturing assembly autonomous_robots collaborative_robots controlled_industry_4 cyber_security cyber learning factory cyber physical_factory cyber physical_implementation enable_industrial_robot_programming_competencies industrial_robots industry_positions mixed_virtual_environment mixed_virtual_reality_environment_implementation realistic_product_specification_3 tecnologico_de_monterrey c7480_production_engineering_computing c5620d_internet_of_things c6110_systems_analysis_and_programming c6130g_groupware c6130j_big_data c6130s_data_security c6130v_virtual_reality c6190j_internet_software c7420_control_engineering_computing c7810c_computer aided_instruction e0410d_industrial_applications_of_it e1510_manufacturing_systems e1550a_robotics education other graphics robotics simulation training collaboration internet_of_things engineering developers data smart_cities manufacturing networks work aim present roadmap towards cyber physical implementation tecnologico de monterrey document describes approach conceptualize design implement mixed virtual environment fulfills paradigm industry 4 0 implementation following benefit 1 cyber learning factory emulates real controlled industry 4 0 workplace 2 allows student design solution manufacture assembly product realistic product specification 3 allows student play similar role found industry position concept validated project build product integrates autonomous industrial collaborative robot product process digital twin flexible cnc machinery additive manufacturing simulation station cad cam cae application horizontal vertical integration me erp augmented virtual mixed reality aid infrastructure application supporting iot cyber security cloud computing big data amp analytics,work aim present roadmap towards cyber physical implementation tecnologico de monterrey document describes approach conceptualize design implement mixed virtual environment fulfills paradigm industry 4 0 implementation following benefit 1 cyber learning factory emulates real controlled industry 4 0 workplace 2 allows student design solution manufacture assembly product realistic product specification 3 allows student play similar role found industry position concept validated project build product integrates autonomous industrial collaborative robot product process digital twin flexible cnc machinery additive manufacturing simulation station cad cam cae application horizontal vertical integration me erp augmented virtual mixed reality aid infrastructure application supporting iot cyber security cloud computing big data amp analyticsbig_data cad cam cloud_computing computer_aided_engineering computer_aided_instruction computerised_numerical_control cyber physical_systems digital_twins groupware industrial_robots internet_of_things production_engineering_computing production_facilities robot_programmingadditive_manufacturing assembly autonomous_robots collaborative_robots controlled_industry_4 cyber_security cyber learning factory cyber physical_factory cyber physical_implementation enable_industrial_robot_programming_competencies industrial_robots industry_positions mixed_virtual_environment mixed_virtual_reality_environment_implementation realistic_product_specification_3 tecnologico_de_monterrey
430,Implementation of varifocal occlusion using lens arrays and focus-tunable lenses,"Chae, M., Shin, J., Jo, Y., Jeong, Y., & Lee, B. (2023). Implementation of varifocal occlusion using lens arrays and focus-tunable lenses. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2649558
",10.1117/12.2649558,"Occlusion technology has grown its importance for enhancing immersive augmented reality experiences by improving mutual depth perceptions between the real and virtual scenes. Among various methods for implementing occlusion in augmented reality displays, the 4f system method has gained a lot of attention for its capability to produce a sharp occlusion effect. However, this method has a drawback of having a large form factor and difficulty in achieving sharp occlusion when implemented to display multiple-depth images. Previous studies have applied a lens array to a 4f system to reduce the form factor.1, 2 In this work, we numerically and experimentally investigate the use of a pair of focus-tunable lenses (FTLs) along with a lens array 4f system to achieve sharp occlusion at multiple levels of depths in addition. &copy; 2023 SPIE.","723 Computer Software, Data Handling and Applications;741.3 Optical Devices and Systems;921.6 Numerical Methods",4-f system;4f-system;Form factors;Immersive augmented realities;Lens array;Occlusion-capable display;System methods;Tunable lens;Varifocal occlusion;Virtual scenes,Approximation theory;Depth perception;Microlenses,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Chae, Minseok; (1) Shin, Jehyeon; (1) Jo, Youngjin; (1) Jeong, Yoonchan; (1) Lee, Byoungho; ","(1) Department of Electrical and Computer Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul; 08826, Korea, Republic of; ",SPIE,-1,"[""approximation theory"", ""depth perception"", ""microlenses""]","[""approximation theory"", ""depth perception"", ""microlenses""]",approximation theory;depth perception;microlenses,display technology;human factors;artificial intelligence;optics,technology;displays;end users and user experience,display technology;human factors;artificial intelligence;optics,technology;displays;end users and user experience,approximation_theory depth_perception microlenses 4 f_system 4f system form_factors immersive_augmented_realities lens_array occlusion capable_display system_methods tunable_lens varifocal_occlusion virtual_scenes 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 921 6_numerical_methods display_technology human_factors artificial_intelligence optics,approximation_theory depth_perception microlenses,4 f_system 4f system form_factors immersive_augmented_realities lens_array occlusion capable_display system_methods tunable_lens varifocal_occlusion virtual_scenes,occlusion technology grown importance enhancing immersive augmented reality experience improving mutual depth perception real virtual scene among various method implementing occlusion augmented reality display 4f system method gained lot attention capability produce sharp occlusion effect however method drawback large form factor difficulty achieving sharp occlusion implemented display multiple depth image previous study applied lens array 4f system reduce form factor 1 2 work numerically experimentally investigate use pair focus tunable lens ftls along lens array 4f system achieve sharp occlusion multiple level depth addition copy 2023 spie,approximation_theory depth_perception microlenses 4 f_system 4f system form_factors immersive_augmented_realities lens_array occlusion capable_display system_methods tunable_lens varifocal_occlusion virtual_scenes 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems 921 6_numerical_methods display_technology human_factors artificial_intelligence optics occlusion technology grown importance enhancing immersive augmented reality experience improving mutual depth perception real virtual scene among various method implementing occlusion augmented reality display 4f system method gained lot attention capability produce sharp occlusion effect however method drawback large form factor difficulty achieving sharp occlusion implemented display multiple depth image previous study applied lens array 4f system reduce form factor 1 2 work numerically experimentally investigate use pair focus tunable lens ftls along lens array 4f system achieve sharp occlusion multiple level depth addition copy 2023 spie,occlusion technology grown importance enhancing immersive augmented reality experience improving mutual depth perception real virtual scene among various method implementing occlusion augmented reality display 4f system method gained lot attention capability produce sharp occlusion effect however method drawback large form factor difficulty achieving sharp occlusion implemented display multiple depth image previous study applied lens array 4f system reduce form factor 1 2 work numerically experimentally investigate use pair focus tunable lens ftls along lens array 4f system achieve sharp occlusion multiple level depth addition copy 2023 spieapproximation_theory depth_perception microlenses4 f_system 4f system form_factors immersive_augmented_realities lens_array occlusion capable_display system_methods tunable_lens varifocal_occlusion virtual_scenes
431,Global phase insensitive loss function for deep learning in holographic imaging and projection applications,"Zheng, Y., & Gordon, G. S. D. (2023). Global phase insensitive loss function for deep learning in holographic imaging and projection applications. AI and Optical Data Sciences IV. https://doi.org/10.1117/12.2648040
",10.1117/12.2648040,"Holographic imaging and projection are increasingly used for important applications such as augmented reality,1 3D microscopy2 and imaging through optical fibres.3 However, there are emerging applications that require control or detection of phase, where deep learning techniques are used as faster alternatives to conventional hologram generation algorithms or phase-retrieval algorithms.4 Although conventional mean absolute error (MAE) loss function or mean squared error (MSE) can directly compare complex values for absolute control of phase, there is a class of problems whose solutions are degenerate within a global phase factor, but whose relative phase between pixels must be preserved. In such cases, MAE is not suitable because it is sensitive to global phase differences. We therefore develop a 'global phase insensitive' loss function that estimates the global phase factor between predicted and target outputs and normalises the predicted output to remove this factor before calculating MAE. As a case study we demonstrate &le; 0.1% error in the recovery of complex-valued optical fibre transmission matrices via a neural network. This global phase insensitive loss function will offer new opportunities for deep learning-based holographic image reconstruction, 3D holographic projection for augmented reality and coherent imaging through optical fibres. &copy; 2023 SPIE.","461.4 Ergonomics and Human Factors Engineering;722 Computer Systems and Equipment;723 Computer Software, Data Handling and Applications;741.1 Light/Optics;741.1.2 Fiber Optics;743 Holography;746 Imaging Techniques;922.2 Mathematical Statistics",Custom loss function;Global phase;Holographic imaging;Holographic imaging application;Holographic projection;Imaging applications;Loss functions;Mean absolute error;Neural-networks;Phase factor,Complex networks;Deep learning;Errors;Holograms;Image reconstruction;Imaging systems;Learning systems;Light transmission;Mean square error;Optical fibers,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Zheng, Yijie; (1) Gordon, George; ","(1) University of Nottingham, Optics and Photonics Research Group, Nottingham, United Kingdom; ",SPIE,-1,"[""complex networks"", ""deep learning"", ""errors"", ""holograms"", ""image reconstruction"", ""imaging systems"", ""learning systems"", ""light transmission"", ""mean square error"", ""optical fibers""]","[""complex networks"", ""deep learning"", ""errors"", ""holograms"", ""image reconstruction"", ""imaging systems"", ""learning systems"", ""light transmission"", ""mean square error"", ""optical fibers""]",complex networks;deep learning;errors;holograms;image reconstruction;imaging systems;learning systems;light transmission;mean square error;optical fibers,construction;computer vision;education;graphics;input;medical;display technology;human factors;telecommunication;data;artificial intelligence,technology;end users and user experience;displays;industries,construction;computer vision;education;graphics;input;medical;display technology;human factors;telecommunication;data;artificial intelligence,technology;end users and user experience;displays;industries,complex_networks deep_learning errors holograms image_reconstruction imaging_systems learning_systems light_transmission mean_square_error optical_fibers custom_loss_function global_phase holographic_imaging holographic_imaging_application holographic_projection imaging_applications loss_functions mean_absolute_error neural networks phase_factor 461 4_ergonomics_and_human_factors_engineering 722_computer_systems_and_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 1 2_fiber_optics 743_holography 746_imaging_techniques 922 2_mathematical_statistics construction computer_vision education graphics input medical display_technology human_factors telecommunication data artificial_intelligence,complex_networks deep_learning errors holograms image_reconstruction imaging_systems learning_systems light_transmission mean_square_error optical_fibers,custom_loss_function global_phase holographic_imaging holographic_imaging_application holographic_projection imaging_applications loss_functions mean_absolute_error neural networks phase_factor,holographic imaging projection increasingly used important application augmented reality 1 3d microscopy2 imaging optical fibre 3 however emerging application require control detection phase deep learning technique used faster alternative conventional hologram generation algorithm phase retrieval algorithm 4 although conventional mean absolute error mae loss function mean squared error mse directly compare complex value absolute control phase class problem whose solution degenerate within global phase factor whose relative phase pixel must preserved case mae suitable sensitive global phase difference therefore develop global phase insensitive loss function estimate global phase factor predicted target output normalises predicted output remove factor calculating mae case study demonstrate le 0 1 error recovery complex valued optical fibre transmission matrix via neural network global phase insensitive loss function offer new opportunity deep learning based holographic image reconstruction 3d holographic projection augmented reality coherent imaging optical fibre copy 2023 spie,complex_networks deep_learning errors holograms image_reconstruction imaging_systems learning_systems light_transmission mean_square_error optical_fibers custom_loss_function global_phase holographic_imaging holographic_imaging_application holographic_projection imaging_applications loss_functions mean_absolute_error neural networks phase_factor 461 4_ergonomics_and_human_factors_engineering 722_computer_systems_and_equipment 723_computer_software _data_handling_and_applications 741 1_light optics 741 1 2_fiber_optics 743_holography 746_imaging_techniques 922 2_mathematical_statistics construction computer_vision education graphics input medical display_technology human_factors telecommunication data artificial_intelligence holographic imaging projection increasingly used important application augmented reality 1 3d microscopy2 imaging optical fibre 3 however emerging application require control detection phase deep learning technique used faster alternative conventional hologram generation algorithm phase retrieval algorithm 4 although conventional mean absolute error mae loss function mean squared error mse directly compare complex value absolute control phase class problem whose solution degenerate within global phase factor whose relative phase pixel must preserved case mae suitable sensitive global phase difference therefore develop global phase insensitive loss function estimate global phase factor predicted target output normalises predicted output remove factor calculating mae case study demonstrate le 0 1 error recovery complex valued optical fibre transmission matrix via neural network global phase insensitive loss function offer new opportunity deep learning based holographic image reconstruction 3d holographic projection augmented reality coherent imaging optical fibre copy 2023 spie,holographic imaging projection increasingly used important application augmented reality 1 3d microscopy2 imaging optical fibre 3 however emerging application require control detection phase deep learning technique used faster alternative conventional hologram generation algorithm phase retrieval algorithm 4 although conventional mean absolute error mae loss function mean squared error mse directly compare complex value absolute control phase class problem whose solution degenerate within global phase factor whose relative phase pixel must preserved case mae suitable sensitive global phase difference therefore develop global phase insensitive loss function estimate global phase factor predicted target output normalises predicted output remove factor calculating mae case study demonstrate le 0 1 error recovery complex valued optical fibre transmission matrix via neural network global phase insensitive loss function offer new opportunity deep learning based holographic image reconstruction 3d holographic projection augmented reality coherent imaging optical fibre copy 2023 spiecomplex_networks deep_learning errors holograms image_reconstruction imaging_systems learning_systems light_transmission mean_square_error optical_fiberscustom_loss_function global_phase holographic_imaging holographic_imaging_application holographic_projection imaging_applications loss_functions mean_absolute_error neural networks phase_factor
432,Towards Virtual Displays in the Interventional Radiology Suite: A Feasibility Study,"Allen, D. R., Cattari, N., Cambranis Romero, J. N., Peters, T. M., & Chen, E. C. S. (2023). Towards virtual displays in the interventional radiology suite: a feasibility study. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2654267
",10.1117/12.2654267,"Interventional Radiology (IR) is a rapidly advancing field, with complex procedures and techniques being developed at increasingly high rates. As these procedures and the underlying imaging technology continue to evolve, one of the challenges for physicians lies in maintaining optimal visualization of the various displays used to guide the procedure. Many Augmented Reality Surgical Navigation Systems (AR-SNS) have been proposed in the literature that aim to improve the way physicians visualize their patient's anatomy, but there are few that address the problem of space within the IR suite. Our solution is the incorporation of an Augmented Reality ""cockpit"", which streams and renders image data inside virtual displays visualized within the Hololens 2, eliminating the need for physical displays. The benefits of our approach is that sterile free interaction and customization can be performed using hand gestures and voice commands, and the physician can optimize the positioning of the display without the need to worry about physical interference from other equipment. For proof of concept, we performed a user study to validate the suitability of our approach in the context of liver tumour ablation procedures. We found there was no significant differences in insertion accuracy or time between the proposed approach and the traditional method. This indicates that visualization of US imaging using our approach is an adequate replacement to the traditional physical display, and paves the way for the next iteration of the system, which is to quantify the benefits of our approach when used in multi-modality procedures. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.6 Medicine and Pharmacology;622.3 Radioactive Material Applications;723 Computer Software, Data Handling and Applications;746 Imaging Techniques;921.6 Numerical Methods",Complex procedure;Customisation;Feasibility studies;High rate;Image data;Imaging technology;Interventional radiology;Patient anatomy;Surgical navigation systems;Virtual displays,Iterative methods;Medical imaging;Navigation systems;Radiology;Visualization,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Allen, Daniel R.; (1) Cattari, Nadia; (1) Cambranis, Joeana; (1) Peters, Terry M.; (1) Chen, Elvis C.S.; ","(1) School of Biomedical Engineering, Western University, London; ON, Canada; (2) Robarts Research Institute, Western University, London; ON, Canada; (3) Department of Information Engineering, University of Pisa, Pisa, Italy; (4) Department of Medical Biophysics, Western University, London; ON, Canada; ",SPIE,-1,"[""iterative methods"", ""medical imaging"", ""navigation systems"", ""radiology"", ""visualization""]","[""iterative methods"", ""medical imaging"", ""navigation systems"", ""radiology"", ""visualization""]",iterative methods;medical imaging;navigation systems;radiology;visualization,education;medical;telecommunication;data;navigation;artificial intelligence,technology;use cases;industries,education;medical;telecommunication;data;navigation;artificial intelligence,technology;use cases;industries,iterative_methods medical_imaging navigation_systems radiology visualization complex_procedure customisation feasibility_studies high_rate image_data imaging_technology interventional_radiology patient_anatomy surgical_navigation_systems virtual_displays 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 622 3_radioactive_material_applications 723_computer_software _data_handling_and_applications 746_imaging_techniques 921 6_numerical_methods education medical telecommunication data navigation artificial_intelligence,iterative_methods medical_imaging navigation_systems radiology visualization,complex_procedure customisation feasibility_studies high_rate image_data imaging_technology interventional_radiology patient_anatomy surgical_navigation_systems virtual_displays,interventional radiology ir rapidly advancing field complex procedure technique developed increasingly high rate procedure underlying imaging technology continue evolve one challenge physician lie maintaining optimal visualization various display used guide procedure many augmented reality surgical navigation system ar sn proposed literature aim improve way physician visualize patient anatomy address problem space within ir suite solution incorporation augmented reality cockpit stream render image data inside virtual display visualized within hololens 2 eliminating need physical display benefit approach sterile free interaction customization performed using hand gesture voice command physician optimize positioning display without need worry physical interference equipment proof concept performed user study validate suitability approach context liver tumour ablation procedure found significant difference insertion accuracy time proposed approach traditional method indicates visualization u imaging using approach adequate replacement traditional physical display pave way next iteration system quantify benefit approach used multi modality procedure copy 2023 spie,iterative_methods medical_imaging navigation_systems radiology visualization complex_procedure customisation feasibility_studies high_rate image_data imaging_technology interventional_radiology patient_anatomy surgical_navigation_systems virtual_displays 461 1_biomedical_engineering 461 6_medicine_and_pharmacology 622 3_radioactive_material_applications 723_computer_software _data_handling_and_applications 746_imaging_techniques 921 6_numerical_methods education medical telecommunication data navigation artificial_intelligence interventional radiology ir rapidly advancing field complex procedure technique developed increasingly high rate procedure underlying imaging technology continue evolve one challenge physician lie maintaining optimal visualization various display used guide procedure many augmented reality surgical navigation system ar sn proposed literature aim improve way physician visualize patient anatomy address problem space within ir suite solution incorporation augmented reality cockpit stream render image data inside virtual display visualized within hololens 2 eliminating need physical display benefit approach sterile free interaction customization performed using hand gesture voice command physician optimize positioning display without need worry physical interference equipment proof concept performed user study validate suitability approach context liver tumour ablation procedure found significant difference insertion accuracy time proposed approach traditional method indicates visualization u imaging using approach adequate replacement traditional physical display pave way next iteration system quantify benefit approach used multi modality procedure copy 2023 spie,interventional radiology ir rapidly advancing field complex procedure technique developed increasingly high rate procedure underlying imaging technology continue evolve one challenge physician lie maintaining optimal visualization various display used guide procedure many augmented reality surgical navigation system ar sn proposed literature aim improve way physician visualize patient anatomy address problem space within ir suite solution incorporation augmented reality cockpit stream render image data inside virtual display visualized within hololens 2 eliminating need physical display benefit approach sterile free interaction customization performed using hand gesture voice command physician optimize positioning display without need worry physical interference equipment proof concept performed user study validate suitability approach context liver tumour ablation procedure found significant difference insertion accuracy time proposed approach traditional method indicates visualization u imaging using approach adequate replacement traditional physical display pave way next iteration system quantify benefit approach used multi modality procedure copy 2023 spieiterative_methods medical_imaging navigation_systems radiology visualizationcomplex_procedure customisation feasibility_studies high_rate image_data imaging_technology interventional_radiology patient_anatomy surgical_navigation_systems virtual_displays
433,Open Source Video-Based Hand-Eye Calibration,"Kemper, T. N., Allen, D. R., Rankin, A., Peters, T. M., & Chen, E. C. S. (2023). Open source video-based hand-eye calibration. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2651160
",10.1117/12.2651160,"Augmented reality is becoming prevalent in modern video-based surgical navigation systems. Augmented reality in forms of image-fusion between the virtual objects (i.e. virtual representation of the anatomy derived from preoperative imaging modalities) and the real objects (i.e. anatomy imaged by a spatially-tracked surgical camera) facilitate the visualization and perception of the surgical scene. However, this requires spatial calibration between the external tracking system and the optical axis of the surgical camera, known as hand-eye calibration. With the standard implementation of the most common hand-eye calibration techniques being static-photo-based, the time required for data collection may inhibit the thoroughness and robustness to achieve an accurate calibration. To address these translational issues, we introduce a video-based hand-eye calibration technique with open-source implementation that is accurate and robust. Based on the point-to-line Procrustean registration, a short video of a tracked and pivot-calibrated ball-tip stylus was recorded where, in each frame of the tracked video, the 3D position of the ball-tip (point) and its projection onto the video (line) serve as a calibration data point. We further devise a data sampling mechanism designed to optimize the spatial configuration of the calibration fiducials, leading to consistently high quality hand-eye calibrations. To demonstrate the efficacy of our work, a Monte Carlo simulation was performed to obtain the mean target projection error as a function of the number of calibration data points. The results obtained, exemplified using a Logitech C920 Pro HD Webcam with an image resolution of 640 &times; 480, show that the mean projection error decreased as more data points were used per calibration, and the majority of mean projection errors fell below 4 pixels. An open-source implementation, in the form of a 3D Slicer module, is available on GitHub. &copy; 2023 SPIE.","461.1 Biomedical Engineering;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;723.4 Artificial Intelligence;742.2 Photographic Equipment;746 Imaging Techniques;922.2 Mathematical Statistics",Calibration data;Calibration techniques;Camera calibration;Datapoints;Hand/eye calibration;Image guided surgery;Open source implementation;Open-source;Projection error;Video-based,Calibration;Cameras;Errors;Image fusion;Image resolution;Intelligent systems;Medical imaging;Monte Carlo methods;Open systems,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Kemper, Tara N.; (1) Allen, Daniel R.; (1) Rankin, Adam; (1) Peters, Terry M.; (1) Chen, Elvis C.S.; ","(1) Robarts Research Institute, Canada; (2) School of Biomedical Engineering, Western University, Canada; (3) Department of Medical Biophysics, Western University, Canada; (4) Department of Physics and Astronomy, Western University, Canada; ",SPIE,-1,"[""calibration"", ""cameras"", ""errors"", ""image fusion"", ""image resolution"", ""intelligent systems"", ""medical imaging"", ""monte carlo methods"", ""open systems""]","[""calibration"", ""cameras"", ""errors"", ""image fusion"", ""image resolution"", ""intelligent systems"", ""medical imaging"", ""monte carlo methods"", ""open systems""]",calibration;cameras;errors;image fusion;image resolution;intelligent systems;medical imaging;monte carlo methods;open systems,computer vision;education;graphics;input;medical;sensors;human factors;developers;artificial intelligence,technology;end users and user experience;industries,computer vision;education;graphics;input;medical;sensors;human factors;developers;artificial intelligence,technology;end users and user experience;industries,calibration cameras errors image_fusion image_resolution intelligent_systems medical_imaging monte_carlo_methods open_systems calibration_data calibration_techniques camera_calibration datapoints hand eye_calibration image_guided_surgery open_source_implementation open source projection_error video based 461 1_biomedical_engineering 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 4_artificial_intelligence 742 2_photographic_equipment 746_imaging_techniques 922 2_mathematical_statistics computer_vision education graphics input medical sensors human_factors developers artificial_intelligence,calibration cameras errors image_fusion image_resolution intelligent_systems medical_imaging monte_carlo_methods open_systems,calibration_data calibration_techniques camera_calibration datapoints hand eye_calibration image_guided_surgery open_source_implementation open source projection_error video based,augmented reality becoming prevalent modern video based surgical navigation system augmented reality form image fusion virtual object e virtual representation anatomy derived preoperative imaging modality real object e anatomy imaged spatially tracked surgical camera facilitate visualization perception surgical scene however requires spatial calibration external tracking system optical axis surgical camera known hand eye calibration standard implementation common hand eye calibration technique static photo based time required data collection may inhibit thoroughness robustness achieve accurate calibration address translational issue introduce video based hand eye calibration technique open source implementation accurate robust based point line procrustean registration short video tracked pivot calibrated ball tip stylus recorded frame tracked video 3d position ball tip point projection onto video line serve calibration data point devise data sampling mechanism designed optimize spatial configuration calibration fiducials leading consistently high quality hand eye calibration demonstrate efficacy work monte carlo simulation performed obtain mean target projection error function number calibration data point result obtained exemplified using logitech c920 pro hd webcam image resolution 640 time 480 show mean projection error decreased data point used per calibration majority mean projection error fell 4 pixel open source implementation form 3d slicer module available github copy 2023 spie,calibration cameras errors image_fusion image_resolution intelligent_systems medical_imaging monte_carlo_methods open_systems calibration_data calibration_techniques camera_calibration datapoints hand eye_calibration image_guided_surgery open_source_implementation open source projection_error video based 461 1_biomedical_engineering 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 4_artificial_intelligence 742 2_photographic_equipment 746_imaging_techniques 922 2_mathematical_statistics computer_vision education graphics input medical sensors human_factors developers artificial_intelligence augmented reality becoming prevalent modern video based surgical navigation system augmented reality form image fusion virtual object e virtual representation anatomy derived preoperative imaging modality real object e anatomy imaged spatially tracked surgical camera facilitate visualization perception surgical scene however requires spatial calibration external tracking system optical axis surgical camera known hand eye calibration standard implementation common hand eye calibration technique static photo based time required data collection may inhibit thoroughness robustness achieve accurate calibration address translational issue introduce video based hand eye calibration technique open source implementation accurate robust based point line procrustean registration short video tracked pivot calibrated ball tip stylus recorded frame tracked video 3d position ball tip point projection onto video line serve calibration data point devise data sampling mechanism designed optimize spatial configuration calibration fiducials leading consistently high quality hand eye calibration demonstrate efficacy work monte carlo simulation performed obtain mean target projection error function number calibration data point result obtained exemplified using logitech c920 pro hd webcam image resolution 640 time 480 show mean projection error decreased data point used per calibration majority mean projection error fell 4 pixel open source implementation form 3d slicer module available github copy 2023 spie,augmented reality becoming prevalent modern video based surgical navigation system augmented reality form image fusion virtual object e virtual representation anatomy derived preoperative imaging modality real object e anatomy imaged spatially tracked surgical camera facilitate visualization perception surgical scene however requires spatial calibration external tracking system optical axis surgical camera known hand eye calibration standard implementation common hand eye calibration technique static photo based time required data collection may inhibit thoroughness robustness achieve accurate calibration address translational issue introduce video based hand eye calibration technique open source implementation accurate robust based point line procrustean registration short video tracked pivot calibrated ball tip stylus recorded frame tracked video 3d position ball tip point projection onto video line serve calibration data point devise data sampling mechanism designed optimize spatial configuration calibration fiducials leading consistently high quality hand eye calibration demonstrate efficacy work monte carlo simulation performed obtain mean target projection error function number calibration data point result obtained exemplified using logitech c920 pro hd webcam image resolution 640 time 480 show mean projection error decreased data point used per calibration majority mean projection error fell 4 pixel open source implementation form 3d slicer module available github copy 2023 spiecalibration cameras errors image_fusion image_resolution intelligent_systems medical_imaging monte_carlo_methods open_systemscalibration_data calibration_techniques camera_calibration datapoints hand eye_calibration image_guided_surgery open_source_implementation open source projection_error video based
434,Digital tools in chemical engineering education: The needs and the desires,"Udugama, I. A., Atkins, M., Bayer, C., Carson, J., Dikicioglu, D., Gernaey, K. V., Glassey, J., Taylor, M., & Young, B. R. (2023). Digital tools in chemical engineering education: The needs and the desires. Education for Chemical Engineers, 44, 63–70. https://doi.org/10.1016/j.ece.2023.05.002
",10.1016/j.ece.2023.05.002,"Educators in chemical engineering have a long and rich history of employing digital tools to solve fundamental engineering problems. Today, with the megatrend of digitalisation, there is a growing set of tools that can be used for chemical engineering education. However, identifying which tool is ideally suited to support teaching a given chemical engineering concept can be challenging. To answer this question a survey was distributed to Heads of Departments at IChemE institutions and members of the IChemE committees focused on digitalisation. The survey respondents rated Microsoft Excel (VBA), commercial simulators, and scripting tools as ideal for teaching core subjects such as mass and energy balances, mass transfer and reaction engineering while respondents found 3D Models, and Virtual/Augmented Reality models as being most suited for teaching subjects such as process design, safety and sustainability. Mathematical/programming simplicity, ease of maintenance, and low initial investment costs were identified as key non-technical aspects that will hinder the adoption of a given digital tool. Weighing the benefits of education and non-technical hurdles, the respondents preferred the use of simpler digitalisation platforms such as Excel and scripting languages over the more advanced platforms such as Virtual/Augmented Reality where possible. It was identified that the widespread adoption of more advanced digitalisation tools will require removal of the above mentioned non-technical barriers as well as other barriers such as tool shareability. &copy; 2023 Institution of Chemical Engineers",641.3 Mass Transfer;901.2 Education,Chemical engineering education;Digital tool in education;Digital tools;Digitalization;Engineering concepts;Engineering problems;Excel-VBA;Megatrends;Microsoft excel;Non-technical barriers,Digital devices;Engineering education;Investments;Mass transfer,2023,Journal article (JA),Educ. Chem. Eng.,"(1) Udugama, Isuru A.; (1) Atkins, Martin; (2) Bayer, Christoph; (1) Carson, James; (3) Dikicioglu, Duygu; (4) Gernaey, Krist V.; (5) Glassey, Jarka; (1) Taylor, Matthew; (6) Young, Brent R.; ","(1) Ahuora &ndash; Centre for Smart Energy Systems, School of Engineering, University of Waikato, Hamilton; 3240, New Zealand; (2) Department of Process Engineering, TH N&uuml;rnberg, N&uuml;rnberg; 90489, Germany; (3) The Advanced Centre for Biochemical Engineering, Department of Biochemical Engineering, University College London, London; WC1E 6BT, United Kingdom; (4) PROSYS Research Center, Department of Chemical and Biochemical Engineering, Technical University of Denmark, S&oslash;ltofts Plads, Building 228A, Kgs. Lyngby; 2800, Denmark; (5) School of Engineering, Merz Court, Newcastle University, Newcastle upon Tyne; NE1 7RU, United Kingdom; (6) Department of Chemical and Materials Engineering, University of Auckland, Private Bag 92019, Auckland, New Zealand; ",Elsevier B.V.,-1,"[""digital devices"", ""engineering education"", ""investments"", ""mass transfer""]","[""digital devices"", ""engineering education"", ""investments"", ""mass transfer""]",digital devices;engineering education;investments;mass transfer,other;education;business planning and management,other;business;industries,other;education;business planning and management,other;business;industries,digital_devices engineering_education investments mass_transfer chemical_engineering_education digital_tool_in_education digital_tools digitalization engineering_concepts engineering_problems excel vba megatrends microsoft_excel non technical_barriers 641 3_mass_transfer 901 2_education other education business_planning_and_management,digital_devices engineering_education investments mass_transfer,chemical_engineering_education digital_tool_in_education digital_tools digitalization engineering_concepts engineering_problems excel vba megatrends microsoft_excel non technical_barriers,educator chemical engineering long rich history employing digital tool solve fundamental engineering problem today megatrend digitalisation growing set tool used chemical engineering education however identifying tool ideally suited support teaching given chemical engineering concept challenging answer question survey distributed head department icheme institution member icheme committee focused digitalisation survey respondent rated microsoft excel vba commercial simulator scripting tool ideal teaching core subject mass energy balance mass transfer reaction engineering respondent found 3d model virtual augmented reality model suited teaching subject process design safety sustainability mathematical programming simplicity ease maintenance low initial investment cost identified key non technical aspect hinder adoption given digital tool weighing benefit education non technical hurdle respondent preferred use simpler digitalisation platform excel scripting language advanced platform virtual augmented reality possible identified widespread adoption advanced digitalisation tool require removal mentioned non technical barrier well barrier tool shareability copy 2023 institution chemical engineer,digital_devices engineering_education investments mass_transfer chemical_engineering_education digital_tool_in_education digital_tools digitalization engineering_concepts engineering_problems excel vba megatrends microsoft_excel non technical_barriers 641 3_mass_transfer 901 2_education other education business_planning_and_management educator chemical engineering long rich history employing digital tool solve fundamental engineering problem today megatrend digitalisation growing set tool used chemical engineering education however identifying tool ideally suited support teaching given chemical engineering concept challenging answer question survey distributed head department icheme institution member icheme committee focused digitalisation survey respondent rated microsoft excel vba commercial simulator scripting tool ideal teaching core subject mass energy balance mass transfer reaction engineering respondent found 3d model virtual augmented reality model suited teaching subject process design safety sustainability mathematical programming simplicity ease maintenance low initial investment cost identified key non technical aspect hinder adoption given digital tool weighing benefit education non technical hurdle respondent preferred use simpler digitalisation platform excel scripting language advanced platform virtual augmented reality possible identified widespread adoption advanced digitalisation tool require removal mentioned non technical barrier well barrier tool shareability copy 2023 institution chemical engineer,educator chemical engineering long rich history employing digital tool solve fundamental engineering problem today megatrend digitalisation growing set tool used chemical engineering education however identifying tool ideally suited support teaching given chemical engineering concept challenging answer question survey distributed head department icheme institution member icheme committee focused digitalisation survey respondent rated microsoft excel vba commercial simulator scripting tool ideal teaching core subject mass energy balance mass transfer reaction engineering respondent found 3d model virtual augmented reality model suited teaching subject process design safety sustainability mathematical programming simplicity ease maintenance low initial investment cost identified key non technical aspect hinder adoption given digital tool weighing benefit education non technical hurdle respondent preferred use simpler digitalisation platform excel scripting language advanced platform virtual augmented reality possible identified widespread adoption advanced digitalisation tool require removal mentioned non technical barrier well barrier tool shareability copy 2023 institution chemical engineerdigital_devices engineering_education investments mass_transferchemical_engineering_education digital_tool_in_education digital_tools digitalization engineering_concepts engineering_problems excel vba megatrends microsoft_excel non technical_barriers
435,A Planar Object Tracking Algorithm with Balanced Speed and Accuracy,"Li, S., Li, P., & Wen, S. (2023). A Planar Object Tracking Algorithm with Balanced Speed and Accuracy. Proceedings of the International Conference on Internet of Things, Communication and Intelligent Technology, 521–528. https://doi.org/10.1007/978-981-99-0416-7_52
",10.1007/978-981-99-0416-7_52,"The planar object tracking algorithm are widely used in robot navigation, intelligent video surveillance, human-computer interaction and augmented reality. For the given object in the first image of the video, the task of the planar object tracking algorithm is to mark the location of the object in subsequent images. In recent years, the research on planar object tracking technology has made great progress, but most tracking algorithms with strong robustness and high accuracy have a slow speed. In this paper, a planar object tracking algorithm combining GIFT feature descriptor and ORB feature descriptor is proposed to solve this problem. The algorithm first uses the faster tracker based on the ORB feature descriptor to track, and if the difference between the obtained tracking result and the previous frame tracking result is larger than a certain threshold, the tracker based on the GIFT feature descriptor will be used. In particular, the threshold can be adjusted to balance the speed and accuracy of the algorithm. Experimental results on POT dataset show when the threshold is 15, the algorithm has a good performance. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications;731.5 Robotics;731.6 Robot Applications;914.1 Accidents and Accident Prevention",Feature descriptors;Intelligent video surveillance;Object Tracking;Object tracking algorithm;Planar object tracking;Planar objects;POT dataset;Robot navigation;Tracking algorithm;Tracking technology,Human computer interaction;Human robot interaction;Intelligent robots;Security systems;Tracking (position),2023,Conference article (CA),Lect. Notes Electr. Eng.,"(1) Li, Shaopeng; (1) Li, Pengxiang; (1) Wen, Suinan; ","(1) Zhengzhou University, Henan, Zhengzhou; 450001, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""human computer interaction"", ""human-robot interaction"", ""intelligent robots"", ""security systems"", ""tracking""]","[""human computer interaction"", ""human-robot interaction"", ""intelligent robots"", ""security systems"", ""tracking""]",human computer interaction;human-robot interaction;intelligent robots;security systems;tracking,computer vision;education;security;robotics;human-computer interaction,technology;end users and user experience;industries,computer vision;education;security;robotics;human-computer interaction,technology;end users and user experience;industries,human_computer_interaction human robot_interaction intelligent_robots security_systems tracking feature_descriptors intelligent_video_surveillance object_tracking object_tracking_algorithm planar_object_tracking planar_objects pot_dataset robot_navigation tracking_algorithm tracking_technology 723_computer_software _data_handling_and_applications 731 5_robotics 731 6_robot_applications 914 1_accidents_and_accident_prevention computer_vision education security robotics human computer_interaction,human_computer_interaction human robot_interaction intelligent_robots security_systems tracking,feature_descriptors intelligent_video_surveillance object_tracking object_tracking_algorithm planar_object_tracking planar_objects pot_dataset robot_navigation tracking_algorithm tracking_technology,planar object tracking algorithm widely used robot navigation intelligent video surveillance human computer interaction augmented reality given object first image video task planar object tracking algorithm mark location object subsequent image recent year research planar object tracking technology made great progress tracking algorithm strong robustness high accuracy slow speed paper planar object tracking algorithm combining gift feature descriptor orb feature descriptor proposed solve problem algorithm first us faster tracker based orb feature descriptor track difference obtained tracking result previous frame tracking result larger certain threshold tracker based gift feature descriptor used particular threshold adjusted balance speed accuracy algorithm experimental result pot dataset show threshold 15 algorithm good performance copy 2023 author exclusive license springer nature singapore pte ltd,human_computer_interaction human robot_interaction intelligent_robots security_systems tracking feature_descriptors intelligent_video_surveillance object_tracking object_tracking_algorithm planar_object_tracking planar_objects pot_dataset robot_navigation tracking_algorithm tracking_technology 723_computer_software _data_handling_and_applications 731 5_robotics 731 6_robot_applications 914 1_accidents_and_accident_prevention computer_vision education security robotics human computer_interaction planar object tracking algorithm widely used robot navigation intelligent video surveillance human computer interaction augmented reality given object first image video task planar object tracking algorithm mark location object subsequent image recent year research planar object tracking technology made great progress tracking algorithm strong robustness high accuracy slow speed paper planar object tracking algorithm combining gift feature descriptor orb feature descriptor proposed solve problem algorithm first us faster tracker based orb feature descriptor track difference obtained tracking result previous frame tracking result larger certain threshold tracker based gift feature descriptor used particular threshold adjusted balance speed accuracy algorithm experimental result pot dataset show threshold 15 algorithm good performance copy 2023 author exclusive license springer nature singapore pte ltd,planar object tracking algorithm widely used robot navigation intelligent video surveillance human computer interaction augmented reality given object first image video task planar object tracking algorithm mark location object subsequent image recent year research planar object tracking technology made great progress tracking algorithm strong robustness high accuracy slow speed paper planar object tracking algorithm combining gift feature descriptor orb feature descriptor proposed solve problem algorithm first us faster tracker based orb feature descriptor track difference obtained tracking result previous frame tracking result larger certain threshold tracker based gift feature descriptor used particular threshold adjusted balance speed accuracy algorithm experimental result pot dataset show threshold 15 algorithm good performance copy 2023 author exclusive license springer nature singapore pte ltdhuman_computer_interaction human robot_interaction intelligent_robots security_systems trackingfeature_descriptors intelligent_video_surveillance object_tracking object_tracking_algorithm planar_object_tracking planar_objects pot_dataset robot_navigation tracking_algorithm tracking_technology
436,A Review of Research on Virtual Reality Technology Based on Human-Computer Interaction in Military,"Qiu, R., Xu, W., Wang, B., & Shen, Q. (2022). A Review of Research on Virtual Reality Technology Based on Human-Computer Interaction in Military. 2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT). https://doi.org/10.1109/acait56212.2022.10137916
",10.1109/ACAIT56212.2022.10137916,"Recent research shows that virtual reality is starting to be used in various field around the world. Virtual reality also has great application value in the civil industry, entertainment and education industries. However, compares to augmented reality, virtual reality has came into a period of bottleneck. Although virtual reality is developing rapidly, the effectiveness and using situation of virtual reality in practical application is still missing. Military operations are also seeking new developments and changes of virtual reality. By applying virtual reality into combat training, decision-making simulation and soldier training can reduce injury risk efficiently. This article classifies and summarizes current virtual reality technology applied in the military field, and looks forward to the virtual reality in military training, learning and actual warfares practical applications.",C7465 Military engineering computing;C6130V Virtual reality;C6180 User interfaces;C7810C Computer-aided instruction,combat training;current virtual reality technology;decision-making simulation;human-computer interaction;injury risk reduction;military operations;military training;soldier training;warfares practical application,computer based training;decision making;human computer interaction;injuries;military computing;virtual reality,2022,Conference article (CA),2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT),"(1) Qiu, R.; (1) Xu, W.; (1) Wang, B.; (1) Shen, Q.; ","(1) Department of No.23 Shanghai Aerospace, Electronic and Communication Equipment Research Institute, China; ",IEEE,-1,"[""computer based training"", ""decision making"", ""human computer interaction"", ""injuries"", ""military computing""]","[""computer based training"", ""decision making"", ""human computer interaction"", ""injuries"", ""military computing""]",computer based training;decision making;human computer interaction;injuries;military computing,farming and natural science;medical;government;training;human factors;human-computer interaction,end users and user experience;use cases;industries,farming and natural science;medical;government;training;human factors;human-computer interaction,end users and user experience;use cases;industries,computer_based_training decision_making human_computer_interaction injuries military_computing combat_training current_virtual_reality_technology decision making_simulation human computer_interaction injury_risk_reduction military_operations military_training soldier_training warfares_practical_application c7465_military_engineering_computing c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction farming_and_natural_science medical government training human_factors human computer_interaction,computer_based_training decision_making human_computer_interaction injuries military_computing,combat_training current_virtual_reality_technology decision making_simulation human computer_interaction injury_risk_reduction military_operations military_training soldier_training warfares_practical_application,recent research show virtual reality starting used various field around world virtual reality also great application value civil industry entertainment education industry however compare augmented reality virtual reality came period bottleneck although virtual reality developing rapidly effectiveness using situation virtual reality practical application still missing military operation also seeking new development change virtual reality applying virtual reality combat training decision making simulation soldier training reduce injury risk efficiently article classifies summarizes current virtual reality technology applied military field look forward virtual reality military training learning actual warfare practical application,computer_based_training decision_making human_computer_interaction injuries military_computing combat_training current_virtual_reality_technology decision making_simulation human computer_interaction injury_risk_reduction military_operations military_training soldier_training warfares_practical_application c7465_military_engineering_computing c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction farming_and_natural_science medical government training human_factors human computer_interaction recent research show virtual reality starting used various field around world virtual reality also great application value civil industry entertainment education industry however compare augmented reality virtual reality came period bottleneck although virtual reality developing rapidly effectiveness using situation virtual reality practical application still missing military operation also seeking new development change virtual reality applying virtual reality combat training decision making simulation soldier training reduce injury risk efficiently article classifies summarizes current virtual reality technology applied military field look forward virtual reality military training learning actual warfare practical application,recent research show virtual reality starting used various field around world virtual reality also great application value civil industry entertainment education industry however compare augmented reality virtual reality came period bottleneck although virtual reality developing rapidly effectiveness using situation virtual reality practical application still missing military operation also seeking new development change virtual reality applying virtual reality combat training decision making simulation soldier training reduce injury risk efficiently article classifies summarizes current virtual reality technology applied military field look forward virtual reality military training learning actual warfare practical applicationcomputer_based_training decision_making human_computer_interaction injuries military_computingcombat_training current_virtual_reality_technology decision making_simulation human computer_interaction injury_risk_reduction military_operations military_training soldier_training warfares_practical_application
437,Compact imaging system based on multi-variable focal lens system in AR display,"Lee, J.-S., Cho, S.-H., Lee, S.-J., Choi, W. J., & Choi, Y.-W. (2023). Compact imaging system based on multi-variable focal lens system in AR display. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2648207
",10.1117/12.2648207,"Augmented reality (AR) has been attracted considerable attention according to the demand for non-face-to-face services. The principle of AR is overlapping a virtual image in the real world. To display a virtual image at a proper position, depth of field is a significant factor. In this paper, we propose a multi-variable focal lens system that can dynamically tune a depth of field. By using a multifocal lens that has several different focal lengths, an image has depth information corresponding to each focal length. A focus tunable lens controls a focused area and magnification to display the appropriate position and size. The proposed system has a huge advantage in form factor and fever issues owing to its simple architecture. In order to verify the feasibility of the system for AR, numerical simulations are performed. The system divides a 2D image into focused and defocused areas. Focused and defocused areas show feasibility that can be tuned by the multifocal lens and focus tunable lens. The results show the depth range from 0.3 m to 2 m (3.3D to 0.5D), which is determined by the design of the system. &copy; 2023 SPIE.","723 Computer Software, Data Handling and Applications;741.3 Optical Devices and Systems",Depth of field;Face to face;Focal lengths;Focal lens;Focus tunable lens;Lens systems;Multi variables;Multifocal lens;Tunable lens;Virtual images,Microlenses,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Lee, Jae-Sang; (1) Cho, Seong-Hyun; (1) Lee, Seung-Jin; (1) Choi, Woo June; (1) Choi, Young-Wan; ","(1) Department of Electrical and Electronics Engineering, Chung-Ang University, 84, Heukseok-ro, Dongjak-gu, Seoul, Korea, Republic of; ",SPIE,-1,"[""microlenses""]","[""microlenses""]",microlenses,display technology;optics,displays,display technology;optics,displays,microlenses depth_of_field face_to_face focal_lengths focal_lens focus_tunable_lens lens_systems multi_variables multifocal_lens tunable_lens virtual_images 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems display_technology optics,microlenses,depth_of_field face_to_face focal_lengths focal_lens focus_tunable_lens lens_systems multi_variables multifocal_lens tunable_lens virtual_images,augmented reality ar attracted considerable attention according demand non face face service principle ar overlapping virtual image real world display virtual image proper position depth field significant factor paper propose multi variable focal lens system dynamically tune depth field using multifocal lens several different focal length image depth information corresponding focal length focus tunable lens control focused area magnification display appropriate position size proposed system huge advantage form factor fever issue owing simple architecture order verify feasibility system ar numerical simulation performed system divide 2d image focused defocused area focused defocused area show feasibility tuned multifocal lens focus tunable lens result show depth range 0 3 2 3 3d 0 5d determined design system copy 2023 spie,microlenses depth_of_field face_to_face focal_lengths focal_lens focus_tunable_lens lens_systems multi_variables multifocal_lens tunable_lens virtual_images 723_computer_software _data_handling_and_applications 741 3_optical_devices_and_systems display_technology optics augmented reality ar attracted considerable attention according demand non face face service principle ar overlapping virtual image real world display virtual image proper position depth field significant factor paper propose multi variable focal lens system dynamically tune depth field using multifocal lens several different focal length image depth information corresponding focal length focus tunable lens control focused area magnification display appropriate position size proposed system huge advantage form factor fever issue owing simple architecture order verify feasibility system ar numerical simulation performed system divide 2d image focused defocused area focused defocused area show feasibility tuned multifocal lens focus tunable lens result show depth range 0 3 2 3 3d 0 5d determined design system copy 2023 spie,augmented reality ar attracted considerable attention according demand non face face service principle ar overlapping virtual image real world display virtual image proper position depth field significant factor paper propose multi variable focal lens system dynamically tune depth field using multifocal lens several different focal length image depth information corresponding focal length focus tunable lens control focused area magnification display appropriate position size proposed system huge advantage form factor fever issue owing simple architecture order verify feasibility system ar numerical simulation performed system divide 2d image focused defocused area focused defocused area show feasibility tuned multifocal lens focus tunable lens result show depth range 0 3 2 3 3d 0 5d determined design system copy 2023 spiemicrolensesdepth_of_field face_to_face focal_lengths focal_lens focus_tunable_lens lens_systems multi_variables multifocal_lens tunable_lens virtual_images
438,Image Stitching Based on Color Difference and KAZE with a Fast Guided Filter,"Zhang, C., Wang, D., & Sun, H. (2023). Image Stitching Based on Color Difference and KAZE with a Fast Guided Filter. Sensors, 23(10), 4583. https://doi.org/10.3390/s23104583
",10.3390/s23104583,"Image stitching is of great importance for multiple fields such as moving object detection and tracking, ground reconnaissance and augmented reality. To ameliorate the stitching effect and alleviate the mismatch rate, an effective image stitching algorithm based on color difference and an improved KAZE with a fast guided filter is proposed. Firstly, the fast guided filter is introduced to reduce the mismatch rate before feature matching. Secondly, the KAZE algorithm based on improved random sample consensus is used for feature matching. Then, the color difference and brightness difference of the overlapping area are calculated to make an overall adjustment to the original images so as to improve the nonuniformity of the splicing result. Finally, the warped images with color difference compensation are fused to obtain the stitched image. The proposed method is evaluated by both visual effect mapping and quantitative values. In addition, the proposed algorithm is compared with other current popular stitching algorithms. The results show that the proposed algorithm is superior to other algorithms in terms of the quantity of feature point pairs, the matching accuracy, the root mean square error and the mean absolute error. &copy; 2023 by the authors.","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;741.1 Light/Optics;922.2 Mathematical Statistics;941.4 Optical Variables Measurements",Color difference;Colour brightness;Fast guided filter;Features matching;Guided filters;Image stitching;KAZE;Moving object detection and tracking;Random sample consensus;RANSAC,Color;Colorimetry;Image enhancement;Mean square error;Object detection,2023,Journal article (JA),Sensors,"(1) Zhang, Chong; (1) Wang, Dejiang; (1) Sun, He; ","(1) Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun; 130033, China; ",MDPI,-1,"[""color"", ""colorimetry"", ""image enhancement"", ""mean square error"", ""object detection""]","[""color"", ""colorimetry"", ""image enhancement"", ""mean square error"", ""object detection""]",color;colorimetry;image enhancement;mean square error;object detection,computer vision;graphics;data;input,technology,computer vision;graphics;data;input,technology,color colorimetry image_enhancement mean_square_error object_detection color_difference colour_brightness fast_guided_filter features_matching guided_filters image_stitching kaze moving_object_detection_and_tracking random_sample_consensus ransac 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 922 2_mathematical_statistics 941 4_optical_variables_measurements computer_vision graphics data input,color colorimetry image_enhancement mean_square_error object_detection,color_difference colour_brightness fast_guided_filter features_matching guided_filters image_stitching kaze moving_object_detection_and_tracking random_sample_consensus ransac,image stitching great importance multiple field moving object detection tracking ground reconnaissance augmented reality ameliorate stitching effect alleviate mismatch rate effective image stitching algorithm based color difference improved kaze fast guided filter proposed firstly fast guided filter introduced reduce mismatch rate feature matching secondly kaze algorithm based improved random sample consensus used feature matching color difference brightness difference overlapping area calculated make overall adjustment original image improve nonuniformity splicing result finally warped image color difference compensation fused obtain stitched image proposed method evaluated visual effect mapping quantitative value addition proposed algorithm compared current popular stitching algorithm result show proposed algorithm superior algorithm term quantity feature point pair matching accuracy root mean square error mean absolute error copy 2023 author,color colorimetry image_enhancement mean_square_error object_detection color_difference colour_brightness fast_guided_filter features_matching guided_filters image_stitching kaze moving_object_detection_and_tracking random_sample_consensus ransac 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 741 1_light optics 922 2_mathematical_statistics 941 4_optical_variables_measurements computer_vision graphics data input image stitching great importance multiple field moving object detection tracking ground reconnaissance augmented reality ameliorate stitching effect alleviate mismatch rate effective image stitching algorithm based color difference improved kaze fast guided filter proposed firstly fast guided filter introduced reduce mismatch rate feature matching secondly kaze algorithm based improved random sample consensus used feature matching color difference brightness difference overlapping area calculated make overall adjustment original image improve nonuniformity splicing result finally warped image color difference compensation fused obtain stitched image proposed method evaluated visual effect mapping quantitative value addition proposed algorithm compared current popular stitching algorithm result show proposed algorithm superior algorithm term quantity feature point pair matching accuracy root mean square error mean absolute error copy 2023 author,image stitching great importance multiple field moving object detection tracking ground reconnaissance augmented reality ameliorate stitching effect alleviate mismatch rate effective image stitching algorithm based color difference improved kaze fast guided filter proposed firstly fast guided filter introduced reduce mismatch rate feature matching secondly kaze algorithm based improved random sample consensus used feature matching color difference brightness difference overlapping area calculated make overall adjustment original image improve nonuniformity splicing result finally warped image color difference compensation fused obtain stitched image proposed method evaluated visual effect mapping quantitative value addition proposed algorithm compared current popular stitching algorithm result show proposed algorithm superior algorithm term quantity feature point pair matching accuracy root mean square error mean absolute error copy 2023 authorcolor colorimetry image_enhancement mean_square_error object_detectioncolor_difference colour_brightness fast_guided_filter features_matching guided_filters image_stitching kaze moving_object_detection_and_tracking random_sample_consensus ransac
439,Effective Extended Reality: A Mixed-Reality Simulation Demonstration with Digitized and Holographic Tools and Intelligent Avatars,"Salvetti, F., Gardner, R., Minehart, R., & Bertagni, B. (2022). Effective Extended Reality: A Mixed-Reality Simulation Demonstration with Digitized and Holographic Tools and Intelligent Avatars. Lecture Notes in Networks and Systems, 370–376. https://doi.org/10.1007/978-3-031-21569-8_35
",10.1007/978-3-031-21569-8_35,"How can we design engaging and effective medical education both online and onsite? Extended reality (XR) is a term referring to all real-and-virtual combined environments and human-machine interactions generated by computer technology and wearables. It includes representative forms such as virtual reality (VR), augmented reality (AR), or mixed reality (MR), and the areas interpolated among them. MR is a domain of particular interest today. It takes place not only in the physical world or in the virtual world, but is a mix of the real and the virtual. Metaverses can be enabled by MR wearable augments. Glasses-free MR is another very interesting dimension: e-REAL&#174;, as a MR environment for hybrid simulation and medical education in general, can be a stand-alone solution or even networked between multiple places through a link to a special videoconferencing system. Digital humans and human-sized holograms are part of the e-REAL scenarios, making this solution unique, rich, and diversified.",A0140 Education;A0260 Numerical approximation and analysis;C4130 Interpolation and function approximation (numerical analysis);C5430 Microcomputers;C6130V Virtual reality;C6180 User interfaces;C7810C Computer-aided instruction,-virtual combined environments;computer technology;digital humans;effective extended reality;effective medical education;human-machine interactions;hybrid simulation;mixed reality;mixed-reality simulation demonstration;MR wearable augments;real- environments;virtual world,avatars;biomedical education;computer aided instruction;human computer interaction;interpolation;wearable computers,2023,Conference article (CA),Innovative Approaches to Technology-Enhanced Learning for the Workplace and Higher Education: Proceedings of 'The Learning Ideas Conference' 2022. Lecture Notes in Networks and Systems (581),"(1) Salvetti, F.; (3) Gardner, R.; (3) Minehart, R.; (1) Bertagni, B.; ","(1) Centro Studi Logos, e-REAL Labs, Italy; (2) Centro Studi Logos, Houston, TX, United States; (3) Center for Medical Simulation, Boston, MA 2129, United States; (4) Massachusetts General Hospital, Boston, MA 2114, United States; ",Springer,-1,"[""avatars"", ""biomedical education"", ""computer aided instruction"", ""human computer interaction"", ""interpolation"", ""wearable computers""]","[""avatars"", ""biomedical education"", ""computer aided instruction"", ""human computer interaction"", ""interpolation"", ""wearable computers""]",avatars;biomedical education;computer aided instruction;human computer interaction;interpolation;wearable computers,"education;medical;inspection, safety and quality;presence;training;wearables;developers;data;human-computer interaction",displays;end users and user experience;industries;use cases;technology,"education;medical;inspection, safety and quality;presence;training;wearables;developers;data;human-computer interaction",displays;end users and user experience;industries;use cases;technology,avatars biomedical_education computer_aided_instruction human_computer_interaction interpolation wearable_computers virtual_combined_environments computer_technology digital_humans effective_extended_reality effective_medical_education human machine_interactions hybrid_simulation mixed_reality mixed reality_simulation_demonstration mr_wearable_augments real _environments virtual_world a0140_education a0260_numerical_approximation_and_analysis c4130_interpolation_and_function_approximation_ numerical_analysis c5430_microcomputers c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction education medical inspection _safety_and_quality presence training wearables developers data human computer_interaction,avatars biomedical_education computer_aided_instruction human_computer_interaction interpolation wearable_computers,virtual_combined_environments computer_technology digital_humans effective_extended_reality effective_medical_education human machine_interactions hybrid_simulation mixed_reality mixed reality_simulation_demonstration mr_wearable_augments real _environments virtual_world,design engaging effective medical education online onsite extended reality xr term referring real virtual combined environment human machine interaction generated computer technology wearable includes representative form virtual reality vr augmented reality ar mixed reality mr area interpolated among mr domain particular interest today take place physical world virtual world mix real virtual metaverses enabled mr wearable augments glass free mr another interesting dimension e real 174 mr environment hybrid simulation medical education general stand alone solution even networked multiple place link special videoconferencing system digital human human sized hologram part e real scenario making solution unique rich diversified,avatars biomedical_education computer_aided_instruction human_computer_interaction interpolation wearable_computers virtual_combined_environments computer_technology digital_humans effective_extended_reality effective_medical_education human machine_interactions hybrid_simulation mixed_reality mixed reality_simulation_demonstration mr_wearable_augments real _environments virtual_world a0140_education a0260_numerical_approximation_and_analysis c4130_interpolation_and_function_approximation_ numerical_analysis c5430_microcomputers c6130v_virtual_reality c6180_user_interfaces c7810c_computer aided_instruction education medical inspection _safety_and_quality presence training wearables developers data human computer_interaction design engaging effective medical education online onsite extended reality xr term referring real virtual combined environment human machine interaction generated computer technology wearable includes representative form virtual reality vr augmented reality ar mixed reality mr area interpolated among mr domain particular interest today take place physical world virtual world mix real virtual metaverses enabled mr wearable augments glass free mr another interesting dimension e real 174 mr environment hybrid simulation medical education general stand alone solution even networked multiple place link special videoconferencing system digital human human sized hologram part e real scenario making solution unique rich diversified,design engaging effective medical education online onsite extended reality xr term referring real virtual combined environment human machine interaction generated computer technology wearable includes representative form virtual reality vr augmented reality ar mixed reality mr area interpolated among mr domain particular interest today take place physical world virtual world mix real virtual metaverses enabled mr wearable augments glass free mr another interesting dimension e real 174 mr environment hybrid simulation medical education general stand alone solution even networked multiple place link special videoconferencing system digital human human sized hologram part e real scenario making solution unique rich diversifiedavatars biomedical_education computer_aided_instruction human_computer_interaction interpolation wearable_computersvirtual_combined_environments computer_technology digital_humans effective_extended_reality effective_medical_education human machine_interactions hybrid_simulation mixed_reality mixed reality_simulation_demonstration mr_wearable_augments real _environments virtual_world
440,Design of&nbsp;a&nbsp;Mixed Reality-Based Immersive Virtual Environment System for&nbsp;Social Interaction and&nbsp;Behavioral Studies,"Matar, S., Shaker, A., Mahmud, S., Kim, J.-H., & van’t Klooster, J.-W. (2023). Design of a Mixed Reality-Based Immersive Virtual Environment System for Social Interaction and Behavioral Studies. Lecture Notes in Computer Science, 201–212. https://doi.org/10.1007/978-3-031-27199-1_21
",10.1007/978-3-031-27199-1_21,"The advancements in immersive technologies allow us to create more sophisticated environments designed to help engage users by merging the physical world with a digital or simulated reality. These can range from completely immersive virtual environments to mixed reality immersive environments, where the virtual world and the real world collide. Virtual reality is a completely immersive environment where the users&rsquo; reality is replaced with a simulated environment, and the hardware works to convince the user that they are in a different world. In contrast, augmented reality is a mixed type of reality, combining both the virtual and the natural world by augmenting the real world with digital assets and components. While both types of experiences contribute to creating rich collaborative environments, a limitation, and sometimes inconvenience, is present with the requirement of wearing a head-mounted device (HMD), creating restriction that prevents users from having physical interactions with others. Rather than interacting in the virtual space, we propose a concept that provides the structure for a physical space where users can interact with the shared mixed reality environment, an environment projected to help create the collaborative aspect in this project without any wearable devices. This paper will present the developed system and implemented four-dimensional interactions and demonstrate the feasibility of the structured experience we have created. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications",Behavioural studies;Environment systems;Immersive environment;Immersive technologies;Immersive virtual environments;Interaction studies;Mixed reality;Mixed-reality environment;Real-world;Social interactions,Helmet mounted displays;Mixed reality,2023,Conference article (CA),Lect. Notes Comput. Sci.,"(1) Matar, Sophia; (1) Shaker, Alfred; (1) Mahmud, Saifuddin; (1) Kim, Jong-Hoon; (2) van&rsquo;t Klooster, Jan-Willem; ","(1) Advanced Telerobotics Research Lab, Computer Science, Kent State University, Kent; OH, United States; (2) The BMS Lab, University of Twente, Enschede, Netherlands; ",Springer Science and Business Media Deutschland GmbH,-1,"[""helmet mounted displays""]","[""helmet mounted displays""]",helmet mounted displays,display technology;wearables,displays,display technology;wearables,displays,helmet_mounted_displays behavioural_studies environment_systems immersive_environment immersive_technologies immersive_virtual_environments interaction_studies mixed_reality mixed reality_environment real world social_interactions 723_computer_software _data_handling_and_applications display_technology wearables,helmet_mounted_displays,behavioural_studies environment_systems immersive_environment immersive_technologies immersive_virtual_environments interaction_studies mixed_reality mixed reality_environment real world social_interactions,advancement immersive technology allow u create sophisticated environment designed help engage user merging physical world digital simulated reality range completely immersive virtual environment mixed reality immersive environment virtual world real world collide virtual reality completely immersive environment user rsquo reality replaced simulated environment hardware work convince user different world contrast augmented reality mixed type reality combining virtual natural world augmenting real world digital asset component type experience contribute creating rich collaborative environment limitation sometimes inconvenience present requirement wearing head mounted device hmd creating restriction prevents user physical interaction others rather interacting virtual space propose concept provides structure physical space user interact shared mixed reality environment environment projected help create collaborative aspect project without wearable device paper present developed system implemented four dimensional interaction demonstrate feasibility structured experience created copy 2023 author exclusive license springer nature switzerland ag,helmet_mounted_displays behavioural_studies environment_systems immersive_environment immersive_technologies immersive_virtual_environments interaction_studies mixed_reality mixed reality_environment real world social_interactions 723_computer_software _data_handling_and_applications display_technology wearables advancement immersive technology allow u create sophisticated environment designed help engage user merging physical world digital simulated reality range completely immersive virtual environment mixed reality immersive environment virtual world real world collide virtual reality completely immersive environment user rsquo reality replaced simulated environment hardware work convince user different world contrast augmented reality mixed type reality combining virtual natural world augmenting real world digital asset component type experience contribute creating rich collaborative environment limitation sometimes inconvenience present requirement wearing head mounted device hmd creating restriction prevents user physical interaction others rather interacting virtual space propose concept provides structure physical space user interact shared mixed reality environment environment projected help create collaborative aspect project without wearable device paper present developed system implemented four dimensional interaction demonstrate feasibility structured experience created copy 2023 author exclusive license springer nature switzerland ag,advancement immersive technology allow u create sophisticated environment designed help engage user merging physical world digital simulated reality range completely immersive virtual environment mixed reality immersive environment virtual world real world collide virtual reality completely immersive environment user rsquo reality replaced simulated environment hardware work convince user different world contrast augmented reality mixed type reality combining virtual natural world augmenting real world digital asset component type experience contribute creating rich collaborative environment limitation sometimes inconvenience present requirement wearing head mounted device hmd creating restriction prevents user physical interaction others rather interacting virtual space propose concept provides structure physical space user interact shared mixed reality environment environment projected help create collaborative aspect project without wearable device paper present developed system implemented four dimensional interaction demonstrate feasibility structured experience created copy 2023 author exclusive license springer nature switzerland aghelmet_mounted_displaysbehavioural_studies environment_systems immersive_environment immersive_technologies immersive_virtual_environments interaction_studies mixed_reality mixed reality_environment real world social_interactions
441,Ultrafast black color tunability of electrochromic dimming films using polyoxometalate-anchored metal oxide nanoparticles,"Jang, H., Kim, J., & Kim, E. (2023). Ultrafast black color tunability of electrochromic dimming films using polyoxometalate-anchored metal oxide nanoparticles. Organic Photonic Materials and Devices XXV. https://doi.org/10.1117/12.2648690
",10.1117/12.2648690,"The fast switchable electrochromic (EC) materials have strong interest for controlling unnecessary lights from environment or achieving color tunability in transmissive-type and reflective-type display. In this study, a black color tunability of electrochromic dimming device was explored using polyoxometalate (PW)-anchored metal oxide (MOx) nanoparticles, poly(3,3-bis(bromomethyl)-3,4-dihydro-2H-thieno[3,4-b][1,4]dioxepine)s (PRBr), and an acid-free electrolyte layer. The PW-anchored MOx (PWMOx) layer was formed by electrostatic anchoring between the protonated MOx film and PW anion on a transparent electrode. The PWMOx was not only gave positive feedback to the electrochromic performance of its film, but also lowered the operating voltage by increasing the potential applied to the polymer layer in the electrochromic device, achieved black EC switching with high transparency modulation, a fast response time, and long endurance at a low operating voltage between 1.5 and -1.5 V. Furthermore, the boosted EC polymer properties arising from the charge balancing effect had the blocking capability for high-intensity light, such as 240 cd/m2 and ~ 2379 cd/m2 of light. The ECD blocked light transmission up to 95 % and dimming was adaptable to step voltage. This strategy may be coupled with various devices, including smart windows, transparent displays, image sensors, and augmented reality systems. &copy; 2023 SPIE.",701.1 Electricity: Basic Concepts and Phenomena;702 Electric Batteries and Fuel Cells;714 Electronic Components and Tubes;722.2 Computer Peripheral Equipment;731.1 Control Systems;741.1 Light/Optics;741.3 Optical Devices and Systems;761 Nanotechnology;803 Chemical Agents and Basic Industrial Chemicals;804 Chemical Products Generally,Black electrochromic device;Color tunability;Electrochromic dimming device;Electrochromic materials;Electrochromics;Fast electrochromism;Metal oxide nanoparticles;Polyoxometalates;Switchable;Ultra-fast,Color;Display devices;Electrochromic devices;Electrolytes;Feedback;High intensity light;Light transmission;Metal nanoparticles;Oxide films;Oxides;Transparent electrodes,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Jang, Hwandong; (1) Kim, Jinbo; (1) Kim, Eunkyoung; ","(1) Dept. of Chemical and Biomolecular Engineering, Yonsei University, 50 Yonsei-ro, Seodaemun-gu, Seoul; 03722, Korea, Republic of; ",SPIE,-1,"[""color"", ""display devices"", ""electrochromic devices"", ""electrolytes"", ""feedback"", ""high intensity light"", ""light transmission"", ""metal nanoparticles"", ""oxide films"", ""oxides"", ""transparent electrodes""]","[""color"", ""display devices"", ""electrochromic devices"", ""electrolytes"", ""feedback"", ""high intensity light"", ""light transmission"", ""metal nanoparticles"", ""oxide films"", ""oxides"", ""transparent electrodes""]",color;display devices;electrochromic devices;electrolytes;feedback;high intensity light;light transmission;metal nanoparticles;oxide films;oxides;transparent electrodes,farming and natural science;other;graphics;input;liberal arts;display technology;human-computer interaction,other;displays;end users and user experience;industries;technology,farming and natural science;other;graphics;input;liberal arts;display technology;human-computer interaction,other;displays;end users and user experience;industries;technology,color display_devices electrochromic_devices electrolytes feedback high_intensity_light light_transmission metal_nanoparticles oxide_films oxides transparent_electrodes black_electrochromic_device color_tunability electrochromic_dimming_device electrochromic_materials electrochromics fast_electrochromism metal_oxide_nanoparticles polyoxometalates switchable ultra fast 701 1_electricity _basic_concepts_and_phenomena 702_electric_batteries_and_fuel_cells 714_electronic_components_and_tubes 722 2_computer_peripheral_equipment 731 1_control_systems 741 1_light optics 741 3_optical_devices_and_systems 761_nanotechnology 803_chemical_agents_and_basic_industrial_chemicals 804_chemical_products_generally farming_and_natural_science other graphics input liberal_arts display_technology human computer_interaction,color display_devices electrochromic_devices electrolytes feedback high_intensity_light light_transmission metal_nanoparticles oxide_films oxides transparent_electrodes,black_electrochromic_device color_tunability electrochromic_dimming_device electrochromic_materials electrochromics fast_electrochromism metal_oxide_nanoparticles polyoxometalates switchable ultra fast,fast switchable electrochromic ec material strong interest controlling unnecessary light environment achieving color tunability transmissive type reflective type display study black color tunability electrochromic dimming device explored using polyoxometalate pw anchored metal oxide mox nanoparticles poly 3 3 bi bromomethyl 3 4 dihydro 2h thieno 3 4 b 1 4 dioxepine prbr acid free electrolyte layer pw anchored mox pwmox layer formed electrostatic anchoring protonated mox film pw anion transparent electrode pwmox gave positive feedback electrochromic performance film also lowered operating voltage increasing potential applied polymer layer electrochromic device achieved black ec switching high transparency modulation fast response time long endurance low operating voltage 1 5 1 5 v furthermore boosted ec polymer property arising charge balancing effect blocking capability high intensity light 240 cd m2 2379 cd m2 light ecd blocked light transmission 95 dimming adaptable step voltage strategy may coupled various device including smart window transparent display image sensor augmented reality system copy 2023 spie,color display_devices electrochromic_devices electrolytes feedback high_intensity_light light_transmission metal_nanoparticles oxide_films oxides transparent_electrodes black_electrochromic_device color_tunability electrochromic_dimming_device electrochromic_materials electrochromics fast_electrochromism metal_oxide_nanoparticles polyoxometalates switchable ultra fast 701 1_electricity _basic_concepts_and_phenomena 702_electric_batteries_and_fuel_cells 714_electronic_components_and_tubes 722 2_computer_peripheral_equipment 731 1_control_systems 741 1_light optics 741 3_optical_devices_and_systems 761_nanotechnology 803_chemical_agents_and_basic_industrial_chemicals 804_chemical_products_generally farming_and_natural_science other graphics input liberal_arts display_technology human computer_interaction fast switchable electrochromic ec material strong interest controlling unnecessary light environment achieving color tunability transmissive type reflective type display study black color tunability electrochromic dimming device explored using polyoxometalate pw anchored metal oxide mox nanoparticles poly 3 3 bi bromomethyl 3 4 dihydro 2h thieno 3 4 b 1 4 dioxepine prbr acid free electrolyte layer pw anchored mox pwmox layer formed electrostatic anchoring protonated mox film pw anion transparent electrode pwmox gave positive feedback electrochromic performance film also lowered operating voltage increasing potential applied polymer layer electrochromic device achieved black ec switching high transparency modulation fast response time long endurance low operating voltage 1 5 1 5 v furthermore boosted ec polymer property arising charge balancing effect blocking capability high intensity light 240 cd m2 2379 cd m2 light ecd blocked light transmission 95 dimming adaptable step voltage strategy may coupled various device including smart window transparent display image sensor augmented reality system copy 2023 spie,fast switchable electrochromic ec material strong interest controlling unnecessary light environment achieving color tunability transmissive type reflective type display study black color tunability electrochromic dimming device explored using polyoxometalate pw anchored metal oxide mox nanoparticles poly 3 3 bi bromomethyl 3 4 dihydro 2h thieno 3 4 b 1 4 dioxepine prbr acid free electrolyte layer pw anchored mox pwmox layer formed electrostatic anchoring protonated mox film pw anion transparent electrode pwmox gave positive feedback electrochromic performance film also lowered operating voltage increasing potential applied polymer layer electrochromic device achieved black ec switching high transparency modulation fast response time long endurance low operating voltage 1 5 1 5 v furthermore boosted ec polymer property arising charge balancing effect blocking capability high intensity light 240 cd m2 2379 cd m2 light ecd blocked light transmission 95 dimming adaptable step voltage strategy may coupled various device including smart window transparent display image sensor augmented reality system copy 2023 spiecolor display_devices electrochromic_devices electrolytes feedback high_intensity_light light_transmission metal_nanoparticles oxide_films oxides transparent_electrodesblack_electrochromic_device color_tunability electrochromic_dimming_device electrochromic_materials electrochromics fast_electrochromism metal_oxide_nanoparticles polyoxometalates switchable ultra fast
442,Adopting Metaverse as a Pedagogy in Problem-Based Learning,"Baby, R., Siby, A., Joseph, J. J., & Zacharias, P. (2023). Adopting Metaverse as a Pedagogy in Problem-Based Learning. Lecture Notes in Networks and Systems, 287–295. https://doi.org/10.1007/978-3-031-31153-6_24
",10.1007/978-3-031-31153-6_24,"Pedagogical practices vary from time to time based on the requirement of various academic disciplines. Course instructors are constantly searching for inclusive and innovative pedagogies to enhance learning experiences. The introduction of Metaverse can be observed as an opportunity to enable the course instructors to combine virtual reality with augmented reality to enable immersive learning. The scope of immersive learning experience with Metaverse attracted many major universities in the world to try Metaverse as a pedagogy in fields such as management studies, medical education, and architecture. Adopting Metaverse as a pedagogy for problem-based learning enables the course instructors to create an active learning space that tackles the physical barriers of traditional pedagogical practices of case-based learning facilitating collaborative learning. Metaverse, as an established virtual learning platform, is provided by Meta Inc., providing the company a monopoly over the VR-based pedagogy. Entry of other tech firms into similar or collaborative ventures would open up a wide array of virtual reality-based platforms, eliminating the monopoly and subsequent dependency on a singular platform. The findings of the study indicate that, currently, the engagements on Metaverse are limited to tier 1 educational institutions worldwide due to the initial investment requirements. The wide adoption of the Metaverse platform in future depends on the ability of the platform providers to bridge the digital gap and facilitate curricula development. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","461.6 Medicine and Pharmacology;723 Computer Software, Data Handling and Applications;901.2 Education;911.2 Industrial Economics",Enhance learning;Immersive learning;In-field;Learning experiences;Metaverses;Pedagogical practices;Pedagogy;Problem based learning;Time based;Virtual learning,Competition;Curricula;E-learning;Medical education;Virtual reality,2023,Conference article (CA),Lect. Notes Networks Syst.,"(1) Baby, Riya; (2) Siby, Amala; (2) Joseph, Jerush John; (3) Zacharias, Prabha; ","(1) School of Sciences, CHRIST (Deemed to be University), Bangalore, India; (2) School of Commerce, Finance and Accountancy, CHRIST (Deemed to be University), Bangalore, India; (3) School of Humanities and Social Sciences, CHRIST (Deemed to be University), Bangalore, India; ",Springer Science and Business Media Deutschland GmbH,-1,"[""competition"", ""curricula"", ""e-learning"", ""medical education""]","[""competition"", ""curricula"", ""e-learning"", ""medical education""]",competition;curricula;e-learning;medical education,medical;education;business performance metrics,business;industries,medical;education;business performance metrics,business;industries,competition curricula e learning medical_education enhance_learning immersive_learning in field learning_experiences metaverses pedagogical_practices pedagogy problem_based_learning time_based virtual_learning 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 901 2_education 911 2_industrial_economics medical education business_performance_metrics,competition curricula e learning medical_education,enhance_learning immersive_learning in field learning_experiences metaverses pedagogical_practices pedagogy problem_based_learning time_based virtual_learning,pedagogical practice vary time time based requirement various academic discipline course instructor constantly searching inclusive innovative pedagogy enhance learning experience introduction metaverse observed opportunity enable course instructor combine virtual reality augmented reality enable immersive learning scope immersive learning experience metaverse attracted many major university world try metaverse pedagogy field management study medical education architecture adopting metaverse pedagogy problem based learning enables course instructor create active learning space tackle physical barrier traditional pedagogical practice case based learning facilitating collaborative learning metaverse established virtual learning platform provided meta inc providing company monopoly vr based pedagogy entry tech firm similar collaborative venture would open wide array virtual reality based platform eliminating monopoly subsequent dependency singular platform finding study indicate currently engagement metaverse limited tier 1 educational institution worldwide due initial investment requirement wide adoption metaverse platform future depends ability platform provider bridge digital gap facilitate curriculum development copy 2023 author exclusive license springer nature switzerland ag,competition curricula e learning medical_education enhance_learning immersive_learning in field learning_experiences metaverses pedagogical_practices pedagogy problem_based_learning time_based virtual_learning 461 6_medicine_and_pharmacology 723_computer_software _data_handling_and_applications 901 2_education 911 2_industrial_economics medical education business_performance_metrics pedagogical practice vary time time based requirement various academic discipline course instructor constantly searching inclusive innovative pedagogy enhance learning experience introduction metaverse observed opportunity enable course instructor combine virtual reality augmented reality enable immersive learning scope immersive learning experience metaverse attracted many major university world try metaverse pedagogy field management study medical education architecture adopting metaverse pedagogy problem based learning enables course instructor create active learning space tackle physical barrier traditional pedagogical practice case based learning facilitating collaborative learning metaverse established virtual learning platform provided meta inc providing company monopoly vr based pedagogy entry tech firm similar collaborative venture would open wide array virtual reality based platform eliminating monopoly subsequent dependency singular platform finding study indicate currently engagement metaverse limited tier 1 educational institution worldwide due initial investment requirement wide adoption metaverse platform future depends ability platform provider bridge digital gap facilitate curriculum development copy 2023 author exclusive license springer nature switzerland ag,pedagogical practice vary time time based requirement various academic discipline course instructor constantly searching inclusive innovative pedagogy enhance learning experience introduction metaverse observed opportunity enable course instructor combine virtual reality augmented reality enable immersive learning scope immersive learning experience metaverse attracted many major university world try metaverse pedagogy field management study medical education architecture adopting metaverse pedagogy problem based learning enables course instructor create active learning space tackle physical barrier traditional pedagogical practice case based learning facilitating collaborative learning metaverse established virtual learning platform provided meta inc providing company monopoly vr based pedagogy entry tech firm similar collaborative venture would open wide array virtual reality based platform eliminating monopoly subsequent dependency singular platform finding study indicate currently engagement metaverse limited tier 1 educational institution worldwide due initial investment requirement wide adoption metaverse platform future depends ability platform provider bridge digital gap facilitate curriculum development copy 2023 author exclusive license springer nature switzerland agcompetition curricula e learning medical_educationenhance_learning immersive_learning in field learning_experiences metaverses pedagogical_practices pedagogy problem_based_learning time_based virtual_learning
443,Software Hope Design for Children with ASD.,"Romero, M. R., Macas, E. M., Armijos, N., & Harari, I. (2023). Software Hope Design for Children with ASD. Communications in Computer and Information Science, 64–76. https://doi.org/10.1007/978-3-031-32213-6_5
",10.1007/978-3-031-32213-6_5,"This article describes the analysis, design, implementation, and evaluation of a software called Hope to help children with autism spectrum disorder (ASD) to express themselves through dance. The proposed software is based on augmented reality and allows strengthening teaching learning processes that include aspects related to imitation, perception, gross and fine motor skills, and visual coordination. The design process conducted in an interactive way, centered on the human being, with the participation and guidance of a multidisciplinary team. The characteristics considered to design and implement the software are explained, which was tested in a Ludic Place Therapeutic Center with children with ASD, in addition, a pedagogical intervention proposal was built where parameters for evaluation are defined; the start-up of Hope required constant interaction, participatory design methods, likewise the software was improved with the recommendations of the participants, some students from the therapeutic center tried the application, they did so initially accompanied by their caregivers and progressively they achieved individual use of the system, Hope was assessed by 5 children with ASD, in addition to 5 parents, 5 IT specialists, followed by 5 experts (teachers, psychologists, therapists, doctors). In the end, encouraging results achieved that included recognition of the body, nonverbal dialogue, less directive, structured expressions, and the ability to create and make the participants&rsquo; thinking more flexible. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;723.5 Computer Applications",Autism spectrum disorder;Autism spectrum disorders;Children with autisms;Dance;Hope project;Software;;Special educational need (NEE;;Special educational needs;Teaching-learning;User centered design (DCU),Application programs;Diseases;Human computer interaction;Software testing;User centered design,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Romero, M&oacute;nica R.; (2) Macas, Estela M.; (3) Armijos, Nancy; (1) Harari, Ivana; ","(1) Faculty of Computer Science, National University of La Plata, LINTI, Calle 50 y 120, Buenos Aires, La Plata, Argentina; (2) International Ibero-American University, UNINI MX, Calle 15 y 36, Campeche, Mexico; (3) Internacional University of Ecuador UIDE, Loja, Ecuador; ",Springer Science and Business Media Deutschland GmbH,-1,"[""application programs"", ""diseases"", ""human computer interaction"", ""software testing"", ""user centered design""]","[""application programs"", ""diseases"", ""human computer interaction"", ""software testing"", ""user centered design""]",application programs;diseases;human computer interaction;software testing;user centered design,"inspection, safety and quality;medical;developers;human-computer interaction",technology;industries;use cases;end users and user experience,"inspection, safety and quality;medical;developers;human-computer interaction",technology;industries;use cases;end users and user experience,application_programs diseases human_computer_interaction software_testing user_centered_design autism_spectrum_disorder autism_spectrum_disorders children_with_autisms dance hope_project software special_educational_need_ nee special_educational_needs teaching learning user_centered_design_ dcu 723_computer_software _data_handling_and_applications 723 5_computer_applications inspection _safety_and_quality medical developers human computer_interaction,application_programs diseases human_computer_interaction software_testing user_centered_design,autism_spectrum_disorder autism_spectrum_disorders children_with_autisms dance hope_project software special_educational_need_ nee special_educational_needs teaching learning user_centered_design_ dcu,article describes analysis design implementation evaluation software called hope help child autism spectrum disorder asd express dance proposed software based augmented reality allows strengthening teaching learning process include aspect related imitation perception gross fine motor skill visual coordination design process conducted interactive way centered human participation guidance multidisciplinary team characteristic considered design implement software explained tested ludic place therapeutic center child asd addition pedagogical intervention proposal built parameter evaluation defined start hope required constant interaction participatory design method likewise software improved recommendation participant student therapeutic center tried application initially accompanied caregiver progressively achieved individual use system hope assessed 5 child asd addition 5 parent 5 specialist followed 5 expert teacher psychologist therapist doctor end encouraging result achieved included recognition body nonverbal dialogue le directive structured expression ability create make participant rsquo thinking flexible copy 2023 author exclusive license springer nature switzerland ag,application_programs diseases human_computer_interaction software_testing user_centered_design autism_spectrum_disorder autism_spectrum_disorders children_with_autisms dance hope_project software special_educational_need_ nee special_educational_needs teaching learning user_centered_design_ dcu 723_computer_software _data_handling_and_applications 723 5_computer_applications inspection _safety_and_quality medical developers human computer_interaction article describes analysis design implementation evaluation software called hope help child autism spectrum disorder asd express dance proposed software based augmented reality allows strengthening teaching learning process include aspect related imitation perception gross fine motor skill visual coordination design process conducted interactive way centered human participation guidance multidisciplinary team characteristic considered design implement software explained tested ludic place therapeutic center child asd addition pedagogical intervention proposal built parameter evaluation defined start hope required constant interaction participatory design method likewise software improved recommendation participant student therapeutic center tried application initially accompanied caregiver progressively achieved individual use system hope assessed 5 child asd addition 5 parent 5 specialist followed 5 expert teacher psychologist therapist doctor end encouraging result achieved included recognition body nonverbal dialogue le directive structured expression ability create make participant rsquo thinking flexible copy 2023 author exclusive license springer nature switzerland ag,article describes analysis design implementation evaluation software called hope help child autism spectrum disorder asd express dance proposed software based augmented reality allows strengthening teaching learning process include aspect related imitation perception gross fine motor skill visual coordination design process conducted interactive way centered human participation guidance multidisciplinary team characteristic considered design implement software explained tested ludic place therapeutic center child asd addition pedagogical intervention proposal built parameter evaluation defined start hope required constant interaction participatory design method likewise software improved recommendation participant student therapeutic center tried application initially accompanied caregiver progressively achieved individual use system hope assessed 5 child asd addition 5 parent 5 specialist followed 5 expert teacher psychologist therapist doctor end encouraging result achieved included recognition body nonverbal dialogue le directive structured expression ability create make participant rsquo thinking flexible copy 2023 author exclusive license springer nature switzerland agapplication_programs diseases human_computer_interaction software_testing user_centered_designautism_spectrum_disorder autism_spectrum_disorders children_with_autisms dance hope_project software special_educational_need_ nee special_educational_needs teaching learning user_centered_design_ dcu
444,Optimized Design and Manufacturing Process of Diffuse Micro Corner Cubes for Head Up Projection Display Applications,"Martinez, C., Quemper, J.-M., Lee, Y., & Sixt, P. (2023). Optimized design and manufacturing process of diffuse micro corner cubes for head-up projection display applications. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2649947
",10.1117/12.2649947,"The superposition of digital information in the Field of View (FOV) of a user is the basis of the current developments in Mixed and Augmented Reality. Before being studied for Near Eye Device and Head Mounted Display, this application was implemented in Head Up Display (HUD) to help pilots and drivers to manage both the driving stress and the information flow related to the vehicle. Classical optical design of HUD based on the use of a combiner are strongly limited in FOV due to the issues related to pupil management. To overcome this issue Head Up Projection Displays have been developed based on the projection of digital image directly on the windshield. To support this approach an efficient projection surface that meets bright reflection and clear transparency has to be developed. We have introduced few years ago an optical approach based on retro-reflective transparent projection surface and a manufacturing process to provide microscopic corner cubes that incorporate an optical diffuser function. We present in this contribution an optimized design that increases the efficiency of the retroreflective structure towards 100%. We also discuss a possible technological process that allows the manufacturing of the master used to replicate the microstructure. This process based on grayscale lithography and on Deep Reactive Ion etching (DRIE) may guaranty a high retro-reflection efficiency, a high transparency and a realistic draft to allow a molding manufacturing process for the microstructure fabrication. &copy; 2023 SPIE.",741.1 Light/Optics;804.2 Inorganic Compounds;913.1 Production Engineering;941.3 Optical Instruments;951 Materials Science,Corner cubes;Field of views;Head-up;Integrated photonics;Manufacturing process;Optimized designs;Projection displays;Random distribution;Routings;Visible spectrums,Efficiency;Helmet mounted displays;Microstructure;Optical design;Optical instruments;Transparency,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Martinez, Christophe; (1) Quemper, Jean-Marie; (1) Lee, Yann; (1) Sixt, Pierre; ","(1) Univ. Grenoble Alpes, CEA, Leti, Grenoble; F-38000, France; ",SPIE,-1,"[""efficiency"", ""helmet mounted displays"", ""microstructure"", ""optical design"", ""optical instruments"", ""transparency""]","[""efficiency"", ""helmet mounted displays"", ""microstructure"", ""optical design"", ""optical instruments"", ""transparency""]",efficiency;helmet mounted displays;microstructure;optical design;optical instruments;transparency,other;graphics;optics;display technology;wearables;human-computer interaction,technology;other;displays;end users and user experience,other;graphics;optics;display technology;wearables;human-computer interaction,technology;other;displays;end users and user experience,efficiency helmet_mounted_displays microstructure optical_design optical_instruments transparency corner_cubes field_of_views head up integrated_photonics manufacturing_process optimized_designs projection_displays random_distribution routings visible_spectrums 741 1_light optics 804 2_inorganic_compounds 913 1_production_engineering 941 3_optical_instruments 951_materials_science other graphics optics display_technology wearables human computer_interaction,efficiency helmet_mounted_displays microstructure optical_design optical_instruments transparency,corner_cubes field_of_views head up integrated_photonics manufacturing_process optimized_designs projection_displays random_distribution routings visible_spectrums,superposition digital information field view fov user basis current development mixed augmented reality studied near eye device head mounted display application implemented head display hud help pilot driver manage driving stress information flow related vehicle classical optical design hud based use combiner strongly limited fov due issue related pupil management overcome issue head projection display developed based projection digital image directly windshield support approach efficient projection surface meet bright reflection clear transparency developed introduced year ago optical approach based retro reflective transparent projection surface manufacturing process provide microscopic corner cube incorporate optical diffuser function present contribution optimized design increase efficiency retroreflective structure towards 100 also discus possible technological process allows manufacturing master used replicate microstructure process based grayscale lithography deep reactive ion etching drie may guaranty high retro reflection efficiency high transparency realistic draft allow molding manufacturing process microstructure fabrication copy 2023 spie,efficiency helmet_mounted_displays microstructure optical_design optical_instruments transparency corner_cubes field_of_views head up integrated_photonics manufacturing_process optimized_designs projection_displays random_distribution routings visible_spectrums 741 1_light optics 804 2_inorganic_compounds 913 1_production_engineering 941 3_optical_instruments 951_materials_science other graphics optics display_technology wearables human computer_interaction superposition digital information field view fov user basis current development mixed augmented reality studied near eye device head mounted display application implemented head display hud help pilot driver manage driving stress information flow related vehicle classical optical design hud based use combiner strongly limited fov due issue related pupil management overcome issue head projection display developed based projection digital image directly windshield support approach efficient projection surface meet bright reflection clear transparency developed introduced year ago optical approach based retro reflective transparent projection surface manufacturing process provide microscopic corner cube incorporate optical diffuser function present contribution optimized design increase efficiency retroreflective structure towards 100 also discus possible technological process allows manufacturing master used replicate microstructure process based grayscale lithography deep reactive ion etching drie may guaranty high retro reflection efficiency high transparency realistic draft allow molding manufacturing process microstructure fabrication copy 2023 spie,superposition digital information field view fov user basis current development mixed augmented reality studied near eye device head mounted display application implemented head display hud help pilot driver manage driving stress information flow related vehicle classical optical design hud based use combiner strongly limited fov due issue related pupil management overcome issue head projection display developed based projection digital image directly windshield support approach efficient projection surface meet bright reflection clear transparency developed introduced year ago optical approach based retro reflective transparent projection surface manufacturing process provide microscopic corner cube incorporate optical diffuser function present contribution optimized design increase efficiency retroreflective structure towards 100 also discus possible technological process allows manufacturing master used replicate microstructure process based grayscale lithography deep reactive ion etching drie may guaranty high retro reflection efficiency high transparency realistic draft allow molding manufacturing process microstructure fabrication copy 2023 spieefficiency helmet_mounted_displays microstructure optical_design optical_instruments transparencycorner_cubes field_of_views head up integrated_photonics manufacturing_process optimized_designs projection_displays random_distribution routings visible_spectrums
445,Polymer Optical Sensor Glove Prototype Based on Eccentric FBGs,"Leffers, L., Roth, B., & Overmeyer, L. (2023). Polymer-optical sensor glove prototype based on eccentric FBGs. Optical Components and Materials XX. https://doi.org/10.1117/12.2647682
",10.1117/12.2647682,"We report on the development, test and comparison of a prototype sensor glove for 3D shape detection of the human hand. The prototype is based on polymer optical fibers with eccentrically inscribed Bragg gratings, which are mantled with a simple jacket woven into a textile fabric glove. All of these elements are lightweight and flexible, taking away the drawback of motion handicaps, that sensor gloves usually come with due to material stiffness. The sensor glove is tested with a set of approximately 15 different and simply defined hand gestures, which incorporate iconic and everyday gestures like grasping a cylindrical shape or showing numbers with fingers, assisted with 3D printed models. Hence a set of gestures is defined, subsequently we compared two commercial systems based on optical sensors from 5DT (Data Glove 5/ 14 Ultra) with the prototype. The prototype is not capable to measure motion accurately yet, due to its long integration times as of now, it is, however, advanced in the measurement accuracy, especially regarding the direction of the shape deformation, which is rendered possible by the structure of the FBG sensor. In the next steps, the integration time of the sensor, as well as its illumination and the evaluation will be improved. For that step, the light source, the optical spectrum analyzer and the computer will be replaced by integrated devices like LEDs, photodiodes and single-board microcontrollers. In the future, the gloves, as well as the used technology of the sensor, offer the potential for application in logistics, virtual and augmented reality as well as medical diagnostics and general observation. &copy; 2023 SPIE.",461.6 Medicine and Pharmacology;512.1.2 Petroleum Deposits : Development Operations;741.1.2 Fiber Optics;741.3 Optical Devices and Systems;819.5 Textile Products and Processing,Bend sensors;Fiber-optics;Integration time;Optical bend;Optical bend sensor;Polymer optical fibre;Prototype;Prototype sensor;Sensor gloves;Wearables,Diagnosis;Fiber optics;Light sources;Optical sensors;Petroleum reservoir evaluation;Plastic optical fibers;Spectrum analyzers;Wearable sensors;Weaving,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Leffers, Lennart; (1) Roth, Bernhard; (1) Overmeyer, Ludger; ","(1) Hanover Centre for Optical Technologies, Gottfried Wilhelm Leibniz University Hanover, Nienburger Str. 17, Hannover; 30167, Germany; (2) Institute for Transport and Automation Technology, Gottfried Wilhelm Leibniz University Hanover, An der Universit&auml;t 2, Garbsen; 30823, Germany; (3) Cluster of Excellence PhoenixD, Gottfried Wilhelm Leibniz University Hanover, Welfengarten 1, Hannover; 30167, Germany; ",SPIE,-1,"[""diagnosis"", ""fiber optics"", ""light sources"", ""optical sensors"", ""petroleum reservoir evaluation"", ""plastic optical fibers"", ""spectrum analyzers"", ""wearable sensors"", ""weaving""]","[""diagnosis"", ""fiber optics"", ""light sources"", ""optical sensors"", ""petroleum reservoir evaluation"", ""plastic optical fibers"", ""spectrum analyzers"", ""wearable sensors"", ""weaving""]",diagnosis;fiber optics;light sources;optical sensors;petroleum reservoir evaluation;plastic optical fibers;spectrum analyzers;wearable sensors;weaving,"other;input;medical;optics;sensors;inspection, safety and quality;power and energy;wearables;telecommunication",other;displays;industries;use cases;technology,"other;input;medical;optics;sensors;inspection, safety and quality;power and energy;wearables;telecommunication",other;displays;industries;use cases;technology,diagnosis fiber_optics light_sources optical_sensors petroleum_reservoir_evaluation plastic_optical_fibers spectrum_analyzers wearable_sensors weaving bend_sensors fiber optics integration_time optical_bend optical_bend_sensor polymer_optical_fibre prototype prototype_sensor sensor_gloves wearables 461 6_medicine_and_pharmacology 512 1 2_petroleum_deposits_ _development_operations 741 1 2_fiber_optics 741 3_optical_devices_and_systems 819 5_textile_products_and_processing other input medical optics sensors inspection _safety_and_quality power_and_energy wearables telecommunication,diagnosis fiber_optics light_sources optical_sensors petroleum_reservoir_evaluation plastic_optical_fibers spectrum_analyzers wearable_sensors weaving,bend_sensors fiber optics integration_time optical_bend optical_bend_sensor polymer_optical_fibre prototype prototype_sensor sensor_gloves wearables,report development test comparison prototype sensor glove 3d shape detection human hand prototype based polymer optical fiber eccentrically inscribed bragg grating mantled simple jacket woven textile fabric glove element lightweight flexible taking away drawback motion handicap sensor glove usually come due material stiffness sensor glove tested set approximately 15 different simply defined hand gesture incorporate iconic everyday gesture like grasping cylindrical shape showing number finger assisted 3d printed model hence set gesture defined subsequently compared two commercial system based optical sensor 5dt data glove 5 14 ultra prototype prototype capable measure motion accurately yet due long integration time however advanced measurement accuracy especially regarding direction shape deformation rendered possible structure fbg sensor next step integration time sensor well illumination evaluation improved step light source optical spectrum analyzer computer replaced integrated device like led photodiodes single board microcontrollers future glove well used technology sensor offer potential application logistics virtual augmented reality well medical diagnostics general observation copy 2023 spie,diagnosis fiber_optics light_sources optical_sensors petroleum_reservoir_evaluation plastic_optical_fibers spectrum_analyzers wearable_sensors weaving bend_sensors fiber optics integration_time optical_bend optical_bend_sensor polymer_optical_fibre prototype prototype_sensor sensor_gloves wearables 461 6_medicine_and_pharmacology 512 1 2_petroleum_deposits_ _development_operations 741 1 2_fiber_optics 741 3_optical_devices_and_systems 819 5_textile_products_and_processing other input medical optics sensors inspection _safety_and_quality power_and_energy wearables telecommunication report development test comparison prototype sensor glove 3d shape detection human hand prototype based polymer optical fiber eccentrically inscribed bragg grating mantled simple jacket woven textile fabric glove element lightweight flexible taking away drawback motion handicap sensor glove usually come due material stiffness sensor glove tested set approximately 15 different simply defined hand gesture incorporate iconic everyday gesture like grasping cylindrical shape showing number finger assisted 3d printed model hence set gesture defined subsequently compared two commercial system based optical sensor 5dt data glove 5 14 ultra prototype prototype capable measure motion accurately yet due long integration time however advanced measurement accuracy especially regarding direction shape deformation rendered possible structure fbg sensor next step integration time sensor well illumination evaluation improved step light source optical spectrum analyzer computer replaced integrated device like led photodiodes single board microcontrollers future glove well used technology sensor offer potential application logistics virtual augmented reality well medical diagnostics general observation copy 2023 spie,report development test comparison prototype sensor glove 3d shape detection human hand prototype based polymer optical fiber eccentrically inscribed bragg grating mantled simple jacket woven textile fabric glove element lightweight flexible taking away drawback motion handicap sensor glove usually come due material stiffness sensor glove tested set approximately 15 different simply defined hand gesture incorporate iconic everyday gesture like grasping cylindrical shape showing number finger assisted 3d printed model hence set gesture defined subsequently compared two commercial system based optical sensor 5dt data glove 5 14 ultra prototype prototype capable measure motion accurately yet due long integration time however advanced measurement accuracy especially regarding direction shape deformation rendered possible structure fbg sensor next step integration time sensor well illumination evaluation improved step light source optical spectrum analyzer computer replaced integrated device like led photodiodes single board microcontrollers future glove well used technology sensor offer potential application logistics virtual augmented reality well medical diagnostics general observation copy 2023 spiediagnosis fiber_optics light_sources optical_sensors petroleum_reservoir_evaluation plastic_optical_fibers spectrum_analyzers wearable_sensors weavingbend_sensors fiber optics integration_time optical_bend optical_bend_sensor polymer_optical_fibre prototype prototype_sensor sensor_gloves wearables
446,A virtual-reality framework for graph-based damage evaluation of reinforced concrete structures,"Bazrafshan, P., & Ebrahimkhanlou, A. (2023). A virtual-reality framework for graph-based damage evaluation of reinforced concrete structures. Nondestructive Characterization and Monitoring of Advanced Materials, Aerospace, Civil Infrastructure, and Transportation XVII. https://doi.org/10.1117/12.2657736
",10.1117/12.2657736,"Artificial intelligence (AI) and virtual/augmented reality (VR/AR) are facilitating objective and fast assessment of infrastructures. Computer vision advancements are also transforming traditional methods into automated information modeling and decision support systems. These advancements offer new opportunities to combat growing challenges that threaten infrastructure systems. In particular, climate change, aging structures, and population growth have intensified threats to infrastructure, requiring methods for evaluating infrastructure quickly after a disaster. VR uses cameras and sensors to provide images of the current state of a structural system, including the pattern of concrete cracks. A novel framework for analyzing the degree of damage in cracked reinforced concrete shear walls (RCSWs) is presented in this paper by leveraging virtual reality (VR) technology. An automated and unbiased approach is enabled by converting images of crack patterns on the surface of concrete structures into graphs. It is possible to extract relevant information from graphs, including graph features, to quantify the extent of damage using graph theory. A machine learning algorithm is then trained using these features to predict the extent of the damage. To validate the approach, the framework was applied to data collected from three RCSWs that were subjected to quasi-static cyclic loading. ML was used to predict the secant stiffness and its descending trend during each load cycle in the experimental test. The VR-based approach achieves high R2 scores of 0.90, 0.91, and 0.99 in a machine learning regression, indicating the framework's success. &copy; 2023 SPIE.","402 Buildings and Towers;412 Concrete;422 Strength of Building Materials; Test Equipment and Methods;443.1 Atmospheric Properties;723 Computer Software, Data Handling and Applications;723.4 Artificial Intelligence;723.4.2 Machine Learning;723.5 Computer Applications;741.2 Vision;912.2 Management;921.4 Combinatorial Mathematics, Includes Graph Theory, Set Theory",Automated information;Concrete cracks;Crack quantification;Damage evaluation;Fast assessment;Graph-based;Machine-learning;Objective assessment;Reinforced concrete shear walls;Reinforced concrete structures,Climate change;Computer vision;Concrete buildings;Concrete construction;Decision support systems;E-learning;Graph theory;Graphic methods;Learning algorithms;Learning systems;Machine learning;Population statistics;Reinforced concrete;Virtual reality,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Bazrafshan, Pedram; (1) Ebrahimkhanlou, Arvin; ","(1) Drexel University, 3141 Chestnut St, Philadelphia; PA; 19104, United States; ",SPIE,-1,"[""climate change"", ""computer vision"", ""concrete buildings"", ""concrete construction"", ""decision support systems"", ""e-learning"", ""graph theory"", ""graphic methods"", ""learning algorithms"", ""learning systems"", ""machine learning"", ""population statistics"", ""reinforced concrete""]","[""climate change"", ""computer vision"", ""concrete buildings"", ""concrete construction"", ""decision support systems"", ""e-learning"", ""graph theory"", ""graphic methods"", ""learning algorithms"", ""learning systems"", ""machine learning"", ""population statistics"", ""reinforced concrete""]",climate change;computer vision;concrete buildings;concrete construction;decision support systems;e-learning;graph theory;graphic methods;learning algorithms;learning systems;machine learning;population statistics;reinforced concrete,construction;computer vision;education;other;graphics;medical;business performance metrics;policy;artificial intelligence,technology;other;business;industries,construction;computer vision;education;other;graphics;medical;business performance metrics;policy;artificial intelligence,technology;other;business;industries,climate_change computer_vision concrete_buildings concrete_construction decision_support_systems e learning graph_theory graphic_methods learning_algorithms learning_systems machine_learning population_statistics reinforced_concrete automated_information concrete_cracks crack_quantification damage_evaluation fast_assessment graph based machine learning objective_assessment reinforced_concrete_shear_walls reinforced_concrete_structures 402_buildings_and_towers 412_concrete 422_strength_of_building_materials _test_equipment_and_methods 443 1_atmospheric_properties 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 4 2_machine_learning 723 5_computer_applications 741 2_vision 912 2_management 921 4_combinatorial_mathematics _includes_graph_theory _set_theory construction computer_vision education other graphics medical business_performance_metrics policy artificial_intelligence,climate_change computer_vision concrete_buildings concrete_construction decision_support_systems e learning graph_theory graphic_methods learning_algorithms learning_systems machine_learning population_statistics reinforced_concrete,automated_information concrete_cracks crack_quantification damage_evaluation fast_assessment graph based machine learning objective_assessment reinforced_concrete_shear_walls reinforced_concrete_structures,artificial intelligence ai virtual augmented reality vr ar facilitating objective fast assessment infrastructure computer vision advancement also transforming traditional method automated information modeling decision support system advancement offer new opportunity combat growing challenge threaten infrastructure system particular climate change aging structure population growth intensified threat infrastructure requiring method evaluating infrastructure quickly disaster vr us camera sensor provide image current state structural system including pattern concrete crack novel framework analyzing degree damage cracked reinforced concrete shear wall rcsws presented paper leveraging virtual reality vr technology automated unbiased approach enabled converting image crack pattern surface concrete structure graph possible extract relevant information graph including graph feature quantify extent damage using graph theory machine learning algorithm trained using feature predict extent damage validate approach framework applied data collected three rcsws subjected quasi static cyclic loading ml used predict secant stiffness descending trend load cycle experimental test vr based approach achieves high r2 score 0 90 0 91 0 99 machine learning regression indicating framework success copy 2023 spie,climate_change computer_vision concrete_buildings concrete_construction decision_support_systems e learning graph_theory graphic_methods learning_algorithms learning_systems machine_learning population_statistics reinforced_concrete automated_information concrete_cracks crack_quantification damage_evaluation fast_assessment graph based machine learning objective_assessment reinforced_concrete_shear_walls reinforced_concrete_structures 402_buildings_and_towers 412_concrete 422_strength_of_building_materials _test_equipment_and_methods 443 1_atmospheric_properties 723_computer_software _data_handling_and_applications 723 4_artificial_intelligence 723 4 2_machine_learning 723 5_computer_applications 741 2_vision 912 2_management 921 4_combinatorial_mathematics _includes_graph_theory _set_theory construction computer_vision education other graphics medical business_performance_metrics policy artificial_intelligence artificial intelligence ai virtual augmented reality vr ar facilitating objective fast assessment infrastructure computer vision advancement also transforming traditional method automated information modeling decision support system advancement offer new opportunity combat growing challenge threaten infrastructure system particular climate change aging structure population growth intensified threat infrastructure requiring method evaluating infrastructure quickly disaster vr us camera sensor provide image current state structural system including pattern concrete crack novel framework analyzing degree damage cracked reinforced concrete shear wall rcsws presented paper leveraging virtual reality vr technology automated unbiased approach enabled converting image crack pattern surface concrete structure graph possible extract relevant information graph including graph feature quantify extent damage using graph theory machine learning algorithm trained using feature predict extent damage validate approach framework applied data collected three rcsws subjected quasi static cyclic loading ml used predict secant stiffness descending trend load cycle experimental test vr based approach achieves high r2 score 0 90 0 91 0 99 machine learning regression indicating framework success copy 2023 spie,artificial intelligence ai virtual augmented reality vr ar facilitating objective fast assessment infrastructure computer vision advancement also transforming traditional method automated information modeling decision support system advancement offer new opportunity combat growing challenge threaten infrastructure system particular climate change aging structure population growth intensified threat infrastructure requiring method evaluating infrastructure quickly disaster vr us camera sensor provide image current state structural system including pattern concrete crack novel framework analyzing degree damage cracked reinforced concrete shear wall rcsws presented paper leveraging virtual reality vr technology automated unbiased approach enabled converting image crack pattern surface concrete structure graph possible extract relevant information graph including graph feature quantify extent damage using graph theory machine learning algorithm trained using feature predict extent damage validate approach framework applied data collected three rcsws subjected quasi static cyclic loading ml used predict secant stiffness descending trend load cycle experimental test vr based approach achieves high r2 score 0 90 0 91 0 99 machine learning regression indicating framework success copy 2023 spieclimate_change computer_vision concrete_buildings concrete_construction decision_support_systems e learning graph_theory graphic_methods learning_algorithms learning_systems machine_learning population_statistics reinforced_concreteautomated_information concrete_cracks crack_quantification damage_evaluation fast_assessment graph based machine learning objective_assessment reinforced_concrete_shear_walls reinforced_concrete_structures
447,"New Technological Waves Emerging in Digital Transformation: Internet of Things IoT/IoE, 5G/6G Mobile Networks and Industries 4.0/5.0","Leite, J. R. E., Ursini, E. L., Chmielewski, A. M. M., & da Silva, A. J. D. (2023). New Technological Waves Emerging in Digital Transformation: Internet of Things IoT/IoE, 5G/6G Mobile Networks and Industries 4.0/5.0. Smart Innovation, Systems and Technologies, 329–339. https://doi.org/10.1007/978-3-031-31007-2_30
",10.1007/978-3-031-31007-2_30,"The Internet has established itself as a ""Network of Networks"" and a globalized communication tool, initially enabling the connection between people themselves and between people and computers (machines). The cheapness and reduction in the size of Internet access components made it possible for simpler equipment and devices of our daily lives to also access the global network, thus creating the Internet of Things (IoT), which aims to interconnect devices/objects/things of everyday use. Intelligence and automation result from the additions of processing, memory, and communication in the objects involved and the use of access by Mobile Networks, AdHoc, and RFID. The 5G Mobile Network&nbsp;evolved to serve as the basis of IoT communication, due to its characteristics of Massive Use, Broadband, Low Latency (Delay), and high demand for better quality service. Aspects of architectures, multiple access techniques, and emerging technologies (massive MIMO, software-defined networking, mm-Wave) are presented historically, including 1G/2G/3G/4G/5G Mobile Networks up to the future 6G Network. Industry 4.0&nbsp;is known as the fourth industrial revolution, in which we will have billions of people connected by mobile devices, with processing power, storage resources, connectivity, and access to knowledge without limits. This new wave of technology, which will include several areas: Artificial Intelligence (AI), Advanced Robotics, Internet of Things (IoT), Autonomous Vehicles, Big Data, Cloud Storage, Virtual Reality (VR)/Augmented Reality (AR), Cyber-Physical Systems, Digital Security, and 3D Printing, among others, has been increasingly incorporated by large companies as a new trend of digital transformation, enabling more security and productivity. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","711 Electromagnetic Waves;716.3 Radio Systems and Equipment;722.1 Data Storage, Equipment and Techniques;722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;913.4 Manufacturing",% reductions;Communication tools;Daily lives;Digital transformation;Indistry 4.0/5.0;Internet access;Internet of thing;Mobile network (1g/2g/3g/4g/5g/6g);Network of networks;Simple++,5G mobile communication systems;Digital storage;Embedded systems;Industry 4.0;Metadata;Millimeter waves;Network security;Virtual reality;Wireless networks,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Leite, Jos&eacute; Roberto Emiliano; (1) Ursini, Edson Luiz; (2) Chmielewski, Ad&atilde;o Maciel Monteiro; (2) da Silva, Ant&ocirc;nio Jos&eacute; Dias; ","(1) School of Technology, State University of Campinas, Limeira, Brazil; (2) University Santa Ursula, Rio de Janeiro, Brazil; ",Springer Science and Business Media Deutschland GmbH,-1,"[""5g mobile communication systems"", ""digital storage"", ""embedded systems"", ""industry 4.0"", ""metadata"", ""millimeter waves"", ""network security"", ""wireless networks""]","[""5g mobile communication systems"", ""digital storage"", ""embedded systems"", ""industry 4.0"", ""metadata"", ""millimeter waves"", ""network security"", ""wireless networks""]",5g mobile communication systems;digital storage;embedded systems;industry 4.0;metadata;millimeter waves;network security;wireless networks,education;security;input;internet of things;telecommunication;developers;data;semiconductors;networks,technology;industries,education;security;input;internet of things;telecommunication;developers;data;semiconductors;networks,technology;industries,5g_mobile_communication_systems digital_storage embedded_systems industry_4 0 metadata millimeter_waves network_security wireless_networks _reductions communication_tools daily_lives digital_transformation indistry_4 0 5 0 internet_access internet_of_thing mobile_network_ 1g 2g 3g 4g 5g 6g network_of_networks simple 711_electromagnetic_waves 716 3_radio_systems_and_equipment 722 1_data_storage _equipment_and_techniques 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 913 4_manufacturing education security input internet_of_things telecommunication developers data semiconductors networks,5g_mobile_communication_systems digital_storage embedded_systems industry_4 0 metadata millimeter_waves network_security wireless_networks,_reductions communication_tools daily_lives digital_transformation indistry_4 0 5 0 internet_access internet_of_thing mobile_network_ 1g 2g 3g 4g 5g 6g network_of_networks simple,internet established network network globalized communication tool initially enabling connection people people computer machine cheapness reduction size internet access component made possible simpler equipment device daily life also access global network thus creating internet thing iot aim interconnect device object thing everyday use intelligence automation result addition processing memory communication object involved use access mobile network adhoc rfid 5g mobile network nbsp evolved serve basis iot communication due characteristic massive use broadband low latency delay high demand better quality service aspect architecture multiple access technique emerging technology massive mimo software defined networking mm wave presented historically including 1g 2g 3g 4g 5g mobile network future 6g network industry 4 0 nbsp known fourth industrial revolution billion people connected mobile device processing power storage resource connectivity access knowledge without limit new wave technology include several area artificial intelligence ai advanced robotics internet thing iot autonomous vehicle big data cloud storage virtual reality vr augmented reality ar cyber physical system digital security 3d printing among others increasingly incorporated large company new trend digital transformation enabling security productivity copy 2023 author exclusive license springer nature switzerland ag,5g_mobile_communication_systems digital_storage embedded_systems industry_4 0 metadata millimeter_waves network_security wireless_networks _reductions communication_tools daily_lives digital_transformation indistry_4 0 5 0 internet_access internet_of_thing mobile_network_ 1g 2g 3g 4g 5g 6g network_of_networks simple 711_electromagnetic_waves 716 3_radio_systems_and_equipment 722 1_data_storage _equipment_and_techniques 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 913 4_manufacturing education security input internet_of_things telecommunication developers data semiconductors networks internet established network network globalized communication tool initially enabling connection people people computer machine cheapness reduction size internet access component made possible simpler equipment device daily life also access global network thus creating internet thing iot aim interconnect device object thing everyday use intelligence automation result addition processing memory communication object involved use access mobile network adhoc rfid 5g mobile network nbsp evolved serve basis iot communication due characteristic massive use broadband low latency delay high demand better quality service aspect architecture multiple access technique emerging technology massive mimo software defined networking mm wave presented historically including 1g 2g 3g 4g 5g mobile network future 6g network industry 4 0 nbsp known fourth industrial revolution billion people connected mobile device processing power storage resource connectivity access knowledge without limit new wave technology include several area artificial intelligence ai advanced robotics internet thing iot autonomous vehicle big data cloud storage virtual reality vr augmented reality ar cyber physical system digital security 3d printing among others increasingly incorporated large company new trend digital transformation enabling security productivity copy 2023 author exclusive license springer nature switzerland ag,internet established network network globalized communication tool initially enabling connection people people computer machine cheapness reduction size internet access component made possible simpler equipment device daily life also access global network thus creating internet thing iot aim interconnect device object thing everyday use intelligence automation result addition processing memory communication object involved use access mobile network adhoc rfid 5g mobile network nbsp evolved serve basis iot communication due characteristic massive use broadband low latency delay high demand better quality service aspect architecture multiple access technique emerging technology massive mimo software defined networking mm wave presented historically including 1g 2g 3g 4g 5g mobile network future 6g network industry 4 0 nbsp known fourth industrial revolution billion people connected mobile device processing power storage resource connectivity access knowledge without limit new wave technology include several area artificial intelligence ai advanced robotics internet thing iot autonomous vehicle big data cloud storage virtual reality vr augmented reality ar cyber physical system digital security 3d printing among others increasingly incorporated large company new trend digital transformation enabling security productivity copy 2023 author exclusive license springer nature switzerland ag5g_mobile_communication_systems digital_storage embedded_systems industry_4 0 metadata millimeter_waves network_security wireless_networks_reductions communication_tools daily_lives digital_transformation indistry_4 0 5 0 internet_access internet_of_thing mobile_network_ 1g 2g 3g 4g 5g 6g network_of_networks simple
448,Future Internet Architectures on an Emerging Scale&mdash;A Systematic Review,"Mohammed, S. A., & Ralescu, A. L. (2023). Future Internet Architectures on an Emerging Scale—A Systematic Review. Future Internet, 15(5), 166. https://doi.org/10.3390/fi15050166
",10.3390/fi15050166,"Future Internet is a general term that is used to refer to the study of new Internet architectures that emphasize the advancements that are paving the way for the next generation of internet. Today&rsquo;s internet has become more complicated and arduous to manage due to its increased traffic. This traffic is a result of the transfer of 247 billion emails, the management of more than a billion websites and 735 active top-level domains, the viewing of at least one billion YouTube videos per day (which is the source of main traffic), and the uploading of more than 2.5 billion photos to Facebook every year. The internet was never anticipated to provide quality of service (QoS) support, but one can have a best effort service that provides support for video streams and downloaded media applications. Therefore, the future architecture of the internet becomes crucial. Furthermore, the internet as a service has witnessed many evolving conflicts among its stakeholders, leading to extensive research. This article presents a systematic review of the internet&rsquo;s evolution and discusses the ongoing research efforts towards new internet architectures, as well as the challenges that are faced in increasing the network&rsquo;s performance and quality. Moreover, as part of these anticipated future developments, this article draws attention to the Metaverse, which combines the emerging areas of augmented reality, virtual reality, mixed reality, and extended reality, and is considered to be the next frontier for the future internet. This article examines the key role of the blockchain in organizing and advancing the applications and services within the Metaverse. It also discusses the potential benefits and challenges of future internet research. Finally, the article outlines certain directions for future internet research, particularly in the context of utilizing blockchains in the Metaverse. &copy; 2023 by the authors.",723.3 Database Systems,Block-chain;Clean slates;Clean-slate approach;Expressive internet architecture;Future internet;Internet architecture;Metaverses;Mobility first;Named data networks;Nebula;Software-defined networks,Blockchain;Network architecture;Quality of service;Software defined networking,2023,Journal article (JA),Future Internet,"(1) Mohammed, Sarfaraz Ahmed; (1) Ralescu, Anca L.; ","(1) Department of Computer Science, College of Engineering and Applied Science, University of Cincinnati, Cincinnati; OH; 45221-0030, United States; ",MDPI,-1,"[""blockchain"", ""network architecture"", ""quality of service"", ""software defined networking""]","[""blockchain"", ""network architecture"", ""quality of service"", ""software defined networking""]",blockchain;network architecture;quality of service;software defined networking,construction;networks;security;business performance metrics,technology;business;industries,construction;networks;security;business performance metrics,technology;business;industries,blockchain network_architecture quality_of_service software_defined_networking block chain clean_slates clean slate_approach expressive_internet_architecture future_internet internet_architecture metaverses mobility_first named_data_networks nebula software defined_networks 723 3_database_systems construction networks security business_performance_metrics,blockchain network_architecture quality_of_service software_defined_networking,block chain clean_slates clean slate_approach expressive_internet_architecture future_internet internet_architecture metaverses mobility_first named_data_networks nebula software defined_networks,future internet general term used refer study new internet architecture emphasize advancement paving way next generation internet today rsquo internet become complicated arduous manage due increased traffic traffic result transfer 247 billion email management billion website 735 active top level domain viewing least one billion youtube video per day source main traffic uploading 2 5 billion photo facebook every year internet never anticipated provide quality service qos support one best effort service provides support video stream downloaded medium application therefore future architecture internet becomes crucial furthermore internet service witnessed many evolving conflict among stakeholder leading extensive research article present systematic review internet rsquo evolution discus ongoing research effort towards new internet architecture well challenge faced increasing network rsquo performance quality moreover part anticipated future development article draw attention metaverse combine emerging area augmented reality virtual reality mixed reality extended reality considered next frontier future internet article examines key role blockchain organizing advancing application service within metaverse also discus potential benefit challenge future internet research finally article outline certain direction future internet research particularly context utilizing blockchains metaverse copy 2023 author,blockchain network_architecture quality_of_service software_defined_networking block chain clean_slates clean slate_approach expressive_internet_architecture future_internet internet_architecture metaverses mobility_first named_data_networks nebula software defined_networks 723 3_database_systems construction networks security business_performance_metrics future internet general term used refer study new internet architecture emphasize advancement paving way next generation internet today rsquo internet become complicated arduous manage due increased traffic traffic result transfer 247 billion email management billion website 735 active top level domain viewing least one billion youtube video per day source main traffic uploading 2 5 billion photo facebook every year internet never anticipated provide quality service qos support one best effort service provides support video stream downloaded medium application therefore future architecture internet becomes crucial furthermore internet service witnessed many evolving conflict among stakeholder leading extensive research article present systematic review internet rsquo evolution discus ongoing research effort towards new internet architecture well challenge faced increasing network rsquo performance quality moreover part anticipated future development article draw attention metaverse combine emerging area augmented reality virtual reality mixed reality extended reality considered next frontier future internet article examines key role blockchain organizing advancing application service within metaverse also discus potential benefit challenge future internet research finally article outline certain direction future internet research particularly context utilizing blockchains metaverse copy 2023 author,future internet general term used refer study new internet architecture emphasize advancement paving way next generation internet today rsquo internet become complicated arduous manage due increased traffic traffic result transfer 247 billion email management billion website 735 active top level domain viewing least one billion youtube video per day source main traffic uploading 2 5 billion photo facebook every year internet never anticipated provide quality service qos support one best effort service provides support video stream downloaded medium application therefore future architecture internet becomes crucial furthermore internet service witnessed many evolving conflict among stakeholder leading extensive research article present systematic review internet rsquo evolution discus ongoing research effort towards new internet architecture well challenge faced increasing network rsquo performance quality moreover part anticipated future development article draw attention metaverse combine emerging area augmented reality virtual reality mixed reality extended reality considered next frontier future internet article examines key role blockchain organizing advancing application service within metaverse also discus potential benefit challenge future internet research finally article outline certain direction future internet research particularly context utilizing blockchains metaverse copy 2023 authorblockchain network_architecture quality_of_service software_defined_networkingblock chain clean_slates clean slate_approach expressive_internet_architecture future_internet internet_architecture metaverses mobility_first named_data_networks nebula software defined_networks
449,Are Industry 4.0 technologies enablers of lean? Evidence from manufacturing industries,"Narula, S., Puppala, H., Kumar, A., Luthra, S., Dwivedy, M., Prakash, S., & Talwar, V. (2022). Are Industry 4.0 technologies enablers of lean? Evidence from manufacturing industries. International Journal of Lean Six Sigma, 14(1), 115–138. https://doi.org/10.1108/ijlss-04-2021-0085
",10.1108/IJLSS-04-2021-0085,"&lt;b&gt;Purpose &lt;/b&gt;This study aims to propose a conceptual model indicating the impact of Industry 4.0 (I4.0) technologies on lean tools. Additionally, it prioritizes I4.0 technologies for the digital transformation of lean plants. &lt;b&gt;Design/methodology/approach &lt;/b&gt;The authors conducted a questionnaire-based survey to capture the perception of 115 experts of manufacturing industries from Germany, India, Taiwan and China. The impact of I4.0 on lean tools, using analysis of variance (ANOVA). Further, the authors drew a prioritization map of I4.0 on the employment of lean tools in manufacturing, using the Best-Worst Method (BWM). &lt;b&gt;Findings &lt;/b&gt;The findings indicate that cloud manufacturing, simulation, industrial internet of things, horizontal and vertical integration impact 100% of the lean tools, while both cyber-security, big data analytics impact 93% of the lean tools and advanced robotics impact 74% of the lean tools. On the other hand, it is observed that augmented reality and additive manufacturing will impact 21% and 14% of the lean tools, respectively. &lt;b&gt;Practical implications &lt;/b&gt;The results of this study would help practitioners draw up a strategic plan and roadmap for implementing lean 4.0. The amalgamation of lean with I4.0 technologies in the right combination would enhance speed productivity and facilitate autonomous operations. &lt;b&gt;Originality/value &lt;/b&gt;Studies exploring the influence of I4.0 on lean manufacturing lack comprehensiveness, testing and validation. Importantly, no studies in the recent past have explored mapping and prioritizing I4.0 technologies in the ""lean"" context. This study thereby attempts to establish a conceptual model, indicating the influence of I4.0 technologies on lean tools and presents the hierarchy of all digital technologies.",C7480 Production engineering computing;C1140Z Other topics in statistics;E0210J Statistics;E0410D Industrial applications of IT;E1510 Manufacturing systems,analysis of variance;ANOVA;Best-Worst Method;BWM;I4.0 technologies;Industry 4.0 technologies;lean manufacturing;lean tools;manufacturing industries,lean production;manufacturing industries;production engineering computing;statistical analysis,2023,Journal article (JA),Int. J. Lean Six Sig. (UK),"(1) Narula, S.; (2) Puppala, H.; (3) Kumar, A.; (4) Luthra, S.; (2) Dwivedy, M.; (5) Prakash, S.; (6) Talwar, V.; ","(1) BML Munjal University, School of Management, India; (2) BML Munjal University, School of Engineering and Technology, India; (3) London Metropolitan University, Guildhall School of Business and Law, United Kingdom; (4) Chaudhary Ranbir Singh State Institute of Engineering & Technology, Department of Mechanical Engineering, India; (5) Indian Institute of Health Management Research, School of Pharma Management, India; (6) Sunder Deep College of Management Technology Ghaziabad, School of Management, India; ",Emerald,-1,"[""lean production"", ""manufacturing industries"", ""production engineering computing"", ""statistical analysis""]","[""lean production"", ""manufacturing industries"", ""production engineering computing"", ""statistical analysis""]",lean production;manufacturing industries;production engineering computing;statistical analysis,other;manufacturing;engineering;data,technology;other;industries,other;manufacturing;engineering;data,technology;other;industries,lean_production manufacturing_industries production_engineering_computing statistical_analysis analysis_of_variance anova best worst_method bwm i4 0_technologies industry_4 0_technologies lean_manufacturing lean_tools manufacturing_industries c7480_production_engineering_computing c1140z_other_topics_in_statistics e0210j_statistics e0410d_industrial_applications_of_it e1510_manufacturing_systems other manufacturing engineering data,lean_production manufacturing_industries production_engineering_computing statistical_analysis,analysis_of_variance anova best worst_method bwm i4 0_technologies industry_4 0_technologies lean_manufacturing lean_tools manufacturing_industries,lt b gt purpose lt b gt study aim propose conceptual model indicating impact industry 4 0 i4 0 technology lean tool additionally prioritizes i4 0 technology digital transformation lean plant lt b gt design methodology approach lt b gt author conducted questionnaire based survey capture perception 115 expert manufacturing industry germany india taiwan china impact i4 0 lean tool using analysis variance anova author drew prioritization map i4 0 employment lean tool manufacturing using best worst method bwm lt b gt finding lt b gt finding indicate cloud manufacturing simulation industrial internet thing horizontal vertical integration impact 100 lean tool cyber security big data analytics impact 93 lean tool advanced robotics impact 74 lean tool hand observed augmented reality additive manufacturing impact 21 14 lean tool respectively lt b gt practical implication lt b gt result study would help practitioner draw strategic plan roadmap implementing lean 4 0 amalgamation lean i4 0 technology right combination would enhance speed productivity facilitate autonomous operation lt b gt originality value lt b gt study exploring influence i4 0 lean manufacturing lack comprehensiveness testing validation importantly study recent past explored mapping prioritizing i4 0 technology lean context study thereby attempt establish conceptual model indicating influence i4 0 technology lean tool present hierarchy digital technology,lean_production manufacturing_industries production_engineering_computing statistical_analysis analysis_of_variance anova best worst_method bwm i4 0_technologies industry_4 0_technologies lean_manufacturing lean_tools manufacturing_industries c7480_production_engineering_computing c1140z_other_topics_in_statistics e0210j_statistics e0410d_industrial_applications_of_it e1510_manufacturing_systems other manufacturing engineering data lt b gt purpose lt b gt study aim propose conceptual model indicating impact industry 4 0 i4 0 technology lean tool additionally prioritizes i4 0 technology digital transformation lean plant lt b gt design methodology approach lt b gt author conducted questionnaire based survey capture perception 115 expert manufacturing industry germany india taiwan china impact i4 0 lean tool using analysis variance anova author drew prioritization map i4 0 employment lean tool manufacturing using best worst method bwm lt b gt finding lt b gt finding indicate cloud manufacturing simulation industrial internet thing horizontal vertical integration impact 100 lean tool cyber security big data analytics impact 93 lean tool advanced robotics impact 74 lean tool hand observed augmented reality additive manufacturing impact 21 14 lean tool respectively lt b gt practical implication lt b gt result study would help practitioner draw strategic plan roadmap implementing lean 4 0 amalgamation lean i4 0 technology right combination would enhance speed productivity facilitate autonomous operation lt b gt originality value lt b gt study exploring influence i4 0 lean manufacturing lack comprehensiveness testing validation importantly study recent past explored mapping prioritizing i4 0 technology lean context study thereby attempt establish conceptual model indicating influence i4 0 technology lean tool present hierarchy digital technology,lt b gt purpose lt b gt study aim propose conceptual model indicating impact industry 4 0 i4 0 technology lean tool additionally prioritizes i4 0 technology digital transformation lean plant lt b gt design methodology approach lt b gt author conducted questionnaire based survey capture perception 115 expert manufacturing industry germany india taiwan china impact i4 0 lean tool using analysis variance anova author drew prioritization map i4 0 employment lean tool manufacturing using best worst method bwm lt b gt finding lt b gt finding indicate cloud manufacturing simulation industrial internet thing horizontal vertical integration impact 100 lean tool cyber security big data analytics impact 93 lean tool advanced robotics impact 74 lean tool hand observed augmented reality additive manufacturing impact 21 14 lean tool respectively lt b gt practical implication lt b gt result study would help practitioner draw strategic plan roadmap implementing lean 4 0 amalgamation lean i4 0 technology right combination would enhance speed productivity facilitate autonomous operation lt b gt originality value lt b gt study exploring influence i4 0 lean manufacturing lack comprehensiveness testing validation importantly study recent past explored mapping prioritizing i4 0 technology lean context study thereby attempt establish conceptual model indicating influence i4 0 technology lean tool present hierarchy digital technologylean_production manufacturing_industries production_engineering_computing statistical_analysisanalysis_of_variance anova best worst_method bwm i4 0_technologies industry_4 0_technologies lean_manufacturing lean_tools manufacturing_industries
450,Generating Diffraction Efficiency Profiles in Bayfol<sup>&reg;</sup> HX vHOEs,"Bruder, F.-K., Frank, J., Hansen, S., Lorenz, A., Manecke, C., Mills, J., Pitzer, L., Pochorovski, I., & Rölle, T. (2023). Generating diffraction efficiency profiles in Bayfol HX vHOEs. Practical Holography XXXVII: Displays, Materials, and Applications. https://doi.org/10.1117/12.2650108
",10.1117/12.2650108,"Bayfol&reg; HX photopolymer films prove themselves as easy-to-process recording materials for volume holographic optical elements (vHOEs) and are available in customized grade at industrial scale. Their full-color (RGB) recording and replay capabilities are two of their major advantages. Moreover, the adjustable diffraction efficiency, tunable angular and spectral selectivity of vHOEs recorded into Bayfol&reg; HX as well as their unmatched optical clarity enables superior invisible ""off Bragg"" optical functionality. As a film product, the replication of vHOEs in Bayfol&reg; HX can be carried out in a highly cost-efficient and purely photonic roll-to-roll (R2R) process. Utilizing thermoplastic substrates, Bayfol&reg; HX was demonstrated to be compatible to state-of-the-art plastic processing techniques like thermoforming, film insert molding and casting, which opened up using a variety of industry-proven integration technologies for vHOEs. Therefore, Bayfol&reg; HX makes its way in applications in the field of augmented reality such as Head-up-Displays (HUD) and Head-mounted-Displays (HMD), in free-space combiners, in plastic optical waveguides, and in transparent screens. Also, vHOEs made from Bayfol&reg; HX are utilized in highly sophisticated spectrometers in astronomy as well as in narrow band notch filters for eyeglasses against laser strikes. See through applications such as, HMD and HUD, have demanding performance requirements on combiner and imaging technologies such as efficiency, optical function, and clarity. The properties of Bayfol&reg; HX make it well suited to solve these challenges in primary display, and near-infrared imaging applications such as eye-tracking, while maintaining the requirements on optical performance. We demonstrate practical examples of Bayfol&reg; HX vHOE's using novel holography techniques for spatially varying diffraction efficiency. &copy; 2023 SPIE.",703.2 Electric Filters;742.1 Photography;743 Holography;746 Imaging Techniques,Head-mounted-displays;Head-UpDisplay;Heads-up-display;Holographic photopolymer;Optical clarity;Spatially varying diffraction efficiency;Transparent screen;Varying diffractions;Volume holographic;Volume holographic optical element,Diffraction efficiency;Eye tracking;Holographic optical elements;Holography;Infrared devices;Notch filters;Thermography (imaging),2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Bruder, Friedrich-Karl; (1) Frank, Johannes; (1) Hansen, Sven; (1) Lorenz, Alexander; (1) Manecke, Christel; (2) Mills, Jack; (1) Pitzer, Lena; (1) Pochorovski, Igor; (1) R&ouml;lle, Thomas; ","(1) Covestro Deutschland AG, Chempark Leverkusen, Leverkusen; D-51365, Germany; (2) Covestro LLC, 1 Covestro Circle, Pittsburgh; PA; 15205, United States; ",SPIE,-1,"[""diffraction efficiency"", ""eye tracking"", ""holographic optical elements"", ""holography"", ""infrared devices"", ""notch filters"", ""thermography""]","[""diffraction efficiency"", ""eye tracking"", ""holographic optical elements"", ""holography"", ""infrared devices"", ""notch filters"", ""thermography""]",diffraction efficiency;eye tracking;holographic optical elements;holography;infrared devices;notch filters;thermography,computer vision;other;input;optics;sensors;display technology;human-computer interaction;networks,technology;other;displays;end users and user experience,computer vision;other;input;optics;sensors;display technology;human-computer interaction;networks,technology;other;displays;end users and user experience,diffraction_efficiency eye_tracking holographic_optical_elements holography infrared_devices notch_filters thermography head mounted displays head updisplay heads up display holographic_photopolymer optical_clarity spatially_varying_diffraction_efficiency transparent_screen varying_diffractions volume_holographic volume_holographic_optical_element 703 2_electric_filters 742 1_photography 743_holography 746_imaging_techniques computer_vision other input optics sensors display_technology human computer_interaction networks,diffraction_efficiency eye_tracking holographic_optical_elements holography infrared_devices notch_filters thermography,head mounted displays head updisplay heads up display holographic_photopolymer optical_clarity spatially_varying_diffraction_efficiency transparent_screen varying_diffractions volume_holographic volume_holographic_optical_element,bayfol reg hx photopolymer film prove easy process recording material volume holographic optical element vhoes available customized grade industrial scale full color rgb recording replay capability two major advantage moreover adjustable diffraction efficiency tunable angular spectral selectivity vhoes recorded bayfol reg hx well unmatched optical clarity enables superior invisible bragg optical functionality film product replication vhoes bayfol reg hx carried highly cost efficient purely photonic roll roll r2r process utilizing thermoplastic substrate bayfol reg hx demonstrated compatible state art plastic processing technique like thermoforming film insert molding casting opened using variety industry proven integration technology vhoes therefore bayfol reg hx make way application field augmented reality head display hud head mounted display hmd free space combiners plastic optical waveguide transparent screen also vhoes made bayfol reg hx utilized highly sophisticated spectrometer astronomy well narrow band notch filter eyeglass laser strike see application hmd hud demanding performance requirement combiner imaging technology efficiency optical function clarity property bayfol reg hx make well suited solve challenge primary display near infrared imaging application eye tracking maintaining requirement optical performance demonstrate practical example bayfol reg hx vhoe using novel holography technique spatially varying diffraction efficiency copy 2023 spie,diffraction_efficiency eye_tracking holographic_optical_elements holography infrared_devices notch_filters thermography head mounted displays head updisplay heads up display holographic_photopolymer optical_clarity spatially_varying_diffraction_efficiency transparent_screen varying_diffractions volume_holographic volume_holographic_optical_element 703 2_electric_filters 742 1_photography 743_holography 746_imaging_techniques computer_vision other input optics sensors display_technology human computer_interaction networks bayfol reg hx photopolymer film prove easy process recording material volume holographic optical element vhoes available customized grade industrial scale full color rgb recording replay capability two major advantage moreover adjustable diffraction efficiency tunable angular spectral selectivity vhoes recorded bayfol reg hx well unmatched optical clarity enables superior invisible bragg optical functionality film product replication vhoes bayfol reg hx carried highly cost efficient purely photonic roll roll r2r process utilizing thermoplastic substrate bayfol reg hx demonstrated compatible state art plastic processing technique like thermoforming film insert molding casting opened using variety industry proven integration technology vhoes therefore bayfol reg hx make way application field augmented reality head display hud head mounted display hmd free space combiners plastic optical waveguide transparent screen also vhoes made bayfol reg hx utilized highly sophisticated spectrometer astronomy well narrow band notch filter eyeglass laser strike see application hmd hud demanding performance requirement combiner imaging technology efficiency optical function clarity property bayfol reg hx make well suited solve challenge primary display near infrared imaging application eye tracking maintaining requirement optical performance demonstrate practical example bayfol reg hx vhoe using novel holography technique spatially varying diffraction efficiency copy 2023 spie,bayfol reg hx photopolymer film prove easy process recording material volume holographic optical element vhoes available customized grade industrial scale full color rgb recording replay capability two major advantage moreover adjustable diffraction efficiency tunable angular spectral selectivity vhoes recorded bayfol reg hx well unmatched optical clarity enables superior invisible bragg optical functionality film product replication vhoes bayfol reg hx carried highly cost efficient purely photonic roll roll r2r process utilizing thermoplastic substrate bayfol reg hx demonstrated compatible state art plastic processing technique like thermoforming film insert molding casting opened using variety industry proven integration technology vhoes therefore bayfol reg hx make way application field augmented reality head display hud head mounted display hmd free space combiners plastic optical waveguide transparent screen also vhoes made bayfol reg hx utilized highly sophisticated spectrometer astronomy well narrow band notch filter eyeglass laser strike see application hmd hud demanding performance requirement combiner imaging technology efficiency optical function clarity property bayfol reg hx make well suited solve challenge primary display near infrared imaging application eye tracking maintaining requirement optical performance demonstrate practical example bayfol reg hx vhoe using novel holography technique spatially varying diffraction efficiency copy 2023 spiediffraction_efficiency eye_tracking holographic_optical_elements holography infrared_devices notch_filters thermographyhead mounted displays head updisplay heads up display holographic_photopolymer optical_clarity spatially_varying_diffraction_efficiency transparent_screen varying_diffractions volume_holographic volume_holographic_optical_element
451,GSV-NET: A Multi-Modal Deep Learning Network for 3D Point Cloud Classification,"Hoang, L., Lee, S.-H., Lee, E.-J., & Kwon, K.-R. (2022). GSV-NET: A Multi-Modal Deep Learning Network for 3D Point Cloud Classification. Applied Sciences, 12(1), 483. https://doi.org/10.3390/app12010483
",10.3390/app12010483,"Light Detection and Ranging (LiDAR), which applies light in the formation of a pulsed laser to estimate the distance between the LiDAR sensor and objects, is an effective remote sensing technology. Many applications use LiDAR including autonomous vehicles, robotics, and virtual and augmented reality (VR/AR). The 3D point cloud classification is now a hot research topic with the evolution of LiDAR technology. This research aims to provide a high performance and compatible real-world data method for 3D point cloud classification. More specifically, we introduce a novel framework for 3D point cloud classification, namely, GSV-NET, which uses Gaussian Supervector and enhancing region representation. GSV-NET extracts and combines both global and regional features of the 3D point cloud to further enhance the information of the point cloud features for the 3D point cloud classification. Firstly, we input the Gaussian Supervector description into a 3D wide-inception convolution neural network (CNN) structure to define the global feature. Secondly, we convert the regions of the 3D point cloud into color representation and capture region features with a 2D wide-inception network. These extracted features are inputs of a 1D CNN architecture. We evaluate the proposed framework on the point cloud dataset: ModelNet and the LiDAR dataset: Sydney. The ModelNet dataset was developed by Princeton University (New Jersey, United States), while the Sydney dataset was created by the University of Sydney (Sydney, Australia). Based on our numerical results, our framework achieves more accuracy than the state-of-the-art approaches.",B6320C Optical radar;B0240Z Other topics in statistics;B6135E Image recognition;C1140Z Other topics in statistics;C5260B Computer vision and image processing techniques;C6264 Neural nets;C7410 Electrical engineering computing,1D CNN architecture;3D point cloud classification;3D wide-inception CNN structure;3D wide-inception convolution neural network structure;Australia;Gaussian Supervector description;GSV-NET;LiDAR sensor;light detection and ranging;ModelNet dataset;multimodal deep learning network;point cloud dataset;point cloud features;Princeton University;pulsed laser;region representation;regional features;remote sensing technology;Sydney dataset;United States;University of Sydney,convolutional neural nets;deep learning (artificial intelligence);feature extraction;Gaussian processes;image classification;image representation;optical radar;radar computing;remote sensing by radar;stereo image processing,2021,Journal article (JA),Appl. Sci. (Switzerland),(1) Long Hoang; (2) Suk-Hwan Lee; (3) Eung-Joo Lee; (1) Ki-Ryong Kwon; ,"(1) Pukyong National University, Department of Artificial Intelligence Convergence, Korea, Republic of; (2) Dong-A University, Department of Computer Engineering, Korea, Republic of; (3) Tongmyong University, Division of Artificial Intelligence, Korea, Republic of; ",MDPI,-1,"[""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""gaussian processes"", ""image classification"", ""image representation"", ""optical radar"", ""radar computing"", ""remote sensing by radar"", ""stereo image processing""]","[""convolutional neural nets"", ""deep learning (artificial intelligence)"", ""feature extraction"", ""gaussian processes"", ""image classification"", ""image representation"", ""optical radar"", ""radar computing"", ""remote sensing by radar"", ""stereo image processing""]",convolutional neural nets;deep learning (artificial intelligence);feature extraction;gaussian processes;image classification;image representation;optical radar;radar computing;remote sensing by radar;stereo image processing,computer vision;other;liberal arts;medical;optics;chemical;sensors;developers;data;geospatial;artificial intelligence;networks,technology;other;displays;industries,computer vision;other;liberal arts;medical;optics;chemical;sensors;developers;data;geospatial;artificial intelligence;networks,technology;other;displays;industries,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction gaussian_processes image_classification image_representation optical_radar radar_computing remote_sensing_by_radar stereo_image_processing 1d_cnn_architecture 3d_point_cloud_classification 3d_wide inception_cnn_structure 3d_wide inception_convolution_neural_network_structure australia gaussian_supervector_description gsv net lidar_sensor light_detection_and_ranging modelnet_dataset multimodal_deep_learning_network point_cloud_dataset point_cloud_features princeton_university pulsed_laser region_representation regional_features remote_sensing_technology sydney_dataset united_states university_of_sydney b6320c_optical_radar b0240z_other_topics_in_statistics b6135e_image_recognition c1140z_other_topics_in_statistics c5260b_computer_vision_and_image_processing_techniques c6264_neural_nets c7410_electrical_engineering_computing computer_vision other liberal_arts medical optics chemical sensors developers data geospatial artificial_intelligence networks,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction gaussian_processes image_classification image_representation optical_radar radar_computing remote_sensing_by_radar stereo_image_processing,1d_cnn_architecture 3d_point_cloud_classification 3d_wide inception_cnn_structure 3d_wide inception_convolution_neural_network_structure australia gaussian_supervector_description gsv net lidar_sensor light_detection_and_ranging modelnet_dataset multimodal_deep_learning_network point_cloud_dataset point_cloud_features princeton_university pulsed_laser region_representation regional_features remote_sensing_technology sydney_dataset united_states university_of_sydney,light detection ranging lidar applies light formation pulsed laser estimate distance lidar sensor object effective remote sensing technology many application use lidar including autonomous vehicle robotics virtual augmented reality vr ar 3d point cloud classification hot research topic evolution lidar technology research aim provide high performance compatible real world data method 3d point cloud classification specifically introduce novel framework 3d point cloud classification namely gsv net us gaussian supervector enhancing region representation gsv net extract combine global regional feature 3d point cloud enhance information point cloud feature 3d point cloud classification firstly input gaussian supervector description 3d wide inception convolution neural network cnn structure define global feature secondly convert region 3d point cloud color representation capture region feature 2d wide inception network extracted feature input 1d cnn architecture evaluate proposed framework point cloud dataset modelnet lidar dataset sydney modelnet dataset developed princeton university new jersey united state sydney dataset created university sydney sydney australia based numerical result framework achieves accuracy state art approach,convolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction gaussian_processes image_classification image_representation optical_radar radar_computing remote_sensing_by_radar stereo_image_processing 1d_cnn_architecture 3d_point_cloud_classification 3d_wide inception_cnn_structure 3d_wide inception_convolution_neural_network_structure australia gaussian_supervector_description gsv net lidar_sensor light_detection_and_ranging modelnet_dataset multimodal_deep_learning_network point_cloud_dataset point_cloud_features princeton_university pulsed_laser region_representation regional_features remote_sensing_technology sydney_dataset united_states university_of_sydney b6320c_optical_radar b0240z_other_topics_in_statistics b6135e_image_recognition c1140z_other_topics_in_statistics c5260b_computer_vision_and_image_processing_techniques c6264_neural_nets c7410_electrical_engineering_computing computer_vision other liberal_arts medical optics chemical sensors developers data geospatial artificial_intelligence networks light detection ranging lidar applies light formation pulsed laser estimate distance lidar sensor object effective remote sensing technology many application use lidar including autonomous vehicle robotics virtual augmented reality vr ar 3d point cloud classification hot research topic evolution lidar technology research aim provide high performance compatible real world data method 3d point cloud classification specifically introduce novel framework 3d point cloud classification namely gsv net us gaussian supervector enhancing region representation gsv net extract combine global regional feature 3d point cloud enhance information point cloud feature 3d point cloud classification firstly input gaussian supervector description 3d wide inception convolution neural network cnn structure define global feature secondly convert region 3d point cloud color representation capture region feature 2d wide inception network extracted feature input 1d cnn architecture evaluate proposed framework point cloud dataset modelnet lidar dataset sydney modelnet dataset developed princeton university new jersey united state sydney dataset created university sydney sydney australia based numerical result framework achieves accuracy state art approach,light detection ranging lidar applies light formation pulsed laser estimate distance lidar sensor object effective remote sensing technology many application use lidar including autonomous vehicle robotics virtual augmented reality vr ar 3d point cloud classification hot research topic evolution lidar technology research aim provide high performance compatible real world data method 3d point cloud classification specifically introduce novel framework 3d point cloud classification namely gsv net us gaussian supervector enhancing region representation gsv net extract combine global regional feature 3d point cloud enhance information point cloud feature 3d point cloud classification firstly input gaussian supervector description 3d wide inception convolution neural network cnn structure define global feature secondly convert region 3d point cloud color representation capture region feature 2d wide inception network extracted feature input 1d cnn architecture evaluate proposed framework point cloud dataset modelnet lidar dataset sydney modelnet dataset developed princeton university new jersey united state sydney dataset created university sydney sydney australia based numerical result framework achieves accuracy state art approachconvolutional_neural_nets deep_learning_ artificial_intelligence feature_extraction gaussian_processes image_classification image_representation optical_radar radar_computing remote_sensing_by_radar stereo_image_processing1d_cnn_architecture 3d_point_cloud_classification 3d_wide inception_cnn_structure 3d_wide inception_convolution_neural_network_structure australia gaussian_supervector_description gsv net lidar_sensor light_detection_and_ranging modelnet_dataset multimodal_deep_learning_network point_cloud_dataset point_cloud_features princeton_university pulsed_laser region_representation regional_features remote_sensing_technology sydney_dataset united_states university_of_sydney
452,Detecting an Offset-Adjusted Similarity Score based on Duchenne Smiles,"Henneberg, M., Eghtebas, C., De Candido, O., Kunze, K., & Ward, J. A. (2023). Detecting an Offset-Adjusted Similarity Score based on Duchenne Smiles. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544549.3585709
",10.1145/3544549.3585709,"Detecting interpersonal synchrony in the wild through ubiquitous wearable sensing invites promising new social insights as well as the possibility of new interactions between humans-humans and humans-agents. We present the Offset-Adjusted SImilarity Score (OASIS), a real-time method of detecting similarity which we show working on visual detection of Duchenne smile between a pair of users. We conduct a user study survey (N = 27) to measure a user-based interoperability score on smile similarity and compare the user score with OASIS as well as the rolling window Pearson correlation and the Dynamic Time Warping (DTW) method. Ultimately, our results indicate that our algorithm has intrinsic qualities comparable to the user score and measures well to the statistical correlation methods. It takes the temporal offset between the input signals into account with the added benefit of being an algorithm which can be adapted to run in real-time will less computational intensity than traditional time series correlation methods.","B6135E Image recognition;B0240T Time series;C1140T Time series;C5260B Computer vision and image processing techniques;C6190V Mobile, ubiquitous and pervasive computing;C7810 Social and behavioural sciences computing",Duchenne smile;dynamic time warping method;humans-agents;humans-humans;interpersonal synchrony;OASIS;offset-adjusted similarity score;rolling window Pearson correlation;smile similarity;social insights;statistical correlation methods;time series correlation methods;ubiquitous wearable sensing;user-based interoperability score;visual detection,correlation methods;emotion recognition;open systems;real-time systems;social sciences computing;time series;ubiquitous computing,2023,Conference article (CA),CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,"(1) Henneberg, M.; (2) Eghtebas, C.; (1) De Candido, O.; (3) Kunze, K.; (4) Ward, J.A.; ","(1) Technical University of Munich, Germany; (2) Research Group Augmented Reality, Germany; (3) Keio University, Japan; (4) Goldsmiths University of London, United Kingdom; ",ACM,-1,"[""correlation methods"", ""emotion recognition"", ""open systems"", ""real-time systems"", ""social sciences computing"", ""time series"", ""ubiquitous computing""]","[""correlation methods"", ""emotion recognition"", ""open systems"", ""real-time systems"", ""social sciences computing"", ""time series"", ""ubiquitous computing""]",correlation methods;emotion recognition;open systems;real-time systems;social sciences computing;time series;ubiquitous computing,education;input;human factors;policy;developers;data;human-computer interaction;artificial intelligence,technology;end users and user experience;business;industries,education;input;human factors;policy;developers;data;human-computer interaction;artificial intelligence,technology;end users and user experience;business;industries,correlation_methods emotion_recognition open_systems real time_systems social_sciences_computing time_series ubiquitous_computing duchenne_smile dynamic_time_warping_method humans agents humans humans interpersonal_synchrony oasis offset adjusted_similarity_score rolling_window_pearson_correlation smile_similarity social_insights statistical_correlation_methods time_series_correlation_methods ubiquitous_wearable_sensing user based_interoperability_score visual_detection b6135e_image_recognition b0240t_time_series c1140t_time_series c5260b_computer_vision_and_image_processing_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7810_social_and_behavioural_sciences_computing education input human_factors policy developers data human computer_interaction artificial_intelligence,correlation_methods emotion_recognition open_systems real time_systems social_sciences_computing time_series ubiquitous_computing,duchenne_smile dynamic_time_warping_method humans agents humans humans interpersonal_synchrony oasis offset adjusted_similarity_score rolling_window_pearson_correlation smile_similarity social_insights statistical_correlation_methods time_series_correlation_methods ubiquitous_wearable_sensing user based_interoperability_score visual_detection,detecting interpersonal synchrony wild ubiquitous wearable sensing invite promising new social insight well possibility new interaction human human human agent present offset adjusted similarity score oasis real time method detecting similarity show working visual detection duchenne smile pair user conduct user study survey n 27 measure user based interoperability score smile similarity compare user score oasis well rolling window pearson correlation dynamic time warping dtw method ultimately result indicate algorithm intrinsic quality comparable user score measure well statistical correlation method take temporal offset input signal account added benefit algorithm adapted run real time le computational intensity traditional time series correlation method,correlation_methods emotion_recognition open_systems real time_systems social_sciences_computing time_series ubiquitous_computing duchenne_smile dynamic_time_warping_method humans agents humans humans interpersonal_synchrony oasis offset adjusted_similarity_score rolling_window_pearson_correlation smile_similarity social_insights statistical_correlation_methods time_series_correlation_methods ubiquitous_wearable_sensing user based_interoperability_score visual_detection b6135e_image_recognition b0240t_time_series c1140t_time_series c5260b_computer_vision_and_image_processing_techniques c6190v_mobile _ubiquitous_and_pervasive_computing c7810_social_and_behavioural_sciences_computing education input human_factors policy developers data human computer_interaction artificial_intelligence detecting interpersonal synchrony wild ubiquitous wearable sensing invite promising new social insight well possibility new interaction human human human agent present offset adjusted similarity score oasis real time method detecting similarity show working visual detection duchenne smile pair user conduct user study survey n 27 measure user based interoperability score smile similarity compare user score oasis well rolling window pearson correlation dynamic time warping dtw method ultimately result indicate algorithm intrinsic quality comparable user score measure well statistical correlation method take temporal offset input signal account added benefit algorithm adapted run real time le computational intensity traditional time series correlation method,detecting interpersonal synchrony wild ubiquitous wearable sensing invite promising new social insight well possibility new interaction human human human agent present offset adjusted similarity score oasis real time method detecting similarity show working visual detection duchenne smile pair user conduct user study survey n 27 measure user based interoperability score smile similarity compare user score oasis well rolling window pearson correlation dynamic time warping dtw method ultimately result indicate algorithm intrinsic quality comparable user score measure well statistical correlation method take temporal offset input signal account added benefit algorithm adapted run real time le computational intensity traditional time series correlation methodcorrelation_methods emotion_recognition open_systems real time_systems social_sciences_computing time_series ubiquitous_computingduchenne_smile dynamic_time_warping_method humans agents humans humans interpersonal_synchrony oasis offset adjusted_similarity_score rolling_window_pearson_correlation smile_similarity social_insights statistical_correlation_methods time_series_correlation_methods ubiquitous_wearable_sensing user based_interoperability_score visual_detection
453,Prediction of Breast Cancer Via Deep Learning,"Huang, Y. (2023). Prediction of Breast Cancer Via Deep Learning. Smart Innovation, Systems and Technologies, 87–97. https://doi.org/10.1007/978-981-99-1230-8_8
",10.1007/978-981-99-1230-8_8,"With the continuous progress of machine learning in image processing, artificial neural networks have more and more applications in medical image processing. Aiming at the method of selecting a BP neural network to realize the diagnosis of breast cancer pathological images, the method of deep learning is selected for prediction, which improves the prediction accuracy and obtains a more effective diagnosis effect. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",461.1 Biomedical Engineering;461.4 Ergonomics and Human Factors Engineering;461.6 Medicine and Pharmacology;746 Imaging Techniques,BP neural networks;Breast Cancer;Cancer prediction;Deep learning;Images processing;Machine-learning;Medical images processing;Pathological images;Pathology image;Prediction accuracy,Deep learning;Diseases;Forecasting;Image enhancement;Medical imaging;Neural networks,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Huang, Yihe; ","(1) College of Software Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""deep learning"", ""diseases"", ""forecasting"", ""image enhancement"", ""medical imaging"", ""neural networks""]","[""deep learning"", ""diseases"", ""forecasting"", ""image enhancement"", ""medical imaging"", ""neural networks""]",deep learning;diseases;forecasting;image enhancement;medical imaging;neural networks,medical;computer vision;artificial intelligence;business planning and management,technology;business;industries,medical;computer vision;artificial intelligence;business planning and management,technology;business;industries,deep_learning diseases forecasting image_enhancement medical_imaging neural_networks bp_neural_networks breast_cancer cancer_prediction deep_learning images_processing machine learning medical_images_processing pathological_images pathology_image prediction_accuracy 461 1_biomedical_engineering 461 4_ergonomics_and_human_factors_engineering 461 6_medicine_and_pharmacology 746_imaging_techniques medical computer_vision artificial_intelligence business_planning_and_management,deep_learning diseases forecasting image_enhancement medical_imaging neural_networks,bp_neural_networks breast_cancer cancer_prediction deep_learning images_processing machine learning medical_images_processing pathological_images pathology_image prediction_accuracy,continuous progress machine learning image processing artificial neural network application medical image processing aiming method selecting bp neural network realize diagnosis breast cancer pathological image method deep learning selected prediction improves prediction accuracy obtains effective diagnosis effect copy 2023 author exclusive license springer nature singapore pte ltd,deep_learning diseases forecasting image_enhancement medical_imaging neural_networks bp_neural_networks breast_cancer cancer_prediction deep_learning images_processing machine learning medical_images_processing pathological_images pathology_image prediction_accuracy 461 1_biomedical_engineering 461 4_ergonomics_and_human_factors_engineering 461 6_medicine_and_pharmacology 746_imaging_techniques medical computer_vision artificial_intelligence business_planning_and_management continuous progress machine learning image processing artificial neural network application medical image processing aiming method selecting bp neural network realize diagnosis breast cancer pathological image method deep learning selected prediction improves prediction accuracy obtains effective diagnosis effect copy 2023 author exclusive license springer nature singapore pte ltd,continuous progress machine learning image processing artificial neural network application medical image processing aiming method selecting bp neural network realize diagnosis breast cancer pathological image method deep learning selected prediction improves prediction accuracy obtains effective diagnosis effect copy 2023 author exclusive license springer nature singapore pte ltddeep_learning diseases forecasting image_enhancement medical_imaging neural_networksbp_neural_networks breast_cancer cancer_prediction deep_learning images_processing machine learning medical_images_processing pathological_images pathology_image prediction_accuracy
454,Augmented and&nbsp;Virtual Reality in&nbsp;Computer Science Education,"Anastasi, G. F., & Munna, E. G. (2023). Augmented and Virtual Reality in Computer Science Education. Communications in Computer and Information Science, 601–612. https://doi.org/10.1007/978-3-031-29800-4_45
",10.1007/978-3-031-29800-4_45,"This paper shares and analyzes some experiences in the use of augmented and virtual reality, presenting technologies and methodologies leveraged for implementing three different projects. Such projects, carried out at the high school level, are used for discussing on the relevance of augmented and virtual reality for providing fundamental concepts on computer science education. To this end, an assessment toolkit is provided for an effective evaluation of this kind of activities. &copy; 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","723 Computer Software, Data Handling and Applications;901.2 Education",Augmented and virtual realities;Computer Science Education;Fundamental concepts;Higher School,E-learning;Education computing;Engineering education;Virtual reality,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Anastasi, Gaetano Francesco; (2) Munna, Enzo Giuseppe; ","(1) ITET G. Garibaldi, Marsala (TP), Italy; (2) ITET G. Caruso, Alcamo (TP), Italy; ",Springer Science and Business Media Deutschland GmbH,-1,"[""e-learning"", ""education computing"", ""engineering education""]","[""e-learning"", ""education computing"", ""engineering education""]",e-learning;education computing;engineering education,medical;education,industries,medical;education,industries,e learning education_computing engineering_education augmented_and_virtual_realities computer_science_education fundamental_concepts higher_school 723_computer_software _data_handling_and_applications 901 2_education medical education,e learning education_computing engineering_education,augmented_and_virtual_realities computer_science_education fundamental_concepts higher_school,paper share analyzes experience use augmented virtual reality presenting technology methodology leveraged implementing three different project project carried high school level used discussing relevance augmented virtual reality providing fundamental concept computer science education end assessment toolkit provided effective evaluation kind activity copy 2023 author exclusive license springer nature switzerland ag,e learning education_computing engineering_education augmented_and_virtual_realities computer_science_education fundamental_concepts higher_school 723_computer_software _data_handling_and_applications 901 2_education medical education paper share analyzes experience use augmented virtual reality presenting technology methodology leveraged implementing three different project project carried high school level used discussing relevance augmented virtual reality providing fundamental concept computer science education end assessment toolkit provided effective evaluation kind activity copy 2023 author exclusive license springer nature switzerland ag,paper share analyzes experience use augmented virtual reality presenting technology methodology leveraged implementing three different project project carried high school level used discussing relevance augmented virtual reality providing fundamental concept computer science education end assessment toolkit provided effective evaluation kind activity copy 2023 author exclusive license springer nature switzerland age learning education_computing engineering_educationaugmented_and_virtual_realities computer_science_education fundamental_concepts higher_school
455,Visual and haptic feedback in detecting motor imagery within a wearable brain-computer interface,"Arpaia, P., Coyle, D., Donnarumma, F., Esposito, A., Natalizio, A., & Parvis, M. (2023). Visual and haptic feedback in detecting motor imagery within a wearable brain–computer interface. Measurement, 206, 112304. https://doi.org/10.1016/j.measurement.2022.112304
",10.1016/j.measurement.2022.112304,"This paper presents a wearable brain-computer interface relying on neurofeedback in extended reality for the enhancement of motor imagery training. Visual and vibrotactile feedback modalities were evaluated when presented either singularly or simultaneously. Only three acquisition channels and state-of-the-art vibrotactile chest-based feedback were employed. Experimental validation was carried out with eight subjects participating in two or three sessions on different days, with 360 trials per subject per session. Neurofeedback led to statistically significant improvement in performance over the two/three sessions, thus demonstrating for the first time functionality of a motor imagery-based instrument even by using an utmost wearable electroencephalograph and a commercial gaming vibrotactile suit. In the best cases, classification accuracy exceeded 80 % with more than 20 % improvement with respect to the initial performance. No feedback modality was generally preferable across the cohort study, but it is concluded that the best feedback modality may be subject-dependent. All rights reserved Elsevier.",A8730C Electrical activity in neurophysiological processes;A8770F Electrodiagnostics and other electrical measurement techniques;B6140 Signal processing and detection;B7510D Bioelectric signals;C5260 Digital signal processing;C5540B Interactive-input devices;C6180 User interfaces;C7330 Biology and medical computing;C7850 Computer assistance for persons with handicaps,chest-based feedback;commercial gaming vibrotactile suit;extended reality;feedback modality;haptic feedback;motor imagery training;motor imagery-based instrument;session;statistically significant improvement;utmost wearable electroencephalograph;vibrotactile feedback modalities;visual feedback modalities;wearable brain-computer interface,brain-computer interfaces;electroencephalography;feedback;haptic interfaces;medical signal processing;neurophysiology,2023,Journal article (JA),Measurement (Netherlands),"(1) Arpaia, P.; (3) Coyle, D.; (1) Donnarumma, F.; (1) Esposito, A.; (1) Natalizio, A.; (5) Parvis, M.; ","(1) Augmented Reality for Health Monitoring Laboratory, Italy; (2) Universita degli Studi di Napoli Federico II, Department of Electrical Engineering and Information Technology, Italy; (3) University of Ulster, Intelligent Systems Research Centre, United Kingdom; (4) National Research Council, Institute of Cognitive Sciences and Technologies, Italy; (5) Polytechnic of Turin, Department of Electronics and Telecommunications, Italy; ",Elsevier B.V.,-1,"[""brain-computer interfaces"", ""electroencephalography"", ""feedback"", ""haptic interfaces"", ""medical signal processing"", ""neurophysiology""]","[""brain-computer interfaces"", ""electroencephalography"", ""feedback"", ""haptic interfaces"", ""medical signal processing"", ""neurophysiology""]",brain-computer interfaces;electroencephalography;feedback;haptic interfaces;medical signal processing;neurophysiology,farming and natural science;input;medical;sensors;human factors;data;human-computer interaction,technology;end users and user experience;industries,farming and natural science;input;medical;sensors;human factors;data;human-computer interaction,technology;end users and user experience;industries,brain computer_interfaces electroencephalography feedback haptic_interfaces medical_signal_processing neurophysiology chest based_feedback commercial_gaming_vibrotactile_suit extended_reality feedback_modality haptic_feedback motor_imagery_training motor_imagery based_instrument session statistically_significant_improvement utmost_wearable_electroencephalograph vibrotactile_feedback_modalities visual_feedback_modalities wearable_brain computer_interface a8730c_electrical_activity_in_neurophysiological_processes a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b6140_signal_processing_and_detection b7510d_bioelectric_signals c5260_digital_signal_processing c5540b_interactive input_devices c6180_user_interfaces c7330_biology_and_medical_computing c7850_computer_assistance_for_persons_with_handicaps farming_and_natural_science input medical sensors human_factors data human computer_interaction,brain computer_interfaces electroencephalography feedback haptic_interfaces medical_signal_processing neurophysiology,chest based_feedback commercial_gaming_vibrotactile_suit extended_reality feedback_modality haptic_feedback motor_imagery_training motor_imagery based_instrument session statistically_significant_improvement utmost_wearable_electroencephalograph vibrotactile_feedback_modalities visual_feedback_modalities wearable_brain computer_interface,paper present wearable brain computer interface relying neurofeedback extended reality enhancement motor imagery training visual vibrotactile feedback modality evaluated presented either singularly simultaneously three acquisition channel state art vibrotactile chest based feedback employed experimental validation carried eight subject participating two three session different day 360 trial per subject per session neurofeedback led statistically significant improvement performance two three session thus demonstrating first time functionality motor imagery based instrument even using utmost wearable electroencephalograph commercial gaming vibrotactile suit best case classification accuracy exceeded 80 20 improvement respect initial performance feedback modality generally preferable across cohort study concluded best feedback modality may subject dependent right reserved elsevier,brain computer_interfaces electroencephalography feedback haptic_interfaces medical_signal_processing neurophysiology chest based_feedback commercial_gaming_vibrotactile_suit extended_reality feedback_modality haptic_feedback motor_imagery_training motor_imagery based_instrument session statistically_significant_improvement utmost_wearable_electroencephalograph vibrotactile_feedback_modalities visual_feedback_modalities wearable_brain computer_interface a8730c_electrical_activity_in_neurophysiological_processes a8770f_electrodiagnostics_and_other_electrical_measurement_techniques b6140_signal_processing_and_detection b7510d_bioelectric_signals c5260_digital_signal_processing c5540b_interactive input_devices c6180_user_interfaces c7330_biology_and_medical_computing c7850_computer_assistance_for_persons_with_handicaps farming_and_natural_science input medical sensors human_factors data human computer_interaction paper present wearable brain computer interface relying neurofeedback extended reality enhancement motor imagery training visual vibrotactile feedback modality evaluated presented either singularly simultaneously three acquisition channel state art vibrotactile chest based feedback employed experimental validation carried eight subject participating two three session different day 360 trial per subject per session neurofeedback led statistically significant improvement performance two three session thus demonstrating first time functionality motor imagery based instrument even using utmost wearable electroencephalograph commercial gaming vibrotactile suit best case classification accuracy exceeded 80 20 improvement respect initial performance feedback modality generally preferable across cohort study concluded best feedback modality may subject dependent right reserved elsevier,paper present wearable brain computer interface relying neurofeedback extended reality enhancement motor imagery training visual vibrotactile feedback modality evaluated presented either singularly simultaneously three acquisition channel state art vibrotactile chest based feedback employed experimental validation carried eight subject participating two three session different day 360 trial per subject per session neurofeedback led statistically significant improvement performance two three session thus demonstrating first time functionality motor imagery based instrument even using utmost wearable electroencephalograph commercial gaming vibrotactile suit best case classification accuracy exceeded 80 20 improvement respect initial performance feedback modality generally preferable across cohort study concluded best feedback modality may subject dependent right reserved elsevierbrain computer_interfaces electroencephalography feedback haptic_interfaces medical_signal_processing neurophysiologychest based_feedback commercial_gaming_vibrotactile_suit extended_reality feedback_modality haptic_feedback motor_imagery_training motor_imagery based_instrument session statistically_significant_improvement utmost_wearable_electroencephalograph vibrotactile_feedback_modalities visual_feedback_modalities wearable_brain computer_interface
456,Ship Target Detection in Remote Sensing Image Based on Improved RetinaNet,"Sun, Y., & Fan, T. (2023). Ship Target Detection in Remote Sensing Image Based on Improved RetinaNet. Smart Innovation, Systems and Technologies, 109–119. https://doi.org/10.1007/978-981-99-1230-8_10
",10.1007/978-981-99-1230-8_10,"Ship image target detection has important applications for ship management. In recent years, target detection based on deep learning has been widely studied in visual ship target detection. However, due to the difference and overlap of ship targets, the target loss rate is high. In order to solve the problem, this paper proposes a target detection algorithm based on improved RetinaNet for ship image target detection. The cyclical focal loss function and CIOU loss function are used to increase the training times of negative samples in the middle of training, which effectively increases ship detection precision by 2.5%. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",461.4 Ergonomics and Human Factors Engineering,Image-based;Loss functions;Loss rates;Negative samples;Remote sensing images;Ship management;Ship targets;Target detection algorithm;Targets detection;Training time,Deep learning;Image enhancement;Image recognition;Remote sensing,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Sun, Yandong; (2) Fan, Tongliang; ","(1) Department of Maritime Command, China Coast Guard Academy, Ningbo; 315801, China; (2) Government Office Administration Bureau, Beilun District, Ningbo; 315801, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""deep learning"", ""image enhancement"", ""image recognition"", ""remote sensing""]","[""deep learning"", ""image enhancement"", ""image recognition"", ""remote sensing""]",deep learning;image enhancement;image recognition;remote sensing,computer vision;medical;sensors;human factors;artificial intelligence,technology;industries;end users and user experience,computer vision;medical;sensors;human factors;artificial intelligence,technology;industries;end users and user experience,deep_learning image_enhancement image_recognition remote_sensing image based loss_functions loss_rates negative_samples remote_sensing_images ship_management ship_targets target_detection_algorithm targets_detection training_time 461 4_ergonomics_and_human_factors_engineering computer_vision medical sensors human_factors artificial_intelligence,deep_learning image_enhancement image_recognition remote_sensing,image based loss_functions loss_rates negative_samples remote_sensing_images ship_management ship_targets target_detection_algorithm targets_detection training_time,ship image target detection important application ship management recent year target detection based deep learning widely studied visual ship target detection however due difference overlap ship target target loss rate high order solve problem paper proposes target detection algorithm based improved retinanet ship image target detection cyclical focal loss function ciou loss function used increase training time negative sample middle training effectively increase ship detection precision 2 5 copy 2023 author exclusive license springer nature singapore pte ltd,deep_learning image_enhancement image_recognition remote_sensing image based loss_functions loss_rates negative_samples remote_sensing_images ship_management ship_targets target_detection_algorithm targets_detection training_time 461 4_ergonomics_and_human_factors_engineering computer_vision medical sensors human_factors artificial_intelligence ship image target detection important application ship management recent year target detection based deep learning widely studied visual ship target detection however due difference overlap ship target target loss rate high order solve problem paper proposes target detection algorithm based improved retinanet ship image target detection cyclical focal loss function ciou loss function used increase training time negative sample middle training effectively increase ship detection precision 2 5 copy 2023 author exclusive license springer nature singapore pte ltd,ship image target detection important application ship management recent year target detection based deep learning widely studied visual ship target detection however due difference overlap ship target target loss rate high order solve problem paper proposes target detection algorithm based improved retinanet ship image target detection cyclical focal loss function ciou loss function used increase training time negative sample middle training effectively increase ship detection precision 2 5 copy 2023 author exclusive license springer nature singapore pte ltddeep_learning image_enhancement image_recognition remote_sensingimage based loss_functions loss_rates negative_samples remote_sensing_images ship_management ship_targets target_detection_algorithm targets_detection training_time
457,Research on the Application of 3D Modeling Technology in Mechanical Structure Teaching,"Qin, L., Yang, J., Tang, L., Gan, Q., & Wang, H. (2023). Research on the Application of 3D Modeling Technology in Mechanical Structure Teaching. Smart Innovation, Systems and Technologies, 121–129. https://doi.org/10.1007/978-981-99-1230-8_11
",10.1007/978-981-99-1230-8_11,"Due to the constant acceleration of the upgrading of equipment, the mechanical structure teaching ability of colleges and universities is required to be higher and higher. Therefore, it is urgent to explore some new and efficient teaching methods to enrich the teaching means. In this paper, the current situation and characteristics of 3D modeling technology are introduced first. Then, the problems and reasons for mechanical structure teaching in college are analyzed in detail. Finally, combined with the characteristics of ""3D modeling technology"", the paper puts forward concrete ideas to improve the quality of mechanical structure teaching. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",723.2 Data Processing and Image Processing;723.5 Computer Applications,3d modeling technologies;Colleges and universities;Constant acceleration;Current characteristic;Current situation;Mechanical structures;Quality improvement;Structure teaching;Teaching means;Teaching methods,3D modeling;Three dimensional computer graphics,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Qin, Lixiang; (1) Yang, Jing; (1) Tang, Liang; (1) Gan, Quan; (1) Wang, Hongkai; ","(1) Nanjing Campus of PLA Army Academy of Artillery and Air Defense, Jiangsu, Nanjing; 210000, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""3d modeling"", ""three dimensional computer graphics""]","[""3d modeling"", ""three dimensional computer graphics""]",3d modeling;three dimensional computer graphics,manufacturing;graphics,technology;industries,manufacturing;graphics,technology;industries,3d_modeling three_dimensional_computer_graphics 3d_modeling_technologies colleges_and_universities constant_acceleration current_characteristic current_situation mechanical_structures quality_improvement structure_teaching teaching_means teaching_methods 723 2_data_processing_and_image_processing 723 5_computer_applications manufacturing graphics,3d_modeling three_dimensional_computer_graphics,3d_modeling_technologies colleges_and_universities constant_acceleration current_characteristic current_situation mechanical_structures quality_improvement structure_teaching teaching_means teaching_methods,due constant acceleration upgrading equipment mechanical structure teaching ability college university required higher higher therefore urgent explore new efficient teaching method enrich teaching mean paper current situation characteristic 3d modeling technology introduced first problem reason mechanical structure teaching college analyzed detail finally combined characteristic 3d modeling technology paper put forward concrete idea improve quality mechanical structure teaching copy 2023 author exclusive license springer nature singapore pte ltd,3d_modeling three_dimensional_computer_graphics 3d_modeling_technologies colleges_and_universities constant_acceleration current_characteristic current_situation mechanical_structures quality_improvement structure_teaching teaching_means teaching_methods 723 2_data_processing_and_image_processing 723 5_computer_applications manufacturing graphics due constant acceleration upgrading equipment mechanical structure teaching ability college university required higher higher therefore urgent explore new efficient teaching method enrich teaching mean paper current situation characteristic 3d modeling technology introduced first problem reason mechanical structure teaching college analyzed detail finally combined characteristic 3d modeling technology paper put forward concrete idea improve quality mechanical structure teaching copy 2023 author exclusive license springer nature singapore pte ltd,due constant acceleration upgrading equipment mechanical structure teaching ability college university required higher higher therefore urgent explore new efficient teaching method enrich teaching mean paper current situation characteristic 3d modeling technology introduced first problem reason mechanical structure teaching college analyzed detail finally combined characteristic 3d modeling technology paper put forward concrete idea improve quality mechanical structure teaching copy 2023 author exclusive license springer nature singapore pte ltd3d_modeling three_dimensional_computer_graphics3d_modeling_technologies colleges_and_universities constant_acceleration current_characteristic current_situation mechanical_structures quality_improvement structure_teaching teaching_means teaching_methods
458,A Review of Temporal Network Analysis and Applications,"Yu, J., Xiao, B., & Cui, Y. (2023). A Review of Temporal Network Analysis and Applications. Smart Innovation, Systems and Technologies, 1–10. https://doi.org/10.1007/978-981-99-1230-8_1
",10.1007/978-981-99-1230-8_1,"With the continuous development of network science, a single and static network structure has become more and more difficult to portray various complex systems, while the temporal network is becoming an effective tool to solve the above problem. At present, the research on the temporal network is still at the stage of primary, and there are still many worthy areas to be further explored. Inspired by this, in our paper, we review the modeling and representation of temporal networks, the structural characteristics and statistical properties of networks, and the application analysis; analyze the weaknesses of the current research; and look forward to the future development aspects. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",other,Application analysis;Continuous development;Network models;Network science;Network structures;Single-networks;Static networks;Structural feature;Temporal network modeling;Temporal networks,other,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Yu, Jintao; (1) Xiao, Bing; (2) Cui, Yuzhu; ","(1) Department of Intelligence, Air Force Early Warning Academy, Hubei, Wuhan; 430019, China; (2) Zhejiang Lab, Hangzhou; 311122, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""other""]","[""other""]",other,other,other,other,other,other application_analysis continuous_development network_models network_science network_structures single networks static_networks structural_feature temporal_network_modeling temporal_networks other other,other,application_analysis continuous_development network_models network_science network_structures single networks static_networks structural_feature temporal_network_modeling temporal_networks,continuous development network science single static network structure become difficult portray various complex system temporal network becoming effective tool solve problem present research temporal network still stage primary still many worthy area explored inspired paper review modeling representation temporal network structural characteristic statistical property network application analysis analyze weakness current research look forward future development aspect copy 2023 author exclusive license springer nature singapore pte ltd,other application_analysis continuous_development network_models network_science network_structures single networks static_networks structural_feature temporal_network_modeling temporal_networks other other continuous development network science single static network structure become difficult portray various complex system temporal network becoming effective tool solve problem present research temporal network still stage primary still many worthy area explored inspired paper review modeling representation temporal network structural characteristic statistical property network application analysis analyze weakness current research look forward future development aspect copy 2023 author exclusive license springer nature singapore pte ltd,continuous development network science single static network structure become difficult portray various complex system temporal network becoming effective tool solve problem present research temporal network still stage primary still many worthy area explored inspired paper review modeling representation temporal network structural characteristic statistical property network application analysis analyze weakness current research look forward future development aspect copy 2023 author exclusive license springer nature singapore pte ltdotherapplication_analysis continuous_development network_models network_science network_structures single networks static_networks structural_feature temporal_network_modeling temporal_networks
459,Course Homework Reform in Universities Based on Extended Reality,"Fu, J., Liu, Y., Mi, C., Peng, X., & Xiao, J. (2023). Course Homework Reform in Universities Based on Extended Reality. Communications in Computer and Information Science, 281–288. https://doi.org/10.1007/978-981-99-2449-3_25
",10.1007/978-981-99-2449-3_25,"In view of the serious issues commonly existing with coursework in Chinese universities at present, such as its original function weakening or being suppressed, its form being too abstract and lack of elaborate design. In order to resolve these problems observed&nbsp;in usual homework, this paper proposes a reform scheme for cloud coursework based on Extended Reality and Bloom model. It mainly includes five key parts, such as interaction, scene, comprehensive evaluation, digital twin and data analysis. In addition, the reform&rsquo;s effectiveness is illustrated through&nbsp;amassing&nbsp;and&nbsp;comparing the feedback of&nbsp;college&nbsp;students&nbsp;for&nbsp;teaching. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications",Chinese universities;Cloud platforms;College students;Comprehensive evaluation;Courseworks;Extended reality;Key parts;Mixed reality,E-learning;Mixed reality;Students,2023,Conference article (CA),Commun. Comput. Info. Sci.,"(1) Fu, Jinrong; (1) Liu, Yiwen; (1) Mi, Chunqiao; (1) Peng, Xiaoning; (1) Xiao, Jianhua; ","(1) School of Computer and Artificial Intelligence, Huaihua University, Hunan, Huaihua; 418000, China; (2) Key Laboratory of Wuling-Mountain Health Big Data Intelligent Processing and Application in Hunan Province Universities, Hunan, Huaihua; 418000, China; (3) Key Laboratory of Intelligent Control Technology for Wuling-Mountain Ecological Agriculture in Hunan Province, Hunan, Huaihua; 418000, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""e-learning"", ""students""]","[""e-learning"", ""students""]",e-learning;students,medical;education;users,end users and user experience;industries,medical;education;users,end users and user experience;industries,e learning students chinese_universities cloud_platforms college_students comprehensive_evaluation courseworks extended_reality key_parts mixed_reality 723_computer_software _data_handling_and_applications medical education users,e learning students,chinese_universities cloud_platforms college_students comprehensive_evaluation courseworks extended_reality key_parts mixed_reality,view serious issue commonly existing coursework chinese university present original function weakening suppressed form abstract lack elaborate design order resolve problem observed nbsp usual homework paper proposes reform scheme cloud coursework based extended reality bloom model mainly includes five key part interaction scene comprehensive evaluation digital twin data analysis addition reform rsquo effectiveness illustrated nbsp amassing nbsp nbsp comparing feedback nbsp college nbsp student nbsp nbsp teaching copy 2023 author exclusive license springer nature singapore pte ltd,e learning students chinese_universities cloud_platforms college_students comprehensive_evaluation courseworks extended_reality key_parts mixed_reality 723_computer_software _data_handling_and_applications medical education users view serious issue commonly existing coursework chinese university present original function weakening suppressed form abstract lack elaborate design order resolve problem observed nbsp usual homework paper proposes reform scheme cloud coursework based extended reality bloom model mainly includes five key part interaction scene comprehensive evaluation digital twin data analysis addition reform rsquo effectiveness illustrated nbsp amassing nbsp nbsp comparing feedback nbsp college nbsp student nbsp nbsp teaching copy 2023 author exclusive license springer nature singapore pte ltd,view serious issue commonly existing coursework chinese university present original function weakening suppressed form abstract lack elaborate design order resolve problem observed nbsp usual homework paper proposes reform scheme cloud coursework based extended reality bloom model mainly includes five key part interaction scene comprehensive evaluation digital twin data analysis addition reform rsquo effectiveness illustrated nbsp amassing nbsp nbsp comparing feedback nbsp college nbsp student nbsp nbsp teaching copy 2023 author exclusive license springer nature singapore pte ltde learning studentschinese_universities cloud_platforms college_students comprehensive_evaluation courseworks extended_reality key_parts mixed_reality
460,SOC Estimation of Lithium Titanate Battery Based on Variable Temperature Equivalent Model,"Song, C., Luo, J., Chen, X., & Peng, Z. (2023). SOC Estimation of Lithium Titanate Battery Based on Variable Temperature Equivalent Model. Smart Innovation, Systems and Technologies, 285–298. https://doi.org/10.1007/978-981-99-1230-8_25
",10.1007/978-981-99-1230-8_25,"To ensure the normal service life and battery safety, accurate estimation of state of charge (SOC) of lithium titanate ion battery is of great significance. For the purpose of improving the accuracy of SOC estimation further, an equivalent circuit model considering temperature factors is established according to the external properties of lithium titanate ion battery at various ambient temperatures. Then, based on the proposed variable temperature equivalent model, the battery SOC is estimated using the Cubature Kalman Filter (CKF) algorithm. Finally, the SOC estimation outcomes are compared with the real value, and it is found that the maximum estimation error is within &plusmn;2% at various temperature conditions. According to the test results, the suggested SOC estimation algorithm on the basis of the variable temperature equivalent model has good temperature adaptability and high estimation accuracy. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",702.1.2 Secondary Batteries,Cubature kalman filters;Equivalent modeling;Ion batteries;Life safety;Lithium titanate;Lithium titanate battery;SOC estimations;State-of-charge estimation;Variable temperature;Variable temperature equivalent model,Battery management systems;Equivalent circuits;Kalman filters;Lithium compounds;Lithium-ion batteries,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Song, Chao; (1) Luo, Jianhua; (1) Chen, Xi; (1) Peng, Zhizhao; ","(1) Army Academy of Armored Forces, Beijing, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""battery management systems"", ""equivalent circuits"", ""kalman filters"", ""lithium compounds"", ""lithium-ion batteries""]","[""battery management systems"", ""equivalent circuits"", ""kalman filters"", ""lithium compounds"", ""lithium-ion batteries""]",battery management systems;equivalent circuits;kalman filters;lithium compounds;lithium-ion batteries,other;education;artificial intelligence,technology;other;industries,other;education;artificial intelligence,technology;other;industries,battery_management_systems equivalent_circuits kalman_filters lithium_compounds lithium ion_batteries cubature_kalman_filters equivalent_modeling ion_batteries life_safety lithium_titanate lithium_titanate_battery soc_estimations state of charge_estimation variable_temperature variable_temperature_equivalent_model 702 1 2_secondary_batteries other education artificial_intelligence,battery_management_systems equivalent_circuits kalman_filters lithium_compounds lithium ion_batteries,cubature_kalman_filters equivalent_modeling ion_batteries life_safety lithium_titanate lithium_titanate_battery soc_estimations state of charge_estimation variable_temperature variable_temperature_equivalent_model,ensure normal service life battery safety accurate estimation state charge soc lithium titanate ion battery great significance purpose improving accuracy soc estimation equivalent circuit model considering temperature factor established according external property lithium titanate ion battery various ambient temperature based proposed variable temperature equivalent model battery soc estimated using cubature kalman filter ckf algorithm finally soc estimation outcome compared real value found maximum estimation error within plusmn 2 various temperature condition according test result suggested soc estimation algorithm basis variable temperature equivalent model good temperature adaptability high estimation accuracy copy 2023 author exclusive license springer nature singapore pte ltd,battery_management_systems equivalent_circuits kalman_filters lithium_compounds lithium ion_batteries cubature_kalman_filters equivalent_modeling ion_batteries life_safety lithium_titanate lithium_titanate_battery soc_estimations state of charge_estimation variable_temperature variable_temperature_equivalent_model 702 1 2_secondary_batteries other education artificial_intelligence ensure normal service life battery safety accurate estimation state charge soc lithium titanate ion battery great significance purpose improving accuracy soc estimation equivalent circuit model considering temperature factor established according external property lithium titanate ion battery various ambient temperature based proposed variable temperature equivalent model battery soc estimated using cubature kalman filter ckf algorithm finally soc estimation outcome compared real value found maximum estimation error within plusmn 2 various temperature condition according test result suggested soc estimation algorithm basis variable temperature equivalent model good temperature adaptability high estimation accuracy copy 2023 author exclusive license springer nature singapore pte ltd,ensure normal service life battery safety accurate estimation state charge soc lithium titanate ion battery great significance purpose improving accuracy soc estimation equivalent circuit model considering temperature factor established according external property lithium titanate ion battery various ambient temperature based proposed variable temperature equivalent model battery soc estimated using cubature kalman filter ckf algorithm finally soc estimation outcome compared real value found maximum estimation error within plusmn 2 various temperature condition according test result suggested soc estimation algorithm basis variable temperature equivalent model good temperature adaptability high estimation accuracy copy 2023 author exclusive license springer nature singapore pte ltdbattery_management_systems equivalent_circuits kalman_filters lithium_compounds lithium ion_batteriescubature_kalman_filters equivalent_modeling ion_batteries life_safety lithium_titanate lithium_titanate_battery soc_estimations state of charge_estimation variable_temperature variable_temperature_equivalent_model
461,Research on Measuring Method of Ball Indentation Based on MATLAB Image Edge Detection,"Zhou, Y., Wang, X., Liu, Y., Wang, X., Li, Z., & Wang, Y. (2023). Research on Measuring Method of Ball Indentation Based on MATLAB Image Edge Detection. Smart Innovation, Systems and Technologies, 41–49. https://doi.org/10.1007/978-981-99-1230-8_4
",10.1007/978-981-99-1230-8_4,"Ball pressure test is an important test to evaluate the heat resistance of non-metallic materials. At present, most of the tests are judged by manual measurement, with low accuracy. In this paper, the digital image measurement technology of MATLAB is used to transform and enhance the collected indentation image. The Gaussian Laplace operator is used to detect the edge of the image, find the maximum value of the coordinate difference between each element point on the image edge and other element points, traverse all the element points on the image edge, and put the obtained maximum value into the maximum value array; continue to find the maximum value in the maximum value array to obtain the diameter of the ball pressure indentation image, thus improving the measurement accuracy and realizing the intelligent measurement of the diameter of the ball pressure detection image. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",other,Ball indentation;Ball pressure;Digital image measurement;Image edge;Image edge detection;Image measurements;Manual measurements;Measuring method;Non-metallic materials;Pressure tests,Edge detection;Image enhancement;Indentation,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Zhou, Yuan; (1) Wang, Xin; (1) Liu, Ya; (1) Wang, Xiaoyuan; (1) Li, Zheng; (1) Wang, Yanying; ","(1) Shandong Institute of Inspection On Product Quality, Jinan; 250102, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""edge detection"", ""image enhancement"", ""indentation""]","[""edge detection"", ""image enhancement"", ""indentation""]",edge detection;image enhancement;indentation,computer vision;other,technology;other,computer vision;other,technology;other,edge_detection image_enhancement indentation ball_indentation ball_pressure digital_image_measurement image_edge image_edge_detection image_measurements manual_measurements measuring_method non metallic_materials pressure_tests other computer_vision other,edge_detection image_enhancement indentation,ball_indentation ball_pressure digital_image_measurement image_edge image_edge_detection image_measurements manual_measurements measuring_method non metallic_materials pressure_tests,ball pressure test important test evaluate heat resistance non metallic material present test judged manual measurement low accuracy paper digital image measurement technology matlab used transform enhance collected indentation image gaussian laplace operator used detect edge image find maximum value coordinate difference element point image edge element point traverse element point image edge put obtained maximum value maximum value array continue find maximum value maximum value array obtain diameter ball pressure indentation image thus improving measurement accuracy realizing intelligent measurement diameter ball pressure detection image copy 2023 author exclusive license springer nature singapore pte ltd,edge_detection image_enhancement indentation ball_indentation ball_pressure digital_image_measurement image_edge image_edge_detection image_measurements manual_measurements measuring_method non metallic_materials pressure_tests other computer_vision other ball pressure test important test evaluate heat resistance non metallic material present test judged manual measurement low accuracy paper digital image measurement technology matlab used transform enhance collected indentation image gaussian laplace operator used detect edge image find maximum value coordinate difference element point image edge element point traverse element point image edge put obtained maximum value maximum value array continue find maximum value maximum value array obtain diameter ball pressure indentation image thus improving measurement accuracy realizing intelligent measurement diameter ball pressure detection image copy 2023 author exclusive license springer nature singapore pte ltd,ball pressure test important test evaluate heat resistance non metallic material present test judged manual measurement low accuracy paper digital image measurement technology matlab used transform enhance collected indentation image gaussian laplace operator used detect edge image find maximum value coordinate difference element point image edge element point traverse element point image edge put obtained maximum value maximum value array continue find maximum value maximum value array obtain diameter ball pressure indentation image thus improving measurement accuracy realizing intelligent measurement diameter ball pressure detection image copy 2023 author exclusive license springer nature singapore pte ltdedge_detection image_enhancement indentationball_indentation ball_pressure digital_image_measurement image_edge image_edge_detection image_measurements manual_measurements measuring_method non metallic_materials pressure_tests
462,Research on Mass Image Data Storage Method for Data Center,"Pan, S., Jiang, J., Qiu, H., Qiao, J., & Xu, M. (2023). Research on Mass Image Data Storage Method for Data Center. Smart Innovation, Systems and Technologies, 69–75. https://doi.org/10.1007/978-981-99-1230-8_6
",10.1007/978-981-99-1230-8_6,"With the advancement of technology and the development of the electric power business, power enterprises have generated a large amount of image data, which contains rich potential information, and it is urgent to store massive-scale image data for further mining and analysis. Starting from the storage requirements of power grid image data, this paper expounds on the drawbacks of direct storage of small files according to the characteristics of power grid image files. Then, the architecture design and function design of the grid image small file storage are carried out, and the function implementation is carried out. Finally, the grid image small file storage method based on the SequenceFile file format is briefly summarized. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","722.1 Data Storage, Equipment and Techniques",Data storage;Datacenter;Electric power business;Grid image data;Image data;Mass storage;Power grids;Sequencefile;Small file storages;Small files,other,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Pan, Sen; (1) Jiang, Jing; (1) Qiu, Hongbin; (1) Qiao, Junfeng; (3) Xu, Menghan; ","(1) State Grid Smart Grid Research Institute Co. Ltd. Nanjing, Jiangsu; 210003, China; (2) State Grid Key Laboratory of Information and Network Security, Nanjing; 210003, China; (3) State Grid Jiangsu Electric Power Co. Ltd. Information and Telecommunication Branch, Nanjing, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""other""]","[""other""]",other,other,other,other,other,other data_storage datacenter electric_power_business grid_image_data image_data mass_storage power_grids sequencefile small_file_storages small_files 722 1_data_storage _equipment_and_techniques other,other,data_storage datacenter electric_power_business grid_image_data image_data mass_storage power_grids sequencefile small_file_storages small_files,advancement technology development electric power business power enterprise generated large amount image data contains rich potential information urgent store massive scale image data mining analysis starting storage requirement power grid image data paper expounds drawback direct storage small file according characteristic power grid image file architecture design function design grid image small file storage carried function implementation carried finally grid image small file storage method based sequencefile file format briefly summarized copy 2023 author exclusive license springer nature singapore pte ltd,other data_storage datacenter electric_power_business grid_image_data image_data mass_storage power_grids sequencefile small_file_storages small_files 722 1_data_storage _equipment_and_techniques other advancement technology development electric power business power enterprise generated large amount image data contains rich potential information urgent store massive scale image data mining analysis starting storage requirement power grid image data paper expounds drawback direct storage small file according characteristic power grid image file architecture design function design grid image small file storage carried function implementation carried finally grid image small file storage method based sequencefile file format briefly summarized copy 2023 author exclusive license springer nature singapore pte ltd,advancement technology development electric power business power enterprise generated large amount image data contains rich potential information urgent store massive scale image data mining analysis starting storage requirement power grid image data paper expounds drawback direct storage small file according characteristic power grid image file architecture design function design grid image small file storage carried function implementation carried finally grid image small file storage method based sequencefile file format briefly summarized copy 2023 author exclusive license springer nature singapore pte ltdotherdata_storage datacenter electric_power_business grid_image_data image_data mass_storage power_grids sequencefile small_file_storages small_files
463,Soft Tissue Cutting Based on Position Dynamics,"Wang, Z., & Yu, H. (2023). Soft Tissue Cutting Based on Position Dynamics. Smart Innovation, Systems and Technologies, 193–201. https://doi.org/10.1007/978-981-99-1230-8_17
",10.1007/978-981-99-1230-8_17,"In order to fit the development wave of virtual medical surgery, a soft tissue cutting model based on position dynamics is proposed. The particle-constrained tetrahedron is used to reconstruct the soft tissue part of the human body, and the facility and real-time operation is met through a visual interactive platform and force feedback calculation. The user can control the surgical instrument to reach the organ lesion area through the manipulation force feedback stroke area, and can also adjust the optimal position and posture of the instrument. Through experimental simulation, it is fully demonstrated that the model has good stability under increasing time steps, and at the same time, the higher computational efficiency is highlighted by expressing the applied force in the form of constraints, which can meet the high standards of human&ndash;computer interaction. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","461.2 Biological Materials and Tissue Engineering;461.6 Medicine and Pharmacology;462.1 Biomedical Equipment, General;723 Computer Software, Data Handling and Applications;731.1 Control Systems;921 Mathematics",Cutting model;Force feedback calculation;Force-feedback;Model-based OPC;Particle constraint;Position based dynamic;Soft tissue;Tetrahedra;Tetrahedron reconstruction;Tissue cutting,Feedback;Geometry;Human computer interaction;Surgery;Surgical equipment;Tissue;Virtual reality,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Wang, Zijun; (1) Yu, Hongfei; ","(1) Yunnan Key Laboratory of Optoelectronic Information, Technology, Yunnan, Kunming, China; (2) Yunnan Normal University, Yunnan, Kunming; 650092, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""feedback"", ""geometry"", ""human computer interaction"", ""surgery"", ""surgical equipment"", ""tissue""]","[""feedback"", ""geometry"", ""human computer interaction"", ""surgery"", ""surgical equipment"", ""tissue""]",feedback;geometry;human computer interaction;surgery;surgical equipment;tissue,medical;graphics;human-computer interaction,technology;industries;end users and user experience,medical;graphics;human-computer interaction,technology;industries;end users and user experience,feedback geometry human_computer_interaction surgery surgical_equipment tissue cutting_model force_feedback_calculation force feedback model based_opc particle_constraint position_based_dynamic soft_tissue tetrahedra tetrahedron_reconstruction tissue_cutting 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 1_biomedical_equipment _general 723_computer_software _data_handling_and_applications 731 1_control_systems 921_mathematics medical graphics human computer_interaction,feedback geometry human_computer_interaction surgery surgical_equipment tissue,cutting_model force_feedback_calculation force feedback model based_opc particle_constraint position_based_dynamic soft_tissue tetrahedra tetrahedron_reconstruction tissue_cutting,order fit development wave virtual medical surgery soft tissue cutting model based position dynamic proposed particle constrained tetrahedron used reconstruct soft tissue part human body facility real time operation met visual interactive platform force feedback calculation user control surgical instrument reach organ lesion area manipulation force feedback stroke area also adjust optimal position posture instrument experimental simulation fully demonstrated model good stability increasing time step time higher computational efficiency highlighted expressing applied force form constraint meet high standard human ndash computer interaction copy 2023 author exclusive license springer nature singapore pte ltd,feedback geometry human_computer_interaction surgery surgical_equipment tissue cutting_model force_feedback_calculation force feedback model based_opc particle_constraint position_based_dynamic soft_tissue tetrahedra tetrahedron_reconstruction tissue_cutting 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 1_biomedical_equipment _general 723_computer_software _data_handling_and_applications 731 1_control_systems 921_mathematics medical graphics human computer_interaction order fit development wave virtual medical surgery soft tissue cutting model based position dynamic proposed particle constrained tetrahedron used reconstruct soft tissue part human body facility real time operation met visual interactive platform force feedback calculation user control surgical instrument reach organ lesion area manipulation force feedback stroke area also adjust optimal position posture instrument experimental simulation fully demonstrated model good stability increasing time step time higher computational efficiency highlighted expressing applied force form constraint meet high standard human ndash computer interaction copy 2023 author exclusive license springer nature singapore pte ltd,order fit development wave virtual medical surgery soft tissue cutting model based position dynamic proposed particle constrained tetrahedron used reconstruct soft tissue part human body facility real time operation met visual interactive platform force feedback calculation user control surgical instrument reach organ lesion area manipulation force feedback stroke area also adjust optimal position posture instrument experimental simulation fully demonstrated model good stability increasing time step time higher computational efficiency highlighted expressing applied force form constraint meet high standard human ndash computer interaction copy 2023 author exclusive license springer nature singapore pte ltdfeedback geometry human_computer_interaction surgery surgical_equipment tissuecutting_model force_feedback_calculation force feedback model based_opc particle_constraint position_based_dynamic soft_tissue tetrahedra tetrahedron_reconstruction tissue_cutting
464,Algorithms Applied in Soft Tissue Deformation Simulation: A Survey,"Cai, X., & Yu, H. (2023). Algorithms Applied in Soft Tissue Deformation Simulation: A Survey. Smart Innovation, Systems and Technologies, 181–192. https://doi.org/10.1007/978-981-99-1230-8_16
",10.1007/978-981-99-1230-8_16,"In modern medical science, Minimally Invasive Surgery (MIS) is one of the most direct and effective ways to treat the malignant lesions. The training of MIS is now not only limited to the actual surgical anatomy but also start to have a growing tendency to the VR technology which is depended on computer graphics and haptic rendering. As well as the surgery equipment simulation and graphics rendering, the Soft Tissue Deformation (STD) simulation is another critical technique in MIS simulation of VR. Therefore, we have collected lots of STD algorithms from 1986&ndash;2022, especially, the haptic feedback algorithms for STD, which can be divided into two categories. The first one is algorithms based on image distortion and the another one is based on the physical properties simulating. After classification of the two categories, we make a comparison among the algorithms proposed above, such as efficiency, accuracy, complexity and rendering speed. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","461.2 Biological Materials and Tissue Engineering;461.6 Medicine and Pharmacology;462.1 Biomedical Equipment, General;723.2 Data Processing and Image Processing;723.5 Computer Applications",Deformation simulation;Feedback algorithms;Haptic feedback algorithm;Haptic feedbacks;Medical science;Minimally invasive surgery simulation;Minimally-invasive surgery;Soft tissue deformation;Soft tissue deformation algorithm;Surgery simulations,Rendering (computer graphics);Surgery;Surgical equipment,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Cai, Xiaoyu; (1) Yu, Hongfei; ","(1) Yunnan Key Lab of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""rendering"", ""surgery"", ""surgical equipment""]","[""rendering"", ""surgery"", ""surgical equipment""]",rendering;surgery;surgical equipment,medical;graphics,technology;industries,medical;graphics,technology;industries,rendering surgery surgical_equipment deformation_simulation feedback_algorithms haptic_feedback_algorithm haptic_feedbacks medical_science minimally_invasive_surgery_simulation minimally invasive_surgery soft_tissue_deformation soft_tissue_deformation_algorithm surgery_simulations 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 1_biomedical_equipment _general 723 2_data_processing_and_image_processing 723 5_computer_applications medical graphics,rendering surgery surgical_equipment,deformation_simulation feedback_algorithms haptic_feedback_algorithm haptic_feedbacks medical_science minimally_invasive_surgery_simulation minimally invasive_surgery soft_tissue_deformation soft_tissue_deformation_algorithm surgery_simulations,modern medical science minimally invasive surgery mi one direct effective way treat malignant lesion training mi limited actual surgical anatomy also start growing tendency vr technology depended computer graphic haptic rendering well surgery equipment simulation graphic rendering soft tissue deformation std simulation another critical technique mi simulation vr therefore collected lot std algorithm 1986 ndash 2022 especially haptic feedback algorithm std divided two category first one algorithm based image distortion another one based physical property simulating classification two category make comparison among algorithm proposed efficiency accuracy complexity rendering speed copy 2023 author exclusive license springer nature singapore pte ltd,rendering surgery surgical_equipment deformation_simulation feedback_algorithms haptic_feedback_algorithm haptic_feedbacks medical_science minimally_invasive_surgery_simulation minimally invasive_surgery soft_tissue_deformation soft_tissue_deformation_algorithm surgery_simulations 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 1_biomedical_equipment _general 723 2_data_processing_and_image_processing 723 5_computer_applications medical graphics modern medical science minimally invasive surgery mi one direct effective way treat malignant lesion training mi limited actual surgical anatomy also start growing tendency vr technology depended computer graphic haptic rendering well surgery equipment simulation graphic rendering soft tissue deformation std simulation another critical technique mi simulation vr therefore collected lot std algorithm 1986 ndash 2022 especially haptic feedback algorithm std divided two category first one algorithm based image distortion another one based physical property simulating classification two category make comparison among algorithm proposed efficiency accuracy complexity rendering speed copy 2023 author exclusive license springer nature singapore pte ltd,modern medical science minimally invasive surgery mi one direct effective way treat malignant lesion training mi limited actual surgical anatomy also start growing tendency vr technology depended computer graphic haptic rendering well surgery equipment simulation graphic rendering soft tissue deformation std simulation another critical technique mi simulation vr therefore collected lot std algorithm 1986 ndash 2022 especially haptic feedback algorithm std divided two category first one algorithm based image distortion another one based physical property simulating classification two category make comparison among algorithm proposed efficiency accuracy complexity rendering speed copy 2023 author exclusive license springer nature singapore pte ltdrendering surgery surgical_equipmentdeformation_simulation feedback_algorithms haptic_feedback_algorithm haptic_feedbacks medical_science minimally_invasive_surgery_simulation minimally invasive_surgery soft_tissue_deformation soft_tissue_deformation_algorithm surgery_simulations
465,Control Strategies for Gait Tele-Rehabilitation System Based on Parallel Robotics,"Bo, A. P. L., Casas, L., Cucho-Padin, G., Hayashibe, M., & Elias, D. (2021). Control Strategies for Gait Tele-Rehabilitation System Based on Parallel Robotics. Applied Sciences, 11(23), 11095. https://doi.org/10.3390/app112311095
",10.3390/app112311095,"Among end-effector robots for lower limb rehabilitation, systems based on Stewart-Gough platforms enable independent movement of each foot in six degrees of freedom. Nevertheless, control strategies described in recent literature have not been able to fully explore the potential of such a mechatronic system. In this work, we propose two novel approaches for controlling a gait simulator based on Stewart-Gough platforms. The first strategy provides the therapist direct control of each platform using movement data measured by wearable sensors. The following scheme is designed to improve the level of engagement of the patient by enabling a limited degree of control based on trunk inclination. Both strategies are designed to facilitate future studies in tele-rehabilitation settings. Experimental results have illustrated the feasibility of both control interfaces, either in terms of system performance or user subjective evaluation. Technical capacity to deploy in tele-rehabilitation was also verified in this work.",C3390M Manipulators;C3385 Biological and medical control systems;C7330 Biology and medical computing;E2230 Robot and manipulator mechanics,control interfaces;control strategies;degrees of freedom;end-effector robots;gait simulator;gait tele-rehabilitation system;independent movement;lower limb rehabilitation;mechatronic system;movement data;parallel robotics;Stewart-Gough platforms;system performance;tele-rehabilitation settings;therapist direct control,end effectors;mechatronics;medical robotics;patient rehabilitation,2021,Journal article (JA),Appl. Sci. (Switzerland),"(1) Bo, A.P.L.; (2) Casas, L.; (3) Cucho-Padin, G.; (5) Hayashibe, M.; (6) Elias, D.; ","(1) University of Brasilia, Electrical Engineering Department, Brazil; (2) Technische Universita&#776;t Mu&#776;nchen, Department of Computer Aided Medical Procedures and Augmented Reality, Germany; (3) Catholic University of America, Department of Physics, Washington, DC 20064, United States; (4) NASA Goddard Space Flight Center, Greenbelt, MD 20771, United States; (5) French Institute for Research in Computer Science and Automation, France; (6) Pontificia Universidad Cato&#769;lica del Peru&#769;, Mechanical Engineering Department, Peru; ",MDPI,-1,"[""end effectors"", ""mechatronics"", ""medical robotics"", ""patient rehabilitation""]","[""end effectors"", ""mechatronics"", ""medical robotics"", ""patient rehabilitation""]",end effectors;mechatronics;medical robotics;patient rehabilitation,medical;internet of things;robotics,technology;industries,medical;internet of things;robotics,technology;industries,end_effectors mechatronics medical_robotics patient_rehabilitation control_interfaces control_strategies degrees_of_freedom end effector_robots gait_simulator gait_tele rehabilitation_system independent_movement lower_limb_rehabilitation mechatronic_system movement_data parallel_robotics stewart gough_platforms system_performance tele rehabilitation_settings therapist_direct_control c3390m_manipulators c3385_biological_and_medical_control_systems c7330_biology_and_medical_computing e2230_robot_and_manipulator_mechanics medical internet_of_things robotics,end_effectors mechatronics medical_robotics patient_rehabilitation,control_interfaces control_strategies degrees_of_freedom end effector_robots gait_simulator gait_tele rehabilitation_system independent_movement lower_limb_rehabilitation mechatronic_system movement_data parallel_robotics stewart gough_platforms system_performance tele rehabilitation_settings therapist_direct_control,among end effector robot lower limb rehabilitation system based stewart gough platform enable independent movement foot six degree freedom nevertheless control strategy described recent literature able fully explore potential mechatronic system work propose two novel approach controlling gait simulator based stewart gough platform first strategy provides therapist direct control platform using movement data measured wearable sensor following scheme designed improve level engagement patient enabling limited degree control based trunk inclination strategy designed facilitate future study tele rehabilitation setting experimental result illustrated feasibility control interface either term system performance user subjective evaluation technical capacity deploy tele rehabilitation also verified work,end_effectors mechatronics medical_robotics patient_rehabilitation control_interfaces control_strategies degrees_of_freedom end effector_robots gait_simulator gait_tele rehabilitation_system independent_movement lower_limb_rehabilitation mechatronic_system movement_data parallel_robotics stewart gough_platforms system_performance tele rehabilitation_settings therapist_direct_control c3390m_manipulators c3385_biological_and_medical_control_systems c7330_biology_and_medical_computing e2230_robot_and_manipulator_mechanics medical internet_of_things robotics among end effector robot lower limb rehabilitation system based stewart gough platform enable independent movement foot six degree freedom nevertheless control strategy described recent literature able fully explore potential mechatronic system work propose two novel approach controlling gait simulator based stewart gough platform first strategy provides therapist direct control platform using movement data measured wearable sensor following scheme designed improve level engagement patient enabling limited degree control based trunk inclination strategy designed facilitate future study tele rehabilitation setting experimental result illustrated feasibility control interface either term system performance user subjective evaluation technical capacity deploy tele rehabilitation also verified work,among end effector robot lower limb rehabilitation system based stewart gough platform enable independent movement foot six degree freedom nevertheless control strategy described recent literature able fully explore potential mechatronic system work propose two novel approach controlling gait simulator based stewart gough platform first strategy provides therapist direct control platform using movement data measured wearable sensor following scheme designed improve level engagement patient enabling limited degree control based trunk inclination strategy designed facilitate future study tele rehabilitation setting experimental result illustrated feasibility control interface either term system performance user subjective evaluation technical capacity deploy tele rehabilitation also verified workend_effectors mechatronics medical_robotics patient_rehabilitationcontrol_interfaces control_strategies degrees_of_freedom end effector_robots gait_simulator gait_tele rehabilitation_system independent_movement lower_limb_rehabilitation mechatronic_system movement_data parallel_robotics stewart gough_platforms system_performance tele rehabilitation_settings therapist_direct_control
466,Identification of Expressway Traffic States Based on the Enhanced FCM Algorithm,"Yang, Z., Hao, L., Liu, Y., & Cai, L. (2023). Identification of Expressway Traffic States Based on the Enhanced FCM Algorithm. Smart Innovation, Systems and Technologies, 167–179. https://doi.org/10.1007/978-981-99-1230-8_15
",10.1007/978-981-99-1230-8_15,"In order to enhance the accuracy and effectiveness of traffic state identification, a fuzzy C-means algorithm based on simulated annealing genetic algorithm (SAGA-FCM) was proposed. First, according to the characteristics of expressway traffic, traffic states were divided into five states based on the Van Aerde model. Second, there are characteristics of fuzziness in expressway traffic. Flow, speed and density were taken as characteristic attributes of sample data. This paper proposed an enhanced fuzzy C-means clustering method SAGA-FCM for the identification of traffic states. It overcomes the problem that the traditional FCM algorithm is sensitive to the initial clustering center and easy to fall into the local optimum. Finally, the M25 motorway was used as an example to evaluate traffic conditions. The results were consistent with measured traffic conditions, which verified the effectiveness of the method. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","537.1 Heat Treatment Processes;723 Computer Software, Data Handling and Applications;745.2 Reproduction, Copying;903.1 Information Sources and Analysis",Expressway;FCM algorithm;Fuzzy C-mean algorithm;Macroscopic fundamental diagram;Simulated annealing genetic algorithms (SAGA);State based;Traffic conditions;Traffic Engineering;Traffic state;Traffic state identifications,Copying;Fuzzy clustering;Genetic algorithms;Highway engineering;Simulated annealing,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Yang, Zhuocheng; (1) Hao, Liang; (1) Liu, Yuchen; (1) Cai, Lei; ","(1) Beijing GOTEC ITS Technology Co., Ltd., Beijing; 100088, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""copying"", ""fuzzy clustering"", ""genetic algorithms"", ""highway engineering"", ""simulated annealing""]","[""copying"", ""fuzzy clustering"", ""genetic algorithms"", ""highway engineering"", ""simulated annealing""]",copying;fuzzy clustering;genetic algorithms;highway engineering;simulated annealing,other;artificial intelligence,technology;other,other;artificial intelligence,technology;other,copying fuzzy_clustering genetic_algorithms highway_engineering simulated_annealing expressway fcm_algorithm fuzzy_c mean_algorithm macroscopic_fundamental_diagram simulated_annealing_genetic_algorithms_ saga state_based traffic_conditions traffic_engineering traffic_state traffic_state_identifications 537 1_heat_treatment_processes 723_computer_software _data_handling_and_applications 745 2_reproduction _copying 903 1_information_sources_and_analysis other artificial_intelligence,copying fuzzy_clustering genetic_algorithms highway_engineering simulated_annealing,expressway fcm_algorithm fuzzy_c mean_algorithm macroscopic_fundamental_diagram simulated_annealing_genetic_algorithms_ saga state_based traffic_conditions traffic_engineering traffic_state traffic_state_identifications,order enhance accuracy effectiveness traffic state identification fuzzy c mean algorithm based simulated annealing genetic algorithm saga fcm proposed first according characteristic expressway traffic traffic state divided five state based van aerde model second characteristic fuzziness expressway traffic flow speed density taken characteristic attribute sample data paper proposed enhanced fuzzy c mean clustering method saga fcm identification traffic state overcomes problem traditional fcm algorithm sensitive initial clustering center easy fall local optimum finally m25 motorway used example evaluate traffic condition result consistent measured traffic condition verified effectiveness method copy 2023 author exclusive license springer nature singapore pte ltd,copying fuzzy_clustering genetic_algorithms highway_engineering simulated_annealing expressway fcm_algorithm fuzzy_c mean_algorithm macroscopic_fundamental_diagram simulated_annealing_genetic_algorithms_ saga state_based traffic_conditions traffic_engineering traffic_state traffic_state_identifications 537 1_heat_treatment_processes 723_computer_software _data_handling_and_applications 745 2_reproduction _copying 903 1_information_sources_and_analysis other artificial_intelligence order enhance accuracy effectiveness traffic state identification fuzzy c mean algorithm based simulated annealing genetic algorithm saga fcm proposed first according characteristic expressway traffic traffic state divided five state based van aerde model second characteristic fuzziness expressway traffic flow speed density taken characteristic attribute sample data paper proposed enhanced fuzzy c mean clustering method saga fcm identification traffic state overcomes problem traditional fcm algorithm sensitive initial clustering center easy fall local optimum finally m25 motorway used example evaluate traffic condition result consistent measured traffic condition verified effectiveness method copy 2023 author exclusive license springer nature singapore pte ltd,order enhance accuracy effectiveness traffic state identification fuzzy c mean algorithm based simulated annealing genetic algorithm saga fcm proposed first according characteristic expressway traffic traffic state divided five state based van aerde model second characteristic fuzziness expressway traffic flow speed density taken characteristic attribute sample data paper proposed enhanced fuzzy c mean clustering method saga fcm identification traffic state overcomes problem traditional fcm algorithm sensitive initial clustering center easy fall local optimum finally m25 motorway used example evaluate traffic condition result consistent measured traffic condition verified effectiveness method copy 2023 author exclusive license springer nature singapore pte ltdcopying fuzzy_clustering genetic_algorithms highway_engineering simulated_annealingexpressway fcm_algorithm fuzzy_c mean_algorithm macroscopic_fundamental_diagram simulated_annealing_genetic_algorithms_ saga state_based traffic_conditions traffic_engineering traffic_state traffic_state_identifications
467,Research on Application Technology of Multi-source Fusion of 3D Digital Resources in Power Grid,"Yu, H., He, Z., Peng, L., Shen, J., & Qian, K. (2023). Research on Application Technology of Multi-source Fusion of 3D Digital Resources in Power Grid. Smart Innovation, Systems and Technologies, 203–211. https://doi.org/10.1007/978-981-99-1230-8_18
",10.1007/978-981-99-1230-8_18,"In view of the technical requirements of 3D model resource fusion in power grid infrastructure and operation and inspection, this paper studies the spatial transformation of multi-media heterogeneous models, pose registration, and comprehensive reconstruction algorithms and analyzes the multi-source 3D digital resource fusion analysis of variable time and space technology. A fusion registration analysis method of 3D digital resources oriented to multi-medium and changeable space&ndash;time is proposed, forming a management scheme for updating 3D digital models of infrastructure and operation inspection. Relevant achievements support the integration analysis and interaction of 3D digital resources and provide a technical basis for the fusion application of multi-source and polymorphic 3D models. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",723.2 Data Processing and Image Processing;723.5 Computer Applications,3d digital resource integration;3D models;3d-modeling;Comprehensive reconstruction;Digital resources;Multi-Media;Multi-Sources;Pose registration;Power grids;Resources integrations,3D modeling;Image reconstruction,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Yu, Hai; (2) He, Zhimin; (2) Peng, Lin; (3) Shen, Jian; (1) Qian, Kun; ","(1) School of Automation, Southeast University, Jiangsu, Nanjing; 210096, China; (2) Power Grid Digitization Technology Research Institute, State Grid Smart Grid Research Institute, Jiangsu, Nanjing; 210003, China; (3) Electric Power Research Institute, State Grid Henan Electric Power Company, Henan, Zhengzhou; 450052, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""3d modeling"", ""image reconstruction""]","[""3d modeling"", ""image reconstruction""]",3d modeling;image reconstruction,construction;computer vision;manufacturing,technology;industries,construction;computer vision;manufacturing,technology;industries,3d_modeling image_reconstruction 3d_digital_resource_integration 3d_models 3d modeling comprehensive_reconstruction digital_resources multi media multi sources pose_registration power_grids resources_integrations 723 2_data_processing_and_image_processing 723 5_computer_applications construction computer_vision manufacturing,3d_modeling image_reconstruction,3d_digital_resource_integration 3d_models 3d modeling comprehensive_reconstruction digital_resources multi media multi sources pose_registration power_grids resources_integrations,view technical requirement 3d model resource fusion power grid infrastructure operation inspection paper study spatial transformation multi medium heterogeneous model pose registration comprehensive reconstruction algorithm analyzes multi source 3d digital resource fusion analysis variable time space technology fusion registration analysis method 3d digital resource oriented multi medium changeable space ndash time proposed forming management scheme updating 3d digital model infrastructure operation inspection relevant achievement support integration analysis interaction 3d digital resource provide technical basis fusion application multi source polymorphic 3d model copy 2023 author exclusive license springer nature singapore pte ltd,3d_modeling image_reconstruction 3d_digital_resource_integration 3d_models 3d modeling comprehensive_reconstruction digital_resources multi media multi sources pose_registration power_grids resources_integrations 723 2_data_processing_and_image_processing 723 5_computer_applications construction computer_vision manufacturing view technical requirement 3d model resource fusion power grid infrastructure operation inspection paper study spatial transformation multi medium heterogeneous model pose registration comprehensive reconstruction algorithm analyzes multi source 3d digital resource fusion analysis variable time space technology fusion registration analysis method 3d digital resource oriented multi medium changeable space ndash time proposed forming management scheme updating 3d digital model infrastructure operation inspection relevant achievement support integration analysis interaction 3d digital resource provide technical basis fusion application multi source polymorphic 3d model copy 2023 author exclusive license springer nature singapore pte ltd,view technical requirement 3d model resource fusion power grid infrastructure operation inspection paper study spatial transformation multi medium heterogeneous model pose registration comprehensive reconstruction algorithm analyzes multi source 3d digital resource fusion analysis variable time space technology fusion registration analysis method 3d digital resource oriented multi medium changeable space ndash time proposed forming management scheme updating 3d digital model infrastructure operation inspection relevant achievement support integration analysis interaction 3d digital resource provide technical basis fusion application multi source polymorphic 3d model copy 2023 author exclusive license springer nature singapore pte ltd3d_modeling image_reconstruction3d_digital_resource_integration 3d_models 3d modeling comprehensive_reconstruction digital_resources multi media multi sources pose_registration power_grids resources_integrations
468,A Knowledge Representation Method for Hierarchical Diagnosis Decision-Making Under Uncertain Conditions,"Ge, Y., Hou, X., Meng, Z., & Lu, Y. (2023). A Knowledge Representation Method for Hierarchical Diagnosis Decision-Making Under Uncertain Conditions. Smart Innovation, Systems and Technologies, 11–29. https://doi.org/10.1007/978-981-99-1230-8_2
",10.1007/978-981-99-1230-8_2,"In order to effectively solve the problems existing in hierarchical diagnosis decision-making knowledge representation under uncertain conditions, the paper lists several key characteristics of complex systems diagnosis decision-making knowledge, combines with hierarchical diagnosis decision-making knowledge classification, makes ontology modeling of related diagnosis decision-making knowledge based on ontology theory, and constructs the semantic hierarchical analysis and its relationship between global ontology and each core domain ontology. In this way, the paper realizes semantic hierarchical analysis and knowledge association. Through the case study of a certain modular aircraft support system, the knowledge representation of diagnosis decision-making under uncertain conditions is realized. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",461.1 Biomedical Engineering;716.1 Information Theory and Signal Processing;723.4 Artificial Intelligence;723.5 Computer Applications;903.1 Information Sources and Analysis;912.2 Management;961 Systems Science,Decisions makings;Diagnosis decision;Hierarchical analysis;Hierarchical diagnose decision-making knowledge;Hierarchical diagnosis;Knowledge representation method;Knowledge-representation;Ontology's;Representation;Uncertain condition,Classification (of information);Computer aided diagnosis;Decision theory;Hierarchical systems;Knowledge representation;Ontology;Semantics,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Ge, Yawei; (2) Hou, Xiqian; (1) Meng, Zhuxuan; (1) Lu, Yue; ","(1) Strategic Assessments and Consultation Institute, Academy of Military Sciences, Beijing; 100091, China; (2) Air Force Command College, Beijing; 100097, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""information classification"", ""computer aided diagnosis"", ""decision theory"", ""hierarchical systems"", ""knowledge representation"", ""ontology"", ""semantics""]","[""information classification"", ""computer aided diagnosis"", ""decision theory"", ""hierarchical systems"", ""knowledge representation"", ""ontology"", ""semantics""]",information classification;computer aided diagnosis;decision theory;hierarchical systems;knowledge representation;ontology;semantics,education;other;medical;data;web services;artificial intelligence,technology;other;industries,education;other;medical;data;web services;artificial intelligence,technology;other;industries,information_classification computer_aided_diagnosis decision_theory hierarchical_systems knowledge_representation ontology semantics decisions_makings diagnosis_decision hierarchical_analysis hierarchical_diagnose_decision making_knowledge hierarchical_diagnosis knowledge_representation_method knowledge representation ontology s representation uncertain_condition 461 1_biomedical_engineering 716 1_information_theory_and_signal_processing 723 4_artificial_intelligence 723 5_computer_applications 903 1_information_sources_and_analysis 912 2_management 961_systems_science education other medical data web_services artificial_intelligence,information_classification computer_aided_diagnosis decision_theory hierarchical_systems knowledge_representation ontology semantics,decisions_makings diagnosis_decision hierarchical_analysis hierarchical_diagnose_decision making_knowledge hierarchical_diagnosis knowledge_representation_method knowledge representation ontology s representation uncertain_condition,order effectively solve problem existing hierarchical diagnosis decision making knowledge representation uncertain condition paper list several key characteristic complex system diagnosis decision making knowledge combine hierarchical diagnosis decision making knowledge classification make ontology modeling related diagnosis decision making knowledge based ontology theory construct semantic hierarchical analysis relationship global ontology core domain ontology way paper realizes semantic hierarchical analysis knowledge association case study certain modular aircraft support system knowledge representation diagnosis decision making uncertain condition realized copy 2023 author exclusive license springer nature singapore pte ltd,information_classification computer_aided_diagnosis decision_theory hierarchical_systems knowledge_representation ontology semantics decisions_makings diagnosis_decision hierarchical_analysis hierarchical_diagnose_decision making_knowledge hierarchical_diagnosis knowledge_representation_method knowledge representation ontology s representation uncertain_condition 461 1_biomedical_engineering 716 1_information_theory_and_signal_processing 723 4_artificial_intelligence 723 5_computer_applications 903 1_information_sources_and_analysis 912 2_management 961_systems_science education other medical data web_services artificial_intelligence order effectively solve problem existing hierarchical diagnosis decision making knowledge representation uncertain condition paper list several key characteristic complex system diagnosis decision making knowledge combine hierarchical diagnosis decision making knowledge classification make ontology modeling related diagnosis decision making knowledge based ontology theory construct semantic hierarchical analysis relationship global ontology core domain ontology way paper realizes semantic hierarchical analysis knowledge association case study certain modular aircraft support system knowledge representation diagnosis decision making uncertain condition realized copy 2023 author exclusive license springer nature singapore pte ltd,order effectively solve problem existing hierarchical diagnosis decision making knowledge representation uncertain condition paper list several key characteristic complex system diagnosis decision making knowledge combine hierarchical diagnosis decision making knowledge classification make ontology modeling related diagnosis decision making knowledge based ontology theory construct semantic hierarchical analysis relationship global ontology core domain ontology way paper realizes semantic hierarchical analysis knowledge association case study certain modular aircraft support system knowledge representation diagnosis decision making uncertain condition realized copy 2023 author exclusive license springer nature singapore pte ltdinformation_classification computer_aided_diagnosis decision_theory hierarchical_systems knowledge_representation ontology semanticsdecisions_makings diagnosis_decision hierarchical_analysis hierarchical_diagnose_decision making_knowledge hierarchical_diagnosis knowledge_representation_method knowledge representation ontology s representation uncertain_condition
469,Scheme Design of Network Neighbor Discovery Algorithm Based on the Combination of Directional Antenna and Multi-channel Parallelism,"Zhao, N., Gao, F., & Pu, K. (2023). Scheme Design of Network Neighbor Discovery Algorithm Based on the Combination of Directional Antenna and Multi-channel Parallelism. Smart Innovation, Systems and Technologies, 99–107. https://doi.org/10.1007/978-981-99-1230-8_9
",10.1007/978-981-99-1230-8_9,"The existing deign has the dynamic blind zone with high energy efficiency, which is lower the quality of connection in the place like airport. The asynchronous, heterogeneous, and multi-channel fusion mobile Ad-Hoc network with multi-channel and multi-interface is an inevitable choice to further improve the communication bandwidth and communication quality. The key problem is to study and design a fast neighbor discovery strategy that integrates ""directional antenna and multi-channel parallel"" in the case of limited energy. This paper proposed a neighbor discovery algorithm combining directional antenna and multi-channel parallelism. In more details, our framework uses multi-channel and multi-interface asynchronous, heterogeneous, and multi-channel fusion mobile Ad Hoc network, and this optimized algorithm enables fast neighbor discovery in energy-constrained situations. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","525.2 Energy Conservation;722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;961 Systems Science",Ad-hoc networks;Antenna channel;Asynchronous channels;Directional Antenna;Discovery algorithm;Heterogeneous channels;Multi channel;Multi-channel parallelism;Neighbor discovery;Network neighbor discovery algorithm,Constrained optimization;Directive antennas;Energy efficiency,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Zhao, Na; (1) Gao, Fei; (3) Pu, Kaijie; ","(1) Beijing Polytechnic, Beijing, China; (2) Assumption University, Bangkok, Thailand; (3) China Power Complete Equipment Co. Ltd., Beijing, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""constrained optimization"", ""directive antennas"", ""energy efficiency""]","[""constrained optimization"", ""directive antennas"", ""energy efficiency""]",constrained optimization;directive antennas;energy efficiency,computer vision;farming and natural science;other;power and energy;business performance metrics;telecommunication;human-computer interaction,other;business;end users and user experience;industries;technology,computer vision;farming and natural science;other;power and energy;business performance metrics;telecommunication;human-computer interaction,other;business;end users and user experience;industries;technology,constrained_optimization directive_antennas energy_efficiency ad hoc_networks antenna_channel asynchronous_channels directional_antenna discovery_algorithm heterogeneous_channels multi_channel multi channel_parallelism neighbor_discovery network_neighbor_discovery_algorithm 525 2_energy_conservation 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 961_systems_science computer_vision farming_and_natural_science other power_and_energy business_performance_metrics telecommunication human computer_interaction,constrained_optimization directive_antennas energy_efficiency,ad hoc_networks antenna_channel asynchronous_channels directional_antenna discovery_algorithm heterogeneous_channels multi_channel multi channel_parallelism neighbor_discovery network_neighbor_discovery_algorithm,existing deign dynamic blind zone high energy efficiency lower quality connection place like airport asynchronous heterogeneous multi channel fusion mobile ad hoc network multi channel multi interface inevitable choice improve communication bandwidth communication quality key problem study design fast neighbor discovery strategy integrates directional antenna multi channel parallel case limited energy paper proposed neighbor discovery algorithm combining directional antenna multi channel parallelism detail framework us multi channel multi interface asynchronous heterogeneous multi channel fusion mobile ad hoc network optimized algorithm enables fast neighbor discovery energy constrained situation copy 2023 author exclusive license springer nature singapore pte ltd,constrained_optimization directive_antennas energy_efficiency ad hoc_networks antenna_channel asynchronous_channels directional_antenna discovery_algorithm heterogeneous_channels multi_channel multi channel_parallelism neighbor_discovery network_neighbor_discovery_algorithm 525 2_energy_conservation 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 961_systems_science computer_vision farming_and_natural_science other power_and_energy business_performance_metrics telecommunication human computer_interaction existing deign dynamic blind zone high energy efficiency lower quality connection place like airport asynchronous heterogeneous multi channel fusion mobile ad hoc network multi channel multi interface inevitable choice improve communication bandwidth communication quality key problem study design fast neighbor discovery strategy integrates directional antenna multi channel parallel case limited energy paper proposed neighbor discovery algorithm combining directional antenna multi channel parallelism detail framework us multi channel multi interface asynchronous heterogeneous multi channel fusion mobile ad hoc network optimized algorithm enables fast neighbor discovery energy constrained situation copy 2023 author exclusive license springer nature singapore pte ltd,existing deign dynamic blind zone high energy efficiency lower quality connection place like airport asynchronous heterogeneous multi channel fusion mobile ad hoc network multi channel multi interface inevitable choice improve communication bandwidth communication quality key problem study design fast neighbor discovery strategy integrates directional antenna multi channel parallel case limited energy paper proposed neighbor discovery algorithm combining directional antenna multi channel parallelism detail framework us multi channel multi interface asynchronous heterogeneous multi channel fusion mobile ad hoc network optimized algorithm enables fast neighbor discovery energy constrained situation copy 2023 author exclusive license springer nature singapore pte ltdconstrained_optimization directive_antennas energy_efficiencyad hoc_networks antenna_channel asynchronous_channels directional_antenna discovery_algorithm heterogeneous_channels multi_channel multi channel_parallelism neighbor_discovery network_neighbor_discovery_algorithm
470,Comparison of video capture cards for streaming real-time procedural imaging onto mixed reality headset,"Shah, S. R., & Park, B. J. (2023). Comparison of video capture cards for streaming real-time procedural imaging onto mixed reality headset. Medical Imaging 2023: Imaging Informatics for Healthcare, Research, and Applications. https://doi.org/10.1117/12.2655751
",10.1117/12.2655751,"Ergonomics for image-guided procedures can be improved by using mixed reality headsets. Such headsets offer the ability to position holographic monitors that display information, such as an ultrasound stream, within the operator&rsquo;s field of view during procedures. However, one of the barriers of clinical adoption of mixed reality headsets is high latency of information projected on to the headset. Upwards of 40% of the overall latency of the entire system can be due to video cards that capture procedural imaging for wireless streaming. The costs of the video cards can vary widely, from as low as $20 to upwards of several hundreds of dollars. The latencies of four separate video cards with a range of costs were evaluated. Based on these results, we propose an ideal tradeoff between latency and costs for clinical use of wirelessly mirroring procedural imaging into mixed reality headsets. &copy; 2023 SPIE.","461.1 Biomedical Engineering;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;746 Imaging Techniques",Entire system;Field of views;Head-UpDisplay;Heads-up-display;Image-guided procedures;Interventional radiology;Mixed reality;Real- time;Video capture card;Video cards,Display devices;Ergonomics;Image enhancement;Medical applications;Medical imaging;Mixed reality,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Shah, Sana; (2) Park, Brian; ","(1) Catlin Gabel School, Portland; OR; 97229, United States; (2) Oregon Health & Science University, Portland; OR; 97239, United States; ",SPIE,-1,"[""display devices"", ""ergonomics"", ""image enhancement"", ""medical applications"", ""medical imaging""]","[""display devices"", ""ergonomics"", ""image enhancement"", ""medical applications"", ""medical imaging""]",display devices;ergonomics;image enhancement;medical applications;medical imaging,computer vision;medical;human factors;display technology;developers,technology;industries;displays;end users and user experience,computer vision;medical;human factors;display technology;developers,technology;industries;displays;end users and user experience,display_devices ergonomics image_enhancement medical_applications medical_imaging entire_system field_of_views head updisplay heads up display image guided_procedures interventional_radiology mixed_reality real _time video_capture_card video_cards 461 1_biomedical_engineering 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 746_imaging_techniques computer_vision medical human_factors display_technology developers,display_devices ergonomics image_enhancement medical_applications medical_imaging,entire_system field_of_views head updisplay heads up display image guided_procedures interventional_radiology mixed_reality real _time video_capture_card video_cards,ergonomics image guided procedure improved using mixed reality headset headset offer ability position holographic monitor display information ultrasound stream within operator rsquo field view procedure however one barrier clinical adoption mixed reality headset high latency information projected headset upwards 40 overall latency entire system due video card capture procedural imaging wireless streaming cost video card vary widely low 20 upwards several hundred dollar latency four separate video card range cost evaluated based result propose ideal tradeoff latency cost clinical use wirelessly mirroring procedural imaging mixed reality headset copy 2023 spie,display_devices ergonomics image_enhancement medical_applications medical_imaging entire_system field_of_views head updisplay heads up display image guided_procedures interventional_radiology mixed_reality real _time video_capture_card video_cards 461 1_biomedical_engineering 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 746_imaging_techniques computer_vision medical human_factors display_technology developers ergonomics image guided procedure improved using mixed reality headset headset offer ability position holographic monitor display information ultrasound stream within operator rsquo field view procedure however one barrier clinical adoption mixed reality headset high latency information projected headset upwards 40 overall latency entire system due video card capture procedural imaging wireless streaming cost video card vary widely low 20 upwards several hundred dollar latency four separate video card range cost evaluated based result propose ideal tradeoff latency cost clinical use wirelessly mirroring procedural imaging mixed reality headset copy 2023 spie,ergonomics image guided procedure improved using mixed reality headset headset offer ability position holographic monitor display information ultrasound stream within operator rsquo field view procedure however one barrier clinical adoption mixed reality headset high latency information projected headset upwards 40 overall latency entire system due video card capture procedural imaging wireless streaming cost video card vary widely low 20 upwards several hundred dollar latency four separate video card range cost evaluated based result propose ideal tradeoff latency cost clinical use wirelessly mirroring procedural imaging mixed reality headset copy 2023 spiedisplay_devices ergonomics image_enhancement medical_applications medical_imagingentire_system field_of_views head updisplay heads up display image guided_procedures interventional_radiology mixed_reality real _time video_capture_card video_cards
471,Space Design of Exhibition Hall Based on Virtual Reality,"Wang, Y. (2023). Space Design of Exhibition Hall Based on Virtual Reality. Smart Innovation, Systems and Technologies, 157–165. https://doi.org/10.1007/978-981-99-1230-8_14
",10.1007/978-981-99-1230-8_14,"With the emergence of new art forms and technical means, more and more exhibition activities are presented in front of people with a novel artistic expression, relying on brand-new technical means, which has greatly changed people&rsquo;s understanding of exhibition space. The author puts forward the idea of applying VR (Virtual Reality) display design method to the space design of exhibition halls and establishes a panoramic view generation model of exhibition halls. Because there is a high similarity between the optimal simple polygon formed by plane discrete corners and TSP (Traveling Salesman Problem), this paper will directly use the basic steps of GA (Genetic Algorithm) to solve TSP problem to generate the building ground contour. The research shows that by comparison, it can be seen that the time consumed by this algorithm is obviously less than that of the algorithm based on feature points. When the number of points is 16, the two algorithms get the same criterion function value. As the number of points increases, the optimization effect of GA becomes more and more obvious, while the error of the algorithm based on feature points becomes larger. It shows that the optimized GA has a good optimization effect. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications;912.3 Operations Research;921.5 Optimization Techniques",3d virtual;Design method;Display designs;Exhibition halls;Optimization effects;Panoramic views;Simple polygon;Space design;View generation;Virtual-reality display,Design;Traveling salesman problem;Virtual reality,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Wang, Yixuan; ","(1) Guangdong University of Science and Technology, Guangdong, Dongguan; 523000, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""design"", ""traveling salesman problem""]","[""design"", ""traveling salesman problem""]",design;traveling salesman problem,sales and marketing;other;human-computer interaction,other;business;end users and user experience,sales and marketing;other;human-computer interaction,other;business;end users and user experience,design traveling_salesman_problem 3d_virtual design_method display_designs exhibition_halls optimization_effects panoramic_views simple_polygon space_design view_generation virtual reality_display 723_computer_software _data_handling_and_applications 912 3_operations_research 921 5_optimization_techniques sales_and_marketing other human computer_interaction,design traveling_salesman_problem,3d_virtual design_method display_designs exhibition_halls optimization_effects panoramic_views simple_polygon space_design view_generation virtual reality_display,emergence new art form technical mean exhibition activity presented front people novel artistic expression relying brand new technical mean greatly changed people rsquo understanding exhibition space author put forward idea applying vr virtual reality display design method space design exhibition hall establishes panoramic view generation model exhibition hall high similarity optimal simple polygon formed plane discrete corner tsp traveling salesman problem paper directly use basic step ga genetic algorithm solve tsp problem generate building ground contour research show comparison seen time consumed algorithm obviously le algorithm based feature point number point 16 two algorithm get criterion function value number point increase optimization effect ga becomes obvious error algorithm based feature point becomes larger show optimized ga good optimization effect copy 2023 author exclusive license springer nature singapore pte ltd,design traveling_salesman_problem 3d_virtual design_method display_designs exhibition_halls optimization_effects panoramic_views simple_polygon space_design view_generation virtual reality_display 723_computer_software _data_handling_and_applications 912 3_operations_research 921 5_optimization_techniques sales_and_marketing other human computer_interaction emergence new art form technical mean exhibition activity presented front people novel artistic expression relying brand new technical mean greatly changed people rsquo understanding exhibition space author put forward idea applying vr virtual reality display design method space design exhibition hall establishes panoramic view generation model exhibition hall high similarity optimal simple polygon formed plane discrete corner tsp traveling salesman problem paper directly use basic step ga genetic algorithm solve tsp problem generate building ground contour research show comparison seen time consumed algorithm obviously le algorithm based feature point number point 16 two algorithm get criterion function value number point increase optimization effect ga becomes obvious error algorithm based feature point becomes larger show optimized ga good optimization effect copy 2023 author exclusive license springer nature singapore pte ltd,emergence new art form technical mean exhibition activity presented front people novel artistic expression relying brand new technical mean greatly changed people rsquo understanding exhibition space author put forward idea applying vr virtual reality display design method space design exhibition hall establishes panoramic view generation model exhibition hall high similarity optimal simple polygon formed plane discrete corner tsp traveling salesman problem paper directly use basic step ga genetic algorithm solve tsp problem generate building ground contour research show comparison seen time consumed algorithm obviously le algorithm based feature point number point 16 two algorithm get criterion function value number point increase optimization effect ga becomes obvious error algorithm based feature point becomes larger show optimized ga good optimization effect copy 2023 author exclusive license springer nature singapore pte ltddesign traveling_salesman_problem3d_virtual design_method display_designs exhibition_halls optimization_effects panoramic_views simple_polygon space_design view_generation virtual reality_display
472,Design and Research of Highway Tunnel Construction Positioning System Based on UWB,"Zhang, H., Wang, X., Liu, Y., & Cai, L. (2023). Design and Research of Highway Tunnel Construction Positioning System Based on UWB. Smart Innovation, Systems and Technologies, 251–259. https://doi.org/10.1007/978-981-99-1230-8_22
",10.1007/978-981-99-1230-8_22,"Maintenance personnel, according to the theory of highway tunnel construction vehicle real-time positioning problem, combined with the tunnel's construction environment, make full use of information technology, the basic principles of UWB indoor positioning technology is analysed, and based on this, advances the UWB positioning system of the highway tunnel construction solution, finally, set up the test environment to analyse the location accuracy of the positioning system. The results show that the system can fully meet the positioning requirements of tunnel construction personnel and vehicles. The system is mainly composed of four parts: the perception layer, the transmission layer, the solution layer, and the application layer. Through the Internet of things technology, the positioning detection, track playback, one-button alarm, and other functions of the construction personnel and vehicles can be realized, which can effectively improve the level of intelligent management and security control in the construction stage of highway tunnel. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","401.2 Tunnels and Tunneling;432.1 Highway Transportation, General;722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;903.3 Information Retrieval and Use;912.2 Management;912.4 Personnel",Construction personnel;Construction safety;Construction vehicle;Highway tunnel;Maintenance personnel;Positioning;Positioning system;The internet of thing;Tunnel construction;UWB,Highway administration;Highway planning;Human resource management;Information use;Internet of things;Vehicles,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Zhang, Hengbo; (1) Wang, Xinke; (1) Liu, Yuchen; (1) Cai, Lei; ","(1) Beijing GOTEC ITS Technology Co., Ltd, Beijing; 100088, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""highway administration"", ""highway planning"", ""human resource management"", ""information use"", ""internet of things"", ""vehicles""]","[""highway administration"", ""highway planning"", ""human resource management"", ""information use"", ""internet of things"", ""vehicles""]",highway administration;highway planning;human resource management;information use;internet of things;vehicles,transportation;automotive;internet of things;business planning and management;human resources;networks,technology;business;industries,transportation;automotive;internet of things;business planning and management;human resources;networks,technology;business;industries,highway_administration highway_planning human_resource_management information_use internet_of_things vehicles construction_personnel construction_safety construction_vehicle highway_tunnel maintenance_personnel positioning positioning_system the_internet_of_thing tunnel_construction uwb 401 2_tunnels_and_tunneling 432 1_highway_transportation _general 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 903 3_information_retrieval_and_use 912 2_management 912 4_personnel transportation automotive internet_of_things business_planning_and_management human_resources networks,highway_administration highway_planning human_resource_management information_use internet_of_things vehicles,construction_personnel construction_safety construction_vehicle highway_tunnel maintenance_personnel positioning positioning_system the_internet_of_thing tunnel_construction uwb,maintenance personnel according theory highway tunnel construction vehicle real time positioning problem combined tunnel construction environment make full use information technology basic principle uwb indoor positioning technology analysed based advance uwb positioning system highway tunnel construction solution finally set test environment analyse location accuracy positioning system result show system fully meet positioning requirement tunnel construction personnel vehicle system mainly composed four part perception layer transmission layer solution layer application layer internet thing technology positioning detection track playback one button alarm function construction personnel vehicle realized effectively improve level intelligent management security control construction stage highway tunnel copy 2023 author exclusive license springer nature singapore pte ltd,highway_administration highway_planning human_resource_management information_use internet_of_things vehicles construction_personnel construction_safety construction_vehicle highway_tunnel maintenance_personnel positioning positioning_system the_internet_of_thing tunnel_construction uwb 401 2_tunnels_and_tunneling 432 1_highway_transportation _general 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 903 3_information_retrieval_and_use 912 2_management 912 4_personnel transportation automotive internet_of_things business_planning_and_management human_resources networks maintenance personnel according theory highway tunnel construction vehicle real time positioning problem combined tunnel construction environment make full use information technology basic principle uwb indoor positioning technology analysed based advance uwb positioning system highway tunnel construction solution finally set test environment analyse location accuracy positioning system result show system fully meet positioning requirement tunnel construction personnel vehicle system mainly composed four part perception layer transmission layer solution layer application layer internet thing technology positioning detection track playback one button alarm function construction personnel vehicle realized effectively improve level intelligent management security control construction stage highway tunnel copy 2023 author exclusive license springer nature singapore pte ltd,maintenance personnel according theory highway tunnel construction vehicle real time positioning problem combined tunnel construction environment make full use information technology basic principle uwb indoor positioning technology analysed based advance uwb positioning system highway tunnel construction solution finally set test environment analyse location accuracy positioning system result show system fully meet positioning requirement tunnel construction personnel vehicle system mainly composed four part perception layer transmission layer solution layer application layer internet thing technology positioning detection track playback one button alarm function construction personnel vehicle realized effectively improve level intelligent management security control construction stage highway tunnel copy 2023 author exclusive license springer nature singapore pte ltdhighway_administration highway_planning human_resource_management information_use internet_of_things vehiclesconstruction_personnel construction_safety construction_vehicle highway_tunnel maintenance_personnel positioning positioning_system the_internet_of_thing tunnel_construction uwb
473,Multi-feature Extraction of Mineral Zone of Tabling Through Deep Semantic Segmentation,"Liu, H., & You, K. (2023). Multi-feature Extraction of Mineral Zone of Tabling Through Deep Semantic Segmentation. Smart Innovation, Systems and Technologies, 51–68. https://doi.org/10.1007/978-981-99-1230-8_5
",10.1007/978-981-99-1230-8_5,"Various segmentation algorithms for mineral zone images can only extract the boundary of the concentrate zone or the separation point of the mineral zone. To obtain fuller and more productive feature information from the mineral zone of Tabling&rsquo;s separation, deep semantic segmentation models with DeepLab, U-net, and Xception are constructed. The image datasets of the industrial Tabling separation are collected and marked, and the corresponding mineral zone image dataset is constructed, the training and test sets are distributed in a certain proportion and imported into the deep semantic models for training. The training results of these models are compared, and the segmentation of the mineral zone images is evaluated. DeepLab-xception and DeepLab v3+ have the highest accuracy 0.9943 and mean intersection over the union value of 0.989. Finally, the DeepLab v3+ is adopted as the model for the image feature segmentation of Tabling&rsquo;s mineral zone. Through the corresponding image processing and feature extraction operators, the effective multi-scale features of Tabling&rsquo;s mineral zone can be well extracted. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",482.2 Minerals;723.4 Artificial Intelligence;802.3 Chemical Operations;922.2 Mathematical Statistics,Automation and intelligence of tabling;Deep semantic segmentation model;Effective multi-scale feature;Features extraction;Image datasets;Image features;Multi-scale features;Segmentation models;Semantic segmentation;Tabling&rsquo;s mineral zone,Extraction;Feature extraction;Minerals;Semantics;Statistical tests,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Liu, Huizhong; (1) You, Keshun; ","(1) Jiangxi University of Science and Technology, Ganzhou; 341000, China; (2) Research Center of Jiangxi Mining and Metallurgical Mechanical and Electrical Engineering Technology, Ganzhou; 341000, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""extraction"", ""feature extraction"", ""minerals"", ""semantics"", ""statistical tests""]","[""extraction"", ""feature extraction"", ""minerals"", ""semantics"", ""statistical tests""]",extraction;feature extraction;minerals;semantics;statistical tests,computer vision;chemical;metals and mining;data;artificial intelligence,technology;industries,computer vision;chemical;metals and mining;data;artificial intelligence,technology;industries,extraction feature_extraction minerals semantics statistical_tests automation_and_intelligence_of_tabling deep_semantic_segmentation_model effective_multi scale_feature features_extraction image_datasets image_features multi scale_features segmentation_models semantic_segmentation tabling rsquo s_mineral_zone 482 2_minerals 723 4_artificial_intelligence 802 3_chemical_operations 922 2_mathematical_statistics computer_vision chemical metals_and_mining data artificial_intelligence,extraction feature_extraction minerals semantics statistical_tests,automation_and_intelligence_of_tabling deep_semantic_segmentation_model effective_multi scale_feature features_extraction image_datasets image_features multi scale_features segmentation_models semantic_segmentation tabling rsquo s_mineral_zone,various segmentation algorithm mineral zone image extract boundary concentrate zone separation point mineral zone obtain fuller productive feature information mineral zone tabling rsquo separation deep semantic segmentation model deeplab u net xception constructed image datasets industrial tabling separation collected marked corresponding mineral zone image dataset constructed training test set distributed certain proportion imported deep semantic model training training result model compared segmentation mineral zone image evaluated deeplab xception deeplab v3 highest accuracy 0 9943 mean intersection union value 0 989 finally deeplab v3 adopted model image feature segmentation tabling rsquo mineral zone corresponding image processing feature extraction operator effective multi scale feature tabling rsquo mineral zone well extracted copy 2023 author exclusive license springer nature singapore pte ltd,extraction feature_extraction minerals semantics statistical_tests automation_and_intelligence_of_tabling deep_semantic_segmentation_model effective_multi scale_feature features_extraction image_datasets image_features multi scale_features segmentation_models semantic_segmentation tabling rsquo s_mineral_zone 482 2_minerals 723 4_artificial_intelligence 802 3_chemical_operations 922 2_mathematical_statistics computer_vision chemical metals_and_mining data artificial_intelligence various segmentation algorithm mineral zone image extract boundary concentrate zone separation point mineral zone obtain fuller productive feature information mineral zone tabling rsquo separation deep semantic segmentation model deeplab u net xception constructed image datasets industrial tabling separation collected marked corresponding mineral zone image dataset constructed training test set distributed certain proportion imported deep semantic model training training result model compared segmentation mineral zone image evaluated deeplab xception deeplab v3 highest accuracy 0 9943 mean intersection union value 0 989 finally deeplab v3 adopted model image feature segmentation tabling rsquo mineral zone corresponding image processing feature extraction operator effective multi scale feature tabling rsquo mineral zone well extracted copy 2023 author exclusive license springer nature singapore pte ltd,various segmentation algorithm mineral zone image extract boundary concentrate zone separation point mineral zone obtain fuller productive feature information mineral zone tabling rsquo separation deep semantic segmentation model deeplab u net xception constructed image datasets industrial tabling separation collected marked corresponding mineral zone image dataset constructed training test set distributed certain proportion imported deep semantic model training training result model compared segmentation mineral zone image evaluated deeplab xception deeplab v3 highest accuracy 0 9943 mean intersection union value 0 989 finally deeplab v3 adopted model image feature segmentation tabling rsquo mineral zone corresponding image processing feature extraction operator effective multi scale feature tabling rsquo mineral zone well extracted copy 2023 author exclusive license springer nature singapore pte ltdextraction feature_extraction minerals semantics statistical_testsautomation_and_intelligence_of_tabling deep_semantic_segmentation_model effective_multi scale_feature features_extraction image_datasets image_features multi scale_features segmentation_models semantic_segmentation tabling rsquo s_mineral_zone
474,Design and Experimental Verification of High Functional Density Cubesat System,"Yao, Y., Fu, W., Guo, X., Shi, S., & Yan, J. (2023). Design and Experimental Verification of High Functional Density Cubesat System. Smart Innovation, Systems and Technologies, 143–156. https://doi.org/10.1007/978-981-99-1230-8_13
",10.1007/978-981-99-1230-8_13,"A Cubesat is regarded as a concentrated instrument intuitively and it includes all necessary elements of a satellite. High-cost performance is the key point and advantage, which is different from traditional satellites. In this paper, the development trends and task dimensions of Cubesat are analyzed first. Then it details the standardization and integration design requirements of high functional density Cubesat as the technologies of electronics and advanced devices are promoted rapidly. Technical approaches are proposed for system design of high functional density Cubesat in two dimensions. Furthermore, a specific design example for 6U Cubesat is shown in detail, which includes standardized stack combination, power system integration, autonomous operation management, and diversified task modes. All these methods are applied to achieve more functions in a Cubesat. The 6U Cubesat is well-verified on orbit for 10&nbsp;months and large amounts of data are transmitted from space to earth. The key developing technologies of Cubesat are prospected at last. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",655.2 Satellites;902.2 Codes and Standards,Cubesat;Design verification;Development tasks;Development trends;Experimental verification;Functional density;High functional density;Higher cost performance;Keypoints;Task dimensions,Earth (planet);Orbits;Small satellites,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Yao, Yuying; (1) Fu, Weida; (1) Guo, Xin; (1) Shi, Sihan; (1) Yan, Jing; ","(1) DFH Satellite Co. Ltd, Haidian District, Beijing; 100094, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""earth"", ""orbits"", ""small satellites""]","[""earth"", ""orbits"", ""small satellites""]",earth;orbits;small satellites,geospatial;other;medical;liberal arts,technology;other;industries,geospatial;other;medical;liberal arts,technology;other;industries,earth orbits small_satellites cubesat design_verification development_tasks development_trends experimental_verification functional_density high_functional_density higher_cost_performance keypoints task_dimensions 655 2_satellites 902 2_codes_and_standards geospatial other medical liberal_arts,earth orbits small_satellites,cubesat design_verification development_tasks development_trends experimental_verification functional_density high_functional_density higher_cost_performance keypoints task_dimensions,cubesat regarded concentrated instrument intuitively includes necessary element satellite high cost performance key point advantage different traditional satellite paper development trend task dimension cubesat analyzed first detail standardization integration design requirement high functional density cubesat technology electronics advanced device promoted rapidly technical approach proposed system design high functional density cubesat two dimension furthermore specific design example 6u cubesat shown detail includes standardized stack combination power system integration autonomous operation management diversified task mode method applied achieve function cubesat 6u cubesat well verified orbit 10 nbsp month large amount data transmitted space earth key developing technology cubesat prospected last copy 2023 author exclusive license springer nature singapore pte ltd,earth orbits small_satellites cubesat design_verification development_tasks development_trends experimental_verification functional_density high_functional_density higher_cost_performance keypoints task_dimensions 655 2_satellites 902 2_codes_and_standards geospatial other medical liberal_arts cubesat regarded concentrated instrument intuitively includes necessary element satellite high cost performance key point advantage different traditional satellite paper development trend task dimension cubesat analyzed first detail standardization integration design requirement high functional density cubesat technology electronics advanced device promoted rapidly technical approach proposed system design high functional density cubesat two dimension furthermore specific design example 6u cubesat shown detail includes standardized stack combination power system integration autonomous operation management diversified task mode method applied achieve function cubesat 6u cubesat well verified orbit 10 nbsp month large amount data transmitted space earth key developing technology cubesat prospected last copy 2023 author exclusive license springer nature singapore pte ltd,cubesat regarded concentrated instrument intuitively includes necessary element satellite high cost performance key point advantage different traditional satellite paper development trend task dimension cubesat analyzed first detail standardization integration design requirement high functional density cubesat technology electronics advanced device promoted rapidly technical approach proposed system design high functional density cubesat two dimension furthermore specific design example 6u cubesat shown detail includes standardized stack combination power system integration autonomous operation management diversified task mode method applied achieve function cubesat 6u cubesat well verified orbit 10 nbsp month large amount data transmitted space earth key developing technology cubesat prospected last copy 2023 author exclusive license springer nature singapore pte ltdearth orbits small_satellitescubesat design_verification development_tasks development_trends experimental_verification functional_density high_functional_density higher_cost_performance keypoints task_dimensions
475,Sustainable Solutions by the Use of Immersive Technologies for Repurposing Buildings,"Rosilius, M., Wilhelm, M., von Eitzen, I., Decker, S., Damek, S., & Braeutigam, V. (2023). Sustainable Solutions by the Use of Immersive Technologies for Repurposing Buildings. Manufacturing Driving Circular Economy, 551–558. https://doi.org/10.1007/978-3-031-28839-5_62
",10.1007/978-3-031-28839-5_62,"In the context of urban production and sustainable reuse of existing buildings, a detailed planning of the later usage is indispensable. One approach is to enable large-scale AR simulation on site with a sufficient Level of Detail (LoD) and stability. To determine performance metrics, a technology-stack is created and presented that enables a realistic field experiment in an industrial environment (area of 1,314&nbsp;m2) using Microsoft HoloLens 2. For the experiment, a 3D model was instantiated as often as possible up to the limit of system stability and in different LoDs (100% down to 10%). The result shows that it is feasible to represent 2.63 million polygons (equivalent to about 1,909&nbsp;m3 of augmented space) on LOD-35%; LoD-100% is equivalent to 327.38&nbsp;m3 and 1,284 million polygons. Polygonal density [polygons/m3] is introduced as new indicator for better comparability when using 3D models. Thus, it is possible to immersively visualize urban production planning processes in large-scale scenarios. This expands the functional planning space of Urban Production and overcomes previous technical limitations. &copy; 2023, The Author(s).","723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;913.2 Production Control;921 Mathematics;961 Systems Science",3d-modeling;Industrial metaverse;Large scale industry scenario;Large-scales;Level-of-detail;Metaverses;Performance;Rendering;Resilience;Urban production,3D modeling;Geometry;Production control;Sustainable development;System stability,2023,Conference article (CA),Lect. Notes Mech. Eng.,"(1) Rosilius, Maximilian; (1) Wilhelm, Markus; (2) von Eitzen, Ingo; (3) Decker, Steffen; (4) Damek, Sebastian; (1) Braeutigam, Volker; ","(1) Technical University of Applied Sciences W&uuml;rzburg-Schweinfurt, Ignaz-Sch&ouml;n-Stra&szlig;e 11, Schweinfurt; 97421, Germany; (2) Julius-Maximilians-Universit&auml;t Wuerzburg, Sanderring 2, W&uuml;rzburg; 97070, Germany; (3) Simplifier AG, N&uuml;rnberger Str. 47A, W&uuml;rzburg; 97076, Germany; (4) University of Applied Sciences Erfurt, Altonaer Stra&szlig;e 25, Erfurt; 99085, Germany; ",Springer Science and Business Media Deutschland GmbH,-1,"[""3d modeling"", ""geometry"", ""production control"", ""sustainable development"", ""system stability""]","[""3d modeling"", ""geometry"", ""production control"", ""sustainable development"", ""system stability""]",3d modeling;geometry;production control;sustainable development;system stability,"education;graphics;inspection, safety and quality;policy;manufacturing",technology;business;use cases;industries,"education;graphics;inspection, safety and quality;policy;manufacturing",technology;business;use cases;industries,3d_modeling geometry production_control sustainable_development system_stability 3d modeling industrial_metaverse large_scale_industry_scenario large scales level of detail metaverses performance rendering resilience urban_production 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 913 2_production_control 921_mathematics 961_systems_science education graphics inspection _safety_and_quality policy manufacturing,3d_modeling geometry production_control sustainable_development system_stability,3d modeling industrial_metaverse large_scale_industry_scenario large scales level of detail metaverses performance rendering resilience urban_production,context urban production sustainable reuse existing building detailed planning later usage indispensable one approach enable large scale ar simulation site sufficient level detail lod stability determine performance metric technology stack created presented enables realistic field experiment industrial environment area 1 314 nbsp m2 using microsoft hololens 2 experiment 3d model instantiated often possible limit system stability different lods 100 10 result show feasible represent 2 63 million polygon equivalent 1 909 nbsp m3 augmented space lod 35 lod 100 equivalent 327 38 nbsp m3 1 284 million polygon polygonal density polygon m3 introduced new indicator better comparability using 3d model thus possible immersively visualize urban production planning process large scale scenario expands functional planning space urban production overcomes previous technical limitation copy 2023 author,3d_modeling geometry production_control sustainable_development system_stability 3d modeling industrial_metaverse large_scale_industry_scenario large scales level of detail metaverses performance rendering resilience urban_production 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 913 2_production_control 921_mathematics 961_systems_science education graphics inspection _safety_and_quality policy manufacturing context urban production sustainable reuse existing building detailed planning later usage indispensable one approach enable large scale ar simulation site sufficient level detail lod stability determine performance metric technology stack created presented enables realistic field experiment industrial environment area 1 314 nbsp m2 using microsoft hololens 2 experiment 3d model instantiated often possible limit system stability different lods 100 10 result show feasible represent 2 63 million polygon equivalent 1 909 nbsp m3 augmented space lod 35 lod 100 equivalent 327 38 nbsp m3 1 284 million polygon polygonal density polygon m3 introduced new indicator better comparability using 3d model thus possible immersively visualize urban production planning process large scale scenario expands functional planning space urban production overcomes previous technical limitation copy 2023 author,context urban production sustainable reuse existing building detailed planning later usage indispensable one approach enable large scale ar simulation site sufficient level detail lod stability determine performance metric technology stack created presented enables realistic field experiment industrial environment area 1 314 nbsp m2 using microsoft hololens 2 experiment 3d model instantiated often possible limit system stability different lods 100 10 result show feasible represent 2 63 million polygon equivalent 1 909 nbsp m3 augmented space lod 35 lod 100 equivalent 327 38 nbsp m3 1 284 million polygon polygonal density polygon m3 introduced new indicator better comparability using 3d model thus possible immersively visualize urban production planning process large scale scenario expands functional planning space urban production overcomes previous technical limitation copy 2023 author3d_modeling geometry production_control sustainable_development system_stability3d modeling industrial_metaverse large_scale_industry_scenario large scales level of detail metaverses performance rendering resilience urban_production
476,Research on Weld Defect Object Detection Based on Multi-channel Fusion Convolutional Neural Network,"Geng, H., Li, Z., & Zhou, Y. (2023). Research on Weld Defect Object Detection Based on Multi-channel Fusion Convolutional Neural Network. Smart Innovation, Systems and Technologies, 237–249. https://doi.org/10.1007/978-981-99-1230-8_21
",10.1007/978-981-99-1230-8_21,"Aiming at the problems of low efficiency and strong subjectivity in the current detection of weld defects by radiographic imaging technology, an object detection method of weld defects based on multi-channel fusion convolutional neural network is proposed. In this method, the images of weld defects are encoded and input into multiple feature extraction channels formed by parallel fusion of CNN. After that, the extracted features are fused with full connection layer and the feature vectors are output. Finally, the final output is obtained by Softmax for classification. The proposed method is verified by weld defect images in actual production. The experimental results indicate that the mAP of the multi-channel fusion convolutional neural network reaches 76.37%, and the detection accuracy of weld defects is higher than that of other network such as ResNet-50 and VGG-16. The proposed method can be applied to X-ray intelligent detection of weld defects and other scenarios. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",538.2 Welding;716.1 Information Theory and Signal Processing;723.2 Data Processing and Image Processing;951 Materials Science,Convolutional neural network;Current detection;Imaging technology;Multi channel;Multi-channel fusion;Object detection method;Objects detection;Radiographic imaging;Weld defects;X-ray image,Convolution;Convolutional neural networks;Defects;Image fusion;Object recognition;Welds,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Geng, Hanlin; (1) Li, Zhaohui; (1) Zhou, Yuanyuan; ","(1) Shanghai Spaceflight Precision Machinery Institute, Shanghai, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""convolution"", ""convolutional neural networks"", ""defects"", ""image fusion"", ""object recognition"", ""welds""]","[""convolution"", ""convolutional neural networks"", ""defects"", ""image fusion"", ""object recognition"", ""welds""]",convolution;convolutional neural networks;defects;image fusion;object recognition;welds,"computer vision;manufacturing;inspection, safety and quality;human factors;artificial intelligence;networks",technology;industries;use cases;end users and user experience,"computer vision;manufacturing;inspection, safety and quality;human factors;artificial intelligence;networks",technology;industries;use cases;end users and user experience,convolution convolutional_neural_networks defects image_fusion object_recognition welds convolutional_neural_network current_detection imaging_technology multi_channel multi channel_fusion object_detection_method objects_detection radiographic_imaging weld_defects x ray_image 538 2_welding 716 1_information_theory_and_signal_processing 723 2_data_processing_and_image_processing 951_materials_science computer_vision manufacturing inspection _safety_and_quality human_factors artificial_intelligence networks,convolution convolutional_neural_networks defects image_fusion object_recognition welds,convolutional_neural_network current_detection imaging_technology multi_channel multi channel_fusion object_detection_method objects_detection radiographic_imaging weld_defects x ray_image,aiming problem low efficiency strong subjectivity current detection weld defect radiographic imaging technology object detection method weld defect based multi channel fusion convolutional neural network proposed method image weld defect encoded input multiple feature extraction channel formed parallel fusion cnn extracted feature fused full connection layer feature vector output finally final output obtained softmax classification proposed method verified weld defect image actual production experimental result indicate map multi channel fusion convolutional neural network reach 76 37 detection accuracy weld defect higher network resnet 50 vgg 16 proposed method applied x ray intelligent detection weld defect scenario copy 2023 author exclusive license springer nature singapore pte ltd,convolution convolutional_neural_networks defects image_fusion object_recognition welds convolutional_neural_network current_detection imaging_technology multi_channel multi channel_fusion object_detection_method objects_detection radiographic_imaging weld_defects x ray_image 538 2_welding 716 1_information_theory_and_signal_processing 723 2_data_processing_and_image_processing 951_materials_science computer_vision manufacturing inspection _safety_and_quality human_factors artificial_intelligence networks aiming problem low efficiency strong subjectivity current detection weld defect radiographic imaging technology object detection method weld defect based multi channel fusion convolutional neural network proposed method image weld defect encoded input multiple feature extraction channel formed parallel fusion cnn extracted feature fused full connection layer feature vector output finally final output obtained softmax classification proposed method verified weld defect image actual production experimental result indicate map multi channel fusion convolutional neural network reach 76 37 detection accuracy weld defect higher network resnet 50 vgg 16 proposed method applied x ray intelligent detection weld defect scenario copy 2023 author exclusive license springer nature singapore pte ltd,aiming problem low efficiency strong subjectivity current detection weld defect radiographic imaging technology object detection method weld defect based multi channel fusion convolutional neural network proposed method image weld defect encoded input multiple feature extraction channel formed parallel fusion cnn extracted feature fused full connection layer feature vector output finally final output obtained softmax classification proposed method verified weld defect image actual production experimental result indicate map multi channel fusion convolutional neural network reach 76 37 detection accuracy weld defect higher network resnet 50 vgg 16 proposed method applied x ray intelligent detection weld defect scenario copy 2023 author exclusive license springer nature singapore pte ltdconvolution convolutional_neural_networks defects image_fusion object_recognition weldsconvolutional_neural_network current_detection imaging_technology multi_channel multi channel_fusion object_detection_method objects_detection radiographic_imaging weld_defects x ray_image
477,2D Numerical Model Used to Investigate the Influence of Vegetation on Geomorphological Evolution of Mudflats,"Ji, J. (2023). 2D Numerical Model Used to Investigate the Influence of Vegetation on Geomorphological Evolution of Mudflats. Smart Innovation, Systems and Technologies, 131–142. https://doi.org/10.1007/978-981-99-1230-8_12
",10.1007/978-981-99-1230-8_12,"In this study, a 2D numerical model (Delft3D) was used to investigate the influence of vegetation on geomorphological evolution of mudflats. The model results indicated that the mudflat was in a pattern of accretion when the vegetation was excluded from the model. The formation of tidal channels in the intertidal zone was well reproduced. Moreover, the middle and upper sections of the intertidal zone were characterized by a convex profile. It is suggested that the presence of vegetation could promote the formation and development of tidal channels compared with that without vegetation. Furthermore, the promoting effect of vegetation on tidal channel formation was more significant when the vegetation biomass was ecologically distributed. Different vegetation biomass distribution patterns showed different effects on the evolution of the mudflat. When the vegetation biomass was ecologically distributed, the intensity of reduction in current flow was stronger than parabolic distribution during the early stage of evolution. However, the result was opposite during the later stage of evolution. Further analysis also indicated that the presence of vegetation decreased the width of the upper intertidal zone (vegetated mudflat), while increased its elevation. In addition, the steep cliff between vegetated mudflat and bare mudflat increased significantly. The findings of this study may provide some implications for the management and restoration of mudflat&ndash;salt marsh ecosystem. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",454.3 Ecology and Ecosystems;921 Mathematics,2d numerical modelling;Biomass distribution;Eco-geomorphology model;Geomorphological evolution;Influence of vegetations;Intertidal zones;Mudflats;Tidal channel;Vegetation biomass;Vegetation biomass distribution,Biomass;Ecology;Numerical models,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Ji, Jiaojiao; ","(1) College of Water Conservancy and Hydropower Engineering, Hohai University, Nanjing; 210098, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""biomass"", ""ecology"", ""numerical models""]","[""biomass"", ""ecology"", ""numerical models""]",biomass;ecology;numerical models,other;farming and natural science;data,technology;other;industries,other;farming and natural science;data,technology;other;industries,biomass ecology numerical_models 2d_numerical_modelling biomass_distribution eco geomorphology_model geomorphological_evolution influence_of_vegetations intertidal_zones mudflats tidal_channel vegetation_biomass vegetation_biomass_distribution 454 3_ecology_and_ecosystems 921_mathematics other farming_and_natural_science data,biomass ecology numerical_models,2d_numerical_modelling biomass_distribution eco geomorphology_model geomorphological_evolution influence_of_vegetations intertidal_zones mudflats tidal_channel vegetation_biomass vegetation_biomass_distribution,study 2d numerical model delft3d used investigate influence vegetation geomorphological evolution mudflats model result indicated mudflat pattern accretion vegetation excluded model formation tidal channel intertidal zone well reproduced moreover middle upper section intertidal zone characterized convex profile suggested presence vegetation could promote formation development tidal channel compared without vegetation furthermore promoting effect vegetation tidal channel formation significant vegetation biomass ecologically distributed different vegetation biomass distribution pattern showed different effect evolution mudflat vegetation biomass ecologically distributed intensity reduction current flow stronger parabolic distribution early stage evolution however result opposite later stage evolution analysis also indicated presence vegetation decreased width upper intertidal zone vegetated mudflat increased elevation addition steep cliff vegetated mudflat bare mudflat increased significantly finding study may provide implication management restoration mudflat ndash salt marsh ecosystem copy 2023 author exclusive license springer nature singapore pte ltd,biomass ecology numerical_models 2d_numerical_modelling biomass_distribution eco geomorphology_model geomorphological_evolution influence_of_vegetations intertidal_zones mudflats tidal_channel vegetation_biomass vegetation_biomass_distribution 454 3_ecology_and_ecosystems 921_mathematics other farming_and_natural_science data study 2d numerical model delft3d used investigate influence vegetation geomorphological evolution mudflats model result indicated mudflat pattern accretion vegetation excluded model formation tidal channel intertidal zone well reproduced moreover middle upper section intertidal zone characterized convex profile suggested presence vegetation could promote formation development tidal channel compared without vegetation furthermore promoting effect vegetation tidal channel formation significant vegetation biomass ecologically distributed different vegetation biomass distribution pattern showed different effect evolution mudflat vegetation biomass ecologically distributed intensity reduction current flow stronger parabolic distribution early stage evolution however result opposite later stage evolution analysis also indicated presence vegetation decreased width upper intertidal zone vegetated mudflat increased elevation addition steep cliff vegetated mudflat bare mudflat increased significantly finding study may provide implication management restoration mudflat ndash salt marsh ecosystem copy 2023 author exclusive license springer nature singapore pte ltd,study 2d numerical model delft3d used investigate influence vegetation geomorphological evolution mudflats model result indicated mudflat pattern accretion vegetation excluded model formation tidal channel intertidal zone well reproduced moreover middle upper section intertidal zone characterized convex profile suggested presence vegetation could promote formation development tidal channel compared without vegetation furthermore promoting effect vegetation tidal channel formation significant vegetation biomass ecologically distributed different vegetation biomass distribution pattern showed different effect evolution mudflat vegetation biomass ecologically distributed intensity reduction current flow stronger parabolic distribution early stage evolution however result opposite later stage evolution analysis also indicated presence vegetation decreased width upper intertidal zone vegetated mudflat increased elevation addition steep cliff vegetated mudflat bare mudflat increased significantly finding study may provide implication management restoration mudflat ndash salt marsh ecosystem copy 2023 author exclusive license springer nature singapore pte ltdbiomass ecology numerical_models2d_numerical_modelling biomass_distribution eco geomorphology_model geomorphological_evolution influence_of_vegetations intertidal_zones mudflats tidal_channel vegetation_biomass vegetation_biomass_distribution
478,Research and Implementation of Hybrid Storage Method for Multi-source Heterogeneous Data of Electric Distribution Network,"Qiao, J., Zhou, A., Peng, L., Zhu, L., Pan, S., & Yang, P. (2023). Research and Implementation of Hybrid Storage Method for Multi-source Heterogeneous Data of Electric Distribution Network. Smart Innovation, Systems and Technologies, 31–40. https://doi.org/10.1007/978-981-99-1230-8_3
",10.1007/978-981-99-1230-8_3,"The traditional relational database is difficult to efficiently store the power grid topology data with complex network relationships, which seriously restricts the application expansion of power grid topology analysis and calculation. Graph database is a new data management and analysis and calculation technology based on graph theory. The research mainly focuses on the following four aspects: first, the basic requirements of the power grid diagram database, including: the data requirements of the power grid diagram database, the functional requirements of the power grid diagram database, and the performance requirements of the power grid diagram database; the second is the research on the core technology of the grid diagram database, including: the research on the data description method of the grid diagram database, the research on the data storage technology of the grid diagram database, the research on the data modeling technology of the grid diagram database, and the research on the fast retrieval technology for the grid diagram data; the third is the development and realization of the main functions of the power grid diagram database, including: the design of the power grid diagram database system framework, the research on the development and selection of the power grid diagram database technology, and the development and realization of the basic functions of the power grid diagram database; the fourth is grid diagram database testing and application verification, including: grid diagram database testing and grid diagram database application verification. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","706.1.2 Electric Power Distribution;722 Computer Systems and Equipment;722.1 Data Storage, Equipment and Techniques;723 Computer Software, Data Handling and Applications;801 Chemistry;921.4 Combinatorial Mathematics, Includes Graph Theory, Set Theory",Data hybrid storage;Distributed new energy;Electric distribution networks;Heterogeneous data;Hybrid storages;Multi-source heterogeneous data;Multi-source isomerism;Multi-Sources;New energies,Complex networks;Electric power distribution;Graph theory;Information management;Search engines;Stereochemistry,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Qiao, Junfeng; (1) Zhou, Aihua; (1) Peng, Lin; (1) Zhu, Lipeng; (1) Pan, Sen; (1) Yang, Pei; ","(1) State Grid Key Laboratory of Information & Network Security of State Grid Smart Grid Research Institute Co., Ltd, Jiangsu, Nanjing; 210003, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""complex networks"", ""electric power distribution"", ""graph theory"", ""information management"", ""search engines"", ""stereochemistry""]","[""complex networks"", ""electric power distribution"", ""graph theory"", ""information management"", ""search engines"", ""stereochemistry""]",complex networks;electric power distribution;graph theory;information management;search engines;stereochemistry,other;medical;chemical;power and energy;data;artificial intelligence;business planning and management,technology;other;business;industries,other;medical;chemical;power and energy;data;artificial intelligence;business planning and management,technology;other;business;industries,complex_networks electric_power_distribution graph_theory information_management search_engines stereochemistry data_hybrid_storage distributed_new_energy electric_distribution_networks heterogeneous_data hybrid_storages multi source_heterogeneous_data multi source_isomerism multi sources new_energies 706 1 2_electric_power_distribution 722_computer_systems_and_equipment 722 1_data_storage _equipment_and_techniques 723_computer_software _data_handling_and_applications 801_chemistry 921 4_combinatorial_mathematics _includes_graph_theory _set_theory other medical chemical power_and_energy data artificial_intelligence business_planning_and_management,complex_networks electric_power_distribution graph_theory information_management search_engines stereochemistry,data_hybrid_storage distributed_new_energy electric_distribution_networks heterogeneous_data hybrid_storages multi source_heterogeneous_data multi source_isomerism multi sources new_energies,traditional relational database difficult efficiently store power grid topology data complex network relationship seriously restricts application expansion power grid topology analysis calculation graph database new data management analysis calculation technology based graph theory research mainly focus following four aspect first basic requirement power grid diagram database including data requirement power grid diagram database functional requirement power grid diagram database performance requirement power grid diagram database second research core technology grid diagram database including research data description method grid diagram database research data storage technology grid diagram database research data modeling technology grid diagram database research fast retrieval technology grid diagram data third development realization main function power grid diagram database including design power grid diagram database system framework research development selection power grid diagram database technology development realization basic function power grid diagram database fourth grid diagram database testing application verification including grid diagram database testing grid diagram database application verification copy 2023 author exclusive license springer nature singapore pte ltd,complex_networks electric_power_distribution graph_theory information_management search_engines stereochemistry data_hybrid_storage distributed_new_energy electric_distribution_networks heterogeneous_data hybrid_storages multi source_heterogeneous_data multi source_isomerism multi sources new_energies 706 1 2_electric_power_distribution 722_computer_systems_and_equipment 722 1_data_storage _equipment_and_techniques 723_computer_software _data_handling_and_applications 801_chemistry 921 4_combinatorial_mathematics _includes_graph_theory _set_theory other medical chemical power_and_energy data artificial_intelligence business_planning_and_management traditional relational database difficult efficiently store power grid topology data complex network relationship seriously restricts application expansion power grid topology analysis calculation graph database new data management analysis calculation technology based graph theory research mainly focus following four aspect first basic requirement power grid diagram database including data requirement power grid diagram database functional requirement power grid diagram database performance requirement power grid diagram database second research core technology grid diagram database including research data description method grid diagram database research data storage technology grid diagram database research data modeling technology grid diagram database research fast retrieval technology grid diagram data third development realization main function power grid diagram database including design power grid diagram database system framework research development selection power grid diagram database technology development realization basic function power grid diagram database fourth grid diagram database testing application verification including grid diagram database testing grid diagram database application verification copy 2023 author exclusive license springer nature singapore pte ltd,traditional relational database difficult efficiently store power grid topology data complex network relationship seriously restricts application expansion power grid topology analysis calculation graph database new data management analysis calculation technology based graph theory research mainly focus following four aspect first basic requirement power grid diagram database including data requirement power grid diagram database functional requirement power grid diagram database performance requirement power grid diagram database second research core technology grid diagram database including research data description method grid diagram database research data storage technology grid diagram database research data modeling technology grid diagram database research fast retrieval technology grid diagram data third development realization main function power grid diagram database including design power grid diagram database system framework research development selection power grid diagram database technology development realization basic function power grid diagram database fourth grid diagram database testing application verification including grid diagram database testing grid diagram database application verification copy 2023 author exclusive license springer nature singapore pte ltdcomplex_networks electric_power_distribution graph_theory information_management search_engines stereochemistrydata_hybrid_storage distributed_new_energy electric_distribution_networks heterogeneous_data hybrid_storages multi source_heterogeneous_data multi source_isomerism multi sources new_energies
479,Research on Cross Domain Data Analysis and Data Mining Technology of Power Grid Digital Benefits,"Wang, G., Dong, A., Lv, C., Zhao, B., & Pan, J. (2023). Research on Cross Domain Data Analysis and Data Mining Technology of Power Grid Digital Benefits. Smart Innovation, Systems and Technologies, 261–270. https://doi.org/10.1007/978-981-99-1230-8_23
",10.1007/978-981-99-1230-8_23,"The digital power grid system integrates flexible resources such as traditional power sources and distributed power sources and has the characteristics of high time variability and high complexity. It urgently needs cross domain data support. However, the traditional evaluation methods can&rsquo;t evaluate cross domain data, which is not targeted and effective, and its practicality needs to be improved. This paper analyzes the cross domain intelligent construction and business service requirements, the characteristics of power grid digital cross domain data, studies the internal coupling relationship between digital system application functions and cross domain data, and proposes a coupling evaluation model to measure the digital system and cross domain data. Research the process of cross domain data mining, cluster similarity measurement, historical data feature mining, and other technologies to achieve historical cross domain data feature analysis. Study the fitting analysis technology, and use correlation analysis and regression analysis to achieve the fitting analysis of spanning data, so as to support the technical and economic analysis of spanning data of power grid digital system. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",723.2 Data Processing and Image Processing;911.2 Industrial Economics;922.2 Mathematical Statistics,Cross domain data analyse;Cross-domain;Data feature;Data mining technology;Digital project;Digital system;Economics evaluations;Power grid system;Power grids;Technical evaluation,Data handling;Data mining;Regression analysis,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Wang, Gang; (3) Dong, Aidi; (4) Lv, Changhui; (4) Zhao, Bo; (3) Pan, Jianhong; ","(1) State Grid Smart Grid Research Institute CO., LTD, Nanjing; 210003, China; (2) State Grid Key Laboratory of Information and Network Security, Nanjing; 210003, China; (3) State Grid Jilin Electric Power Company Limited, Changchun; 130021, China; (4) Power Economic Research Institute of Jilin Electric Power Co, Ltd, Changchun; 130011, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""data handling"", ""data mining"", ""regression analysis""]","[""data handling"", ""data mining"", ""regression analysis""]",data handling;data mining;regression analysis,artificial intelligence;metals and mining;data,technology;industries,artificial intelligence;metals and mining;data,technology;industries,data_handling data_mining regression_analysis cross_domain_data_analyse cross domain data_feature data_mining_technology digital_project digital_system economics_evaluations power_grid_system power_grids technical_evaluation 723 2_data_processing_and_image_processing 911 2_industrial_economics 922 2_mathematical_statistics artificial_intelligence metals_and_mining data,data_handling data_mining regression_analysis,cross_domain_data_analyse cross domain data_feature data_mining_technology digital_project digital_system economics_evaluations power_grid_system power_grids technical_evaluation,digital power grid system integrates flexible resource traditional power source distributed power source characteristic high time variability high complexity urgently need cross domain data support however traditional evaluation method rsquo evaluate cross domain data targeted effective practicality need improved paper analyzes cross domain intelligent construction business service requirement characteristic power grid digital cross domain data study internal coupling relationship digital system application function cross domain data proposes coupling evaluation model measure digital system cross domain data research process cross domain data mining cluster similarity measurement historical data feature mining technology achieve historical cross domain data feature analysis study fitting analysis technology use correlation analysis regression analysis achieve fitting analysis spanning data support technical economic analysis spanning data power grid digital system copy 2023 author exclusive license springer nature singapore pte ltd,data_handling data_mining regression_analysis cross_domain_data_analyse cross domain data_feature data_mining_technology digital_project digital_system economics_evaluations power_grid_system power_grids technical_evaluation 723 2_data_processing_and_image_processing 911 2_industrial_economics 922 2_mathematical_statistics artificial_intelligence metals_and_mining data digital power grid system integrates flexible resource traditional power source distributed power source characteristic high time variability high complexity urgently need cross domain data support however traditional evaluation method rsquo evaluate cross domain data targeted effective practicality need improved paper analyzes cross domain intelligent construction business service requirement characteristic power grid digital cross domain data study internal coupling relationship digital system application function cross domain data proposes coupling evaluation model measure digital system cross domain data research process cross domain data mining cluster similarity measurement historical data feature mining technology achieve historical cross domain data feature analysis study fitting analysis technology use correlation analysis regression analysis achieve fitting analysis spanning data support technical economic analysis spanning data power grid digital system copy 2023 author exclusive license springer nature singapore pte ltd,digital power grid system integrates flexible resource traditional power source distributed power source characteristic high time variability high complexity urgently need cross domain data support however traditional evaluation method rsquo evaluate cross domain data targeted effective practicality need improved paper analyzes cross domain intelligent construction business service requirement characteristic power grid digital cross domain data study internal coupling relationship digital system application function cross domain data proposes coupling evaluation model measure digital system cross domain data research process cross domain data mining cluster similarity measurement historical data feature mining technology achieve historical cross domain data feature analysis study fitting analysis technology use correlation analysis regression analysis achieve fitting analysis spanning data support technical economic analysis spanning data power grid digital system copy 2023 author exclusive license springer nature singapore pte ltddata_handling data_mining regression_analysiscross_domain_data_analyse cross domain data_feature data_mining_technology digital_project digital_system economics_evaluations power_grid_system power_grids technical_evaluation
480,An Ensemble Approach for Histopathological Classification of Vulvar Cancer,"Mushunuri, R. V., Choschzick, M., Braumann, U.-D., & Hess, J. (2023). An ensemble approach for histopathological classification of vulvar cancer. Medical Imaging 2023: Digital and Computational Pathology. https://doi.org/10.1117/12.2653858
",10.1117/12.2653858,"Light microscopy of tissue slides is an important tool for analyzing human diseases including cancer. In this work, we focus on classifying patches from a immunohistochemically stained tissue microarray (TMA) of vulvar cancer. We propose a novel ensemble-based deep learning technique to classify patches of tissue as cancerous, stroma, both, or none. Our ensemble model consists of a pre-trained data-efficient image transformer (DeiT) module to extract features of patches followed by a transformer block and graph convolutional networks (GCN). Transformer blocks aid the sequential learning of the extracted features from DeiT while the graph convolutional network (GCN) extracts neighborhood information. Our approach combines both methods for classification. In the evaluation, we show that our approach outperforms state-of-the-art architectures for the addressed application. We also show that is applicable when only small amounts of labelled data are available. &copy; 2023 SPIE.",461.2 Biological Materials and Tissue Engineering;461.4 Ergonomics and Human Factors Engineering;716.1 Information Theory and Signal Processing;723.2 Data Processing and Image Processing;723.4 Artificial Intelligence,Convolutional networks;Ensemble approaches;Ensemble-based deep learning;Graph neural networks;Human disease;Image transformers;Immunohistochemistry;Transformer network;Vulvar cancer;Whole slide images,Convolution;Convolutional neural networks;Deep learning;Diseases;Image classification;Learning systems;Tissue,2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Mushunuri, Raghava Vinaykanth; (3) Choschzick, Matthias; (1) Braumann, Ulf-Dietrich; (1) Hess, Juergen; ","(1) Fraunhofer Center for Microelectronic and Optical Systems for Biomedicine (MEOS), Herman-Hollerith-Stra&szlig;e 3, Erfurt; 99099, Germany; (2) Virtual and Augmented Reality Group, Faculty of Computer Science, Otto-Von-Guericke University (OvGU) Magdeburg, Universit&auml;tsplatz 2, Magdeburg; 39106, Germany; (3) Institute of Pathology and Molecular Pathology, University Hospital Zurich (USZ), R&auml;mistrasse 100, Z&uuml;rich; 8091, Switzerland; (4) Fraunhofer Institute for Cell Therapy and Immunology (IZI), Perlickstra&szlig;e 1, Leipzig; 04103, Germany; (5) Institute for Applied Informatics (InfAI), The University Leipzig, Goerdelerring 9, Leipzig; 04109, Germany; (6) Institute for Medical Informatics, Statistics and Epidemiology (IMISE), Medical Faculty, University Leipzig, H&auml;rtelstra&szlig;e 16-18, Leipzig; 04107, Germany; (7) Interdisciplinary Centre for Bioinformatics (IZBI), University Leipzig, H&auml;rtelstra&szlig;e 16-18, Leipzig; 04107, Germany; (8) Fraunhofer Institute for Applied Optics and Precision Engineering (IOF), Albert-Einstein-Stra&szlig;e 7, Jena; 07745, Germany; ",SPIE,-1,"[""convolution"", ""convolutional neural networks"", ""deep learning"", ""diseases"", ""image classification"", ""learning systems"", ""tissue""]","[""convolution"", ""convolutional neural networks"", ""deep learning"", ""diseases"", ""image classification"", ""learning systems"", ""tissue""]",convolution;convolutional neural networks;deep learning;diseases;image classification;learning systems;tissue,computer vision;education;medical;artificial intelligence;networks,technology;industries,computer vision;education;medical;artificial intelligence;networks,technology;industries,convolution convolutional_neural_networks deep_learning diseases image_classification learning_systems tissue convolutional_networks ensemble_approaches ensemble based_deep_learning graph_neural_networks human_disease image_transformers immunohistochemistry transformer_network vulvar_cancer whole_slide_images 461 2_biological_materials_and_tissue_engineering 461 4_ergonomics_and_human_factors_engineering 716 1_information_theory_and_signal_processing 723 2_data_processing_and_image_processing 723 4_artificial_intelligence computer_vision education medical artificial_intelligence networks,convolution convolutional_neural_networks deep_learning diseases image_classification learning_systems tissue,convolutional_networks ensemble_approaches ensemble based_deep_learning graph_neural_networks human_disease image_transformers immunohistochemistry transformer_network vulvar_cancer whole_slide_images,light microscopy tissue slide important tool analyzing human disease including cancer work focus classifying patch immunohistochemically stained tissue microarray tma vulvar cancer propose novel ensemble based deep learning technique classify patch tissue cancerous stroma none ensemble model consists pre trained data efficient image transformer deit module extract feature patch followed transformer block graph convolutional network gcn transformer block aid sequential learning extracted feature deit graph convolutional network gcn extract neighborhood information approach combine method classification evaluation show approach outperforms state art architecture addressed application also show applicable small amount labelled data available copy 2023 spie,convolution convolutional_neural_networks deep_learning diseases image_classification learning_systems tissue convolutional_networks ensemble_approaches ensemble based_deep_learning graph_neural_networks human_disease image_transformers immunohistochemistry transformer_network vulvar_cancer whole_slide_images 461 2_biological_materials_and_tissue_engineering 461 4_ergonomics_and_human_factors_engineering 716 1_information_theory_and_signal_processing 723 2_data_processing_and_image_processing 723 4_artificial_intelligence computer_vision education medical artificial_intelligence networks light microscopy tissue slide important tool analyzing human disease including cancer work focus classifying patch immunohistochemically stained tissue microarray tma vulvar cancer propose novel ensemble based deep learning technique classify patch tissue cancerous stroma none ensemble model consists pre trained data efficient image transformer deit module extract feature patch followed transformer block graph convolutional network gcn transformer block aid sequential learning extracted feature deit graph convolutional network gcn extract neighborhood information approach combine method classification evaluation show approach outperforms state art architecture addressed application also show applicable small amount labelled data available copy 2023 spie,light microscopy tissue slide important tool analyzing human disease including cancer work focus classifying patch immunohistochemically stained tissue microarray tma vulvar cancer propose novel ensemble based deep learning technique classify patch tissue cancerous stroma none ensemble model consists pre trained data efficient image transformer deit module extract feature patch followed transformer block graph convolutional network gcn transformer block aid sequential learning extracted feature deit graph convolutional network gcn extract neighborhood information approach combine method classification evaluation show approach outperforms state art architecture addressed application also show applicable small amount labelled data available copy 2023 spieconvolution convolutional_neural_networks deep_learning diseases image_classification learning_systems tissueconvolutional_networks ensemble_approaches ensemble based_deep_learning graph_neural_networks human_disease image_transformers immunohistochemistry transformer_network vulvar_cancer whole_slide_images
481,RGB LED matrix display for augmented driving for higher traffic safety,"Blankenbach, K., Eisenhardt, M., Brezing, K., & Reichel, S. (2023). RGB LED matrix display for augmented driving for higher traffic safety. Advances in Display Technologies XIII. https://doi.org/10.1117/12.2648294
",10.1117/12.2648294,"Augmentation in manually driven vehicles can raise traffic safety significantly. The most ergonomic (eyes -on-the-road, no refocusing) solution is AR-HUD but the FOV is limited today to 10&deg; by 5&deg;. Transparent displays in the windshield (eyes-on-the-road, refocusing required) are costly (replacement) and hardly meet legal requirements for transparency. The cheapest solution is video-AR on dashboard displays (eyes-off-the-road, refocusing required). We report on a new approach for augmentation as compromise between ergonomics and cost: An 8-line RGB matrix display to be mounted on top of the dashboard at the bottom of the windshield. It spreads from pillar -to-pillar (150 cm, 150 x 8 pixel, RGB LED) and therefore enables augmented information along the whole windshield. In consequence, it needs less eyes-off-the road and refocusing and is a very ergonomic add-on for video-AR. We started with a single line pixelated light guide in a seating buck to measure and to evaluate the required luminance (&gt; 3,300 cd/m2) RGB luminance ratio (35:50:15) and perception of information from night to blinding sunlight. We optimized the RGB LED display by testing and measuring various diffusers at different distances to the LEDs for an optimum combination of sharpness and pixelation. Image quality and content such as the visualization of actual speed (including color-coding), warnings (e.g. slippery), navigation, and comfort functions (e.g. incoming call, beat mode) were evaluated by subjects via online survey and in our seating buck. The display was rated as being very helpful with significantly reduction in time for grasping the information. &copy; 2023 SPIE.","406.2 Roads and Streets;714.2 Semiconductor Devices and Integrated Circuits;722.2 Computer Peripheral Equipment;723 Computer Software, Data Handling and Applications;914.1 Accidents and Accident Prevention",Automotives;Contrast;Diffuser;Legal requirements;Manually driven vehicles;Matrix display;RGB LED;RGB LED matrix;Traffic safety;Transparent displays,Accident prevention;Display devices;Ergonomics;Light emitting diodes;Luminance;Roads and streets;Windshields,2023,Conference article (CA),Proc SPIE Int Soc Opt Eng,"(1) Blankenbach, Karlheinz; (1) Eisenhardt, M.; (1) Brezing, K.; (1) Reichel, Steffen; ","(1) Pforzheim University, Display Lab, Pforzheim; 75175, Germany; ",SPIE,-1,"[""accident prevention"", ""display devices"", ""ergonomics"", ""light emitting diodes"", ""luminance"", ""roads and streets"", ""windshields""]","[""accident prevention"", ""display devices"", ""ergonomics"", ""light emitting diodes"", ""luminance"", ""roads and streets"", ""windshields""]",accident prevention;display devices;ergonomics;light emitting diodes;luminance;roads and streets;windshields,"farming and natural science;graphics;input;transportation;automotive;inspection, safety and quality;display technology;human factors",displays;end users and user experience;industries;use cases;technology,"farming and natural science;graphics;input;transportation;automotive;inspection, safety and quality;display technology;human factors",displays;end users and user experience;industries;use cases;technology,accident_prevention display_devices ergonomics light_emitting_diodes luminance roads_and_streets windshields automotives contrast diffuser legal_requirements manually_driven_vehicles matrix_display rgb_led rgb_led_matrix traffic_safety transparent_displays 406 2_roads_and_streets 714 2_semiconductor_devices_and_integrated_circuits 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 914 1_accidents_and_accident_prevention farming_and_natural_science graphics input transportation automotive inspection _safety_and_quality display_technology human_factors,accident_prevention display_devices ergonomics light_emitting_diodes luminance roads_and_streets windshields,automotives contrast diffuser legal_requirements manually_driven_vehicles matrix_display rgb_led rgb_led_matrix traffic_safety transparent_displays,augmentation manually driven vehicle raise traffic safety significantly ergonomic eye road refocusing solution ar hud fov limited today 10 deg 5 deg transparent display windshield eye road refocusing required costly replacement hardly meet legal requirement transparency cheapest solution video ar dashboard display eye road refocusing required report new approach augmentation compromise ergonomics cost 8 line rgb matrix display mounted top dashboard bottom windshield spread pillar pillar 150 cm 150 x 8 pixel rgb led therefore enables augmented information along whole windshield consequence need le eye road refocusing ergonomic add video ar started single line pixelated light guide seating buck measure evaluate required luminance gt 3 300 cd m2 rgb luminance ratio 35 50 15 perception information night blinding sunlight optimized rgb led display testing measuring various diffuser different distance led optimum combination sharpness pixelation image quality content visualization actual speed including color coding warning e g slippery navigation comfort function e g incoming call beat mode evaluated subject via online survey seating buck display rated helpful significantly reduction time grasping information copy 2023 spie,accident_prevention display_devices ergonomics light_emitting_diodes luminance roads_and_streets windshields automotives contrast diffuser legal_requirements manually_driven_vehicles matrix_display rgb_led rgb_led_matrix traffic_safety transparent_displays 406 2_roads_and_streets 714 2_semiconductor_devices_and_integrated_circuits 722 2_computer_peripheral_equipment 723_computer_software _data_handling_and_applications 914 1_accidents_and_accident_prevention farming_and_natural_science graphics input transportation automotive inspection _safety_and_quality display_technology human_factors augmentation manually driven vehicle raise traffic safety significantly ergonomic eye road refocusing solution ar hud fov limited today 10 deg 5 deg transparent display windshield eye road refocusing required costly replacement hardly meet legal requirement transparency cheapest solution video ar dashboard display eye road refocusing required report new approach augmentation compromise ergonomics cost 8 line rgb matrix display mounted top dashboard bottom windshield spread pillar pillar 150 cm 150 x 8 pixel rgb led therefore enables augmented information along whole windshield consequence need le eye road refocusing ergonomic add video ar started single line pixelated light guide seating buck measure evaluate required luminance gt 3 300 cd m2 rgb luminance ratio 35 50 15 perception information night blinding sunlight optimized rgb led display testing measuring various diffuser different distance led optimum combination sharpness pixelation image quality content visualization actual speed including color coding warning e g slippery navigation comfort function e g incoming call beat mode evaluated subject via online survey seating buck display rated helpful significantly reduction time grasping information copy 2023 spie,augmentation manually driven vehicle raise traffic safety significantly ergonomic eye road refocusing solution ar hud fov limited today 10 deg 5 deg transparent display windshield eye road refocusing required costly replacement hardly meet legal requirement transparency cheapest solution video ar dashboard display eye road refocusing required report new approach augmentation compromise ergonomics cost 8 line rgb matrix display mounted top dashboard bottom windshield spread pillar pillar 150 cm 150 x 8 pixel rgb led therefore enables augmented information along whole windshield consequence need le eye road refocusing ergonomic add video ar started single line pixelated light guide seating buck measure evaluate required luminance gt 3 300 cd m2 rgb luminance ratio 35 50 15 perception information night blinding sunlight optimized rgb led display testing measuring various diffuser different distance led optimum combination sharpness pixelation image quality content visualization actual speed including color coding warning e g slippery navigation comfort function e g incoming call beat mode evaluated subject via online survey seating buck display rated helpful significantly reduction time grasping information copy 2023 spieaccident_prevention display_devices ergonomics light_emitting_diodes luminance roads_and_streets windshieldsautomotives contrast diffuser legal_requirements manually_driven_vehicles matrix_display rgb_led rgb_led_matrix traffic_safety transparent_displays
482,Rapid Identification of Herbaceous Biomass Based on Raman Spectrum Analysis,"Li, Q., Ye, Z., Liang, H., Yu, Z., Fang, Z., Cai, G., Zheng, Q., Yan, L., Zhong, H., Xiong, Z., Xu, J., & Liu, Z. (2023). Rapid Identification of Herbaceous Biomass Based on Raman Spectrum Analysis. Smart Innovation, Systems and Technologies, 213–226. https://doi.org/10.1007/978-981-99-1230-8_19
",10.1007/978-981-99-1230-8_19,"To realize the rapid online identification of tobacco quality style in a few seconds, this paper proposed a rapid identification method of tobacco quality style based on the Raman spectrum analysis. This method could quickly obtain the Raman spectrum of tobacco samples, then establish the mapping relationship database between the tobacco information and the Raman signal. The KNN (K-Nearest Neighbors) algorithm as the identification algorithm of tobacco information was used. The rapid and accurate identification of tobacco origin through the Raman signal in the range of 2700&ndash;3500&nbsp;cm&minus;1 was realized. The accuracy of origin identification can reach 95.7%. To identify the tobacco grade accurately, the competitive adaptive weighted sampling (CARS) was used to select the key Raman characteristic spectral coverage that determines the acteristics of tobacco grade. Combined with the KNN algorithm, the rapid and accurate identification of tobacco grades by analyzing the signals of key Raman characteristic spectral coverage was realized. By using the key Raman characteristic spectral coverage in the range of 800&ndash;800&nbsp;cm&minus;1 and 2700&ndash;3500&nbsp;cm&minus;1, the accuracy of tobacco grade identification can reach 87.0%. The results showed that by analyzing the key Raman characteristic band signals of unknown tobacco samples, combined with the identification algorithm proposed in this paper, the efficient identification of the quality style of unknown tobacco can be realized. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",723.4.2 Machine Learning;741.1 Light/Optics;821.4 Agricultural Products;903.1 Information Sources and Analysis;913.3 Quality Assurance and Control;921.5 Optimization Techniques;922 Statistical Methods,Component;Formatting;Raman characteristics;Raman signal;Rapid identification;Spectra analysis;Spectral coverage;Style;Styling;Tobacco samples,Discriminant analysis;Learning algorithms;Nearest neighbor search;Quality control;Raman scattering;Raman spectroscopy;Spectrum analysis,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Li, Qiaoling; (1) Ye, Zhongli; (1) Liang, Hui; (1) Yu, Zhiqiang; (2) Fang, Zhou; (1) Cai, Guohua; (1) Zheng, Quanxing; (1) Yan, Li; (1) Zhong, Hongxiang; (2) Xiong, Zhe; (2) Xu, Jun; (1) Liu, Zechun; ","(1) Technology Center, China Tobacco Fujian Industrial Co., Ltd., Xiamen, China; (2) School of Energy and Power Engineering, Huazhong University of Science and Technology, Wuhan, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""discriminant analysis"", ""learning algorithms"", ""nearest neighbor search"", ""quality control"", ""raman scattering"", ""raman spectroscopy"", ""spectrum analysis""]","[""discriminant analysis"", ""learning algorithms"", ""nearest neighbor search"", ""quality control"", ""raman scattering"", ""raman spectroscopy"", ""spectrum analysis""]",discriminant analysis;learning algorithms;nearest neighbor search;quality control;raman scattering;raman spectroscopy;spectrum analysis,"other;input;medical;inspection, safety and quality;artificial intelligence",technology;other;use cases;industries,"other;input;medical;inspection, safety and quality;artificial intelligence",technology;other;use cases;industries,discriminant_analysis learning_algorithms nearest_neighbor_search quality_control raman_scattering raman_spectroscopy spectrum_analysis component formatting raman_characteristics raman_signal rapid_identification spectra_analysis spectral_coverage style styling tobacco_samples 723 4 2_machine_learning 741 1_light optics 821 4_agricultural_products 903 1_information_sources_and_analysis 913 3_quality_assurance_and_control 921 5_optimization_techniques 922_statistical_methods other input medical inspection _safety_and_quality artificial_intelligence,discriminant_analysis learning_algorithms nearest_neighbor_search quality_control raman_scattering raman_spectroscopy spectrum_analysis,component formatting raman_characteristics raman_signal rapid_identification spectra_analysis spectral_coverage style styling tobacco_samples,realize rapid online identification tobacco quality style second paper proposed rapid identification method tobacco quality style based raman spectrum analysis method could quickly obtain raman spectrum tobacco sample establish mapping relationship database tobacco information raman signal knn k nearest neighbor algorithm identification algorithm tobacco information used rapid accurate identification tobacco origin raman signal range 2700 ndash 3500 nbsp cm minus 1 realized accuracy origin identification reach 95 7 identify tobacco grade accurately competitive adaptive weighted sampling car used select key raman characteristic spectral coverage determines acteristics tobacco grade combined knn algorithm rapid accurate identification tobacco grade analyzing signal key raman characteristic spectral coverage realized using key raman characteristic spectral coverage range 800 ndash 800 nbsp cm minus 1 2700 ndash 3500 nbsp cm minus 1 accuracy tobacco grade identification reach 87 0 result showed analyzing key raman characteristic band signal unknown tobacco sample combined identification algorithm proposed paper efficient identification quality style unknown tobacco realized copy 2023 author exclusive license springer nature singapore pte ltd,discriminant_analysis learning_algorithms nearest_neighbor_search quality_control raman_scattering raman_spectroscopy spectrum_analysis component formatting raman_characteristics raman_signal rapid_identification spectra_analysis spectral_coverage style styling tobacco_samples 723 4 2_machine_learning 741 1_light optics 821 4_agricultural_products 903 1_information_sources_and_analysis 913 3_quality_assurance_and_control 921 5_optimization_techniques 922_statistical_methods other input medical inspection _safety_and_quality artificial_intelligence realize rapid online identification tobacco quality style second paper proposed rapid identification method tobacco quality style based raman spectrum analysis method could quickly obtain raman spectrum tobacco sample establish mapping relationship database tobacco information raman signal knn k nearest neighbor algorithm identification algorithm tobacco information used rapid accurate identification tobacco origin raman signal range 2700 ndash 3500 nbsp cm minus 1 realized accuracy origin identification reach 95 7 identify tobacco grade accurately competitive adaptive weighted sampling car used select key raman characteristic spectral coverage determines acteristics tobacco grade combined knn algorithm rapid accurate identification tobacco grade analyzing signal key raman characteristic spectral coverage realized using key raman characteristic spectral coverage range 800 ndash 800 nbsp cm minus 1 2700 ndash 3500 nbsp cm minus 1 accuracy tobacco grade identification reach 87 0 result showed analyzing key raman characteristic band signal unknown tobacco sample combined identification algorithm proposed paper efficient identification quality style unknown tobacco realized copy 2023 author exclusive license springer nature singapore pte ltd,realize rapid online identification tobacco quality style second paper proposed rapid identification method tobacco quality style based raman spectrum analysis method could quickly obtain raman spectrum tobacco sample establish mapping relationship database tobacco information raman signal knn k nearest neighbor algorithm identification algorithm tobacco information used rapid accurate identification tobacco origin raman signal range 2700 ndash 3500 nbsp cm minus 1 realized accuracy origin identification reach 95 7 identify tobacco grade accurately competitive adaptive weighted sampling car used select key raman characteristic spectral coverage determines acteristics tobacco grade combined knn algorithm rapid accurate identification tobacco grade analyzing signal key raman characteristic spectral coverage realized using key raman characteristic spectral coverage range 800 ndash 800 nbsp cm minus 1 2700 ndash 3500 nbsp cm minus 1 accuracy tobacco grade identification reach 87 0 result showed analyzing key raman characteristic band signal unknown tobacco sample combined identification algorithm proposed paper efficient identification quality style unknown tobacco realized copy 2023 author exclusive license springer nature singapore pte ltddiscriminant_analysis learning_algorithms nearest_neighbor_search quality_control raman_scattering raman_spectroscopy spectrum_analysiscomponent formatting raman_characteristics raman_signal rapid_identification spectra_analysis spectral_coverage style styling tobacco_samples
483,f<sup>2</sup>-ToF: A feature-alignment and frequency-division time-of-flight data denoise network,"Tong, Y., Chen, J., Leng, Z., Liu, B., & Wang, Y. (2023). <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" display=""inline"" id=""d1e930"" altimg=""si53.svg""><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math>-ToF: A feature-alignment and frequency-division time-of-flight data denoise network. Computer Communications, 207, 66–76. https://doi.org/10.1016/j.comcom.2023.04.033
",10.1016/j.comcom.2023.04.033,"Infrared wave time-of-flight (ToF) imaging is a important method to sense the 3D information of scene for Internet of Things (IoT) and artificial intelligent (AI). Driven by heavy demands from industry and users, ToF imaging has received significant research attention in recent year, but the artifacts of depth image still remain and need to be improved. Removing multiple artifacts of ToF data is usually treated as a multi-stage stitching problem for deep learning methods. However, the multi-stage cascade and cross-domain refinement architecture could increase the difficulty of model fitting and hurt the effect of noise reduction. In this paper, we classify the artifacts of ToF data as temporal-related or modulation frequency-related noise and propose a ToF denoising convolutional neural network (f2-ToF) to reduce multiple artifacts simultaneously. Specifically, a frequency-division structure is designed to reduce the influence of frequency-related noise in different modulation frequencies. For efficient correcting misalignment data and ensuring a one-stage end-to-end training, the feature-wise alignment module is proposed. In experiments, every proposed module effectively performed its designed task, and the whole framework achieved strong performance in ToF image refinement. &copy; 2023 Elsevier B.V.","461.4 Ergonomics and Human Factors Engineering;722.3 Data Communication, Equipment and Techniques;723 Computer Software, Data Handling and Applications;723.5 Computer Applications;741.2 Vision;751.4 Acoustic Noise",De-Noise;Deep learning;Feature frequencies;Frequency division;Modulation frequencies;Multi-stages;Time-of flight;Time-of-flight data;Time-of-flight data denoise;Time-of-flight imaging,Computer vision;Convolutional neural networks;Deep learning;Frequency modulation;Image enhancement;Internet of things;Learning systems,2023,Journal article (JA),Comput Commun,"(1) Tong, Yanfeng; (1) Chen, Jing; (1) Leng, Zhen; (1) Liu, Bo; (1) Wang, Yongtian; ","(1) National Engineering Laboratory of Virtual Reality and Augmented Reality, School of Optics and Photonics, Beijing Institute of Technology, Beijing, 100081, China; ",Elsevier B.V.,-1,"[""computer vision"", ""convolutional neural networks"", ""deep learning"", ""frequency modulation"", ""image enhancement"", ""internet of things"", ""learning systems""]","[""computer vision"", ""convolutional neural networks"", ""deep learning"", ""frequency modulation"", ""image enhancement"", ""internet of things"", ""learning systems""]",computer vision;convolutional neural networks;deep learning;frequency modulation;image enhancement;internet of things;learning systems,computer vision;education;medical;power and energy;internet of things;artificial intelligence;networks,technology;industries,computer vision;education;medical;power and energy;internet of things;artificial intelligence;networks,technology;industries,computer_vision convolutional_neural_networks deep_learning frequency_modulation image_enhancement internet_of_things learning_systems de noise deep_learning feature_frequencies frequency_division modulation_frequencies multi stages time of_flight time of flight_data time of flight_data_denoise time of flight_imaging 461 4_ergonomics_and_human_factors_engineering 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 723 5_computer_applications 741 2_vision 751 4_acoustic_noise computer_vision education medical power_and_energy internet_of_things artificial_intelligence networks,computer_vision convolutional_neural_networks deep_learning frequency_modulation image_enhancement internet_of_things learning_systems,de noise deep_learning feature_frequencies frequency_division modulation_frequencies multi stages time of_flight time of flight_data time of flight_data_denoise time of flight_imaging,infrared wave time flight tof imaging important method sense 3d information scene internet thing iot artificial intelligent ai driven heavy demand industry user tof imaging received significant research attention recent year artifact depth image still remain need improved removing multiple artifact tof data usually treated multi stage stitching problem deep learning method however multi stage cascade cross domain refinement architecture could increase difficulty model fitting hurt effect noise reduction paper classify artifact tof data temporal related modulation frequency related noise propose tof denoising convolutional neural network f2 tof reduce multiple artifact simultaneously specifically frequency division structure designed reduce influence frequency related noise different modulation frequency efficient correcting misalignment data ensuring one stage end end training feature wise alignment module proposed experiment every proposed module effectively performed designed task whole framework achieved strong performance tof image refinement copy 2023 elsevier b v,computer_vision convolutional_neural_networks deep_learning frequency_modulation image_enhancement internet_of_things learning_systems de noise deep_learning feature_frequencies frequency_division modulation_frequencies multi stages time of_flight time of flight_data time of flight_data_denoise time of flight_imaging 461 4_ergonomics_and_human_factors_engineering 722 3_data_communication _equipment_and_techniques 723_computer_software _data_handling_and_applications 723 5_computer_applications 741 2_vision 751 4_acoustic_noise computer_vision education medical power_and_energy internet_of_things artificial_intelligence networks infrared wave time flight tof imaging important method sense 3d information scene internet thing iot artificial intelligent ai driven heavy demand industry user tof imaging received significant research attention recent year artifact depth image still remain need improved removing multiple artifact tof data usually treated multi stage stitching problem deep learning method however multi stage cascade cross domain refinement architecture could increase difficulty model fitting hurt effect noise reduction paper classify artifact tof data temporal related modulation frequency related noise propose tof denoising convolutional neural network f2 tof reduce multiple artifact simultaneously specifically frequency division structure designed reduce influence frequency related noise different modulation frequency efficient correcting misalignment data ensuring one stage end end training feature wise alignment module proposed experiment every proposed module effectively performed designed task whole framework achieved strong performance tof image refinement copy 2023 elsevier b v,infrared wave time flight tof imaging important method sense 3d information scene internet thing iot artificial intelligent ai driven heavy demand industry user tof imaging received significant research attention recent year artifact depth image still remain need improved removing multiple artifact tof data usually treated multi stage stitching problem deep learning method however multi stage cascade cross domain refinement architecture could increase difficulty model fitting hurt effect noise reduction paper classify artifact tof data temporal related modulation frequency related noise propose tof denoising convolutional neural network f2 tof reduce multiple artifact simultaneously specifically frequency division structure designed reduce influence frequency related noise different modulation frequency efficient correcting misalignment data ensuring one stage end end training feature wise alignment module proposed experiment every proposed module effectively performed designed task whole framework achieved strong performance tof image refinement copy 2023 elsevier b vcomputer_vision convolutional_neural_networks deep_learning frequency_modulation image_enhancement internet_of_things learning_systemsde noise deep_learning feature_frequencies frequency_division modulation_frequencies multi stages time of_flight time of flight_data time of flight_data_denoise time of flight_imaging
484,Graph Convolutional Neural Networks for Drug Target Affinity Prediction in U-Shaped and Skip-Connection Architectures,"Chen, J., Dong, X., & Yang, Z. (2023). Graph Convolutional Neural Networks for Drug Target Affinity Prediction in U-Shaped and Skip-Connection Architectures. Smart Innovation, Systems and Technologies, 271–283. https://doi.org/10.1007/978-981-99-1230-8_24
",10.1007/978-981-99-1230-8_24,"It is common knowledge that traditional new medication development is a costly, drawn-out procedure with greater safety uncertainty. Among them, drug target affinity prediction (DTA) is an important step in drug discovery and drug research. If we can significantly improve the accuracy of DTA prediction, it can help us potentially reduce the cost of new drug design and development significantly. Therefore, drug target affinity prediction is a very important topic. The precise and thorough characterization of medicines and proteins is the key to this subject. With the advancement of deep learning, it has become popular for academics to integrate deep learning into DTA prediction in an effort to increase accuracy. For example, DeepDTA, WideDTA, GraphDTA, etc., which are basically trained using information of drug molecules, information of protein molecules respectively, and does not make good use of their graph relationships as well as graph deep information, and with the increase in depth of the model over the years, what should have been excellent results are hardly excellent training results because of the difficulty of training. Inspired by Unet, this paper proposes a new method, UGraphDTA, which uses a new U-shaped architecture and Skip connection architecture to enable the model to understand deeper graph information. The novelty of this method is the use of skip connections in the convolutional network, which allows the model to utilize both the original molecular graph structure information and the information after convolution of the graph, enhancing the model's prediction ability for DTA tasks. The prediction performance of UGraphDTA is empirically proven to be better than other baseline models. This indicates that our proposed U-shaped convolutional architecture for drug target affinity prediction strategy that mines the deep information of drugs and proteins is effective. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",461.4 Ergonomics and Human Factors Engineering;716.1 Information Theory and Signal Processing;723.4 Artificial Intelligence;801.4 Physical Chemistry;804.1 Organic Compounds;903.3 Information Retrieval and Use;931.3 Atomic and Molecular Physics,Binding affinities;Deep learning;Drug repurposing;Drug targets;Drug-target binding affinity;GCN;Repurposing;Target binding;U-shaped;Unet,Binding energy;Convolution;Convolutional neural networks;Deep learning;Graph neural networks;Information use;Molecules;Network architecture;Proteins,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Chen, Jiale; (1) Dong, Xuelian; (1) Yang, Zhongyuan; ","(1) School of Computer Science, University of South China, Hengyang, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""binding energy"", ""convolution"", ""convolutional neural networks"", ""deep learning"", ""graph neural networks"", ""information use"", ""molecules"", ""network architecture"", ""proteins""]","[""binding energy"", ""convolution"", ""convolutional neural networks"", ""deep learning"", ""graph neural networks"", ""information use"", ""molecules"", ""network architecture"", ""proteins""]",binding energy;convolution;convolutional neural networks;deep learning;graph neural networks;information use;molecules;network architecture;proteins,construction;other;medical;artificial intelligence;business planning and management;networks,technology;other;business;industries,construction;other;medical;artificial intelligence;business planning and management;networks,technology;other;business;industries,binding_energy convolution convolutional_neural_networks deep_learning graph_neural_networks information_use molecules network_architecture proteins binding_affinities deep_learning drug_repurposing drug_targets drug target_binding_affinity gcn repurposing target_binding u shaped unet 461 4_ergonomics_and_human_factors_engineering 716 1_information_theory_and_signal_processing 723 4_artificial_intelligence 801 4_physical_chemistry 804 1_organic_compounds 903 3_information_retrieval_and_use 931 3_atomic_and_molecular_physics construction other medical artificial_intelligence business_planning_and_management networks,binding_energy convolution convolutional_neural_networks deep_learning graph_neural_networks information_use molecules network_architecture proteins,binding_affinities deep_learning drug_repurposing drug_targets drug target_binding_affinity gcn repurposing target_binding u shaped unet,common knowledge traditional new medication development costly drawn procedure greater safety uncertainty among drug target affinity prediction dta important step drug discovery drug research significantly improve accuracy dta prediction help u potentially reduce cost new drug design development significantly therefore drug target affinity prediction important topic precise thorough characterization medicine protein key subject advancement deep learning become popular academic integrate deep learning dta prediction effort increase accuracy example deepdta widedta graphdta etc basically trained using information drug molecule information protein molecule respectively make good use graph relationship well graph deep information increase depth model year excellent result hardly excellent training result difficulty training inspired unet paper proposes new method ugraphdta us new u shaped architecture skip connection architecture enable model understand deeper graph information novelty method use skip connection convolutional network allows model utilize original molecular graph structure information information convolution graph enhancing model prediction ability dta task prediction performance ugraphdta empirically proven better baseline model indicates proposed u shaped convolutional architecture drug target affinity prediction strategy mine deep information drug protein effective copy 2023 author exclusive license springer nature singapore pte ltd,binding_energy convolution convolutional_neural_networks deep_learning graph_neural_networks information_use molecules network_architecture proteins binding_affinities deep_learning drug_repurposing drug_targets drug target_binding_affinity gcn repurposing target_binding u shaped unet 461 4_ergonomics_and_human_factors_engineering 716 1_information_theory_and_signal_processing 723 4_artificial_intelligence 801 4_physical_chemistry 804 1_organic_compounds 903 3_information_retrieval_and_use 931 3_atomic_and_molecular_physics construction other medical artificial_intelligence business_planning_and_management networks common knowledge traditional new medication development costly drawn procedure greater safety uncertainty among drug target affinity prediction dta important step drug discovery drug research significantly improve accuracy dta prediction help u potentially reduce cost new drug design development significantly therefore drug target affinity prediction important topic precise thorough characterization medicine protein key subject advancement deep learning become popular academic integrate deep learning dta prediction effort increase accuracy example deepdta widedta graphdta etc basically trained using information drug molecule information protein molecule respectively make good use graph relationship well graph deep information increase depth model year excellent result hardly excellent training result difficulty training inspired unet paper proposes new method ugraphdta us new u shaped architecture skip connection architecture enable model understand deeper graph information novelty method use skip connection convolutional network allows model utilize original molecular graph structure information information convolution graph enhancing model prediction ability dta task prediction performance ugraphdta empirically proven better baseline model indicates proposed u shaped convolutional architecture drug target affinity prediction strategy mine deep information drug protein effective copy 2023 author exclusive license springer nature singapore pte ltd,common knowledge traditional new medication development costly drawn procedure greater safety uncertainty among drug target affinity prediction dta important step drug discovery drug research significantly improve accuracy dta prediction help u potentially reduce cost new drug design development significantly therefore drug target affinity prediction important topic precise thorough characterization medicine protein key subject advancement deep learning become popular academic integrate deep learning dta prediction effort increase accuracy example deepdta widedta graphdta etc basically trained using information drug molecule information protein molecule respectively make good use graph relationship well graph deep information increase depth model year excellent result hardly excellent training result difficulty training inspired unet paper proposes new method ugraphdta us new u shaped architecture skip connection architecture enable model understand deeper graph information novelty method use skip connection convolutional network allows model utilize original molecular graph structure information information convolution graph enhancing model prediction ability dta task prediction performance ugraphdta empirically proven better baseline model indicates proposed u shaped convolutional architecture drug target affinity prediction strategy mine deep information drug protein effective copy 2023 author exclusive license springer nature singapore pte ltdbinding_energy convolution convolutional_neural_networks deep_learning graph_neural_networks information_use molecules network_architecture proteinsbinding_affinities deep_learning drug_repurposing drug_targets drug target_binding_affinity gcn repurposing target_binding u shaped unet
485,Research on Spam Detection with a Hybrid Machine Learning Model,"Gao, Y., Song, J., Gao, J., Suo, N., Ren, A., Wang, J., & Zhang, K. (2023). Research on Spam Detection with a Hybrid Machine Learning Model. Smart Innovation, Systems and Technologies, 227–235. https://doi.org/10.1007/978-981-99-1230-8_20
",10.1007/978-981-99-1230-8_20,"Since the beginning of the twentieth century, with the rapid development and popularization of computer technology, e-mail has become an indispensable communication tool in people's social life, and greatly simplified people's daily life such as learning and working methods. However, following the rapid development of computer information technology, e-mail brings convenience to people, also generates some spam messages, which seriously threaten and discount the safety of e-mail users. Although the spam detection technology has been deeply studied and widely used, the traditional spam detection methods mostly rely on the static features extracted from the mails while these methods have great limitations and cannot effectively deal with new malicious mail attacks that are complex, aggressive, destructive, and targeted. Thus, with the rapid development of machine learning and artificial intelligence technology, this paper proposed a spam detection model with a hybrid machine learning method: first presented text pre-processing process including word tokenization, removing stop word, and extracting feature vector, then a spam detection classifier based on linear-regression hybrid model with three commonly-used machine learning methods, namely SVM, ANN, and RF, was discussed. The results show that the three models are able to produce a good result, but the hybrid model would present a better performance and demonstrate the effectiveness of the hybrid method. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","723 Computer Software, Data Handling and Applications;901.2 Education",Communication tools;Computer technology;Hybrid machine learning;Hybrid model;Machine learning methods;Machine learning models;Machine-learning;Social life;Spam detection;Twentieth century,Electronic mail;Engineering education;Support vector machines,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) Gao, Yifu; (1) Song, Jiuguang; (1) Gao, Jia; (2) Suo, Na; (1) Ren, An; (3) Wang, Juan; (3) Zhang, Kun; ","(1) The Research Institute of Petroleum Exploration and Development, No. 20 Xueyuan Rd, Beijing; 100083, China; (2) China Petroluem Pipeline Telcom and Electricity Engineering Co., Ltd., No. 49, Jin Guang Rd, Guangyang District, Hebei Province, Langfang, China; (3) Kunlun Digital Technology Co., Ltd., Level 5 Building B2 Block A12, The North Huanghe Street, ChangPing District, Beijing; 100083, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""electronic mail"", ""engineering education"", ""support vector machines""]","[""electronic mail"", ""engineering education"", ""support vector machines""]",electronic mail;engineering education;support vector machines,other;education;artificial intelligence,technology;other;industries,other;education;artificial intelligence,technology;other;industries,electronic_mail engineering_education support_vector_machines communication_tools computer_technology hybrid_machine_learning hybrid_model machine_learning_methods machine_learning_models machine learning social_life spam_detection twentieth_century 723_computer_software _data_handling_and_applications 901 2_education other education artificial_intelligence,electronic_mail engineering_education support_vector_machines,communication_tools computer_technology hybrid_machine_learning hybrid_model machine_learning_methods machine_learning_models machine learning social_life spam_detection twentieth_century,since beginning twentieth century rapid development popularization computer technology e mail become indispensable communication tool people social life greatly simplified people daily life learning working method however following rapid development computer information technology e mail brings convenience people also generates spam message seriously threaten discount safety e mail user although spam detection technology deeply studied widely used traditional spam detection method mostly rely static feature extracted mail method great limitation cannot effectively deal new malicious mail attack complex aggressive destructive targeted thus rapid development machine learning artificial intelligence technology paper proposed spam detection model hybrid machine learning method first presented text pre processing process including word tokenization removing stop word extracting feature vector spam detection classifier based linear regression hybrid model three commonly used machine learning method namely svm ann rf discussed result show three model able produce good result hybrid model would present better performance demonstrate effectiveness hybrid method copy 2023 author exclusive license springer nature singapore pte ltd,electronic_mail engineering_education support_vector_machines communication_tools computer_technology hybrid_machine_learning hybrid_model machine_learning_methods machine_learning_models machine learning social_life spam_detection twentieth_century 723_computer_software _data_handling_and_applications 901 2_education other education artificial_intelligence since beginning twentieth century rapid development popularization computer technology e mail become indispensable communication tool people social life greatly simplified people daily life learning working method however following rapid development computer information technology e mail brings convenience people also generates spam message seriously threaten discount safety e mail user although spam detection technology deeply studied widely used traditional spam detection method mostly rely static feature extracted mail method great limitation cannot effectively deal new malicious mail attack complex aggressive destructive targeted thus rapid development machine learning artificial intelligence technology paper proposed spam detection model hybrid machine learning method first presented text pre processing process including word tokenization removing stop word extracting feature vector spam detection classifier based linear regression hybrid model three commonly used machine learning method namely svm ann rf discussed result show three model able produce good result hybrid model would present better performance demonstrate effectiveness hybrid method copy 2023 author exclusive license springer nature singapore pte ltd,since beginning twentieth century rapid development popularization computer technology e mail become indispensable communication tool people social life greatly simplified people daily life learning working method however following rapid development computer information technology e mail brings convenience people also generates spam message seriously threaten discount safety e mail user although spam detection technology deeply studied widely used traditional spam detection method mostly rely static feature extracted mail method great limitation cannot effectively deal new malicious mail attack complex aggressive destructive targeted thus rapid development machine learning artificial intelligence technology paper proposed spam detection model hybrid machine learning method first presented text pre processing process including word tokenization removing stop word extracting feature vector spam detection classifier based linear regression hybrid model three commonly used machine learning method namely svm ann rf discussed result show three model able produce good result hybrid model would present better performance demonstrate effectiveness hybrid method copy 2023 author exclusive license springer nature singapore pte ltdelectronic_mail engineering_education support_vector_machinescommunication_tools computer_technology hybrid_machine_learning hybrid_model machine_learning_methods machine_learning_models machine learning social_life spam_detection twentieth_century
486,Research on Virtual and Real Spatial Data Interconnection Mapping Technology for Digital Twin,"He, Z., Peng, L., Yu, H., & Wang, H. (2023). Research on Virtual and Real Spatial Data Interconnection Mapping Technology for Digital Twin. Smart Innovation, Systems and Technologies, 77–85. https://doi.org/10.1007/978-981-99-1230-8_7
",10.1007/978-981-99-1230-8_7,"In recent years, distributed photovoltaics, decentralized wind power, new loads, electric vehicles, etc. have been connected to the power grid in a wide range, and the distribution network has become more active, with strong fluctuations, and large peak-to-valley differences. The management and coordination of distributed resources interaction put forward higher requirements. This paper conducts research on the data interconnection and mapping technology of virtual and real space for digital twins. The first step is to study the modeling and driving technology of data interconnection, fusion mechanism model, and information model based on the real twin of the power grid. Coordinate data and monitoring data of main and auxiliary equipment and the data interconnection mechanism of the power grid real scene twin, build a dual-mode driving method that integrates the mechanism model and data model; the second step is to study the power grid ""virtual-real"" space multi-service continuous mapping mechanism and real-time data. The panoramic mapping method realizes the continuous and real-time mapping of point data and surface data to the digital twin and realizes multi-block, multi-level, and multi-type mapping according to the steps of feature extraction, feature matching, model parameter estimation, transformation, and interpolation. The digital twin data is accurately matched; the third step is to study the efficient transmission and update integration technology of twin data in the power grid environment, research methods to improve the real-time and concurrency of data transmission, and research multi-source heterogeneous data dynamic update and integration technology. The fourth step is to study the two-way intelligent cooperation and integration technology of station equipment, realize real-time data interaction and state interaction between the virtual digital model and the real physical model, and realize the interconnection and mapping between the station panoramic model and the virtual and real data. &copy; 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","405.3 Surveying;615.8 Wind Power (Before 1993, use code 611 );706.1 Electric Power Systems;706.1.1 Electric Power Transmission;706.1.2 Electric Power Distribution;723.2 Data Processing and Image Processing;901 Engineering Profession;921.2 Calculus",Data interconnect;Data interconnect mapping;Fake and real data;Integration technologies;Mechanism modeling;Photovoltaics;Power grids;Real-space;Real-time data;Spatial data,Auxiliary equipment;Data integration;Electric loads;Electric power distribution;Electric power system interconnection;Electric power transmission;Electric power transmission networks;Integration;Metadata;Wind power,2023,Conference article (CA),Smart Innov. Syst. Technol.,"(1) He, Zhimin; (1) Peng, Lin; (1) Yu, Hai; (1) Wang, He; ","(1) State Grid Smart Grid Research Institute Co.,LTD, Jiangsu, Nanjing; 210003, China; (2) State Grid Laboratory of Power cyber-Security Protection and Monitoring Technology, Nanjing,Jiangsu; 210003, China; ",Springer Science and Business Media Deutschland GmbH,-1,"[""auxiliary equipment"", ""data integration"", ""electric loads"", ""electric power distribution"", ""electric power system interconnection"", ""electric power transmission"", ""electric power transmission networks"", ""integration"", ""metadata"", ""wind power""]","[""auxiliary equipment"", ""data integration"", ""electric loads"", ""electric power distribution"", ""electric power system interconnection"", ""electric power transmission"", ""electric power transmission networks"", ""integration"", ""metadata"", ""wind power""]",auxiliary equipment;data integration;electric loads;electric power distribution;electric power system interconnection;electric power transmission;electric power transmission networks;integration;metadata;wind power,education;farming and natural science;other;power and energy;developers;data;integration,technology;other;business;industries,education;farming and natural science;other;power and energy;developers;data;integration,technology;other;business;industries,auxiliary_equipment data_integration electric_loads electric_power_distribution electric_power_system_interconnection electric_power_transmission electric_power_transmission_networks integration metadata wind_power data_interconnect data_interconnect_mapping fake_and_real_data integration_technologies mechanism_modeling photovoltaics power_grids real space real time_data spatial_data 405 3_surveying 615 8_wind_power_ before_1993 _use_code_611_ 706 1_electric_power_systems 706 1 1_electric_power_transmission 706 1 2_electric_power_distribution 723 2_data_processing_and_image_processing 901_engineering_profession 921 2_calculus education farming_and_natural_science other power_and_energy developers data integration,auxiliary_equipment data_integration electric_loads electric_power_distribution electric_power_system_interconnection electric_power_transmission electric_power_transmission_networks integration metadata wind_power,data_interconnect data_interconnect_mapping fake_and_real_data integration_technologies mechanism_modeling photovoltaics power_grids real space real time_data spatial_data,recent year distributed photovoltaics decentralized wind power new load electric vehicle etc connected power grid wide range distribution network become active strong fluctuation large peak valley difference management coordination distributed resource interaction put forward higher requirement paper conduct research data interconnection mapping technology virtual real space digital twin first step study modeling driving technology data interconnection fusion mechanism model information model based real twin power grid coordinate data monitoring data main auxiliary equipment data interconnection mechanism power grid real scene twin build dual mode driving method integrates mechanism model data model second step study power grid virtual real space multi service continuous mapping mechanism real time data panoramic mapping method realizes continuous real time mapping point data surface data digital twin realizes multi block multi level multi type mapping according step feature extraction feature matching model parameter estimation transformation interpolation digital twin data accurately matched third step study efficient transmission update integration technology twin data power grid environment research method improve real time concurrency data transmission research multi source heterogeneous data dynamic update integration technology fourth step study two way intelligent cooperation integration technology station equipment realize real time data interaction state interaction virtual digital model real physical model realize interconnection mapping station panoramic model virtual real data copy 2023 author exclusive license springer nature singapore pte ltd,auxiliary_equipment data_integration electric_loads electric_power_distribution electric_power_system_interconnection electric_power_transmission electric_power_transmission_networks integration metadata wind_power data_interconnect data_interconnect_mapping fake_and_real_data integration_technologies mechanism_modeling photovoltaics power_grids real space real time_data spatial_data 405 3_surveying 615 8_wind_power_ before_1993 _use_code_611_ 706 1_electric_power_systems 706 1 1_electric_power_transmission 706 1 2_electric_power_distribution 723 2_data_processing_and_image_processing 901_engineering_profession 921 2_calculus education farming_and_natural_science other power_and_energy developers data integration recent year distributed photovoltaics decentralized wind power new load electric vehicle etc connected power grid wide range distribution network become active strong fluctuation large peak valley difference management coordination distributed resource interaction put forward higher requirement paper conduct research data interconnection mapping technology virtual real space digital twin first step study modeling driving technology data interconnection fusion mechanism model information model based real twin power grid coordinate data monitoring data main auxiliary equipment data interconnection mechanism power grid real scene twin build dual mode driving method integrates mechanism model data model second step study power grid virtual real space multi service continuous mapping mechanism real time data panoramic mapping method realizes continuous real time mapping point data surface data digital twin realizes multi block multi level multi type mapping according step feature extraction feature matching model parameter estimation transformation interpolation digital twin data accurately matched third step study efficient transmission update integration technology twin data power grid environment research method improve real time concurrency data transmission research multi source heterogeneous data dynamic update integration technology fourth step study two way intelligent cooperation integration technology station equipment realize real time data interaction state interaction virtual digital model real physical model realize interconnection mapping station panoramic model virtual real data copy 2023 author exclusive license springer nature singapore pte ltd,recent year distributed photovoltaics decentralized wind power new load electric vehicle etc connected power grid wide range distribution network become active strong fluctuation large peak valley difference management coordination distributed resource interaction put forward higher requirement paper conduct research data interconnection mapping technology virtual real space digital twin first step study modeling driving technology data interconnection fusion mechanism model information model based real twin power grid coordinate data monitoring data main auxiliary equipment data interconnection mechanism power grid real scene twin build dual mode driving method integrates mechanism model data model second step study power grid virtual real space multi service continuous mapping mechanism real time data panoramic mapping method realizes continuous real time mapping point data surface data digital twin realizes multi block multi level multi type mapping according step feature extraction feature matching model parameter estimation transformation interpolation digital twin data accurately matched third step study efficient transmission update integration technology twin data power grid environment research method improve real time concurrency data transmission research multi source heterogeneous data dynamic update integration technology fourth step study two way intelligent cooperation integration technology station equipment realize real time data interaction state interaction virtual digital model real physical model realize interconnection mapping station panoramic model virtual real data copy 2023 author exclusive license springer nature singapore pte ltdauxiliary_equipment data_integration electric_loads electric_power_distribution electric_power_system_interconnection electric_power_transmission electric_power_transmission_networks integration metadata wind_powerdata_interconnect data_interconnect_mapping fake_and_real_data integration_technologies mechanism_modeling photovoltaics power_grids real space real time_data spatial_data
487,Text-driven object affordance for guiding grasp-type recognition in multimodal robot teaching,"Wake, N., Saito, D., Sasabuchi, K., Koike, H., & Ikeuchi, K. (2023). Text-driven object affordance for guiding grasp-type recognition in multimodal robot teaching. Machine Vision and Applications, 34(4). https://doi.org/10.1007/s00138-023-01408-z
",10.1007/s00138-023-01408-z,"In robot teaching, the grasping strategies taught to robots by users are critical information, because these strategies contain the implicit knowledge necessary to successfully perform a series of manipulations; however, limited practical knowledge exists on how to utilize linguistic information for supporting grasp-type recognition in multimodal teaching. This study focused on the effects of text-driven object affordance&mdash;a prior distribution of grasp types for each object&mdash;on image-based grasp-type recognition. To this end, we created the datasets of first-person grasping-hand images labeled with grasp types and object names and tested if the object affordance enhanced the performance of image-based recognition. We evaluated two scenarios with real and illusory objects to be grasped, considering a teaching condition in mixed reality, where the lack of visual object information can make image-based recognition challenging. The results show that object affordance guided the image-based recognition in two scenarios, that is, increasing the recognition accuracy by (1) excluding the unlikely grasp types from the candidates and (2) enhancing the likely grasp types. Additionally, the ""enhancing effect"" was more pronounced with greater grasp-type bias for each object in a test dataset. These results indicate the effectiveness of object affordance for guiding grasp-type recognition in multimodal robot teaching applications. The contributions of this study are (1) demonstrating the effectiveness of object affordance in guiding grasp-type recognition both with and without the real objects in images, (2) demonstrating the conditions under which the merits of object affordance are pronounced, and (3) providing a dataset of first-person grasping images labeled with possible grasp types for each object. &copy; 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","723 Computer Software, Data Handling and Applications;731.5 Robotics;913 Production Planning and Control; Manufacturing;922.2 Mathematical Statistics",Affordances;Condition;First person;Grasp-type recognition;Human-centered computing;Image-based;Implicit knowledge;Mixed reality;Multi-modal;Robot teaching,Acceptance tests;Character recognition;Image enhancement;Image recognition;Mixed reality;Robots;Statistical tests,2023,Journal article (JA),Mach Vision Appl,"(1) Wake, Naoki; (1) Saito, Daichi; (1) Sasabuchi, Kazuhiro; (2) Koike, Hideki; (1) Ikeuchi, Katsushi; ","(1) Applied Robotics Research, Microsoft, One Microsoft Way, Redmond; WA; 98052, United States; (2) School of Computing, Tokyo Institute of Technology, Ookayama, Meguro, Tokyo; 1528550, Japan; ",Springer Science and Business Media Deutschland GmbH,-1,"[""acceptance tests"", ""character recognition"", ""image enhancement"", ""image recognition"", ""robotics"", ""statistical tests""]","[""acceptance tests"", ""character recognition"", ""image enhancement"", ""image recognition"", ""robotics"", ""statistical tests""]",acceptance tests;character recognition;image enhancement;image recognition;robotics;statistical tests,computer vision;robotics;input;human factors;developers;data,technology;end users and user experience,computer vision;robotics;input;human factors;developers;data,technology;end users and user experience,acceptance_tests character_recognition image_enhancement image_recognition robotics statistical_tests affordances condition first_person grasp type_recognition human centered_computing image based implicit_knowledge mixed_reality multi modal robot_teaching 723_computer_software _data_handling_and_applications 731 5_robotics 913_production_planning_and_control _manufacturing 922 2_mathematical_statistics computer_vision robotics input human_factors developers data,acceptance_tests character_recognition image_enhancement image_recognition robotics statistical_tests,affordances condition first_person grasp type_recognition human centered_computing image based implicit_knowledge mixed_reality multi modal robot_teaching,robot teaching grasping strategy taught robot user critical information strategy contain implicit knowledge necessary successfully perform series manipulation however limited practical knowledge exists utilize linguistic information supporting grasp type recognition multimodal teaching study focused effect text driven object affordance mdash prior distribution grasp type object mdash image based grasp type recognition end created datasets first person grasping hand image labeled grasp type object name tested object affordance enhanced performance image based recognition evaluated two scenario real illusory object grasped considering teaching condition mixed reality lack visual object information make image based recognition challenging result show object affordance guided image based recognition two scenario increasing recognition accuracy 1 excluding unlikely grasp type candidate 2 enhancing likely grasp type additionally enhancing effect pronounced greater grasp type bias object test dataset result indicate effectiveness object affordance guiding grasp type recognition multimodal robot teaching application contribution study 1 demonstrating effectiveness object affordance guiding grasp type recognition without real object image 2 demonstrating condition merit object affordance pronounced 3 providing dataset first person grasping image labeled possible grasp type object copy 2023 author exclusive licence springer verlag gmbh germany part springer nature,acceptance_tests character_recognition image_enhancement image_recognition robotics statistical_tests affordances condition first_person grasp type_recognition human centered_computing image based implicit_knowledge mixed_reality multi modal robot_teaching 723_computer_software _data_handling_and_applications 731 5_robotics 913_production_planning_and_control _manufacturing 922 2_mathematical_statistics computer_vision robotics input human_factors developers data robot teaching grasping strategy taught robot user critical information strategy contain implicit knowledge necessary successfully perform series manipulation however limited practical knowledge exists utilize linguistic information supporting grasp type recognition multimodal teaching study focused effect text driven object affordance mdash prior distribution grasp type object mdash image based grasp type recognition end created datasets first person grasping hand image labeled grasp type object name tested object affordance enhanced performance image based recognition evaluated two scenario real illusory object grasped considering teaching condition mixed reality lack visual object information make image based recognition challenging result show object affordance guided image based recognition two scenario increasing recognition accuracy 1 excluding unlikely grasp type candidate 2 enhancing likely grasp type additionally enhancing effect pronounced greater grasp type bias object test dataset result indicate effectiveness object affordance guiding grasp type recognition multimodal robot teaching application contribution study 1 demonstrating effectiveness object affordance guiding grasp type recognition without real object image 2 demonstrating condition merit object affordance pronounced 3 providing dataset first person grasping image labeled possible grasp type object copy 2023 author exclusive licence springer verlag gmbh germany part springer nature,robot teaching grasping strategy taught robot user critical information strategy contain implicit knowledge necessary successfully perform series manipulation however limited practical knowledge exists utilize linguistic information supporting grasp type recognition multimodal teaching study focused effect text driven object affordance mdash prior distribution grasp type object mdash image based grasp type recognition end created datasets first person grasping hand image labeled grasp type object name tested object affordance enhanced performance image based recognition evaluated two scenario real illusory object grasped considering teaching condition mixed reality lack visual object information make image based recognition challenging result show object affordance guided image based recognition two scenario increasing recognition accuracy 1 excluding unlikely grasp type candidate 2 enhancing likely grasp type additionally enhancing effect pronounced greater grasp type bias object test dataset result indicate effectiveness object affordance guiding grasp type recognition multimodal robot teaching application contribution study 1 demonstrating effectiveness object affordance guiding grasp type recognition without real object image 2 demonstrating condition merit object affordance pronounced 3 providing dataset first person grasping image labeled possible grasp type object copy 2023 author exclusive licence springer verlag gmbh germany part springer natureacceptance_tests character_recognition image_enhancement image_recognition robotics statistical_testsaffordances condition first_person grasp type_recognition human centered_computing image based implicit_knowledge mixed_reality multi modal robot_teaching
488,Real-Time 3D Neuroendoscopic Guidance Using SLAM: First Clinical Studies,"Vagdargi, P., Uneri, A., Jones, C. K., Zhang, X., Wu, P., Han, R., Sisniega, A., Lee, J., Helm, P. A., Luciano, M. G., Anderson, W. S., Hager, G., & Siewerdsen, J. H. (2023). Real-time 3D neuroendoscopic guidance using SLAM: first clinical studies. Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling. https://doi.org/10.1117/12.2654595
",10.1117/12.2654595,"Purpose: Neurosurgical techniques often require accurate targeting of deep-brain structures even in the presence of deformation due intervention and egress of cerebrospinal fluid (CSF) during surgical access. Prior work reported simultaneous localization and mapping (SLAM) methods for endoscopic guidance using 3D reconstruction. In this work, methods for correcting the geometric distortion of a neuroendoscope are reported in a form that have been translated intraoperative use in first clinical studies. Furthermore, SLAM methods are evaluated in first clinical studies for real-time 3D endoscopic navigation with near real-time registration in the presence of deep-brain tissue deformation. Methods: A custom calibration jig with swivel mounts was designed and manufactured for neuroendoscope calibration in the operating room. The process is potentially suitable to intraoperative use while maintaining sterility of the endoscope, although the current calibration system was used in the operating room (OR) immediately following the case for offline analysis. A 6&times;7 checkerboard pattern was used to obtain corner locations for calibration, and the method was evaluated in terms of reprojection error (RPE). Neuroendoscopic video was acquired under an IRB-approved clinical study, demonstrating rich vascular features and other structures on the interior walls of the lateral ventricles for 3D point-cloud reconstruction. Geometric accuracy was evaluated in terms of projected error (PE) on a ground truth surface defined from MR or cone-beam CT (CBCT) images. Results: Intraoperative neuroendoscope calibration was achieved with sub-pixel [0.61 &plusmn; 0.20 px] error. The calibration yielded a focal length of 816.42 px and 822.71 px in X and Y directions respectively, along with radial distortion coefficients of -0.432 (first order term [k1]) and 0.158 (second order term [k2]). The 3D reconstruction was performed successfully with a PE of 0.23 &plusmn; 0.15 mm compared to the ground truth surface. Conclusions: The system for neuroendoscopic guidance based on SLAM 3D point-cloud reconstruction provided a promising platform for the development of 3D neuroendoscopy. The studies reported in this work presented an important means of neuroendoscope calibration in the OR and provided preliminary evidence for accurate 3D video reconstruction in first clinical studies. Future work aims to further extend the clinical evaluation and improve reconstruction accuracy using ventricular shape priors. &copy; 2023 SPIE.","461.1 Biomedical Engineering;461.2 Biological Materials and Tissue Engineering;461.6 Medicine and Pharmacology;462.4 Prosthetics;723 Computer Software, Data Handling and Applications;723.2 Data Processing and Image Processing;723.5 Computer Applications;741.2 Vision;746 Imaging Techniques",3D reconstruction;Clinical study;Image guided surgery;Intra-operative;Localization method;Mapping method;Neuro-endoscopes;Neuro-endoscopy;Real- time;Simultaneous localization and mapping,Calibration;Cerebrospinal fluid;Computer vision;Computerized tomography;Endoscopy;Errors;Image reconstruction;Medical imaging;Neurosurgery;Stereo image processing;Three dimensional computer graphics;Transplantation (surgical),2023,Conference article (CA),Progr. Biomed. Opt. Imaging Proc. SPIE,"(1) Vagdargi, P.; (2) Uneri, A.; (1) Jones, C.K.; (2) Zhang, X.; (2) Wu, P.; (2) Han, R.; (2) Sisniega, A.; (3) Lee, J.; (4) Helm, P.A.; (5) Luciano, M.; (5) Anderson, W.S.; (1) Hager, G.D.; (2) Siewerdsen, J.H.; ","(1) Department of Computer Science, Johns Hopkins University, Baltimore; MD, United States; (2) Department of Biomedical Engineering, Johns Hopkins University, Baltimore; MD, United States; (3) Department of Radiation Oncology, Johns Hopkins Medicine, Baltimore; MD, United States; (4) Medtronic, Littleton; MA, United States; (5) Department of Neurosurgery, Johns Hopkins Medicine, Baltimore; MD, United States; (6) Department of Imaging Physics, The University of Texas M. D. Anderson Cancer Center, Houston; TX, United States; ",SPIE,-1,"[""calibration"", ""cerebrospinal fluid"", ""computer vision"", ""computerized tomography"", ""endoscopy"", ""errors"", ""image reconstruction"", ""medical imaging"", ""neurosurgery"", ""stereo image processing"", ""three dimensional computer graphics"", ""transplantation""]","[""calibration"", ""cerebrospinal fluid"", ""computer vision"", ""computerized tomography"", ""endoscopy"", ""errors"", ""image reconstruction"", ""medical imaging"", ""neurosurgery"", ""stereo image processing"", ""three dimensional computer graphics"", ""transplantation""]",calibration;cerebrospinal fluid;computer vision;computerized tomography;endoscopy;errors;image reconstruction;medical imaging;neurosurgery;stereo image processing;three dimensional computer graphics;transplantation,construction;computer vision;other;graphics;medical;sensors;human factors;data,technology;other;end users and user experience;industries,construction;computer vision;other;graphics;medical;sensors;human factors;data,technology;other;end users and user experience;industries,calibration cerebrospinal_fluid computer_vision computerized_tomography endoscopy errors image_reconstruction medical_imaging neurosurgery stereo_image_processing three_dimensional_computer_graphics transplantation 3d_reconstruction clinical_study image_guided_surgery intra operative localization_method mapping_method neuro endoscopes neuro endoscopy real _time simultaneous_localization_and_mapping 461 1_biomedical_engineering 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 4_prosthetics 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications 741 2_vision 746_imaging_techniques construction computer_vision other graphics medical sensors human_factors data,calibration cerebrospinal_fluid computer_vision computerized_tomography endoscopy errors image_reconstruction medical_imaging neurosurgery stereo_image_processing three_dimensional_computer_graphics transplantation,3d_reconstruction clinical_study image_guided_surgery intra operative localization_method mapping_method neuro endoscopes neuro endoscopy real _time simultaneous_localization_and_mapping,purpose neurosurgical technique often require accurate targeting deep brain structure even presence deformation due intervention egress cerebrospinal fluid csf surgical access prior work reported simultaneous localization mapping slam method endoscopic guidance using 3d reconstruction work method correcting geometric distortion neuroendoscope reported form translated intraoperative use first clinical study furthermore slam method evaluated first clinical study real time 3d endoscopic navigation near real time registration presence deep brain tissue deformation method custom calibration jig swivel mount designed manufactured neuroendoscope calibration operating room process potentially suitable intraoperative use maintaining sterility endoscope although current calibration system used operating room immediately following case offline analysis 6 time 7 checkerboard pattern used obtain corner location calibration method evaluated term reprojection error rpe neuroendoscopic video acquired irb approved clinical study demonstrating rich vascular feature structure interior wall lateral ventricle 3d point cloud reconstruction geometric accuracy evaluated term projected error pe ground truth surface defined mr cone beam ct cbct image result intraoperative neuroendoscope calibration achieved sub pixel 0 61 plusmn 0 20 px error calibration yielded focal length 816 42 px 822 71 px x direction respectively along radial distortion coefficient 0 432 first order term k1 0 158 second order term k2 3d reconstruction performed successfully pe 0 23 plusmn 0 15 mm compared ground truth surface conclusion system neuroendoscopic guidance based slam 3d point cloud reconstruction provided promising platform development 3d neuroendoscopy study reported work presented important mean neuroendoscope calibration provided preliminary evidence accurate 3d video reconstruction first clinical study future work aim extend clinical evaluation improve reconstruction accuracy using ventricular shape prior copy 2023 spie,calibration cerebrospinal_fluid computer_vision computerized_tomography endoscopy errors image_reconstruction medical_imaging neurosurgery stereo_image_processing three_dimensional_computer_graphics transplantation 3d_reconstruction clinical_study image_guided_surgery intra operative localization_method mapping_method neuro endoscopes neuro endoscopy real _time simultaneous_localization_and_mapping 461 1_biomedical_engineering 461 2_biological_materials_and_tissue_engineering 461 6_medicine_and_pharmacology 462 4_prosthetics 723_computer_software _data_handling_and_applications 723 2_data_processing_and_image_processing 723 5_computer_applications 741 2_vision 746_imaging_techniques construction computer_vision other graphics medical sensors human_factors data purpose neurosurgical technique often require accurate targeting deep brain structure even presence deformation due intervention egress cerebrospinal fluid csf surgical access prior work reported simultaneous localization mapping slam method endoscopic guidance using 3d reconstruction work method correcting geometric distortion neuroendoscope reported form translated intraoperative use first clinical study furthermore slam method evaluated first clinical study real time 3d endoscopic navigation near real time registration presence deep brain tissue deformation method custom calibration jig swivel mount designed manufactured neuroendoscope calibration operating room process potentially suitable intraoperative use maintaining sterility endoscope although current calibration system used operating room immediately following case offline analysis 6 time 7 checkerboard pattern used obtain corner location calibration method evaluated term reprojection error rpe neuroendoscopic video acquired irb approved clinical study demonstrating rich vascular feature structure interior wall lateral ventricle 3d point cloud reconstruction geometric accuracy evaluated term projected error pe ground truth surface defined mr cone beam ct cbct image result intraoperative neuroendoscope calibration achieved sub pixel 0 61 plusmn 0 20 px error calibration yielded focal length 816 42 px 822 71 px x direction respectively along radial distortion coefficient 0 432 first order term k1 0 158 second order term k2 3d reconstruction performed successfully pe 0 23 plusmn 0 15 mm compared ground truth surface conclusion system neuroendoscopic guidance based slam 3d point cloud reconstruction provided promising platform development 3d neuroendoscopy study reported work presented important mean neuroendoscope calibration provided preliminary evidence accurate 3d video reconstruction first clinical study future work aim extend clinical evaluation improve reconstruction accuracy using ventricular shape prior copy 2023 spie,purpose neurosurgical technique often require accurate targeting deep brain structure even presence deformation due intervention egress cerebrospinal fluid csf surgical access prior work reported simultaneous localization mapping slam method endoscopic guidance using 3d reconstruction work method correcting geometric distortion neuroendoscope reported form translated intraoperative use first clinical study furthermore slam method evaluated first clinical study real time 3d endoscopic navigation near real time registration presence deep brain tissue deformation method custom calibration jig swivel mount designed manufactured neuroendoscope calibration operating room process potentially suitable intraoperative use maintaining sterility endoscope although current calibration system used operating room immediately following case offline analysis 6 time 7 checkerboard pattern used obtain corner location calibration method evaluated term reprojection error rpe neuroendoscopic video acquired irb approved clinical study demonstrating rich vascular feature structure interior wall lateral ventricle 3d point cloud reconstruction geometric accuracy evaluated term projected error pe ground truth surface defined mr cone beam ct cbct image result intraoperative neuroendoscope calibration achieved sub pixel 0 61 plusmn 0 20 px error calibration yielded focal length 816 42 px 822 71 px x direction respectively along radial distortion coefficient 0 432 first order term k1 0 158 second order term k2 3d reconstruction performed successfully pe 0 23 plusmn 0 15 mm compared ground truth surface conclusion system neuroendoscopic guidance based slam 3d point cloud reconstruction provided promising platform development 3d neuroendoscopy study reported work presented important mean neuroendoscope calibration provided preliminary evidence accurate 3d video reconstruction first clinical study future work aim extend clinical evaluation improve reconstruction accuracy using ventricular shape prior copy 2023 spiecalibration cerebrospinal_fluid computer_vision computerized_tomography endoscopy errors image_reconstruction medical_imaging neurosurgery stereo_image_processing three_dimensional_computer_graphics transplantation3d_reconstruction clinical_study image_guided_surgery intra operative localization_method mapping_method neuro endoscopes neuro endoscopy real _time simultaneous_localization_and_mapping
